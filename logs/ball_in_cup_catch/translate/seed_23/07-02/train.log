{"episode_reward": 0.0, "episode": 1.0, "duration": 24.838342905044556, "step": 250}
{"episode_reward": 0.0, "episode": 2.0, "duration": 1.1846904754638672, "step": 500}
{"episode_reward": 0.0, "episode": 3.0, "duration": 1.185708999633789, "step": 750}
{"episode_reward": 20.0, "episode": 4.0, "duration": 1.1845009326934814, "step": 1000}
{"episode_reward": 0.0, "episode": 5.0, "batch_reward": 0.0170546875, "critic_loss": 0.16893608708539978, "actor_loss": 0.056753730468917636, "actor_target_entropy": -2.0, "actor_entropy": 2.446104305461049, "alpha_loss": 0.31417872846126554, "alpha_value": 0.09939031655438636, "duration": 83.8653507232666, "step": 1250}
{"episode_reward": 0.0, "episode": 6.0, "batch_reward": 0.0135390625, "critic_loss": 0.09916519813449122, "actor_loss": -0.2152064539194107, "actor_target_entropy": -2.0, "actor_entropy": 2.5183586158752442, "alpha_loss": 0.32932173466682435, "alpha_value": 0.09811943094139614, "duration": 86.29091048240662, "step": 1500}
{"episode_reward": 0.0, "episode": 7.0, "batch_reward": 0.012375, "critic_loss": 0.0901733882110566, "actor_loss": -0.36370299744606016, "actor_target_entropy": -2.0, "actor_entropy": 2.550167013168335, "alpha_loss": 0.32448231244087217, "alpha_value": 0.09690001680756143, "duration": 86.39694952964783, "step": 1750}
{"episode_reward": 0.0, "episode": 8.0, "batch_reward": 0.010609375, "critic_loss": 0.057531677869847045, "actor_loss": -0.4210627205371857, "actor_target_entropy": -2.0, "actor_entropy": 2.567789659500122, "alpha_loss": 0.3208845269680023, "alpha_value": 0.09570942151966354, "duration": 86.31418919563293, "step": 2000}
{"episode_reward": 0.0, "episode": 9.0, "batch_reward": 0.1137109375, "critic_loss": 0.41157213562726974, "actor_loss": -0.651941239118576, "actor_target_entropy": -2.0, "actor_entropy": 2.58063041305542, "alpha_loss": 0.30170704555511474, "alpha_value": 0.09455650144609305, "duration": 86.39241051673889, "step": 2250}
{"episode_reward": 291.0, "episode": 10.0, "batch_reward": 0.132109375, "critic_loss": 0.3467736733257771, "actor_loss": -0.9140788717269898, "actor_target_entropy": -2.0, "actor_entropy": 2.5281855430603026, "alpha_loss": 0.2949866156578064, "alpha_value": 0.09346953690807097, "duration": 86.42666840553284, "step": 2500}
{"episode_reward": 0.0, "episode": 11.0, "batch_reward": 0.1212109375, "critic_loss": 0.3798987897634506, "actor_loss": -1.1279701981544494, "actor_target_entropy": -2.0, "actor_entropy": 2.485616174697876, "alpha_loss": 0.293095118522644, "alpha_value": 0.09237811828386237, "duration": 86.5286750793457, "step": 2750}
{"episode_reward": 0.0, "episode": 12.0, "batch_reward": 0.1088125, "critic_loss": 0.49980275890231135, "actor_loss": -1.386221743106842, "actor_target_entropy": -2.0, "actor_entropy": 2.504412281036377, "alpha_loss": 0.2851219930648804, "alpha_value": 0.09130634067615559, "duration": 86.4071593284607, "step": 3000}
{"episode_reward": 0.0, "episode": 13.0, "batch_reward": 0.103203125, "critic_loss": 0.6454079387784004, "actor_loss": -1.7115956258773803, "actor_target_entropy": -2.0, "actor_entropy": 2.5015161762237548, "alpha_loss": 0.27259965205192566, "alpha_value": 0.09026805840441234, "duration": 86.49437713623047, "step": 3250}
{"episode_reward": 0.0, "episode": 14.0, "batch_reward": 0.0918828125, "critic_loss": 1.0657657945156098, "actor_loss": -1.946552843093872, "actor_target_entropy": -2.0, "actor_entropy": 2.523634117126465, "alpha_loss": 0.26911446774005887, "alpha_value": 0.08925361024018054, "duration": 86.59441995620728, "step": 3500}
{"episode_reward": 0.0, "episode": 15.0, "batch_reward": 0.0886015625, "critic_loss": 1.1226382043361665, "actor_loss": -2.2449005613327024, "actor_target_entropy": -2.0, "actor_entropy": 2.5180802326202394, "alpha_loss": 0.2651040518283844, "alpha_value": 0.08825093200805757, "duration": 86.80704045295715, "step": 3750}
{"episode_reward": 0.0, "episode": 16.0, "batch_reward": 0.08275, "critic_loss": 2.222165058851242, "actor_loss": -2.513770893096924, "actor_target_entropy": -2.0, "actor_entropy": 2.5021158866882325, "alpha_loss": 0.2532707635164261, "alpha_value": 0.08727043241346556, "duration": 86.8094596862793, "step": 4000}
{"episode_reward": 24.0, "episode": 17.0, "batch_reward": 0.1162734375, "critic_loss": 6.9261011114120485, "actor_loss": -2.9423822116851808, "actor_target_entropy": -2.0, "actor_entropy": 2.444653057098389, "alpha_loss": 0.2288481068611145, "alpha_value": 0.08634640915787553, "duration": 86.91626358032227, "step": 4250}
{"episode_reward": 190.0, "episode": 18.0, "batch_reward": 0.1212421875, "critic_loss": 4.424764370918274, "actor_loss": -3.377595323562622, "actor_target_entropy": -2.0, "actor_entropy": 2.3952542877197267, "alpha_loss": 0.19714011806249618, "alpha_value": 0.08552443208109019, "duration": 86.60984706878662, "step": 4500}
{"episode_reward": 0.0, "episode": 19.0, "batch_reward": 0.110765625, "critic_loss": 4.478216033458709, "actor_loss": -3.7114163436889647, "actor_target_entropy": -2.0, "actor_entropy": 2.2339043130874634, "alpha_loss": 0.18903024715185165, "alpha_value": 0.0847596705584199, "duration": 86.62303352355957, "step": 4750}
{"episode_reward": 0.0, "episode": 20.0, "batch_reward": 0.19278125, "critic_loss": 6.283492637634278, "actor_loss": -5.494146224975586, "actor_target_entropy": -2.0, "actor_entropy": 2.0276773805618284, "alpha_loss": 0.15218331760168075, "alpha_value": 0.08404597950744382, "step": 5000}
{"duration": 109.61503672599792, "step": 5000}
{"episode_reward": 895.0, "episode": 21.0, "batch_reward": 0.2798046875, "critic_loss": 6.927744021415711, "actor_loss": -7.79472229385376, "actor_target_entropy": -2.0, "actor_entropy": 1.7893000679016113, "alpha_loss": 0.11545864301919938, "alpha_value": 0.08349132936055302, "duration": 87.76811838150024, "step": 5250}
{"episode_reward": 0.0, "episode": 22.0, "batch_reward": 0.282359375, "critic_loss": 10.663683801651, "actor_loss": -8.724384071350098, "actor_target_entropy": -2.0, "actor_entropy": 1.7566217794418335, "alpha_loss": 0.10920995950698853, "alpha_value": 0.08299263657819367, "duration": 88.51646065711975, "step": 5500}
{"episode_reward": 436.0, "episode": 23.0, "batch_reward": 0.32946875, "critic_loss": 12.789770921707154, "actor_loss": -10.493152164459229, "actor_target_entropy": -2.0, "actor_entropy": 1.633583529472351, "alpha_loss": 0.06637014743220061, "alpha_value": 0.08256745290284769, "duration": 88.82273697853088, "step": 5750}
{"episode_reward": 0.0, "episode": 24.0, "batch_reward": 0.3115703125, "critic_loss": 15.226354557037354, "actor_loss": -11.427676902770996, "actor_target_entropy": -2.0, "actor_entropy": 1.4738065433502197, "alpha_loss": 0.03876404949184507, "alpha_value": 0.0823417761082666, "duration": 88.64454555511475, "step": 6000}
{"episode_reward": 73.0, "episode": 25.0, "batch_reward": 0.33221875, "critic_loss": 18.439978496551515, "actor_loss": -12.878535362243653, "actor_target_entropy": -2.0, "actor_entropy": 1.3180474510192872, "alpha_loss": 0.05802138650789857, "alpha_value": 0.08208233417232377, "duration": 88.5742506980896, "step": 6250}
{"episode_reward": 470.0, "episode": 26.0, "batch_reward": 0.409375, "critic_loss": 18.502138427734376, "actor_loss": -15.713017860412597, "actor_target_entropy": -2.0, "actor_entropy": 1.2197434015274047, "alpha_loss": 0.0744638679921627, "alpha_value": 0.08170158254387323, "duration": 88.43802094459534, "step": 6500}
{"episode_reward": 658.0, "episode": 27.0, "batch_reward": 0.476234375, "critic_loss": 23.334756980895996, "actor_loss": -18.39760149383545, "actor_target_entropy": -2.0, "actor_entropy": 1.0587427091598511, "alpha_loss": 0.06571105879545212, "alpha_value": 0.08129388426050298, "duration": 88.87321400642395, "step": 6750}
{"episode_reward": 318.0, "episode": 28.0, "batch_reward": 0.549640625, "critic_loss": 27.307477767944334, "actor_loss": -21.328468643188476, "actor_target_entropy": -2.0, "actor_entropy": 0.8854913289546966, "alpha_loss": 0.06753980383276939, "alpha_value": 0.08088999006493934, "duration": 88.88681364059448, "step": 7000}
{"episode_reward": 876.0, "episode": 29.0, "batch_reward": 0.663734375, "critic_loss": 31.420890083312987, "actor_loss": -26.067894470214842, "actor_target_entropy": -2.0, "actor_entropy": 0.6922860488891601, "alpha_loss": 0.05667747205495834, "alpha_value": 0.080470661351335, "duration": 88.62375283241272, "step": 7250}
{"episode_reward": 994.0, "episode": 30.0, "batch_reward": 0.712484375, "critic_loss": 42.60890911865234, "actor_loss": -29.287434982299803, "actor_target_entropy": -2.0, "actor_entropy": 0.42082988560199736, "alpha_loss": 0.04088847096823156, "alpha_value": 0.08013636872706496, "duration": 88.66289019584656, "step": 7500}
{"episode_reward": 0.0, "episode": 31.0, "batch_reward": 0.74721875, "critic_loss": 48.64259497833252, "actor_loss": -32.68497340393066, "actor_target_entropy": -2.0, "actor_entropy": 0.3149634211882949, "alpha_loss": 0.026240957960952074, "alpha_value": 0.07990453303538382, "duration": 88.8836658000946, "step": 7750}
{"episode_reward": 992.0, "episode": 32.0, "batch_reward": 0.81325, "critic_loss": 54.62191020202637, "actor_loss": -36.83419140625, "actor_target_entropy": -2.0, "actor_entropy": 0.18102702143788338, "alpha_loss": 0.003586699662730098, "alpha_value": 0.07977761229237716, "duration": 88.6548535823822, "step": 8000}
{"episode_reward": 566.0, "episode": 33.0, "batch_reward": 0.8733828125, "critic_loss": 59.58523327636719, "actor_loss": -41.794831451416016, "actor_target_entropy": -2.0, "actor_entropy": 0.09415109487622976, "alpha_loss": -0.017805050547234715, "alpha_value": 0.07984371188615852, "duration": 88.99407434463501, "step": 8250}
{"episode_reward": 804.0, "episode": 34.0, "batch_reward": 0.9394453125, "critic_loss": 60.67979685974121, "actor_loss": -46.877769775390625, "actor_target_entropy": -2.0, "actor_entropy": -0.016348648019135, "alpha_loss": -0.03526073812134564, "alpha_value": 0.08007517421871815, "duration": 88.85589694976807, "step": 8500}
{"episode_reward": 733.0, "episode": 35.0, "batch_reward": 1.014, "critic_loss": 59.95006086730957, "actor_loss": -52.751538787841795, "actor_target_entropy": -2.0, "actor_entropy": -0.02786625040695071, "alpha_loss": -0.051836286269128326, "alpha_value": 0.08048337550045959, "duration": 88.58704137802124, "step": 8750}
{"episode_reward": 990.0, "episode": 36.0, "batch_reward": 1.0552265625, "critic_loss": 65.94490043640137, "actor_loss": -57.79631546020508, "actor_target_entropy": -2.0, "actor_entropy": -0.10603705189377069, "alpha_loss": -0.05266381774842739, "alpha_value": 0.08099293533307024, "duration": 89.0171639919281, "step": 9000}
{"episode_reward": 0.0, "episode": 37.0, "batch_reward": 1.0264375, "critic_loss": 67.20346420288087, "actor_loss": -60.86845523071289, "actor_target_entropy": -2.0, "actor_entropy": -0.2110059608221054, "alpha_loss": -0.05619831143319607, "alpha_value": 0.0815577812623234, "duration": 88.86472749710083, "step": 9250}
{"episode_reward": 0.0, "episode": 38.0, "batch_reward": 1.0069921875, "critic_loss": 63.862243026733395, "actor_loss": -63.889033508300784, "actor_target_entropy": -2.0, "actor_entropy": -0.1862174497321248, "alpha_loss": -0.0472395299077034, "alpha_value": 0.08211914485718298, "duration": 88.87008333206177, "step": 9500}
{"episode_reward": 558.0, "episode": 39.0, "batch_reward": 1.053265625, "critic_loss": 58.67529969787598, "actor_loss": -67.2513987121582, "actor_target_entropy": -2.0, "actor_entropy": -0.15539592507481576, "alpha_loss": -0.038581402719020844, "alpha_value": 0.08259916380618146, "duration": 88.81559419631958, "step": 9750}
{"episode_reward": 757.0, "episode": 40.0, "batch_reward": 1.096265625, "critic_loss": 52.27701303100586, "actor_loss": -70.59830737304688, "actor_target_entropy": -2.0, "actor_entropy": -0.009550365515053272, "alpha_loss": -0.03712381695210934, "alpha_value": 0.0830397575923982, "step": 10000}
{"duration": 111.5163505077362, "step": 10000}
{"episode_reward": 563.0, "episode": 41.0, "batch_reward": 1.1292109375, "critic_loss": 50.22652761077881, "actor_loss": -73.80383447265625, "actor_target_entropy": -2.0, "actor_entropy": 0.20393623358756305, "alpha_loss": -0.03363856279663741, "alpha_value": 0.08349381621696927, "duration": 93.96475434303284, "step": 10250}
{"episode_reward": 649.0, "episode": 42.0, "batch_reward": 1.191, "critic_loss": 51.013809341430665, "actor_loss": -77.62914611816406, "actor_target_entropy": -2.0, "actor_entropy": 0.28580792260169985, "alpha_loss": -0.03752685905620456, "alpha_value": 0.08396858146995367, "duration": 95.5815041065216, "step": 10500}
{"episode_reward": 988.0, "episode": 43.0, "batch_reward": 1.2587265625, "critic_loss": 51.572835525512694, "actor_loss": -82.35882916259766, "actor_target_entropy": -2.0, "actor_entropy": 0.3920265519022942, "alpha_loss": -0.05578980940580368, "alpha_value": 0.08456295830497504, "duration": 95.8153064250946, "step": 10750}
{"episode_reward": 995.0, "episode": 44.0, "batch_reward": 1.2705234375, "critic_loss": 59.02071070861816, "actor_loss": -85.7426548461914, "actor_target_entropy": -2.0, "actor_entropy": 0.49848889207839964, "alpha_loss": -0.06531901542842389, "alpha_value": 0.0854749270637335, "duration": 95.015310049057, "step": 11000}
{"episode_reward": 181.0, "episode": 45.0, "batch_reward": 1.2718125, "critic_loss": 68.26671769714355, "actor_loss": -89.19731622314453, "actor_target_entropy": -2.0, "actor_entropy": 0.4299777970314026, "alpha_loss": -0.07103691674768925, "alpha_value": 0.08649804816972831, "duration": 95.30405306816101, "step": 11250}
{"episode_reward": 641.0, "episode": 46.0, "batch_reward": 1.328234375, "critic_loss": 68.85977717590332, "actor_loss": -94.21737268066406, "actor_target_entropy": -2.0, "actor_entropy": 0.33619937220215795, "alpha_loss": -0.07079240643978119, "alpha_value": 0.08756098903955994, "duration": 95.23414087295532, "step": 11500}
{"episode_reward": 875.0, "episode": 47.0, "batch_reward": 1.3543359375, "critic_loss": 74.2864404449463, "actor_loss": -98.64347357177735, "actor_target_entropy": -2.0, "actor_entropy": 0.23256015990674495, "alpha_loss": -0.08094380351901054, "alpha_value": 0.08871646749373659, "duration": 95.1015088558197, "step": 11750}
{"episode_reward": 676.0, "episode": 48.0, "batch_reward": 1.383859375, "critic_loss": 76.47953392028809, "actor_loss": -102.70402569580078, "actor_target_entropy": -2.0, "actor_entropy": 0.08128419056534768, "alpha_loss": -0.08364905703067779, "alpha_value": 0.0899526413770152, "duration": 95.25693535804749, "step": 12000}
{"episode_reward": 841.0, "episode": 49.0, "batch_reward": 1.4447890625, "critic_loss": 73.42669021606446, "actor_loss": -109.00107348632812, "actor_target_entropy": -2.0, "actor_entropy": 0.11044529795646668, "alpha_loss": -0.09392613062262535, "alpha_value": 0.09127931139771822, "duration": 95.3878014087677, "step": 12250}
{"episode_reward": 869.0, "episode": 50.0, "batch_reward": 1.4786015625, "critic_loss": 66.36168878173828, "actor_loss": -113.17373449707031, "actor_target_entropy": -2.0, "actor_entropy": 0.09712371494621039, "alpha_loss": -0.0891093708574772, "alpha_value": 0.09266646046259233, "duration": 95.33311343193054, "step": 12500}
{"episode_reward": 864.0, "episode": 51.0, "batch_reward": 1.5166015625, "critic_loss": 65.2231053161621, "actor_loss": -117.94924951171875, "actor_target_entropy": -2.0, "actor_entropy": 0.03458728574961424, "alpha_loss": -0.08304616859555244, "alpha_value": 0.09395037733242063, "duration": 95.3576295375824, "step": 12750}
{"episode_reward": 944.0, "episode": 52.0, "batch_reward": 1.563890625, "critic_loss": 62.26304008483887, "actor_loss": -123.44963403320313, "actor_target_entropy": -2.0, "actor_entropy": -0.06633387193828821, "alpha_loss": -0.08007149413228035, "alpha_value": 0.09513724913196957, "duration": 95.39079594612122, "step": 13000}
{"episode_reward": 884.0, "episode": 53.0, "batch_reward": 1.5796953125, "critic_loss": 64.0819797821045, "actor_loss": -127.48471130371094, "actor_target_entropy": -2.0, "actor_entropy": -0.10578827188163996, "alpha_loss": -0.07235963079333306, "alpha_value": 0.0962726947080457, "duration": 95.50324130058289, "step": 13250}
{"episode_reward": 335.0, "episode": 54.0, "batch_reward": 1.604296875, "critic_loss": 61.263440231323244, "actor_loss": -131.03311596679688, "actor_target_entropy": -2.0, "actor_entropy": -0.177051146119833, "alpha_loss": -0.06552502861618996, "alpha_value": 0.0973319463862492, "duration": 95.44494295120239, "step": 13500}
{"episode_reward": 948.0, "episode": 55.0, "batch_reward": 1.64828125, "critic_loss": 56.55675326538086, "actor_loss": -135.8660831298828, "actor_target_entropy": -2.0, "actor_entropy": -0.16078336037695407, "alpha_loss": -0.06122643640637398, "alpha_value": 0.09831501508245484, "duration": 95.50740098953247, "step": 13750}
{"episode_reward": 981.0, "episode": 56.0, "batch_reward": 1.6760078125, "critic_loss": 55.24644303894043, "actor_loss": -139.58761889648437, "actor_target_entropy": -2.0, "actor_entropy": -0.13879845438152552, "alpha_loss": -0.06071400652825833, "alpha_value": 0.09929493198184115, "duration": 95.46967792510986, "step": 14000}
{"episode_reward": 784.0, "episode": 57.0, "batch_reward": 1.6970703125, "critic_loss": 56.678880493164066, "actor_loss": -143.54674108886718, "actor_target_entropy": -2.0, "actor_entropy": 2.4041511118412018e-05, "alpha_loss": -0.05783605061471462, "alpha_value": 0.10029339985497544, "duration": 95.89145135879517, "step": 14250}
{"episode_reward": 787.0, "episode": 58.0, "batch_reward": 1.696375, "critic_loss": 57.24530390930176, "actor_loss": -146.46540979003908, "actor_target_entropy": -2.0, "actor_entropy": 0.05922443177551031, "alpha_loss": -0.05489980438351631, "alpha_value": 0.1012430837079228, "duration": 95.84410405158997, "step": 14500}
{"episode_reward": 433.0, "episode": 59.0, "batch_reward": 1.7244765625, "critic_loss": 55.1838349609375, "actor_loss": -150.0897266845703, "actor_target_entropy": -2.0, "actor_entropy": 0.024281186483800413, "alpha_loss": -0.04208215519040823, "alpha_value": 0.10212262369129149, "duration": 95.98117589950562, "step": 14750}
{"episode_reward": 919.0, "episode": 60.0, "batch_reward": 1.77784375, "critic_loss": 51.14794879150391, "actor_loss": -154.5173494873047, "actor_target_entropy": -2.0, "actor_entropy": 0.03444983982294798, "alpha_loss": -0.03482674304023385, "alpha_value": 0.10281336804806623, "step": 15000}
{"duration": 118.9445652961731, "step": 15000}
{"episode_reward": 937.0, "episode": 61.0, "batch_reward": 1.7892578125, "critic_loss": 48.895360969543454, "actor_loss": -158.07028210449218, "actor_target_entropy": -2.0, "actor_entropy": 0.0859951651841402, "alpha_loss": -0.032393622981384394, "alpha_value": 0.10347101458361785, "duration": 96.01911115646362, "step": 15250}
{"episode_reward": 987.0, "episode": 62.0, "batch_reward": 1.83603125, "critic_loss": 44.95706783294678, "actor_loss": -162.01491857910156, "actor_target_entropy": -2.0, "actor_entropy": 0.01585108098387718, "alpha_loss": -0.030266917063854634, "alpha_value": 0.10411740659782986, "duration": 96.2275538444519, "step": 15500}
{"episode_reward": 972.0, "episode": 63.0, "batch_reward": 1.8581796875, "critic_loss": 44.25126668548584, "actor_loss": -165.3784158935547, "actor_target_entropy": -2.0, "actor_entropy": 0.0588187160640955, "alpha_loss": -0.031001301154494284, "alpha_value": 0.10479220356031697, "duration": 96.21411943435669, "step": 15750}
{"episode_reward": 848.0, "episode": 64.0, "batch_reward": 1.871296875, "critic_loss": 48.24524248504639, "actor_loss": -168.8239295654297, "actor_target_entropy": -2.0, "actor_entropy": -0.049702732048928736, "alpha_loss": -0.0406982235070318, "alpha_value": 0.10556339683020535, "duration": 96.12349820137024, "step": 16000}
{"episode_reward": 577.0, "episode": 65.0, "batch_reward": 1.90178125, "critic_loss": 46.043563987731936, "actor_loss": -171.7747039794922, "actor_target_entropy": -2.0, "actor_entropy": -0.030480293162167073, "alpha_loss": -0.03630396414827555, "alpha_value": 0.10650686946897474, "duration": 96.00897407531738, "step": 16250}
{"episode_reward": 987.0, "episode": 66.0, "batch_reward": 1.9250625, "critic_loss": 44.71898931121826, "actor_loss": -175.60855395507812, "actor_target_entropy": -2.0, "actor_entropy": -0.06132390286773443, "alpha_loss": -0.03428003020584583, "alpha_value": 0.10736525511170139, "duration": 96.18285727500916, "step": 16500}
{"episode_reward": 864.0, "episode": 67.0, "batch_reward": 1.949078125, "critic_loss": 42.12076055145263, "actor_loss": -179.0590870361328, "actor_target_entropy": -2.0, "actor_entropy": -0.04115402974188328, "alpha_loss": -0.03774483114294708, "alpha_value": 0.10827093700977229, "duration": 96.21106052398682, "step": 16750}
{"episode_reward": 856.0, "episode": 68.0, "batch_reward": 1.9770234375, "critic_loss": 39.91339398956299, "actor_loss": -182.13672192382813, "actor_target_entropy": -2.0, "actor_entropy": -0.04509861511737108, "alpha_loss": -0.03043636104092002, "alpha_value": 0.10922452551659657, "duration": 95.81639552116394, "step": 17000}
{"episode_reward": 924.0, "episode": 69.0, "batch_reward": 1.9880546875, "critic_loss": 38.68065431213379, "actor_loss": -185.06933178710938, "actor_target_entropy": -2.0, "actor_entropy": -0.020082707919180393, "alpha_loss": -0.01820609637349844, "alpha_value": 0.1098226794483178, "duration": 95.86138653755188, "step": 17250}
{"episode_reward": 991.0, "episode": 70.0, "batch_reward": 2.0335, "critic_loss": 36.42311409759522, "actor_loss": -188.96754736328126, "actor_target_entropy": -2.0, "actor_entropy": -0.0010286852121353148, "alpha_loss": -0.004078868417069316, "alpha_value": 0.11019352107229971, "duration": 95.84050583839417, "step": 17500}
