{"episode_reward": 0.0, "episode": 1.0, "duration": 24.838342905044556, "step": 250}
{"episode_reward": 0.0, "episode": 2.0, "duration": 1.1846904754638672, "step": 500}
{"episode_reward": 0.0, "episode": 3.0, "duration": 1.185708999633789, "step": 750}
{"episode_reward": 20.0, "episode": 4.0, "duration": 1.1845009326934814, "step": 1000}
{"episode_reward": 0.0, "episode": 5.0, "batch_reward": 0.0170546875, "critic_loss": 0.16893608708539978, "actor_loss": 0.056753730468917636, "actor_target_entropy": -2.0, "actor_entropy": 2.446104305461049, "alpha_loss": 0.31417872846126554, "alpha_value": 0.09939031655438636, "duration": 83.8653507232666, "step": 1250}
{"episode_reward": 0.0, "episode": 6.0, "batch_reward": 0.0135390625, "critic_loss": 0.09916519813449122, "actor_loss": -0.2152064539194107, "actor_target_entropy": -2.0, "actor_entropy": 2.5183586158752442, "alpha_loss": 0.32932173466682435, "alpha_value": 0.09811943094139614, "duration": 86.29091048240662, "step": 1500}
{"episode_reward": 0.0, "episode": 7.0, "batch_reward": 0.012375, "critic_loss": 0.0901733882110566, "actor_loss": -0.36370299744606016, "actor_target_entropy": -2.0, "actor_entropy": 2.550167013168335, "alpha_loss": 0.32448231244087217, "alpha_value": 0.09690001680756143, "duration": 86.39694952964783, "step": 1750}
{"episode_reward": 0.0, "episode": 8.0, "batch_reward": 0.010609375, "critic_loss": 0.057531677869847045, "actor_loss": -0.4210627205371857, "actor_target_entropy": -2.0, "actor_entropy": 2.567789659500122, "alpha_loss": 0.3208845269680023, "alpha_value": 0.09570942151966354, "duration": 86.31418919563293, "step": 2000}
{"episode_reward": 0.0, "episode": 9.0, "batch_reward": 0.1137109375, "critic_loss": 0.41157213562726974, "actor_loss": -0.651941239118576, "actor_target_entropy": -2.0, "actor_entropy": 2.58063041305542, "alpha_loss": 0.30170704555511474, "alpha_value": 0.09455650144609305, "duration": 86.39241051673889, "step": 2250}
{"episode_reward": 291.0, "episode": 10.0, "batch_reward": 0.132109375, "critic_loss": 0.3467736733257771, "actor_loss": -0.9140788717269898, "actor_target_entropy": -2.0, "actor_entropy": 2.5281855430603026, "alpha_loss": 0.2949866156578064, "alpha_value": 0.09346953690807097, "duration": 86.42666840553284, "step": 2500}
{"episode_reward": 0.0, "episode": 11.0, "batch_reward": 0.1212109375, "critic_loss": 0.3798987897634506, "actor_loss": -1.1279701981544494, "actor_target_entropy": -2.0, "actor_entropy": 2.485616174697876, "alpha_loss": 0.293095118522644, "alpha_value": 0.09237811828386237, "duration": 86.5286750793457, "step": 2750}
{"episode_reward": 0.0, "episode": 12.0, "batch_reward": 0.1088125, "critic_loss": 0.49980275890231135, "actor_loss": -1.386221743106842, "actor_target_entropy": -2.0, "actor_entropy": 2.504412281036377, "alpha_loss": 0.2851219930648804, "alpha_value": 0.09130634067615559, "duration": 86.4071593284607, "step": 3000}
{"episode_reward": 0.0, "episode": 13.0, "batch_reward": 0.103203125, "critic_loss": 0.6454079387784004, "actor_loss": -1.7115956258773803, "actor_target_entropy": -2.0, "actor_entropy": 2.5015161762237548, "alpha_loss": 0.27259965205192566, "alpha_value": 0.09026805840441234, "duration": 86.49437713623047, "step": 3250}
{"episode_reward": 0.0, "episode": 14.0, "batch_reward": 0.0918828125, "critic_loss": 1.0657657945156098, "actor_loss": -1.946552843093872, "actor_target_entropy": -2.0, "actor_entropy": 2.523634117126465, "alpha_loss": 0.26911446774005887, "alpha_value": 0.08925361024018054, "duration": 86.59441995620728, "step": 3500}
{"episode_reward": 0.0, "episode": 15.0, "batch_reward": 0.0886015625, "critic_loss": 1.1226382043361665, "actor_loss": -2.2449005613327024, "actor_target_entropy": -2.0, "actor_entropy": 2.5180802326202394, "alpha_loss": 0.2651040518283844, "alpha_value": 0.08825093200805757, "duration": 86.80704045295715, "step": 3750}
{"episode_reward": 0.0, "episode": 16.0, "batch_reward": 0.08275, "critic_loss": 2.222165058851242, "actor_loss": -2.513770893096924, "actor_target_entropy": -2.0, "actor_entropy": 2.5021158866882325, "alpha_loss": 0.2532707635164261, "alpha_value": 0.08727043241346556, "duration": 86.8094596862793, "step": 4000}
{"episode_reward": 24.0, "episode": 17.0, "batch_reward": 0.1162734375, "critic_loss": 6.9261011114120485, "actor_loss": -2.9423822116851808, "actor_target_entropy": -2.0, "actor_entropy": 2.444653057098389, "alpha_loss": 0.2288481068611145, "alpha_value": 0.08634640915787553, "duration": 86.91626358032227, "step": 4250}
{"episode_reward": 190.0, "episode": 18.0, "batch_reward": 0.1212421875, "critic_loss": 4.424764370918274, "actor_loss": -3.377595323562622, "actor_target_entropy": -2.0, "actor_entropy": 2.3952542877197267, "alpha_loss": 0.19714011806249618, "alpha_value": 0.08552443208109019, "duration": 86.60984706878662, "step": 4500}
{"episode_reward": 0.0, "episode": 19.0, "batch_reward": 0.110765625, "critic_loss": 4.478216033458709, "actor_loss": -3.7114163436889647, "actor_target_entropy": -2.0, "actor_entropy": 2.2339043130874634, "alpha_loss": 0.18903024715185165, "alpha_value": 0.0847596705584199, "duration": 86.62303352355957, "step": 4750}
{"episode_reward": 0.0, "episode": 20.0, "batch_reward": 0.19278125, "critic_loss": 6.283492637634278, "actor_loss": -5.494146224975586, "actor_target_entropy": -2.0, "actor_entropy": 2.0276773805618284, "alpha_loss": 0.15218331760168075, "alpha_value": 0.08404597950744382, "step": 5000}
{"duration": 109.61503672599792, "step": 5000}
{"episode_reward": 895.0, "episode": 21.0, "batch_reward": 0.2798046875, "critic_loss": 6.927744021415711, "actor_loss": -7.79472229385376, "actor_target_entropy": -2.0, "actor_entropy": 1.7893000679016113, "alpha_loss": 0.11545864301919938, "alpha_value": 0.08349132936055302, "duration": 87.76811838150024, "step": 5250}
{"episode_reward": 0.0, "episode": 22.0, "batch_reward": 0.282359375, "critic_loss": 10.663683801651, "actor_loss": -8.724384071350098, "actor_target_entropy": -2.0, "actor_entropy": 1.7566217794418335, "alpha_loss": 0.10920995950698853, "alpha_value": 0.08299263657819367, "duration": 88.51646065711975, "step": 5500}
{"episode_reward": 436.0, "episode": 23.0, "batch_reward": 0.32946875, "critic_loss": 12.789770921707154, "actor_loss": -10.493152164459229, "actor_target_entropy": -2.0, "actor_entropy": 1.633583529472351, "alpha_loss": 0.06637014743220061, "alpha_value": 0.08256745290284769, "duration": 88.82273697853088, "step": 5750}
{"episode_reward": 0.0, "episode": 24.0, "batch_reward": 0.3115703125, "critic_loss": 15.226354557037354, "actor_loss": -11.427676902770996, "actor_target_entropy": -2.0, "actor_entropy": 1.4738065433502197, "alpha_loss": 0.03876404949184507, "alpha_value": 0.0823417761082666, "duration": 88.64454555511475, "step": 6000}
{"episode_reward": 73.0, "episode": 25.0, "batch_reward": 0.33221875, "critic_loss": 18.439978496551515, "actor_loss": -12.878535362243653, "actor_target_entropy": -2.0, "actor_entropy": 1.3180474510192872, "alpha_loss": 0.05802138650789857, "alpha_value": 0.08208233417232377, "duration": 88.5742506980896, "step": 6250}
{"episode_reward": 470.0, "episode": 26.0, "batch_reward": 0.409375, "critic_loss": 18.502138427734376, "actor_loss": -15.713017860412597, "actor_target_entropy": -2.0, "actor_entropy": 1.2197434015274047, "alpha_loss": 0.0744638679921627, "alpha_value": 0.08170158254387323, "duration": 88.43802094459534, "step": 6500}
{"episode_reward": 658.0, "episode": 27.0, "batch_reward": 0.476234375, "critic_loss": 23.334756980895996, "actor_loss": -18.39760149383545, "actor_target_entropy": -2.0, "actor_entropy": 1.0587427091598511, "alpha_loss": 0.06571105879545212, "alpha_value": 0.08129388426050298, "duration": 88.87321400642395, "step": 6750}
{"episode_reward": 318.0, "episode": 28.0, "batch_reward": 0.549640625, "critic_loss": 27.307477767944334, "actor_loss": -21.328468643188476, "actor_target_entropy": -2.0, "actor_entropy": 0.8854913289546966, "alpha_loss": 0.06753980383276939, "alpha_value": 0.08088999006493934, "duration": 88.88681364059448, "step": 7000}
{"episode_reward": 876.0, "episode": 29.0, "batch_reward": 0.663734375, "critic_loss": 31.420890083312987, "actor_loss": -26.067894470214842, "actor_target_entropy": -2.0, "actor_entropy": 0.6922860488891601, "alpha_loss": 0.05667747205495834, "alpha_value": 0.080470661351335, "duration": 88.62375283241272, "step": 7250}
{"episode_reward": 994.0, "episode": 30.0, "batch_reward": 0.712484375, "critic_loss": 42.60890911865234, "actor_loss": -29.287434982299803, "actor_target_entropy": -2.0, "actor_entropy": 0.42082988560199736, "alpha_loss": 0.04088847096823156, "alpha_value": 0.08013636872706496, "duration": 88.66289019584656, "step": 7500}
{"episode_reward": 0.0, "episode": 31.0, "batch_reward": 0.74721875, "critic_loss": 48.64259497833252, "actor_loss": -32.68497340393066, "actor_target_entropy": -2.0, "actor_entropy": 0.3149634211882949, "alpha_loss": 0.026240957960952074, "alpha_value": 0.07990453303538382, "duration": 88.8836658000946, "step": 7750}
{"episode_reward": 992.0, "episode": 32.0, "batch_reward": 0.81325, "critic_loss": 54.62191020202637, "actor_loss": -36.83419140625, "actor_target_entropy": -2.0, "actor_entropy": 0.18102702143788338, "alpha_loss": 0.003586699662730098, "alpha_value": 0.07977761229237716, "duration": 88.6548535823822, "step": 8000}
{"episode_reward": 566.0, "episode": 33.0, "batch_reward": 0.8733828125, "critic_loss": 59.58523327636719, "actor_loss": -41.794831451416016, "actor_target_entropy": -2.0, "actor_entropy": 0.09415109487622976, "alpha_loss": -0.017805050547234715, "alpha_value": 0.07984371188615852, "duration": 88.99407434463501, "step": 8250}
{"episode_reward": 804.0, "episode": 34.0, "batch_reward": 0.9394453125, "critic_loss": 60.67979685974121, "actor_loss": -46.877769775390625, "actor_target_entropy": -2.0, "actor_entropy": -0.016348648019135, "alpha_loss": -0.03526073812134564, "alpha_value": 0.08007517421871815, "duration": 88.85589694976807, "step": 8500}
{"episode_reward": 733.0, "episode": 35.0, "batch_reward": 1.014, "critic_loss": 59.95006086730957, "actor_loss": -52.751538787841795, "actor_target_entropy": -2.0, "actor_entropy": -0.02786625040695071, "alpha_loss": -0.051836286269128326, "alpha_value": 0.08048337550045959, "duration": 88.58704137802124, "step": 8750}
{"episode_reward": 990.0, "episode": 36.0, "batch_reward": 1.0552265625, "critic_loss": 65.94490043640137, "actor_loss": -57.79631546020508, "actor_target_entropy": -2.0, "actor_entropy": -0.10603705189377069, "alpha_loss": -0.05266381774842739, "alpha_value": 0.08099293533307024, "duration": 89.0171639919281, "step": 9000}
{"episode_reward": 0.0, "episode": 37.0, "batch_reward": 1.0264375, "critic_loss": 67.20346420288087, "actor_loss": -60.86845523071289, "actor_target_entropy": -2.0, "actor_entropy": -0.2110059608221054, "alpha_loss": -0.05619831143319607, "alpha_value": 0.0815577812623234, "duration": 88.86472749710083, "step": 9250}
{"episode_reward": 0.0, "episode": 38.0, "batch_reward": 1.0069921875, "critic_loss": 63.862243026733395, "actor_loss": -63.889033508300784, "actor_target_entropy": -2.0, "actor_entropy": -0.1862174497321248, "alpha_loss": -0.0472395299077034, "alpha_value": 0.08211914485718298, "duration": 88.87008333206177, "step": 9500}
{"episode_reward": 558.0, "episode": 39.0, "batch_reward": 1.053265625, "critic_loss": 58.67529969787598, "actor_loss": -67.2513987121582, "actor_target_entropy": -2.0, "actor_entropy": -0.15539592507481576, "alpha_loss": -0.038581402719020844, "alpha_value": 0.08259916380618146, "duration": 88.81559419631958, "step": 9750}
{"episode_reward": 757.0, "episode": 40.0, "batch_reward": 1.096265625, "critic_loss": 52.27701303100586, "actor_loss": -70.59830737304688, "actor_target_entropy": -2.0, "actor_entropy": -0.009550365515053272, "alpha_loss": -0.03712381695210934, "alpha_value": 0.0830397575923982, "step": 10000}
{"duration": 111.5163505077362, "step": 10000}
{"episode_reward": 563.0, "episode": 41.0, "batch_reward": 1.1292109375, "critic_loss": 50.22652761077881, "actor_loss": -73.80383447265625, "actor_target_entropy": -2.0, "actor_entropy": 0.20393623358756305, "alpha_loss": -0.03363856279663741, "alpha_value": 0.08349381621696927, "duration": 93.96475434303284, "step": 10250}
{"episode_reward": 649.0, "episode": 42.0, "batch_reward": 1.191, "critic_loss": 51.013809341430665, "actor_loss": -77.62914611816406, "actor_target_entropy": -2.0, "actor_entropy": 0.28580792260169985, "alpha_loss": -0.03752685905620456, "alpha_value": 0.08396858146995367, "duration": 95.5815041065216, "step": 10500}
{"episode_reward": 988.0, "episode": 43.0, "batch_reward": 1.2587265625, "critic_loss": 51.572835525512694, "actor_loss": -82.35882916259766, "actor_target_entropy": -2.0, "actor_entropy": 0.3920265519022942, "alpha_loss": -0.05578980940580368, "alpha_value": 0.08456295830497504, "duration": 95.8153064250946, "step": 10750}
{"episode_reward": 995.0, "episode": 44.0, "batch_reward": 1.2705234375, "critic_loss": 59.02071070861816, "actor_loss": -85.7426548461914, "actor_target_entropy": -2.0, "actor_entropy": 0.49848889207839964, "alpha_loss": -0.06531901542842389, "alpha_value": 0.0854749270637335, "duration": 95.015310049057, "step": 11000}
{"episode_reward": 181.0, "episode": 45.0, "batch_reward": 1.2718125, "critic_loss": 68.26671769714355, "actor_loss": -89.19731622314453, "actor_target_entropy": -2.0, "actor_entropy": 0.4299777970314026, "alpha_loss": -0.07103691674768925, "alpha_value": 0.08649804816972831, "duration": 95.30405306816101, "step": 11250}
{"episode_reward": 641.0, "episode": 46.0, "batch_reward": 1.328234375, "critic_loss": 68.85977717590332, "actor_loss": -94.21737268066406, "actor_target_entropy": -2.0, "actor_entropy": 0.33619937220215795, "alpha_loss": -0.07079240643978119, "alpha_value": 0.08756098903955994, "duration": 95.23414087295532, "step": 11500}
{"episode_reward": 875.0, "episode": 47.0, "batch_reward": 1.3543359375, "critic_loss": 74.2864404449463, "actor_loss": -98.64347357177735, "actor_target_entropy": -2.0, "actor_entropy": 0.23256015990674495, "alpha_loss": -0.08094380351901054, "alpha_value": 0.08871646749373659, "duration": 95.1015088558197, "step": 11750}
{"episode_reward": 676.0, "episode": 48.0, "batch_reward": 1.383859375, "critic_loss": 76.47953392028809, "actor_loss": -102.70402569580078, "actor_target_entropy": -2.0, "actor_entropy": 0.08128419056534768, "alpha_loss": -0.08364905703067779, "alpha_value": 0.0899526413770152, "duration": 95.25693535804749, "step": 12000}
{"episode_reward": 841.0, "episode": 49.0, "batch_reward": 1.4447890625, "critic_loss": 73.42669021606446, "actor_loss": -109.00107348632812, "actor_target_entropy": -2.0, "actor_entropy": 0.11044529795646668, "alpha_loss": -0.09392613062262535, "alpha_value": 0.09127931139771822, "duration": 95.3878014087677, "step": 12250}
{"episode_reward": 869.0, "episode": 50.0, "batch_reward": 1.4786015625, "critic_loss": 66.36168878173828, "actor_loss": -113.17373449707031, "actor_target_entropy": -2.0, "actor_entropy": 0.09712371494621039, "alpha_loss": -0.0891093708574772, "alpha_value": 0.09266646046259233, "duration": 95.33311343193054, "step": 12500}
{"episode_reward": 864.0, "episode": 51.0, "batch_reward": 1.5166015625, "critic_loss": 65.2231053161621, "actor_loss": -117.94924951171875, "actor_target_entropy": -2.0, "actor_entropy": 0.03458728574961424, "alpha_loss": -0.08304616859555244, "alpha_value": 0.09395037733242063, "duration": 95.3576295375824, "step": 12750}
{"episode_reward": 944.0, "episode": 52.0, "batch_reward": 1.563890625, "critic_loss": 62.26304008483887, "actor_loss": -123.44963403320313, "actor_target_entropy": -2.0, "actor_entropy": -0.06633387193828821, "alpha_loss": -0.08007149413228035, "alpha_value": 0.09513724913196957, "duration": 95.39079594612122, "step": 13000}
{"episode_reward": 884.0, "episode": 53.0, "batch_reward": 1.5796953125, "critic_loss": 64.0819797821045, "actor_loss": -127.48471130371094, "actor_target_entropy": -2.0, "actor_entropy": -0.10578827188163996, "alpha_loss": -0.07235963079333306, "alpha_value": 0.0962726947080457, "duration": 95.50324130058289, "step": 13250}
{"episode_reward": 335.0, "episode": 54.0, "batch_reward": 1.604296875, "critic_loss": 61.263440231323244, "actor_loss": -131.03311596679688, "actor_target_entropy": -2.0, "actor_entropy": -0.177051146119833, "alpha_loss": -0.06552502861618996, "alpha_value": 0.0973319463862492, "duration": 95.44494295120239, "step": 13500}
{"episode_reward": 948.0, "episode": 55.0, "batch_reward": 1.64828125, "critic_loss": 56.55675326538086, "actor_loss": -135.8660831298828, "actor_target_entropy": -2.0, "actor_entropy": -0.16078336037695407, "alpha_loss": -0.06122643640637398, "alpha_value": 0.09831501508245484, "duration": 95.50740098953247, "step": 13750}
{"episode_reward": 981.0, "episode": 56.0, "batch_reward": 1.6760078125, "critic_loss": 55.24644303894043, "actor_loss": -139.58761889648437, "actor_target_entropy": -2.0, "actor_entropy": -0.13879845438152552, "alpha_loss": -0.06071400652825833, "alpha_value": 0.09929493198184115, "duration": 95.46967792510986, "step": 14000}
{"episode_reward": 784.0, "episode": 57.0, "batch_reward": 1.6970703125, "critic_loss": 56.678880493164066, "actor_loss": -143.54674108886718, "actor_target_entropy": -2.0, "actor_entropy": 2.4041511118412018e-05, "alpha_loss": -0.05783605061471462, "alpha_value": 0.10029339985497544, "duration": 95.89145135879517, "step": 14250}
{"episode_reward": 787.0, "episode": 58.0, "batch_reward": 1.696375, "critic_loss": 57.24530390930176, "actor_loss": -146.46540979003908, "actor_target_entropy": -2.0, "actor_entropy": 0.05922443177551031, "alpha_loss": -0.05489980438351631, "alpha_value": 0.1012430837079228, "duration": 95.84410405158997, "step": 14500}
{"episode_reward": 433.0, "episode": 59.0, "batch_reward": 1.7244765625, "critic_loss": 55.1838349609375, "actor_loss": -150.0897266845703, "actor_target_entropy": -2.0, "actor_entropy": 0.024281186483800413, "alpha_loss": -0.04208215519040823, "alpha_value": 0.10212262369129149, "duration": 95.98117589950562, "step": 14750}
{"episode_reward": 919.0, "episode": 60.0, "batch_reward": 1.77784375, "critic_loss": 51.14794879150391, "actor_loss": -154.5173494873047, "actor_target_entropy": -2.0, "actor_entropy": 0.03444983982294798, "alpha_loss": -0.03482674304023385, "alpha_value": 0.10281336804806623, "step": 15000}
{"duration": 118.9445652961731, "step": 15000}
{"episode_reward": 937.0, "episode": 61.0, "batch_reward": 1.7892578125, "critic_loss": 48.895360969543454, "actor_loss": -158.07028210449218, "actor_target_entropy": -2.0, "actor_entropy": 0.0859951651841402, "alpha_loss": -0.032393622981384394, "alpha_value": 0.10347101458361785, "duration": 96.01911115646362, "step": 15250}
{"episode_reward": 987.0, "episode": 62.0, "batch_reward": 1.83603125, "critic_loss": 44.95706783294678, "actor_loss": -162.01491857910156, "actor_target_entropy": -2.0, "actor_entropy": 0.01585108098387718, "alpha_loss": -0.030266917063854634, "alpha_value": 0.10411740659782986, "duration": 96.2275538444519, "step": 15500}
{"episode_reward": 972.0, "episode": 63.0, "batch_reward": 1.8581796875, "critic_loss": 44.25126668548584, "actor_loss": -165.3784158935547, "actor_target_entropy": -2.0, "actor_entropy": 0.0588187160640955, "alpha_loss": -0.031001301154494284, "alpha_value": 0.10479220356031697, "duration": 96.21411943435669, "step": 15750}
{"episode_reward": 848.0, "episode": 64.0, "batch_reward": 1.871296875, "critic_loss": 48.24524248504639, "actor_loss": -168.8239295654297, "actor_target_entropy": -2.0, "actor_entropy": -0.049702732048928736, "alpha_loss": -0.0406982235070318, "alpha_value": 0.10556339683020535, "duration": 96.12349820137024, "step": 16000}
{"episode_reward": 577.0, "episode": 65.0, "batch_reward": 1.90178125, "critic_loss": 46.043563987731936, "actor_loss": -171.7747039794922, "actor_target_entropy": -2.0, "actor_entropy": -0.030480293162167073, "alpha_loss": -0.03630396414827555, "alpha_value": 0.10650686946897474, "duration": 96.00897407531738, "step": 16250}
{"episode_reward": 987.0, "episode": 66.0, "batch_reward": 1.9250625, "critic_loss": 44.71898931121826, "actor_loss": -175.60855395507812, "actor_target_entropy": -2.0, "actor_entropy": -0.06132390286773443, "alpha_loss": -0.03428003020584583, "alpha_value": 0.10736525511170139, "duration": 96.18285727500916, "step": 16500}
{"episode_reward": 864.0, "episode": 67.0, "batch_reward": 1.949078125, "critic_loss": 42.12076055145263, "actor_loss": -179.0590870361328, "actor_target_entropy": -2.0, "actor_entropy": -0.04115402974188328, "alpha_loss": -0.03774483114294708, "alpha_value": 0.10827093700977229, "duration": 96.21106052398682, "step": 16750}
{"episode_reward": 856.0, "episode": 68.0, "batch_reward": 1.9770234375, "critic_loss": 39.91339398956299, "actor_loss": -182.13672192382813, "actor_target_entropy": -2.0, "actor_entropy": -0.04509861511737108, "alpha_loss": -0.03043636104092002, "alpha_value": 0.10922452551659657, "duration": 95.81639552116394, "step": 17000}
{"episode_reward": 924.0, "episode": 69.0, "batch_reward": 1.9880546875, "critic_loss": 38.68065431213379, "actor_loss": -185.06933178710938, "actor_target_entropy": -2.0, "actor_entropy": -0.020082707919180393, "alpha_loss": -0.01820609637349844, "alpha_value": 0.1098226794483178, "duration": 95.86138653755188, "step": 17250}
{"episode_reward": 991.0, "episode": 70.0, "batch_reward": 2.0335, "critic_loss": 36.42311409759522, "actor_loss": -188.96754736328126, "actor_target_entropy": -2.0, "actor_entropy": -0.0010286852121353148, "alpha_loss": -0.004078868417069316, "alpha_value": 0.11019352107229971, "duration": 95.84050583839417, "step": 17500}
{"episode_reward": 939.0, "episode": 71.0, "batch_reward": 2.047265625, "critic_loss": 33.41006177520752, "actor_loss": -191.80367272949218, "actor_target_entropy": -2.0, "actor_entropy": 0.03961743710190058, "alpha_loss": -0.0023611985445022585, "alpha_value": 0.11028266005510094, "duration": 95.76309752464294, "step": 17750}
{"episode_reward": 993.0, "episode": 72.0, "batch_reward": 2.06828125, "critic_loss": 34.12212713623047, "actor_loss": -194.7702694091797, "actor_target_entropy": -2.0, "actor_entropy": 0.0583353533744812, "alpha_loss": 0.006184091975912452, "alpha_value": 0.11019505568223337, "duration": 96.09544205665588, "step": 18000}
{"episode_reward": 928.0, "episode": 73.0, "batch_reward": 2.1034140625, "critic_loss": 32.9717651977539, "actor_loss": -197.86971130371094, "actor_target_entropy": -2.0, "actor_entropy": 0.06731469236314297, "alpha_loss": 0.011068522884510457, "alpha_value": 0.10990714045184198, "duration": 96.11289882659912, "step": 18250}
{"episode_reward": 910.0, "episode": 74.0, "batch_reward": 2.1210234375, "critic_loss": 31.93649331665039, "actor_loss": -201.06605505371093, "actor_target_entropy": -2.0, "actor_entropy": 0.15113571086898447, "alpha_loss": 0.01102581129875034, "alpha_value": 0.10949562097242622, "duration": 95.93389868736267, "step": 18500}
{"episode_reward": 988.0, "episode": 75.0, "batch_reward": 2.1509296875, "critic_loss": 32.66179328918457, "actor_loss": -204.26136218261718, "actor_target_entropy": -2.0, "actor_entropy": 0.16372423997521401, "alpha_loss": 0.01003544577397406, "alpha_value": 0.10906302818056549, "duration": 95.9866349697113, "step": 18750}
{"episode_reward": 914.0, "episode": 76.0, "batch_reward": 2.1649140625, "critic_loss": 31.003694648742677, "actor_loss": -206.49553845214842, "actor_target_entropy": -2.0, "actor_entropy": 0.1327775446102023, "alpha_loss": 0.009249711136333645, "alpha_value": 0.10869459178962773, "duration": 96.21821594238281, "step": 19000}
{"episode_reward": 944.0, "episode": 77.0, "batch_reward": 2.1944453125, "critic_loss": 30.421693267822267, "actor_loss": -209.82969140625, "actor_target_entropy": -2.0, "actor_entropy": 0.009839229732751847, "alpha_loss": 0.014029928758740425, "alpha_value": 0.1081987262966749, "duration": 96.12192463874817, "step": 19250}
{"episode_reward": 905.0, "episode": 78.0, "batch_reward": 2.19890625, "critic_loss": 28.867360641479493, "actor_loss": -212.56150573730469, "actor_target_entropy": -2.0, "actor_entropy": -0.16805212546139955, "alpha_loss": -0.006049081021454185, "alpha_value": 0.10799754165372148, "duration": 139.94884181022644, "step": 19500}
{"episode_reward": 898.0, "episode": 79.0, "batch_reward": 2.2208671875, "critic_loss": 29.763212265014648, "actor_loss": -215.51516979980468, "actor_target_entropy": -2.0, "actor_entropy": -0.2884101951420307, "alpha_loss": -0.011692369122058153, "alpha_value": 0.108495604473061, "duration": 99.16600060462952, "step": 19750}
{"episode_reward": 840.0, "episode": 80.0, "batch_reward": 2.2384453125, "critic_loss": 28.468935455322267, "actor_loss": -218.49284729003907, "actor_target_entropy": -2.0, "actor_entropy": -0.28991656577587127, "alpha_loss": -0.005798284938558936, "alpha_value": 0.10891867055628157, "step": 20000}
{"duration": 119.34154152870178, "step": 20000}
{"episode_reward": 944.0, "episode": 81.0, "batch_reward": 2.24790625, "critic_loss": 26.484118240356445, "actor_loss": -220.81060888671874, "actor_target_entropy": -2.0, "actor_entropy": -0.12932290280610323, "alpha_loss": -0.0011271237377077341, "alpha_value": 0.1090429230034103, "duration": 98.26523756980896, "step": 20250}
{"episode_reward": 924.0, "episode": 82.0, "batch_reward": 2.2749609375, "critic_loss": 23.46385182952881, "actor_loss": -223.27844787597655, "actor_target_entropy": -2.0, "actor_entropy": 0.07985357221961022, "alpha_loss": 0.007496221797540784, "alpha_value": 0.10887344294919202, "duration": 95.11725211143494, "step": 20500}
{"episode_reward": 989.0, "episode": 83.0, "batch_reward": 2.3001328125, "critic_loss": 21.910837913513184, "actor_loss": -225.87761474609374, "actor_target_entropy": -2.0, "actor_entropy": 0.12524563919007778, "alpha_loss": 0.007618630176410079, "alpha_value": 0.10842638103836862, "duration": 96.15198969841003, "step": 20750}
{"episode_reward": 918.0, "episode": 84.0, "batch_reward": 2.3024765625, "critic_loss": 20.130295307159425, "actor_loss": -227.90626721191407, "actor_target_entropy": -2.0, "actor_entropy": 0.18185924059897662, "alpha_loss": 0.0076990374475717546, "alpha_value": 0.10809009274877505, "duration": 95.9794340133667, "step": 21000}
{"episode_reward": 992.0, "episode": 85.0, "batch_reward": 2.339734375, "critic_loss": 19.04884965133667, "actor_loss": -230.59627111816405, "actor_target_entropy": -2.0, "actor_entropy": 0.26753194296360017, "alpha_loss": 0.013004573784768582, "alpha_value": 0.10745933621085282, "duration": 95.56290102005005, "step": 21250}
{"episode_reward": 986.0, "episode": 86.0, "batch_reward": 2.348421875, "critic_loss": 18.907634220123292, "actor_loss": -233.02983618164063, "actor_target_entropy": -2.0, "actor_entropy": 0.3594568680524826, "alpha_loss": 0.009385945945046843, "alpha_value": 0.10680247023313373, "duration": 95.07978439331055, "step": 21500}
{"episode_reward": 922.0, "episode": 87.0, "batch_reward": 2.3650390625, "critic_loss": 18.109144859313965, "actor_loss": -234.97555310058593, "actor_target_entropy": -2.0, "actor_entropy": 0.3228567576408386, "alpha_loss": 0.016605122556909917, "alpha_value": 0.1060599065506518, "duration": 96.91481804847717, "step": 21750}
{"episode_reward": 929.0, "episode": 88.0, "batch_reward": 2.36384375, "critic_loss": 16.661509925842285, "actor_loss": -236.9335994873047, "actor_target_entropy": -2.0, "actor_entropy": 0.28358854073286055, "alpha_loss": 0.015555474163033068, "alpha_value": 0.10507207196989352, "duration": 96.45682573318481, "step": 22000}
{"episode_reward": 932.0, "episode": 89.0, "batch_reward": 2.383234375, "critic_loss": 17.455417598724367, "actor_loss": -239.14167895507813, "actor_target_entropy": -2.0, "actor_entropy": 0.30207063849270344, "alpha_loss": 0.0184987835790962, "alpha_value": 0.1040271955316743, "duration": 95.13920617103577, "step": 22250}
{"episode_reward": 648.0, "episode": 90.0, "batch_reward": 2.396125, "critic_loss": 16.021212375640868, "actor_loss": -241.08434533691405, "actor_target_entropy": -2.0, "actor_entropy": 0.34996329379081725, "alpha_loss": 0.016198123547248543, "alpha_value": 0.10312671000611001, "duration": 95.0281388759613, "step": 22500}
{"episode_reward": 928.0, "episode": 91.0, "batch_reward": 2.3930078125, "critic_loss": 15.162226371765136, "actor_loss": -242.71111206054687, "actor_target_entropy": -2.0, "actor_entropy": 0.3744556782245636, "alpha_loss": 0.015050560179166495, "alpha_value": 0.10206127409450332, "duration": 95.2602117061615, "step": 22750}
{"episode_reward": 934.0, "episode": 92.0, "batch_reward": 2.422234375, "critic_loss": 15.604282669067382, "actor_loss": -244.8116904296875, "actor_target_entropy": -2.0, "actor_entropy": 0.41840450012683866, "alpha_loss": 0.01633797102794051, "alpha_value": 0.10118010218633568, "duration": 95.45592737197876, "step": 23000}
{"episode_reward": 940.0, "episode": 93.0, "batch_reward": 2.4361328125, "critic_loss": 15.89384419631958, "actor_loss": -246.47658544921876, "actor_target_entropy": -2.0, "actor_entropy": 0.3529043370485306, "alpha_loss": 0.016637748906388878, "alpha_value": 0.10020663497642791, "duration": 95.70692110061646, "step": 23250}
{"episode_reward": 766.0, "episode": 94.0, "batch_reward": 2.45446875, "critic_loss": 14.802472118377686, "actor_loss": -248.4320965576172, "actor_target_entropy": -2.0, "actor_entropy": 0.3590282804965973, "alpha_loss": 0.01786222726618871, "alpha_value": 0.09924672088355768, "duration": 97.52421236038208, "step": 23500}
{"episode_reward": 916.0, "episode": 95.0, "batch_reward": 2.45125, "critic_loss": 13.416031047821045, "actor_loss": -250.00970300292968, "actor_target_entropy": -2.0, "actor_entropy": 0.3835729402303696, "alpha_loss": 0.0240937182623893, "alpha_value": 0.0980916066211166, "duration": 95.40343356132507, "step": 23750}
{"episode_reward": 937.0, "episode": 96.0, "batch_reward": 2.4798671875, "critic_loss": 13.632704730987548, "actor_loss": -251.87184765625, "actor_target_entropy": -2.0, "actor_entropy": 0.36960101199150086, "alpha_loss": 0.02273716935142875, "alpha_value": 0.09673424424780441, "duration": 95.95733761787415, "step": 24000}
{"episode_reward": 985.0, "episode": 97.0, "batch_reward": 2.492421875, "critic_loss": 13.27414511680603, "actor_loss": -253.54601245117186, "actor_target_entropy": -2.0, "actor_entropy": 0.3326083316206932, "alpha_loss": 0.028422123901546, "alpha_value": 0.09542639136015577, "duration": 96.32596850395203, "step": 24250}
{"episode_reward": 955.0, "episode": 98.0, "batch_reward": 2.4878125, "critic_loss": 14.16857406616211, "actor_loss": -254.7200690917969, "actor_target_entropy": -2.0, "actor_entropy": 0.37065867441892625, "alpha_loss": 0.02815500747784972, "alpha_value": 0.09402669491516388, "duration": 95.59495282173157, "step": 24500}
{"episode_reward": 781.0, "episode": 99.0, "batch_reward": 2.5282890625, "critic_loss": 13.375173015594482, "actor_loss": -257.0279718017578, "actor_target_entropy": -2.0, "actor_entropy": 0.411424822807312, "alpha_loss": 0.025522055375389756, "alpha_value": 0.09271080822092104, "duration": 96.36353945732117, "step": 24750}
{"episode_reward": 980.0, "episode": 100.0, "batch_reward": 2.5191796875, "critic_loss": 13.249342987060547, "actor_loss": -258.2259423828125, "actor_target_entropy": -2.0, "actor_entropy": 0.3587322133779526, "alpha_loss": 0.027181488581001757, "alpha_value": 0.09155559014868403, "step": 25000}
{"duration": 118.40959310531616, "step": 25000}
{"episode_reward": 939.0, "episode": 101.0, "batch_reward": 2.5334921875, "critic_loss": 13.242412034988403, "actor_loss": -259.88668017578124, "actor_target_entropy": -2.0, "actor_entropy": 0.34503774261474607, "alpha_loss": 0.029648652507923545, "alpha_value": 0.09029295830755382, "duration": 96.50201630592346, "step": 25250}
{"episode_reward": 922.0, "episode": 102.0, "batch_reward": 2.5433046875, "critic_loss": 13.325143753051758, "actor_loss": -261.391046875, "actor_target_entropy": -2.0, "actor_entropy": 0.2605660162866116, "alpha_loss": 0.026912435630336403, "alpha_value": 0.08902710168347981, "duration": 95.79063177108765, "step": 25500}
{"episode_reward": 853.0, "episode": 103.0, "batch_reward": 2.5529375, "critic_loss": 13.486674263000488, "actor_loss": -263.0530068359375, "actor_target_entropy": -2.0, "actor_entropy": 0.3146225236356258, "alpha_loss": 0.020217710994184016, "alpha_value": 0.08807880403437843, "duration": 95.30242276191711, "step": 25750}
{"episode_reward": 868.0, "episode": 104.0, "batch_reward": 2.5548125, "critic_loss": 13.404560325622558, "actor_loss": -264.54253515625, "actor_target_entropy": -2.0, "actor_entropy": 0.3629560163021088, "alpha_loss": 0.02608458018861711, "alpha_value": 0.08713413148940785, "duration": 96.2421658039093, "step": 26000}
{"episode_reward": 989.0, "episode": 105.0, "batch_reward": 2.5740546875, "critic_loss": 12.315628038406372, "actor_loss": -266.0531318359375, "actor_target_entropy": -2.0, "actor_entropy": 0.316487415894866, "alpha_loss": 0.021897770475596188, "alpha_value": 0.08610619539499918, "duration": 95.05589032173157, "step": 26250}
{"episode_reward": 906.0, "episode": 106.0, "batch_reward": 2.5881640625, "critic_loss": 12.577154518127442, "actor_loss": -267.4040517578125, "actor_target_entropy": -2.0, "actor_entropy": 0.28530286794900894, "alpha_loss": 0.020315650055184962, "alpha_value": 0.08529380293884543, "duration": 96.2564115524292, "step": 26500}
{"episode_reward": 959.0, "episode": 107.0, "batch_reward": 2.605796875, "critic_loss": 11.90638722038269, "actor_loss": -269.08348876953124, "actor_target_entropy": -2.0, "actor_entropy": 0.3653611854314804, "alpha_loss": 0.022439934693276882, "alpha_value": 0.08441190795611822, "duration": 95.87135910987854, "step": 26750}
{"episode_reward": 989.0, "episode": 108.0, "batch_reward": 2.6166015625, "critic_loss": 12.255469440460205, "actor_loss": -270.7364873046875, "actor_target_entropy": -2.0, "actor_entropy": 0.3424514480829239, "alpha_loss": 0.02014206964708865, "alpha_value": 0.08352223450493053, "duration": 99.03724908828735, "step": 27000}
{"episode_reward": 940.0, "episode": 109.0, "batch_reward": 2.6150703125, "critic_loss": 12.986459922790527, "actor_loss": -271.7561171875, "actor_target_entropy": -2.0, "actor_entropy": 0.40902092134952545, "alpha_loss": 0.01999318212084472, "alpha_value": 0.08277326736649965, "duration": 95.22456693649292, "step": 27250}
{"episode_reward": 721.0, "episode": 110.0, "batch_reward": 2.6329140625, "critic_loss": 12.527075046539307, "actor_loss": -273.40295141601564, "actor_target_entropy": -2.0, "actor_entropy": 0.49968069553375244, "alpha_loss": 0.024653803776949645, "alpha_value": 0.08175784565964446, "duration": 95.72269535064697, "step": 27500}
{"episode_reward": 987.0, "episode": 111.0, "batch_reward": 2.63225, "critic_loss": 12.599263582229614, "actor_loss": -274.3384118652344, "actor_target_entropy": -2.0, "actor_entropy": 0.4569498265981674, "alpha_loss": 0.019963136805221438, "alpha_value": 0.08090034018127677, "duration": 96.68514609336853, "step": 27750}
{"episode_reward": 937.0, "episode": 112.0, "batch_reward": 2.647375, "critic_loss": 12.152034257888793, "actor_loss": -275.7757192382812, "actor_target_entropy": -2.0, "actor_entropy": 0.38964493286609647, "alpha_loss": 0.030955132871866225, "alpha_value": 0.07989397237377155, "duration": 97.49807381629944, "step": 28000}
{"episode_reward": 985.0, "episode": 113.0, "batch_reward": 2.659703125, "critic_loss": 11.703867891311646, "actor_loss": -277.0049838867188, "actor_target_entropy": -2.0, "actor_entropy": 0.33627333748340604, "alpha_loss": 0.027209812700748445, "alpha_value": 0.07877337629152528, "duration": 95.61543250083923, "step": 28250}
{"episode_reward": 936.0, "episode": 114.0, "batch_reward": 2.6704765625, "critic_loss": 11.901725254058839, "actor_loss": -278.5662800292969, "actor_target_entropy": -2.0, "actor_entropy": 0.3444599664211273, "alpha_loss": 0.026548147097229958, "alpha_value": 0.07780800989873429, "duration": 95.27947402000427, "step": 28500}
{"episode_reward": 921.0, "episode": 115.0, "batch_reward": 2.676984375, "critic_loss": 12.308877433776855, "actor_loss": -279.6746940917969, "actor_target_entropy": -2.0, "actor_entropy": 0.34615843945741653, "alpha_loss": 0.026382231436669828, "alpha_value": 0.07686466920260654, "duration": 95.49822092056274, "step": 28750}
{"episode_reward": 802.0, "episode": 116.0, "batch_reward": 2.6785234375, "critic_loss": 11.656457500457764, "actor_loss": -280.7783479003906, "actor_target_entropy": -2.0, "actor_entropy": 0.42583619117736815, "alpha_loss": 0.025767394576221705, "alpha_value": 0.07588248493989537, "duration": 94.9566810131073, "step": 29000}
{"episode_reward": 938.0, "episode": 117.0, "batch_reward": 2.6894765625, "critic_loss": 12.130834030151368, "actor_loss": -282.1090546875, "actor_target_entropy": -2.0, "actor_entropy": 0.324672946870327, "alpha_loss": 0.024908028088510035, "alpha_value": 0.07499162347720882, "duration": 96.61741590499878, "step": 29250}
{"episode_reward": 799.0, "episode": 118.0, "batch_reward": 2.6853203125, "critic_loss": 13.575831668853759, "actor_loss": -283.15198046875, "actor_target_entropy": -2.0, "actor_entropy": 0.2488258207887411, "alpha_loss": 0.02393143172003329, "alpha_value": 0.07414685024941582, "duration": 96.187002658844, "step": 29500}
{"episode_reward": 653.0, "episode": 119.0, "batch_reward": 2.7002734375, "critic_loss": 12.88196460723877, "actor_loss": -284.54963256835936, "actor_target_entropy": -2.0, "actor_entropy": 0.29774666571617125, "alpha_loss": 0.025463070986792444, "alpha_value": 0.07331014016511159, "duration": 95.78174901008606, "step": 29750}
{"episode_reward": 983.0, "episode": 120.0, "batch_reward": 2.69853125, "critic_loss": 12.851315378189087, "actor_loss": -285.5133898925781, "actor_target_entropy": -2.0, "actor_entropy": 0.38315077698230743, "alpha_loss": 0.019976696729660036, "alpha_value": 0.07251953067637262, "step": 30000}
{"duration": 118.4127299785614, "step": 30000}
{"episode_reward": 972.0, "episode": 121.0, "batch_reward": 2.707859375, "critic_loss": 12.48700168609619, "actor_loss": -286.65674658203125, "actor_target_entropy": -2.0, "actor_entropy": 0.3483640168905258, "alpha_loss": 0.014793716254644096, "alpha_value": 0.07192495055753524, "duration": 96.111741065979, "step": 30250}
{"episode_reward": 949.0, "episode": 122.0, "batch_reward": 2.71790625, "critic_loss": 12.820343942642213, "actor_loss": -287.81865625, "actor_target_entropy": -2.0, "actor_entropy": 0.29595805776119233, "alpha_loss": 0.020817550901323558, "alpha_value": 0.07131665745735426, "duration": 94.92653608322144, "step": 30500}
{"episode_reward": 889.0, "episode": 123.0, "batch_reward": 2.7231953125, "critic_loss": 12.648756490707397, "actor_loss": -289.09816723632815, "actor_target_entropy": -2.0, "actor_entropy": 0.2791839681267738, "alpha_loss": 0.01869737238623202, "alpha_value": 0.07059260134799047, "duration": 95.04756569862366, "step": 30750}
{"episode_reward": 863.0, "episode": 124.0, "batch_reward": 2.732, "critic_loss": 12.389988960266113, "actor_loss": -290.36624169921873, "actor_target_entropy": -2.0, "actor_entropy": 0.24350311010330916, "alpha_loss": 0.010759148835204542, "alpha_value": 0.07007986295100362, "duration": 98.15189623832703, "step": 31000}
{"episode_reward": 940.0, "episode": 125.0, "batch_reward": 2.7420234375, "critic_loss": 12.215980283737183, "actor_loss": -291.38596337890624, "actor_target_entropy": -2.0, "actor_entropy": 0.295481883585453, "alpha_loss": 0.01685476592555642, "alpha_value": 0.06957503636540262, "duration": 96.35384035110474, "step": 31250}
{"episode_reward": 993.0, "episode": 126.0, "batch_reward": 2.7525703125, "critic_loss": 11.871941247940063, "actor_loss": -292.87027368164064, "actor_target_entropy": -2.0, "actor_entropy": 0.23397584667801857, "alpha_loss": 0.019224502159282564, "alpha_value": 0.06889255491182375, "duration": 95.05340838432312, "step": 31500}
{"episode_reward": 945.0, "episode": 127.0, "batch_reward": 2.7548125, "critic_loss": 10.895533153533936, "actor_loss": -293.8202766113281, "actor_target_entropy": -2.0, "actor_entropy": 0.2814789406955242, "alpha_loss": 0.019275241462513804, "alpha_value": 0.06815622767537134, "duration": 96.05093884468079, "step": 31750}
{"episode_reward": 991.0, "episode": 128.0, "batch_reward": 2.77721875, "critic_loss": 10.761983394622803, "actor_loss": -295.2419958496094, "actor_target_entropy": -2.0, "actor_entropy": 0.24368669164180756, "alpha_loss": 0.018420475345104933, "alpha_value": 0.06747144574995817, "duration": 95.20386552810669, "step": 32000}
{"episode_reward": 993.0, "episode": 129.0, "batch_reward": 2.776046875, "critic_loss": 10.99036032295227, "actor_loss": -296.186736328125, "actor_target_entropy": -2.0, "actor_entropy": 0.30152634781599047, "alpha_loss": 0.016644976053386926, "alpha_value": 0.06677966312010805, "duration": 95.14617776870728, "step": 32250}
{"episode_reward": 991.0, "episode": 130.0, "batch_reward": 2.7908828125, "critic_loss": 11.521075933456421, "actor_loss": -297.371275390625, "actor_target_entropy": -2.0, "actor_entropy": 0.2726631563901901, "alpha_loss": 0.018188914090394973, "alpha_value": 0.06617685380418617, "duration": 95.49047613143921, "step": 32500}
{"episode_reward": 926.0, "episode": 131.0, "batch_reward": 2.8025078125, "critic_loss": 10.67225018119812, "actor_loss": -298.46153271484377, "actor_target_entropy": -2.0, "actor_entropy": 0.2548741232454777, "alpha_loss": 0.013330682078376413, "alpha_value": 0.06559386867925368, "duration": 95.6135425567627, "step": 32750}
{"episode_reward": 975.0, "episode": 132.0, "batch_reward": 2.804203125, "critic_loss": 10.609130012512207, "actor_loss": -299.4187868652344, "actor_target_entropy": -2.0, "actor_entropy": 0.2073267650604248, "alpha_loss": 0.016329222899861634, "alpha_value": 0.06499192053768675, "duration": 96.47506880760193, "step": 33000}
{"episode_reward": 960.0, "episode": 133.0, "batch_reward": 2.807359375, "critic_loss": 10.31913072013855, "actor_loss": -300.35020629882814, "actor_target_entropy": -2.0, "actor_entropy": 0.30657971078157426, "alpha_loss": 0.01685527731664479, "alpha_value": 0.06431173541342639, "duration": 95.27443170547485, "step": 33250}
{"episode_reward": 944.0, "episode": 134.0, "batch_reward": 2.8149453125, "critic_loss": 10.095945964813232, "actor_loss": -301.4331862792969, "actor_target_entropy": -2.0, "actor_entropy": 0.4012100349664688, "alpha_loss": 0.013161188527941703, "alpha_value": 0.06373164006676167, "duration": 96.39697313308716, "step": 33500}
{"episode_reward": 940.0, "episode": 135.0, "batch_reward": 2.82871875, "critic_loss": 10.228703588485718, "actor_loss": -302.69182836914064, "actor_target_entropy": -2.0, "actor_entropy": 0.3565776460170746, "alpha_loss": 0.01757680417969823, "alpha_value": 0.06315263460646876, "duration": 95.35237526893616, "step": 33750}
{"episode_reward": 949.0, "episode": 136.0, "batch_reward": 2.838078125, "critic_loss": 9.759478008270264, "actor_loss": -303.55684448242187, "actor_target_entropy": -2.0, "actor_entropy": 0.34729200875759125, "alpha_loss": 0.012882632683962584, "alpha_value": 0.06252642777160079, "duration": 95.34758853912354, "step": 34000}
{"episode_reward": 956.0, "episode": 137.0, "batch_reward": 2.842546875, "critic_loss": 10.421549938201904, "actor_loss": -304.8142299804687, "actor_target_entropy": -2.0, "actor_entropy": 0.34445679959654807, "alpha_loss": 0.011700800949707628, "alpha_value": 0.062022047806622294, "duration": 96.13406705856323, "step": 34250}
{"episode_reward": 994.0, "episode": 138.0, "batch_reward": 2.8493203125, "critic_loss": 9.825912401199341, "actor_loss": -305.7582841796875, "actor_target_entropy": -2.0, "actor_entropy": 0.2899253850579262, "alpha_loss": 0.010595764957834035, "alpha_value": 0.06157427548551079, "duration": 96.11078667640686, "step": 34500}
{"episode_reward": 961.0, "episode": 139.0, "batch_reward": 2.863875, "critic_loss": 9.941394857406616, "actor_loss": -306.929107421875, "actor_target_entropy": -2.0, "actor_entropy": 0.33874170506000517, "alpha_loss": 0.008267411800101399, "alpha_value": 0.061219842536641006, "duration": 96.09270596504211, "step": 34750}
{"episode_reward": 909.0, "episode": 140.0, "batch_reward": 2.865015625, "critic_loss": 9.871157537460327, "actor_loss": -307.8225085449219, "actor_target_entropy": -2.0, "actor_entropy": 0.2693959683179855, "alpha_loss": 0.015295405989512801, "alpha_value": 0.06070377418466816, "step": 35000}
{"duration": 118.86938428878784, "step": 35000}
{"episode_reward": 938.0, "episode": 141.0, "batch_reward": 2.8658359375, "critic_loss": 9.188960840225219, "actor_loss": -308.8574802246094, "actor_target_entropy": -2.0, "actor_entropy": 0.2136987355053425, "alpha_loss": 0.012746105894446373, "alpha_value": 0.06009701066713586, "duration": 96.28763222694397, "step": 35250}
{"episode_reward": 938.0, "episode": 142.0, "batch_reward": 2.87275, "critic_loss": 9.069168460845948, "actor_loss": -309.9478393554688, "actor_target_entropy": -2.0, "actor_entropy": 0.21223361103236676, "alpha_loss": 0.011578434049151837, "alpha_value": 0.05957489584097464, "duration": 95.95788359642029, "step": 35500}
{"episode_reward": 991.0, "episode": 143.0, "batch_reward": 2.87978125, "critic_loss": 8.983135665893554, "actor_loss": -310.9289345703125, "actor_target_entropy": -2.0, "actor_entropy": 0.26022568023204806, "alpha_loss": 0.009713768563233315, "alpha_value": 0.059130238738537254, "duration": 96.1411440372467, "step": 35750}
{"episode_reward": 994.0, "episode": 144.0, "batch_reward": 2.882859375, "critic_loss": 8.993215015411376, "actor_loss": -311.9192570800781, "actor_target_entropy": -2.0, "actor_entropy": 0.23731357121467592, "alpha_loss": 0.014968348361551762, "alpha_value": 0.058539435937262116, "duration": 96.16987299919128, "step": 36000}
{"episode_reward": 871.0, "episode": 145.0, "batch_reward": 2.8835625, "critic_loss": 9.182245525360107, "actor_loss": -312.7845612792969, "actor_target_entropy": -2.0, "actor_entropy": 0.34511029106378555, "alpha_loss": 0.011897891553118826, "alpha_value": 0.05794118176127956, "duration": 96.18332386016846, "step": 36250}
{"episode_reward": 898.0, "episode": 146.0, "batch_reward": 2.9076640625, "critic_loss": 8.963696222305298, "actor_loss": -314.0410849609375, "actor_target_entropy": -2.0, "actor_entropy": 0.29501126682758333, "alpha_loss": 0.016233067080844193, "alpha_value": 0.057328638398776444, "duration": 96.26391839981079, "step": 36500}
{"episode_reward": 960.0, "episode": 147.0, "batch_reward": 2.91090625, "critic_loss": 8.143395181655883, "actor_loss": -314.9184104003906, "actor_target_entropy": -2.0, "actor_entropy": 0.2208490288928151, "alpha_loss": 0.013894526437856257, "alpha_value": 0.05663862611937988, "duration": 96.21059036254883, "step": 36750}
{"episode_reward": 986.0, "episode": 148.0, "batch_reward": 2.909765625, "critic_loss": 8.37027155303955, "actor_loss": -315.7735178222656, "actor_target_entropy": -2.0, "actor_entropy": 0.12473826760798692, "alpha_loss": 0.013498934962786735, "alpha_value": 0.056090587900588934, "duration": 96.20539975166321, "step": 37000}
{"episode_reward": 950.0, "episode": 149.0, "batch_reward": 2.915859375, "critic_loss": 8.5875733127594, "actor_loss": -316.5091760253906, "actor_target_entropy": -2.0, "actor_entropy": 0.1476594705954194, "alpha_loss": 0.008968105333857238, "alpha_value": 0.05557826741527813, "duration": 96.37706136703491, "step": 37250}
{"episode_reward": 880.0, "episode": 150.0, "batch_reward": 2.92265625, "critic_loss": 8.547376073837281, "actor_loss": -317.4521496582031, "actor_target_entropy": -2.0, "actor_entropy": 0.2114347626566887, "alpha_loss": 0.009336331299040466, "alpha_value": 0.05517219553142085, "duration": 96.27489590644836, "step": 37500}
{"episode_reward": 994.0, "episode": 151.0, "batch_reward": 2.9299375, "critic_loss": 7.722375308990478, "actor_loss": -318.28672534179685, "actor_target_entropy": -2.0, "actor_entropy": 0.2511441416144371, "alpha_loss": 0.008224484594538808, "alpha_value": 0.054753615351829606, "duration": 96.23533535003662, "step": 37750}
{"episode_reward": 876.0, "episode": 152.0, "batch_reward": 2.9242265625, "critic_loss": 7.6600390167236325, "actor_loss": -319.0616125488281, "actor_target_entropy": -2.0, "actor_entropy": 0.14489262653887272, "alpha_loss": 0.011606593151111155, "alpha_value": 0.05435077885028663, "duration": 96.4321768283844, "step": 38000}
{"episode_reward": 942.0, "episode": 153.0, "batch_reward": 2.947640625, "critic_loss": 7.644078842163086, "actor_loss": -320.2530095214844, "actor_target_entropy": -2.0, "actor_entropy": 0.2284501331448555, "alpha_loss": 0.01377132725622505, "alpha_value": 0.05370502849727578, "duration": 96.24838876724243, "step": 38250}
{"episode_reward": 950.0, "episode": 154.0, "batch_reward": 2.943921875, "critic_loss": 7.607975698471069, "actor_loss": -320.82075732421873, "actor_target_entropy": -2.0, "actor_entropy": 0.21228510004281997, "alpha_loss": 0.01317241176404059, "alpha_value": 0.053120985945399796, "duration": 96.34622764587402, "step": 38500}
{"episode_reward": 944.0, "episode": 155.0, "batch_reward": 2.939703125, "critic_loss": 7.880965547561646, "actor_loss": -321.469048828125, "actor_target_entropy": -2.0, "actor_entropy": 0.1987828325033188, "alpha_loss": 0.01105143914418295, "alpha_value": 0.05254990817059634, "duration": 96.24439835548401, "step": 38750}
{"episode_reward": 951.0, "episode": 156.0, "batch_reward": 2.9463671875, "critic_loss": 7.614508333206177, "actor_loss": -322.27902758789065, "actor_target_entropy": -2.0, "actor_entropy": 0.17736812368035315, "alpha_loss": 0.012104264325462282, "alpha_value": 0.05206329750643002, "duration": 96.39405226707458, "step": 39000}
{"episode_reward": 722.0, "episode": 157.0, "batch_reward": 2.955828125, "critic_loss": 8.14917039680481, "actor_loss": -323.00803466796873, "actor_target_entropy": -2.0, "actor_entropy": 0.18119956738501788, "alpha_loss": 0.011313653752207756, "alpha_value": 0.05150775267291437, "duration": 96.21793985366821, "step": 39250}
{"episode_reward": 990.0, "episode": 158.0, "batch_reward": 2.9638515625, "critic_loss": 7.600188018798828, "actor_loss": -323.7262116699219, "actor_target_entropy": -2.0, "actor_entropy": 0.20438194808363913, "alpha_loss": 0.012673039488960057, "alpha_value": 0.050988297216879, "duration": 96.30429792404175, "step": 39500}
{"episode_reward": 991.0, "episode": 159.0, "batch_reward": 2.972171875, "critic_loss": 7.013653704643249, "actor_loss": -324.5312399902344, "actor_target_entropy": -2.0, "actor_entropy": 0.24523460242152215, "alpha_loss": 0.009776437100954353, "alpha_value": 0.050477243187941855, "duration": 96.3528425693512, "step": 39750}
{"episode_reward": 941.0, "episode": 160.0, "batch_reward": 2.975078125, "critic_loss": 7.6711604070663455, "actor_loss": -325.4570246582031, "actor_target_entropy": -2.0, "actor_entropy": 0.189075955145061, "alpha_loss": 0.010497998427599669, "alpha_value": 0.05005669366298879, "step": 40000}
{"duration": 119.46671104431152, "step": 40000}
{"episode_reward": 952.0, "episode": 161.0, "batch_reward": 2.9776328125, "critic_loss": 7.342155578613281, "actor_loss": -325.87547412109376, "actor_target_entropy": -2.0, "actor_entropy": 0.21817090509086848, "alpha_loss": 0.013601124581880867, "alpha_value": 0.04950411213506693, "duration": 96.32244539260864, "step": 40250}
{"episode_reward": 941.0, "episode": 162.0, "batch_reward": 2.976125, "critic_loss": 7.464318086624146, "actor_loss": -326.63218383789064, "actor_target_entropy": -2.0, "actor_entropy": 0.19859027460217477, "alpha_loss": 0.012707898902706802, "alpha_value": 0.04892841421445957, "duration": 96.27784037590027, "step": 40500}
{"episode_reward": 939.0, "episode": 163.0, "batch_reward": 2.9898671875, "critic_loss": 7.497258039474487, "actor_loss": -327.30690185546877, "actor_target_entropy": -2.0, "actor_entropy": 0.24473630461096763, "alpha_loss": 0.010440624782815575, "alpha_value": 0.04841077795567042, "duration": 96.57060289382935, "step": 40750}
{"episode_reward": 916.0, "episode": 164.0, "batch_reward": 2.98128125, "critic_loss": 7.757119740486145, "actor_loss": -327.9335734863281, "actor_target_entropy": -2.0, "actor_entropy": 0.17080588755011558, "alpha_loss": 0.013197212120518088, "alpha_value": 0.047880004136395406, "duration": 96.4840190410614, "step": 41000}
{"episode_reward": 823.0, "episode": 165.0, "batch_reward": 2.98959375, "critic_loss": 7.6881484699249265, "actor_loss": -328.6640720214844, "actor_target_entropy": -2.0, "actor_entropy": 0.19410441938787698, "alpha_loss": 0.00831152931880206, "alpha_value": 0.047461214894508275, "duration": 96.33430576324463, "step": 41250}
{"episode_reward": 941.0, "episode": 166.0, "batch_reward": 3.0011484375, "critic_loss": 7.668952741622925, "actor_loss": -329.4655634765625, "actor_target_entropy": -2.0, "actor_entropy": 0.14408072140812875, "alpha_loss": 0.010574432203546166, "alpha_value": 0.04702288736048163, "duration": 96.27155542373657, "step": 41500}
{"episode_reward": 943.0, "episode": 167.0, "batch_reward": 3.0041015625, "critic_loss": 8.019382843017578, "actor_loss": -330.2462438964844, "actor_target_entropy": -2.0, "actor_entropy": 0.223295846298337, "alpha_loss": 0.009902584823779762, "alpha_value": 0.04659204305437789, "duration": 96.34777545928955, "step": 41750}
{"episode_reward": 929.0, "episode": 168.0, "batch_reward": 3.0089921875, "critic_loss": 7.565796973228455, "actor_loss": -330.86839575195313, "actor_target_entropy": -2.0, "actor_entropy": 0.16113284918665885, "alpha_loss": 0.010872251554392278, "alpha_value": 0.04611375776332265, "duration": 96.35338997840881, "step": 42000}
{"episode_reward": 939.0, "episode": 169.0, "batch_reward": 3.011046875, "critic_loss": 7.585048545837402, "actor_loss": -331.4611970214844, "actor_target_entropy": -2.0, "actor_entropy": 0.14260558474808932, "alpha_loss": 0.013011110004037619, "alpha_value": 0.04560120396601108, "duration": 96.11992239952087, "step": 42250}
{"episode_reward": 938.0, "episode": 170.0, "batch_reward": 3.0159921875, "critic_loss": 7.476168956756592, "actor_loss": -332.1740190429687, "actor_target_entropy": -2.0, "actor_entropy": 0.1549734874367714, "alpha_loss": 0.00831767339631915, "alpha_value": 0.04506429676641279, "duration": 96.33341646194458, "step": 42500}
{"episode_reward": 943.0, "episode": 171.0, "batch_reward": 3.0126015625, "critic_loss": 7.449456573486328, "actor_loss": -332.588056640625, "actor_target_entropy": -2.0, "actor_entropy": 0.1703435202166438, "alpha_loss": 0.008509326059836893, "alpha_value": 0.04477487395680032, "duration": 96.56701850891113, "step": 42750}
{"episode_reward": 923.0, "episode": 172.0, "batch_reward": 3.02340625, "critic_loss": 7.391181811332703, "actor_loss": -333.3006423339844, "actor_target_entropy": -2.0, "actor_entropy": 0.07409771821647883, "alpha_loss": 0.011284788471646608, "alpha_value": 0.04436297677143254, "duration": 95.64965963363647, "step": 43000}
{"episode_reward": 944.0, "episode": 173.0, "batch_reward": 3.0269609375, "critic_loss": 7.547705810546875, "actor_loss": -333.7290908203125, "actor_target_entropy": -2.0, "actor_entropy": 0.11954820101708173, "alpha_loss": 0.013752819968387484, "alpha_value": 0.04378856050663597, "duration": 94.87242698669434, "step": 43250}
{"episode_reward": 807.0, "episode": 174.0, "batch_reward": 3.0354921875, "critic_loss": 7.256708715438843, "actor_loss": -334.3726650390625, "actor_target_entropy": -2.0, "actor_entropy": 0.13523713447898628, "alpha_loss": 0.009323059504851699, "alpha_value": 0.0432792968794204, "duration": 94.62311387062073, "step": 43500}
{"episode_reward": 993.0, "episode": 175.0, "batch_reward": 3.0342578125, "critic_loss": 7.0701951370239255, "actor_loss": -335.0107697753906, "actor_target_entropy": -2.0, "actor_entropy": 0.13982573137432336, "alpha_loss": 0.007742544050794095, "alpha_value": 0.042945623754831616, "duration": 94.67760944366455, "step": 43750}
{"episode_reward": 992.0, "episode": 176.0, "batch_reward": 3.046765625, "critic_loss": 7.05386909866333, "actor_loss": -335.746412109375, "actor_target_entropy": -2.0, "actor_entropy": 0.13576097501069306, "alpha_loss": 0.009229914170689881, "alpha_value": 0.04258383451537833, "duration": 94.76657748222351, "step": 44000}
{"episode_reward": 953.0, "episode": 177.0, "batch_reward": 3.03834375, "critic_loss": 7.2215483894348145, "actor_loss": -336.135703125, "actor_target_entropy": -2.0, "actor_entropy": 0.11815427323430777, "alpha_loss": 0.00974298980506137, "alpha_value": 0.042186481355896775, "duration": 94.55229187011719, "step": 44250}
{"episode_reward": 938.0, "episode": 178.0, "batch_reward": 3.0508671875, "critic_loss": 7.05770574092865, "actor_loss": -336.972244140625, "actor_target_entropy": -2.0, "actor_entropy": 0.06472987642139197, "alpha_loss": 0.007386176014319062, "alpha_value": 0.041777004317708755, "duration": 95.30414366722107, "step": 44500}
{"episode_reward": 1000.0, "episode": 179.0, "batch_reward": 3.049015625, "critic_loss": 7.530919940948486, "actor_loss": -337.45336596679687, "actor_target_entropy": -2.0, "actor_entropy": 0.09459613003581763, "alpha_loss": 0.0037153492728248237, "alpha_value": 0.04153979203521954, "duration": 95.16098475456238, "step": 44750}
{"episode_reward": 987.0, "episode": 180.0, "batch_reward": 3.0563125, "critic_loss": 7.341955221176147, "actor_loss": -338.15017993164065, "actor_target_entropy": -2.0, "actor_entropy": 0.19194319558888673, "alpha_loss": 0.006964618067257107, "alpha_value": 0.04129012010841364, "step": 45000}
{"duration": 118.0936951637268, "step": 45000}
{"episode_reward": 893.0, "episode": 181.0, "batch_reward": 3.059671875, "critic_loss": 6.962726649284363, "actor_loss": -338.7898486328125, "actor_target_entropy": -2.0, "actor_entropy": 0.15212140858918427, "alpha_loss": 0.0024225160372443495, "alpha_value": 0.041031141148852306, "duration": 94.89942145347595, "step": 45250}
{"episode_reward": 955.0, "episode": 182.0, "batch_reward": 3.058859375, "critic_loss": 6.8045224208831785, "actor_loss": -339.1891730957031, "actor_target_entropy": -2.0, "actor_entropy": 0.11871767549216747, "alpha_loss": 0.002867710801307112, "alpha_value": 0.04096669224663883, "duration": 94.65633034706116, "step": 45500}
{"episode_reward": 942.0, "episode": 183.0, "batch_reward": 3.0755859375, "critic_loss": 6.753603701591492, "actor_loss": -339.94441748046876, "actor_target_entropy": -2.0, "actor_entropy": 0.23053657477349043, "alpha_loss": 0.0067139655877836045, "alpha_value": 0.04070320677314598, "duration": 95.10130667686462, "step": 45750}
{"episode_reward": 997.0, "episode": 184.0, "batch_reward": 3.0729375, "critic_loss": 7.130162851333618, "actor_loss": -340.5621989746094, "actor_target_entropy": -2.0, "actor_entropy": 0.06146372098475695, "alpha_loss": 0.00574343819078058, "alpha_value": 0.04037303901525857, "duration": 94.93690967559814, "step": 46000}
{"episode_reward": 931.0, "episode": 185.0, "batch_reward": 3.0774921875, "critic_loss": 6.413934736251831, "actor_loss": -341.182185546875, "actor_target_entropy": -2.0, "actor_entropy": -0.004031455926597118, "alpha_loss": 0.00675723018636927, "alpha_value": 0.040091044578935614, "duration": 94.770676612854, "step": 46250}
{"episode_reward": 960.0, "episode": 186.0, "batch_reward": 3.0789453125, "critic_loss": 6.728002511024475, "actor_loss": -341.7656005859375, "actor_target_entropy": -2.0, "actor_entropy": 0.013693176865577698, "alpha_loss": 0.005686759217176586, "alpha_value": 0.03975205730276817, "duration": 94.74008870124817, "step": 46500}
{"episode_reward": 935.0, "episode": 187.0, "batch_reward": 3.07984375, "critic_loss": 6.758761972427368, "actor_loss": -342.3118798828125, "actor_target_entropy": -2.0, "actor_entropy": 0.05315462553501129, "alpha_loss": 0.009358900516293943, "alpha_value": 0.03934502972661521, "duration": 94.72665309906006, "step": 46750}
{"episode_reward": 941.0, "episode": 188.0, "batch_reward": 3.0837734375, "critic_loss": 6.637483488082886, "actor_loss": -342.7142272949219, "actor_target_entropy": -2.0, "actor_entropy": 0.09030227770656347, "alpha_loss": 0.007027023466769606, "alpha_value": 0.03892892271612639, "duration": 94.7117931842804, "step": 47000}
{"episode_reward": 874.0, "episode": 189.0, "batch_reward": 3.0918984375, "critic_loss": 6.418898391723633, "actor_loss": -343.2620927734375, "actor_target_entropy": -2.0, "actor_entropy": 0.13333596392720937, "alpha_loss": 0.004654888556338847, "alpha_value": 0.03861263456531221, "duration": 94.48864436149597, "step": 47250}
{"episode_reward": 926.0, "episode": 190.0, "batch_reward": 3.0866875, "critic_loss": 6.72350301361084, "actor_loss": -343.7531428222656, "actor_target_entropy": -2.0, "actor_entropy": 0.17442669405788183, "alpha_loss": 0.0009958916599862278, "alpha_value": 0.03844839186245564, "duration": 94.61931037902832, "step": 47500}
{"episode_reward": 989.0, "episode": 191.0, "batch_reward": 3.095609375, "critic_loss": 6.6345984096527095, "actor_loss": -344.3963186035156, "actor_target_entropy": -2.0, "actor_entropy": 0.0925976668894291, "alpha_loss": 0.00447184126963839, "alpha_value": 0.03834882454218207, "duration": 94.66418504714966, "step": 47750}
{"episode_reward": 958.0, "episode": 192.0, "batch_reward": 3.1015703125, "critic_loss": 6.552732118606567, "actor_loss": -344.8665883789063, "actor_target_entropy": -2.0, "actor_entropy": 0.19769667006283997, "alpha_loss": 0.008719276350457222, "alpha_value": 0.03795333124307279, "duration": 94.5402283668518, "step": 48000}
{"episode_reward": 821.0, "episode": 193.0, "batch_reward": 3.1061015625, "critic_loss": 6.1287615222930905, "actor_loss": -345.3600002441406, "actor_target_entropy": -2.0, "actor_entropy": 0.0759529092758894, "alpha_loss": 0.011193868030793966, "alpha_value": 0.03745139163162729, "duration": 94.55528235435486, "step": 48250}
{"episode_reward": 947.0, "episode": 194.0, "batch_reward": 3.114796875, "critic_loss": 6.046837163925171, "actor_loss": -345.8802177734375, "actor_target_entropy": -2.0, "actor_entropy": 0.008116977743804455, "alpha_loss": 0.00994038774445653, "alpha_value": 0.03690033294866328, "duration": 94.68874311447144, "step": 48500}
{"episode_reward": 988.0, "episode": 195.0, "batch_reward": 3.106, "critic_loss": 6.242678544998169, "actor_loss": -346.29759497070313, "actor_target_entropy": -2.0, "actor_entropy": -0.026716708548367024, "alpha_loss": 0.008029065166600048, "alpha_value": 0.036477687623976573, "duration": 94.82556343078613, "step": 48750}
{"episode_reward": 943.0, "episode": 196.0, "batch_reward": 3.10803125, "critic_loss": 6.1512948522567745, "actor_loss": -346.7890314941406, "actor_target_entropy": -2.0, "actor_entropy": -0.039687350146472455, "alpha_loss": 0.00785005732253194, "alpha_value": 0.03609795838519868, "duration": 94.68417739868164, "step": 49000}
{"episode_reward": 941.0, "episode": 197.0, "batch_reward": 3.12471875, "critic_loss": 6.09531966972351, "actor_loss": -347.15865112304687, "actor_target_entropy": -2.0, "actor_entropy": 0.008728019148111343, "alpha_loss": 0.005043785452842712, "alpha_value": 0.03578973232591046, "duration": 94.67111444473267, "step": 49250}
{"episode_reward": 950.0, "episode": 198.0, "batch_reward": 3.120203125, "critic_loss": 6.1360251302719115, "actor_loss": -347.719123046875, "actor_target_entropy": -2.0, "actor_entropy": 0.12635839732736348, "alpha_loss": 0.0028717508055269717, "alpha_value": 0.03562777599936124, "duration": 94.68364453315735, "step": 49500}
{"episode_reward": 926.0, "episode": 199.0, "batch_reward": 3.1303359375, "critic_loss": 6.686258848190308, "actor_loss": -348.192775390625, "actor_target_entropy": -2.0, "actor_entropy": 0.11628726925700902, "alpha_loss": 0.00413561510713771, "alpha_value": 0.03548642332034654, "duration": 94.9548761844635, "step": 49750}
{"episode_reward": 958.0, "episode": 200.0, "batch_reward": 3.134859375, "critic_loss": 6.698433353424072, "actor_loss": -348.51800610351563, "actor_target_entropy": -2.0, "actor_entropy": 0.040525776468217374, "alpha_loss": 0.005702493615914136, "alpha_value": 0.03519585834490809, "step": 50000}
{"duration": 117.57710003852844, "step": 50000}
{"episode_reward": 988.0, "episode": 201.0, "batch_reward": 3.129, "critic_loss": 6.675592660903931, "actor_loss": -348.7897209472656, "actor_target_entropy": -2.0, "actor_entropy": -0.023692573770880698, "alpha_loss": 0.002809176406241022, "alpha_value": 0.0350180572941912, "duration": 94.57857584953308, "step": 50250}
{"episode_reward": 990.0, "episode": 202.0, "batch_reward": 3.1366875, "critic_loss": 6.272949392318726, "actor_loss": -349.29058447265623, "actor_target_entropy": -2.0, "actor_entropy": -0.04613369368761778, "alpha_loss": 0.005066870700567961, "alpha_value": 0.03478143200321595, "duration": 94.39284634590149, "step": 50500}
{"episode_reward": 935.0, "episode": 203.0, "batch_reward": 3.14153125, "critic_loss": 6.607071201324463, "actor_loss": -349.79051440429686, "actor_target_entropy": -2.0, "actor_entropy": -0.014708871237933636, "alpha_loss": 0.005829926188802346, "alpha_value": 0.03446765081815157, "duration": 94.3965117931366, "step": 50750}
{"episode_reward": 985.0, "episode": 204.0, "batch_reward": 3.142, "critic_loss": 6.564919390678406, "actor_loss": -350.2577255859375, "actor_target_entropy": -2.0, "actor_entropy": -0.03834296064823866, "alpha_loss": 0.0054222108274698255, "alpha_value": 0.03417618912759206, "duration": 94.45957708358765, "step": 51000}
{"episode_reward": 991.0, "episode": 205.0, "batch_reward": 3.138828125, "critic_loss": 6.100036450386048, "actor_loss": -350.5956669921875, "actor_target_entropy": -2.0, "actor_entropy": -0.06473484683036804, "alpha_loss": 0.005571439219405875, "alpha_value": 0.03390002894847925, "duration": 94.13092422485352, "step": 51250}
{"episode_reward": 961.0, "episode": 206.0, "batch_reward": 3.1517890625, "critic_loss": 5.812178266525269, "actor_loss": -351.1778288574219, "actor_target_entropy": -2.0, "actor_entropy": -0.11386486778408289, "alpha_loss": 0.002640818924526684, "alpha_value": 0.03368527209727177, "duration": 94.15491390228271, "step": 51500}
{"episode_reward": 948.0, "episode": 207.0, "batch_reward": 3.157921875, "critic_loss": 5.80816548538208, "actor_loss": -351.5497048339844, "actor_target_entropy": -2.0, "actor_entropy": -0.026753902330994606, "alpha_loss": 0.0034316700922790914, "alpha_value": 0.0335286621919024, "duration": 94.34038519859314, "step": 51750}
{"episode_reward": 991.0, "episode": 208.0, "batch_reward": 3.16275, "critic_loss": 5.953274713516235, "actor_loss": -352.06199951171874, "actor_target_entropy": -2.0, "actor_entropy": -0.08644657053798437, "alpha_loss": 0.0035501918359659612, "alpha_value": 0.03331204715237944, "duration": 94.12018465995789, "step": 52000}
{"episode_reward": 924.0, "episode": 209.0, "batch_reward": 3.1576796875, "critic_loss": 5.6679290046691895, "actor_loss": -352.2534592285156, "actor_target_entropy": -2.0, "actor_entropy": -0.19439361446350814, "alpha_loss": 0.005239715299103409, "alpha_value": 0.03304210316753655, "duration": 94.27080154418945, "step": 52250}
{"episode_reward": 958.0, "episode": 210.0, "batch_reward": 3.168515625, "critic_loss": 5.881785297393799, "actor_loss": -352.9181716308594, "actor_target_entropy": -2.0, "actor_entropy": 0.04420624736696482, "alpha_loss": 0.0014337127530016005, "alpha_value": 0.03288784905971637, "duration": 94.16048383712769, "step": 52500}
{"episode_reward": 961.0, "episode": 211.0, "batch_reward": 3.170078125, "critic_loss": 6.1563803005218505, "actor_loss": -353.18921337890623, "actor_target_entropy": -2.0, "actor_entropy": 0.04187326018884778, "alpha_loss": 0.004296609441749751, "alpha_value": 0.03265811120037315, "duration": 94.40636372566223, "step": 52750}
{"episode_reward": 945.0, "episode": 212.0, "batch_reward": 3.1760078125, "critic_loss": 5.955780236244202, "actor_loss": -353.6486606445313, "actor_target_entropy": -2.0, "actor_entropy": 0.05025783482939005, "alpha_loss": 0.003785901219584048, "alpha_value": 0.032431641375693106, "duration": 94.72828197479248, "step": 53000}
{"episode_reward": 990.0, "episode": 213.0, "batch_reward": 3.174140625, "critic_loss": 5.919768911361694, "actor_loss": -353.7877844238281, "actor_target_entropy": -2.0, "actor_entropy": -0.03356431307643652, "alpha_loss": 0.00396594278793782, "alpha_value": 0.03224006204938211, "duration": 94.59591341018677, "step": 53250}
{"episode_reward": 933.0, "episode": 214.0, "batch_reward": 3.1704765625, "critic_loss": 5.696516032218933, "actor_loss": -354.1986484375, "actor_target_entropy": -2.0, "actor_entropy": 0.01647449056059122, "alpha_loss": 0.005216693704016507, "alpha_value": 0.03193997218121696, "duration": 94.77124166488647, "step": 53500}
{"episode_reward": 958.0, "episode": 215.0, "batch_reward": 3.1821953125, "critic_loss": 5.900985750198364, "actor_loss": -354.5988825683594, "actor_target_entropy": -2.0, "actor_entropy": -0.05754379411786795, "alpha_loss": 0.0035284809530712665, "alpha_value": 0.031671860705207985, "duration": 94.57979464530945, "step": 53750}
{"episode_reward": 991.0, "episode": 216.0, "batch_reward": 3.184890625, "critic_loss": 5.818702457427978, "actor_loss": -354.9630280761719, "actor_target_entropy": -2.0, "actor_entropy": -0.03985602810233831, "alpha_loss": 0.00408636036561802, "alpha_value": 0.0314680130516567, "duration": 94.84177708625793, "step": 54000}
{"episode_reward": 992.0, "episode": 217.0, "batch_reward": 3.18815625, "critic_loss": 5.290567636489868, "actor_loss": -355.2794128417969, "actor_target_entropy": -2.0, "actor_entropy": 0.03515864145755768, "alpha_loss": 0.005375813025981188, "alpha_value": 0.03115367162218344, "duration": 94.79587006568909, "step": 54250}
{"episode_reward": 991.0, "episode": 218.0, "batch_reward": 3.1909140625, "critic_loss": 5.575244070053101, "actor_loss": -355.72233935546876, "actor_target_entropy": -2.0, "actor_entropy": 0.028246406935155392, "alpha_loss": 0.0026086942318361253, "alpha_value": 0.030932751667176905, "duration": 95.07859373092651, "step": 54500}
{"episode_reward": 992.0, "episode": 219.0, "batch_reward": 3.2048515625, "critic_loss": 5.123667494773865, "actor_loss": -356.30402783203124, "actor_target_entropy": -2.0, "actor_entropy": -0.11268617777526378, "alpha_loss": 0.0011808354016393423, "alpha_value": 0.030845984991632415, "duration": 95.09862208366394, "step": 54750}
{"episode_reward": 961.0, "episode": 220.0, "batch_reward": 3.200375, "critic_loss": 5.757829173088074, "actor_loss": -356.51321728515626, "actor_target_entropy": -2.0, "actor_entropy": -0.16206825979799033, "alpha_loss": 0.0021312866096850486, "alpha_value": 0.03072568322770244, "step": 55000}
{"duration": 118.30663275718689, "step": 55000}
{"episode_reward": 942.0, "episode": 221.0, "batch_reward": 3.196734375, "critic_loss": 6.362771233558655, "actor_loss": -356.74541186523436, "actor_target_entropy": -2.0, "actor_entropy": -0.19652146942913531, "alpha_loss": 0.0007191396867856384, "alpha_value": 0.030614682315814875, "duration": 94.54047322273254, "step": 55250}
{"episode_reward": 925.0, "episode": 222.0, "batch_reward": 3.1988515625, "critic_loss": 6.077645913124084, "actor_loss": -357.277173828125, "actor_target_entropy": -2.0, "actor_entropy": 0.07732359161227942, "alpha_loss": 0.0005910817063413561, "alpha_value": 0.030583655917807998, "duration": 94.59065842628479, "step": 55500}
{"episode_reward": 895.0, "episode": 223.0, "batch_reward": 3.2086875, "critic_loss": 5.556111406326294, "actor_loss": -357.6281625976562, "actor_target_entropy": -2.0, "actor_entropy": 0.024360096715390682, "alpha_loss": 0.002083668696694076, "alpha_value": 0.030528922389460905, "duration": 94.29131507873535, "step": 55750}
{"episode_reward": 951.0, "episode": 224.0, "batch_reward": 3.2097265625, "critic_loss": 6.138656867027283, "actor_loss": -358.04584814453125, "actor_target_entropy": -2.0, "actor_entropy": -0.26000435489416124, "alpha_loss": 0.0040116991039831195, "alpha_value": 0.03025909127563944, "duration": 94.37101817131042, "step": 56000}
{"episode_reward": 907.0, "episode": 225.0, "batch_reward": 3.19584375, "critic_loss": 6.406463013648986, "actor_loss": -358.1634323730469, "actor_target_entropy": -2.0, "actor_entropy": -0.13793593768030404, "alpha_loss": 0.0041826788960024714, "alpha_value": 0.030005522555448486, "duration": 94.31693410873413, "step": 56250}
{"episode_reward": 932.0, "episode": 226.0, "batch_reward": 3.212640625, "critic_loss": 5.541303983688355, "actor_loss": -358.5601271972656, "actor_target_entropy": -2.0, "actor_entropy": -0.09835574920475483, "alpha_loss": 0.0019880005228333176, "alpha_value": 0.029809371332285266, "duration": 94.37775874137878, "step": 56500}
{"episode_reward": 989.0, "episode": 227.0, "batch_reward": 3.2163125, "critic_loss": 5.551578575134277, "actor_loss": -359.0710927734375, "actor_target_entropy": -2.0, "actor_entropy": -0.05037945953384042, "alpha_loss": 0.0046915530464611945, "alpha_value": 0.029573598045113232, "duration": 94.45198440551758, "step": 56750}
{"episode_reward": 993.0, "episode": 228.0, "batch_reward": 3.2156640625, "critic_loss": 5.229204480171203, "actor_loss": -359.29973876953125, "actor_target_entropy": -2.0, "actor_entropy": -0.11230161594599486, "alpha_loss": 0.003750612634699792, "alpha_value": 0.029286006489648332, "duration": 94.4030921459198, "step": 57000}
{"episode_reward": 987.0, "episode": 229.0, "batch_reward": 3.227296875, "critic_loss": 5.172192938804627, "actor_loss": -359.79727685546874, "actor_target_entropy": -2.0, "actor_entropy": -0.29163206891715526, "alpha_loss": 0.001700409040087834, "alpha_value": 0.029081355777094236, "duration": 94.84769201278687, "step": 57250}
{"episode_reward": 953.0, "episode": 230.0, "batch_reward": 3.2153515625, "critic_loss": 5.637794041633606, "actor_loss": -359.903814453125, "actor_target_entropy": -2.0, "actor_entropy": -0.20429613686352968, "alpha_loss": 0.001926632612477988, "alpha_value": 0.028990427289098338, "duration": 94.9077832698822, "step": 57500}
{"episode_reward": 953.0, "episode": 231.0, "batch_reward": 3.2235703125, "critic_loss": 5.072652685165405, "actor_loss": -360.26784057617186, "actor_target_entropy": -2.0, "actor_entropy": 0.09111793990433216, "alpha_loss": 0.0032033846799749883, "alpha_value": 0.028780370480809284, "duration": 94.77681112289429, "step": 57750}
{"episode_reward": 959.0, "episode": 232.0, "batch_reward": 3.2324140625, "critic_loss": 4.765391143798828, "actor_loss": -360.73763061523437, "actor_target_entropy": -2.0, "actor_entropy": 0.10770105521380902, "alpha_loss": 0.0016365342638455331, "alpha_value": 0.028664475529494273, "duration": 94.73214101791382, "step": 58000}
{"episode_reward": 990.0, "episode": 233.0, "batch_reward": 3.2428671875, "critic_loss": 4.68759373664856, "actor_loss": -361.12593676757814, "actor_target_entropy": -2.0, "actor_entropy": 0.0034536960162222384, "alpha_loss": 0.0016480649705044926, "alpha_value": 0.02856893222108733, "duration": 94.87232518196106, "step": 58250}
{"episode_reward": 995.0, "episode": 234.0, "batch_reward": 3.235296875, "critic_loss": 4.885636644363403, "actor_loss": -361.28307373046874, "actor_target_entropy": -2.0, "actor_entropy": -0.128731720328331, "alpha_loss": 0.005673975303769112, "alpha_value": 0.02827074627421029, "duration": 94.84824991226196, "step": 58500}
{"episode_reward": 986.0, "episode": 235.0, "batch_reward": 3.2344609375, "critic_loss": 5.467371557235718, "actor_loss": -361.6313000488281, "actor_target_entropy": -2.0, "actor_entropy": -0.07496945502609015, "alpha_loss": 0.0046451587211340664, "alpha_value": 0.027896725879104453, "duration": 94.81979632377625, "step": 58750}
{"episode_reward": 951.0, "episode": 236.0, "batch_reward": 3.2456796875, "critic_loss": 4.949186899662018, "actor_loss": -361.91990307617186, "actor_target_entropy": -2.0, "actor_entropy": -0.0578354224935174, "alpha_loss": 0.003627561151981354, "alpha_value": 0.027657822858281732, "duration": 94.81704473495483, "step": 59000}
{"episode_reward": 990.0, "episode": 237.0, "batch_reward": 3.2382265625, "critic_loss": 5.281852921485901, "actor_loss": -362.1207287597656, "actor_target_entropy": -2.0, "actor_entropy": -0.11393665270507336, "alpha_loss": 0.0035834614681079986, "alpha_value": 0.027387780803444534, "duration": 94.94473958015442, "step": 59250}
{"episode_reward": 990.0, "episode": 238.0, "batch_reward": 3.2439453125, "critic_loss": 5.11421721458435, "actor_loss": -362.3064697265625, "actor_target_entropy": -2.0, "actor_entropy": -0.08200176832824946, "alpha_loss": 0.002096499170642346, "alpha_value": 0.027262804601285287, "duration": 94.98824000358582, "step": 59500}
{"episode_reward": 959.0, "episode": 239.0, "batch_reward": 3.253484375, "critic_loss": 4.934364490509033, "actor_loss": -362.72453271484375, "actor_target_entropy": -2.0, "actor_entropy": 0.14003578627109528, "alpha_loss": 0.00027839824254624547, "alpha_value": 0.02718611524993666, "duration": 94.83355593681335, "step": 59750}
{"episode_reward": 985.0, "episode": 240.0, "batch_reward": 3.2568203125, "critic_loss": 4.959751097679138, "actor_loss": -362.9946484375, "actor_target_entropy": -2.0, "actor_entropy": -0.13907568406313658, "alpha_loss": 0.00252997186454013, "alpha_value": 0.027076810786500267, "step": 60000}
{"duration": 117.90919280052185, "step": 60000}
{"episode_reward": 994.0, "episode": 241.0, "batch_reward": 3.256203125, "critic_loss": 4.7680100240707395, "actor_loss": -363.36773608398437, "actor_target_entropy": -2.0, "actor_entropy": -0.16844035483151673, "alpha_loss": 0.0029457267001271248, "alpha_value": 0.026865813640479845, "duration": 94.18268275260925, "step": 60250}
{"episode_reward": 978.0, "episode": 242.0, "batch_reward": 3.2648671875, "critic_loss": 4.782084301948547, "actor_loss": -363.5324484863281, "actor_target_entropy": -2.0, "actor_entropy": -0.14203958509117365, "alpha_loss": 0.0006869354569353164, "alpha_value": 0.02678562769842915, "duration": 94.34479188919067, "step": 60500}
{"episode_reward": 933.0, "episode": 243.0, "batch_reward": 3.2578828125, "critic_loss": 4.954787190437317, "actor_loss": -363.89144482421875, "actor_target_entropy": -2.0, "actor_entropy": 0.05663814599812031, "alpha_loss": -0.0014199868144933133, "alpha_value": 0.026743556964914733, "duration": 94.19614458084106, "step": 60750}
{"episode_reward": 995.0, "episode": 244.0, "batch_reward": 3.2621015625, "critic_loss": 4.603393049240112, "actor_loss": -364.1893684082031, "actor_target_entropy": -2.0, "actor_entropy": 0.04384097331017256, "alpha_loss": -0.00010871872771531344, "alpha_value": 0.026793834268856346, "duration": 94.15697860717773, "step": 61000}
{"episode_reward": 989.0, "episode": 245.0, "batch_reward": 3.264984375, "critic_loss": 4.49653759765625, "actor_loss": -364.4739677734375, "actor_target_entropy": -2.0, "actor_entropy": -0.23355783668905497, "alpha_loss": 0.00296649683220312, "alpha_value": 0.026754148047420382, "duration": 94.09667301177979, "step": 61250}
{"episode_reward": 905.0, "episode": 246.0, "batch_reward": 3.2645078125, "critic_loss": 4.568111555099487, "actor_loss": -364.72935131835936, "actor_target_entropy": -2.0, "actor_entropy": -0.10305663201957942, "alpha_loss": 0.003216695348965004, "alpha_value": 0.0264928869955793, "duration": 93.89469194412231, "step": 61500}
{"episode_reward": 960.0, "episode": 247.0, "batch_reward": 3.2691640625, "critic_loss": 4.51186442565918, "actor_loss": -365.02472607421873, "actor_target_entropy": -2.0, "actor_entropy": -0.08379741337150336, "alpha_loss": -0.0004498802237212658, "alpha_value": 0.026394554515644944, "duration": 94.15283751487732, "step": 61750}
{"episode_reward": 946.0, "episode": 248.0, "batch_reward": 3.2785078125, "critic_loss": 4.767482260704041, "actor_loss": -365.4954299316406, "actor_target_entropy": -2.0, "actor_entropy": 0.004667701005935669, "alpha_loss": 0.002244649119209498, "alpha_value": 0.02631000760299657, "duration": 94.19922041893005, "step": 62000}
{"episode_reward": 974.0, "episode": 249.0, "batch_reward": 3.267796875, "critic_loss": 4.528692031860351, "actor_loss": -365.516216796875, "actor_target_entropy": -2.0, "actor_entropy": -0.05755099412053823, "alpha_loss": 0.0010292399497702717, "alpha_value": 0.02623052705983176, "duration": 94.25285172462463, "step": 62250}
{"episode_reward": 954.0, "episode": 250.0, "batch_reward": 3.2746484375, "critic_loss": 4.390502886772156, "actor_loss": -365.78616796875, "actor_target_entropy": -2.0, "actor_entropy": -0.023523426085710526, "alpha_loss": 0.0025611253925599156, "alpha_value": 0.02613771852416797, "duration": 94.02996873855591, "step": 62500}
{"episode_reward": 951.0, "episode": 251.0, "batch_reward": 3.284140625, "critic_loss": 4.259158259391785, "actor_loss": -366.22415649414063, "actor_target_entropy": -2.0, "actor_entropy": -0.06031043853610754, "alpha_loss": 0.002368949773721397, "alpha_value": 0.025909111904740146, "duration": 94.23935866355896, "step": 62750}
{"episode_reward": 996.0, "episode": 252.0, "batch_reward": 3.28109375, "critic_loss": 4.562567843437195, "actor_loss": -366.2575966796875, "actor_target_entropy": -2.0, "actor_entropy": 0.05124716318398714, "alpha_loss": 0.00037082952447235583, "alpha_value": 0.02584973231636259, "duration": 94.21672224998474, "step": 63000}
{"episode_reward": 990.0, "episode": 253.0, "batch_reward": 3.2879609375, "critic_loss": 4.573716301918029, "actor_loss": -366.7503525390625, "actor_target_entropy": -2.0, "actor_entropy": -0.26005263037234544, "alpha_loss": 0.0021941242064349355, "alpha_value": 0.025724930115139547, "duration": 94.4518404006958, "step": 63250}
{"episode_reward": 956.0, "episode": 254.0, "batch_reward": 3.2834453125, "critic_loss": 4.159347854614258, "actor_loss": -367.0133601074219, "actor_target_entropy": -2.0, "actor_entropy": -0.08321962054818868, "alpha_loss": 0.003490406600758433, "alpha_value": 0.02556433962865162, "duration": 94.26256990432739, "step": 63500}
{"episode_reward": 959.0, "episode": 255.0, "batch_reward": 3.2889765625, "critic_loss": 4.293091456890107, "actor_loss": -367.28916650390624, "actor_target_entropy": -2.0, "actor_entropy": -0.1334088553711772, "alpha_loss": 0.005847016550600529, "alpha_value": 0.02523033747662306, "duration": 94.32232284545898, "step": 63750}
{"episode_reward": 902.0, "episode": 256.0, "batch_reward": 3.285390625, "critic_loss": 4.640640163421631, "actor_loss": -367.3752509765625, "actor_target_entropy": -2.0, "actor_entropy": 0.07528050983697177, "alpha_loss": 0.002292989100329578, "alpha_value": 0.02497024104493242, "duration": 94.36298942565918, "step": 64000}
{"episode_reward": 989.0, "episode": 257.0, "batch_reward": 3.2923359375, "critic_loss": 4.123273950099945, "actor_loss": -367.6480773925781, "actor_target_entropy": -2.0, "actor_entropy": 0.007319376096129418, "alpha_loss": -0.0011250891473609955, "alpha_value": 0.024938152267151556, "duration": 94.51141571998596, "step": 64250}
{"episode_reward": 944.0, "episode": 258.0, "batch_reward": 3.2904765625, "critic_loss": 4.1120881690979, "actor_loss": -367.84733056640624, "actor_target_entropy": -2.0, "actor_entropy": 0.0020475254207849504, "alpha_loss": 0.00028383892681449653, "alpha_value": 0.024979747507133818, "duration": 94.2247986793518, "step": 64500}
{"episode_reward": 941.0, "episode": 259.0, "batch_reward": 3.2960859375, "critic_loss": 4.229120587348938, "actor_loss": -368.200279296875, "actor_target_entropy": -2.0, "actor_entropy": -0.05786184711754322, "alpha_loss": 0.0021089126621373, "alpha_value": 0.024863692174203873, "duration": 94.17102861404419, "step": 64750}
{"episode_reward": 957.0, "episode": 260.0, "batch_reward": 3.295078125, "critic_loss": 4.439842744827271, "actor_loss": -368.3496357421875, "actor_target_entropy": -2.0, "actor_entropy": -0.06947803612798452, "alpha_loss": 0.0005962581946514547, "alpha_value": 0.024787084251662043, "step": 65000}
{"duration": 117.1397385597229, "step": 65000}
{"episode_reward": 960.0, "episode": 261.0, "batch_reward": 3.304859375, "critic_loss": 4.140441534996032, "actor_loss": -368.727939453125, "actor_target_entropy": -2.0, "actor_entropy": -0.28129260742664336, "alpha_loss": 0.004571705986279994, "alpha_value": 0.024610881870934662, "duration": 94.20596575737, "step": 65250}
{"episode_reward": 981.0, "episode": 262.0, "batch_reward": 3.30215625, "critic_loss": 4.233068443775177, "actor_loss": -368.9603481445312, "actor_target_entropy": -2.0, "actor_entropy": -0.20596637582033872, "alpha_loss": 0.00428004593832884, "alpha_value": 0.02433371907422241, "duration": 94.1229395866394, "step": 65500}
{"episode_reward": 945.0, "episode": 263.0, "batch_reward": 3.30159375, "critic_loss": 4.209460448265076, "actor_loss": -369.04072119140625, "actor_target_entropy": -2.0, "actor_entropy": 0.0067628779038786885, "alpha_loss": -0.0014983117750380188, "alpha_value": 0.024229958509924012, "duration": 94.12260055541992, "step": 65750}
{"episode_reward": 991.0, "episode": 264.0, "batch_reward": 3.3110625, "critic_loss": 4.154165880680084, "actor_loss": -369.34669165039065, "actor_target_entropy": -2.0, "actor_entropy": 0.05556805658340454, "alpha_loss": -0.002718793906038627, "alpha_value": 0.02433492894314042, "duration": 94.26101517677307, "step": 66000}
{"episode_reward": 836.0, "episode": 265.0, "batch_reward": 3.308890625, "critic_loss": 3.9588485808372496, "actor_loss": -369.469220703125, "actor_target_entropy": -2.0, "actor_entropy": 0.08957195870950818, "alpha_loss": -0.00307922024326399, "alpha_value": 0.02459706109705634, "duration": 94.08015489578247, "step": 66250}
{"episode_reward": 942.0, "episode": 266.0, "batch_reward": 3.3109296875, "critic_loss": 4.243276738166809, "actor_loss": -369.76262329101564, "actor_target_entropy": -2.0, "actor_entropy": -0.0534818449690938, "alpha_loss": 0.0007838538945652545, "alpha_value": 0.024598323875237096, "duration": 94.13391613960266, "step": 66500}
{"episode_reward": 960.0, "episode": 267.0, "batch_reward": 3.30628125, "critic_loss": 4.455360794067383, "actor_loss": -369.9161591796875, "actor_target_entropy": -2.0, "actor_entropy": -0.30844925917685034, "alpha_loss": 0.0013780404590070247, "alpha_value": 0.024544796415306873, "duration": 94.1744749546051, "step": 66750}
{"episode_reward": 993.0, "episode": 268.0, "batch_reward": 3.31809375, "critic_loss": 4.148356961250305, "actor_loss": -370.18017309570314, "actor_target_entropy": -2.0, "actor_entropy": -0.2927082719132304, "alpha_loss": 0.0022363038146868347, "alpha_value": 0.02444122302978061, "duration": 94.04893255233765, "step": 67000}
{"episode_reward": 961.0, "episode": 269.0, "batch_reward": 3.3148984375, "critic_loss": 4.584688970565796, "actor_loss": -370.2702099609375, "actor_target_entropy": -2.0, "actor_entropy": -0.1809709984585643, "alpha_loss": 0.0028909448720514774, "alpha_value": 0.024238417755501146, "duration": 94.19946026802063, "step": 67250}
{"episode_reward": 946.0, "episode": 270.0, "batch_reward": 3.3150234375, "critic_loss": 4.277716212749481, "actor_loss": -370.47867626953126, "actor_target_entropy": -2.0, "actor_entropy": 0.1657830379679799, "alpha_loss": -0.0008758920188993215, "alpha_value": 0.02417726153597021, "duration": 94.26035571098328, "step": 67500}
{"episode_reward": 946.0, "episode": 271.0, "batch_reward": 3.3243515625, "critic_loss": 3.8819107213020323, "actor_loss": -370.8030256347656, "actor_target_entropy": -2.0, "actor_entropy": 0.15670815371721983, "alpha_loss": 0.0021481998953968287, "alpha_value": 0.02414457201107846, "duration": 94.38027954101562, "step": 67750}
{"episode_reward": 945.0, "episode": 272.0, "batch_reward": 3.316234375, "critic_loss": 3.7308504033088683, "actor_loss": -370.91688671875, "actor_target_entropy": -2.0, "actor_entropy": 0.0645558405816555, "alpha_loss": 0.005249752049800009, "alpha_value": 0.023919283215953026, "duration": 94.35747647285461, "step": 68000}
{"episode_reward": 986.0, "episode": 273.0, "batch_reward": 3.3301015625, "critic_loss": 4.0410629215240474, "actor_loss": -371.1588342285156, "actor_target_entropy": -2.0, "actor_entropy": -0.04266639620810747, "alpha_loss": 0.002918102725641802, "alpha_value": 0.023643339015040444, "duration": 94.28117513656616, "step": 68250}
{"episode_reward": 946.0, "episode": 274.0, "batch_reward": 3.324125, "critic_loss": 4.002347804069519, "actor_loss": -371.2971520996094, "actor_target_entropy": -2.0, "actor_entropy": 0.06790487237274646, "alpha_loss": 0.0032257249508984387, "alpha_value": 0.02344817728471198, "duration": 94.47985911369324, "step": 68500}
{"episode_reward": 958.0, "episode": 275.0, "batch_reward": 3.3270859375, "critic_loss": 3.9922043256759645, "actor_loss": -371.4620051269531, "actor_target_entropy": -2.0, "actor_entropy": 0.017159768261015416, "alpha_loss": -0.0015548315953928978, "alpha_value": 0.02340593819456848, "duration": 94.17472553253174, "step": 68750}
{"episode_reward": 943.0, "episode": 276.0, "batch_reward": 3.3299453125, "critic_loss": 3.8101026077270506, "actor_loss": -371.76460302734375, "actor_target_entropy": -2.0, "actor_entropy": -0.13459678383916615, "alpha_loss": 0.0007194015425629914, "alpha_value": 0.023479580634473564, "duration": 94.30850887298584, "step": 69000}
{"episode_reward": 937.0, "episode": 277.0, "batch_reward": 3.3326015625, "critic_loss": 3.781843839645386, "actor_loss": -371.991341796875, "actor_target_entropy": -2.0, "actor_entropy": -0.17356327944993974, "alpha_loss": 0.0018643150692805649, "alpha_value": 0.023355356560136223, "duration": 94.3597354888916, "step": 69250}
{"episode_reward": 987.0, "episode": 278.0, "batch_reward": 3.324765625, "critic_loss": 4.259994129657746, "actor_loss": -371.985966796875, "actor_target_entropy": -2.0, "actor_entropy": -0.30613554299622775, "alpha_loss": 0.0013062721574679018, "alpha_value": 0.023242416514194692, "duration": 94.52939534187317, "step": 69500}
{"episode_reward": 878.0, "episode": 279.0, "batch_reward": 3.3308984375, "critic_loss": 4.154226545333862, "actor_loss": -372.3148676757813, "actor_target_entropy": -2.0, "actor_entropy": -0.04110184121876955, "alpha_loss": -0.0018608034949284047, "alpha_value": 0.023201091380440915, "duration": 94.57227110862732, "step": 69750}
{"episode_reward": 988.0, "episode": 280.0, "batch_reward": 3.3299140625, "critic_loss": 4.236637542247772, "actor_loss": -372.3664226074219, "actor_target_entropy": -2.0, "actor_entropy": 0.1429237760566175, "alpha_loss": -0.0016507455441169441, "alpha_value": 0.023374883409954143, "step": 70000}
{"duration": 117.52336168289185, "step": 70000}
{"episode_reward": 988.0, "episode": 281.0, "batch_reward": 3.3375, "critic_loss": 4.055546570777893, "actor_loss": -372.494091796875, "actor_target_entropy": -2.0, "actor_entropy": 0.06951927333325147, "alpha_loss": 0.0009561146541964263, "alpha_value": 0.02341989503462558, "duration": 94.37621545791626, "step": 70250}
{"episode_reward": 934.0, "episode": 282.0, "batch_reward": 3.339234375, "critic_loss": 3.811771012306213, "actor_loss": -372.77276147460935, "actor_target_entropy": -2.0, "actor_entropy": 0.027259025529026985, "alpha_loss": 0.004497113870922476, "alpha_value": 0.023213270155489525, "duration": 94.19196677207947, "step": 70500}
{"episode_reward": 948.0, "episode": 283.0, "batch_reward": 3.3335, "critic_loss": 3.6680346817970277, "actor_loss": -372.8174287109375, "actor_target_entropy": -2.0, "actor_entropy": -0.07325599451363086, "alpha_loss": 0.0035674918186850845, "alpha_value": 0.023013148488398902, "duration": 94.13377332687378, "step": 70750}
{"episode_reward": 959.0, "episode": 284.0, "batch_reward": 3.3430078125, "critic_loss": 3.554677783489227, "actor_loss": -372.96716943359377, "actor_target_entropy": -2.0, "actor_entropy": 0.04674453934282064, "alpha_loss": 0.0022292162557132544, "alpha_value": 0.02279503360146495, "duration": 94.26504707336426, "step": 71000}
{"episode_reward": 946.0, "episode": 285.0, "batch_reward": 3.33946875, "critic_loss": 3.752103877544403, "actor_loss": -373.26116357421876, "actor_target_entropy": -2.0, "actor_entropy": -0.013955492064356805, "alpha_loss": 0.002140429347520694, "alpha_value": 0.02264174427887811, "duration": 94.0720477104187, "step": 71250}
{"episode_reward": 938.0, "episode": 286.0, "batch_reward": 3.335390625, "critic_loss": 3.985177631378174, "actor_loss": -373.36955834960935, "actor_target_entropy": -2.0, "actor_entropy": -0.027493252128362657, "alpha_loss": 0.0012034124054480344, "alpha_value": 0.02257216491895757, "duration": 94.1440007686615, "step": 71500}
{"episode_reward": 941.0, "episode": 287.0, "batch_reward": 3.3471328125, "critic_loss": 3.7993427782058715, "actor_loss": -373.7141005859375, "actor_target_entropy": -2.0, "actor_entropy": 0.03556079840660095, "alpha_loss": 0.004568583300802857, "alpha_value": 0.022404031648676024, "duration": 94.37663269042969, "step": 71750}
{"episode_reward": 946.0, "episode": 288.0, "batch_reward": 3.34471875, "critic_loss": 3.8350319495201113, "actor_loss": -373.7492248535156, "actor_target_entropy": -2.0, "actor_entropy": -0.004316893741488457, "alpha_loss": 0.003024671801365912, "alpha_value": 0.02215413172604911, "duration": 94.34546971321106, "step": 72000}
{"episode_reward": 958.0, "episode": 289.0, "batch_reward": 3.3504609375, "critic_loss": 3.8594721379280092, "actor_loss": -373.9943291015625, "actor_target_entropy": -2.0, "actor_entropy": -0.12250403632968664, "alpha_loss": -0.0003807755084708333, "alpha_value": 0.022075185420171995, "duration": 94.26186299324036, "step": 72250}
{"episode_reward": 988.0, "episode": 290.0, "batch_reward": 3.3471171875, "critic_loss": 3.8452481298446655, "actor_loss": -374.13693286132815, "actor_target_entropy": -2.0, "actor_entropy": -0.14025626354664564, "alpha_loss": 0.0019224488642066717, "alpha_value": 0.02203300881658497, "duration": 94.2827205657959, "step": 72500}
{"episode_reward": 960.0, "episode": 291.0, "batch_reward": 3.349125, "critic_loss": 3.7191070127487182, "actor_loss": -374.21811596679686, "actor_target_entropy": -2.0, "actor_entropy": -0.09756348399817943, "alpha_loss": 0.004766683199908584, "alpha_value": 0.021822599514692904, "duration": 93.70605778694153, "step": 72750}
{"episode_reward": 989.0, "episode": 292.0, "batch_reward": 3.355140625, "critic_loss": 3.6030035128593445, "actor_loss": -374.46432080078125, "actor_target_entropy": -2.0, "actor_entropy": -0.08622323531657457, "alpha_loss": 0.003710020400118083, "alpha_value": 0.02156032839638462, "duration": 91.25972509384155, "step": 73000}
{"episode_reward": 987.0, "episode": 293.0, "batch_reward": 3.35709375, "critic_loss": 3.639920063495636, "actor_loss": -374.4583693847656, "actor_target_entropy": -2.0, "actor_entropy": -0.15381484511867166, "alpha_loss": 0.000529520913027227, "alpha_value": 0.02140885212217803, "duration": 89.4480836391449, "step": 73250}
{"episode_reward": 924.0, "episode": 294.0, "batch_reward": 3.36153125, "critic_loss": 3.830907286167145, "actor_loss": -374.88459765625, "actor_target_entropy": -2.0, "actor_entropy": -0.3045999502763152, "alpha_loss": 0.0015845045307651161, "alpha_value": 0.021332002782721043, "duration": 88.19737362861633, "step": 73500}
{"episode_reward": 986.0, "episode": 295.0, "batch_reward": 3.3614140625, "critic_loss": 3.640827721118927, "actor_loss": -374.91470776367186, "actor_target_entropy": -2.0, "actor_entropy": -0.22508257268369197, "alpha_loss": 0.0009798520638141781, "alpha_value": 0.021281752972338388, "duration": 88.42512488365173, "step": 73750}
{"episode_reward": 960.0, "episode": 296.0, "batch_reward": 3.36975, "critic_loss": 3.947596930027008, "actor_loss": -375.16213940429685, "actor_target_entropy": -2.0, "actor_entropy": -0.12952005871385336, "alpha_loss": 0.0022139029314275833, "alpha_value": 0.021211646664312522, "duration": 87.96192574501038, "step": 74000}
{"episode_reward": 959.0, "episode": 297.0, "batch_reward": 3.363953125, "critic_loss": 3.8070907773971556, "actor_loss": -375.25466137695315, "actor_target_entropy": -2.0, "actor_entropy": -0.14268935752660036, "alpha_loss": 0.002685237692669034, "alpha_value": 0.021022070789153996, "duration": 88.08829116821289, "step": 74250}
{"episode_reward": 999.0, "episode": 298.0, "batch_reward": 3.367375, "critic_loss": 3.7964475479125976, "actor_loss": -375.46550415039064, "actor_target_entropy": -2.0, "actor_entropy": -0.31459153300523757, "alpha_loss": 0.002387781957630068, "alpha_value": 0.02088919839554099, "duration": 88.03789210319519, "step": 74500}
{"episode_reward": 943.0, "episode": 299.0, "batch_reward": 3.36490625, "critic_loss": 3.5531692323684694, "actor_loss": -375.5599528808594, "actor_target_entropy": -2.0, "actor_entropy": -0.5326780595779419, "alpha_loss": -0.002011398021131754, "alpha_value": 0.020818151723731356, "duration": 88.41225600242615, "step": 74750}
{"episode_reward": 949.0, "episode": 300.0, "batch_reward": 3.3698203125, "critic_loss": 3.585317600250244, "actor_loss": -375.79237670898436, "actor_target_entropy": -2.0, "actor_entropy": -0.1537201265320182, "alpha_loss": 0.0022016304857097567, "alpha_value": 0.020856352819578174, "step": 75000}
{"duration": 113.42906451225281, "step": 75000}
{"episode_reward": 948.0, "episode": 301.0, "batch_reward": 3.362796875, "critic_loss": 3.8658796062469483, "actor_loss": -375.8015334472656, "actor_target_entropy": -2.0, "actor_entropy": -0.031890727639198306, "alpha_loss": -0.0004254562782589346, "alpha_value": 0.02075750341808693, "duration": 89.14681434631348, "step": 75250}
{"episode_reward": 989.0, "episode": 302.0, "batch_reward": 3.363609375, "critic_loss": 3.535539565563202, "actor_loss": -375.92639892578126, "actor_target_entropy": -2.0, "actor_entropy": -0.003562107764184475, "alpha_loss": -0.0006078944292385131, "alpha_value": 0.020872679523272014, "duration": 89.21903109550476, "step": 75500}
{"episode_reward": 949.0, "episode": 303.0, "batch_reward": 3.36990625, "critic_loss": 3.604262023448944, "actor_loss": -376.07799536132814, "actor_target_entropy": -2.0, "actor_entropy": -0.11619413778930902, "alpha_loss": 0.002175512128742412, "alpha_value": 0.020811275644764374, "duration": 88.29740500450134, "step": 75750}
{"episode_reward": 991.0, "episode": 304.0, "batch_reward": 3.375265625, "critic_loss": 3.246088560581207, "actor_loss": -376.3551186523438, "actor_target_entropy": -2.0, "actor_entropy": -0.2072026391029358, "alpha_loss": 0.003423084172420204, "alpha_value": 0.020590932847973885, "duration": 87.81404757499695, "step": 76000}
{"episode_reward": 944.0, "episode": 305.0, "batch_reward": 3.3675, "critic_loss": 3.466811275959015, "actor_loss": -376.309802734375, "actor_target_entropy": -2.0, "actor_entropy": -0.24223660657554866, "alpha_loss": 0.004579779838444665, "alpha_value": 0.020379382290820352, "duration": 87.94391655921936, "step": 76250}
{"episode_reward": 987.0, "episode": 306.0, "batch_reward": 3.37471875, "critic_loss": 3.4009118905067446, "actor_loss": -376.569712890625, "actor_target_entropy": -2.0, "actor_entropy": -0.2188298337161541, "alpha_loss": 0.003859193045645952, "alpha_value": 0.020096106545847387, "duration": 87.60467553138733, "step": 76500}
{"episode_reward": 977.0, "episode": 307.0, "batch_reward": 3.373375, "critic_loss": 3.706771505832672, "actor_loss": -376.5898071289063, "actor_target_entropy": -2.0, "actor_entropy": -0.2210952176526189, "alpha_loss": 0.004069720375351608, "alpha_value": 0.019914415033607157, "duration": 88.34822344779968, "step": 76750}
{"episode_reward": 897.0, "episode": 308.0, "batch_reward": 3.37503125, "critic_loss": 3.8798729343414307, "actor_loss": -376.8149313964844, "actor_target_entropy": -2.0, "actor_entropy": -0.20790910280495883, "alpha_loss": 0.0027901548515073954, "alpha_value": 0.019675097671556077, "duration": 90.31918168067932, "step": 77000}
{"episode_reward": 990.0, "episode": 309.0, "batch_reward": 3.3810546875, "critic_loss": 3.38112033033371, "actor_loss": -377.0323896484375, "actor_target_entropy": -2.0, "actor_entropy": -0.2893202558159828, "alpha_loss": 0.0028197749690152705, "alpha_value": 0.019547170739476195, "duration": 87.66999340057373, "step": 77250}
{"episode_reward": 936.0, "episode": 310.0, "batch_reward": 3.3808828125, "critic_loss": 3.5575263562202455, "actor_loss": -377.1076391601562, "actor_target_entropy": -2.0, "actor_entropy": -0.3353203540444374, "alpha_loss": 0.0014838712681084871, "alpha_value": 0.019404377939998753, "duration": 87.5484848022461, "step": 77500}
{"episode_reward": 959.0, "episode": 311.0, "batch_reward": 3.3826796875, "critic_loss": 3.933968731403351, "actor_loss": -377.3716296386719, "actor_target_entropy": -2.0, "actor_entropy": -0.3187339379042387, "alpha_loss": 0.0008300558004993945, "alpha_value": 0.01934584084664183, "duration": 87.44765257835388, "step": 77750}
{"episode_reward": 944.0, "episode": 312.0, "batch_reward": 3.3893046875, "critic_loss": 3.701924139022827, "actor_loss": -377.49263525390626, "actor_target_entropy": -2.0, "actor_entropy": -0.33561686296761034, "alpha_loss": 0.00080170719884336, "alpha_value": 0.01931418109889982, "duration": 87.3247594833374, "step": 78000}
{"episode_reward": 960.0, "episode": 313.0, "batch_reward": 3.389109375, "critic_loss": 3.6272648434638977, "actor_loss": -377.4622270507812, "actor_target_entropy": -2.0, "actor_entropy": -0.4391782050579786, "alpha_loss": 0.0003735489237587899, "alpha_value": 0.019269266283009134, "duration": 87.17273473739624, "step": 78250}
{"episode_reward": 959.0, "episode": 314.0, "batch_reward": 3.3866171875, "critic_loss": 3.4423708868026734, "actor_loss": -377.55159765625, "actor_target_entropy": -2.0, "actor_entropy": -0.3675425066947937, "alpha_loss": 0.0014523900197818875, "alpha_value": 0.019215888742276702, "duration": 87.11750864982605, "step": 78500}
{"episode_reward": 948.0, "episode": 315.0, "batch_reward": 3.3949296875, "critic_loss": 3.2417362761497497, "actor_loss": -377.86474169921877, "actor_target_entropy": -2.0, "actor_entropy": -0.11611601852998138, "alpha_loss": 0.0009083807952702046, "alpha_value": 0.01908942915877644, "duration": 88.04946732521057, "step": 78750}
{"episode_reward": 958.0, "episode": 316.0, "batch_reward": 3.392046875, "critic_loss": 3.2966893396377563, "actor_loss": -377.8410847167969, "actor_target_entropy": -2.0, "actor_entropy": 0.12343471972644329, "alpha_loss": -0.0033063363113906234, "alpha_value": 0.0192250012449876, "duration": 87.67218136787415, "step": 79000}
{"episode_reward": 960.0, "episode": 317.0, "batch_reward": 3.391796875, "critic_loss": 3.39421336889267, "actor_loss": -377.7678193359375, "actor_target_entropy": -2.0, "actor_entropy": -0.19143059208244084, "alpha_loss": 0.0020660847895778716, "alpha_value": 0.01925987990662851, "duration": 87.3027856349945, "step": 79250}
{"episode_reward": 946.0, "episode": 318.0, "batch_reward": 3.3926171875, "critic_loss": 3.5810075511932373, "actor_loss": -377.9750871582031, "actor_target_entropy": -2.0, "actor_entropy": -0.266886289909482, "alpha_loss": 0.0028926275963895025, "alpha_value": 0.019108574535168597, "duration": 87.60245442390442, "step": 79500}
{"episode_reward": 995.0, "episode": 319.0, "batch_reward": 3.3966796875, "critic_loss": 3.6661355700492857, "actor_loss": -378.1338291015625, "actor_target_entropy": -2.0, "actor_entropy": -0.37777481610327956, "alpha_loss": 0.00020814673276618124, "alpha_value": 0.019013000930258372, "duration": 87.4296441078186, "step": 79750}
{"episode_reward": 964.0, "episode": 320.0, "batch_reward": 3.3893515625, "critic_loss": 3.471749718666077, "actor_loss": -378.36618212890625, "actor_target_entropy": -2.0, "actor_entropy": -0.27095207760483025, "alpha_loss": 0.0017025150081608445, "alpha_value": 0.018959879850060098, "step": 80000}
{"duration": 110.54249095916748, "step": 80000}
{"episode_reward": 961.0, "episode": 321.0, "batch_reward": 3.39834375, "critic_loss": 3.357857307434082, "actor_loss": -378.4642221679687, "actor_target_entropy": -2.0, "actor_entropy": -0.478629986166954, "alpha_loss": 0.0010065512540750206, "alpha_value": 0.018838222188668315, "duration": 88.21353387832642, "step": 80250}
{"episode_reward": 949.0, "episode": 322.0, "batch_reward": 3.3965703125, "critic_loss": 3.593853808879852, "actor_loss": -378.58661938476564, "actor_target_entropy": -2.0, "actor_entropy": -0.4402192550227046, "alpha_loss": 0.00019729840336367487, "alpha_value": 0.01883452936633637, "duration": 87.8931474685669, "step": 80500}
{"episode_reward": 991.0, "episode": 323.0, "batch_reward": 3.39821875, "critic_loss": 3.247858827114105, "actor_loss": -378.6519099121094, "actor_target_entropy": -2.0, "actor_entropy": 0.020816487140953542, "alpha_loss": 0.0004637089895550162, "alpha_value": 0.01877905071209476, "duration": 87.826162815094, "step": 80750}
{"episode_reward": 997.0, "episode": 324.0, "batch_reward": 3.39609375, "critic_loss": 3.267540602207184, "actor_loss": -378.8547626953125, "actor_target_entropy": -2.0, "actor_entropy": 0.13853489803150296, "alpha_loss": -0.0011797499535605312, "alpha_value": 0.018835850483375733, "duration": 87.66686582565308, "step": 81000}
{"episode_reward": 993.0, "episode": 325.0, "batch_reward": 3.401640625, "critic_loss": 3.2833904504776, "actor_loss": -378.9495654296875, "actor_target_entropy": -2.0, "actor_entropy": -0.19941806177049876, "alpha_loss": 0.0021281552501022814, "alpha_value": 0.01879663788008662, "duration": 87.1109549999237, "step": 81250}
{"episode_reward": 956.0, "episode": 326.0, "batch_reward": 3.40134375, "critic_loss": 3.1492906136512757, "actor_loss": -379.027017578125, "actor_target_entropy": -2.0, "actor_entropy": -0.2288673091083765, "alpha_loss": 0.004045354256872088, "alpha_value": 0.018585294105843447, "duration": 87.56536650657654, "step": 81500}
{"episode_reward": 987.0, "episode": 327.0, "batch_reward": 3.4164375, "critic_loss": 2.90976864862442, "actor_loss": -379.33734252929685, "actor_target_entropy": -2.0, "actor_entropy": -0.058374283149838446, "alpha_loss": 0.002536075155250728, "alpha_value": 0.018365226111435408, "duration": 92.8644449710846, "step": 81750}
{"episode_reward": 960.0, "episode": 328.0, "batch_reward": 3.4071328125, "critic_loss": 3.0252462105751037, "actor_loss": -379.3403637695312, "actor_target_entropy": -2.0, "actor_entropy": -0.18184594461321832, "alpha_loss": 0.002896110933274031, "alpha_value": 0.0182339828760908, "duration": 113.30531644821167, "step": 82000}
{"episode_reward": 962.0, "episode": 329.0, "batch_reward": 3.4096171875, "critic_loss": 3.1130215682983398, "actor_loss": -379.5880576171875, "actor_target_entropy": -2.0, "actor_entropy": -0.08474877427890896, "alpha_loss": 0.0037786439193878323, "alpha_value": 0.01799616700128812, "duration": 89.29988932609558, "step": 82250}
{"episode_reward": 990.0, "episode": 330.0, "batch_reward": 3.4094453125, "critic_loss": 2.993193289756775, "actor_loss": -379.64188549804686, "actor_target_entropy": -2.0, "actor_entropy": -0.3850065766572952, "alpha_loss": 0.0031977932087611407, "alpha_value": 0.017799538201564578, "duration": 89.00481152534485, "step": 82500}
{"episode_reward": 943.0, "episode": 331.0, "batch_reward": 3.4127109375, "critic_loss": 3.1474540252685546, "actor_loss": -379.6842734375, "actor_target_entropy": -2.0, "actor_entropy": -0.3979022890329361, "alpha_loss": 0.0017043816773220897, "alpha_value": 0.017645002579023947, "duration": 88.07476854324341, "step": 82750}
{"episode_reward": 962.0, "episode": 332.0, "batch_reward": 3.413921875, "critic_loss": 3.1540267329216003, "actor_loss": -379.73777514648435, "actor_target_entropy": -2.0, "actor_entropy": -0.16871265614032746, "alpha_loss": 0.002877444643294439, "alpha_value": 0.017525090062454764, "duration": 86.92185950279236, "step": 83000}
{"episode_reward": 947.0, "episode": 333.0, "batch_reward": 3.4133203125, "critic_loss": 3.10187943983078, "actor_loss": -379.8344838867188, "actor_target_entropy": -2.0, "actor_entropy": -0.15385761979222298, "alpha_loss": 0.0025707657847087832, "alpha_value": 0.01737475182060019, "duration": 88.39487409591675, "step": 83250}
{"episode_reward": 961.0, "episode": 334.0, "batch_reward": 3.410078125, "critic_loss": 2.8380927934646607, "actor_loss": -380.14469409179685, "actor_target_entropy": -2.0, "actor_entropy": -0.6141159064769744, "alpha_loss": 0.0008350026295520365, "alpha_value": 0.017244000417626665, "duration": 87.09131836891174, "step": 83500}
{"episode_reward": 961.0, "episode": 335.0, "batch_reward": 3.4185, "critic_loss": 3.190636944770813, "actor_loss": -380.07858837890626, "actor_target_entropy": -2.0, "actor_entropy": -0.4896534116268158, "alpha_loss": 0.00034418345196172593, "alpha_value": 0.017243973063832296, "duration": 88.8620035648346, "step": 83750}
{"episode_reward": 955.0, "episode": 336.0, "batch_reward": 3.4206015625, "critic_loss": 2.884014194011688, "actor_loss": -380.1861469726563, "actor_target_entropy": -2.0, "actor_entropy": -0.20476796550303697, "alpha_loss": 0.0007090517128817737, "alpha_value": 0.01718901217093805, "duration": 87.49544024467468, "step": 84000}
{"episode_reward": 994.0, "episode": 337.0, "batch_reward": 3.4204921875, "critic_loss": 3.0278980693817137, "actor_loss": -380.31008740234375, "actor_target_entropy": -2.0, "actor_entropy": -0.3610406581163406, "alpha_loss": 0.0011996976628433913, "alpha_value": 0.017150795508375657, "duration": 88.71213388442993, "step": 84250}
{"episode_reward": 991.0, "episode": 338.0, "batch_reward": 3.420828125, "critic_loss": 2.940551050186157, "actor_loss": -380.39043017578126, "actor_target_entropy": -2.0, "actor_entropy": -0.31802544416487216, "alpha_loss": 0.003440023194300011, "alpha_value": 0.016974543542118643, "duration": 86.85947751998901, "step": 84500}
{"episode_reward": 946.0, "episode": 339.0, "batch_reward": 3.426796875, "critic_loss": 2.9058698902130127, "actor_loss": -380.57566040039063, "actor_target_entropy": -2.0, "actor_entropy": -0.2901830065846443, "alpha_loss": 0.002874009461607784, "alpha_value": 0.0167899310884516, "duration": 87.04543423652649, "step": 84750}
{"episode_reward": 992.0, "episode": 340.0, "batch_reward": 3.424609375, "critic_loss": 3.066723275184631, "actor_loss": -380.7691696777344, "actor_target_entropy": -2.0, "actor_entropy": -0.3944513322710991, "alpha_loss": 0.002306620634626597, "alpha_value": 0.016651031522259645, "step": 85000}
{"duration": 110.0771586894989, "step": 85000}
{"episode_reward": 951.0, "episode": 341.0, "batch_reward": 3.4234609375, "critic_loss": 3.113795799732208, "actor_loss": -380.75566455078126, "actor_target_entropy": -2.0, "actor_entropy": -0.18813642568141223, "alpha_loss": 0.0021766076888889074, "alpha_value": 0.016515374484578016, "duration": 87.05258011817932, "step": 85250}
{"episode_reward": 953.0, "episode": 342.0, "batch_reward": 3.43075, "critic_loss": 2.8948044996261597, "actor_loss": -381.0283798828125, "actor_target_entropy": -2.0, "actor_entropy": -0.14329591140151024, "alpha_loss": 0.00119998831814155, "alpha_value": 0.01639554493804335, "duration": 87.88245368003845, "step": 85500}
{"episode_reward": 850.0, "episode": 343.0, "batch_reward": 3.4319375, "critic_loss": 2.74852569770813, "actor_loss": -380.95031005859374, "actor_target_entropy": -2.0, "actor_entropy": -0.15150528751313685, "alpha_loss": 0.00017346191947581246, "alpha_value": 0.01636272874883811, "duration": 87.38329577445984, "step": 85750}
{"episode_reward": 988.0, "episode": 344.0, "batch_reward": 3.4358125, "critic_loss": 3.121093641281128, "actor_loss": -381.1784982910156, "actor_target_entropy": -2.0, "actor_entropy": -0.3069762842208147, "alpha_loss": 0.00209415440633893, "alpha_value": 0.016284774553333374, "duration": 86.88685750961304, "step": 86000}
{"episode_reward": 986.0, "episode": 345.0, "batch_reward": 3.4387734375, "critic_loss": 2.823421854496002, "actor_loss": -381.321228515625, "actor_target_entropy": -2.0, "actor_entropy": -0.3781503673195839, "alpha_loss": 0.001797154257306829, "alpha_value": 0.01619306629590956, "duration": 88.01309561729431, "step": 86250}
{"episode_reward": 999.0, "episode": 346.0, "batch_reward": 3.4355546875, "critic_loss": 3.0193841257095335, "actor_loss": -381.3387216796875, "actor_target_entropy": -2.0, "actor_entropy": -0.41266250759363177, "alpha_loss": 0.001389275886118412, "alpha_value": 0.01608910552768119, "duration": 87.71968388557434, "step": 86500}
{"episode_reward": 946.0, "episode": 347.0, "batch_reward": 3.429796875, "critic_loss": 2.9305196413993837, "actor_loss": -381.3919724121094, "actor_target_entropy": -2.0, "actor_entropy": -0.09908863496780396, "alpha_loss": 0.00034063766594044864, "alpha_value": 0.01601179786716407, "duration": 86.9793930053711, "step": 86750}
{"episode_reward": 940.0, "episode": 348.0, "batch_reward": 3.4327265625, "critic_loss": 3.1509382371902466, "actor_loss": -381.57982543945315, "actor_target_entropy": -2.0, "actor_entropy": -0.21661374132335187, "alpha_loss": -0.0003900533525738865, "alpha_value": 0.016043310698391985, "duration": 87.04975771903992, "step": 87000}
{"episode_reward": 991.0, "episode": 349.0, "batch_reward": 3.437546875, "critic_loss": 2.853713324546814, "actor_loss": -381.68198046875, "actor_target_entropy": -2.0, "actor_entropy": -0.0948674115985632, "alpha_loss": 0.0027854461716488002, "alpha_value": 0.01594653513523037, "duration": 87.84004545211792, "step": 87250}
{"episode_reward": 989.0, "episode": 350.0, "batch_reward": 3.4426953125, "critic_loss": 3.0584982380867003, "actor_loss": -381.7601901855469, "actor_target_entropy": -2.0, "actor_entropy": -0.2828621641099453, "alpha_loss": 0.0011684601852903142, "alpha_value": 0.015839361065183147, "duration": 86.99471092224121, "step": 87500}
{"episode_reward": 962.0, "episode": 351.0, "batch_reward": 3.4420390625, "critic_loss": 2.8730802297592164, "actor_loss": -381.80893676757813, "actor_target_entropy": -2.0, "actor_entropy": -0.24370778681337835, "alpha_loss": 0.0027160076354630293, "alpha_value": 0.015694805916272776, "duration": 88.02445983886719, "step": 87750}
{"episode_reward": 999.0, "episode": 352.0, "batch_reward": 3.4366875, "critic_loss": 3.0512995076179505, "actor_loss": -381.84076025390624, "actor_target_entropy": -2.0, "actor_entropy": -0.24919852848351, "alpha_loss": 0.001953483324847184, "alpha_value": 0.015565298954352257, "duration": 86.72079205513, "step": 88000}
{"episode_reward": 995.0, "episode": 353.0, "batch_reward": 3.4374921875, "critic_loss": 2.822415661811829, "actor_loss": -381.9531208496094, "actor_target_entropy": -2.0, "actor_entropy": -0.24665550778806208, "alpha_loss": 0.0017119252488482744, "alpha_value": 0.015438979883237313, "duration": 87.01440501213074, "step": 88250}
{"episode_reward": 960.0, "episode": 354.0, "batch_reward": 3.43765625, "critic_loss": 3.2271618995666502, "actor_loss": -381.9355666503906, "actor_target_entropy": -2.0, "actor_entropy": -0.2957206095084548, "alpha_loss": 0.0022054648199118674, "alpha_value": 0.015327807354391052, "duration": 90.32167553901672, "step": 88500}
{"episode_reward": 946.0, "episode": 355.0, "batch_reward": 3.4446328125, "critic_loss": 2.9812030143737793, "actor_loss": -382.0481755371094, "actor_target_entropy": -2.0, "actor_entropy": -0.3266774756535888, "alpha_loss": 0.0031133716271724552, "alpha_value": 0.015168438370311515, "duration": 86.8849470615387, "step": 88750}
{"episode_reward": 1000.0, "episode": 356.0, "batch_reward": 3.4449296875, "critic_loss": 2.889335825920105, "actor_loss": -382.09807739257815, "actor_target_entropy": -2.0, "actor_entropy": -0.23939769779145717, "alpha_loss": 0.00035747525817714633, "alpha_value": 0.015021078898841455, "duration": 87.90915703773499, "step": 89000}
{"episode_reward": 927.0, "episode": 357.0, "batch_reward": 3.441328125, "critic_loss": 2.852610955238342, "actor_loss": -382.2805861816406, "actor_target_entropy": -2.0, "actor_entropy": -0.30977975234389304, "alpha_loss": -0.0015507532035699113, "alpha_value": 0.01506968133103024, "duration": 87.6355721950531, "step": 89250}
{"episode_reward": 947.0, "episode": 358.0, "batch_reward": 3.4459765625, "critic_loss": 3.041668041229248, "actor_loss": -382.25733715820314, "actor_target_entropy": -2.0, "actor_entropy": -0.15875138529390095, "alpha_loss": 0.0004970427862135693, "alpha_value": 0.015157117199458881, "duration": 86.85390257835388, "step": 89500}
{"episode_reward": 948.0, "episode": 359.0, "batch_reward": 3.4487421875, "critic_loss": 3.102815400123596, "actor_loss": -382.387220703125, "actor_target_entropy": -2.0, "actor_entropy": -0.45184894526004793, "alpha_loss": 0.0018872805056162178, "alpha_value": 0.015050793203630411, "duration": 88.5506021976471, "step": 89750}
{"episode_reward": 947.0, "episode": 360.0, "batch_reward": 3.44940625, "critic_loss": 2.9481124300956725, "actor_loss": -382.45307006835935, "actor_target_entropy": -2.0, "actor_entropy": -0.42247753155231477, "alpha_loss": 0.0021957209245301785, "alpha_value": 0.014926808334898262, "step": 90000}
{"duration": 110.28957152366638, "step": 90000}
{"episode_reward": 990.0, "episode": 361.0, "batch_reward": 3.4407734375, "critic_loss": 2.9560046863555907, "actor_loss": -382.446619140625, "actor_target_entropy": -2.0, "actor_entropy": -0.5113995509743691, "alpha_loss": 0.0011512262062169612, "alpha_value": 0.014863006664340057, "duration": 87.59032773971558, "step": 90250}
{"episode_reward": 988.0, "episode": 362.0, "batch_reward": 3.4563984375, "critic_loss": 2.8075513234138487, "actor_loss": -382.757560546875, "actor_target_entropy": -2.0, "actor_entropy": -0.33575062853097914, "alpha_loss": 0.0016937338903080673, "alpha_value": 0.014756007970726525, "duration": 87.66570091247559, "step": 90500}
{"episode_reward": 948.0, "episode": 363.0, "batch_reward": 3.4480234375, "critic_loss": 3.198926333904266, "actor_loss": -382.75408862304687, "actor_target_entropy": -2.0, "actor_entropy": -0.15315404593199491, "alpha_loss": 0.0005516965389251709, "alpha_value": 0.014683966007751693, "duration": 87.55087852478027, "step": 90750}
{"episode_reward": 962.0, "episode": 364.0, "batch_reward": 3.449, "critic_loss": 2.8407980365753174, "actor_loss": -382.6842451171875, "actor_target_entropy": -2.0, "actor_entropy": -0.3442088648676872, "alpha_loss": 0.0018733732349937781, "alpha_value": 0.014617319061056549, "duration": 88.98349356651306, "step": 91000}
{"episode_reward": 996.0, "episode": 365.0, "batch_reward": 3.455859375, "critic_loss": 2.835693172454834, "actor_loss": -382.92553857421876, "actor_target_entropy": -2.0, "actor_entropy": -0.3227947524636984, "alpha_loss": 0.00190536454890389, "alpha_value": 0.014499678838592574, "duration": 87.69985914230347, "step": 91250}
{"episode_reward": 942.0, "episode": 366.0, "batch_reward": 3.4621953125, "critic_loss": 2.8549521007537844, "actor_loss": -383.14746948242185, "actor_target_entropy": -2.0, "actor_entropy": -0.4135218783020973, "alpha_loss": 0.0017243374572135507, "alpha_value": 0.01438082355781573, "duration": 87.7077648639679, "step": 91500}
{"episode_reward": 999.0, "episode": 367.0, "batch_reward": 3.46325, "critic_loss": 2.66587837934494, "actor_loss": -383.26440625, "actor_target_entropy": -2.0, "actor_entropy": -0.4369675817489624, "alpha_loss": 0.0021589372295420617, "alpha_value": 0.014248444152603944, "duration": 87.55600547790527, "step": 91750}
{"episode_reward": 960.0, "episode": 368.0, "batch_reward": 3.460390625, "critic_loss": 2.8762427062988283, "actor_loss": -383.29735693359373, "actor_target_entropy": -2.0, "actor_entropy": -0.3013989841043949, "alpha_loss": 0.0007964080714154988, "alpha_value": 0.014178852055528764, "duration": 87.50218749046326, "step": 92000}
{"episode_reward": 951.0, "episode": 369.0, "batch_reward": 3.45290625, "critic_loss": 2.7878531975746155, "actor_loss": -383.16861791992187, "actor_target_entropy": -2.0, "actor_entropy": -0.2942416567504406, "alpha_loss": -7.307968172244727e-05, "alpha_value": 0.014173474802366977, "duration": 87.40703058242798, "step": 92250}
{"episode_reward": 888.0, "episode": 370.0, "batch_reward": 3.4606640625, "critic_loss": 2.9203647251129152, "actor_loss": -383.46901293945314, "actor_target_entropy": -2.0, "actor_entropy": -0.25090414007008077, "alpha_loss": 0.0027473944823723285, "alpha_value": 0.014086064583251609, "duration": 87.38758444786072, "step": 92500}
{"episode_reward": 962.0, "episode": 371.0, "batch_reward": 3.4614765625, "critic_loss": 2.779870098590851, "actor_loss": -383.42921362304685, "actor_target_entropy": -2.0, "actor_entropy": -0.07261654267460108, "alpha_loss": 0.0011505815155105664, "alpha_value": 0.013938398840485615, "duration": 87.33187866210938, "step": 92750}
{"episode_reward": 960.0, "episode": 372.0, "batch_reward": 3.466203125, "critic_loss": 2.7503840527534487, "actor_loss": -383.61115673828124, "actor_target_entropy": -2.0, "actor_entropy": -0.2378732862174511, "alpha_loss": 0.0024288902510888875, "alpha_value": 0.013866379459598491, "duration": 87.61347818374634, "step": 93000}
{"episode_reward": 959.0, "episode": 373.0, "batch_reward": 3.46746875, "critic_loss": 2.4260642127990724, "actor_loss": -383.5931103515625, "actor_target_entropy": -2.0, "actor_entropy": -0.3399969480931759, "alpha_loss": 0.0029768576428759845, "alpha_value": 0.01368924058047015, "duration": 87.34483027458191, "step": 93250}
{"episode_reward": 961.0, "episode": 374.0, "batch_reward": 3.467234375, "critic_loss": 2.6906064496040343, "actor_loss": -383.79542431640624, "actor_target_entropy": -2.0, "actor_entropy": -0.22042392561584712, "alpha_loss": 0.002191322196042165, "alpha_value": 0.013544052585401393, "duration": 87.45663094520569, "step": 93500}
{"episode_reward": 988.0, "episode": 375.0, "batch_reward": 3.4640078125, "critic_loss": 2.665645363330841, "actor_loss": -383.78587890625, "actor_target_entropy": -2.0, "actor_entropy": -0.3226064973026514, "alpha_loss": 4.5145280193537475e-05, "alpha_value": 0.01348422373216204, "duration": 87.38452339172363, "step": 93750}
{"episode_reward": 990.0, "episode": 376.0, "batch_reward": 3.47371875, "critic_loss": 2.7418016810417174, "actor_loss": -383.8644177246094, "actor_target_entropy": -2.0, "actor_entropy": -0.19762011136114596, "alpha_loss": 0.0027016370054334404, "alpha_value": 0.0134323103492304, "duration": 87.5362901687622, "step": 94000}
{"episode_reward": 948.0, "episode": 377.0, "batch_reward": 3.465, "critic_loss": 2.705748581409454, "actor_loss": -383.94470581054685, "actor_target_entropy": -2.0, "actor_entropy": -0.1309875336959958, "alpha_loss": 0.0023026445743162187, "alpha_value": 0.01328124253810927, "duration": 87.38969039916992, "step": 94250}
{"episode_reward": 959.0, "episode": 378.0, "batch_reward": 3.46421875, "critic_loss": 2.7758813738822936, "actor_loss": -383.9444560546875, "actor_target_entropy": -2.0, "actor_entropy": -0.2612418956570327, "alpha_loss": 0.0022829877315089105, "alpha_value": 0.01315585487143099, "duration": 87.71778130531311, "step": 94500}
{"episode_reward": 1000.0, "episode": 379.0, "batch_reward": 3.4727734375, "critic_loss": 2.7588624980449676, "actor_loss": -384.15506909179686, "actor_target_entropy": -2.0, "actor_entropy": -0.31712204674631356, "alpha_loss": 0.002597271899576299, "alpha_value": 0.01302418192056609, "duration": 87.43511152267456, "step": 94750}
{"episode_reward": 952.0, "episode": 380.0, "batch_reward": 3.47640625, "critic_loss": 2.785947762489319, "actor_loss": -384.17136889648435, "actor_target_entropy": -2.0, "actor_entropy": -0.5412348111867905, "alpha_loss": 0.00020247351890429854, "alpha_value": 0.012944061270487466, "step": 95000}
{"duration": 111.11006116867065, "step": 95000}
{"episode_reward": 988.0, "episode": 381.0, "batch_reward": 3.47053125, "critic_loss": 2.9833808484077453, "actor_loss": -384.12513037109375, "actor_target_entropy": -2.0, "actor_entropy": -0.22029960914701224, "alpha_loss": 0.0014739070439245552, "alpha_value": 0.012884748476239442, "duration": 88.81469440460205, "step": 95250}
{"episode_reward": 955.0, "episode": 382.0, "batch_reward": 3.4742421875, "critic_loss": 2.777012276172638, "actor_loss": -384.28569091796874, "actor_target_entropy": -2.0, "actor_entropy": -0.37058158015459775, "alpha_loss": 0.0024042621382977815, "alpha_value": 0.012780494245758443, "duration": 87.25129890441895, "step": 95500}
{"episode_reward": 961.0, "episode": 383.0, "batch_reward": 3.4718671875, "critic_loss": 2.7754503808021544, "actor_loss": -384.2051887207031, "actor_target_entropy": -2.0, "actor_entropy": -0.2975852788984776, "alpha_loss": 0.0017216271162033081, "alpha_value": 0.012659697096209316, "duration": 87.27983522415161, "step": 95750}
{"episode_reward": 988.0, "episode": 384.0, "batch_reward": 3.4734140625, "critic_loss": 2.6991961460113525, "actor_loss": -384.4547321777344, "actor_target_entropy": -2.0, "actor_entropy": -0.3812855685800314, "alpha_loss": 0.0012906014253385365, "alpha_value": 0.01258789373960292, "duration": 87.19408202171326, "step": 96000}
{"episode_reward": 944.0, "episode": 385.0, "batch_reward": 3.473078125, "critic_loss": 2.741417128562927, "actor_loss": -384.40307861328125, "actor_target_entropy": -2.0, "actor_entropy": -0.3398474253416061, "alpha_loss": -0.0009758203232195228, "alpha_value": 0.012573329807900466, "duration": 87.40799689292908, "step": 96250}
{"episode_reward": 952.0, "episode": 386.0, "batch_reward": 3.4769765625, "critic_loss": 2.623252153158188, "actor_loss": -384.56985888671875, "actor_target_entropy": -2.0, "actor_entropy": -0.26403137631714346, "alpha_loss": 0.0016533553986810149, "alpha_value": 0.012561881277452322, "duration": 87.60253834724426, "step": 96500}
{"episode_reward": 960.0, "episode": 387.0, "batch_reward": 3.4823046875, "critic_loss": 2.5620813994407654, "actor_loss": -384.63547509765624, "actor_target_entropy": -2.0, "actor_entropy": -0.4251547998785973, "alpha_loss": 0.0006822995708789676, "alpha_value": 0.012491259243924302, "duration": 87.62149047851562, "step": 96750}
{"episode_reward": 994.0, "episode": 388.0, "batch_reward": 3.4793125, "critic_loss": 2.74127833032608, "actor_loss": -384.61240771484376, "actor_target_entropy": -2.0, "actor_entropy": -0.47344462859630587, "alpha_loss": 0.000329636590089649, "alpha_value": 0.012464756381407809, "duration": 86.98853707313538, "step": 97000}
{"episode_reward": 932.0, "episode": 389.0, "batch_reward": 3.469765625, "critic_loss": 2.6625123348236084, "actor_loss": -384.59102880859376, "actor_target_entropy": -2.0, "actor_entropy": -0.4421169117093086, "alpha_loss": 3.105418046470732e-05, "alpha_value": 0.012445313897008434, "duration": 87.5731987953186, "step": 97250}
{"episode_reward": 951.0, "episode": 390.0, "batch_reward": 3.479140625, "critic_loss": 2.8059616341590883, "actor_loss": -384.76804736328126, "actor_target_entropy": -2.0, "actor_entropy": -0.2043046599328518, "alpha_loss": 0.000501653142971918, "alpha_value": 0.012431354417191398, "duration": 87.45327258110046, "step": 97500}
{"episode_reward": 923.0, "episode": 391.0, "batch_reward": 3.4724453125, "critic_loss": 2.5111570830345156, "actor_loss": -384.71010083007815, "actor_target_entropy": -2.0, "actor_entropy": -0.38628961888700725, "alpha_loss": -0.0005205850786296651, "alpha_value": 0.0124342407211345, "duration": 87.12328457832336, "step": 97750}
{"episode_reward": 948.0, "episode": 392.0, "batch_reward": 3.4793671875, "critic_loss": 2.5425359926223754, "actor_loss": -384.8029504394531, "actor_target_entropy": -2.0, "actor_entropy": -0.304329115241766, "alpha_loss": 0.0004574681466910988, "alpha_value": 0.01244965027560893, "duration": 90.48818182945251, "step": 98000}
{"episode_reward": 994.0, "episode": 393.0, "batch_reward": 3.4804765625, "critic_loss": 2.670333827495575, "actor_loss": -384.8964577636719, "actor_target_entropy": -2.0, "actor_entropy": -0.4254953552484512, "alpha_loss": -0.0003128593100700527, "alpha_value": 0.01243645606322678, "duration": 95.44907593727112, "step": 98250}
{"episode_reward": 950.0, "episode": 394.0, "batch_reward": 3.4854140625, "critic_loss": 2.876343786716461, "actor_loss": -385.0666083984375, "actor_target_entropy": -2.0, "actor_entropy": -0.5278976831436157, "alpha_loss": 0.0003112813918851316, "alpha_value": 0.012450646879447544, "duration": 91.66387748718262, "step": 98500}
{"episode_reward": 951.0, "episode": 395.0, "batch_reward": 3.48028125, "critic_loss": 2.669741183280945, "actor_loss": -385.14800073242185, "actor_target_entropy": -2.0, "actor_entropy": -0.023606884069740774, "alpha_loss": -0.0016607848287094385, "alpha_value": 0.012429987837223431, "duration": 87.21560406684875, "step": 98750}
{"episode_reward": 990.0, "episode": 396.0, "batch_reward": 3.4889921875, "critic_loss": 3.002660102844238, "actor_loss": -385.2320439453125, "actor_target_entropy": -2.0, "actor_entropy": -0.15942830399423838, "alpha_loss": -0.0016015996590722351, "alpha_value": 0.012579809525897658, "duration": 87.75826382637024, "step": 99000}
{"episode_reward": 989.0, "episode": 397.0, "batch_reward": 3.4891171875, "critic_loss": 2.6255216734409332, "actor_loss": -385.32521411132814, "actor_target_entropy": -2.0, "actor_entropy": -0.16511517173051835, "alpha_loss": -0.0007704071686603129, "alpha_value": 0.012670954719013949, "duration": 88.03516387939453, "step": 99250}
{"episode_reward": 952.0, "episode": 398.0, "batch_reward": 3.4889765625, "critic_loss": 2.585528692245483, "actor_loss": -385.45633959960935, "actor_target_entropy": -2.0, "actor_entropy": -0.28388374257087706, "alpha_loss": 0.0004328162696911022, "alpha_value": 0.012694546856756398, "duration": 87.01058316230774, "step": 99500}
{"episode_reward": 962.0, "episode": 399.0, "batch_reward": 3.4882109375, "critic_loss": 2.6247248706817627, "actor_loss": -385.52626416015624, "actor_target_entropy": -2.0, "actor_entropy": -0.1555929735377431, "alpha_loss": -0.0005902572218328715, "alpha_value": 0.012657020171919582, "duration": 86.48725414276123, "step": 99750}
{"episode_reward": 997.0, "episode": 400.0, "batch_reward": 3.4924777233935744, "critic_loss": 2.5651809987294145, "actor_loss": -385.50374877929687, "actor_target_entropy": -2.0, "actor_entropy": -0.3310420741289854, "alpha_loss": 0.0006075962570030242, "alpha_value": 0.012659633692261354, "step": 99999}
