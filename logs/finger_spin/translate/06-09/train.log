{"episode_reward": 0.0, "episode": 1.0, "duration": 51.22274041175842, "step": 500}
{"episode_reward": 3.0, "episode": 2.0, "duration": 1.260591745376587, "step": 1000}
{"episode_reward": 11.0, "episode": 3.0, "Q1 loss": 0.035528058069292455, "Q2 loss": 0.036101398587692526, "Mean Target Q": 0.0838255062950775, "Mean Q1": 0.08356732489098795, "Mean Q2": 0.08413198067503981, "critic_loss": 0.07162945661647245, "batch_reward": 0.0142734375, "actor_loss": -0.20317125174403192, "actor_target_entropy": -2.0, "actor_entropy": 2.521509122237563, "alpha_loss": 0.3236227491274476, "alpha_value": 0.09876851565739542, "duration": 1246.075894832611, "step": 1500}
{"episode_reward": 5.0, "episode": 4.0, "Q1 loss": 0.01695211803400889, "Q2 loss": 0.0168447659406811, "Mean Target Q": 0.34677769082784654, "Mean Q1": 0.3459023334085941, "Mean Q2": 0.34587519469857214, "critic_loss": 0.03379688389133662, "batch_reward": 0.01178515625, "actor_loss": -0.4780619864463806, "actor_target_entropy": -2.0, "actor_entropy": 2.5713626470565796, "alpha_loss": 0.31517115676403046, "alpha_value": 0.09634690388816552, "duration": 498.80143761634827, "step": 2000}
{"episode_reward": 8.0, "episode": 5.0, "Q1 loss": 0.023745861433446407, "Q2 loss": 0.023645380274392665, "Mean Target Q": 0.6423779768943787, "Mean Q1": 0.6416300557851792, "Mean Q2": 0.6417154630422592, "critic_loss": 0.047391241602599624, "batch_reward": 0.01394921875, "actor_loss": -0.7690939702987671, "actor_target_entropy": -2.0, "actor_entropy": 2.6164080047607423, "alpha_loss": 0.3035891070365906, "alpha_value": 0.094061792037214, "duration": 149.6039650440216, "step": 2500}
{"episode_reward": 13.0, "episode": 6.0, "Q1 loss": 0.04242350787483156, "Q2 loss": 0.0419343887232244, "Mean Target Q": 0.9490354288816452, "Mean Q1": 0.9480905188322067, "Mean Q2": 0.9481056555509567, "critic_loss": 0.08435789672285318, "batch_reward": 0.01711328125, "actor_loss": -1.1047932772636413, "actor_target_entropy": -2.0, "actor_entropy": 2.5897648477554323, "alpha_loss": 0.27756491404771805, "alpha_value": 0.09187661077422946, "duration": 204.75331592559814, "step": 3000}
{"episode_reward": 12.0, "episode": 7.0, "Q1 loss": 0.08583386592566968, "Q2 loss": 0.08536110463738442, "Mean Target Q": 1.4490021440982819, "Mean Q1": 1.4474852931499482, "Mean Q2": 1.44750927734375, "critic_loss": 0.17119497087597846, "batch_reward": 0.02047265625, "actor_loss": -1.6610013761520386, "actor_target_entropy": -2.0, "actor_entropy": 2.4214570741653443, "alpha_loss": 0.2387258810400963, "alpha_value": 0.08994225640602063, "duration": 153.14814829826355, "step": 3500}
{"episode_reward": 38.0, "episode": 8.0, "Q1 loss": 0.11600387592613697, "Q2 loss": 0.11496803147345781, "Mean Target Q": 2.080351526975632, "Mean Q1": 2.0790310697555543, "Mean Q2": 2.0790714988708494, "critic_loss": 0.23097190776467325, "batch_reward": 0.0308984375, "actor_loss": -2.2890250859260557, "actor_target_entropy": -2.0, "actor_entropy": 2.26304746389389, "alpha_loss": 0.21987455028295516, "alpha_value": 0.08813686055396244, "duration": 152.16074895858765, "step": 4000}
{"episode_reward": 52.0, "episode": 9.0, "Q1 loss": 0.0925687707811594, "Q2 loss": 0.09179739102721214, "Mean Target Q": 2.7400952248573303, "Mean Q1": 2.738913221359253, "Mean Q2": 2.7388746304512024, "critic_loss": 0.1843661617487669, "batch_reward": 0.03275390625, "actor_loss": -2.987896807670593, "actor_target_entropy": -2.0, "actor_entropy": 2.141799473762512, "alpha_loss": 0.1974322304725647, "alpha_value": 0.08643982825917802, "duration": 152.86897110939026, "step": 4500}
{"episode_reward": 0.0, "episode": 10.0, "Q1 loss": 0.09688083426654338, "Q2 loss": 0.09599475000798702, "Mean Target Q": 3.566035186290741, "Mean Q1": 3.5646877155303955, "Mean Q2": 3.564735713005066, "critic_loss": 0.19287558411061764, "batch_reward": 0.03146484375, "actor_loss": -3.7983220977783203, "actor_target_entropy": -2.0, "actor_entropy": 2.0966494340896604, "alpha_loss": 0.18951572877168654, "alpha_value": 0.08478921316800762, "step": 5000}
{"duration": 581.1035268306732, "step": 5000}
{"episode_reward": 58.0, "episode": 11.0, "Q1 loss": 0.12708792757987977, "Q2 loss": 0.1274512628763914, "Mean Target Q": 4.262455881595612, "Mean Q1": 4.261000035762787, "Mean Q2": 4.261010180950165, "critic_loss": 0.2545391908288002, "batch_reward": 0.0532578125, "actor_loss": -4.485245323181152, "actor_target_entropy": -2.0, "actor_entropy": 2.0249186544418336, "alpha_loss": 0.165569188952446, "alpha_value": 0.08318749604321368, "duration": 156.4640290737152, "step": 5500}
{"episode_reward": 201.0, "episode": 12.0, "Q1 loss": 0.10785592524707317, "Q2 loss": 0.10799421969056129, "Mean Target Q": 5.202317311286926, "Mean Q1": 5.2012437782287595, "Mean Q2": 5.201128503799438, "critic_loss": 0.21585014489293097, "batch_reward": 0.06830078125, "actor_loss": -5.468487998962402, "actor_target_entropy": -2.0, "actor_entropy": 1.8978762245178222, "alpha_loss": 0.1430274099111557, "alpha_value": 0.08176461494390577, "duration": 198.07720375061035, "step": 6000}
{"episode_reward": 17.0, "episode": 13.0, "Q1 loss": 0.13056958030164242, "Q2 loss": 0.13152378372848034, "Mean Target Q": 6.176199284553528, "Mean Q1": 6.174908968925476, "Mean Q2": 6.174864359855652, "critic_loss": 0.26209336444735526, "batch_reward": 0.0845390625, "actor_loss": -6.482179874420166, "actor_target_entropy": -2.0, "actor_entropy": 1.8319687647819518, "alpha_loss": 0.11822582894563675, "alpha_value": 0.08044960463988741, "duration": 151.29987692832947, "step": 6500}
{"episode_reward": 278.0, "episode": 14.0, "Q1 loss": 0.1798245356976986, "Q2 loss": 0.1808701937198639, "Mean Target Q": 7.375910826683045, "Mean Q1": 7.374375867843628, "Mean Q2": 7.374416351318359, "critic_loss": 0.36069472894072535, "batch_reward": 0.13276953125, "actor_loss": -7.7590237255096435, "actor_target_entropy": -2.0, "actor_entropy": 1.6597888622283936, "alpha_loss": 0.07997386930882931, "alpha_value": 0.0794056292333367, "duration": 151.6694371700287, "step": 7000}
{"episode_reward": 450.0, "episode": 15.0, "Q1 loss": 0.21718008345365525, "Q2 loss": 0.2174439944922924, "Mean Target Q": 8.96387442970276, "Mean Q1": 8.962303269386291, "Mean Q2": 8.962311896324158, "critic_loss": 0.4346240784525871, "batch_reward": 0.1928984375, "actor_loss": -9.396505409240723, "actor_target_entropy": -2.0, "actor_entropy": 1.5169621605873107, "alpha_loss": 0.0504904899597168, "alpha_value": 0.07865248579390424, "duration": 151.8699016571045, "step": 7500}
{"episode_reward": 507.0, "episode": 16.0, "Q1 loss": 0.26342752957344057, "Q2 loss": 0.26584090405702593, "Mean Target Q": 10.802330949783325, "Mean Q1": 10.800875181198121, "Mean Q2": 10.800747711181641, "critic_loss": 0.52926843470335, "batch_reward": 0.244109375, "actor_loss": -11.287996822357178, "actor_target_entropy": -2.0, "actor_entropy": 1.4255403478145598, "alpha_loss": 0.03159728323388845, "alpha_value": 0.07812612929628596, "duration": 151.3707001209259, "step": 8000}
{"episode_reward": 528.0, "episode": 17.0, "Q1 loss": 0.2957992470264435, "Q2 loss": 0.29456407749652863, "Mean Target Q": 12.908532114028931, "Mean Q1": 12.90666739654541, "Mean Q2": 12.90685312652588, "critic_loss": 0.5903633236289024, "batch_reward": 0.29848046875, "actor_loss": -13.43525270462036, "actor_target_entropy": -2.0, "actor_entropy": 1.3186808457374573, "alpha_loss": 0.013632008218672127, "alpha_value": 0.07780288633980312, "duration": 151.174955368042, "step": 8500}
{"episode_reward": 615.0, "episode": 18.0, "Q1 loss": 0.29486753916740416, "Q2 loss": 0.298328145891428, "Mean Target Q": 15.239589450836181, "Mean Q1": 15.237766296386718, "Mean Q2": 15.237521995544434, "critic_loss": 0.5931956841945648, "batch_reward": 0.35108203125, "actor_loss": -15.79958910369873, "actor_target_entropy": -2.0, "actor_entropy": 1.2459268293380736, "alpha_loss": 0.0005557471783831715, "alpha_value": 0.07768772113793801, "duration": 151.58520674705505, "step": 9000}
{"episode_reward": 604.0, "episode": 19.0, "Q1 loss": 0.29342866775393484, "Q2 loss": 0.29432968759536743, "Mean Target Q": 17.697679187774657, "Mean Q1": 17.695679054260253, "Mean Q2": 17.69572480392456, "critic_loss": 0.5877583556771279, "batch_reward": 0.40204296875, "actor_loss": -18.285168853759764, "actor_target_entropy": -2.0, "actor_entropy": 1.178487640142441, "alpha_loss": -0.008880169368349016, "alpha_value": 0.07778243751382838, "duration": 151.8070318698883, "step": 9500}
{"episode_reward": 671.0, "episode": 20.0, "Q1 loss": 0.2791888042986393, "Q2 loss": 0.27846904489398, "Mean Target Q": 20.292686847686767, "Mean Q1": 20.291330295562744, "Mean Q2": 20.29130630874634, "critic_loss": 0.5576578496098519, "batch_reward": 0.45273828125, "actor_loss": -20.89428956604004, "actor_target_entropy": -2.0, "actor_entropy": 1.120606234073639, "alpha_loss": -0.014462995022535324, "alpha_value": 0.07803698361741407, "step": 10000}
{"duration": 166.8290557861328, "step": 10000}
{"episode_reward": 699.0, "episode": 21.0, "Q1 loss": 0.2516694574952126, "Q2 loss": 0.25334182173013686, "Mean Target Q": 22.998068004608154, "Mean Q1": 22.99630641555786, "Mean Q2": 22.99630573654175, "critic_loss": 0.5050112789869309, "batch_reward": 0.499359375, "actor_loss": -23.613672462463377, "actor_target_entropy": -2.0, "actor_entropy": 1.0657439742088317, "alpha_loss": -0.019440679299645127, "alpha_value": 0.07844610233492723, "duration": 151.59991788864136, "step": 10500}
{"episode_reward": 723.0, "episode": 22.0, "Q1 loss": 0.23783172103762626, "Q2 loss": 0.23974661287665366, "Mean Target Q": 25.66759761047363, "Mean Q1": 25.666073608398438, "Mean Q2": 25.6659453125, "critic_loss": 0.4775783341526985, "batch_reward": 0.54631640625, "actor_loss": -26.23411293029785, "actor_target_entropy": -2.0, "actor_entropy": 1.0478499190807342, "alpha_loss": -0.018278227833565325, "alpha_value": 0.07897146132328098, "duration": 148.58463597297668, "step": 11000}
{"episode_reward": 737.0, "episode": 23.0, "Q1 loss": 0.23192083498835564, "Q2 loss": 0.23393769592046737, "Mean Target Q": 28.279410385131836, "Mean Q1": 28.27796957397461, "Mean Q2": 28.277992698669433, "critic_loss": 0.4658585295677185, "batch_reward": 0.58431640625, "actor_loss": -28.824069969177245, "actor_target_entropy": -2.0, "actor_entropy": 1.016948252916336, "alpha_loss": -0.018858131895773112, "alpha_value": 0.07954674586130309, "duration": 147.99455094337463, "step": 11500}
{"episode_reward": 699.0, "episode": 24.0, "Q1 loss": 0.24054948860406875, "Q2 loss": 0.24080354234576226, "Mean Target Q": 30.85051300430298, "Mean Q1": 30.84949937057495, "Mean Q2": 30.849424758911134, "critic_loss": 0.48135303181409833, "batch_reward": 0.6174765625, "actor_loss": -31.390841987609864, "actor_target_entropy": -2.0, "actor_entropy": 1.02650212931633, "alpha_loss": -0.018386413568165155, "alpha_value": 0.08018618431645438, "duration": 152.29377222061157, "step": 12000}
{"episode_reward": 738.0, "episode": 25.0, "Q1 loss": 0.23158331722021103, "Q2 loss": 0.23321725299954416, "Mean Target Q": 33.37683027648926, "Mean Q1": 33.37523093795777, "Mean Q2": 33.37535763549805, "critic_loss": 0.46480057007074355, "batch_reward": 0.6572421875, "actor_loss": -33.89833493041992, "actor_target_entropy": -2.0, "actor_entropy": 1.0151207327842713, "alpha_loss": -0.018544512978289275, "alpha_value": 0.0809075552099554, "duration": 149.51518988609314, "step": 12500}
{"episode_reward": 743.0, "episode": 26.0, "Q1 loss": 0.2339399927854538, "Q2 loss": 0.23941246247291564, "Mean Target Q": 35.79457189178467, "Mean Q1": 35.79356032562256, "Mean Q2": 35.79335208129883, "critic_loss": 0.4733524551987648, "batch_reward": 0.68606640625, "actor_loss": -36.27728636169434, "actor_target_entropy": -2.0, "actor_entropy": 1.0131842155456543, "alpha_loss": -0.018338372476398943, "alpha_value": 0.081734873659712, "duration": 150.1052930355072, "step": 13000}
{"episode_reward": 738.0, "episode": 27.0, "Q1 loss": 0.23740423914790154, "Q2 loss": 0.2370087822675705, "Mean Target Q": 38.21902306365967, "Mean Q1": 38.2178378829956, "Mean Q2": 38.21786294555664, "critic_loss": 0.47441302222013476, "batch_reward": 0.7186015625, "actor_loss": -38.68148541259766, "actor_target_entropy": -2.0, "actor_entropy": 1.004986918926239, "alpha_loss": -0.019019054458476604, "alpha_value": 0.08264197835132402, "duration": 150.24499487876892, "step": 13500}
{"episode_reward": 765.0, "episode": 28.0, "Q1 loss": 0.2177757612168789, "Q2 loss": 0.22040235978364944, "Mean Target Q": 40.603023796081544, "Mean Q1": 40.60199488830566, "Mean Q2": 40.60190908050537, "critic_loss": 0.4381781216263771, "batch_reward": 0.74879296875, "actor_loss": -41.03933992004394, "actor_target_entropy": -2.0, "actor_entropy": 1.0035447499752044, "alpha_loss": -0.01914102096809074, "alpha_value": 0.08365522238812191, "duration": 150.81755805015564, "step": 14000}
{"episode_reward": 750.0, "episode": 29.0, "Q1 loss": 0.22009171348810197, "Q2 loss": 0.22020579320192338, "Mean Target Q": 42.917792259216306, "Mean Q1": 42.91698803710938, "Mean Q2": 42.917044799804685, "critic_loss": 0.44029750663042067, "batch_reward": 0.773984375, "actor_loss": -43.33668287658691, "actor_target_entropy": -2.0, "actor_entropy": 0.9924956340789794, "alpha_loss": -0.018219280710909516, "alpha_value": 0.08476520391118342, "duration": 149.7726149559021, "step": 14500}
{"episode_reward": 761.0, "episode": 30.0, "Q1 loss": 0.22296491166949273, "Q2 loss": 0.22171929931640624, "Mean Target Q": 45.177906196594236, "Mean Q1": 45.17655847167969, "Mean Q2": 45.176604377746585, "critic_loss": 0.44468421095609667, "batch_reward": 0.79715625, "actor_loss": -45.585653686523436, "actor_target_entropy": -2.0, "actor_entropy": 0.9887832288742066, "alpha_loss": -0.016675787810236216, "alpha_value": 0.08590507436683129, "step": 15000}
{"duration": 166.62073969841003, "step": 15000}
{"episode_reward": 733.0, "episode": 31.0, "Q1 loss": 0.23039110168814658, "Q2 loss": 0.22974716031551362, "Mean Target Q": 47.30985279846191, "Mean Q1": 47.30888395690918, "Mean Q2": 47.30884657287598, "critic_loss": 0.4601382627487183, "batch_reward": 0.8167421875, "actor_loss": -47.676685577392576, "actor_target_entropy": -2.0, "actor_entropy": 0.9783171355724335, "alpha_loss": -0.012762938892003148, "alpha_value": 0.08695235938825652, "duration": 149.87277603149414, "step": 15500}
{"episode_reward": 749.0, "episode": 32.0, "Q1 loss": 0.21926432883739472, "Q2 loss": 0.22200498542189598, "Mean Target Q": 49.45619403076172, "Mean Q1": 49.455148551940916, "Mean Q2": 49.45528601837158, "critic_loss": 0.44126931446790696, "batch_reward": 0.8466953125, "actor_loss": -49.804025360107424, "actor_target_entropy": -2.0, "actor_entropy": 0.9673014912605286, "alpha_loss": -0.010606887627858668, "alpha_value": 0.08785428934355921, "duration": 150.39163327217102, "step": 16000}
{"episode_reward": 769.0, "episode": 33.0, "Q1 loss": 0.21728331696987152, "Q2 loss": 0.21730359303951263, "Mean Target Q": 51.558667549133304, "Mean Q1": 51.55775228118897, "Mean Q2": 51.55770918273926, "critic_loss": 0.43458690917491916, "batch_reward": 0.86910546875, "actor_loss": -51.88125419616699, "actor_target_entropy": -2.0, "actor_entropy": 0.9487900340557098, "alpha_loss": -0.009925328069832175, "alpha_value": 0.08873050399084974, "duration": 149.4845917224884, "step": 16500}
{"episode_reward": 779.0, "episode": 34.0, "Q1 loss": 0.21534421148896218, "Q2 loss": 0.2155163215994835, "Mean Target Q": 53.67075408935547, "Mean Q1": 53.66999634552002, "Mean Q2": 53.66985723876953, "critic_loss": 0.4308605333566666, "batch_reward": 0.8871640625, "actor_loss": -54.00690823364258, "actor_target_entropy": -2.0, "actor_entropy": 0.9462082855701447, "alpha_loss": -0.011435099840629846, "alpha_value": 0.08978276572151177, "duration": 149.51402282714844, "step": 17000}
{"episode_reward": 739.0, "episode": 35.0, "Q1 loss": 0.22662705966830254, "Q2 loss": 0.2249395200908184, "Mean Target Q": 55.706688049316405, "Mean Q1": 55.70559970855713, "Mean Q2": 55.705710830688474, "critic_loss": 0.4515665799975395, "batch_reward": 0.90069140625, "actor_loss": -56.005414016723634, "actor_target_entropy": -2.0, "actor_entropy": 0.9587395112514496, "alpha_loss": -0.009056342190131544, "alpha_value": 0.0908782493500194, "duration": 150.32173705101013, "step": 17500}
{"episode_reward": 791.0, "episode": 36.0, "Q1 loss": 0.2222759076654911, "Q2 loss": 0.219955589979887, "Mean Target Q": 57.65448222351074, "Mean Q1": 57.653951225280764, "Mean Q2": 57.65386181640625, "critic_loss": 0.44223149806261064, "batch_reward": 0.91930859375, "actor_loss": -57.96906817626953, "actor_target_entropy": -2.0, "actor_entropy": 0.9318163049221039, "alpha_loss": -0.011407489759381861, "alpha_value": 0.09191781413623015, "duration": 149.54079699516296, "step": 18000}
{"episode_reward": 775.0, "episode": 37.0, "Q1 loss": 0.21953285697102548, "Q2 loss": 0.21723797908425332, "Mean Target Q": 59.69612400054932, "Mean Q1": 59.695235717773436, "Mean Q2": 59.69520700836182, "critic_loss": 0.43677083575725556, "batch_reward": 0.9421328125, "actor_loss": -60.01005781555176, "actor_target_entropy": -2.0, "actor_entropy": 0.9201391804218292, "alpha_loss": -0.012374937050510198, "alpha_value": 0.09337349538732595, "duration": 149.6404528617859, "step": 18500}
{"episode_reward": 816.0, "episode": 38.0, "Q1 loss": 0.21761845079064368, "Q2 loss": 0.2150932689011097, "Mean Target Q": 61.66282342529297, "Mean Q1": 61.66180187225342, "Mean Q2": 61.6619024887085, "critic_loss": 0.43271172070503233, "batch_reward": 0.95994921875, "actor_loss": -61.955230590820314, "actor_target_entropy": -2.0, "actor_entropy": 0.9179987735748291, "alpha_loss": -0.01276041981158778, "alpha_value": 0.09496513432747283, "duration": 148.79515933990479, "step": 19000}
{"episode_reward": 761.0, "episode": 39.0, "Q1 loss": 0.21235159984230995, "Q2 loss": 0.21244278013706208, "Mean Target Q": 63.56904903411865, "Mean Q1": 63.568522636413576, "Mean Q2": 63.56848793029785, "critic_loss": 0.4247943806052208, "batch_reward": 0.97227734375, "actor_loss": -63.85704035949707, "actor_target_entropy": -2.0, "actor_entropy": 0.9129112863540649, "alpha_loss": -0.00971243828907609, "alpha_value": 0.09644852863837222, "duration": 148.49612188339233, "step": 19500}
{"episode_reward": 783.0, "episode": 40.0, "Q1 loss": 0.233259292781353, "Q2 loss": 0.2331386635005474, "Mean Target Q": 65.4069808883667, "Mean Q1": 65.40611309814453, "Mean Q2": 65.40613955688477, "critic_loss": 0.46639795684814456, "batch_reward": 0.98687890625, "actor_loss": -65.6714845275879, "actor_target_entropy": -2.0, "actor_entropy": 0.9090102918148041, "alpha_loss": -0.007505077801179141, "alpha_value": 0.09751343485864804, "step": 20000}
{"duration": 164.7781720161438, "step": 20000}
{"episode_reward": 752.0, "episode": 41.0, "Q1 loss": 0.22912307757139205, "Q2 loss": 0.22921429350972175, "Mean Target Q": 67.17893600463867, "Mean Q1": 67.1783048095703, "Mean Q2": 67.17825137329102, "critic_loss": 0.4583373707532883, "batch_reward": 0.9984375, "actor_loss": -67.43908303833008, "actor_target_entropy": -2.0, "actor_entropy": 0.8999295709133148, "alpha_loss": -0.007236070116981864, "alpha_value": 0.09876021958425776, "duration": 164.710510969162, "step": 20500}
{"episode_reward": 742.0, "episode": 42.0, "Q1 loss": 0.22019598266482354, "Q2 loss": 0.22176842802762986, "Mean Target Q": 68.92223832702636, "Mean Q1": 68.92131134033202, "Mean Q2": 68.92136018371582, "critic_loss": 0.44196441024541855, "batch_reward": 1.01275390625, "actor_loss": -69.13929818725586, "actor_target_entropy": -2.0, "actor_entropy": 0.8956091363430023, "alpha_loss": -0.005948776237666607, "alpha_value": 0.09962211511066199, "duration": 147.63396978378296, "step": 21000}
{"episode_reward": 805.0, "episode": 43.0, "Q1 loss": 0.22457461920380592, "Q2 loss": 0.2228063171207905, "Mean Target Q": 70.67413497924805, "Mean Q1": 70.67361242675781, "Mean Q2": 70.67355183410645, "critic_loss": 0.44738093543052676, "batch_reward": 1.02673828125, "actor_loss": -70.9164981994629, "actor_target_entropy": -2.0, "actor_entropy": 0.8920248532295227, "alpha_loss": -0.005142823938280344, "alpha_value": 0.10056176162790965, "duration": 147.39851546287537, "step": 21500}
{"episode_reward": 758.0, "episode": 44.0, "Q1 loss": 0.2353644773066044, "Q2 loss": 0.23671531638503074, "Mean Target Q": 72.33897302246093, "Mean Q1": 72.33843794250488, "Mean Q2": 72.33821141052246, "critic_loss": 0.4720797941684723, "batch_reward": 1.03493359375, "actor_loss": -72.55393646240235, "actor_target_entropy": -2.0, "actor_entropy": 0.8816843721866607, "alpha_loss": -0.0046806752171833065, "alpha_value": 0.10134574628140694, "duration": 147.54702877998352, "step": 22000}
{"episode_reward": 799.0, "episode": 45.0, "Q1 loss": 0.23737233167886734, "Q2 loss": 0.23482830354571343, "Mean Target Q": 73.96741438293456, "Mean Q1": 73.96628494262696, "Mean Q2": 73.96662454223633, "critic_loss": 0.4722006344795227, "batch_reward": 1.0478046875, "actor_loss": -74.20296994018555, "actor_target_entropy": -2.0, "actor_entropy": 0.885474943637848, "alpha_loss": -0.004897572208661586, "alpha_value": 0.10217842910720103, "duration": 148.09764790534973, "step": 22500}
{"episode_reward": 750.0, "episode": 46.0, "Q1 loss": 0.22574767836928367, "Q2 loss": 0.22915438291430473, "Mean Target Q": 75.54901486206055, "Mean Q1": 75.54865684509278, "Mean Q2": 75.54832972717286, "critic_loss": 0.454902060508728, "batch_reward": 1.05745703125, "actor_loss": -75.76737573242187, "actor_target_entropy": -2.0, "actor_entropy": 0.876939578294754, "alpha_loss": -0.0030208894833922387, "alpha_value": 0.10291162087184473, "duration": 147.94462323188782, "step": 23000}
{"episode_reward": 772.0, "episode": 47.0, "Q1 loss": 0.25254590311646463, "Q2 loss": 0.24736868980526924, "Mean Target Q": 77.09496711730957, "Mean Q1": 77.09406781005859, "Mean Q2": 77.09435220336914, "critic_loss": 0.49991459321975706, "batch_reward": 1.067765625, "actor_loss": -77.27923236083984, "actor_target_entropy": -2.0, "actor_entropy": 0.8900684154033661, "alpha_loss": -0.003204958785092458, "alpha_value": 0.10350231444551931, "duration": 145.22746801376343, "step": 23500}
{"episode_reward": 727.0, "episode": 48.0, "Q1 loss": 0.2390472840964794, "Q2 loss": 0.24241221830248832, "Mean Target Q": 78.6003504486084, "Mean Q1": 78.5998244934082, "Mean Q2": 78.59983125305176, "critic_loss": 0.48145950108766555, "batch_reward": 1.0787421875, "actor_loss": -78.78737707519531, "actor_target_entropy": -2.0, "actor_entropy": 0.8796011557579041, "alpha_loss": -0.0002832239237613976, "alpha_value": 0.10377134519458836, "duration": 147.03802013397217, "step": 24000}
{"episode_reward": 794.0, "episode": 49.0, "Q1 loss": 0.2505914813578129, "Q2 loss": 0.2521080693602562, "Mean Target Q": 80.02306233215332, "Mean Q1": 80.02239863586426, "Mean Q2": 80.02233703613281, "critic_loss": 0.502699550151825, "batch_reward": 1.084453125, "actor_loss": -80.17824996948242, "actor_target_entropy": -2.0, "actor_entropy": 0.8733453924655914, "alpha_loss": -0.0026111617465503514, "alpha_value": 0.10401391476652001, "duration": 153.45631623268127, "step": 24500}
{"episode_reward": 818.0, "episode": 50.0, "Q1 loss": 0.22663411545753478, "Q2 loss": 0.22768197321891784, "Mean Target Q": 81.53355932617187, "Mean Q1": 81.53290023803712, "Mean Q2": 81.53283807373047, "critic_loss": 0.454316089451313, "batch_reward": 1.1033359375, "actor_loss": -81.7071169128418, "actor_target_entropy": -2.0, "actor_entropy": 0.8633185529708862, "alpha_loss": -0.001780887417960912, "alpha_value": 0.104626744885117, "step": 25000}
{"duration": 162.54173684120178, "step": 25000}
{"episode_reward": 821.0, "episode": 51.0, "Q1 loss": 0.24781211304664613, "Q2 loss": 0.24806475296616554, "Mean Target Q": 82.9373175354004, "Mean Q1": 82.93672694396973, "Mean Q2": 82.93675398254395, "critic_loss": 0.49587686598300934, "batch_reward": 1.1117578125, "actor_loss": -83.09982760620117, "actor_target_entropy": -2.0, "actor_entropy": 0.8557863981723786, "alpha_loss": -0.0027373582273721693, "alpha_value": 0.10496718344990312, "duration": 149.78404235839844, "step": 25500}
{"episode_reward": 794.0, "episode": 52.0, "Q1 loss": 0.225216919362545, "Q2 loss": 0.22390788057446478, "Mean Target Q": 84.28875390625, "Mean Q1": 84.28815759277344, "Mean Q2": 84.28818293762207, "critic_loss": 0.44912480032444, "batch_reward": 1.11687109375, "actor_loss": -84.48736889648437, "actor_target_entropy": -2.0, "actor_entropy": 0.8620024578571319, "alpha_loss": -0.0024929114002734424, "alpha_value": 0.10552456935785007, "duration": 245.28285717964172, "step": 26000}
{"episode_reward": 794.0, "episode": 53.0, "Q1 loss": 0.2284224197268486, "Q2 loss": 0.2277788672745228, "Mean Target Q": 85.65254458618163, "Mean Q1": 85.65209376525878, "Mean Q2": 85.65211354064941, "critic_loss": 0.4562012863755226, "batch_reward": 1.128046875, "actor_loss": -85.82383966064454, "actor_target_entropy": -2.0, "actor_entropy": 0.8473540551662445, "alpha_loss": -0.002317585601937026, "alpha_value": 0.10602388078680136, "duration": 246.67377138137817, "step": 26500}
{"episode_reward": 796.0, "episode": 54.0, "Q1 loss": 0.22984702363610268, "Q2 loss": 0.23080308094620705, "Mean Target Q": 86.97411625671387, "Mean Q1": 86.97344668579102, "Mean Q2": 86.97343142700196, "critic_loss": 0.4606501045823097, "batch_reward": 1.1396953125, "actor_loss": -87.1368197631836, "actor_target_entropy": -2.0, "actor_entropy": 0.8520985488891601, "alpha_loss": -0.0004115315857343376, "alpha_value": 0.10635743479586787, "duration": 246.5490758419037, "step": 27000}
{"episode_reward": 812.0, "episode": 55.0, "Q1 loss": 0.22640874686837195, "Q2 loss": 0.22843162375688553, "Mean Target Q": 88.28344038391113, "Mean Q1": 88.28315257263183, "Mean Q2": 88.28295932006836, "critic_loss": 0.45484037071466443, "batch_reward": 1.1458359375, "actor_loss": -88.44629922485352, "actor_target_entropy": -2.0, "actor_entropy": 0.8348186535835266, "alpha_loss": -0.0011561030244920402, "alpha_value": 0.10646300545057001, "duration": 246.97072076797485, "step": 27500}
{"episode_reward": 817.0, "episode": 56.0, "Q1 loss": 0.21906053179502488, "Q2 loss": 0.21972594386339186, "Mean Target Q": 89.52731684875488, "Mean Q1": 89.52658952331544, "Mean Q2": 89.5267094116211, "critic_loss": 0.43878647553920747, "batch_reward": 1.15688671875, "actor_loss": -89.64697549438476, "actor_target_entropy": -2.0, "actor_entropy": 0.8391154332160949, "alpha_loss": 0.0003104012804105878, "alpha_value": 0.10654781707716611, "duration": 247.92937183380127, "step": 28000}
{"episode_reward": 790.0, "episode": 57.0, "Q1 loss": 0.2168956956267357, "Q2 loss": 0.2181666457951069, "Mean Target Q": 90.75219979858399, "Mean Q1": 90.75170965576172, "Mean Q2": 90.75170993041992, "critic_loss": 0.4350623407959938, "batch_reward": 1.16006640625, "actor_loss": -90.87645431518554, "actor_target_entropy": -2.0, "actor_entropy": 0.8386946005821228, "alpha_loss": 0.0002477177050895989, "alpha_value": 0.10653218513397415, "duration": 247.92072677612305, "step": 28500}
{"episode_reward": 802.0, "episode": 58.0, "Q1 loss": 0.23195749315619468, "Q2 loss": 0.22876237735152244, "Mean Target Q": 91.95788711547851, "Mean Q1": 91.95755213928223, "Mean Q2": 91.95741772460937, "critic_loss": 0.4607198719382286, "batch_reward": 1.1715859375, "actor_loss": -92.07476818847657, "actor_target_entropy": -2.0, "actor_entropy": 0.8264343264102936, "alpha_loss": 0.0019422093890607357, "alpha_value": 0.10621305817269408, "duration": 248.28920769691467, "step": 29000}
{"episode_reward": 814.0, "episode": 59.0, "Q1 loss": 0.22629476994276046, "Q2 loss": 0.22819651439785957, "Mean Target Q": 93.13432165527344, "Mean Q1": 93.13362982177735, "Mean Q2": 93.1336823272705, "critic_loss": 0.45449128437042235, "batch_reward": 1.17895703125, "actor_loss": -93.2804341430664, "actor_target_entropy": -2.0, "actor_entropy": 0.8039230351448059, "alpha_loss": -0.0012331142388284206, "alpha_value": 0.10608445796027526, "duration": 248.17681169509888, "step": 29500}
{"episode_reward": 788.0, "episode": 60.0, "Q1 loss": 0.2199114762544632, "Q2 loss": 0.22096000188589096, "Mean Target Q": 94.28793447875977, "Mean Q1": 94.28727044677734, "Mean Q2": 94.28749076843262, "critic_loss": 0.44087147825956347, "batch_reward": 1.1831640625, "actor_loss": -94.41095748901367, "actor_target_entropy": -2.0, "actor_entropy": 0.7966210000514984, "alpha_loss": -0.0020735028395429253, "alpha_value": 0.10660176066020004, "step": 30000}
{"duration": 284.0489356517792, "step": 30000}
{"episode_reward": 795.0, "episode": 61.0, "Q1 loss": 0.2105298049747944, "Q2 loss": 0.21059309792518616, "Mean Target Q": 95.4227205657959, "Mean Q1": 95.42204577636718, "Mean Q2": 95.42192155456543, "critic_loss": 0.42112290346622466, "batch_reward": 1.19106640625, "actor_loss": -95.52971206665039, "actor_target_entropy": -2.0, "actor_entropy": 0.7887568380832672, "alpha_loss": 0.0011550159468315543, "alpha_value": 0.10671234338880023, "duration": 250.16098761558533, "step": 30500}
{"episode_reward": 835.0, "episode": 62.0, "Q1 loss": 0.21555384361743926, "Q2 loss": 0.21371183568239213, "Mean Target Q": 96.55491705322265, "Mean Q1": 96.55459346008301, "Mean Q2": 96.55471664428711, "critic_loss": 0.4292656795978546, "batch_reward": 1.19855078125, "actor_loss": -96.6533178100586, "actor_target_entropy": -2.0, "actor_entropy": 0.7848130159378052, "alpha_loss": 0.0016626013785135002, "alpha_value": 0.1063362193024506, "duration": 248.9809193611145, "step": 31000}
{"episode_reward": 841.0, "episode": 63.0, "Q1 loss": 0.21084382539987565, "Q2 loss": 0.2096562494635582, "Mean Target Q": 97.71939961242676, "Mean Q1": 97.71879933166504, "Mean Q2": 97.71886320495605, "critic_loss": 0.42050007510185244, "batch_reward": 1.20890625, "actor_loss": -97.83394036865235, "actor_target_entropy": -2.0, "actor_entropy": 0.7894737939834595, "alpha_loss": 0.0007857805117964745, "alpha_value": 0.10620351649020104, "duration": 248.76607823371887, "step": 31500}
{"episode_reward": 815.0, "episode": 64.0, "Q1 loss": 0.19118310916423797, "Q2 loss": 0.19255316424369812, "Mean Target Q": 98.80202862548828, "Mean Q1": 98.80159767150879, "Mean Q2": 98.80160145568847, "critic_loss": 0.38373627299070356, "batch_reward": 1.2133984375, "actor_loss": -98.93163525390625, "actor_target_entropy": -2.0, "actor_entropy": 0.7844941201210022, "alpha_loss": 0.0001767530208453536, "alpha_value": 0.10597167102847872, "duration": 249.70139360427856, "step": 32000}
{"episode_reward": 819.0, "episode": 65.0, "Q1 loss": 0.19407880483567716, "Q2 loss": 0.19282491749525071, "Mean Target Q": 99.89155633544922, "Mean Q1": 99.89115486145019, "Mean Q2": 99.89112013244629, "critic_loss": 0.38690372264385225, "batch_reward": 1.22248828125, "actor_loss": -100.00708444213868, "actor_target_entropy": -2.0, "actor_entropy": 0.7896964569091797, "alpha_loss": 0.0005977825440932065, "alpha_value": 0.10588603863041805, "duration": 250.6319682598114, "step": 32500}
{"episode_reward": 816.0, "episode": 66.0, "Q1 loss": 0.20373061473667622, "Q2 loss": 0.2033759981095791, "Mean Target Q": 100.97501856994629, "Mean Q1": 100.9745736694336, "Mean Q2": 100.97458108520507, "critic_loss": 0.4071066129207611, "batch_reward": 1.2280234375, "actor_loss": -101.08008178710938, "actor_target_entropy": -2.0, "actor_entropy": 0.7767125904560089, "alpha_loss": 0.000474587919190526, "alpha_value": 0.10580429279123192, "duration": 250.47124481201172, "step": 33000}
{"episode_reward": 844.0, "episode": 67.0, "Q1 loss": 0.19614223727583885, "Q2 loss": 0.19396645104885102, "Mean Target Q": 101.98640783691407, "Mean Q1": 101.98589530944824, "Mean Q2": 101.9859168701172, "critic_loss": 0.39010868781805036, "batch_reward": 1.23434765625, "actor_loss": -102.08126040649414, "actor_target_entropy": -2.0, "actor_entropy": 0.7792339396476745, "alpha_loss": 0.0007792502734810114, "alpha_value": 0.10564232755177883, "duration": 251.23994779586792, "step": 33500}
{"episode_reward": 811.0, "episode": 68.0, "Q1 loss": 0.1867102246582508, "Q2 loss": 0.1846318889260292, "Mean Target Q": 103.04124932861328, "Mean Q1": 103.04082421875, "Mean Q2": 103.0407946472168, "critic_loss": 0.3713421140909195, "batch_reward": 1.242015625, "actor_loss": -103.1197759399414, "actor_target_entropy": -2.0, "actor_entropy": 0.7698361856937408, "alpha_loss": 1.8171542091295124e-05, "alpha_value": 0.10564281137500636, "duration": 250.42057752609253, "step": 34000}
{"episode_reward": 817.0, "episode": 69.0, "Q1 loss": 0.21621440660953523, "Q2 loss": 0.21510720747709275, "Mean Target Q": 104.0221376953125, "Mean Q1": 104.02167301940918, "Mean Q2": 104.02156449890137, "critic_loss": 0.4313216136097908, "batch_reward": 1.2463515625, "actor_loss": -104.13009201049805, "actor_target_entropy": -2.0, "actor_entropy": 0.7873330125808716, "alpha_loss": 0.00025810140976682307, "alpha_value": 0.10551389638001535, "duration": 251.21898365020752, "step": 34500}
{"episode_reward": 805.0, "episode": 70.0, "Q1 loss": 0.19171570727229117, "Q2 loss": 0.18961088660359382, "Mean Target Q": 105.00801866149902, "Mean Q1": 105.0076312713623, "Mean Q2": 105.00777714538575, "critic_loss": 0.38132659390568735, "batch_reward": 1.2539140625, "actor_loss": -105.10332690429688, "actor_target_entropy": -2.0, "actor_entropy": 0.769612636089325, "alpha_loss": 0.0004179480317980051, "alpha_value": 0.1055109777790439, "step": 35000}
{"duration": 288.5320951938629, "step": 35000}
{"episode_reward": 832.0, "episode": 71.0, "Q1 loss": 0.17589865842461586, "Q2 loss": 0.17511835405230522, "Mean Target Q": 105.90973785400391, "Mean Q1": 105.90937835693359, "Mean Q2": 105.90932257080078, "critic_loss": 0.3510170132517815, "batch_reward": 1.2552421875, "actor_loss": -106.0120060119629, "actor_target_entropy": -2.0, "actor_entropy": 0.7603257882595063, "alpha_loss": 0.00020469331601634622, "alpha_value": 0.10556398304839124, "duration": 255.57148814201355, "step": 35500}
{"episode_reward": 830.0, "episode": 72.0, "Q1 loss": 0.18340870013833047, "Q2 loss": 0.18481249867379665, "Mean Target Q": 106.82261787414551, "Mean Q1": 106.82210012817383, "Mean Q2": 106.82208393859864, "critic_loss": 0.368221199542284, "batch_reward": 1.25897265625, "actor_loss": -106.9239859008789, "actor_target_entropy": -2.0, "actor_entropy": 0.781957478761673, "alpha_loss": 0.002275895470753312, "alpha_value": 0.10522297196901198, "duration": 254.32145309448242, "step": 36000}
{"episode_reward": 809.0, "episode": 73.0, "Q1 loss": 0.1824188471734524, "Q2 loss": 0.18009293727576733, "Mean Target Q": 107.72989508056641, "Mean Q1": 107.7292534942627, "Mean Q2": 107.72937838745118, "critic_loss": 0.36251178377866744, "batch_reward": 1.26784765625, "actor_loss": -107.79927587890624, "actor_target_entropy": -2.0, "actor_entropy": 0.7917394127845764, "alpha_loss": 0.0015116916322149337, "alpha_value": 0.10466871198674495, "duration": 255.59475755691528, "step": 36500}
{"episode_reward": 819.0, "episode": 74.0, "Q1 loss": 0.1853852876573801, "Q2 loss": 0.18314829774200916, "Mean Target Q": 108.60829594421386, "Mean Q1": 108.60806063842773, "Mean Q2": 108.60806622314453, "critic_loss": 0.3685335857570171, "batch_reward": 1.27151171875, "actor_loss": -108.6957398071289, "actor_target_entropy": -2.0, "actor_entropy": 0.7704483397006988, "alpha_loss": -0.0003419711566530168, "alpha_value": 0.10468310650032546, "duration": 255.84212183952332, "step": 37000}
{"episode_reward": 831.0, "episode": 75.0, "Q1 loss": 0.16452542980015278, "Q2 loss": 0.16428170961141586, "Mean Target Q": 109.49056106567383, "Mean Q1": 109.49027841186523, "Mean Q2": 109.49020936584472, "critic_loss": 0.32880713948607443, "batch_reward": 1.27787890625, "actor_loss": -109.54885025024414, "actor_target_entropy": -2.0, "actor_entropy": 0.7702736418247222, "alpha_loss": 0.0016218011686578394, "alpha_value": 0.10460828242264199, "duration": 256.413831949234, "step": 37500}
{"episode_reward": 826.0, "episode": 76.0, "Q1 loss": 0.185024497538805, "Q2 loss": 0.18262306921184063, "Mean Target Q": 110.33719317626954, "Mean Q1": 110.33659948730468, "Mean Q2": 110.33652517700196, "critic_loss": 0.36764756646752356, "batch_reward": 1.27944140625, "actor_loss": -110.39357336425782, "actor_target_entropy": -2.0, "actor_entropy": 0.7674814903736115, "alpha_loss": -0.000762103233486414, "alpha_value": 0.10451767197165902, "duration": 257.1501247882843, "step": 38000}
{"episode_reward": 817.0, "episode": 77.0, "Q1 loss": 0.1778627310693264, "Q2 loss": 0.17874350868165492, "Mean Target Q": 111.17535792541504, "Mean Q1": 111.17492555236817, "Mean Q2": 111.17508427429199, "critic_loss": 0.35660623985528944, "batch_reward": 1.28796875, "actor_loss": -111.24351593017577, "actor_target_entropy": -2.0, "actor_entropy": 0.7628357925415039, "alpha_loss": 0.0018730233097448946, "alpha_value": 0.10428211817706759, "duration": 257.3026292324066, "step": 38500}
{"episode_reward": 818.0, "episode": 78.0, "Q1 loss": 0.17722281822562216, "Q2 loss": 0.17207548929750918, "Mean Target Q": 111.9530592956543, "Mean Q1": 111.95274850463868, "Mean Q2": 111.95261122131348, "critic_loss": 0.34929830744862556, "batch_reward": 1.29091015625, "actor_loss": -112.01310446166993, "actor_target_entropy": -2.0, "actor_entropy": 0.7645400259494781, "alpha_loss": 0.0021857338109984993, "alpha_value": 0.10382510197761537, "duration": 257.7848641872406, "step": 39000}
{"episode_reward": 841.0, "episode": 79.0, "Q1 loss": 0.1716071730852127, "Q2 loss": 0.1731729491353035, "Mean Target Q": 112.7906865234375, "Mean Q1": 112.7899884185791, "Mean Q2": 112.79009275817872, "critic_loss": 0.34478012219071386, "batch_reward": 1.296484375, "actor_loss": -112.84606909179688, "actor_target_entropy": -2.0, "actor_entropy": 0.7688865697383881, "alpha_loss": -0.00010129798436537386, "alpha_value": 0.10365381356423511, "duration": 258.6089689731598, "step": 39500}
{"episode_reward": 807.0, "episode": 80.0, "Q1 loss": 0.17564640752971172, "Q2 loss": 0.1735911603420973, "Mean Target Q": 113.5648053894043, "Mean Q1": 113.56466497802734, "Mean Q2": 113.5647476348877, "critic_loss": 0.34923756831884384, "batch_reward": 1.3022890625, "actor_loss": -113.63275592041016, "actor_target_entropy": -2.0, "actor_entropy": 0.7669138798713684, "alpha_loss": -0.0007140257344581186, "alpha_value": 0.10365695965058114, "step": 40000}
{"duration": 286.0938968658447, "step": 40000}
{"episode_reward": 782.0, "episode": 81.0, "Q1 loss": 0.18398300111293792, "Q2 loss": 0.1812566677480936, "Mean Target Q": 114.31503323364258, "Mean Q1": 114.31477461242676, "Mean Q2": 114.31455610656738, "critic_loss": 0.3652396686375141, "batch_reward": 1.3025859375, "actor_loss": -114.37176101684571, "actor_target_entropy": -2.0, "actor_entropy": 0.7767764108181, "alpha_loss": 0.0004455486345104873, "alpha_value": 0.10383553933618345, "duration": 238.2005650997162, "step": 40500}
{"episode_reward": 825.0, "episode": 82.0, "Q1 loss": 0.1767551756054163, "Q2 loss": 0.17394235442578793, "Mean Target Q": 115.03203987121582, "Mean Q1": 115.03164532470703, "Mean Q2": 115.03187377929687, "critic_loss": 0.35069753071665766, "batch_reward": 1.30454296875, "actor_loss": -115.08169314575196, "actor_target_entropy": -2.0, "actor_entropy": 0.7612171068191528, "alpha_loss": 0.0009416055902838707, "alpha_value": 0.10368311157450204, "duration": 239.7516541481018, "step": 41000}
{"episode_reward": 833.0, "episode": 83.0, "Q1 loss": 0.1861015481352806, "Q2 loss": 0.18508973185718058, "Mean Target Q": 115.77221522521972, "Mean Q1": 115.77162699890137, "Mean Q2": 115.77159315490722, "critic_loss": 0.3711912799179554, "batch_reward": 1.31426171875, "actor_loss": -115.82147079467774, "actor_target_entropy": -2.0, "actor_entropy": 0.757632880449295, "alpha_loss": 0.002392783775459975, "alpha_value": 0.10331177120251221, "duration": 270.69451785087585, "step": 41500}
{"episode_reward": 826.0, "episode": 84.0, "Q1 loss": 0.17325625209510326, "Q2 loss": 0.17221279314160348, "Mean Target Q": 116.46634115600585, "Mean Q1": 116.46625590515137, "Mean Q2": 116.46619996643066, "critic_loss": 0.34546904626488684, "batch_reward": 1.3153359375, "actor_loss": -116.51374880981446, "actor_target_entropy": -2.0, "actor_entropy": 0.7402029051780701, "alpha_loss": 0.0012098183473572134, "alpha_value": 0.10295137943716814, "duration": 240.00219106674194, "step": 42000}
{"episode_reward": 827.0, "episode": 85.0, "Q1 loss": 0.16395767705142497, "Q2 loss": 0.1606339434236288, "Mean Target Q": 117.15648260498047, "Mean Q1": 117.15597731018066, "Mean Q2": 117.15594528198243, "critic_loss": 0.3245916193127632, "batch_reward": 1.31737109375, "actor_loss": -117.21582333374023, "actor_target_entropy": -2.0, "actor_entropy": 0.7458122317790985, "alpha_loss": 0.0010333267727401108, "alpha_value": 0.10256343251200073, "duration": 240.21446228027344, "step": 42500}
{"episode_reward": 831.0, "episode": 86.0, "Q1 loss": 0.16526949916779995, "Q2 loss": 0.16243756441771984, "Mean Target Q": 117.84961003112792, "Mean Q1": 117.84929315185546, "Mean Q2": 117.8492266998291, "critic_loss": 0.3277070638239384, "batch_reward": 1.3253828125, "actor_loss": -117.8974480895996, "actor_target_entropy": -2.0, "actor_entropy": 0.7402826702594757, "alpha_loss": 0.0012023775423876941, "alpha_value": 0.10243475868552974, "duration": 240.2112011909485, "step": 43000}
{"episode_reward": 842.0, "episode": 87.0, "Q1 loss": 0.16328329259157182, "Q2 loss": 0.16215446276962758, "Mean Target Q": 118.52002716064453, "Mean Q1": 118.51968467712402, "Mean Q2": 118.51978759765625, "critic_loss": 0.3254377553462982, "batch_reward": 1.3268671875, "actor_loss": -118.55846026611329, "actor_target_entropy": -2.0, "actor_entropy": 0.7450665359497071, "alpha_loss": 0.0018386068993713706, "alpha_value": 0.10215767640195063, "duration": 240.21895384788513, "step": 43500}
{"episode_reward": 798.0, "episode": 88.0, "Q1 loss": 0.17222126644849778, "Q2 loss": 0.17178125278651715, "Mean Target Q": 119.17094502258301, "Mean Q1": 119.17038836669921, "Mean Q2": 119.17054463195801, "critic_loss": 0.34400251880288124, "batch_reward": 1.33215625, "actor_loss": -119.20620385742187, "actor_target_entropy": -2.0, "actor_entropy": 0.7396225430965424, "alpha_loss": 0.0031254987427964806, "alpha_value": 0.10166348865899134, "duration": 258.6360421180725, "step": 44000}
{"episode_reward": 833.0, "episode": 89.0, "Q1 loss": 0.15884361933171748, "Q2 loss": 0.15672771270573138, "Mean Target Q": 119.78191732788086, "Mean Q1": 119.78193949890137, "Mean Q2": 119.781755859375, "critic_loss": 0.31557133224606515, "batch_reward": 1.3327734375, "actor_loss": -119.82051278686524, "actor_target_entropy": -2.0, "actor_entropy": 0.7288994860649108, "alpha_loss": 0.002000035423785448, "alpha_value": 0.10106064730487965, "duration": 240.88584995269775, "step": 44500}
{"episode_reward": 825.0, "episode": 90.0, "Q1 loss": 0.16674455703794958, "Q2 loss": 0.16469250272214414, "Mean Target Q": 120.42654319763183, "Mean Q1": 120.42621423339844, "Mean Q2": 120.42631355285644, "critic_loss": 0.3314370595216751, "batch_reward": 1.340546875, "actor_loss": -120.47677328491211, "actor_target_entropy": -2.0, "actor_entropy": 0.7313761577606201, "alpha_loss": 0.0023965490446425973, "alpha_value": 0.10065552588137447, "step": 45000}
{"duration": 275.4042785167694, "step": 45000}
{"episode_reward": 830.0, "episode": 91.0, "Q1 loss": 0.17224081656336784, "Q2 loss": 0.1710333578288555, "Mean Target Q": 121.04506224060059, "Mean Q1": 121.04463404846192, "Mean Q2": 121.0445932006836, "critic_loss": 0.34327417448163033, "batch_reward": 1.34207421875, "actor_loss": -121.0970845336914, "actor_target_entropy": -2.0, "actor_entropy": 0.7392459638118744, "alpha_loss": 0.0008159671837929636, "alpha_value": 0.10034481956313857, "duration": 241.97816967964172, "step": 45500}
{"episode_reward": 817.0, "episode": 92.0, "Q1 loss": 0.1640655287504196, "Q2 loss": 0.1650401391685009, "Mean Target Q": 121.68582687377929, "Mean Q1": 121.68533934020996, "Mean Q2": 121.68535298156738, "critic_loss": 0.32910566779971123, "batch_reward": 1.3471796875, "actor_loss": -121.72576483154297, "actor_target_entropy": -2.0, "actor_entropy": 0.7121395280361176, "alpha_loss": -0.0013222192239481956, "alpha_value": 0.10042913086999966, "duration": 241.22842407226562, "step": 46000}
{"episode_reward": 831.0, "episode": 93.0, "Q1 loss": 0.15609118331968785, "Q2 loss": 0.1533938345462084, "Mean Target Q": 122.26630120849609, "Mean Q1": 122.26634242248535, "Mean Q2": 122.2663074798584, "critic_loss": 0.3094850181341171, "batch_reward": 1.34775390625, "actor_loss": -122.32260049438477, "actor_target_entropy": -2.0, "actor_entropy": 0.7216278610229492, "alpha_loss": 0.001523793299216777, "alpha_value": 0.10037393287491193, "duration": 241.1373999118805, "step": 46500}
{"episode_reward": 837.0, "episode": 94.0, "Q1 loss": 0.15202678667008876, "Q2 loss": 0.15106831756234168, "Mean Target Q": 122.85496476745605, "Mean Q1": 122.85466432189942, "Mean Q2": 122.85454330444335, "critic_loss": 0.30309510487318037, "batch_reward": 1.35392578125, "actor_loss": -122.88990838623047, "actor_target_entropy": -2.0, "actor_entropy": 0.7269036259651184, "alpha_loss": 0.0014452260425314308, "alpha_value": 0.09999399652127713, "duration": 241.24361395835876, "step": 47000}
{"episode_reward": 810.0, "episode": 95.0, "Q1 loss": 0.15661897152662277, "Q2 loss": 0.1567642797976732, "Mean Target Q": 123.40391659545898, "Mean Q1": 123.40338911437988, "Mean Q2": 123.40347662353516, "critic_loss": 0.3133832513988018, "batch_reward": 1.35267578125, "actor_loss": -123.42817428588867, "actor_target_entropy": -2.0, "actor_entropy": 0.7383983254432678, "alpha_loss": 0.0017649067994207144, "alpha_value": 0.09978676779960552, "duration": 241.47446608543396, "step": 47500}
{"episode_reward": 813.0, "episode": 96.0, "Q1 loss": 0.1494152693003416, "Q2 loss": 0.14697786498069762, "Mean Target Q": 123.99263223266601, "Mean Q1": 123.99227684020997, "Mean Q2": 123.99254818725586, "critic_loss": 0.29639313438534737, "batch_reward": 1.35978125, "actor_loss": -124.02845248413085, "actor_target_entropy": -2.0, "actor_entropy": 0.7248107273578643, "alpha_loss": 0.0013429343048483133, "alpha_value": 0.09936983102645916, "duration": 241.49350953102112, "step": 48000}
{"episode_reward": 828.0, "episode": 97.0, "Q1 loss": 0.15756135682761668, "Q2 loss": 0.15772721450030805, "Mean Target Q": 124.54271284484864, "Mean Q1": 124.54242112731933, "Mean Q2": 124.54222692871093, "critic_loss": 0.31528857135772703, "batch_reward": 1.3637734375, "actor_loss": -124.55948513793945, "actor_target_entropy": -2.0, "actor_entropy": 0.7369538028240203, "alpha_loss": 0.0015825854004360735, "alpha_value": 0.09913545382402339, "duration": 198.66464352607727, "step": 48500}
{"episode_reward": 836.0, "episode": 98.0, "Q1 loss": 0.1596683078855276, "Q2 loss": 0.15647047679126264, "Mean Target Q": 125.05540547180176, "Mean Q1": 125.05528948974609, "Mean Q2": 125.05534169006347, "critic_loss": 0.3161387843489647, "batch_reward": 1.362796875, "actor_loss": -125.09985626220703, "actor_target_entropy": -2.0, "actor_entropy": 0.727622480392456, "alpha_loss": 0.0013345310008153319, "alpha_value": 0.09875945594146812, "duration": 164.20314955711365, "step": 49000}
{"episode_reward": 834.0, "episode": 99.0, "Q1 loss": 0.13968644545972347, "Q2 loss": 0.1386921902447939, "Mean Target Q": 125.60479110717773, "Mean Q1": 125.60457159423828, "Mean Q2": 125.60445756530761, "critic_loss": 0.2783786356449127, "batch_reward": 1.368265625, "actor_loss": -125.62136520385742, "actor_target_entropy": -2.0, "actor_entropy": 0.7149939410686493, "alpha_loss": -9.92885883897543e-06, "alpha_value": 0.09858594816063243, "duration": 158.73573541641235, "step": 49500}
{"episode_reward": 807.0, "episode": 100.0, "Q1 loss": 0.136033146828413, "Q2 loss": 0.1357996364980936, "Mean Target Q": 126.13280270385742, "Mean Q1": 126.13259284973145, "Mean Q2": 126.13255917358399, "critic_loss": 0.27183278369903563, "batch_reward": 1.3730078125, "actor_loss": -126.13447375488282, "actor_target_entropy": -2.0, "actor_entropy": 0.7167905323505401, "alpha_loss": 0.0013219078090041876, "alpha_value": 0.09851806101707586, "step": 50000}
{"duration": 175.989000082016, "step": 50000}
{"episode_reward": 839.0, "episode": 101.0, "Q1 loss": 0.1493782689422369, "Q2 loss": 0.14542396369576455, "Mean Target Q": 126.63797430419922, "Mean Q1": 126.63754840087891, "Mean Q2": 126.63756416320801, "critic_loss": 0.29480223268270495, "batch_reward": 1.37294140625, "actor_loss": -126.65234335327149, "actor_target_entropy": -2.0, "actor_entropy": 0.7229079511165619, "alpha_loss": 0.0018330122092738747, "alpha_value": 0.09817491530221636, "duration": 160.63128018379211, "step": 50500}
{"episode_reward": 834.0, "episode": 102.0, "Q1 loss": 0.14354033303260802, "Q2 loss": 0.14161917667090893, "Mean Target Q": 127.1439584350586, "Mean Q1": 127.14377923583984, "Mean Q2": 127.14392161560059, "critic_loss": 0.28515950906276705, "batch_reward": 1.3769921875, "actor_loss": -127.1654917602539, "actor_target_entropy": -2.0, "actor_entropy": 0.7128409540653229, "alpha_loss": 0.001640477790031582, "alpha_value": 0.09777395425120847, "duration": 169.6393358707428, "step": 51000}
{"episode_reward": 832.0, "episode": 103.0, "Q1 loss": 0.1498066671192646, "Q2 loss": 0.1490514575392008, "Mean Target Q": 127.63513067626953, "Mean Q1": 127.63490272521973, "Mean Q2": 127.63481362915039, "critic_loss": 0.2988581243753433, "batch_reward": 1.3773125, "actor_loss": -127.65491271972657, "actor_target_entropy": -2.0, "actor_entropy": 0.721208476305008, "alpha_loss": 0.002815026287920773, "alpha_value": 0.09737357287018673, "duration": 166.5428228378296, "step": 51500}
{"episode_reward": 799.0, "episode": 104.0, "Q1 loss": 0.14115315021574498, "Q2 loss": 0.13939096201956272, "Mean Target Q": 128.12182775878907, "Mean Q1": 128.1216064605713, "Mean Q2": 128.12159255981445, "critic_loss": 0.28054411193728446, "batch_reward": 1.385109375, "actor_loss": -128.1484234008789, "actor_target_entropy": -2.0, "actor_entropy": 0.7137902173995971, "alpha_loss": 0.0035205662841908633, "alpha_value": 0.09670693413016976, "duration": 162.47083735466003, "step": 52000}
{"episode_reward": 827.0, "episode": 105.0, "Q1 loss": 0.14893965178728102, "Q2 loss": 0.14735150995850563, "Mean Target Q": 128.59519834899902, "Mean Q1": 128.59488914489745, "Mean Q2": 128.5948847808838, "critic_loss": 0.29629116240143777, "batch_reward": 1.38209765625, "actor_loss": -128.62518057250978, "actor_target_entropy": -2.0, "actor_entropy": 0.7140616915225982, "alpha_loss": 0.0004438226600177586, "alpha_value": 0.09633081600207492, "duration": 159.0594937801361, "step": 52500}
{"episode_reward": 817.0, "episode": 106.0, "Q1 loss": 0.1500680407434702, "Q2 loss": 0.14732861141860484, "Mean Target Q": 129.06862588500977, "Mean Q1": 129.0681389160156, "Mean Q2": 129.06829666137696, "critic_loss": 0.29739665213227273, "batch_reward": 1.388125, "actor_loss": -129.1068159790039, "actor_target_entropy": -2.0, "actor_entropy": 0.7282761707305908, "alpha_loss": 0.0020471067940816285, "alpha_value": 0.09611051506705252, "duration": 158.89397144317627, "step": 53000}
{"episode_reward": 843.0, "episode": 107.0, "Q1 loss": 0.14379532043635845, "Q2 loss": 0.14072019220888615, "Mean Target Q": 129.49418585205078, "Mean Q1": 129.4938009338379, "Mean Q2": 129.49369711303711, "critic_loss": 0.28451551285386084, "batch_reward": 1.3871640625, "actor_loss": -129.52043041992187, "actor_target_entropy": -2.0, "actor_entropy": 0.7175402286052703, "alpha_loss": 0.0016418678010813891, "alpha_value": 0.09570147277919817, "duration": 171.2638783454895, "step": 53500}
{"episode_reward": 834.0, "episode": 108.0, "Q1 loss": 0.13809334038197993, "Q2 loss": 0.13837781953811645, "Mean Target Q": 129.95191256713866, "Mean Q1": 129.95175833129883, "Mean Q2": 129.95161407470704, "critic_loss": 0.27647116032242774, "batch_reward": 1.391890625, "actor_loss": -129.96994439697266, "actor_target_entropy": -2.0, "actor_entropy": 0.7161270091533661, "alpha_loss": 0.0007426254032179713, "alpha_value": 0.09552413374098712, "duration": 160.06737351417542, "step": 54000}
{"episode_reward": 835.0, "episode": 109.0, "Q1 loss": 0.14650944951176642, "Q2 loss": 0.14418711552023888, "Mean Target Q": 130.37850454711915, "Mean Q1": 130.37824481201173, "Mean Q2": 130.3785104675293, "critic_loss": 0.29069656524062154, "batch_reward": 1.3969375, "actor_loss": -130.3697125854492, "actor_target_entropy": -2.0, "actor_entropy": 0.7096645288467407, "alpha_loss": 0.0012001334570813924, "alpha_value": 0.09525577740445916, "duration": 159.26870322227478, "step": 54500}
{"episode_reward": 836.0, "episode": 110.0, "Q1 loss": 0.14321551059186458, "Q2 loss": 0.14079976008832454, "Mean Target Q": 130.8058846435547, "Mean Q1": 130.80566885375976, "Mean Q2": 130.80554974365234, "critic_loss": 0.2840152704715729, "batch_reward": 1.3966328125, "actor_loss": -130.81120837402344, "actor_target_entropy": -2.0, "actor_entropy": 0.7171461689472198, "alpha_loss": -0.00031267449632287026, "alpha_value": 0.09520772732740114, "step": 55000}
{"duration": 177.30478930473328, "step": 55000}
{"episode_reward": 821.0, "episode": 111.0, "Q1 loss": 0.1375736817419529, "Q2 loss": 0.13617922994494439, "Mean Target Q": 131.21692797851563, "Mean Q1": 131.2164891357422, "Mean Q2": 131.2165749206543, "critic_loss": 0.273752911478281, "batch_reward": 1.40075390625, "actor_loss": -131.22160424804687, "actor_target_entropy": -2.0, "actor_entropy": 0.7190171306133271, "alpha_loss": 0.0014589662943035363, "alpha_value": 0.09512955156703448, "duration": 159.55012583732605, "step": 55500}
{"episode_reward": 834.0, "episode": 112.0, "Q1 loss": 0.14049836526811124, "Q2 loss": 0.1394552861750126, "Mean Target Q": 131.62584191894533, "Mean Q1": 131.62591500854492, "Mean Q2": 131.62593426513672, "critic_loss": 0.2799536516666412, "batch_reward": 1.401078125, "actor_loss": -131.62769012451173, "actor_target_entropy": -2.0, "actor_entropy": 0.7175228991508484, "alpha_loss": 0.0026544713615439834, "alpha_value": 0.09469584357307317, "duration": 179.8133623600006, "step": 56000}
{"episode_reward": 829.0, "episode": 113.0, "Q1 loss": 0.14098016752302647, "Q2 loss": 0.14167315708100794, "Mean Target Q": 131.99177523803712, "Mean Q1": 131.99148187255858, "Mean Q2": 131.99145764160156, "critic_loss": 0.28265332451462744, "batch_reward": 1.4021328125, "actor_loss": -131.97814489746094, "actor_target_entropy": -2.0, "actor_entropy": 0.7366268148422241, "alpha_loss": 0.0020764817278832197, "alpha_value": 0.09410748990733198, "duration": 163.69707036018372, "step": 56500}
{"episode_reward": 809.0, "episode": 114.0, "Q1 loss": 0.14267714466154574, "Q2 loss": 0.1399412785768509, "Mean Target Q": 132.38795413208007, "Mean Q1": 132.3877869567871, "Mean Q2": 132.3878157043457, "critic_loss": 0.28261842331290243, "batch_reward": 1.4043515625, "actor_loss": -132.39168432617188, "actor_target_entropy": -2.0, "actor_entropy": 0.717277241230011, "alpha_loss": 0.001302117280429229, "alpha_value": 0.09379732603388323, "duration": 159.3942792415619, "step": 57000}
{"episode_reward": 836.0, "episode": 115.0, "Q1 loss": 0.14599411131441592, "Q2 loss": 0.14201803135871888, "Mean Target Q": 132.74902792358398, "Mean Q1": 132.74876232910157, "Mean Q2": 132.74867105102538, "critic_loss": 0.2880121433436871, "batch_reward": 1.40733984375, "actor_loss": -132.75442083740234, "actor_target_entropy": -2.0, "actor_entropy": 0.7136555924415589, "alpha_loss": 0.0027433043206110596, "alpha_value": 0.09347508098517848, "duration": 160.31604051589966, "step": 57500}
{"episode_reward": 820.0, "episode": 116.0, "Q1 loss": 0.1376005992293358, "Q2 loss": 0.13658215738832952, "Mean Target Q": 133.1415486755371, "Mean Q1": 133.14125991821288, "Mean Q2": 133.14126782226563, "critic_loss": 0.2741827566623688, "batch_reward": 1.4106171875, "actor_loss": -133.13668731689452, "actor_target_entropy": -2.0, "actor_entropy": 0.7212093043327331, "alpha_loss": 0.0024215475274249913, "alpha_value": 0.09292682022085602, "duration": 170.04637575149536, "step": 58000}
{"episode_reward": 843.0, "episode": 117.0, "Q1 loss": 0.1443605883717537, "Q2 loss": 0.14324858282506467, "Mean Target Q": 133.50296987915038, "Mean Q1": 133.50263375854493, "Mean Q2": 133.50264392089844, "critic_loss": 0.2876091711521149, "batch_reward": 1.41045703125, "actor_loss": -133.5087999267578, "actor_target_entropy": -2.0, "actor_entropy": 0.7239431099891662, "alpha_loss": 0.0016162549662403762, "alpha_value": 0.0926142922161184, "duration": 159.67755961418152, "step": 58500}
{"episode_reward": 827.0, "episode": 118.0, "Q1 loss": 0.14681303106248378, "Q2 loss": 0.14148880322277546, "Mean Target Q": 133.87980615234375, "Mean Q1": 133.8795506591797, "Mean Q2": 133.87953778076172, "critic_loss": 0.28830183410644533, "batch_reward": 1.415203125, "actor_loss": -133.8824905395508, "actor_target_entropy": -2.0, "actor_entropy": 0.7261141338348389, "alpha_loss": 0.0029679263001307844, "alpha_value": 0.09203297949621918, "duration": 159.85314297676086, "step": 59000}
{"episode_reward": 810.0, "episode": 119.0, "Q1 loss": 0.1337459796667099, "Q2 loss": 0.1335005879253149, "Mean Target Q": 134.22077764892578, "Mean Q1": 134.2204528503418, "Mean Q2": 134.22038287353516, "critic_loss": 0.2672465680539608, "batch_reward": 1.416421875, "actor_loss": -134.22267138671876, "actor_target_entropy": -2.0, "actor_entropy": 0.7118661410808563, "alpha_loss": 0.0017811384522356092, "alpha_value": 0.09158816346627807, "duration": 159.73841190338135, "step": 59500}
{"episode_reward": 849.0, "episode": 120.0, "Q1 loss": 0.1330505411028862, "Q2 loss": 0.13099647271633147, "Mean Target Q": 134.59544848632814, "Mean Q1": 134.59556723022462, "Mean Q2": 134.59578347778321, "critic_loss": 0.2640470134615898, "batch_reward": 1.42000390625, "actor_loss": -134.59746655273437, "actor_target_entropy": -2.0, "actor_entropy": 0.7084963748455048, "alpha_loss": 0.0028665873003192247, "alpha_value": 0.09104446837389335, "step": 60000}
{"duration": 177.31369304656982, "step": 60000}
{"episode_reward": 826.0, "episode": 121.0, "Q1 loss": 0.13490542532503605, "Q2 loss": 0.13269578851759434, "Mean Target Q": 134.94263174438476, "Mean Q1": 134.9420202026367, "Mean Q2": 134.9419621887207, "critic_loss": 0.26760121378302576, "batch_reward": 1.4210859375, "actor_loss": -134.94320111083985, "actor_target_entropy": -2.0, "actor_entropy": 0.7187405982017517, "alpha_loss": 0.0015346617801114918, "alpha_value": 0.09070002848465498, "duration": 161.35420608520508, "step": 60500}
{"episode_reward": 836.0, "episode": 122.0, "Q1 loss": 0.1361325220912695, "Q2 loss": 0.13630004046857358, "Mean Target Q": 135.27924584960937, "Mean Q1": 135.27918035888672, "Mean Q2": 135.27904089355468, "critic_loss": 0.27243256303668023, "batch_reward": 1.42301171875, "actor_loss": -135.2676072998047, "actor_target_entropy": -2.0, "actor_entropy": 0.7192074470520019, "alpha_loss": 0.0015539312306791543, "alpha_value": 0.09030744525047328, "duration": 161.282235622406, "step": 61000}
{"episode_reward": 837.0, "episode": 123.0, "Q1 loss": 0.12743372282385826, "Q2 loss": 0.12583242858946322, "Mean Target Q": 135.60621932983398, "Mean Q1": 135.6060710144043, "Mean Q2": 135.60621697998047, "critic_loss": 0.2532661514282227, "batch_reward": 1.42147265625, "actor_loss": -135.6014203491211, "actor_target_entropy": -2.0, "actor_entropy": 0.7209740145206451, "alpha_loss": 0.00033445263979956506, "alpha_value": 0.09012116414036747, "duration": 167.75416612625122, "step": 61500}
{"episode_reward": 830.0, "episode": 124.0, "Q1 loss": 0.13140201245248317, "Q2 loss": 0.127870337754488, "Mean Target Q": 135.96771710205078, "Mean Q1": 135.9672731628418, "Mean Q2": 135.9673738708496, "critic_loss": 0.25927235025167467, "batch_reward": 1.42696484375, "actor_loss": -135.95968041992188, "actor_target_entropy": -2.0, "actor_entropy": 0.7144003217220306, "alpha_loss": 0.0015919066944625228, "alpha_value": 0.09003724407448302, "duration": 160.3617296218872, "step": 62000}
{"episode_reward": 837.0, "episode": 125.0, "Q1 loss": 0.12468050320446492, "Q2 loss": 0.12362879192829132, "Mean Target Q": 136.2821172180176, "Mean Q1": 136.28183651733397, "Mean Q2": 136.281712890625, "critic_loss": 0.24830929559469223, "batch_reward": 1.42803515625, "actor_loss": -136.2737783203125, "actor_target_entropy": -2.0, "actor_entropy": 0.7142522940635682, "alpha_loss": 0.003078538317698985, "alpha_value": 0.0896025005387452, "duration": 160.06085014343262, "step": 62500}
{"episode_reward": 839.0, "episode": 126.0, "Q1 loss": 0.12398016637563705, "Q2 loss": 0.12150964784622192, "Mean Target Q": 136.62092193603516, "Mean Q1": 136.62082656860352, "Mean Q2": 136.62081689453126, "critic_loss": 0.24548981398344039, "batch_reward": 1.43257421875, "actor_loss": -136.6056344604492, "actor_target_entropy": -2.0, "actor_entropy": 0.7220671441555023, "alpha_loss": 0.0028583515752106906, "alpha_value": 0.08891431832788058, "duration": 160.35815691947937, "step": 63000}
{"episode_reward": 827.0, "episode": 127.0, "Q1 loss": 0.12662177562713622, "Q2 loss": 0.12513890416920184, "Mean Target Q": 136.9174017944336, "Mean Q1": 136.91701165771485, "Mean Q2": 136.91713146972657, "critic_loss": 0.2517606801390648, "batch_reward": 1.43271875, "actor_loss": -136.93244354248046, "actor_target_entropy": -2.0, "actor_entropy": 0.7079897673130036, "alpha_loss": 0.0016684216146823018, "alpha_value": 0.08856549914537545, "duration": 160.16966366767883, "step": 63500}
{"episode_reward": 816.0, "episode": 128.0, "Q1 loss": 0.12268131957948208, "Q2 loss": 0.12291012944281102, "Mean Target Q": 137.24983682250976, "Mean Q1": 137.24984530639648, "Mean Q2": 137.24972491455077, "critic_loss": 0.2455914490222931, "batch_reward": 1.43578125, "actor_loss": -137.25169091796874, "actor_target_entropy": -2.0, "actor_entropy": 0.7195588965415954, "alpha_loss": 0.0030328255663625895, "alpha_value": 0.08798302303733507, "duration": 162.0014786720276, "step": 64000}
{"episode_reward": 835.0, "episode": 129.0, "Q1 loss": 0.12549497155845166, "Q2 loss": 0.12234226861596108, "Mean Target Q": 137.57143252563478, "Mean Q1": 137.5712914428711, "Mean Q2": 137.5714194946289, "critic_loss": 0.2478372407257557, "batch_reward": 1.43629296875, "actor_loss": -137.55521978759765, "actor_target_entropy": -2.0, "actor_entropy": 0.7209652245044709, "alpha_loss": 0.0023400324932299553, "alpha_value": 0.08749037855760104, "duration": 222.8654465675354, "step": 64500}
{"episode_reward": 843.0, "episode": 130.0, "Q1 loss": 0.12823837538063526, "Q2 loss": 0.126878380343318, "Mean Target Q": 137.8639128417969, "Mean Q1": 137.8637844543457, "Mean Q2": 137.86375817871092, "critic_loss": 0.2551167558431625, "batch_reward": 1.43423828125, "actor_loss": -137.85121075439454, "actor_target_entropy": -2.0, "actor_entropy": 0.7031409084796906, "alpha_loss": -0.0008712570886127651, "alpha_value": 0.08731237402217464, "step": 65000}
{"duration": 250.9241919517517, "step": 65000}
{"episode_reward": 821.0, "episode": 131.0, "Q1 loss": 0.12935889476537704, "Q2 loss": 0.12888791435956956, "Mean Target Q": 138.18787979125977, "Mean Q1": 138.1876442260742, "Mean Q2": 138.18754000854491, "critic_loss": 0.25824680918455123, "batch_reward": 1.4415625, "actor_loss": -138.18691485595704, "actor_target_entropy": -2.0, "actor_entropy": 0.7056531410217285, "alpha_loss": 0.0010330090103670955, "alpha_value": 0.0872950660637195, "duration": 187.89433908462524, "step": 65500}
{"episode_reward": 828.0, "episode": 132.0, "Q1 loss": 0.12941292063891888, "Q2 loss": 0.1281667850315571, "Mean Target Q": 138.43368927001953, "Mean Q1": 138.4335461730957, "Mean Q2": 138.43365118408204, "critic_loss": 0.25757970571517946, "batch_reward": 1.43873046875, "actor_loss": -138.41500854492188, "actor_target_entropy": -2.0, "actor_entropy": 0.732776596069336, "alpha_loss": 0.001922706949757412, "alpha_value": 0.08704947632490016, "duration": 160.51909685134888, "step": 66000}
{"episode_reward": 823.0, "episode": 133.0, "Q1 loss": 0.1238427310436964, "Q2 loss": 0.12207535333931446, "Mean Target Q": 138.7095347595215, "Mean Q1": 138.70898440551758, "Mean Q2": 138.70898617553712, "critic_loss": 0.24591808435320855, "batch_reward": 1.44411328125, "actor_loss": -138.70140594482422, "actor_target_entropy": -2.0, "actor_entropy": 0.708129736661911, "alpha_loss": 0.0017112064147368075, "alpha_value": 0.08659041711718339, "duration": 160.5071256160736, "step": 66500}
{"episode_reward": 828.0, "episode": 134.0, "Q1 loss": 0.12300891509652137, "Q2 loss": 0.12025723610818385, "Mean Target Q": 138.97522003173827, "Mean Q1": 138.97525268554688, "Mean Q2": 138.97534323120118, "critic_loss": 0.24326615130901336, "batch_reward": 1.44334375, "actor_loss": -138.98125006103515, "actor_target_entropy": -2.0, "actor_entropy": 0.7264849359989166, "alpha_loss": 0.00123512411583215, "alpha_value": 0.08638591540553009, "duration": 161.7184739112854, "step": 67000}
{"episode_reward": 832.0, "episode": 135.0, "Q1 loss": 0.12745341911911964, "Q2 loss": 0.1259859940558672, "Mean Target Q": 139.23161587524413, "Mean Q1": 139.2312654724121, "Mean Q2": 139.23108520507813, "critic_loss": 0.2534394134879112, "batch_reward": 1.44769921875, "actor_loss": -139.20978869628905, "actor_target_entropy": -2.0, "actor_entropy": 0.7393950552940368, "alpha_loss": 0.0017652840674854816, "alpha_value": 0.08606672502632225, "duration": 160.01180148124695, "step": 67500}
{"episode_reward": 842.0, "episode": 136.0, "Q1 loss": 0.12245917056500912, "Q2 loss": 0.1179749738574028, "Mean Target Q": 139.5077501525879, "Mean Q1": 139.50761447143555, "Mean Q2": 139.50776217651367, "critic_loss": 0.24043414428830145, "batch_reward": 1.445828125, "actor_loss": -139.50548559570314, "actor_target_entropy": -2.0, "actor_entropy": 0.7222320899963379, "alpha_loss": 0.0023019855038728565, "alpha_value": 0.08567905288056202, "duration": 160.3173577785492, "step": 68000}
{"episode_reward": 826.0, "episode": 137.0, "Q1 loss": 0.1254716358780861, "Q2 loss": 0.12281873528659344, "Mean Target Q": 139.76863549804688, "Mean Q1": 139.7686001586914, "Mean Q2": 139.76856985473634, "critic_loss": 0.2482903710603714, "batch_reward": 1.44812109375, "actor_loss": -139.7548071899414, "actor_target_entropy": -2.0, "actor_entropy": 0.7118336479663849, "alpha_loss": 0.002396705043036491, "alpha_value": 0.08525576045351228, "duration": 160.17692041397095, "step": 68500}
{"episode_reward": 841.0, "episode": 138.0, "Q1 loss": 0.1161993106752634, "Q2 loss": 0.11511406345665455, "Mean Target Q": 140.04032833862306, "Mean Q1": 140.03994567871095, "Mean Q2": 140.0399691772461, "critic_loss": 0.23131337413191796, "batch_reward": 1.45120703125, "actor_loss": -140.0243985595703, "actor_target_entropy": -2.0, "actor_entropy": 0.7296326310634613, "alpha_loss": 0.0019779184551443904, "alpha_value": 0.0848516580255763, "duration": 160.32538843154907, "step": 69000}
{"episode_reward": 839.0, "episode": 139.0, "Q1 loss": 0.11590467700362206, "Q2 loss": 0.11637272197008133, "Mean Target Q": 140.28990371704103, "Mean Q1": 140.28955715942382, "Mean Q2": 140.28965267944335, "critic_loss": 0.232277399122715, "batch_reward": 1.449796875, "actor_loss": -140.27317102050782, "actor_target_entropy": -2.0, "actor_entropy": 0.7337167758941651, "alpha_loss": 0.001967492839321494, "alpha_value": 0.08437198983311402, "duration": 160.1596565246582, "step": 69500}
{"episode_reward": 837.0, "episode": 140.0, "Q1 loss": 0.12665470829606057, "Q2 loss": 0.12657994642853737, "Mean Target Q": 140.55972387695311, "Mean Q1": 140.55948474121095, "Mean Q2": 140.55933432006836, "critic_loss": 0.2532346543073654, "batch_reward": 1.4527109375, "actor_loss": -140.5488623046875, "actor_target_entropy": -2.0, "actor_entropy": 0.720435446023941, "alpha_loss": 0.0005925285215489566, "alpha_value": 0.08411294057020485, "step": 70000}
{"duration": 178.71119260787964, "step": 70000}
{"episode_reward": 846.0, "episode": 141.0, "Q1 loss": 0.12283414299786091, "Q2 loss": 0.11927482150495053, "Mean Target Q": 140.82488159179687, "Mean Q1": 140.8246184692383, "Mean Q2": 140.82471020507813, "critic_loss": 0.24210896468162538, "batch_reward": 1.4559765625, "actor_loss": -140.82000665283203, "actor_target_entropy": -2.0, "actor_entropy": 0.7168823654651642, "alpha_loss": 0.0012731731268577277, "alpha_value": 0.08395080828050787, "duration": 160.7162582874298, "step": 70500}
{"episode_reward": 841.0, "episode": 142.0, "Q1 loss": 0.11420186607539654, "Q2 loss": 0.11391117297112942, "Mean Target Q": 141.05973431396484, "Mean Q1": 141.05980813598632, "Mean Q2": 141.05985482788086, "critic_loss": 0.22811303913593292, "batch_reward": 1.45732421875, "actor_loss": -141.05576263427736, "actor_target_entropy": -2.0, "actor_entropy": 0.7193285999298096, "alpha_loss": 0.0015839500362053514, "alpha_value": 0.08374833943412183, "duration": 160.65688610076904, "step": 71000}
{"episode_reward": 842.0, "episode": 143.0, "Q1 loss": 0.11361120972782374, "Q2 loss": 0.11157451459765434, "Mean Target Q": 141.28711672973634, "Mean Q1": 141.28674658203124, "Mean Q2": 141.2867674560547, "critic_loss": 0.2251857237815857, "batch_reward": 1.4569921875, "actor_loss": -141.27204437255858, "actor_target_entropy": -2.0, "actor_entropy": 0.6984461116790771, "alpha_loss": 0.0013436236646957695, "alpha_value": 0.08339233096355952, "duration": 160.3745937347412, "step": 71500}
{"episode_reward": 841.0, "episode": 144.0, "Q1 loss": 0.11841188797354699, "Q2 loss": 0.11649152836948633, "Mean Target Q": 141.53206451416017, "Mean Q1": 141.5318659362793, "Mean Q2": 141.53183877563475, "critic_loss": 0.234903416544199, "batch_reward": 1.461078125, "actor_loss": -141.51360565185547, "actor_target_entropy": -2.0, "actor_entropy": 0.706916908979416, "alpha_loss": -0.0002672098863404244, "alpha_value": 0.0834024405304726, "duration": 160.4203860759735, "step": 72000}
{"episode_reward": 836.0, "episode": 145.0, "Q1 loss": 0.12169309543073177, "Q2 loss": 0.12018100897967815, "Mean Target Q": 141.75952587890626, "Mean Q1": 141.759403717041, "Mean Q2": 141.759440826416, "critic_loss": 0.2418741048872471, "batch_reward": 1.45992578125, "actor_loss": -141.74674627685548, "actor_target_entropy": -2.0, "actor_entropy": 0.7341866588592529, "alpha_loss": 0.0026898462909739464, "alpha_value": 0.08316792062609384, "duration": 208.31905126571655, "step": 72500}
{"episode_reward": 831.0, "episode": 146.0, "Q1 loss": 0.10667103394120932, "Q2 loss": 0.10306027116626501, "Mean Target Q": 141.99679861450196, "Mean Q1": 141.99662899780273, "Mean Q2": 141.99657482910158, "critic_loss": 0.20973130503296852, "batch_reward": 1.4610859375, "actor_loss": -141.98549993896484, "actor_target_entropy": -2.0, "actor_entropy": 0.6935294318199158, "alpha_loss": -0.0006473420537076891, "alpha_value": 0.08284625561366928, "duration": 231.4228639602661, "step": 73000}
{"episode_reward": 839.0, "episode": 147.0, "Q1 loss": 0.11349419114738703, "Q2 loss": 0.11315527076274157, "Mean Target Q": 142.22948370361328, "Mean Q1": 142.2292780456543, "Mean Q2": 142.2293406677246, "critic_loss": 0.22664946219325066, "batch_reward": 1.46452734375, "actor_loss": -142.21471228027343, "actor_target_entropy": -2.0, "actor_entropy": 0.7179762926101685, "alpha_loss": 0.00017173128365539014, "alpha_value": 0.08299348418929929, "duration": 262.2460639476776, "step": 73500}
{"episode_reward": 827.0, "episode": 148.0, "Q1 loss": 0.11342154423892498, "Q2 loss": 0.1119083155542612, "Mean Target Q": 142.43150939941407, "Mean Q1": 142.43124551391602, "Mean Q2": 142.43129888916016, "critic_loss": 0.22532986009120942, "batch_reward": 1.46680078125, "actor_loss": -142.40929644775392, "actor_target_entropy": -2.0, "actor_entropy": 0.712689698934555, "alpha_loss": 0.001515194700565189, "alpha_value": 0.08282089309783071, "duration": 235.2851207256317, "step": 74000}
{"episode_reward": 816.0, "episode": 149.0, "Q1 loss": 0.12203142384439707, "Q2 loss": 0.11998689368367195, "Mean Target Q": 142.64050778198242, "Mean Q1": 142.6402424621582, "Mean Q2": 142.64012338256836, "critic_loss": 0.24201831731200218, "batch_reward": 1.4677109375, "actor_loss": -142.61646691894532, "actor_target_entropy": -2.0, "actor_entropy": 0.7168053126335144, "alpha_loss": 0.001153538045939058, "alpha_value": 0.08251894916116655, "duration": 238.55841660499573, "step": 74500}
{"episode_reward": 817.0, "episode": 150.0, "Q1 loss": 0.11657704099267721, "Q2 loss": 0.11404208782315255, "Mean Target Q": 142.82294815063477, "Mean Q1": 142.8227780761719, "Mean Q2": 142.82279733276368, "critic_loss": 0.23061912852525712, "batch_reward": 1.4671875, "actor_loss": -142.80231628417968, "actor_target_entropy": -2.0, "actor_entropy": 0.7075794816017151, "alpha_loss": 0.001513030676636845, "alpha_value": 0.08223817165826454, "step": 75000}
{"duration": 189.71086740493774, "step": 75000}
{"episode_reward": 829.0, "episode": 151.0, "Q1 loss": 0.11442497886717319, "Q2 loss": 0.1132178322672844, "Mean Target Q": 143.02005368041992, "Mean Q1": 143.02005197143555, "Mean Q2": 143.02001632690428, "critic_loss": 0.227642811357975, "batch_reward": 1.46842578125, "actor_loss": -143.00619451904296, "actor_target_entropy": -2.0, "actor_entropy": 0.7184969284534455, "alpha_loss": 0.0026234908984042703, "alpha_value": 0.08188768817879706, "duration": 174.19695115089417, "step": 75500}
{"episode_reward": 847.0, "episode": 152.0, "Q1 loss": 0.11326089721173048, "Q2 loss": 0.11208829867839813, "Mean Target Q": 143.21689401245118, "Mean Q1": 143.2167138977051, "Mean Q2": 143.21673764038087, "critic_loss": 0.22534919622540475, "batch_reward": 1.4690546875, "actor_loss": -143.19706579589842, "actor_target_entropy": -2.0, "actor_entropy": 0.7059522275924682, "alpha_loss": 0.0022789782430045306, "alpha_value": 0.08140014262479815, "duration": 294.39442443847656, "step": 76000}
{"episode_reward": 830.0, "episode": 153.0, "Q1 loss": 0.11638955755531788, "Q2 loss": 0.11617375740408897, "Mean Target Q": 143.41496423339845, "Mean Q1": 143.41470013427735, "Mean Q2": 143.41472619628905, "critic_loss": 0.2325633152425289, "batch_reward": 1.46816015625, "actor_loss": -143.40655139160157, "actor_target_entropy": -2.0, "actor_entropy": 0.7102430737018586, "alpha_loss": -7.924093282781542e-05, "alpha_value": 0.08116704419901687, "duration": 366.71095085144043, "step": 76500}
{"episode_reward": 833.0, "episode": 154.0, "Q1 loss": 0.11288571258634329, "Q2 loss": 0.11127218933403492, "Mean Target Q": 143.62943759155274, "Mean Q1": 143.62942694091797, "Mean Q2": 143.62942178344727, "critic_loss": 0.22415790267288685, "batch_reward": 1.4729453125, "actor_loss": -143.6036862182617, "actor_target_entropy": -2.0, "actor_entropy": 0.7091931779384613, "alpha_loss": 0.0003597092517884448, "alpha_value": 0.08120688895009995, "duration": 249.2714695930481, "step": 77000}
{"episode_reward": 841.0, "episode": 155.0, "Q1 loss": 0.12457039132714272, "Q2 loss": 0.12264872771501541, "Mean Target Q": 143.83887533569336, "Mean Q1": 143.8385343322754, "Mean Q2": 143.83871588134767, "critic_loss": 0.2472191185504198, "batch_reward": 1.47661328125, "actor_loss": -143.83509692382813, "actor_target_entropy": -2.0, "actor_entropy": 0.7128321490287781, "alpha_loss": 0.0021834252807311715, "alpha_value": 0.08094543990899111, "duration": 160.7495527267456, "step": 77500}
{"episode_reward": 829.0, "episode": 156.0, "Q1 loss": 0.10943676552921533, "Q2 loss": 0.10832240860164165, "Mean Target Q": 144.03862579345704, "Mean Q1": 144.0385223083496, "Mean Q2": 144.03837271118164, "critic_loss": 0.21775917455554009, "batch_reward": 1.4753515625, "actor_loss": -144.02940002441406, "actor_target_entropy": -2.0, "actor_entropy": 0.7242268245220185, "alpha_loss": 0.002337248456897214, "alpha_value": 0.08055988087617173, "duration": 161.10056805610657, "step": 78000}
{"episode_reward": 830.0, "episode": 157.0, "Q1 loss": 0.11398368694633246, "Q2 loss": 0.11234603645652533, "Mean Target Q": 144.22718814086915, "Mean Q1": 144.22710430908202, "Mean Q2": 144.2272113342285, "critic_loss": 0.22632972356677056, "batch_reward": 1.47779296875, "actor_loss": -144.20798522949218, "actor_target_entropy": -2.0, "actor_entropy": 0.6935381088256836, "alpha_loss": 0.0013312481297180056, "alpha_value": 0.08016182637236687, "duration": 160.1703600883484, "step": 78500}
{"episode_reward": 833.0, "episode": 158.0, "Q1 loss": 0.12500339597463608, "Q2 loss": 0.12591586096584798, "Mean Target Q": 144.43042208862306, "Mean Q1": 144.4299620666504, "Mean Q2": 144.42982064819336, "critic_loss": 0.2509192578494549, "batch_reward": 1.47916015625, "actor_loss": -144.41411724853515, "actor_target_entropy": -2.0, "actor_entropy": 0.7035715769529343, "alpha_loss": 0.002344876563176513, "alpha_value": 0.07976825568828598, "duration": 160.92449498176575, "step": 79000}
{"episode_reward": 817.0, "episode": 159.0, "Q1 loss": 0.11070963074266911, "Q2 loss": 0.10796042088419198, "Mean Target Q": 144.5962178955078, "Mean Q1": 144.59628228759766, "Mean Q2": 144.5962830505371, "critic_loss": 0.21867005127668382, "batch_reward": 1.48013671875, "actor_loss": -144.55500561523436, "actor_target_entropy": -2.0, "actor_entropy": 0.7052139780521393, "alpha_loss": 0.0013310326156206428, "alpha_value": 0.07935828885281516, "duration": 160.99467968940735, "step": 79500}
{"episode_reward": 821.0, "episode": 160.0, "Q1 loss": 0.10811085026711226, "Q2 loss": 0.10679935944080353, "Mean Target Q": 144.75712057495116, "Mean Q1": 144.75699545288086, "Mean Q2": 144.75715390014648, "critic_loss": 0.21491020968556404, "batch_reward": 1.47791796875, "actor_loss": -144.7297826538086, "actor_target_entropy": -2.0, "actor_entropy": 0.6880295094251633, "alpha_loss": 0.0005574432606808841, "alpha_value": 0.07916888028190905, "step": 80000}
{"duration": 188.50724458694458, "step": 80000}
{"episode_reward": 838.0, "episode": 161.0, "Q1 loss": 0.1125998530164361, "Q2 loss": 0.11123330634087324, "Mean Target Q": 144.94977255249023, "Mean Q1": 144.94948306274415, "Mean Q2": 144.94947961425783, "critic_loss": 0.22383315959572792, "batch_reward": 1.48338671875, "actor_loss": -144.9343857421875, "actor_target_entropy": -2.0, "actor_entropy": 0.7006694352626801, "alpha_loss": 0.0008075596587732434, "alpha_value": 0.07917289753995228, "duration": 161.61909818649292, "step": 80500}
{"episode_reward": 826.0, "episode": 162.0, "Q1 loss": 0.11871226534247398, "Q2 loss": 0.11734608118236065, "Mean Target Q": 145.10085482788085, "Mean Q1": 145.10069546508788, "Mean Q2": 145.1006287841797, "critic_loss": 0.23605834662914277, "batch_reward": 1.48191796875, "actor_loss": -145.06354840087891, "actor_target_entropy": -2.0, "actor_entropy": 0.7096202740669251, "alpha_loss": 0.001498859155923128, "alpha_value": 0.07889121557894059, "duration": 161.52904891967773, "step": 81000}
{"episode_reward": 842.0, "episode": 163.0, "Q1 loss": 0.11043926887959242, "Q2 loss": 0.1100812592804432, "Mean Target Q": 145.25034368896485, "Mean Q1": 145.24999963378906, "Mean Q2": 145.24992877197266, "critic_loss": 0.22052052825689317, "batch_reward": 1.48285546875, "actor_loss": -145.22162255859374, "actor_target_entropy": -2.0, "actor_entropy": 0.7057032747268677, "alpha_loss": 0.00211299551371485, "alpha_value": 0.0785397610865839, "duration": 176.81092643737793, "step": 81500}
{"episode_reward": 842.0, "episode": 164.0, "Q1 loss": 0.11294531458616257, "Q2 loss": 0.11029936998337507, "Mean Target Q": 145.4461655883789, "Mean Q1": 145.4460928955078, "Mean Q2": 145.4463196411133, "critic_loss": 0.22324468488991261, "batch_reward": 1.48796484375, "actor_loss": -145.42993566894532, "actor_target_entropy": -2.0, "actor_entropy": 0.7075912921428681, "alpha_loss": 0.0008038213185500353, "alpha_value": 0.0782375017930017, "duration": 161.89859461784363, "step": 82000}
{"episode_reward": 842.0, "episode": 165.0, "Q1 loss": 0.10363701802492142, "Q2 loss": 0.10280269788950681, "Mean Target Q": 145.6250205383301, "Mean Q1": 145.62498922729492, "Mean Q2": 145.62489291381837, "critic_loss": 0.2064397160410881, "batch_reward": 1.48553125, "actor_loss": -145.61427490234374, "actor_target_entropy": -2.0, "actor_entropy": 0.6920368535518646, "alpha_loss": 0.0008616728237830103, "alpha_value": 0.07801519014588544, "duration": 161.0687484741211, "step": 82500}
{"episode_reward": 816.0, "episode": 166.0, "Q1 loss": 0.10780718593299389, "Q2 loss": 0.10655177412927151, "Mean Target Q": 145.78535342407227, "Mean Q1": 145.7849970703125, "Mean Q2": 145.78504544067383, "critic_loss": 0.2143589601069689, "batch_reward": 1.485625, "actor_loss": -145.75991436767578, "actor_target_entropy": -2.0, "actor_entropy": 0.6624724454879761, "alpha_loss": 0.0004879014841280878, "alpha_value": 0.07792204156222572, "duration": 162.10943579673767, "step": 83000}
{"episode_reward": 826.0, "episode": 167.0, "Q1 loss": 0.11238385078310967, "Q2 loss": 0.11156802540272474, "Mean Target Q": 145.94323413085937, "Mean Q1": 145.9432453918457, "Mean Q2": 145.9431730041504, "critic_loss": 0.22395187641680242, "batch_reward": 1.48628515625, "actor_loss": -145.93719464111328, "actor_target_entropy": -2.0, "actor_entropy": 0.6946414847373963, "alpha_loss": 0.0018961584405042232, "alpha_value": 0.0777824260923798, "duration": 218.59229230880737, "step": 83500}
{"episode_reward": 834.0, "episode": 168.0, "Q1 loss": 0.10950872545689344, "Q2 loss": 0.10545146742463112, "Mean Target Q": 146.12367257690428, "Mean Q1": 146.1234237060547, "Mean Q2": 146.12348245239258, "critic_loss": 0.21496019238233566, "batch_reward": 1.49022265625, "actor_loss": -146.09214434814453, "actor_target_entropy": -2.0, "actor_entropy": 0.6959762487411499, "alpha_loss": 0.0007829594253562391, "alpha_value": 0.07743992142017765, "duration": 246.73558497428894, "step": 84000}
{"episode_reward": 828.0, "episode": 169.0, "Q1 loss": 0.10445706959068775, "Q2 loss": 0.10324468499422074, "Mean Target Q": 146.26303436279298, "Mean Q1": 146.2628465576172, "Mean Q2": 146.2628879699707, "critic_loss": 0.2077017545849085, "batch_reward": 1.489859375, "actor_loss": -146.24486608886718, "actor_target_entropy": -2.0, "actor_entropy": 0.6898562731742859, "alpha_loss": 0.0015406152347568422, "alpha_value": 0.07724116936669409, "duration": 201.62553596496582, "step": 84500}
{"episode_reward": 827.0, "episode": 170.0, "Q1 loss": 0.10761975589394569, "Q2 loss": 0.10470809575170278, "Mean Target Q": 146.4151725463867, "Mean Q1": 146.41501043701172, "Mean Q2": 146.41510647583007, "critic_loss": 0.21232785177230834, "batch_reward": 1.491890625, "actor_loss": -146.39500958251952, "actor_target_entropy": -2.0, "actor_entropy": 0.6804397249221802, "alpha_loss": 0.0003370261015370488, "alpha_value": 0.0770397175859414, "step": 85000}
{"duration": 178.16216397285461, "step": 85000}
{"episode_reward": 830.0, "episode": 171.0, "Q1 loss": 0.0967977338656783, "Q2 loss": 0.09850028263032437, "Mean Target Q": 146.57795489501953, "Mean Q1": 146.5778642578125, "Mean Q2": 146.57791275024414, "critic_loss": 0.19529801632463933, "batch_reward": 1.49403125, "actor_loss": -146.56427362060546, "actor_target_entropy": -2.0, "actor_entropy": 0.675298336982727, "alpha_loss": 3.883537673391402e-05, "alpha_value": 0.07701033965230264, "duration": 162.12769627571106, "step": 85500}
{"episode_reward": 843.0, "episode": 172.0, "Q1 loss": 0.11231647848337889, "Q2 loss": 0.10913962090760469, "Mean Target Q": 146.70923614501953, "Mean Q1": 146.70899597167968, "Mean Q2": 146.70893328857423, "critic_loss": 0.22145609930157661, "batch_reward": 1.49409375, "actor_loss": -146.67414672851564, "actor_target_entropy": -2.0, "actor_entropy": 0.6867800920009614, "alpha_loss": 0.0001962316120043397, "alpha_value": 0.0769813183234363, "duration": 161.29824137687683, "step": 86000}
{"episode_reward": 843.0, "episode": 173.0, "Q1 loss": 0.10965305269509554, "Q2 loss": 0.1069936899766326, "Mean Target Q": 146.8498455505371, "Mean Q1": 146.84967544555664, "Mean Q2": 146.84975225830078, "critic_loss": 0.21664674298465253, "batch_reward": 1.49623828125, "actor_loss": -146.816357421875, "actor_target_entropy": -2.0, "actor_entropy": 0.675856954574585, "alpha_loss": 0.0007626667150761932, "alpha_value": 0.07685758641581421, "duration": 333.8106846809387, "step": 86500}
{"episode_reward": 830.0, "episode": 174.0, "Q1 loss": 0.10353351324051618, "Q2 loss": 0.10223033994436265, "Mean Target Q": 146.9729040222168, "Mean Q1": 146.9730108947754, "Mean Q2": 146.9727478942871, "critic_loss": 0.205763853341341, "batch_reward": 1.49494921875, "actor_loss": -146.95220513916016, "actor_target_entropy": -2.0, "actor_entropy": 0.6894609779119492, "alpha_loss": 0.0011319857640191913, "alpha_value": 0.0766876622996394, "duration": 351.18785643577576, "step": 87000}
{"episode_reward": 835.0, "episode": 175.0, "Q1 loss": 0.10031573974341154, "Q2 loss": 0.09964694261550903, "Mean Target Q": 147.14163543701173, "Mean Q1": 147.14112509155274, "Mean Q2": 147.14129162597655, "critic_loss": 0.1999626825004816, "batch_reward": 1.499390625, "actor_loss": -147.13246740722656, "actor_target_entropy": -2.0, "actor_entropy": 0.6927351512908936, "alpha_loss": 0.0019412530562840401, "alpha_value": 0.07642047689180878, "duration": 177.42538690567017, "step": 87500}
{"episode_reward": 831.0, "episode": 176.0, "Q1 loss": 0.10160676675289869, "Q2 loss": 0.09965640552341938, "Mean Target Q": 147.28230297851562, "Mean Q1": 147.28228298950197, "Mean Q2": 147.28214352416992, "critic_loss": 0.2012631721198559, "batch_reward": 1.50109375, "actor_loss": -147.2613441772461, "actor_target_entropy": -2.0, "actor_entropy": 0.7042319242954254, "alpha_loss": 0.0019367454105522484, "alpha_value": 0.0760067779697712, "duration": 161.5668330192566, "step": 88000}
{"episode_reward": 837.0, "episode": 177.0, "Q1 loss": 0.10355994326621294, "Q2 loss": 0.10172614230960607, "Mean Target Q": 147.40124508666992, "Mean Q1": 147.4012059020996, "Mean Q2": 147.40141983032225, "critic_loss": 0.2052860858142376, "batch_reward": 1.4945546875, "actor_loss": -147.38971270751952, "actor_target_entropy": -2.0, "actor_entropy": 0.6988154013156891, "alpha_loss": 0.0010264130802825093, "alpha_value": 0.07570093697482642, "duration": 161.545884847641, "step": 88500}
{"episode_reward": 841.0, "episode": 178.0, "Q1 loss": 0.10627681225538253, "Q2 loss": 0.10411580850183964, "Mean Target Q": 147.54894442749023, "Mean Q1": 147.54835763549804, "Mean Q2": 147.5482875366211, "critic_loss": 0.21039262075722218, "batch_reward": 1.49976953125, "actor_loss": -147.52469635009766, "actor_target_entropy": -2.0, "actor_entropy": 0.699462354183197, "alpha_loss": 0.0015683470820076764, "alpha_value": 0.07544700864437694, "duration": 161.73203420639038, "step": 89000}
{"episode_reward": 825.0, "episode": 179.0, "Q1 loss": 0.10323579681664705, "Q2 loss": 0.10153036182373762, "Mean Target Q": 147.68301263427733, "Mean Q1": 147.68332720947265, "Mean Q2": 147.68333407592775, "critic_loss": 0.20476615849137306, "batch_reward": 1.5001484375, "actor_loss": -147.6547032470703, "actor_target_entropy": -2.0, "actor_entropy": 0.6835513777732849, "alpha_loss": 0.0022736317715607583, "alpha_value": 0.0750596522098115, "duration": 162.69148063659668, "step": 89500}
{"episode_reward": 841.0, "episode": 180.0, "Q1 loss": 0.09610762681812048, "Q2 loss": 0.09600568678230047, "Mean Target Q": 147.81196612548828, "Mean Q1": 147.81162521362305, "Mean Q2": 147.81172915649415, "critic_loss": 0.19211331328749656, "batch_reward": 1.5016328125, "actor_loss": -147.78090893554688, "actor_target_entropy": -2.0, "actor_entropy": 0.6951665593385696, "alpha_loss": 0.0004635843150317669, "alpha_value": 0.07479275836772374, "step": 90000}
{"duration": 179.07192587852478, "step": 90000}
{"episode_reward": 832.0, "episode": 181.0, "Q1 loss": 0.10278438820689917, "Q2 loss": 0.09982145883888006, "Mean Target Q": 147.94073568725585, "Mean Q1": 147.9408843383789, "Mean Q2": 147.94062997436524, "critic_loss": 0.20260584719479083, "batch_reward": 1.50179296875, "actor_loss": -147.91593811035156, "actor_target_entropy": -2.0, "actor_entropy": 0.6981755840778351, "alpha_loss": -0.00033510027290321886, "alpha_value": 0.07481925843469492, "duration": 163.29434609413147, "step": 90500}
{"episode_reward": 845.0, "episode": 182.0, "Q1 loss": 0.09872696888446808, "Q2 loss": 0.09930259735882283, "Mean Target Q": 148.05810287475586, "Mean Q1": 148.05754638671874, "Mean Q2": 148.05767175292968, "critic_loss": 0.1980295663177967, "batch_reward": 1.49947265625, "actor_loss": -148.0307689819336, "actor_target_entropy": -2.0, "actor_entropy": 0.699568439245224, "alpha_loss": 0.0015848318894859403, "alpha_value": 0.07463503928839516, "duration": 161.7979154586792, "step": 91000}
{"episode_reward": 823.0, "episode": 183.0, "Q1 loss": 0.09693936246633529, "Q2 loss": 0.09451593340188265, "Mean Target Q": 148.23098532104493, "Mean Q1": 148.2312204284668, "Mean Q2": 148.2312894897461, "critic_loss": 0.19145529541373252, "batch_reward": 1.5084140625, "actor_loss": -148.20245434570313, "actor_target_entropy": -2.0, "actor_entropy": 0.6710971089601516, "alpha_loss": 0.002657147930935025, "alpha_value": 0.07425516462934899, "duration": 161.8295338153839, "step": 91500}
{"episode_reward": 843.0, "episode": 184.0, "Q1 loss": 0.10658562465012074, "Q2 loss": 0.10476519323885441, "Mean Target Q": 148.3448603515625, "Mean Q1": 148.34458996582032, "Mean Q2": 148.34453723144532, "critic_loss": 0.21135081757605076, "batch_reward": 1.50766796875, "actor_loss": -148.31747448730468, "actor_target_entropy": -2.0, "actor_entropy": 0.6860740232467651, "alpha_loss": 0.002062567007727921, "alpha_value": 0.07377598148702944, "duration": 161.85402536392212, "step": 92000}
{"episode_reward": 832.0, "episode": 185.0, "Q1 loss": 0.11243429182469845, "Q2 loss": 0.11103757688403129, "Mean Target Q": 148.46918911743165, "Mean Q1": 148.46882104492187, "Mean Q2": 148.46887527465822, "critic_loss": 0.22347186875343322, "batch_reward": 1.5070546875, "actor_loss": -148.43919213867187, "actor_target_entropy": -2.0, "actor_entropy": 0.7025678312778473, "alpha_loss": 0.0023502219908405095, "alpha_value": 0.07334892777338524, "duration": 161.8553442955017, "step": 92500}
{"episode_reward": 822.0, "episode": 186.0, "Q1 loss": 0.09643791238218546, "Q2 loss": 0.09525793738663196, "Mean Target Q": 148.58917263793944, "Mean Q1": 148.5890712890625, "Mean Q2": 148.58911660766603, "critic_loss": 0.1916958495080471, "batch_reward": 1.50869921875, "actor_loss": -148.55554229736327, "actor_target_entropy": -2.0, "actor_entropy": 0.7013575241565705, "alpha_loss": 0.0012607942218892277, "alpha_value": 0.07300267090946412, "duration": 163.2156822681427, "step": 93000}
{"episode_reward": 842.0, "episode": 187.0, "Q1 loss": 0.08877474834769965, "Q2 loss": 0.08749115604907275, "Mean Target Q": 148.71156823730468, "Mean Q1": 148.71156008911132, "Mean Q2": 148.711551361084, "critic_loss": 0.1762659045904875, "batch_reward": 1.5073828125, "actor_loss": -148.68454772949218, "actor_target_entropy": -2.0, "actor_entropy": 0.6765803190469741, "alpha_loss": 0.000190564259653911, "alpha_value": 0.07286726495045294, "duration": 162.59445071220398, "step": 93500}
{"episode_reward": 844.0, "episode": 188.0, "Q1 loss": 0.09574918008595705, "Q2 loss": 0.09482853800058365, "Mean Target Q": 148.8562553100586, "Mean Q1": 148.85596493530272, "Mean Q2": 148.85603234863282, "critic_loss": 0.1905777181982994, "batch_reward": 1.510046875, "actor_loss": -148.83065020751954, "actor_target_entropy": -2.0, "actor_entropy": 0.6856699011325836, "alpha_loss": 0.0010617055918555707, "alpha_value": 0.07275364453159504, "duration": 161.9739546775818, "step": 94000}
{"episode_reward": 842.0, "episode": 189.0, "Q1 loss": 0.09925328603386879, "Q2 loss": 0.09677550761401653, "Mean Target Q": 148.9784299621582, "Mean Q1": 148.97854272460938, "Mean Q2": 148.97843759155273, "critic_loss": 0.19602879367768763, "batch_reward": 1.50901171875, "actor_loss": -148.94653161621093, "actor_target_entropy": -2.0, "actor_entropy": 0.6902847447395325, "alpha_loss": 0.002050645320676267, "alpha_value": 0.07237444301064123, "duration": 162.20610189437866, "step": 94500}
{"episode_reward": 833.0, "episode": 190.0, "Q1 loss": 0.09425374548882245, "Q2 loss": 0.09476527462899685, "Mean Target Q": 149.0913899536133, "Mean Q1": 149.09108737182618, "Mean Q2": 149.09123776245116, "critic_loss": 0.18901901982724667, "batch_reward": 1.51051171875, "actor_loss": -149.06385388183594, "actor_target_entropy": -2.0, "actor_entropy": 0.6987282333374023, "alpha_loss": 0.002477776094106957, "alpha_value": 0.07194030164011411, "step": 95000}
{"duration": 178.61152482032776, "step": 95000}
{"episode_reward": 799.0, "episode": 191.0, "Q1 loss": 0.09270453299582004, "Q2 loss": 0.09173524599522352, "Mean Target Q": 149.22366424560548, "Mean Q1": 149.22314575195313, "Mean Q2": 149.22303744506837, "critic_loss": 0.1844397794008255, "batch_reward": 1.512015625, "actor_loss": -149.21339434814453, "actor_target_entropy": -2.0, "actor_entropy": 0.690517790555954, "alpha_loss": 0.0011252531819045545, "alpha_value": 0.07157019594563953, "duration": 162.27660155296326, "step": 95500}
{"episode_reward": 838.0, "episode": 192.0, "Q1 loss": 0.09475965041667223, "Q2 loss": 0.09334208186715841, "Mean Target Q": 149.32909494018554, "Mean Q1": 149.32950479125978, "Mean Q2": 149.32935568237303, "critic_loss": 0.18810173223912716, "batch_reward": 1.51436328125, "actor_loss": -149.29801782226562, "actor_target_entropy": -2.0, "actor_entropy": 0.6844622621536255, "alpha_loss": 0.001780885606771335, "alpha_value": 0.07132500582998375, "duration": 163.34791827201843, "step": 96000}
{"episode_reward": 837.0, "episode": 193.0, "Q1 loss": 0.09686848054081201, "Q2 loss": 0.09700431056320667, "Mean Target Q": 149.44515466308593, "Mean Q1": 149.44483233642578, "Mean Q2": 149.44488958740234, "critic_loss": 0.19387279142439365, "batch_reward": 1.5136796875, "actor_loss": -149.42050982666015, "actor_target_entropy": -2.0, "actor_entropy": 0.6965062756538392, "alpha_loss": 0.001128551871050149, "alpha_value": 0.07101965687972031, "duration": 162.74489617347717, "step": 96500}
{"episode_reward": 837.0, "episode": 194.0, "Q1 loss": 0.09713641135394573, "Q2 loss": 0.09664250207692385, "Mean Target Q": 149.5617484741211, "Mean Q1": 149.56151275634767, "Mean Q2": 149.56152645874025, "critic_loss": 0.19377891337871553, "batch_reward": 1.51309375, "actor_loss": -149.51911938476562, "actor_target_entropy": -2.0, "actor_entropy": 0.6984217875003814, "alpha_loss": 0.0026047733835875986, "alpha_value": 0.07066295547536984, "duration": 162.22078108787537, "step": 97000}
{"episode_reward": 816.0, "episode": 195.0, "Q1 loss": 0.0928274353146553, "Q2 loss": 0.0902475645467639, "Mean Target Q": 149.66739306640625, "Mean Q1": 149.667361328125, "Mean Q2": 149.6674338684082, "critic_loss": 0.18307499992847442, "batch_reward": 1.512984375, "actor_loss": -149.63397357177735, "actor_target_entropy": -2.0, "actor_entropy": 0.6902086181640625, "alpha_loss": 0.0019090390964411198, "alpha_value": 0.07020220987983251, "duration": 162.19797468185425, "step": 97500}
{"episode_reward": 837.0, "episode": 196.0, "Q1 loss": 0.0967858252003789, "Q2 loss": 0.0946678254827857, "Mean Target Q": 149.76629956054688, "Mean Q1": 149.7661481628418, "Mean Q2": 149.7660164489746, "critic_loss": 0.19145365083217622, "batch_reward": 1.51178125, "actor_loss": -149.72206365966798, "actor_target_entropy": -2.0, "actor_entropy": 0.6868512120246887, "alpha_loss": 0.0008020591891836375, "alpha_value": 0.0699526777850345, "duration": 162.2181191444397, "step": 98000}
{"episode_reward": 832.0, "episode": 197.0, "Q1 loss": 0.09573349630087614, "Q2 loss": 0.09450163504481315, "Mean Target Q": 149.87271130371093, "Mean Q1": 149.87292932128906, "Mean Q2": 149.87291076660156, "critic_loss": 0.19023513139784337, "batch_reward": 1.51485546875, "actor_loss": -149.833736328125, "actor_target_entropy": -2.0, "actor_entropy": 0.686631707906723, "alpha_loss": 0.0018757853934075683, "alpha_value": 0.06969296909787762, "duration": 162.50987601280212, "step": 98500}
{"episode_reward": 837.0, "episode": 198.0, "Q1 loss": 0.08808332172781229, "Q2 loss": 0.08754034924507141, "Mean Target Q": 149.97304718017577, "Mean Q1": 149.97246520996094, "Mean Q2": 149.97255865478516, "critic_loss": 0.17562367056310177, "batch_reward": 1.5151171875, "actor_loss": -149.95311328125, "actor_target_entropy": -2.0, "actor_entropy": 0.6899879131317138, "alpha_loss": 0.0004222348260227591, "alpha_value": 0.06939370759845004, "duration": 162.89823508262634, "step": 99000}
{"episode_reward": 838.0, "episode": 199.0, "Q1 loss": 0.08959581661224365, "Q2 loss": 0.08859549586474895, "Mean Target Q": 150.08649212646483, "Mean Q1": 150.08639990234374, "Mean Q2": 150.08658181762695, "critic_loss": 0.1781913126260042, "batch_reward": 1.5179453125, "actor_loss": -150.0529227294922, "actor_target_entropy": -2.0, "actor_entropy": 0.6917948708534241, "alpha_loss": 0.000206003294326365, "alpha_value": 0.06941041144447256, "duration": 163.22553491592407, "step": 99500}
{"episode_reward": 835.0, "episode": 200.0, "Q1 loss": 0.08838702644966169, "Q2 loss": 0.0876595161347566, "Mean Target Q": 150.1734558288941, "Mean Q1": 150.1732822028334, "Mean Q2": 150.17324563066563, "critic_loss": 0.17604654274865955, "batch_reward": 1.515863758767535, "actor_loss": -150.14828637695314, "actor_target_entropy": -2.0, "actor_entropy": 0.6941062097549439, "alpha_loss": 0.0013749490503687412, "alpha_value": 0.06919535364116294, "step": 99999}
