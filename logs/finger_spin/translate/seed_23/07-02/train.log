{"episode_reward": 0.0, "episode": 1.0, "duration": 37.1664559841156, "step": 500}
{"episode_reward": 3.0, "episode": 2.0, "duration": 1.2626867294311523, "step": 1000}
{"episode_reward": 11.0, "episode": 3.0, "batch_reward": 0.01107421875, "critic_loss": 0.06418418550933712, "actor_loss": -0.15909295754879713, "actor_target_entropy": -2.0, "actor_entropy": 2.5251792783737184, "alpha_loss": 0.3217965438365936, "alpha_value": 0.09877077589020054, "duration": 152.43513441085815, "step": 1500}
{"episode_reward": 0.0, "episode": 4.0, "batch_reward": 0.00969921875, "critic_loss": 0.03576397565938532, "actor_loss": -0.5026524603366852, "actor_target_entropy": -2.0, "actor_entropy": 2.5921466093063357, "alpha_loss": 0.31385881948471067, "alpha_value": 0.0963445995077662, "duration": 152.61539149284363, "step": 2000}
{"episode_reward": 8.0, "episode": 5.0, "batch_reward": 0.014125, "critic_loss": 0.07340318208560348, "actor_loss": -0.7971405415534973, "actor_target_entropy": -2.0, "actor_entropy": 2.6132427501678466, "alpha_loss": 0.29554595065116884, "alpha_value": 0.09407779061256281, "duration": 152.80618000030518, "step": 2500}
{"episode_reward": 20.0, "episode": 6.0, "batch_reward": 0.02023828125, "critic_loss": 0.10418411902338266, "actor_loss": -1.1716194756031035, "actor_target_entropy": -2.0, "actor_entropy": 2.506498396873474, "alpha_loss": 0.272925390124321, "alpha_value": 0.09193800759217437, "duration": 152.77446746826172, "step": 3000}
{"episode_reward": 35.0, "episode": 7.0, "batch_reward": 0.03537890625, "critic_loss": 0.19550003845989705, "actor_loss": -1.7363305659294128, "actor_target_entropy": -2.0, "actor_entropy": 2.3233326420783995, "alpha_loss": 0.23752336645126343, "alpha_value": 0.08998205051105937, "duration": 152.82474851608276, "step": 3500}
{"episode_reward": 79.0, "episode": 8.0, "batch_reward": 0.0603984375, "critic_loss": 0.31604359421133993, "actor_loss": -2.4620147790908815, "actor_target_entropy": -2.0, "actor_entropy": 2.1224150223731995, "alpha_loss": 0.2025909932255745, "alpha_value": 0.08821193498178485, "duration": 152.8778440952301, "step": 4000}
{"episode_reward": 153.0, "episode": 9.0, "batch_reward": 0.1002265625, "critic_loss": 0.43171032577753066, "actor_loss": -3.502254532814026, "actor_target_entropy": -2.0, "actor_entropy": 1.8062057700157166, "alpha_loss": 0.14962990418076516, "alpha_value": 0.08674150525455565, "duration": 152.83022260665894, "step": 4500}
{"episode_reward": 290.0, "episode": 10.0, "batch_reward": 0.1741953125, "critic_loss": 0.44654838848114015, "actor_loss": -5.11766284942627, "actor_target_entropy": -2.0, "actor_entropy": 1.526986023426056, "alpha_loss": 0.10180507412552833, "alpha_value": 0.08559500665982614, "step": 5000}
{"duration": 189.12341570854187, "step": 5000}
{"episode_reward": 522.0, "episode": 11.0, "batch_reward": 0.26712890625, "critic_loss": 0.38895256251096727, "actor_loss": -7.228606708526612, "actor_target_entropy": -2.0, "actor_entropy": 1.3448968620300292, "alpha_loss": 0.06789952951669694, "alpha_value": 0.08475169764753938, "duration": 152.61668825149536, "step": 5500}
{"episode_reward": 604.0, "episode": 12.0, "batch_reward": 0.352421875, "critic_loss": 0.4128719009757042, "actor_loss": -9.52224613571167, "actor_target_entropy": -2.0, "actor_entropy": 1.2485927715301515, "alpha_loss": 0.0468040072247386, "alpha_value": 0.08411241752125752, "duration": 152.7039315700531, "step": 6000}
{"episode_reward": 646.0, "episode": 13.0, "batch_reward": 0.42862109375, "critic_loss": 0.41908316403627394, "actor_loss": -11.934195083618164, "actor_target_entropy": -2.0, "actor_entropy": 1.2028041660785675, "alpha_loss": 0.03244601552560925, "alpha_value": 0.08360346653288023, "duration": 152.87167191505432, "step": 6500}
{"episode_reward": 664.0, "episode": 14.0, "batch_reward": 0.49920703125, "critic_loss": 0.4076434169411659, "actor_loss": -14.550769603729249, "actor_target_entropy": -2.0, "actor_entropy": 1.1407717120647431, "alpha_loss": 0.01805020684283227, "alpha_value": 0.08323946180858971, "duration": 152.78241348266602, "step": 7000}
{"episode_reward": 705.0, "episode": 15.0, "batch_reward": 0.56708984375, "critic_loss": 0.420555655837059, "actor_loss": -17.40018872451782, "actor_target_entropy": -2.0, "actor_entropy": 1.0959481081962585, "alpha_loss": 0.005050741765182465, "alpha_value": 0.08305188464558645, "duration": 152.83982181549072, "step": 7500}
{"episode_reward": 733.0, "episode": 16.0, "batch_reward": 0.6207734375, "critic_loss": 0.3941142656803131, "actor_loss": -20.330684310913085, "actor_target_entropy": -2.0, "actor_entropy": 1.069306666135788, "alpha_loss": -0.0043662306708283725, "alpha_value": 0.08307075818505757, "duration": 152.78942227363586, "step": 8000}
{"episode_reward": 725.0, "episode": 17.0, "batch_reward": 0.67069140625, "critic_loss": 0.4363518103659153, "actor_loss": -23.183125564575196, "actor_target_entropy": -2.0, "actor_entropy": 1.0467087595462798, "alpha_loss": -0.007738323297351599, "alpha_value": 0.08320169187316732, "duration": 152.8810694217682, "step": 8500}
{"episode_reward": 735.0, "episode": 18.0, "batch_reward": 0.72209375, "critic_loss": 0.3882033645808697, "actor_loss": -26.068342018127442, "actor_target_entropy": -2.0, "actor_entropy": 1.008422043323517, "alpha_loss": -0.009958651720080525, "alpha_value": 0.08341583314377805, "duration": 152.96227717399597, "step": 9000}
{"episode_reward": 761.0, "episode": 19.0, "batch_reward": 0.76270703125, "critic_loss": 0.3897310089468956, "actor_loss": -28.87599387359619, "actor_target_entropy": -2.0, "actor_entropy": 0.9695796678066254, "alpha_loss": -0.010933625098317861, "alpha_value": 0.08371020854915705, "duration": 152.8220202922821, "step": 9500}
{"episode_reward": 778.0, "episode": 20.0, "batch_reward": 0.8041796875, "critic_loss": 0.3502900499403477, "actor_loss": -31.683153900146486, "actor_target_entropy": -2.0, "actor_entropy": 0.9467685399055481, "alpha_loss": -0.01146051354915835, "alpha_value": 0.08405802242268721, "step": 10000}
{"duration": 189.21776866912842, "step": 10000}
{"episode_reward": 740.0, "episode": 21.0, "batch_reward": 0.84089453125, "critic_loss": 0.34929195272922514, "actor_loss": -34.46044970703125, "actor_target_entropy": -2.0, "actor_entropy": 0.9278044290542603, "alpha_loss": -0.011563366014743224, "alpha_value": 0.08445416560498352, "duration": 152.91951847076416, "step": 10500}
{"episode_reward": 771.0, "episode": 22.0, "batch_reward": 0.87358203125, "critic_loss": 0.38819741377234457, "actor_loss": -37.11866488647461, "actor_target_entropy": -2.0, "actor_entropy": 0.9069527134895324, "alpha_loss": -0.013726555677130818, "alpha_value": 0.08496011474731602, "duration": 152.9235897064209, "step": 11000}
{"episode_reward": 798.0, "episode": 23.0, "batch_reward": 0.90332421875, "critic_loss": 0.330710747808218, "actor_loss": -39.78891523742676, "actor_target_entropy": -2.0, "actor_entropy": 0.8922908542156219, "alpha_loss": -0.014218778972979636, "alpha_value": 0.08560210642207647, "duration": 152.97223138809204, "step": 11500}
{"episode_reward": 793.0, "episode": 24.0, "batch_reward": 0.931609375, "critic_loss": 0.3151687242090702, "actor_loss": -42.422065338134765, "actor_target_entropy": -2.0, "actor_entropy": 0.8970564539432526, "alpha_loss": -0.013925576098728925, "alpha_value": 0.08632339880801844, "duration": 152.9383704662323, "step": 12000}
{"episode_reward": 778.0, "episode": 25.0, "batch_reward": 0.9582109375, "critic_loss": 0.31125697603821756, "actor_loss": -44.98607084655762, "actor_target_entropy": -2.0, "actor_entropy": 0.8738987951278686, "alpha_loss": -0.010384359874762595, "alpha_value": 0.08699678264270991, "duration": 152.91516375541687, "step": 12500}
{"episode_reward": 788.0, "episode": 26.0, "batch_reward": 0.98275, "critic_loss": 0.33781822511553766, "actor_loss": -47.42510284423828, "actor_target_entropy": -2.0, "actor_entropy": 0.8412220323085785, "alpha_loss": -0.00894715823745355, "alpha_value": 0.08761861162430867, "duration": 152.9263048171997, "step": 13000}
{"episode_reward": 794.0, "episode": 27.0, "batch_reward": 1.00979296875, "critic_loss": 0.30013422718644145, "actor_loss": -49.86430041503906, "actor_target_entropy": -2.0, "actor_entropy": 0.8585733721256256, "alpha_loss": -0.008135868359357118, "alpha_value": 0.08819541357054624, "duration": 153.00723218917847, "step": 13500}
{"episode_reward": 817.0, "episode": 28.0, "batch_reward": 1.029609375, "critic_loss": 0.2901699631512165, "actor_loss": -52.181118881225586, "actor_target_entropy": -2.0, "actor_entropy": 0.8600686602592468, "alpha_loss": -0.007875120649812743, "alpha_value": 0.08882118812660564, "duration": 152.94191765785217, "step": 14000}
{"episode_reward": 812.0, "episode": 29.0, "batch_reward": 1.04883984375, "critic_loss": 0.2968428267836571, "actor_loss": -54.51080451965332, "actor_target_entropy": -2.0, "actor_entropy": 0.8507948853969574, "alpha_loss": -0.007175347467884422, "alpha_value": 0.08948951154904894, "duration": 152.93845653533936, "step": 14500}
{"episode_reward": 798.0, "episode": 30.0, "batch_reward": 1.066671875, "critic_loss": 0.31700401252508165, "actor_loss": -56.7709425201416, "actor_target_entropy": -2.0, "actor_entropy": 0.8587722039222717, "alpha_loss": -0.007743720351019875, "alpha_value": 0.09022943163609619, "step": 15000}
{"duration": 189.2628834247589, "step": 15000}
{"episode_reward": 817.0, "episode": 31.0, "batch_reward": 1.082765625, "critic_loss": 0.29579743832349775, "actor_loss": -58.92501745605469, "actor_target_entropy": -2.0, "actor_entropy": 0.8439826369285583, "alpha_loss": -0.004953752793604508, "alpha_value": 0.09083425970552123, "duration": 152.77509903907776, "step": 15500}
{"episode_reward": 780.0, "episode": 32.0, "batch_reward": 1.10079296875, "critic_loss": 0.31239613974094393, "actor_loss": -61.066620056152345, "actor_target_entropy": -2.0, "actor_entropy": 0.8336664257049561, "alpha_loss": -0.0077237194757908585, "alpha_value": 0.09156235463229416, "duration": 152.67938470840454, "step": 16000}
{"episode_reward": 822.0, "episode": 33.0, "batch_reward": 1.1183515625, "critic_loss": 0.3052559640109539, "actor_loss": -63.13217951965332, "actor_target_entropy": -2.0, "actor_entropy": 0.825351888179779, "alpha_loss": -0.004155022999271751, "alpha_value": 0.09234893833429816, "duration": 152.68308568000793, "step": 16500}
{"episode_reward": 805.0, "episode": 34.0, "batch_reward": 1.13610546875, "critic_loss": 0.3000672059953213, "actor_loss": -65.20170140075683, "actor_target_entropy": -2.0, "actor_entropy": 0.832433741569519, "alpha_loss": -0.002645764206070453, "alpha_value": 0.09280877497554031, "duration": 152.75585460662842, "step": 17000}
{"episode_reward": 806.0, "episode": 35.0, "batch_reward": 1.14759375, "critic_loss": 0.3333114583790302, "actor_loss": -67.129484375, "actor_target_entropy": -2.0, "actor_entropy": 0.8337728023529053, "alpha_loss": -0.004213219281751663, "alpha_value": 0.09321095675945712, "duration": 152.7663288116455, "step": 17500}
{"episode_reward": 809.0, "episode": 36.0, "batch_reward": 1.15733203125, "critic_loss": 0.30249429351091384, "actor_loss": -69.04154757690429, "actor_target_entropy": -2.0, "actor_entropy": 0.8092343826293945, "alpha_loss": -0.0026896868522744625, "alpha_value": 0.09380449121323531, "duration": 152.7611768245697, "step": 18000}
{"episode_reward": 826.0, "episode": 37.0, "batch_reward": 1.17700390625, "critic_loss": 0.28125635722279546, "actor_loss": -71.00769412231445, "actor_target_entropy": -2.0, "actor_entropy": 0.8157579112052917, "alpha_loss": -0.0032267352156341075, "alpha_value": 0.09429471188604438, "duration": 152.78080105781555, "step": 18500}
{"episode_reward": 829.0, "episode": 38.0, "batch_reward": 1.18934375, "critic_loss": 0.2992670189142227, "actor_loss": -72.87228903198242, "actor_target_entropy": -2.0, "actor_entropy": 0.8148796737194062, "alpha_loss": -0.001126135022379458, "alpha_value": 0.09461136855513395, "duration": 152.82998704910278, "step": 19000}
{"episode_reward": 800.0, "episode": 39.0, "batch_reward": 1.1980859375, "critic_loss": 0.3057476287186146, "actor_loss": -74.67754504394532, "actor_target_entropy": -2.0, "actor_entropy": 0.8241423506736756, "alpha_loss": -0.0005605823858641088, "alpha_value": 0.09484645725336596, "duration": 152.69995856285095, "step": 19500}
{"episode_reward": 785.0, "episode": 40.0, "batch_reward": 1.20912109375, "critic_loss": 0.310977835804224, "actor_loss": -76.46103643798828, "actor_target_entropy": -2.0, "actor_entropy": 0.8194526393413544, "alpha_loss": -6.419895216822625e-05, "alpha_value": 0.09485584157139487, "step": 20000}
{"duration": 189.23447513580322, "step": 20000}
{"episode_reward": 835.0, "episode": 41.0, "batch_reward": 1.2161484375, "critic_loss": 0.3295603152513504, "actor_loss": -78.18095477294922, "actor_target_entropy": -2.0, "actor_entropy": 0.8197634091377258, "alpha_loss": -6.20840818155557e-05, "alpha_value": 0.09486381106687818, "duration": 152.71325373649597, "step": 20500}
