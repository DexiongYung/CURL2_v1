{"episode_reward": 0.0, "episode": 1.0, "duration": 37.1664559841156, "step": 500}
{"episode_reward": 3.0, "episode": 2.0, "duration": 1.2626867294311523, "step": 1000}
{"episode_reward": 11.0, "episode": 3.0, "batch_reward": 0.01107421875, "critic_loss": 0.06418418550933712, "actor_loss": -0.15909295754879713, "actor_target_entropy": -2.0, "actor_entropy": 2.5251792783737184, "alpha_loss": 0.3217965438365936, "alpha_value": 0.09877077589020054, "duration": 152.43513441085815, "step": 1500}
{"episode_reward": 0.0, "episode": 4.0, "batch_reward": 0.00969921875, "critic_loss": 0.03576397565938532, "actor_loss": -0.5026524603366852, "actor_target_entropy": -2.0, "actor_entropy": 2.5921466093063357, "alpha_loss": 0.31385881948471067, "alpha_value": 0.0963445995077662, "duration": 152.61539149284363, "step": 2000}
{"episode_reward": 8.0, "episode": 5.0, "batch_reward": 0.014125, "critic_loss": 0.07340318208560348, "actor_loss": -0.7971405415534973, "actor_target_entropy": -2.0, "actor_entropy": 2.6132427501678466, "alpha_loss": 0.29554595065116884, "alpha_value": 0.09407779061256281, "duration": 152.80618000030518, "step": 2500}
{"episode_reward": 20.0, "episode": 6.0, "batch_reward": 0.02023828125, "critic_loss": 0.10418411902338266, "actor_loss": -1.1716194756031035, "actor_target_entropy": -2.0, "actor_entropy": 2.506498396873474, "alpha_loss": 0.272925390124321, "alpha_value": 0.09193800759217437, "duration": 152.77446746826172, "step": 3000}
{"episode_reward": 35.0, "episode": 7.0, "batch_reward": 0.03537890625, "critic_loss": 0.19550003845989705, "actor_loss": -1.7363305659294128, "actor_target_entropy": -2.0, "actor_entropy": 2.3233326420783995, "alpha_loss": 0.23752336645126343, "alpha_value": 0.08998205051105937, "duration": 152.82474851608276, "step": 3500}
{"episode_reward": 79.0, "episode": 8.0, "batch_reward": 0.0603984375, "critic_loss": 0.31604359421133993, "actor_loss": -2.4620147790908815, "actor_target_entropy": -2.0, "actor_entropy": 2.1224150223731995, "alpha_loss": 0.2025909932255745, "alpha_value": 0.08821193498178485, "duration": 152.8778440952301, "step": 4000}
{"episode_reward": 153.0, "episode": 9.0, "batch_reward": 0.1002265625, "critic_loss": 0.43171032577753066, "actor_loss": -3.502254532814026, "actor_target_entropy": -2.0, "actor_entropy": 1.8062057700157166, "alpha_loss": 0.14962990418076516, "alpha_value": 0.08674150525455565, "duration": 152.83022260665894, "step": 4500}
{"episode_reward": 290.0, "episode": 10.0, "batch_reward": 0.1741953125, "critic_loss": 0.44654838848114015, "actor_loss": -5.11766284942627, "actor_target_entropy": -2.0, "actor_entropy": 1.526986023426056, "alpha_loss": 0.10180507412552833, "alpha_value": 0.08559500665982614, "step": 5000}
{"duration": 189.12341570854187, "step": 5000}
{"episode_reward": 522.0, "episode": 11.0, "batch_reward": 0.26712890625, "critic_loss": 0.38895256251096727, "actor_loss": -7.228606708526612, "actor_target_entropy": -2.0, "actor_entropy": 1.3448968620300292, "alpha_loss": 0.06789952951669694, "alpha_value": 0.08475169764753938, "duration": 152.61668825149536, "step": 5500}
{"episode_reward": 604.0, "episode": 12.0, "batch_reward": 0.352421875, "critic_loss": 0.4128719009757042, "actor_loss": -9.52224613571167, "actor_target_entropy": -2.0, "actor_entropy": 1.2485927715301515, "alpha_loss": 0.0468040072247386, "alpha_value": 0.08411241752125752, "duration": 152.7039315700531, "step": 6000}
{"episode_reward": 646.0, "episode": 13.0, "batch_reward": 0.42862109375, "critic_loss": 0.41908316403627394, "actor_loss": -11.934195083618164, "actor_target_entropy": -2.0, "actor_entropy": 1.2028041660785675, "alpha_loss": 0.03244601552560925, "alpha_value": 0.08360346653288023, "duration": 152.87167191505432, "step": 6500}
{"episode_reward": 664.0, "episode": 14.0, "batch_reward": 0.49920703125, "critic_loss": 0.4076434169411659, "actor_loss": -14.550769603729249, "actor_target_entropy": -2.0, "actor_entropy": 1.1407717120647431, "alpha_loss": 0.01805020684283227, "alpha_value": 0.08323946180858971, "duration": 152.78241348266602, "step": 7000}
{"episode_reward": 705.0, "episode": 15.0, "batch_reward": 0.56708984375, "critic_loss": 0.420555655837059, "actor_loss": -17.40018872451782, "actor_target_entropy": -2.0, "actor_entropy": 1.0959481081962585, "alpha_loss": 0.005050741765182465, "alpha_value": 0.08305188464558645, "duration": 152.83982181549072, "step": 7500}
{"episode_reward": 733.0, "episode": 16.0, "batch_reward": 0.6207734375, "critic_loss": 0.3941142656803131, "actor_loss": -20.330684310913085, "actor_target_entropy": -2.0, "actor_entropy": 1.069306666135788, "alpha_loss": -0.0043662306708283725, "alpha_value": 0.08307075818505757, "duration": 152.78942227363586, "step": 8000}
{"episode_reward": 725.0, "episode": 17.0, "batch_reward": 0.67069140625, "critic_loss": 0.4363518103659153, "actor_loss": -23.183125564575196, "actor_target_entropy": -2.0, "actor_entropy": 1.0467087595462798, "alpha_loss": -0.007738323297351599, "alpha_value": 0.08320169187316732, "duration": 152.8810694217682, "step": 8500}
{"episode_reward": 735.0, "episode": 18.0, "batch_reward": 0.72209375, "critic_loss": 0.3882033645808697, "actor_loss": -26.068342018127442, "actor_target_entropy": -2.0, "actor_entropy": 1.008422043323517, "alpha_loss": -0.009958651720080525, "alpha_value": 0.08341583314377805, "duration": 152.96227717399597, "step": 9000}
{"episode_reward": 761.0, "episode": 19.0, "batch_reward": 0.76270703125, "critic_loss": 0.3897310089468956, "actor_loss": -28.87599387359619, "actor_target_entropy": -2.0, "actor_entropy": 0.9695796678066254, "alpha_loss": -0.010933625098317861, "alpha_value": 0.08371020854915705, "duration": 152.8220202922821, "step": 9500}
{"episode_reward": 778.0, "episode": 20.0, "batch_reward": 0.8041796875, "critic_loss": 0.3502900499403477, "actor_loss": -31.683153900146486, "actor_target_entropy": -2.0, "actor_entropy": 0.9467685399055481, "alpha_loss": -0.01146051354915835, "alpha_value": 0.08405802242268721, "step": 10000}
{"duration": 189.21776866912842, "step": 10000}
{"episode_reward": 740.0, "episode": 21.0, "batch_reward": 0.84089453125, "critic_loss": 0.34929195272922514, "actor_loss": -34.46044970703125, "actor_target_entropy": -2.0, "actor_entropy": 0.9278044290542603, "alpha_loss": -0.011563366014743224, "alpha_value": 0.08445416560498352, "duration": 152.91951847076416, "step": 10500}
{"episode_reward": 771.0, "episode": 22.0, "batch_reward": 0.87358203125, "critic_loss": 0.38819741377234457, "actor_loss": -37.11866488647461, "actor_target_entropy": -2.0, "actor_entropy": 0.9069527134895324, "alpha_loss": -0.013726555677130818, "alpha_value": 0.08496011474731602, "duration": 152.9235897064209, "step": 11000}
{"episode_reward": 798.0, "episode": 23.0, "batch_reward": 0.90332421875, "critic_loss": 0.330710747808218, "actor_loss": -39.78891523742676, "actor_target_entropy": -2.0, "actor_entropy": 0.8922908542156219, "alpha_loss": -0.014218778972979636, "alpha_value": 0.08560210642207647, "duration": 152.97223138809204, "step": 11500}
{"episode_reward": 793.0, "episode": 24.0, "batch_reward": 0.931609375, "critic_loss": 0.3151687242090702, "actor_loss": -42.422065338134765, "actor_target_entropy": -2.0, "actor_entropy": 0.8970564539432526, "alpha_loss": -0.013925576098728925, "alpha_value": 0.08632339880801844, "duration": 152.9383704662323, "step": 12000}
{"episode_reward": 778.0, "episode": 25.0, "batch_reward": 0.9582109375, "critic_loss": 0.31125697603821756, "actor_loss": -44.98607084655762, "actor_target_entropy": -2.0, "actor_entropy": 0.8738987951278686, "alpha_loss": -0.010384359874762595, "alpha_value": 0.08699678264270991, "duration": 152.91516375541687, "step": 12500}
{"episode_reward": 788.0, "episode": 26.0, "batch_reward": 0.98275, "critic_loss": 0.33781822511553766, "actor_loss": -47.42510284423828, "actor_target_entropy": -2.0, "actor_entropy": 0.8412220323085785, "alpha_loss": -0.00894715823745355, "alpha_value": 0.08761861162430867, "duration": 152.9263048171997, "step": 13000}
{"episode_reward": 794.0, "episode": 27.0, "batch_reward": 1.00979296875, "critic_loss": 0.30013422718644145, "actor_loss": -49.86430041503906, "actor_target_entropy": -2.0, "actor_entropy": 0.8585733721256256, "alpha_loss": -0.008135868359357118, "alpha_value": 0.08819541357054624, "duration": 153.00723218917847, "step": 13500}
{"episode_reward": 817.0, "episode": 28.0, "batch_reward": 1.029609375, "critic_loss": 0.2901699631512165, "actor_loss": -52.181118881225586, "actor_target_entropy": -2.0, "actor_entropy": 0.8600686602592468, "alpha_loss": -0.007875120649812743, "alpha_value": 0.08882118812660564, "duration": 152.94191765785217, "step": 14000}
{"episode_reward": 812.0, "episode": 29.0, "batch_reward": 1.04883984375, "critic_loss": 0.2968428267836571, "actor_loss": -54.51080451965332, "actor_target_entropy": -2.0, "actor_entropy": 0.8507948853969574, "alpha_loss": -0.007175347467884422, "alpha_value": 0.08948951154904894, "duration": 152.93845653533936, "step": 14500}
{"episode_reward": 798.0, "episode": 30.0, "batch_reward": 1.066671875, "critic_loss": 0.31700401252508165, "actor_loss": -56.7709425201416, "actor_target_entropy": -2.0, "actor_entropy": 0.8587722039222717, "alpha_loss": -0.007743720351019875, "alpha_value": 0.09022943163609619, "step": 15000}
{"duration": 189.2628834247589, "step": 15000}
{"episode_reward": 817.0, "episode": 31.0, "batch_reward": 1.082765625, "critic_loss": 0.29579743832349775, "actor_loss": -58.92501745605469, "actor_target_entropy": -2.0, "actor_entropy": 0.8439826369285583, "alpha_loss": -0.004953752793604508, "alpha_value": 0.09083425970552123, "duration": 152.77509903907776, "step": 15500}
{"episode_reward": 780.0, "episode": 32.0, "batch_reward": 1.10079296875, "critic_loss": 0.31239613974094393, "actor_loss": -61.066620056152345, "actor_target_entropy": -2.0, "actor_entropy": 0.8336664257049561, "alpha_loss": -0.0077237194757908585, "alpha_value": 0.09156235463229416, "duration": 152.67938470840454, "step": 16000}
{"episode_reward": 822.0, "episode": 33.0, "batch_reward": 1.1183515625, "critic_loss": 0.3052559640109539, "actor_loss": -63.13217951965332, "actor_target_entropy": -2.0, "actor_entropy": 0.825351888179779, "alpha_loss": -0.004155022999271751, "alpha_value": 0.09234893833429816, "duration": 152.68308568000793, "step": 16500}
{"episode_reward": 805.0, "episode": 34.0, "batch_reward": 1.13610546875, "critic_loss": 0.3000672059953213, "actor_loss": -65.20170140075683, "actor_target_entropy": -2.0, "actor_entropy": 0.832433741569519, "alpha_loss": -0.002645764206070453, "alpha_value": 0.09280877497554031, "duration": 152.75585460662842, "step": 17000}
{"episode_reward": 806.0, "episode": 35.0, "batch_reward": 1.14759375, "critic_loss": 0.3333114583790302, "actor_loss": -67.129484375, "actor_target_entropy": -2.0, "actor_entropy": 0.8337728023529053, "alpha_loss": -0.004213219281751663, "alpha_value": 0.09321095675945712, "duration": 152.7663288116455, "step": 17500}
{"episode_reward": 809.0, "episode": 36.0, "batch_reward": 1.15733203125, "critic_loss": 0.30249429351091384, "actor_loss": -69.04154757690429, "actor_target_entropy": -2.0, "actor_entropy": 0.8092343826293945, "alpha_loss": -0.0026896868522744625, "alpha_value": 0.09380449121323531, "duration": 152.7611768245697, "step": 18000}
{"episode_reward": 826.0, "episode": 37.0, "batch_reward": 1.17700390625, "critic_loss": 0.28125635722279546, "actor_loss": -71.00769412231445, "actor_target_entropy": -2.0, "actor_entropy": 0.8157579112052917, "alpha_loss": -0.0032267352156341075, "alpha_value": 0.09429471188604438, "duration": 152.78080105781555, "step": 18500}
{"episode_reward": 829.0, "episode": 38.0, "batch_reward": 1.18934375, "critic_loss": 0.2992670189142227, "actor_loss": -72.87228903198242, "actor_target_entropy": -2.0, "actor_entropy": 0.8148796737194062, "alpha_loss": -0.001126135022379458, "alpha_value": 0.09461136855513395, "duration": 152.82998704910278, "step": 19000}
{"episode_reward": 800.0, "episode": 39.0, "batch_reward": 1.1980859375, "critic_loss": 0.3057476287186146, "actor_loss": -74.67754504394532, "actor_target_entropy": -2.0, "actor_entropy": 0.8241423506736756, "alpha_loss": -0.0005605823858641088, "alpha_value": 0.09484645725336596, "duration": 152.69995856285095, "step": 19500}
{"episode_reward": 785.0, "episode": 40.0, "batch_reward": 1.20912109375, "critic_loss": 0.310977835804224, "actor_loss": -76.46103643798828, "actor_target_entropy": -2.0, "actor_entropy": 0.8194526393413544, "alpha_loss": -6.419895216822625e-05, "alpha_value": 0.09485584157139487, "step": 20000}
{"duration": 189.23447513580322, "step": 20000}
{"episode_reward": 835.0, "episode": 41.0, "batch_reward": 1.2161484375, "critic_loss": 0.3295603152513504, "actor_loss": -78.18095477294922, "actor_target_entropy": -2.0, "actor_entropy": 0.8197634091377258, "alpha_loss": -6.20840818155557e-05, "alpha_value": 0.09486381106687818, "duration": 152.71325373649597, "step": 20500}
{"episode_reward": 812.0, "episode": 42.0, "batch_reward": 1.22829296875, "critic_loss": 0.3332542062699795, "actor_loss": -79.86482653808594, "actor_target_entropy": -2.0, "actor_entropy": 0.8258679826259613, "alpha_loss": -0.0027920201844535766, "alpha_value": 0.09510979024672096, "duration": 152.69585871696472, "step": 21000}
{"episode_reward": 821.0, "episode": 43.0, "batch_reward": 1.2404140625, "critic_loss": 0.32646596187353133, "actor_loss": -81.55813723754883, "actor_target_entropy": -2.0, "actor_entropy": 0.8250420823097229, "alpha_loss": -0.000849748986074701, "alpha_value": 0.09546642840019605, "duration": 152.65143823623657, "step": 21500}
{"episode_reward": 815.0, "episode": 44.0, "batch_reward": 1.24508984375, "critic_loss": 0.3088812690675259, "actor_loss": -83.1823366394043, "actor_target_entropy": -2.0, "actor_entropy": 0.8193640706539154, "alpha_loss": -0.0021244562971405685, "alpha_value": 0.09580197198211217, "duration": 152.72966384887695, "step": 22000}
{"episode_reward": 839.0, "episode": 45.0, "batch_reward": 1.25603125, "critic_loss": 0.31562487146258356, "actor_loss": -84.79249713134766, "actor_target_entropy": -2.0, "actor_entropy": 0.8255748448371887, "alpha_loss": -0.0011954688634723426, "alpha_value": 0.09622965475922211, "duration": 152.6616952419281, "step": 22500}
{"episode_reward": 828.0, "episode": 46.0, "batch_reward": 1.26291015625, "critic_loss": 0.3276264437139034, "actor_loss": -86.37586465454102, "actor_target_entropy": -2.0, "actor_entropy": 0.8249389815330506, "alpha_loss": 0.0009839539467357099, "alpha_value": 0.09614772691866331, "duration": 191.29783391952515, "step": 23000}
{"episode_reward": 829.0, "episode": 47.0, "batch_reward": 1.27298046875, "critic_loss": 0.30628005784749984, "actor_loss": -87.90783847045898, "actor_target_entropy": -2.0, "actor_entropy": 0.8412437851428985, "alpha_loss": 0.0006632225257344544, "alpha_value": 0.09595167639738604, "duration": 159.02323126792908, "step": 23500}
{"episode_reward": 814.0, "episode": 48.0, "batch_reward": 1.28441796875, "critic_loss": 0.30253460839390756, "actor_loss": -89.44237396240234, "actor_target_entropy": -2.0, "actor_entropy": 0.8296990625858307, "alpha_loss": 0.0029429726963862775, "alpha_value": 0.09557946446817003, "duration": 153.8932237625122, "step": 24000}
{"episode_reward": 856.0, "episode": 49.0, "batch_reward": 1.28991015625, "critic_loss": 0.32099035048484803, "actor_loss": -90.84866857910156, "actor_target_entropy": -2.0, "actor_entropy": 0.8219819898605347, "alpha_loss": 0.003082196038682014, "alpha_value": 0.09491058342067903, "duration": 153.9069848060608, "step": 24500}
{"episode_reward": 856.0, "episode": 50.0, "batch_reward": 1.3001171875, "critic_loss": 0.32037721529603, "actor_loss": -92.33609024047851, "actor_target_entropy": -2.0, "actor_entropy": 0.8134830553531647, "alpha_loss": 0.0015127057975623756, "alpha_value": 0.09448126170053486, "step": 25000}
{"duration": 190.30661416053772, "step": 25000}
{"episode_reward": 806.0, "episode": 51.0, "batch_reward": 1.30595703125, "critic_loss": 0.351040615350008, "actor_loss": -93.71996102905274, "actor_target_entropy": -2.0, "actor_entropy": 0.8025540697574616, "alpha_loss": 0.0002819004328921437, "alpha_value": 0.09424154259686013, "duration": 153.0936734676361, "step": 25500}
{"episode_reward": 802.0, "episode": 52.0, "batch_reward": 1.31132421875, "critic_loss": 0.33410998064279557, "actor_loss": -95.13124716186523, "actor_target_entropy": -2.0, "actor_entropy": 0.7892610943317413, "alpha_loss": 0.0008109304120298475, "alpha_value": 0.09419177244055212, "duration": 152.7596995830536, "step": 26000}
{"episode_reward": 828.0, "episode": 53.0, "batch_reward": 1.3189296875, "critic_loss": 0.3368750236928463, "actor_loss": -96.50154364013672, "actor_target_entropy": -2.0, "actor_entropy": 0.7907890584468842, "alpha_loss": 0.0010326471019070596, "alpha_value": 0.09396921218075745, "duration": 152.61260867118835, "step": 26500}
{"episode_reward": 834.0, "episode": 54.0, "batch_reward": 1.3240546875, "critic_loss": 0.3397520731985569, "actor_loss": -97.85046878051757, "actor_target_entropy": -2.0, "actor_entropy": 0.7975810008049011, "alpha_loss": 0.0009357199023943395, "alpha_value": 0.09379235851468537, "duration": 152.86432456970215, "step": 27000}
{"episode_reward": 848.0, "episode": 55.0, "batch_reward": 1.3305625, "critic_loss": 0.3260495569109917, "actor_loss": -99.15180975341796, "actor_target_entropy": -2.0, "actor_entropy": 0.7735765926837921, "alpha_loss": 0.0004164966819807887, "alpha_value": 0.093593125509373, "duration": 152.5735297203064, "step": 27500}
{"episode_reward": 850.0, "episode": 56.0, "batch_reward": 1.33744140625, "critic_loss": 0.33095454278588293, "actor_loss": -100.39044189453125, "actor_target_entropy": -2.0, "actor_entropy": 0.7942069001197815, "alpha_loss": 0.0015701854322105646, "alpha_value": 0.0934552919430183, "duration": 153.02348136901855, "step": 28000}
{"episode_reward": 851.0, "episode": 57.0, "batch_reward": 1.34188671875, "critic_loss": 0.34411915388703346, "actor_loss": -101.63812197875977, "actor_target_entropy": -2.0, "actor_entropy": 0.7796473243236541, "alpha_loss": -6.64113606326282e-05, "alpha_value": 0.09324810958126659, "duration": 153.0137791633606, "step": 28500}
{"episode_reward": 833.0, "episode": 58.0, "batch_reward": 1.35269921875, "critic_loss": 0.33425417855381967, "actor_loss": -102.87726272583008, "actor_target_entropy": -2.0, "actor_entropy": 0.7895068552494049, "alpha_loss": 0.0010879618984181434, "alpha_value": 0.09317857286564478, "duration": 152.89922070503235, "step": 29000}
{"episode_reward": 850.0, "episode": 59.0, "batch_reward": 1.3538828125, "critic_loss": 0.3436700388193131, "actor_loss": -104.08345092773438, "actor_target_entropy": -2.0, "actor_entropy": 0.7924333946704865, "alpha_loss": -0.0010643735849298537, "alpha_value": 0.09315160718468489, "duration": 152.55959582328796, "step": 29500}
{"episode_reward": 848.0, "episode": 60.0, "batch_reward": 1.362984375, "critic_loss": 0.31946838715672493, "actor_loss": -105.24134436035156, "actor_target_entropy": -2.0, "actor_entropy": 0.7838510494232178, "alpha_loss": -0.0005922812933567912, "alpha_value": 0.09339735047248049, "step": 30000}
{"duration": 189.34594249725342, "step": 30000}
{"episode_reward": 853.0, "episode": 61.0, "batch_reward": 1.36867578125, "critic_loss": 0.33722818657755854, "actor_loss": -106.40665686035156, "actor_target_entropy": -2.0, "actor_entropy": 0.7819735612869263, "alpha_loss": 0.0013158537223935127, "alpha_value": 0.09322676939144967, "duration": 152.67976260185242, "step": 30500}
{"episode_reward": 851.0, "episode": 62.0, "batch_reward": 1.37235546875, "critic_loss": 0.30959375444054604, "actor_loss": -107.52096090698242, "actor_target_entropy": -2.0, "actor_entropy": 0.7665627362728119, "alpha_loss": 0.0016121263285167515, "alpha_value": 0.0929244142141535, "duration": 152.9909062385559, "step": 31000}
{"episode_reward": 884.0, "episode": 63.0, "batch_reward": 1.3799296875, "critic_loss": 0.31961203590035436, "actor_loss": -108.70295010375976, "actor_target_entropy": -2.0, "actor_entropy": 0.7707481172084808, "alpha_loss": 0.002027500779367983, "alpha_value": 0.09254419880365916, "duration": 153.04358530044556, "step": 31500}
{"episode_reward": 877.0, "episode": 64.0, "batch_reward": 1.38428515625, "critic_loss": 0.3467706175744534, "actor_loss": -109.76662860107422, "actor_target_entropy": -2.0, "actor_entropy": 0.7773575916290283, "alpha_loss": 0.0015992768928408622, "alpha_value": 0.09222975072065345, "duration": 152.8035671710968, "step": 32000}
{"episode_reward": 847.0, "episode": 65.0, "batch_reward": 1.3877109375, "critic_loss": 0.349998682975769, "actor_loss": -110.79015805053712, "actor_target_entropy": -2.0, "actor_entropy": 0.7597363731861114, "alpha_loss": 0.000613242032006383, "alpha_value": 0.09192689568558737, "duration": 153.71069622039795, "step": 32500}
{"episode_reward": 830.0, "episode": 66.0, "batch_reward": 1.39378125, "critic_loss": 0.34801043233275414, "actor_loss": -111.84913821411133, "actor_target_entropy": -2.0, "actor_entropy": 0.7524223883152008, "alpha_loss": 0.0024570868355222046, "alpha_value": 0.09164013354341982, "duration": 152.9203703403473, "step": 33000}
{"episode_reward": 841.0, "episode": 67.0, "batch_reward": 1.39800390625, "critic_loss": 0.3596527381241322, "actor_loss": -112.82886624145507, "actor_target_entropy": -2.0, "actor_entropy": 0.758515564918518, "alpha_loss": -0.0005030584302730858, "alpha_value": 0.09140568354651249, "duration": 153.04287362098694, "step": 33500}
{"episode_reward": 856.0, "episode": 68.0, "batch_reward": 1.40558984375, "critic_loss": 0.3199302980005741, "actor_loss": -113.85995501708985, "actor_target_entropy": -2.0, "actor_entropy": 0.7318919167518616, "alpha_loss": 0.0006265518674626946, "alpha_value": 0.09146314396384336, "duration": 152.98920559883118, "step": 34000}
{"episode_reward": 870.0, "episode": 69.0, "batch_reward": 1.408, "critic_loss": 0.3244919510483742, "actor_loss": -114.84960858154297, "actor_target_entropy": -2.0, "actor_entropy": 0.7371466598510742, "alpha_loss": 0.00032387930690310894, "alpha_value": 0.09128434239879916, "duration": 152.6904468536377, "step": 34500}
{"episode_reward": 870.0, "episode": 70.0, "batch_reward": 1.41471875, "critic_loss": 0.3419578187763691, "actor_loss": -115.82916143798828, "actor_target_entropy": -2.0, "actor_entropy": 0.7527032513618469, "alpha_loss": 0.0031761249490082264, "alpha_value": 0.09091421076274528, "step": 35000}
{"duration": 189.57145404815674, "step": 35000}
{"episode_reward": 882.0, "episode": 71.0, "batch_reward": 1.4179296875, "critic_loss": 0.3251426928639412, "actor_loss": -116.75964974975587, "actor_target_entropy": -2.0, "actor_entropy": 0.7277845859527587, "alpha_loss": 0.0011816801652312278, "alpha_value": 0.09059457567669002, "duration": 152.76483702659607, "step": 35500}
{"episode_reward": 863.0, "episode": 72.0, "batch_reward": 1.4201875, "critic_loss": 0.32866537219285963, "actor_loss": -117.70365432739258, "actor_target_entropy": -2.0, "actor_entropy": 0.7243276703357696, "alpha_loss": 0.0016426568091847003, "alpha_value": 0.09019762937027379, "duration": 152.72835636138916, "step": 36000}
{"episode_reward": 866.0, "episode": 73.0, "batch_reward": 1.42593359375, "critic_loss": 0.3487882373332977, "actor_loss": -118.63255197143555, "actor_target_entropy": -2.0, "actor_entropy": 0.7200369248390198, "alpha_loss": 0.0010847405488602817, "alpha_value": 0.08992981551559963, "duration": 152.75621247291565, "step": 36500}
{"episode_reward": 863.0, "episode": 74.0, "batch_reward": 1.432, "critic_loss": 0.33382126584649086, "actor_loss": -119.52773919677735, "actor_target_entropy": -2.0, "actor_entropy": 0.6850602304935456, "alpha_loss": -9.229273884557187e-05, "alpha_value": 0.08986134798223357, "duration": 152.78274512290955, "step": 37000}
{"episode_reward": 858.0, "episode": 75.0, "batch_reward": 1.4320234375, "critic_loss": 0.32438780009746554, "actor_loss": -120.38158367919922, "actor_target_entropy": -2.0, "actor_entropy": 0.6902276557683945, "alpha_loss": -0.00020928064500913023, "alpha_value": 0.08984951040257658, "duration": 153.07212924957275, "step": 37500}
{"episode_reward": 878.0, "episode": 76.0, "batch_reward": 1.43871484375, "critic_loss": 0.3234342898130417, "actor_loss": -121.29254608154297, "actor_target_entropy": -2.0, "actor_entropy": 0.6971415216922761, "alpha_loss": 0.00019304902525618672, "alpha_value": 0.08995294921429944, "duration": 152.81985878944397, "step": 38000}
{"episode_reward": 876.0, "episode": 77.0, "batch_reward": 1.44224609375, "critic_loss": 0.3481226689219475, "actor_loss": -122.16260696411133, "actor_target_entropy": -2.0, "actor_entropy": 0.7013924295902252, "alpha_loss": 0.0018536874735727907, "alpha_value": 0.08964089951405117, "duration": 152.73672318458557, "step": 38500}
{"episode_reward": 854.0, "episode": 78.0, "batch_reward": 1.444078125, "critic_loss": 0.33125679793953894, "actor_loss": -122.9812632446289, "actor_target_entropy": -2.0, "actor_entropy": 0.7050423152446746, "alpha_loss": 0.001125825309427455, "alpha_value": 0.08936472747978151, "duration": 152.8349006175995, "step": 39000}
{"episode_reward": 889.0, "episode": 79.0, "batch_reward": 1.451875, "critic_loss": 0.3279176556766033, "actor_loss": -123.81780746459961, "actor_target_entropy": -2.0, "actor_entropy": 0.6816341483592987, "alpha_loss": 0.0011026171196717768, "alpha_value": 0.08911478062500976, "duration": 152.56622862815857, "step": 39500}
{"episode_reward": 877.0, "episode": 80.0, "batch_reward": 1.45644921875, "critic_loss": 0.3208527052402496, "actor_loss": -124.63823764038086, "actor_target_entropy": -2.0, "actor_entropy": 0.6964122556447983, "alpha_loss": 0.002484245858155191, "alpha_value": 0.0887540051447505, "step": 40000}
{"duration": 189.1050534248352, "step": 40000}
{"episode_reward": 861.0, "episode": 81.0, "batch_reward": 1.4580703125, "critic_loss": 0.34364717644453047, "actor_loss": -125.42756036376953, "actor_target_entropy": -2.0, "actor_entropy": 0.68590087890625, "alpha_loss": 0.001376930628437549, "alpha_value": 0.08832105457192166, "duration": 152.79224967956543, "step": 40500}
{"episode_reward": 899.0, "episode": 82.0, "batch_reward": 1.4602890625, "critic_loss": 0.3286867987513542, "actor_loss": -126.20785961914062, "actor_target_entropy": -2.0, "actor_entropy": 0.6781181902885437, "alpha_loss": 0.0018252907195128502, "alpha_value": 0.08798447669285951, "duration": 152.72283720970154, "step": 41000}
{"episode_reward": 877.0, "episode": 83.0, "batch_reward": 1.4649765625, "critic_loss": 0.35715851065516474, "actor_loss": -127.00114700317383, "actor_target_entropy": -2.0, "actor_entropy": 0.6662643191814422, "alpha_loss": 0.0004580621193163097, "alpha_value": 0.08787313334804181, "duration": 152.80018782615662, "step": 41500}
{"episode_reward": 878.0, "episode": 84.0, "batch_reward": 1.4684453125, "critic_loss": 0.3333322159051895, "actor_loss": -127.7419390258789, "actor_target_entropy": -2.0, "actor_entropy": 0.6690494080781937, "alpha_loss": 0.0005789905241690576, "alpha_value": 0.08767396176248476, "duration": 152.64059734344482, "step": 42000}
{"episode_reward": 898.0, "episode": 85.0, "batch_reward": 1.4693359375, "critic_loss": 0.3128001197874546, "actor_loss": -128.4888372192383, "actor_target_entropy": -2.0, "actor_entropy": 0.6561509613990784, "alpha_loss": 0.0015806593485176562, "alpha_value": 0.0874929259911347, "duration": 152.75067281723022, "step": 42500}
{"episode_reward": 884.0, "episode": 86.0, "batch_reward": 1.4761953125, "critic_loss": 0.299088983297348, "actor_loss": -129.21811685180663, "actor_target_entropy": -2.0, "actor_entropy": 0.6660520596504211, "alpha_loss": 0.0012793833599425853, "alpha_value": 0.08717458593519282, "duration": 152.7436239719391, "step": 43000}
{"episode_reward": 912.0, "episode": 87.0, "batch_reward": 1.47983203125, "critic_loss": 0.3260607167482376, "actor_loss": -129.9508364868164, "actor_target_entropy": -2.0, "actor_entropy": 0.6601201885938645, "alpha_loss": 0.00022588328644633293, "alpha_value": 0.08702581259608246, "duration": 152.7300066947937, "step": 43500}
{"episode_reward": 862.0, "episode": 88.0, "batch_reward": 1.4823515625, "critic_loss": 0.33964358082413676, "actor_loss": -130.64235150146484, "actor_target_entropy": -2.0, "actor_entropy": 0.6721714279651642, "alpha_loss": 0.0017477653892710805, "alpha_value": 0.08679688702729554, "duration": 152.79197907447815, "step": 44000}
{"episode_reward": 899.0, "episode": 89.0, "batch_reward": 1.4878359375, "critic_loss": 0.32358593013882636, "actor_loss": -131.35567724609376, "actor_target_entropy": -2.0, "actor_entropy": 0.6610554904937744, "alpha_loss": 0.001007090446073562, "alpha_value": 0.0865702106177279, "duration": 152.6022675037384, "step": 44500}
{"episode_reward": 887.0, "episode": 90.0, "batch_reward": 1.48876953125, "critic_loss": 0.3148191477954388, "actor_loss": -132.04885473632814, "actor_target_entropy": -2.0, "actor_entropy": 0.6402835887670517, "alpha_loss": 0.00038548543537035584, "alpha_value": 0.0863795646450017, "step": 45000}
{"duration": 189.20322489738464, "step": 45000}
{"episode_reward": 879.0, "episode": 91.0, "batch_reward": 1.49076171875, "critic_loss": 0.331067900121212, "actor_loss": -132.66693768310546, "actor_target_entropy": -2.0, "actor_entropy": 0.6507674533128739, "alpha_loss": 0.0009580702353268862, "alpha_value": 0.08623125513022785, "duration": 152.51593017578125, "step": 45500}
{"episode_reward": 875.0, "episode": 92.0, "batch_reward": 1.49722265625, "critic_loss": 0.3189980963766575, "actor_loss": -133.34715228271483, "actor_target_entropy": -2.0, "actor_entropy": 0.6386118286848068, "alpha_loss": -0.00050644719065167, "alpha_value": 0.08625359630432816, "duration": 152.79859328269958, "step": 46000}
{"episode_reward": 902.0, "episode": 93.0, "batch_reward": 1.49715234375, "critic_loss": 0.3138083813786507, "actor_loss": -133.9797533569336, "actor_target_entropy": -2.0, "actor_entropy": 0.6553251591920852, "alpha_loss": 0.0005675705114845187, "alpha_value": 0.08621014183799756, "duration": 152.79140520095825, "step": 46500}
{"episode_reward": 878.0, "episode": 94.0, "batch_reward": 1.5033671875, "critic_loss": 0.3355103009939194, "actor_loss": -134.61657745361327, "actor_target_entropy": -2.0, "actor_entropy": 0.6525331805944443, "alpha_loss": 0.00010712920082733035, "alpha_value": 0.08609859850612428, "duration": 152.86185908317566, "step": 47000}
{"episode_reward": 875.0, "episode": 95.0, "batch_reward": 1.5044296875, "critic_loss": 0.3605871311724186, "actor_loss": -135.19823675537108, "actor_target_entropy": -2.0, "actor_entropy": 0.6417000498771668, "alpha_loss": 0.00012111643259413541, "alpha_value": 0.08608791580285095, "duration": 152.91660475730896, "step": 47500}
{"episode_reward": 902.0, "episode": 96.0, "batch_reward": 1.5116953125, "critic_loss": 0.30942558708786966, "actor_loss": -135.8522100830078, "actor_target_entropy": -2.0, "actor_entropy": 0.6318401041030883, "alpha_loss": -0.0020150710646994413, "alpha_value": 0.08634228875234079, "duration": 152.90666460990906, "step": 48000}
{"episode_reward": 900.0, "episode": 97.0, "batch_reward": 1.51344140625, "critic_loss": 0.32260930714011193, "actor_loss": -136.44359350585938, "actor_target_entropy": -2.0, "actor_entropy": 0.6284967287778854, "alpha_loss": 0.00023729096306487917, "alpha_value": 0.0865856871382158, "duration": 152.89431428909302, "step": 48500}
{"episode_reward": 907.0, "episode": 98.0, "batch_reward": 1.51066015625, "critic_loss": 0.331153146058321, "actor_loss": -137.00430041503907, "actor_target_entropy": -2.0, "actor_entropy": 0.6342047054767609, "alpha_loss": -0.00035201775818131866, "alpha_value": 0.08654717598607517, "duration": 152.90849542617798, "step": 49000}
{"episode_reward": 900.0, "episode": 99.0, "batch_reward": 1.516796875, "critic_loss": 0.31587850308418275, "actor_loss": -137.58982110595704, "actor_target_entropy": -2.0, "actor_entropy": 0.6274433299303055, "alpha_loss": -0.0014655303666368128, "alpha_value": 0.08674352476354064, "duration": 152.6855194568634, "step": 49500}
{"episode_reward": 887.0, "episode": 100.0, "batch_reward": 1.51933984375, "critic_loss": 0.3285166526436806, "actor_loss": -138.11795727539064, "actor_target_entropy": -2.0, "actor_entropy": 0.6253681862354279, "alpha_loss": -0.0004145442950539291, "alpha_value": 0.086857777821549, "step": 50000}
{"duration": 189.30788040161133, "step": 50000}
{"episode_reward": 915.0, "episode": 101.0, "batch_reward": 1.52034765625, "critic_loss": 0.311460840344429, "actor_loss": -138.66845300292968, "actor_target_entropy": -2.0, "actor_entropy": 0.6182535427808762, "alpha_loss": -0.0005869677835144102, "alpha_value": 0.08697720382102353, "duration": 152.77728986740112, "step": 50500}
{"episode_reward": 877.0, "episode": 102.0, "batch_reward": 1.52533984375, "critic_loss": 0.32528466698527336, "actor_loss": -139.20063122558594, "actor_target_entropy": -2.0, "actor_entropy": 0.6198256427049637, "alpha_loss": 0.001183142793364823, "alpha_value": 0.08697490184469096, "duration": 152.92280292510986, "step": 51000}
{"episode_reward": 888.0, "episode": 103.0, "batch_reward": 1.52633203125, "critic_loss": 0.32089709138870237, "actor_loss": -139.74974975585937, "actor_target_entropy": -2.0, "actor_entropy": 0.6191754673719406, "alpha_loss": 0.0005233294568024575, "alpha_value": 0.08674552499368209, "duration": 152.8453230857849, "step": 51500}
{"episode_reward": 892.0, "episode": 104.0, "batch_reward": 1.5300234375, "critic_loss": 0.34132926794886587, "actor_loss": -140.25393774414061, "actor_target_entropy": -2.0, "actor_entropy": 0.6247747882604598, "alpha_loss": 0.0014892462983261794, "alpha_value": 0.0865476954027519, "duration": 152.7897047996521, "step": 52000}
{"episode_reward": 880.0, "episode": 105.0, "batch_reward": 1.53480859375, "critic_loss": 0.3211422118842602, "actor_loss": -140.75621020507813, "actor_target_entropy": -2.0, "actor_entropy": 0.6264750895500183, "alpha_loss": 0.001106400987599045, "alpha_value": 0.08631575112701272, "duration": 152.9006004333496, "step": 52500}
{"episode_reward": 890.0, "episode": 106.0, "batch_reward": 1.5354609375, "critic_loss": 0.3078798710405827, "actor_loss": -141.25648168945312, "actor_target_entropy": -2.0, "actor_entropy": 0.6041027286052704, "alpha_loss": 0.0011180144650861621, "alpha_value": 0.08616191906194788, "duration": 152.90801978111267, "step": 53000}
{"episode_reward": 911.0, "episode": 107.0, "batch_reward": 1.5366015625, "critic_loss": 0.3134436602592468, "actor_loss": -141.71831115722657, "actor_target_entropy": -2.0, "actor_entropy": 0.624701509475708, "alpha_loss": 0.0010971060879528523, "alpha_value": 0.0858655417560642, "duration": 152.97526788711548, "step": 53500}
{"episode_reward": 896.0, "episode": 108.0, "batch_reward": 1.54105078125, "critic_loss": 0.3265150199532509, "actor_loss": -142.18845397949218, "actor_target_entropy": -2.0, "actor_entropy": 0.6255229367017746, "alpha_loss": -0.0006762916892766953, "alpha_value": 0.08574888568361193, "duration": 152.95069432258606, "step": 54000}
{"episode_reward": 906.0, "episode": 109.0, "batch_reward": 1.5444140625, "critic_loss": 0.3286500211954117, "actor_loss": -142.6550256958008, "actor_target_entropy": -2.0, "actor_entropy": 0.6206357247829437, "alpha_loss": -0.0003993176314979792, "alpha_value": 0.08587021368249476, "duration": 152.8467082977295, "step": 54500}
{"episode_reward": 902.0, "episode": 110.0, "batch_reward": 1.5440390625, "critic_loss": 0.31372639334201813, "actor_loss": -143.11955346679687, "actor_target_entropy": -2.0, "actor_entropy": 0.6093876715898514, "alpha_loss": -0.0009060985422693193, "alpha_value": 0.08602527637762025, "step": 55000}
{"duration": 189.47274565696716, "step": 55000}
{"episode_reward": 905.0, "episode": 111.0, "batch_reward": 1.545828125, "critic_loss": 0.310698119699955, "actor_loss": -143.5627049560547, "actor_target_entropy": -2.0, "actor_entropy": 0.6036372233629227, "alpha_loss": 0.00018282718723639847, "alpha_value": 0.08614410061925246, "duration": 153.33715772628784, "step": 55500}
{"episode_reward": 901.0, "episode": 112.0, "batch_reward": 1.5504140625, "critic_loss": 0.3091777704656124, "actor_loss": -144.01350817871094, "actor_target_entropy": -2.0, "actor_entropy": 0.6059817506074905, "alpha_loss": 0.0012607510895468294, "alpha_value": 0.08599990999401472, "duration": 152.9997956752777, "step": 56000}
{"episode_reward": 908.0, "episode": 113.0, "batch_reward": 1.5499609375, "critic_loss": 0.30706301057338714, "actor_loss": -144.4592982788086, "actor_target_entropy": -2.0, "actor_entropy": 0.6119331374168396, "alpha_loss": 0.0016147473843302579, "alpha_value": 0.08565468893194905, "duration": 152.97790670394897, "step": 56500}
{"episode_reward": 902.0, "episode": 114.0, "batch_reward": 1.553515625, "critic_loss": 0.30042841511964796, "actor_loss": -144.89464672851562, "actor_target_entropy": -2.0, "actor_entropy": 0.6047937873601913, "alpha_loss": 0.0009915517368353902, "alpha_value": 0.08534505133121699, "duration": 152.92837357521057, "step": 57000}
{"episode_reward": 893.0, "episode": 115.0, "batch_reward": 1.55635546875, "critic_loss": 0.31549508875608445, "actor_loss": -145.28655651855468, "actor_target_entropy": -2.0, "actor_entropy": 0.6055386620759964, "alpha_loss": 0.00031061232066713275, "alpha_value": 0.08529109258078499, "duration": 153.04236841201782, "step": 57500}
{"episode_reward": 919.0, "episode": 116.0, "batch_reward": 1.558625, "critic_loss": 0.30789774814248083, "actor_loss": -145.70460540771484, "actor_target_entropy": -2.0, "actor_entropy": 0.6191763954162598, "alpha_loss": 0.000985391420777887, "alpha_value": 0.0851939013259179, "duration": 152.962660074234, "step": 58000}
{"episode_reward": 909.0, "episode": 117.0, "batch_reward": 1.563640625, "critic_loss": 0.2953385272026062, "actor_loss": -146.12635437011718, "actor_target_entropy": -2.0, "actor_entropy": 0.6077013918161392, "alpha_loss": 0.001088758515426889, "alpha_value": 0.08486799566958568, "duration": 152.94090485572815, "step": 58500}
{"episode_reward": 914.0, "episode": 118.0, "batch_reward": 1.5622890625, "critic_loss": 0.30544314298033715, "actor_loss": -146.53174353027345, "actor_target_entropy": -2.0, "actor_entropy": 0.6062734378576279, "alpha_loss": 0.0005608641530852764, "alpha_value": 0.0847340437348353, "duration": 152.83453750610352, "step": 59000}
{"episode_reward": 900.0, "episode": 119.0, "batch_reward": 1.563765625, "critic_loss": 0.32495835596323014, "actor_loss": -146.88447680664063, "actor_target_entropy": -2.0, "actor_entropy": 0.608191858291626, "alpha_loss": 0.0004358502000104636, "alpha_value": 0.08466919996264266, "duration": 152.78754329681396, "step": 59500}
{"episode_reward": 922.0, "episode": 120.0, "batch_reward": 1.56664453125, "critic_loss": 0.30032170644402506, "actor_loss": -147.28046301269532, "actor_target_entropy": -2.0, "actor_entropy": 0.5929703598022461, "alpha_loss": 0.00039367298409342765, "alpha_value": 0.08449990562293491, "step": 60000}
{"duration": 189.3689591884613, "step": 60000}
{"episode_reward": 859.0, "episode": 121.0, "batch_reward": 1.57059375, "critic_loss": 0.3205414841771126, "actor_loss": -147.6674867553711, "actor_target_entropy": -2.0, "actor_entropy": 0.612182769536972, "alpha_loss": 0.0007584755492862314, "alpha_value": 0.08446857849114524, "duration": 152.80119967460632, "step": 60500}
{"episode_reward": 900.0, "episode": 122.0, "batch_reward": 1.57203515625, "critic_loss": 0.3236490247249603, "actor_loss": -148.0209158935547, "actor_target_entropy": -2.0, "actor_entropy": 0.5937540521621704, "alpha_loss": 0.001489890676457435, "alpha_value": 0.084120887106307, "duration": 152.95978093147278, "step": 61000}
{"episode_reward": 893.0, "episode": 123.0, "batch_reward": 1.57242578125, "critic_loss": 0.3034160180687904, "actor_loss": -148.38555279541015, "actor_target_entropy": -2.0, "actor_entropy": 0.5979320487976074, "alpha_loss": 0.00018152596172876656, "alpha_value": 0.08413354411568143, "duration": 152.9597578048706, "step": 61500}
{"episode_reward": 893.0, "episode": 124.0, "batch_reward": 1.57407421875, "critic_loss": 0.30715090987086296, "actor_loss": -148.7258681640625, "actor_target_entropy": -2.0, "actor_entropy": 0.5889609222412109, "alpha_loss": 0.0002663162099197507, "alpha_value": 0.08404625508896241, "duration": 152.9587664604187, "step": 62000}
{"episode_reward": 926.0, "episode": 125.0, "batch_reward": 1.57723046875, "critic_loss": 0.3125931767821312, "actor_loss": -149.05337634277345, "actor_target_entropy": -2.0, "actor_entropy": 0.5841247398853302, "alpha_loss": 0.0002155355354771018, "alpha_value": 0.08382847359083104, "duration": 152.8861105442047, "step": 62500}
{"episode_reward": 917.0, "episode": 126.0, "batch_reward": 1.57562109375, "critic_loss": 0.3076849723160267, "actor_loss": -149.37912927246094, "actor_target_entropy": -2.0, "actor_entropy": 0.5944336737394333, "alpha_loss": -0.0006527001205831766, "alpha_value": 0.08404993685982294, "duration": 152.9764838218689, "step": 63000}
{"episode_reward": 857.0, "episode": 127.0, "batch_reward": 1.57913671875, "critic_loss": 0.31692023485898974, "actor_loss": -149.75002282714843, "actor_target_entropy": -2.0, "actor_entropy": 0.5706148583889008, "alpha_loss": 0.0002828370309434831, "alpha_value": 0.08401947672761441, "duration": 152.95676565170288, "step": 63500}
{"episode_reward": 905.0, "episode": 128.0, "batch_reward": 1.58301171875, "critic_loss": 0.2997332956492901, "actor_loss": -150.07293634033203, "actor_target_entropy": -2.0, "actor_entropy": 0.5856602948904037, "alpha_loss": 0.001815610679332167, "alpha_value": 0.08382647879975436, "duration": 152.7640299797058, "step": 64000}
{"episode_reward": 917.0, "episode": 129.0, "batch_reward": 1.58342578125, "critic_loss": 0.3469035576283932, "actor_loss": -150.37316912841797, "actor_target_entropy": -2.0, "actor_entropy": 0.5665314902067184, "alpha_loss": -0.00015086576947942376, "alpha_value": 0.08371115714511328, "duration": 152.85377764701843, "step": 64500}
{"episode_reward": 892.0, "episode": 130.0, "batch_reward": 1.5822890625, "critic_loss": 0.32061701545119287, "actor_loss": -150.6345559082031, "actor_target_entropy": -2.0, "actor_entropy": 0.5740012419223786, "alpha_loss": -0.0002890517341438681, "alpha_value": 0.0835759813190947, "step": 65000}
{"duration": 189.32961750030518, "step": 65000}
{"episode_reward": 898.0, "episode": 131.0, "batch_reward": 1.587359375, "critic_loss": 0.3169795344173908, "actor_loss": -150.95639501953124, "actor_target_entropy": -2.0, "actor_entropy": 0.5659745062589645, "alpha_loss": 0.0002976635536178946, "alpha_value": 0.08373482864072716, "duration": 148.79608511924744, "step": 65500}
{"episode_reward": 904.0, "episode": 132.0, "batch_reward": 1.5858984375, "critic_loss": 0.31994611233472825, "actor_loss": -151.25071203613282, "actor_target_entropy": -2.0, "actor_entropy": 0.5588264284133911, "alpha_loss": 0.0008787310412153601, "alpha_value": 0.08356083098275349, "duration": 152.62972927093506, "step": 66000}
{"episode_reward": 905.0, "episode": 133.0, "batch_reward": 1.5891953125, "critic_loss": 0.31746462514996526, "actor_loss": -151.57297290039062, "actor_target_entropy": -2.0, "actor_entropy": 0.5589110637903214, "alpha_loss": 0.0008230335672851652, "alpha_value": 0.08329690089428597, "duration": 153.16157722473145, "step": 66500}
{"episode_reward": 926.0, "episode": 134.0, "batch_reward": 1.5906015625, "critic_loss": 0.33312004923820493, "actor_loss": -151.90094714355467, "actor_target_entropy": -2.0, "actor_entropy": 0.5505286655426025, "alpha_loss": -0.00047969208331778647, "alpha_value": 0.08337036991108025, "duration": 153.06319427490234, "step": 67000}
{"episode_reward": 911.0, "episode": 135.0, "batch_reward": 1.5913984375, "critic_loss": 0.30258431056141855, "actor_loss": -152.1721824951172, "actor_target_entropy": -2.0, "actor_entropy": 0.5548484958410264, "alpha_loss": 0.0007950504296459258, "alpha_value": 0.0833142380965587, "duration": 153.10048913955688, "step": 67500}
{"episode_reward": 917.0, "episode": 136.0, "batch_reward": 1.59376171875, "critic_loss": 0.29681013071537016, "actor_loss": -152.494529296875, "actor_target_entropy": -2.0, "actor_entropy": 0.5658262625932694, "alpha_loss": 0.0005959660545922816, "alpha_value": 0.08310685399902623, "duration": 153.0856487751007, "step": 68000}
{"episode_reward": 933.0, "episode": 137.0, "batch_reward": 1.59607421875, "critic_loss": 0.3114129937291145, "actor_loss": -152.81638842773438, "actor_target_entropy": -2.0, "actor_entropy": 0.5390225119590759, "alpha_loss": -3.0421413015574217e-05, "alpha_value": 0.08303777511409155, "duration": 153.06216526031494, "step": 68500}
{"episode_reward": 919.0, "episode": 138.0, "batch_reward": 1.59894921875, "critic_loss": 0.29670090207457545, "actor_loss": -153.0947053222656, "actor_target_entropy": -2.0, "actor_entropy": 0.5280707151889801, "alpha_loss": 0.0005808051754720509, "alpha_value": 0.0829940441700135, "duration": 152.93501162528992, "step": 69000}
{"episode_reward": 935.0, "episode": 139.0, "batch_reward": 1.60315625, "critic_loss": 0.30962675929069516, "actor_loss": -153.39465716552735, "actor_target_entropy": -2.0, "actor_entropy": 0.5434521847963333, "alpha_loss": -0.0005123799580615014, "alpha_value": 0.08303350959813174, "duration": 153.07618951797485, "step": 69500}
{"episode_reward": 929.0, "episode": 140.0, "batch_reward": 1.60534765625, "critic_loss": 0.27791944816708564, "actor_loss": -153.7143773803711, "actor_target_entropy": -2.0, "actor_entropy": 0.5404717041254044, "alpha_loss": 9.511549351736903e-05, "alpha_value": 0.08312902301141437, "step": 70000}
{"duration": 189.51927256584167, "step": 70000}
{"episode_reward": 920.0, "episode": 141.0, "batch_reward": 1.60421484375, "critic_loss": 0.3084423534274101, "actor_loss": -154.0018994140625, "actor_target_entropy": -2.0, "actor_entropy": 0.5295229198932647, "alpha_loss": 0.0005169329531490803, "alpha_value": 0.08305401528640044, "duration": 152.71023988723755, "step": 70500}
{"episode_reward": 931.0, "episode": 142.0, "batch_reward": 1.60512109375, "critic_loss": 0.3042870677411556, "actor_loss": -154.2891771850586, "actor_target_entropy": -2.0, "actor_entropy": 0.5458804627656937, "alpha_loss": 1.1146443197503685e-05, "alpha_value": 0.0829371147054165, "duration": 152.8101282119751, "step": 71000}
{"episode_reward": 943.0, "episode": 143.0, "batch_reward": 1.60830859375, "critic_loss": 0.2945558481812477, "actor_loss": -154.55708392333983, "actor_target_entropy": -2.0, "actor_entropy": 0.5331910374164581, "alpha_loss": 0.0002916199848987162, "alpha_value": 0.08284473713334115, "duration": 152.91956686973572, "step": 71500}
{"episode_reward": 932.0, "episode": 144.0, "batch_reward": 1.609953125, "critic_loss": 0.31512183776497843, "actor_loss": -154.83758184814454, "actor_target_entropy": -2.0, "actor_entropy": 0.537546068906784, "alpha_loss": -0.00063987842714414, "alpha_value": 0.08299387289511118, "duration": 152.847815990448, "step": 72000}
{"episode_reward": 942.0, "episode": 145.0, "batch_reward": 1.60963671875, "critic_loss": 0.2875209693610668, "actor_loss": -155.11450512695313, "actor_target_entropy": -2.0, "actor_entropy": 0.5310862510204315, "alpha_loss": -0.0005009362469427287, "alpha_value": 0.08305312348973973, "duration": 152.93455958366394, "step": 72500}
{"episode_reward": 912.0, "episode": 146.0, "batch_reward": 1.61350390625, "critic_loss": 0.297644169151783, "actor_loss": -155.39780981445313, "actor_target_entropy": -2.0, "actor_entropy": 0.537060060620308, "alpha_loss": -0.0010352901015430688, "alpha_value": 0.08330295743489312, "duration": 152.95965957641602, "step": 73000}
{"episode_reward": 933.0, "episode": 147.0, "batch_reward": 1.61526171875, "critic_loss": 0.28755364218354224, "actor_loss": -155.6579869995117, "actor_target_entropy": -2.0, "actor_entropy": 0.5106342772245407, "alpha_loss": -0.0009824299779720605, "alpha_value": 0.0834809733038525, "duration": 152.79670333862305, "step": 73500}
{"episode_reward": 929.0, "episode": 148.0, "batch_reward": 1.61709375, "critic_loss": 0.3031033134460449, "actor_loss": -155.90699420166015, "actor_target_entropy": -2.0, "actor_entropy": 0.5061788558959961, "alpha_loss": -0.0008744393945671618, "alpha_value": 0.08367469886808537, "duration": 152.73526573181152, "step": 74000}
{"episode_reward": 921.0, "episode": 149.0, "batch_reward": 1.6177265625, "critic_loss": 0.29388644352555277, "actor_loss": -156.1300308227539, "actor_target_entropy": -2.0, "actor_entropy": 0.5151250731945037, "alpha_loss": -0.0013437651824206114, "alpha_value": 0.08395327653010771, "duration": 152.80983591079712, "step": 74500}
{"episode_reward": 939.0, "episode": 150.0, "batch_reward": 1.620421875, "critic_loss": 0.3023538179695606, "actor_loss": -156.4000845336914, "actor_target_entropy": -2.0, "actor_entropy": 0.49637313175201414, "alpha_loss": -0.0007494656117632985, "alpha_value": 0.08406041208137578, "step": 75000}
{"duration": 189.27808165550232, "step": 75000}
{"episode_reward": 906.0, "episode": 151.0, "batch_reward": 1.61822265625, "critic_loss": 0.3082631644308567, "actor_loss": -156.62754821777344, "actor_target_entropy": -2.0, "actor_entropy": 0.5305906056165696, "alpha_loss": -0.0018339234893210233, "alpha_value": 0.0843097092198362, "duration": 152.92210483551025, "step": 75500}
{"episode_reward": 935.0, "episode": 152.0, "batch_reward": 1.62319140625, "critic_loss": 0.3004095984995365, "actor_loss": -156.8637055053711, "actor_target_entropy": -2.0, "actor_entropy": 0.5074789303541184, "alpha_loss": -0.0009110360969789326, "alpha_value": 0.08471997696121612, "duration": 153.1451416015625, "step": 76000}
{"episode_reward": 933.0, "episode": 153.0, "batch_reward": 1.62308984375, "critic_loss": 0.2955659223198891, "actor_loss": -157.10128009033204, "actor_target_entropy": -2.0, "actor_entropy": 0.4969206817150116, "alpha_loss": -0.001770121382083744, "alpha_value": 0.08490109705308675, "duration": 152.97018694877625, "step": 76500}
{"episode_reward": 944.0, "episode": 154.0, "batch_reward": 1.62403125, "critic_loss": 0.30076982206106184, "actor_loss": -157.3286704711914, "actor_target_entropy": -2.0, "actor_entropy": 0.4888203078508377, "alpha_loss": -0.0018263635330367832, "alpha_value": 0.08521446585291162, "duration": 152.88020849227905, "step": 77000}
{"episode_reward": 940.0, "episode": 155.0, "batch_reward": 1.62612109375, "critic_loss": 0.2928376662135124, "actor_loss": -157.5717268066406, "actor_target_entropy": -2.0, "actor_entropy": 0.48943151712417604, "alpha_loss": -0.0012644440201111137, "alpha_value": 0.08563778978899642, "duration": 153.02558255195618, "step": 77500}
{"episode_reward": 941.0, "episode": 156.0, "batch_reward": 1.629015625, "critic_loss": 0.3146506656706333, "actor_loss": -157.7873073120117, "actor_target_entropy": -2.0, "actor_entropy": 0.48278924739360807, "alpha_loss": -0.0022588518876582382, "alpha_value": 0.08605043723492756, "duration": 152.8768711090088, "step": 78000}
{"episode_reward": 935.0, "episode": 157.0, "batch_reward": 1.63129296875, "critic_loss": 0.29708941397070887, "actor_loss": -158.0129260253906, "actor_target_entropy": -2.0, "actor_entropy": 0.4795505452156067, "alpha_loss": -0.002689617285039276, "alpha_value": 0.08652193215233771, "duration": 153.0188536643982, "step": 78500}
{"episode_reward": 926.0, "episode": 158.0, "batch_reward": 1.632828125, "critic_loss": 0.2978271159827709, "actor_loss": -158.23399243164062, "actor_target_entropy": -2.0, "actor_entropy": 0.4907817474603653, "alpha_loss": -0.0016657893313094974, "alpha_value": 0.08704748065021765, "duration": 152.72496128082275, "step": 79000}
{"episode_reward": 927.0, "episode": 159.0, "batch_reward": 1.63275390625, "critic_loss": 0.29743075427412985, "actor_loss": -158.39012030029298, "actor_target_entropy": -2.0, "actor_entropy": 0.5113204625844956, "alpha_loss": 0.00029832609137520196, "alpha_value": 0.08720780726766807, "duration": 152.9244363307953, "step": 79500}
{"episode_reward": 936.0, "episode": 160.0, "batch_reward": 1.6327265625, "critic_loss": 0.2895444910824299, "actor_loss": -158.60018341064452, "actor_target_entropy": -2.0, "actor_entropy": 0.491459504365921, "alpha_loss": -0.00017942950944416225, "alpha_value": 0.08712688794419458, "step": 80000}
{"duration": 189.25394582748413, "step": 80000}
{"episode_reward": 931.0, "episode": 161.0, "batch_reward": 1.63629296875, "critic_loss": 0.28142771077156065, "actor_loss": -158.84956616210937, "actor_target_entropy": -2.0, "actor_entropy": 0.5071921558380127, "alpha_loss": 0.00010035897186025977, "alpha_value": 0.0871695468205989, "duration": 152.9985692501068, "step": 80500}
{"episode_reward": 930.0, "episode": 162.0, "batch_reward": 1.63852734375, "critic_loss": 0.28084466415643694, "actor_loss": -159.03147235107423, "actor_target_entropy": -2.0, "actor_entropy": 0.5089890621900558, "alpha_loss": -0.0008862369393464178, "alpha_value": 0.08730371723934381, "duration": 152.92067575454712, "step": 81000}
{"episode_reward": 944.0, "episode": 163.0, "batch_reward": 1.64003515625, "critic_loss": 0.28760247632861136, "actor_loss": -159.2433397216797, "actor_target_entropy": -2.0, "actor_entropy": 0.5092617425918579, "alpha_loss": -0.0009229541635140776, "alpha_value": 0.08738505899460507, "duration": 152.98899674415588, "step": 81500}
{"episode_reward": 946.0, "episode": 164.0, "batch_reward": 1.643375, "critic_loss": 0.2977878544926643, "actor_loss": -159.45734838867187, "actor_target_entropy": -2.0, "actor_entropy": 0.5123135746717453, "alpha_loss": -0.0007681287415325642, "alpha_value": 0.0876470670235753, "duration": 152.98388957977295, "step": 82000}
{"episode_reward": 939.0, "episode": 165.0, "batch_reward": 1.63992578125, "critic_loss": 0.287512664347887, "actor_loss": -159.6545437011719, "actor_target_entropy": -2.0, "actor_entropy": 0.5043534647226333, "alpha_loss": 6.860799947753549e-05, "alpha_value": 0.0877465526013089, "duration": 152.94068551063538, "step": 82500}
{"episode_reward": 940.0, "episode": 166.0, "batch_reward": 1.6418984375, "critic_loss": 0.2777325114607811, "actor_loss": -159.84757232666016, "actor_target_entropy": -2.0, "actor_entropy": 0.49167540442943575, "alpha_loss": -0.0013974697515368461, "alpha_value": 0.08786416347088155, "duration": 152.90610527992249, "step": 83000}
{"episode_reward": 928.0, "episode": 167.0, "batch_reward": 1.6431484375, "critic_loss": 0.2970829091668129, "actor_loss": -160.02990899658204, "actor_target_entropy": -2.0, "actor_entropy": 0.49358582925796507, "alpha_loss": -0.0010027998588047922, "alpha_value": 0.08814128191516002, "duration": 152.8287296295166, "step": 83500}
{"episode_reward": 932.0, "episode": 168.0, "batch_reward": 1.6444453125, "critic_loss": 0.2766454719305039, "actor_loss": -160.21441259765626, "actor_target_entropy": -2.0, "actor_entropy": 0.4960153856277466, "alpha_loss": -0.0009843556568957866, "alpha_value": 0.0882531520330529, "duration": 152.9572401046753, "step": 84000}
{"episode_reward": 940.0, "episode": 169.0, "batch_reward": 1.64726171875, "critic_loss": 0.2842864326238632, "actor_loss": -160.37413500976564, "actor_target_entropy": -2.0, "actor_entropy": 0.492363091468811, "alpha_loss": -0.0005260204095393419, "alpha_value": 0.0885539752669275, "duration": 152.99547815322876, "step": 84500}
{"episode_reward": 923.0, "episode": 170.0, "batch_reward": 1.6497109375, "critic_loss": 0.27811161133646967, "actor_loss": -160.580642578125, "actor_target_entropy": -2.0, "actor_entropy": 0.4877848958969116, "alpha_loss": -0.0013034341265447439, "alpha_value": 0.08870123395410355, "step": 85000}
{"duration": 189.4222390651703, "step": 85000}
{"episode_reward": 939.0, "episode": 171.0, "batch_reward": 1.6507734375, "critic_loss": 0.3038006731271744, "actor_loss": -160.75850555419922, "actor_target_entropy": -2.0, "actor_entropy": 0.49264988327026366, "alpha_loss": -4.9557071179151535e-05, "alpha_value": 0.08882605965240854, "duration": 152.83502984046936, "step": 85500}
{"episode_reward": 936.0, "episode": 172.0, "batch_reward": 1.6528828125, "critic_loss": 0.2864040520489216, "actor_loss": -160.91019018554687, "actor_target_entropy": -2.0, "actor_entropy": 0.4881123884916306, "alpha_loss": -0.0009978518113493919, "alpha_value": 0.08899553179365952, "duration": 152.99940061569214, "step": 86000}
{"episode_reward": 939.0, "episode": 173.0, "batch_reward": 1.6548984375, "critic_loss": 0.28229472795128824, "actor_loss": -161.06141522216797, "actor_target_entropy": -2.0, "actor_entropy": 0.4880883408784866, "alpha_loss": -0.0004313996620476246, "alpha_value": 0.08909937936628087, "duration": 152.905748128891, "step": 86500}
{"episode_reward": 940.0, "episode": 174.0, "batch_reward": 1.6531171875, "critic_loss": 0.28618055510520934, "actor_loss": -161.22442584228514, "actor_target_entropy": -2.0, "actor_entropy": 0.4783639483451843, "alpha_loss": -0.0017327379579655825, "alpha_value": 0.08930829511971465, "duration": 152.96639490127563, "step": 87000}
{"episode_reward": 943.0, "episode": 175.0, "batch_reward": 1.658015625, "critic_loss": 0.28008387073874474, "actor_loss": -161.40292150878906, "actor_target_entropy": -2.0, "actor_entropy": 0.47874236714839935, "alpha_loss": -0.0010605233269743621, "alpha_value": 0.08952035792531256, "duration": 152.91545629501343, "step": 87500}
{"episode_reward": 939.0, "episode": 176.0, "batch_reward": 1.657765625, "critic_loss": 0.2740928561985493, "actor_loss": -161.55967864990234, "actor_target_entropy": -2.0, "actor_entropy": 0.4789525506496429, "alpha_loss": -0.0006226559784263372, "alpha_value": 0.08982068131512878, "duration": 152.87339234352112, "step": 88000}
{"episode_reward": 942.0, "episode": 177.0, "batch_reward": 1.6571875, "critic_loss": 0.291775859028101, "actor_loss": -161.6873335571289, "actor_target_entropy": -2.0, "actor_entropy": 0.5038605859279632, "alpha_loss": 0.0007164677353575826, "alpha_value": 0.08987475321071729, "duration": 152.74944519996643, "step": 88500}
{"episode_reward": 949.0, "episode": 178.0, "batch_reward": 1.659, "critic_loss": 0.2760204799473286, "actor_loss": -161.84660888671874, "actor_target_entropy": -2.0, "actor_entropy": 0.49471670615673063, "alpha_loss": 0.0012779184277169407, "alpha_value": 0.08964347920077727, "duration": 152.97600531578064, "step": 89000}
{"episode_reward": 923.0, "episode": 179.0, "batch_reward": 1.65845703125, "critic_loss": 0.2655047076642513, "actor_loss": -161.9942240600586, "actor_target_entropy": -2.0, "actor_entropy": 0.5017099961042404, "alpha_loss": 0.0013107662429101764, "alpha_value": 0.08937536402659052, "duration": 152.84493279457092, "step": 89500}
{"episode_reward": 939.0, "episode": 180.0, "batch_reward": 1.66266015625, "critic_loss": 0.2671094234585762, "actor_loss": -162.1540203857422, "actor_target_entropy": -2.0, "actor_entropy": 0.4976524728536606, "alpha_loss": 0.001617369674379006, "alpha_value": 0.08890822692921282, "step": 90000}
{"duration": 189.38251662254333, "step": 90000}
{"episode_reward": 948.0, "episode": 181.0, "batch_reward": 1.66196484375, "critic_loss": 0.2610091925561428, "actor_loss": -162.32113610839843, "actor_target_entropy": -2.0, "actor_entropy": 0.48901826214790345, "alpha_loss": 0.0014243858237750829, "alpha_value": 0.08866461137112712, "duration": 152.83727025985718, "step": 90500}
{"episode_reward": 937.0, "episode": 182.0, "batch_reward": 1.6619375, "critic_loss": 0.27154612624645236, "actor_loss": -162.47191900634766, "actor_target_entropy": -2.0, "actor_entropy": 0.4828003643751144, "alpha_loss": 0.00041056591877713797, "alpha_value": 0.08853347003050113, "duration": 152.86679458618164, "step": 91000}
{"episode_reward": 947.0, "episode": 183.0, "batch_reward": 1.66824609375, "critic_loss": 0.2756390239596367, "actor_loss": -162.64077893066406, "actor_target_entropy": -2.0, "actor_entropy": 0.5000792104005813, "alpha_loss": 0.0006069816132076084, "alpha_value": 0.08838492533196775, "duration": 152.94863152503967, "step": 91500}
{"episode_reward": 923.0, "episode": 184.0, "batch_reward": 1.66642578125, "critic_loss": 0.30089176428318026, "actor_loss": -162.76694262695312, "actor_target_entropy": -2.0, "actor_entropy": 0.4995021917819977, "alpha_loss": 0.0023006168054416774, "alpha_value": 0.08798776626141959, "duration": 152.89472818374634, "step": 92000}
{"episode_reward": 929.0, "episode": 185.0, "batch_reward": 1.66744140625, "critic_loss": 0.25836922428011894, "actor_loss": -162.92405926513672, "actor_target_entropy": -2.0, "actor_entropy": 0.48358576321601865, "alpha_loss": -0.0017561279439833016, "alpha_value": 0.08800661613926268, "duration": 152.87611436843872, "step": 92500}
{"episode_reward": 934.0, "episode": 186.0, "batch_reward": 1.666046875, "critic_loss": 0.26149522855877877, "actor_loss": -163.06516485595702, "actor_target_entropy": -2.0, "actor_entropy": 0.4974775325059891, "alpha_loss": 0.0013838028605096043, "alpha_value": 0.08804862760252045, "duration": 153.01851773262024, "step": 93000}
{"episode_reward": 943.0, "episode": 187.0, "batch_reward": 1.6709140625, "critic_loss": 0.2614888496100903, "actor_loss": -163.21616479492187, "actor_target_entropy": -2.0, "actor_entropy": 0.4772559162378311, "alpha_loss": 0.002199773360742256, "alpha_value": 0.08764620814607041, "duration": 152.78509855270386, "step": 93500}
{"episode_reward": 945.0, "episode": 188.0, "batch_reward": 1.6720234375, "critic_loss": 0.2636418772637844, "actor_loss": -163.37141552734374, "actor_target_entropy": -2.0, "actor_entropy": 0.48316014766693116, "alpha_loss": 0.002711813540197909, "alpha_value": 0.08714699775334463, "duration": 152.88166189193726, "step": 94000}
{"episode_reward": 950.0, "episode": 189.0, "batch_reward": 1.67160546875, "critic_loss": 0.2613948070406914, "actor_loss": -163.50038873291015, "actor_target_entropy": -2.0, "actor_entropy": 0.48028636276721953, "alpha_loss": 0.0014996061390265822, "alpha_value": 0.08674822908104021, "duration": 152.8605558872223, "step": 94500}
{"episode_reward": 942.0, "episode": 190.0, "batch_reward": 1.67138671875, "critic_loss": 0.2636362802684307, "actor_loss": -163.66367065429688, "actor_target_entropy": -2.0, "actor_entropy": 0.4718363808393478, "alpha_loss": 0.00016593174100853502, "alpha_value": 0.08655934649961912, "step": 95000}
{"duration": 189.67280888557434, "step": 95000}
{"episode_reward": 945.0, "episode": 191.0, "batch_reward": 1.67257421875, "critic_loss": 0.2798754286468029, "actor_loss": -163.80935864257813, "actor_target_entropy": -2.0, "actor_entropy": 0.4812744257450104, "alpha_loss": 0.0009606289230287075, "alpha_value": 0.08642989590094656, "duration": 152.87287092208862, "step": 95500}
{"episode_reward": 939.0, "episode": 192.0, "batch_reward": 1.67421875, "critic_loss": 0.26605995535850524, "actor_loss": -163.94677508544922, "actor_target_entropy": -2.0, "actor_entropy": 0.4815184177160263, "alpha_loss": 0.002729243469890207, "alpha_value": 0.08607036166281197, "duration": 152.79557847976685, "step": 96000}
{"episode_reward": 945.0, "episode": 193.0, "batch_reward": 1.67716796875, "critic_loss": 0.2568513172864914, "actor_loss": -164.10181884765626, "actor_target_entropy": -2.0, "actor_entropy": 0.4671301939487457, "alpha_loss": 0.0008887133104726672, "alpha_value": 0.08568158335988914, "duration": 152.8539595603943, "step": 96500}
{"episode_reward": 941.0, "episode": 194.0, "batch_reward": 1.6784375, "critic_loss": 0.2527753781378269, "actor_loss": -164.21883880615235, "actor_target_entropy": -2.0, "actor_entropy": 0.46679561233520506, "alpha_loss": 0.00044969847472384574, "alpha_value": 0.08556935331221781, "duration": 152.83643317222595, "step": 97000}
{"episode_reward": 923.0, "episode": 195.0, "batch_reward": 1.67609375, "critic_loss": 0.26013692781329156, "actor_loss": -164.37234606933595, "actor_target_entropy": -2.0, "actor_entropy": 0.4619907186031342, "alpha_loss": -0.0005927734079305083, "alpha_value": 0.0855855717399137, "duration": 152.8588547706604, "step": 97500}
{"episode_reward": 932.0, "episode": 196.0, "batch_reward": 1.67926953125, "critic_loss": 0.2712317953705788, "actor_loss": -164.50104095458985, "actor_target_entropy": -2.0, "actor_entropy": 0.47748270905017853, "alpha_loss": 0.0009130754047073424, "alpha_value": 0.08557708587644589, "duration": 152.9243185520172, "step": 98000}
{"episode_reward": 939.0, "episode": 197.0, "batch_reward": 1.680828125, "critic_loss": 0.25931398665905, "actor_loss": -164.64850122070314, "actor_target_entropy": -2.0, "actor_entropy": 0.4708745412826538, "alpha_loss": 0.0024557614093646406, "alpha_value": 0.08516988400091034, "duration": 151.97012853622437, "step": 98500}
{"episode_reward": 931.0, "episode": 198.0, "batch_reward": 1.68203515625, "critic_loss": 0.23459568950533866, "actor_loss": -164.8126348876953, "actor_target_entropy": -2.0, "actor_entropy": 0.45208140802383423, "alpha_loss": 0.00017864872119389475, "alpha_value": 0.08484422549435935, "duration": 178.23483777046204, "step": 99000}
{"episode_reward": 944.0, "episode": 199.0, "batch_reward": 1.68179296875, "critic_loss": 0.24298242899775505, "actor_loss": -164.95984143066406, "actor_target_entropy": -2.0, "actor_entropy": 0.448986425280571, "alpha_loss": 0.0018185602803714573, "alpha_value": 0.08476232175384762, "duration": 163.68205094337463, "step": 99500}
{"episode_reward": 923.0, "episode": 200.0, "batch_reward": 1.682329502755511, "critic_loss": 0.26607571154056425, "actor_loss": -165.07849517822265, "actor_target_entropy": -2.0, "actor_entropy": 0.4677735171318054, "alpha_loss": 0.00041097466996870935, "alpha_value": 0.08442557768193257, "step": 99999}
