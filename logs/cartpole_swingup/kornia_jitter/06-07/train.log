{"episode_reward": 0.0, "episode": 1.0, "duration": 20.357122898101807, "step": 125}
{"episode_reward": 188.54858664024, "episode": 2.0, "duration": 0.8055329322814941, "step": 250}
{"episode_reward": 148.42677041475667, "episode": 3.0, "duration": 0.805518388748169, "step": 375}
{"episode_reward": 96.18193741935099, "episode": 4.0, "duration": 0.8018290996551514, "step": 500}
{"episode_reward": 82.30982819659563, "episode": 5.0, "duration": 0.8034791946411133, "step": 625}
{"episode_reward": 198.98424208864233, "episode": 6.0, "duration": 0.806506872177124, "step": 750}
{"episode_reward": 159.49821390562659, "episode": 7.0, "duration": 0.8033449649810791, "step": 875}
{"episode_reward": 113.95622178975879, "episode": 8.0, "duration": 0.8063082695007324, "step": 1000}
{"episode_reward": 89.62519938559855, "episode": 9.0, "Q1 loss": 1.7193062086105346, "Q2 loss": 1.7312467613220215, "Mean Target Q": 1.9351526265144348, "Mean Q1": 1.9205447159260511, "Mean Q2": 1.921427109003067, "critic_loss": 3.450552972793579, "batch_reward": 1.108465678691864, "actor_loss": -1.950704935051146, "actor_target_entropy": -1.0, "actor_entropy": 1.0957890635445005, "alpha_loss": 0.11628421945201736, "alpha_value": 0.09980220274397204, "duration": 138.30088829994202, "step": 1125}
{"episode_reward": 227.2990789668967, "episode": 10.0, "Q1 loss": 1.4811814885139465, "Q2 loss": 1.4814548907279967, "Mean Target Q": 2.8923327713012696, "Mean Q1": 2.8879620246887208, "Mean Q2": 2.8875268440246584, "critic_loss": 2.962636366844177, "batch_reward": 1.1765293960571288, "actor_loss": -2.96202749975266, "actor_target_entropy": -1.0, "actor_entropy": 1.1811108723763497, "alpha_loss": 0.13561132490154235, "alpha_value": 0.09921379926723875, "duration": 132.0052056312561, "step": 1250}
{"episode_reward": 204.55209142688713, "episode": 11.0, "Q1 loss": 0.7206072545051575, "Q2 loss": 0.7182285256385803, "Mean Target Q": 3.3809432067871095, "Mean Q1": 3.380446876525879, "Mean Q2": 3.3805196418762207, "critic_loss": 1.4388357782363892, "batch_reward": 1.2221432371139527, "actor_loss": -3.4459667962694924, "actor_target_entropy": -1.0, "actor_entropy": 1.232528943864126, "alpha_loss": 0.15096902705374218, "alpha_value": 0.0985736970308929, "duration": 130.91135025024414, "step": 1375}
{"episode_reward": 178.7587235636163, "episode": 12.0, "Q1 loss": 0.6131898164749146, "Q2 loss": 0.6108887102603913, "Mean Target Q": 3.925983070373535, "Mean Q1": 3.9243620014190674, "Mean Q2": 3.924422002792358, "critic_loss": 1.2240785307884217, "batch_reward": 1.1935972661972045, "actor_loss": -3.974332751766328, "actor_target_entropy": -1.0, "actor_entropy": 1.1430179842056767, "alpha_loss": 0.14704894574899827, "alpha_value": 0.09792697022948808, "duration": 143.3909192085266, "step": 1500}
{"episode_reward": 54.50843618181011, "episode": 13.0, "Q1 loss": 0.7308574204444885, "Q2 loss": 0.729753424167633, "Mean Target Q": 4.551647762298584, "Mean Q1": 4.548520866394043, "Mean Q2": 4.548347906112671, "critic_loss": 1.4606108493804932, "batch_reward": 1.167254677772522, "actor_loss": -4.656124289073642, "actor_target_entropy": -1.0, "actor_entropy": 1.0455560116540819, "alpha_loss": 0.13077864109996765, "alpha_value": 0.09734010158187231, "duration": 133.12407803535461, "step": 1625}
{"episode_reward": 195.35174732946479, "episode": 14.0, "Q1 loss": 0.8829216980934143, "Q2 loss": 0.8861305918693543, "Mean Target Q": 5.248270832061768, "Mean Q1": 5.24541344833374, "Mean Q2": 5.245479320526123, "critic_loss": 1.769052297592163, "batch_reward": 1.1613974370956421, "actor_loss": -5.3545299576174825, "actor_target_entropy": -1.0, "actor_entropy": 0.9652606402674029, "alpha_loss": 0.11694094358432677, "alpha_value": 0.09680685347111999, "duration": 134.00606656074524, "step": 1750}
{"episode_reward": 50.26515393946933, "episode": 15.0, "Q1 loss": 0.977489725112915, "Q2 loss": 0.9793499269485474, "Mean Target Q": 5.780890193939209, "Mean Q1": 5.776818244934082, "Mean Q2": 5.776619716644287, "critic_loss": 1.956839653968811, "batch_reward": 1.1067758145332336, "actor_loss": -5.9434610321408226, "actor_target_entropy": -1.0, "actor_entropy": 0.8224147066237435, "alpha_loss": 0.11122273831140428, "alpha_value": 0.09630558057488942, "duration": 116.24813294410706, "step": 1875}
{"episode_reward": 59.82434728639592, "episode": 16.0, "Q1 loss": 1.1281894421577454, "Q2 loss": 1.1302445039749145, "Mean Target Q": 6.3509622535705565, "Mean Q1": 6.347473987579345, "Mean Q2": 6.3473016548156735, "critic_loss": 2.2584339447021486, "batch_reward": 1.0974987678527832, "actor_loss": -6.560772119029876, "actor_target_entropy": -1.0, "actor_entropy": 0.7939815415490058, "alpha_loss": 0.09761142826849414, "alpha_value": 0.09582952284535294, "duration": 102.79812145233154, "step": 2000}
{"episode_reward": 193.41738834903845, "episode": 17.0, "Q1 loss": 1.2244891543388368, "Q2 loss": 1.2281019024848938, "Mean Target Q": 7.029032291412354, "Mean Q1": 7.023689376831054, "Mean Q2": 7.023931476593018, "critic_loss": 2.452591055870056, "batch_reward": 1.1034850635528564, "actor_loss": -7.336748403216165, "actor_target_entropy": -1.0, "actor_entropy": 0.8170132783670274, "alpha_loss": 0.07272110566023797, "alpha_value": 0.0954317703538379, "duration": 89.16724729537964, "step": 2125}
{"episode_reward": 117.74956246836804, "episode": 18.0, "Q1 loss": 1.3180238814353944, "Q2 loss": 1.3162691249847411, "Mean Target Q": 7.810846313476563, "Mean Q1": 7.805538516998291, "Mean Q2": 7.805136573791504, "critic_loss": 2.634293001174927, "batch_reward": 1.1135354900360108, "actor_loss": -8.159216111706149, "actor_target_entropy": -1.0, "actor_entropy": 0.7696685858311192, "alpha_loss": 0.059715139889909376, "alpha_value": 0.09510951263613199, "duration": 107.63443183898926, "step": 2250}
{"episode_reward": 187.18561324295632, "episode": 19.0, "Q1 loss": 1.4588895401954651, "Q2 loss": 1.461500271320343, "Mean Target Q": 8.850945602416992, "Mean Q1": 8.845998626708985, "Mean Q2": 8.84560927963257, "critic_loss": 2.920389813423157, "batch_reward": 1.152134171962738, "actor_loss": -9.25309249332973, "actor_target_entropy": -1.0, "actor_entropy": 0.6688204294159299, "alpha_loss": 0.04308602270034571, "alpha_value": 0.09484455359312548, "duration": 95.86532211303711, "step": 2375}
{"episode_reward": 278.39152948599065, "episode": 20.0, "Q1 loss": 1.6823795948028564, "Q2 loss": 1.6820106000900268, "Mean Target Q": 9.997175895690917, "Mean Q1": 9.99238542175293, "Mean Q2": 9.992874580383301, "critic_loss": 3.3643901891708374, "batch_reward": 1.2114466819763183, "actor_loss": -10.55233693891956, "actor_target_entropy": -1.0, "actor_entropy": 0.5103619884579412, "alpha_loss": 0.021596239249300844, "alpha_value": 0.09466929602979993, "duration": 103.92922711372375, "step": 2500}
{"episode_reward": 258.71919760725723, "episode": 21.0, "Q1 loss": 1.7941961679458618, "Q2 loss": 1.7983593292236328, "Mean Target Q": 11.11166219329834, "Mean Q1": 11.099335494995117, "Mean Q2": 11.099677726745606, "critic_loss": 3.592555492401123, "batch_reward": 1.2352522020339967, "actor_loss": -11.706888213990227, "actor_target_entropy": -1.0, "actor_entropy": 0.45517015646374415, "alpha_loss": 0.006083345609820551, "alpha_value": 0.09458196766872357, "duration": 81.19923758506775, "step": 2625}
{"episode_reward": 201.3425401743003, "episode": 22.0, "Q1 loss": 1.8440156087875366, "Q2 loss": 1.845546516418457, "Mean Target Q": 12.24575936126709, "Mean Q1": 12.240311515808106, "Mean Q2": 12.24014479827881, "critic_loss": 3.6895621185302736, "batch_reward": 1.2605923128128051, "actor_loss": -12.92148390123921, "actor_target_entropy": -1.0, "actor_entropy": 0.48400300116308276, "alpha_loss": -0.01222073092245527, "alpha_value": 0.09460193426148056, "duration": 105.44993925094604, "step": 2750}
{"episode_reward": 224.06448267894027, "episode": 23.0, "Q1 loss": 2.1770499687194826, "Q2 loss": 2.1852553386688234, "Mean Target Q": 13.453926551818848, "Mean Q1": 13.448989555358887, "Mean Q2": 13.448972831726074, "critic_loss": 4.362305305480957, "batch_reward": 1.2750920686721803, "actor_loss": -14.162616245330327, "actor_target_entropy": -1.0, "actor_entropy": 0.43443795281743247, "alpha_loss": -0.019352056620095575, "alpha_value": 0.09471125070013277, "duration": 132.64092183113098, "step": 2875}
{"episode_reward": 186.9991345086562, "episode": 24.0, "Q1 loss": 2.249758056640625, "Q2 loss": 2.2570531368255615, "Mean Target Q": 14.685632286071778, "Mean Q1": 14.675776466369628, "Mean Q2": 14.675501625061035, "critic_loss": 4.506811164855957, "batch_reward": 1.2914717702865601, "actor_loss": -15.393097354519751, "actor_target_entropy": -1.0, "actor_entropy": 0.4734555968353825, "alpha_loss": -0.026328245313057014, "alpha_value": 0.09486373734743266, "duration": 148.63521909713745, "step": 3000}
{"episode_reward": 165.4851187114019, "episode": 25.0, "Q1 loss": 2.256984456062317, "Q2 loss": 2.251008345603943, "Mean Target Q": 15.813526504516602, "Mean Q1": 15.807269172668457, "Mean Q2": 15.807390090942382, "critic_loss": 4.507992799758911, "batch_reward": 1.2945685224533081, "actor_loss": -16.59873742905874, "actor_target_entropy": -1.0, "actor_entropy": 0.43822695527757916, "alpha_loss": -0.031192755341411582, "alpha_value": 0.0950620774925836, "duration": 124.88613414764404, "step": 3125}
{"episode_reward": 204.95606875674818, "episode": 26.0, "Q1 loss": 2.5422773065567017, "Q2 loss": 2.5420807905197145, "Mean Target Q": 16.93808023071289, "Mean Q1": 16.93470859527588, "Mean Q2": 16.934536361694335, "critic_loss": 5.08435809135437, "batch_reward": 1.3024646644592286, "actor_loss": -17.728722387744533, "actor_target_entropy": -1.0, "actor_entropy": 0.38836739128155096, "alpha_loss": -0.03734119987535861, "alpha_value": 0.09531066669277156, "duration": 122.18602395057678, "step": 3250}
{"episode_reward": 159.81004953532678, "episode": 27.0, "Q1 loss": 2.6691778011322023, "Q2 loss": 2.6724876861572264, "Mean Target Q": 18.07667823791504, "Mean Q1": 18.06693927001953, "Mean Q2": 18.067385009765626, "critic_loss": 5.341665483474731, "batch_reward": 1.2977340116500855, "actor_loss": -18.89186595735096, "actor_target_entropy": -1.0, "actor_entropy": 0.4417947076615833, "alpha_loss": -0.044287524910436735, "alpha_value": 0.09562641887365199, "duration": 123.35998821258545, "step": 3375}
{"episode_reward": 141.61267194228816, "episode": 28.0, "Q1 loss": 2.663169969558716, "Q2 loss": 2.664601788520813, "Mean Target Q": 19.094663314819336, "Mean Q1": 19.088186004638672, "Mean Q2": 19.087817108154297, "critic_loss": 5.3277717895507815, "batch_reward": 1.285293423652649, "actor_loss": -19.819637729275613, "actor_target_entropy": -1.0, "actor_entropy": 0.43480805908479997, "alpha_loss": -0.04640496828623356, "alpha_value": 0.09598044386314114, "duration": 115.75114130973816, "step": 3500}
{"episode_reward": 100.90596192142874, "episode": 29.0, "Q1 loss": 2.9468713731765748, "Q2 loss": 2.951790846824646, "Mean Target Q": 20.095452819824217, "Mean Q1": 20.088192031860352, "Mean Q2": 20.087486755371092, "critic_loss": 5.898662216186524, "batch_reward": 1.280074330329895, "actor_loss": -20.847111141870894, "actor_target_entropy": -1.0, "actor_entropy": 0.45103607858930317, "alpha_loss": -0.04364647955766746, "alpha_value": 0.0963348389575843, "duration": 111.64931964874268, "step": 3625}
{"episode_reward": 179.03621211219925, "episode": 30.0, "Q1 loss": 2.749617774963379, "Q2 loss": 2.7547479038238527, "Mean Target Q": 21.258319625854494, "Mean Q1": 21.254121871948243, "Mean Q2": 21.254248748779297, "critic_loss": 5.504365697860718, "batch_reward": 1.298120659828186, "actor_loss": -21.954183363145397, "actor_target_entropy": -1.0, "actor_entropy": 0.4765442645838184, "alpha_loss": -0.03849452592793011, "alpha_value": 0.09669575678619712, "duration": 132.03637886047363, "step": 3750}
{"episode_reward": 194.6079740670497, "episode": 31.0, "Q1 loss": 3.005847731590271, "Q2 loss": 3.005460759162903, "Mean Target Q": 22.342076278686523, "Mean Q1": 22.332036560058594, "Mean Q2": 22.332255401611327, "critic_loss": 6.01130849647522, "batch_reward": 1.2892034711837768, "actor_loss": -23.075270789010183, "actor_target_entropy": -1.0, "actor_entropy": 0.4537526508645406, "alpha_loss": -0.03568085106015797, "alpha_value": 0.09700308533325765, "duration": 127.02093648910522, "step": 3875}
{"episode_reward": 149.51774060450492, "episode": 32.0, "Q1 loss": 3.085945149421692, "Q2 loss": 3.0837626123428343, "Mean Target Q": 23.392803436279298, "Mean Q1": 23.386824752807616, "Mean Q2": 23.386284774780272, "critic_loss": 6.169707765579224, "batch_reward": 1.3037228994369507, "actor_loss": -24.027336059078092, "actor_target_entropy": -1.0, "actor_entropy": 0.5163498924624536, "alpha_loss": -0.03714675028177519, "alpha_value": 0.0973227772218569, "duration": 115.31725072860718, "step": 4000}
{"episode_reward": 233.7567480596188, "episode": 33.0, "Q1 loss": 3.1543865146636962, "Q2 loss": 3.156869440078735, "Mean Target Q": 24.58827551269531, "Mean Q1": 24.58411079406738, "Mean Q2": 24.584028717041015, "critic_loss": 6.31125594329834, "batch_reward": 1.3115553884506226, "actor_loss": -25.32279190184578, "actor_target_entropy": -1.0, "actor_entropy": 0.5106445508343833, "alpha_loss": -0.04106852283612603, "alpha_value": 0.09767641978491104, "duration": 85.79976487159729, "step": 4125}
{"episode_reward": 256.7426916938638, "episode": 34.0, "Q1 loss": 3.4043720655441283, "Q2 loss": 3.3957894897460936, "Mean Target Q": 25.62770115661621, "Mean Q1": 25.621309661865233, "Mean Q2": 25.620958984375, "critic_loss": 6.800161552429199, "batch_reward": 1.3232334575653075, "actor_loss": -26.380607881853656, "actor_target_entropy": -1.0, "actor_entropy": 0.49218729378715637, "alpha_loss": -0.0372039349599471, "alpha_value": 0.09804897789229482, "duration": 69.37879490852356, "step": 4250}
{"episode_reward": 197.97068631996132, "episode": 35.0, "Q1 loss": 3.767203294754028, "Q2 loss": 3.771538377761841, "Mean Target Q": 26.833744537353514, "Mean Q1": 26.827394485473633, "Mean Q2": 26.827373977661132, "critic_loss": 7.538741668701172, "batch_reward": 1.3441977710723878, "actor_loss": -27.551972676837256, "actor_target_entropy": -1.0, "actor_entropy": 0.4739772942331102, "alpha_loss": -0.04146092609753684, "alpha_value": 0.09843542252467989, "duration": 82.91067457199097, "step": 4375}
{"episode_reward": 219.9781232039217, "episode": 36.0, "Q1 loss": 3.748070281982422, "Q2 loss": 3.752471134185791, "Mean Target Q": 28.056040481567383, "Mean Q1": 28.051325027465822, "Mean Q2": 28.051975631713866, "critic_loss": 7.500541435241699, "batch_reward": 1.35720379447937, "actor_loss": -28.876970967938824, "actor_target_entropy": -1.0, "actor_entropy": 0.4959130873603205, "alpha_loss": -0.04755012132227421, "alpha_value": 0.0988856084033269, "duration": 117.16079926490784, "step": 4500}
{"episode_reward": 235.67606296846625, "episode": 37.0, "Q1 loss": 3.6825432415008543, "Q2 loss": 3.695957706451416, "Mean Target Q": 29.197184295654296, "Mean Q1": 29.186265213012696, "Mean Q2": 29.186296829223632, "critic_loss": 7.378500984191895, "batch_reward": 1.3600970430374146, "actor_loss": -29.97873790680416, "actor_target_entropy": -1.0, "actor_entropy": 0.469854093733288, "alpha_loss": -0.05417197629336327, "alpha_value": 0.09938515522080837, "duration": 123.93620800971985, "step": 4625}
{"episode_reward": 175.8756891700065, "episode": 38.0, "Q1 loss": 3.842881567001343, "Q2 loss": 3.8433552513122557, "Mean Target Q": 30.34464030456543, "Mean Q1": 30.33912872314453, "Mean Q2": 30.339098693847657, "critic_loss": 7.6862367858886715, "batch_reward": 1.3715286540985108, "actor_loss": -31.12585969125071, "actor_target_entropy": -1.0, "actor_entropy": 0.4975926722249677, "alpha_loss": -0.05022366678402308, "alpha_value": 0.09992707945943981, "duration": 101.06588339805603, "step": 4750}
{"episode_reward": 206.51427610245713, "episode": 39.0, "Q1 loss": 4.157027713775634, "Q2 loss": 4.157684595108032, "Mean Target Q": 31.492025390625, "Mean Q1": 31.48412730407715, "Mean Q2": 31.48382321166992, "critic_loss": 8.31471230316162, "batch_reward": 1.374116822242737, "actor_loss": -32.28379019479903, "actor_target_entropy": -1.0, "actor_entropy": 0.48507538627064417, "alpha_loss": -0.0556557620505965, "alpha_value": 0.1004789520350684, "duration": 94.4161684513092, "step": 4875}
{"episode_reward": 194.16315086880581, "episode": 40.0, "Q1 loss": 3.9680391445159913, "Q2 loss": 3.9606431789398195, "Mean Target Q": 32.611124252319335, "Mean Q1": 32.60853025817871, "Mean Q2": 32.60862400817871, "critic_loss": 7.928682308197022, "batch_reward": 1.3807979555130006, "actor_loss": -33.404927407541585, "actor_target_entropy": -1.0, "actor_entropy": 0.47705020491153965, "alpha_loss": -0.05943086863525452, "alpha_value": 0.10106512431206828, "step": 5000}
{"duration": 116.7770447731018, "step": 5000}
{"episode_reward": 210.52083512264363, "episode": 41.0, "Q1 loss": 3.9095096969604493, "Q2 loss": 3.894368600845337, "Mean Target Q": 33.74860382080078, "Mean Q1": 33.73938858032226, "Mean Q2": 33.73972500610351, "critic_loss": 7.803878303527832, "batch_reward": 1.3717767391204834, "actor_loss": -34.39832505725679, "actor_target_entropy": -1.0, "actor_entropy": 0.4814067189655607, "alpha_loss": -0.05401504196463123, "alpha_value": 0.10167857318323321, "duration": 124.20384740829468, "step": 5125}
{"episode_reward": 174.0128600555239, "episode": 42.0, "Q1 loss": 4.019195316314697, "Q2 loss": 4.027458814620972, "Mean Target Q": 34.85504583740234, "Mean Q1": 34.85248086547852, "Mean Q2": 34.85195776367188, "critic_loss": 8.046654140472413, "batch_reward": 1.387126449584961, "actor_loss": -35.59211774026194, "actor_target_entropy": -1.0, "actor_entropy": 0.4321170667967489, "alpha_loss": -0.05130856189756624, "alpha_value": 0.1022153870921042, "duration": 126.58247780799866, "step": 5250}
{"episode_reward": 181.09273921300394, "episode": 43.0, "Q1 loss": 4.2966295433044435, "Q2 loss": 4.295494285583496, "Mean Target Q": 35.92106802368164, "Mean Q1": 35.913083129882814, "Mean Q2": 35.91408926391602, "critic_loss": 8.592123851776122, "batch_reward": 1.3707583742141725, "actor_loss": -36.691012427920384, "actor_target_entropy": -1.0, "actor_entropy": 0.4531281817527044, "alpha_loss": -0.050903421900575126, "alpha_value": 0.10278881010733121, "duration": 136.0364911556244, "step": 5375}
{"episode_reward": 120.55628793522666, "episode": 44.0, "Q1 loss": 4.523308483123779, "Q2 loss": 4.514690010070801, "Mean Target Q": 37.08582788085938, "Mean Q1": 37.07780322265625, "Mean Q2": 37.07731500244141, "critic_loss": 9.03799849319458, "batch_reward": 1.3813728981018067, "actor_loss": -37.75837264522429, "actor_target_entropy": -1.0, "actor_entropy": 0.43590961300557657, "alpha_loss": -0.05350351123319518, "alpha_value": 0.10335107976346203, "duration": 118.19894456863403, "step": 5500}
{"episode_reward": 206.3440630492113, "episode": 45.0, "Q1 loss": 4.182581098556518, "Q2 loss": 4.177309278488159, "Mean Target Q": 38.152171966552736, "Mean Q1": 38.14500814819336, "Mean Q2": 38.144701629638675, "critic_loss": 8.359890342712403, "batch_reward": 1.3776549425125122, "actor_loss": -38.77480812678262, "actor_target_entropy": -1.0, "actor_entropy": 0.4316337432653185, "alpha_loss": -0.04346326197541896, "alpha_value": 0.10388506632439617, "duration": 130.47762179374695, "step": 5625}
{"episode_reward": 152.46179442798362, "episode": 46.0, "Q1 loss": 4.206877410888672, "Q2 loss": 4.198279125213623, "Mean Target Q": 39.261007385253905, "Mean Q1": 39.255724609375, "Mean Q2": 39.256716613769534, "critic_loss": 8.40515655517578, "batch_reward": 1.368369502067566, "actor_loss": -39.92150072897634, "actor_target_entropy": -1.0, "actor_entropy": 0.4505832435623292, "alpha_loss": -0.037944867966636535, "alpha_value": 0.10434191018589553, "duration": 116.6588339805603, "step": 5750}
{"episode_reward": 222.8857501718919, "episode": 47.0, "Q1 loss": 3.844421136856079, "Q2 loss": 3.8564327487945556, "Mean Target Q": 40.38914712524414, "Mean Q1": 40.384985443115234, "Mean Q2": 40.38447225952149, "critic_loss": 7.700853874206543, "batch_reward": 1.3873204288482666, "actor_loss": -41.137870728023465, "actor_target_entropy": -1.0, "actor_entropy": 0.4411636548382895, "alpha_loss": -0.038755343059107425, "alpha_value": 0.10476982346130692, "duration": 118.08522653579712, "step": 5875}
{"episode_reward": 220.44344135090384, "episode": 48.0, "Q1 loss": 4.286220689773559, "Q2 loss": 4.295135414123535, "Mean Target Q": 41.46729916381836, "Mean Q1": 41.462978271484374, "Mean Q2": 41.46298150634765, "critic_loss": 8.58135608291626, "batch_reward": 1.3989783630371093, "actor_loss": -42.15805176765688, "actor_target_entropy": -1.0, "actor_entropy": 0.4346487012601668, "alpha_loss": -0.04457348409379201, "alpha_value": 0.105288266925454, "duration": 125.32800936698914, "step": 6000}
{"episode_reward": 249.21719838711957, "episode": 49.0, "Q1 loss": 4.2295442428588865, "Q2 loss": 4.235156377792358, "Mean Target Q": 42.55007162475586, "Mean Q1": 42.54241967773437, "Mean Q2": 42.542705017089844, "critic_loss": 8.464700607299804, "batch_reward": 1.4145989427566528, "actor_loss": -43.255638728066096, "actor_target_entropy": -1.0, "actor_entropy": 0.42566940897987005, "alpha_loss": -0.041477082977219235, "alpha_value": 0.10576899374949267, "duration": 123.63223052024841, "step": 6125}
{"episode_reward": 251.21268207529752, "episode": 50.0, "Q1 loss": 4.019271654129028, "Q2 loss": 4.0206869430542, "Mean Target Q": 43.63351501464844, "Mean Q1": 43.62995608520508, "Mean Q2": 43.62951824951172, "critic_loss": 8.039958583831787, "batch_reward": 1.430452625274658, "actor_loss": -44.32190396708827, "actor_target_entropy": -1.0, "actor_entropy": 0.4490858229898637, "alpha_loss": -0.043172888848329746, "alpha_value": 0.10629264210601541, "duration": 133.55651187896729, "step": 6250}
{"episode_reward": 220.60813908092086, "episode": 51.0, "Q1 loss": 4.033844966888427, "Q2 loss": 4.027790817260742, "Mean Target Q": 44.72319155883789, "Mean Q1": 44.714106506347655, "Mean Q2": 44.71355416870117, "critic_loss": 8.061635791778565, "batch_reward": 1.4340422992706299, "actor_loss": -45.43726058233352, "actor_target_entropy": -1.0, "actor_entropy": 0.4597306180567968, "alpha_loss": -0.04867095591884757, "alpha_value": 0.10686206963636281, "duration": 112.08833122253418, "step": 6375}
{"episode_reward": 215.72093785312651, "episode": 52.0, "Q1 loss": 4.050953941345215, "Q2 loss": 4.04280460357666, "Mean Target Q": 45.86572799682617, "Mean Q1": 45.86019918823242, "Mean Q2": 45.86022314453125, "critic_loss": 8.093758544921876, "batch_reward": 1.4293859872817993, "actor_loss": -46.59517866565335, "actor_target_entropy": -1.0, "actor_entropy": 0.4763947400835253, "alpha_loss": -0.04664652833654996, "alpha_value": 0.10744766337770097, "duration": 122.2653431892395, "step": 6500}
{"episode_reward": 206.681063850032, "episode": 53.0, "Q1 loss": 4.01227068901062, "Q2 loss": 4.010811265945435, "Mean Target Q": 46.935032501220704, "Mean Q1": 46.935086273193356, "Mean Q2": 46.93487698364258, "critic_loss": 8.023081985473633, "batch_reward": 1.434917022705078, "actor_loss": -47.636142791263644, "actor_target_entropy": -1.0, "actor_entropy": 0.4666597852631221, "alpha_loss": -0.044976532370561643, "alpha_value": 0.10801892456178204, "duration": 134.20396828651428, "step": 6625}
{"episode_reward": 154.86991022904178, "episode": 54.0, "Q1 loss": 3.911026231765747, "Q2 loss": 3.9256213779449465, "Mean Target Q": 47.8192424621582, "Mean Q1": 47.812463989257814, "Mean Q2": 47.81181536865235, "critic_loss": 7.836647609710694, "batch_reward": 1.4313590002059937, "actor_loss": -48.523562462099136, "actor_target_entropy": -1.0, "actor_entropy": 0.46849715373208445, "alpha_loss": -0.045449360634290406, "alpha_value": 0.10860048074638134, "duration": 131.66986632347107, "step": 6750}
{"episode_reward": 163.66865047610267, "episode": 55.0, "Q1 loss": 3.9314898529052735, "Q2 loss": 3.9335443325042725, "Mean Target Q": 48.83410278320312, "Mean Q1": 48.82834048461914, "Mean Q2": 48.82906228637695, "critic_loss": 7.865034194946289, "batch_reward": 1.4390903930664063, "actor_loss": -49.46050207955496, "actor_target_entropy": -1.0, "actor_entropy": 0.46266783655635896, "alpha_loss": -0.04012962971769628, "alpha_value": 0.10915571654400921, "duration": 144.00388026237488, "step": 6875}
{"episode_reward": 215.04891831243816, "episode": 56.0, "Q1 loss": 3.8861137580871583, "Q2 loss": 3.890151601791382, "Mean Target Q": 49.78706591796875, "Mean Q1": 49.78360153198242, "Mean Q2": 49.784118103027346, "critic_loss": 7.776265361785889, "batch_reward": 1.439845238685608, "actor_loss": -50.405043263589185, "actor_target_entropy": -1.0, "actor_entropy": 0.46630900233022626, "alpha_loss": -0.035336284928264156, "alpha_value": 0.10965644997291751, "duration": 126.86378765106201, "step": 7000}
{"episode_reward": 183.42185003108634, "episode": 57.0, "Q1 loss": 4.094288181304932, "Q2 loss": 4.0986906433105466, "Mean Target Q": 50.85857244873047, "Mean Q1": 50.85392474365234, "Mean Q2": 50.853520324707034, "critic_loss": 8.19297883605957, "batch_reward": 1.4435703048706054, "actor_loss": -51.43079691084604, "actor_target_entropy": -1.0, "actor_entropy": 0.4520450939261724, "alpha_loss": -0.03837981205137949, "alpha_value": 0.11016599004148982, "duration": 129.39002895355225, "step": 7125}
{"episode_reward": 285.0261074516538, "episode": 58.0, "Q1 loss": 4.262775888442993, "Q2 loss": 4.256362867355347, "Mean Target Q": 51.88972076416016, "Mean Q1": 51.887091064453124, "Mean Q2": 51.88701617431641, "critic_loss": 8.519138751983643, "batch_reward": 1.4631841259002685, "actor_loss": -52.51158825043709, "actor_target_entropy": -1.0, "actor_entropy": 0.45465066596384973, "alpha_loss": -0.040130128513180444, "alpha_value": 0.11068180899490468, "duration": 100.32110142707825, "step": 7250}
{"episode_reward": 240.23605575955938, "episode": 59.0, "Q1 loss": 3.9658238620758057, "Q2 loss": 3.970055637359619, "Mean Target Q": 52.80129345703125, "Mean Q1": 52.792265533447264, "Mean Q2": 52.791409118652346, "critic_loss": 7.9358794937133785, "batch_reward": 1.4544984064102173, "actor_loss": -53.442877451578774, "actor_target_entropy": -1.0, "actor_entropy": 0.44514086274873643, "alpha_loss": -0.04122875157802824, "alpha_value": 0.11122100418513126, "duration": 77.87710547447205, "step": 7375}
{"episode_reward": 266.37516892772754, "episode": 60.0, "Q1 loss": 4.0538534278869625, "Q2 loss": 4.058814161300659, "Mean Target Q": 53.88621160888672, "Mean Q1": 53.885876037597654, "Mean Q2": 53.88716552734375, "critic_loss": 8.112667575836182, "batch_reward": 1.4778523120880127, "actor_loss": -54.59408353990124, "actor_target_entropy": -1.0, "actor_entropy": 0.43302898301232245, "alpha_loss": -0.04709996373182343, "alpha_value": 0.11184258708567005, "duration": 110.85276412963867, "step": 7500}
{"episode_reward": 185.441102782708, "episode": 61.0, "Q1 loss": 4.122859106063843, "Q2 loss": 4.110723684310913, "Mean Target Q": 54.78548559570312, "Mean Q1": 54.77889379882812, "Mean Q2": 54.778464935302736, "critic_loss": 8.233582752227782, "batch_reward": 1.4630316133499146, "actor_loss": -55.42263533577086, "actor_target_entropy": -1.0, "actor_entropy": 0.43351363331552534, "alpha_loss": -0.051107872366195635, "alpha_value": 0.11252863875878526, "duration": 127.29619836807251, "step": 7625}
{"episode_reward": 212.6146143704204, "episode": 62.0, "Q1 loss": 4.078572584152222, "Q2 loss": 4.069017425537109, "Mean Target Q": 55.79410153198242, "Mean Q1": 55.78995526123047, "Mean Q2": 55.789481872558596, "critic_loss": 8.147590030670166, "batch_reward": 1.4808056764602662, "actor_loss": -56.52965170337308, "actor_target_entropy": -1.0, "actor_entropy": 0.4341084130348698, "alpha_loss": -0.05284539171524586, "alpha_value": 0.11328385345382766, "duration": 136.2760558128357, "step": 7750}
{"episode_reward": 187.9844466063773, "episode": 63.0, "Q1 loss": 4.291381591796875, "Q2 loss": 4.304572071075439, "Mean Target Q": 56.756214508056644, "Mean Q1": 56.74957131958008, "Mean Q2": 56.74982440185547, "critic_loss": 8.595953647613525, "batch_reward": 1.478258526802063, "actor_loss": -57.41371354602632, "actor_target_entropy": -1.0, "actor_entropy": 0.3953377105413921, "alpha_loss": -0.056587395923478265, "alpha_value": 0.11405546352543289, "duration": 122.01076889038086, "step": 7875}
{"episode_reward": 214.40894477738655, "episode": 64.0, "Q1 loss": 4.5186458568573, "Q2 loss": 4.5023132495880125, "Mean Target Q": 57.75492303466797, "Mean Q1": 57.75439385986328, "Mean Q2": 57.754970458984374, "critic_loss": 9.020959060668945, "batch_reward": 1.4717942295074462, "actor_loss": -58.502455311436805, "actor_target_entropy": -1.0, "actor_entropy": 0.4104937016963959, "alpha_loss": -0.05423486464086079, "alpha_value": 0.11481956464991105, "duration": 112.38525366783142, "step": 8000}
{"episode_reward": 190.31385854402998, "episode": 65.0, "Q1 loss": 4.542396125793457, "Q2 loss": 4.544680227279663, "Mean Target Q": 58.78170065307617, "Mean Q1": 58.77455047607422, "Mean Q2": 58.77458709716797, "critic_loss": 9.087076320648194, "batch_reward": 1.4798935651779175, "actor_loss": -59.447818513900515, "actor_target_entropy": -1.0, "actor_entropy": 0.43691673496412853, "alpha_loss": -0.055025752988599595, "alpha_value": 0.11560356040258574, "duration": 103.48899054527283, "step": 8125}
{"episode_reward": 198.92099745098673, "episode": 66.0, "Q1 loss": 4.5705255641937255, "Q2 loss": 4.564435970306397, "Mean Target Q": 59.802599609375, "Mean Q1": 59.79661444091797, "Mean Q2": 59.797290649414066, "critic_loss": 9.134961547851562, "batch_reward": 1.4846347980499268, "actor_loss": -60.446861759308845, "actor_target_entropy": -1.0, "actor_entropy": 0.3710368922160518, "alpha_loss": -0.04936465467776983, "alpha_value": 0.11634215004422534, "duration": 112.80148601531982, "step": 8250}
{"episode_reward": 168.14844380942282, "episode": 67.0, "Q1 loss": 4.4624719867706295, "Q2 loss": 4.480250118255615, "Mean Target Q": 60.68677188110352, "Mean Q1": 60.68671133422851, "Mean Q2": 60.686944396972656, "critic_loss": 8.942722091674804, "batch_reward": 1.4773006019592285, "actor_loss": -61.308383396693635, "actor_target_entropy": -1.0, "actor_entropy": 0.3997977508438958, "alpha_loss": -0.04833770448726321, "alpha_value": 0.11703301586820965, "duration": 110.08225774765015, "step": 8375}
{"episode_reward": 200.40972969630317, "episode": 68.0, "Q1 loss": 4.412494596481324, "Q2 loss": 4.421024332046509, "Mean Target Q": 61.656465637207035, "Mean Q1": 61.65137030029297, "Mean Q2": 61.65139743041992, "critic_loss": 8.83351891708374, "batch_reward": 1.4914839162826539, "actor_loss": -62.26256376697171, "actor_target_entropy": -1.0, "actor_entropy": 0.398665786750855, "alpha_loss": -0.05393454498581348, "alpha_value": 0.11775495792766628, "duration": 130.70785760879517, "step": 8500}
{"episode_reward": 211.09703376949017, "episode": 69.0, "Q1 loss": 4.279102882385254, "Q2 loss": 4.282353837966919, "Mean Target Q": 62.57918859863281, "Mean Q1": 62.57687716674805, "Mean Q2": 62.57610452270508, "critic_loss": 8.561456691741943, "batch_reward": 1.4898485736846925, "actor_loss": -63.30562143477182, "actor_target_entropy": -1.0, "actor_entropy": 0.421060237619612, "alpha_loss": -0.05405353612843014, "alpha_value": 0.11853160366290877, "duration": 135.51640462875366, "step": 8625}
{"episode_reward": 251.7701702287209, "episode": 70.0, "Q1 loss": 4.268577116012573, "Q2 loss": 4.265887552261352, "Mean Target Q": 63.57180334472656, "Mean Q1": 63.57161163330078, "Mean Q2": 63.571368927001956, "critic_loss": 8.534464664459229, "batch_reward": 1.5036324043273925, "actor_loss": -64.22951464499197, "actor_target_entropy": -1.0, "actor_entropy": 0.4156119958046944, "alpha_loss": -0.05888996531646098, "alpha_value": 0.11933340798649901, "duration": 110.0729808807373, "step": 8750}
{"episode_reward": 276.76711737443674, "episode": 71.0, "Q1 loss": 4.633714176177978, "Q2 loss": 4.613925788879395, "Mean Target Q": 64.4756322631836, "Mean Q1": 64.46529098510742, "Mean Q2": 64.4649115600586, "critic_loss": 9.24763996887207, "batch_reward": 1.499168643951416, "actor_loss": -65.06821659633091, "actor_target_entropy": -1.0, "actor_entropy": 0.43090053446709164, "alpha_loss": -0.056973210550726405, "alpha_value": 0.12015419750720831, "duration": 108.14899277687073, "step": 8875}
{"episode_reward": 133.65212344417205, "episode": 72.0, "Q1 loss": 4.329531192779541, "Q2 loss": 4.331856380462646, "Mean Target Q": 65.38867205810547, "Mean Q1": 65.38637991333007, "Mean Q2": 65.38778936767578, "critic_loss": 8.66138759994507, "batch_reward": 1.4966266288757324, "actor_loss": -66.0116697742093, "actor_target_entropy": -1.0, "actor_entropy": 0.4385816901922226, "alpha_loss": -0.05989385384225076, "alpha_value": 0.12099448907776135, "duration": 110.50042581558228, "step": 9000}
{"episode_reward": 153.13684608415, "episode": 73.0, "Q1 loss": 4.445532312393189, "Q2 loss": 4.4527451667785645, "Mean Target Q": 66.37775579833985, "Mean Q1": 66.37520837402344, "Mean Q2": 66.37388439941407, "critic_loss": 8.898277488708496, "batch_reward": 1.5102320156097413, "actor_loss": -67.03332168336898, "actor_target_entropy": -1.0, "actor_entropy": 0.45414300286580644, "alpha_loss": -0.06042175441389046, "alpha_value": 0.12186040183699445, "duration": 134.64645957946777, "step": 9125}
{"episode_reward": 383.94157747955745, "episode": 74.0, "Q1 loss": 4.58420880317688, "Q2 loss": 4.593634033203125, "Mean Target Q": 67.3679400024414, "Mean Q1": 67.36139508056641, "Mean Q2": 67.36102056884765, "critic_loss": 9.177842819213867, "batch_reward": 1.5134884195327758, "actor_loss": -68.01664487777218, "actor_target_entropy": -1.0, "actor_entropy": 0.4530929264522368, "alpha_loss": -0.058454167518404224, "alpha_value": 0.12271053065025878, "duration": 134.95478773117065, "step": 9250}
{"episode_reward": 213.60443344380764, "episode": 75.0, "Q1 loss": 4.6790219459533695, "Q2 loss": 4.67235330581665, "Mean Target Q": 68.2870888671875, "Mean Q1": 68.28340802001954, "Mean Q2": 68.28378784179688, "critic_loss": 9.351375232696533, "batch_reward": 1.5082538394927978, "actor_loss": -68.90582469153026, "actor_target_entropy": -1.0, "actor_entropy": 0.4594128377853878, "alpha_loss": -0.06023865287739133, "alpha_value": 0.12353203689982302, "duration": 109.39162993431091, "step": 9375}
{"episode_reward": 236.6667306561396, "episode": 76.0, "Q1 loss": 4.923044004440308, "Q2 loss": 4.899523096084595, "Mean Target Q": 69.23903198242188, "Mean Q1": 69.23562628173828, "Mean Q2": 69.23491564941406, "critic_loss": 9.822567100524902, "batch_reward": 1.5262054538726806, "actor_loss": -69.94146580849925, "actor_target_entropy": -1.0, "actor_entropy": 0.46461728311354117, "alpha_loss": -0.06333425019176737, "alpha_value": 0.12440427837256837, "duration": 122.59904456138611, "step": 9500}
{"episode_reward": 186.19775802901677, "episode": 77.0, "Q1 loss": 4.743342985153198, "Q2 loss": 4.730949205398559, "Mean Target Q": 70.12912371826172, "Mean Q1": 70.12390356445313, "Mean Q2": 70.12462170410156, "critic_loss": 9.47429216003418, "batch_reward": 1.5199033041000367, "actor_loss": -70.78729453919426, "actor_target_entropy": -1.0, "actor_entropy": 0.45446282530587817, "alpha_loss": -0.06115064060404187, "alpha_value": 0.1252848169301742, "duration": 144.59578108787537, "step": 9625}
{"episode_reward": 208.63777808305093, "episode": 78.0, "Q1 loss": 4.989461275100708, "Q2 loss": 4.975165575027466, "Mean Target Q": 70.9630365600586, "Mean Q1": 70.95872607421875, "Mean Q2": 70.95879650878906, "critic_loss": 9.964626880645753, "batch_reward": 1.5302730865478515, "actor_loss": -71.58479678246283, "actor_target_entropy": -1.0, "actor_entropy": 0.4648598699319747, "alpha_loss": -0.062497437120445316, "alpha_value": 0.12613760800666537, "duration": 124.32930207252502, "step": 9750}
{"episode_reward": 235.25545169779005, "episode": 79.0, "Q1 loss": 4.81178098487854, "Q2 loss": 4.791254751205444, "Mean Target Q": 71.90603948974609, "Mean Q1": 71.90215728759766, "Mean Q2": 71.90240106201172, "critic_loss": 9.603035736083985, "batch_reward": 1.525645570755005, "actor_loss": -72.61832863943917, "actor_target_entropy": -1.0, "actor_entropy": 0.4585415200581626, "alpha_loss": -0.06605461387643738, "alpha_value": 0.12706345500610688, "duration": 142.6310567855835, "step": 9875}
{"episode_reward": 186.59955606059415, "episode": 80.0, "Q1 loss": 5.084218423843383, "Q2 loss": 5.072802244186401, "Mean Target Q": 72.89574993896484, "Mean Q1": 72.89344567871093, "Mean Q2": 72.89319177246094, "critic_loss": 10.157020706176757, "batch_reward": 1.5292973098754883, "actor_loss": -73.58051583074754, "actor_target_entropy": -1.0, "actor_entropy": 0.4573462187282501, "alpha_loss": -0.0673559740065567, "alpha_value": 0.1279772120231852, "step": 10000}
{"duration": 133.6782145500183, "step": 10000}
{"episode_reward": 195.52775443973397, "episode": 81.0, "Q1 loss": 5.121450798034668, "Q2 loss": 5.1296209011077885, "Mean Target Q": 73.82308959960938, "Mean Q1": 73.81941381835938, "Mean Q2": 73.81998626708985, "critic_loss": 10.251071681976319, "batch_reward": 1.5313179330825806, "actor_loss": -74.45682452973865, "actor_target_entropy": -1.0, "actor_entropy": 0.43996276552714997, "alpha_loss": -0.06155966446986274, "alpha_value": 0.12887506954159794, "duration": 105.96662783622742, "step": 10125}
{"episode_reward": 210.45964139862363, "episode": 82.0, "Q1 loss": 5.107735206604004, "Q2 loss": 5.116111865997315, "Mean Target Q": 74.64985510253906, "Mean Q1": 74.64998669433594, "Mean Q2": 74.64986968994141, "critic_loss": 10.223847011566162, "batch_reward": 1.527397038459778, "actor_loss": -75.29875933739447, "actor_target_entropy": -1.0, "actor_entropy": 0.4609909956493685, "alpha_loss": -0.06224774509187667, "alpha_value": 0.12972583019376993, "duration": 108.085622549057, "step": 10250}
{"episode_reward": 210.4521414455679, "episode": 83.0, "Q1 loss": 4.9140675888061525, "Q2 loss": 4.913555610656738, "Mean Target Q": 75.56906927490235, "Mean Q1": 75.56116082763671, "Mean Q2": 75.56222393798828, "critic_loss": 9.827623153686524, "batch_reward": 1.5347772417068481, "actor_loss": -76.18604581318205, "actor_target_entropy": -1.0, "actor_entropy": 0.47395107339298914, "alpha_loss": -0.061148959315485425, "alpha_value": 0.1305922984702021, "duration": 109.52175712585449, "step": 10375}
{"episode_reward": 208.06285248172762, "episode": 84.0, "Q1 loss": 5.111188369750977, "Q2 loss": 5.1057279052734375, "Mean Target Q": 76.46707427978515, "Mean Q1": 76.46200347900391, "Mean Q2": 76.46113360595703, "critic_loss": 10.216916271209717, "batch_reward": 1.5340160665512086, "actor_loss": -77.09508539015248, "actor_target_entropy": -1.0, "actor_entropy": 0.47039103700268653, "alpha_loss": -0.061068794179347255, "alpha_value": 0.1314497950821125, "duration": 120.48875784873962, "step": 10500}
{"episode_reward": 204.67060196341583, "episode": 85.0, "Q1 loss": 4.856449104309082, "Q2 loss": 4.831952878952026, "Mean Target Q": 77.28906732177734, "Mean Q1": 77.28660070800781, "Mean Q2": 77.28609057617187, "critic_loss": 9.688401969909668, "batch_reward": 1.5326567668914794, "actor_loss": -78.00555395701575, "actor_target_entropy": -1.0, "actor_entropy": 0.437539089293707, "alpha_loss": -0.057967893897540985, "alpha_value": 0.1322631721661766, "duration": 119.855215549469, "step": 10625}
{"episode_reward": 172.1017723573244, "episode": 86.0, "Q1 loss": 5.2814239921569825, "Q2 loss": 5.270524297714234, "Mean Target Q": 78.15201037597656, "Mean Q1": 78.14129852294921, "Mean Q2": 78.14175897216796, "critic_loss": 10.551948314666747, "batch_reward": 1.5278825025558471, "actor_loss": -78.74356891262916, "actor_target_entropy": -1.0, "actor_entropy": 0.4404452572907171, "alpha_loss": -0.05790956354429645, "alpha_value": 0.1330708006561609, "duration": 114.22268748283386, "step": 10750}
{"episode_reward": 192.87308533998743, "episode": 87.0, "Q1 loss": 5.142816709518432, "Q2 loss": 5.185737604141235, "Mean Target Q": 79.027341796875, "Mean Q1": 79.0242348022461, "Mean Q2": 79.02375402832031, "critic_loss": 10.328554363250733, "batch_reward": 1.5394345808029175, "actor_loss": -79.65844096834698, "actor_target_entropy": -1.0, "actor_entropy": 0.4532244735293918, "alpha_loss": -0.06337796565559176, "alpha_value": 0.1339307092682934, "duration": 139.39750051498413, "step": 10875}
{"episode_reward": 219.78290414084276, "episode": 88.0, "Q1 loss": 5.1851234626770015, "Q2 loss": 5.183264476776123, "Mean Target Q": 79.94881317138672, "Mean Q1": 79.94905902099609, "Mean Q2": 79.94963513183593, "critic_loss": 10.36838790512085, "batch_reward": 1.535428053855896, "actor_loss": -80.47888860394877, "actor_target_entropy": -1.0, "actor_entropy": 0.49110704804620436, "alpha_loss": -0.059475485175367326, "alpha_value": 0.13479582859420647, "duration": 126.77688217163086, "step": 11000}
{"episode_reward": 161.41817246218218, "episode": 89.0, "Q1 loss": 5.344645809173584, "Q2 loss": 5.31413383102417, "Mean Target Q": 80.76747589111328, "Mean Q1": 80.76541717529297, "Mean Q2": 80.76520196533203, "critic_loss": 10.658779644012451, "batch_reward": 1.54089928150177, "actor_loss": -81.49998692103794, "actor_target_entropy": -1.0, "actor_entropy": 0.45815004715843805, "alpha_loss": -0.058583011525490926, "alpha_value": 0.13563000262543656, "duration": 116.122793674469, "step": 11125}
{"episode_reward": 164.06356910636495, "episode": 90.0, "Q1 loss": 5.629163061141968, "Q2 loss": 5.6108347511291505, "Mean Target Q": 81.58821240234376, "Mean Q1": 81.58401678466797, "Mean Q2": 81.58394793701171, "critic_loss": 11.239997840881347, "batch_reward": 1.5330169296264649, "actor_loss": -82.17937826341198, "actor_target_entropy": -1.0, "actor_entropy": 0.45558608251233257, "alpha_loss": -0.06424523625643022, "alpha_value": 0.13649900210622545, "duration": 116.75073289871216, "step": 11250}
{"episode_reward": 249.62407018360713, "episode": 91.0, "Q1 loss": 5.1507496223449705, "Q2 loss": 5.130422815322876, "Mean Target Q": 82.40577667236329, "Mean Q1": 82.40237573242187, "Mean Q2": 82.4028970336914, "critic_loss": 10.281172428131104, "batch_reward": 1.5232922401428222, "actor_loss": -83.06794799320282, "actor_target_entropy": -1.0, "actor_entropy": 0.45455198770477656, "alpha_loss": -0.06085281316486616, "alpha_value": 0.13739009443995798, "duration": 116.80658531188965, "step": 11375}
{"episode_reward": 154.78054740136508, "episode": 92.0, "Q1 loss": 4.762721151351928, "Q2 loss": 4.779082590103149, "Mean Target Q": 83.18507446289063, "Mean Q1": 83.1821978149414, "Mean Q2": 83.18170141601563, "critic_loss": 9.541803787231446, "batch_reward": 1.536336630821228, "actor_loss": -83.79586324384135, "actor_target_entropy": -1.0, "actor_entropy": 0.48031967397659053, "alpha_loss": -0.056290190486658, "alpha_value": 0.1382599960021582, "duration": 130.06470489501953, "step": 11500}
{"episode_reward": 206.4224274215686, "episode": 93.0, "Q1 loss": 5.172036533355713, "Q2 loss": 5.1640462284088136, "Mean Target Q": 84.03062329101563, "Mean Q1": 84.02846997070313, "Mean Q2": 84.02987738037109, "critic_loss": 10.336082775115967, "batch_reward": 1.5453207216262816, "actor_loss": -84.62928105914403, "actor_target_entropy": -1.0, "actor_entropy": 0.4627831299153585, "alpha_loss": -0.05419644565572814, "alpha_value": 0.13902945508422268, "duration": 148.93354725837708, "step": 11625}
{"episode_reward": 188.80353994717265, "episode": 94.0, "Q1 loss": 5.123730304718017, "Q2 loss": 5.124056991577149, "Mean Target Q": 84.7792944946289, "Mean Q1": 84.77258184814453, "Mean Q2": 84.77147485351563, "critic_loss": 10.24778733062744, "batch_reward": 1.5310729713439941, "actor_loss": -85.3412964113297, "actor_target_entropy": -1.0, "actor_entropy": 0.4558674481607253, "alpha_loss": -0.06013043287901148, "alpha_value": 0.13985488164448828, "duration": 122.5083680152893, "step": 11750}
{"episode_reward": 205.84838075203217, "episode": 95.0, "Q1 loss": 5.194079513549805, "Q2 loss": 5.205447502136231, "Mean Target Q": 85.71828173828125, "Mean Q1": 85.71344500732422, "Mean Q2": 85.71347045898438, "critic_loss": 10.399527000427247, "batch_reward": 1.5389658374786377, "actor_loss": -86.36755504305401, "actor_target_entropy": -1.0, "actor_entropy": 0.45364912492888315, "alpha_loss": -0.05939065771443503, "alpha_value": 0.14073608346749072, "duration": 120.80539751052856, "step": 11875}
{"episode_reward": 191.45288671218503, "episode": 96.0, "Q1 loss": 5.188640827178955, "Q2 loss": 5.195403642654419, "Mean Target Q": 86.54339959716796, "Mean Q1": 86.54103009033203, "Mean Q2": 86.54116644287109, "critic_loss": 10.384044498443604, "batch_reward": 1.5407712450027466, "actor_loss": -87.1623047859438, "actor_target_entropy": -1.0, "actor_entropy": 0.47127731144428253, "alpha_loss": -0.05661916846950208, "alpha_value": 0.14159463586710727, "duration": 136.30704259872437, "step": 12000}
{"episode_reward": 219.27124901644424, "episode": 97.0, "Q1 loss": 5.269003431320191, "Q2 loss": 5.2981697368621825, "Mean Target Q": 87.30499926757813, "Mean Q1": 87.30031988525391, "Mean Q2": 87.30081072998047, "critic_loss": 10.567173141479492, "batch_reward": 1.5386446933746338, "actor_loss": -87.90087805853949, "actor_target_entropy": -1.0, "actor_entropy": 0.4577753174872625, "alpha_loss": -0.05603478050657681, "alpha_value": 0.14240496659834764, "duration": 116.35498785972595, "step": 12125}
{"episode_reward": 240.807916774474, "episode": 98.0, "Q1 loss": 4.845805006027222, "Q2 loss": 4.859510877609253, "Mean Target Q": 88.10533502197265, "Mean Q1": 88.10221472167969, "Mean Q2": 88.10295874023437, "critic_loss": 9.705315898895263, "batch_reward": 1.550438786506653, "actor_loss": -88.61060690110729, "actor_target_entropy": -1.0, "actor_entropy": 0.4221295844162664, "alpha_loss": -0.05660474432572242, "alpha_value": 0.14327110855999575, "duration": 112.40100979804993, "step": 12250}
{"episode_reward": 231.33123695937263, "episode": 99.0, "Q1 loss": 4.954313222885132, "Q2 loss": 4.96910807800293, "Mean Target Q": 88.90961938476562, "Mean Q1": 88.91009252929688, "Mean Q2": 88.90864801025391, "critic_loss": 9.923421279907227, "batch_reward": 1.5434150142669678, "actor_loss": -89.47457425556486, "actor_target_entropy": -1.0, "actor_entropy": 0.4220145666410053, "alpha_loss": -0.05782440733460207, "alpha_value": 0.1441230354821568, "duration": 113.59592366218567, "step": 12375}
{"episode_reward": 251.26376761592942, "episode": 100.0, "Q1 loss": 5.0075048751831055, "Q2 loss": 5.028307119369507, "Mean Target Q": 89.63742669677734, "Mean Q1": 89.62843823242187, "Mean Q2": 89.62838293457031, "critic_loss": 10.035812034606934, "batch_reward": 1.5527157564163208, "actor_loss": -90.28565757505355, "actor_target_entropy": -1.0, "actor_entropy": 0.43705674717503207, "alpha_loss": -0.05502109572051033, "alpha_value": 0.14499188848615943, "duration": 106.78029274940491, "step": 12500}
{"episode_reward": 216.73486455810792, "episode": 101.0, "Q1 loss": 5.195664875030517, "Q2 loss": 5.194439395904541, "Mean Target Q": 90.38951342773437, "Mean Q1": 90.38770184326172, "Mean Q2": 90.38822564697266, "critic_loss": 10.390104286193848, "batch_reward": 1.5535444622039796, "actor_loss": -90.95762634277344, "actor_target_entropy": -1.0, "actor_entropy": 0.4650090431410169, "alpha_loss": -0.057225835465249564, "alpha_value": 0.1458204365747056, "duration": 116.3097026348114, "step": 12625}
{"episode_reward": 223.6827044869186, "episode": 102.0, "Q1 loss": 5.202616771697998, "Q2 loss": 5.1935434322357175, "Mean Target Q": 91.23592419433594, "Mean Q1": 91.23464776611328, "Mean Q2": 91.23395672607423, "critic_loss": 10.39616021347046, "batch_reward": 1.5659044542312621, "actor_loss": -91.89864361670709, "actor_target_entropy": -1.0, "actor_entropy": 0.460610271942231, "alpha_loss": -0.0525743986570066, "alpha_value": 0.14668077625832923, "duration": 112.2773003578186, "step": 12750}
{"episode_reward": 286.62567793158905, "episode": 103.0, "Q1 loss": 5.139610731124878, "Q2 loss": 5.1326677589416505, "Mean Target Q": 91.94397576904296, "Mean Q1": 91.93962744140624, "Mean Q2": 91.94011291503907, "critic_loss": 10.272278469085693, "batch_reward": 1.5634453048706054, "actor_loss": -92.53993733723958, "actor_target_entropy": -1.0, "actor_entropy": 0.4354148578076136, "alpha_loss": -0.06261139877495311, "alpha_value": 0.14758606778854969, "duration": 108.76805758476257, "step": 12875}
{"episode_reward": 259.89051555149496, "episode": 104.0, "Q1 loss": 5.2266557483673095, "Q2 loss": 5.2144587059021, "Mean Target Q": 92.74548565673828, "Mean Q1": 92.74019189453125, "Mean Q2": 92.73949499511718, "critic_loss": 10.441114494323731, "batch_reward": 1.5662028474807739, "actor_loss": -93.32080545733052, "actor_target_entropy": -1.0, "actor_entropy": 0.45431203274957593, "alpha_loss": -0.056065837552230206, "alpha_value": 0.1484882685526394, "duration": 138.6772220134735, "step": 13000}
{"episode_reward": 144.90657741459668, "episode": 105.0, "Q1 loss": 5.354771385192871, "Q2 loss": 5.340310039520264, "Mean Target Q": 93.53680859375, "Mean Q1": 93.53277166748047, "Mean Q2": 93.53405975341796, "critic_loss": 10.695081398010254, "batch_reward": 1.5630407667160033, "actor_loss": -94.21856289818173, "actor_target_entropy": -1.0, "actor_entropy": 0.43684926439845373, "alpha_loss": -0.06155820356474982, "alpha_value": 0.14940019900476983, "duration": 133.85734868049622, "step": 13125}
{"episode_reward": 125.41453800978506, "episode": 106.0, "Q1 loss": 5.090060428619385, "Q2 loss": 5.088712600708008, "Mean Target Q": 94.22992565917968, "Mean Q1": 94.22618963623047, "Mean Q2": 94.22608331298828, "critic_loss": 10.178773017883302, "batch_reward": 1.5521972723007202, "actor_loss": -94.74996209913685, "actor_target_entropy": -1.0, "actor_entropy": 0.4473796198444982, "alpha_loss": -0.05685920646834758, "alpha_value": 0.15032636668043114, "duration": 137.10360026359558, "step": 13250}
{"episode_reward": 267.9472028450617, "episode": 107.0, "Q1 loss": 5.091378921508789, "Q2 loss": 5.052189682006836, "Mean Target Q": 95.00490582275391, "Mean Q1": 95.0061763305664, "Mean Q2": 95.00592492675781, "critic_loss": 10.143568634033203, "batch_reward": 1.5626916637420654, "actor_loss": -95.48875826881046, "actor_target_entropy": -1.0, "actor_entropy": 0.44804591886580936, "alpha_loss": -0.05733357559120844, "alpha_value": 0.15124828490100195, "duration": 132.82463002204895, "step": 13375}
{"episode_reward": 188.92624615822882, "episode": 108.0, "Q1 loss": 5.412518255233764, "Q2 loss": 5.415055335998535, "Mean Target Q": 95.68955462646484, "Mean Q1": 95.68514453125, "Mean Q2": 95.68550463867187, "critic_loss": 10.827573585510255, "batch_reward": 1.549038188934326, "actor_loss": -96.24900596372542, "actor_target_entropy": -1.0, "actor_entropy": 0.4583460361726822, "alpha_loss": -0.05792071484029293, "alpha_value": 0.15217297831367155, "duration": 147.50173568725586, "step": 13500}
{"episode_reward": 262.72482068252225, "episode": 109.0, "Q1 loss": 5.020098236083984, "Q2 loss": 5.037120000839233, "Mean Target Q": 96.43386840820312, "Mean Q1": 96.42941522216798, "Mean Q2": 96.4296439819336, "critic_loss": 10.057218269348144, "batch_reward": 1.5582426862716674, "actor_loss": -97.02496277339874, "actor_target_entropy": -1.0, "actor_entropy": 0.44309012142438736, "alpha_loss": -0.05774419769526474, "alpha_value": 0.1530809841755861, "duration": 121.76671743392944, "step": 13625}
{"episode_reward": 140.39670560446058, "episode": 110.0, "Q1 loss": 5.060527889251709, "Q2 loss": 5.077060708999634, "Mean Target Q": 97.10033428955079, "Mean Q1": 97.09804168701172, "Mean Q2": 97.09739282226562, "critic_loss": 10.137588554382324, "batch_reward": 1.5683194332122803, "actor_loss": -97.63836989864227, "actor_target_entropy": -1.0, "actor_entropy": 0.4138397316057836, "alpha_loss": -0.05731617196673347, "alpha_value": 0.15403486263424834, "duration": 129.49214959144592, "step": 13750}
{"episode_reward": 223.82793790163623, "episode": 111.0, "Q1 loss": 5.142680812835693, "Q2 loss": 5.1391136207580566, "Mean Target Q": 97.77320422363282, "Mean Q1": 97.76913208007812, "Mean Q2": 97.76945013427735, "critic_loss": 10.281794410705567, "batch_reward": 1.5612100458145142, "actor_loss": -98.3021994696723, "actor_target_entropy": -1.0, "actor_entropy": 0.44421894209725515, "alpha_loss": -0.05487688793431199, "alpha_value": 0.15491816660210264, "duration": 138.98760867118835, "step": 13875}
{"episode_reward": 208.58848399904375, "episode": 112.0, "Q1 loss": 4.968653427124023, "Q2 loss": 4.984379770278931, "Mean Target Q": 98.4916953125, "Mean Q1": 98.488005859375, "Mean Q2": 98.48728314208985, "critic_loss": 9.953033187866211, "batch_reward": 1.5640786266326905, "actor_loss": -99.1280271468624, "actor_target_entropy": -1.0, "actor_entropy": 0.4533588607465067, "alpha_loss": -0.05897705704574623, "alpha_value": 0.1558615413938171, "duration": 119.67478060722351, "step": 14000}
{"episode_reward": 207.80855594930048, "episode": 113.0, "Q1 loss": 5.42058444404602, "Q2 loss": 5.438107204437256, "Mean Target Q": 99.23749438476563, "Mean Q1": 99.23414501953125, "Mean Q2": 99.23458038330078, "critic_loss": 10.858691619873047, "batch_reward": 1.5608387451171875, "actor_loss": -99.75307428269159, "actor_target_entropy": -1.0, "actor_entropy": 0.4382141639315893, "alpha_loss": -0.05662611135769458, "alpha_value": 0.1568121123705626, "duration": 118.76312232017517, "step": 14125}
{"episode_reward": 236.22267140725603, "episode": 114.0, "Q1 loss": 5.516478162765503, "Q2 loss": 5.5082856388092045, "Mean Target Q": 99.93920690917969, "Mean Q1": 99.94056024169922, "Mean Q2": 99.94069451904296, "critic_loss": 11.024763801574707, "batch_reward": 1.5644989070892334, "actor_loss": -100.48145503382528, "actor_target_entropy": -1.0, "actor_entropy": 0.449390945415343, "alpha_loss": -0.05663902835259514, "alpha_value": 0.1577443043560955, "duration": 106.21563172340393, "step": 14250}
{"episode_reward": 193.38327519913577, "episode": 115.0, "Q1 loss": 5.300965124130249, "Q2 loss": 5.27953991317749, "Mean Target Q": 100.67985986328125, "Mean Q1": 100.67015130615235, "Mean Q2": 100.6700322265625, "critic_loss": 10.5805050201416, "batch_reward": 1.5739127178192138, "actor_loss": -101.22171662345765, "actor_target_entropy": -1.0, "actor_entropy": 0.4456170504055326, "alpha_loss": -0.0540912017107956, "alpha_value": 0.15866752627327385, "duration": 107.56292009353638, "step": 14375}
{"episode_reward": 272.71118342476865, "episode": 116.0, "Q1 loss": 5.344819969177246, "Q2 loss": 5.339409057617187, "Mean Target Q": 101.40465582275391, "Mean Q1": 101.40562585449219, "Mean Q2": 101.40579144287109, "critic_loss": 10.684229030609131, "batch_reward": 1.5743995237350463, "actor_loss": -101.93050175328409, "actor_target_entropy": -1.0, "actor_entropy": 0.4609755561236412, "alpha_loss": -0.05307000415820268, "alpha_value": 0.15955898310991543, "duration": 110.45453214645386, "step": 14500}
{"episode_reward": 225.69415405372382, "episode": 117.0, "Q1 loss": 5.257569957733154, "Q2 loss": 5.228061243057251, "Mean Target Q": 102.16479443359376, "Mean Q1": 102.16285217285156, "Mean Q2": 102.16319177246093, "critic_loss": 10.485631206512451, "batch_reward": 1.578612148284912, "actor_loss": -102.70406087239583, "actor_target_entropy": -1.0, "actor_entropy": 0.44177078396554975, "alpha_loss": -0.05359440905943749, "alpha_value": 0.160468459874732, "duration": 133.9535529613495, "step": 14625}
{"episode_reward": 260.34689808763284, "episode": 118.0, "Q1 loss": 5.365093160629272, "Q2 loss": 5.354693908691406, "Mean Target Q": 102.83095043945312, "Mean Q1": 102.82740161132813, "Mean Q2": 102.82815911865234, "critic_loss": 10.719787086486816, "batch_reward": 1.5886293659210204, "actor_loss": -103.47542030580583, "actor_target_entropy": -1.0, "actor_entropy": 0.43320588046504604, "alpha_loss": -0.05433763251189263, "alpha_value": 0.16137799764708222, "duration": 140.63603472709656, "step": 14750}
{"episode_reward": 231.62203950117393, "episode": 119.0, "Q1 loss": 5.493340509414673, "Q2 loss": 5.4977786808013915, "Mean Target Q": 103.51153662109375, "Mean Q1": 103.50626892089844, "Mean Q2": 103.50545599365235, "critic_loss": 10.991119148254395, "batch_reward": 1.5769990396499634, "actor_loss": -104.15302034408327, "actor_target_entropy": -1.0, "actor_entropy": 0.41002574988773893, "alpha_loss": -0.05248749288656409, "alpha_value": 0.16228505622206543, "duration": 108.74637222290039, "step": 14875}
{"episode_reward": 212.32203238420274, "episode": 120.0, "Q1 loss": 5.313372440338135, "Q2 loss": 5.343980525970459, "Mean Target Q": 104.21535821533203, "Mean Q1": 104.21083319091797, "Mean Q2": 104.21135552978515, "critic_loss": 10.657352924346924, "batch_reward": 1.5899678449630736, "actor_loss": -104.75355628228957, "actor_target_entropy": -1.0, "actor_entropy": 0.4300023634587565, "alpha_loss": -0.05255987508703144, "alpha_value": 0.1632109223739867, "step": 15000}
{"duration": 132.89691162109375, "step": 15000}
{"episode_reward": 231.5425164498552, "episode": 121.0, "Q1 loss": 5.25451972579956, "Q2 loss": 5.270085845947266, "Mean Target Q": 104.99276776123047, "Mean Q1": 104.99398999023437, "Mean Q2": 104.99254748535157, "critic_loss": 10.524605632781983, "batch_reward": 1.5957979831695557, "actor_loss": -105.53438640776135, "actor_target_entropy": -1.0, "actor_entropy": 0.4413749849985516, "alpha_loss": -0.047126369639521555, "alpha_value": 0.16408296834570438, "duration": 132.59043216705322, "step": 15125}
{"episode_reward": 179.47969140555333, "episode": 122.0, "Q1 loss": 5.0433282470703125, "Q2 loss": 5.014874328613281, "Mean Target Q": 105.5998310546875, "Mean Q1": 105.59577349853515, "Mean Q2": 105.5977533569336, "critic_loss": 10.058202548980713, "batch_reward": 1.5964397869110107, "actor_loss": -106.16966050670993, "actor_target_entropy": -1.0, "actor_entropy": 0.42295415723516094, "alpha_loss": -0.055720628179129095, "alpha_value": 0.16500109542759608, "duration": 148.58868932724, "step": 15250}
{"episode_reward": 280.6054870316468, "episode": 123.0, "Q1 loss": 5.09378031539917, "Q2 loss": 5.105455614089966, "Mean Target Q": 106.38844421386719, "Mean Q1": 106.38204705810547, "Mean Q2": 106.38083221435546, "critic_loss": 10.199235961914063, "batch_reward": 1.6064984617233276, "actor_loss": -107.02453225756449, "actor_target_entropy": -1.0, "actor_entropy": 0.4289477467536926, "alpha_loss": -0.05161090869279135, "alpha_value": 0.16596101568066596, "duration": 126.6471700668335, "step": 15375}
{"episode_reward": 226.69547162676915, "episode": 124.0, "Q1 loss": 5.524832715988159, "Q2 loss": 5.521550527572632, "Mean Target Q": 106.9650689086914, "Mean Q1": 106.96987292480469, "Mean Q2": 106.97042175292968, "critic_loss": 11.046383251190186, "batch_reward": 1.5874876556396484, "actor_loss": -107.52277312740203, "actor_target_entropy": -1.0, "actor_entropy": 0.41363460498471416, "alpha_loss": -0.04624048835267463, "alpha_value": 0.16684834806491863, "duration": 117.13331580162048, "step": 15500}
{"episode_reward": 206.35906551784294, "episode": 125.0, "Q1 loss": 5.453351863861084, "Q2 loss": 5.5266086235046386, "Mean Target Q": 107.67173919677734, "Mean Q1": 107.66503948974609, "Mean Q2": 107.66512310791016, "critic_loss": 10.979960502624511, "batch_reward": 1.5926219673156738, "actor_loss": -108.2029791937934, "actor_target_entropy": -1.0, "actor_entropy": 0.4397472729758611, "alpha_loss": -0.04482362719459666, "alpha_value": 0.16769442673413204, "duration": 135.15763902664185, "step": 15625}
{"episode_reward": 189.04647129795455, "episode": 126.0, "Q1 loss": 5.340002950668335, "Q2 loss": 5.313987537384033, "Mean Target Q": 108.23455584716797, "Mean Q1": 108.2303201904297, "Mean Q2": 108.23049060058594, "critic_loss": 10.653990509033203, "batch_reward": 1.5818738117218019, "actor_loss": -108.81048091765373, "actor_target_entropy": -1.0, "actor_entropy": 0.4526198963003774, "alpha_loss": -0.04483815052756859, "alpha_value": 0.16854814844685412, "duration": 131.75691747665405, "step": 15750}
{"episode_reward": 169.93169072039697, "episode": 127.0, "Q1 loss": 5.371731979370117, "Q2 loss": 5.376862180709839, "Mean Target Q": 108.95143463134765, "Mean Q1": 108.94325311279297, "Mean Q2": 108.94140173339844, "critic_loss": 10.74859421157837, "batch_reward": 1.600246883392334, "actor_loss": -109.48776656862289, "actor_target_entropy": -1.0, "actor_entropy": 0.44938999556359793, "alpha_loss": -0.04699366928506938, "alpha_value": 0.16938392311072828, "duration": 108.34221911430359, "step": 15875}
{"episode_reward": 200.43649291415787, "episode": 128.0, "Q1 loss": 5.752487598419189, "Q2 loss": 5.779096672058105, "Mean Target Q": 109.54396807861328, "Mean Q1": 109.54681591796874, "Mean Q2": 109.54709460449219, "critic_loss": 11.531584293365478, "batch_reward": 1.5908378915786743, "actor_loss": -110.13337079940304, "actor_target_entropy": -1.0, "actor_entropy": 0.45402321219444275, "alpha_loss": -0.04240301240896506, "alpha_value": 0.1702625374725467, "duration": 104.18303346633911, "step": 16000}
{"episode_reward": 199.63877720130722, "episode": 129.0, "Q1 loss": 5.522110370635986, "Q2 loss": 5.535378932952881, "Mean Target Q": 110.2401138305664, "Mean Q1": 110.23222583007812, "Mean Q2": 110.23265856933594, "critic_loss": 11.057489322662354, "batch_reward": 1.5875294809341431, "actor_loss": -110.69410330151754, "actor_target_entropy": -1.0, "actor_entropy": 0.44782160813846283, "alpha_loss": -0.048559105688972135, "alpha_value": 0.17111933999133566, "duration": 102.10844397544861, "step": 16125}
{"episode_reward": 222.7109414991736, "episode": 130.0, "Q1 loss": 5.397764356613159, "Q2 loss": 5.370910612106323, "Mean Target Q": 110.85045037841797, "Mean Q1": 110.85282287597656, "Mean Q2": 110.85346081542968, "critic_loss": 10.768674964904784, "batch_reward": 1.5828020858764649, "actor_loss": -111.45495125555223, "actor_target_entropy": -1.0, "actor_entropy": 0.4241447645810343, "alpha_loss": -0.04282577984756039, "alpha_value": 0.1720125119940204, "duration": 106.69948387145996, "step": 16250}
{"episode_reward": 184.75034411714074, "episode": 131.0, "Q1 loss": 5.126694660186768, "Q2 loss": 5.095783716201782, "Mean Target Q": 111.46271215820312, "Mean Q1": 111.45559930419923, "Mean Q2": 111.45541137695312, "critic_loss": 10.222478385925292, "batch_reward": 1.6049067449569703, "actor_loss": -111.96315462627108, "actor_target_entropy": -1.0, "actor_entropy": 0.4531775883265904, "alpha_loss": -0.04357698646980145, "alpha_value": 0.17284126151439716, "duration": 117.40503740310669, "step": 16375}
{"episode_reward": 255.61436970564364, "episode": 132.0, "Q1 loss": 5.300717882156372, "Q2 loss": 5.337064344406128, "Mean Target Q": 112.11985729980469, "Mean Q1": 112.11660833740234, "Mean Q2": 112.11642657470703, "critic_loss": 10.637782207489014, "batch_reward": 1.6016294841766356, "actor_loss": -112.67564798170521, "actor_target_entropy": -1.0, "actor_entropy": 0.43296312228325873, "alpha_loss": -0.044605005352247144, "alpha_value": 0.17374243528369493, "duration": 105.15611124038696, "step": 16500}
{"episode_reward": 228.58360277901727, "episode": 133.0, "Q1 loss": 5.311270524978638, "Q2 loss": 5.326052080154419, "Mean Target Q": 112.75861895751953, "Mean Q1": 112.75894104003906, "Mean Q2": 112.7588871459961, "critic_loss": 10.63732260131836, "batch_reward": 1.6074645156860352, "actor_loss": -113.27471875387525, "actor_target_entropy": -1.0, "actor_entropy": 0.4581326747697497, "alpha_loss": -0.04260996740961832, "alpha_value": 0.17463726799196846, "duration": 105.08601093292236, "step": 16625}
{"episode_reward": 312.11478192617164, "episode": 134.0, "Q1 loss": 5.446551137924194, "Q2 loss": 5.4718172740936275, "Mean Target Q": 113.4560971069336, "Mean Q1": 113.45352124023438, "Mean Q2": 113.45371350097656, "critic_loss": 10.918368408203126, "batch_reward": 1.6030939121246337, "actor_loss": -113.90091926820817, "actor_target_entropy": -1.0, "actor_entropy": 0.44892570520600966, "alpha_loss": -0.041273108567111194, "alpha_value": 0.17553972907796211, "duration": 107.2762520313263, "step": 16750}
{"episode_reward": 189.13424737180776, "episode": 135.0, "Q1 loss": 5.211496719360351, "Q2 loss": 5.182575656890869, "Mean Target Q": 114.02130297851562, "Mean Q1": 114.01808898925782, "Mean Q2": 114.01768603515625, "critic_loss": 10.394072399139404, "batch_reward": 1.5996469774246216, "actor_loss": -114.54958040752108, "actor_target_entropy": -1.0, "actor_entropy": 0.4716858423891522, "alpha_loss": -0.044930029786117966, "alpha_value": 0.1764041647401496, "duration": 107.66598796844482, "step": 16875}
{"episode_reward": 229.39097300531537, "episode": 136.0, "Q1 loss": 5.227821420669556, "Q2 loss": 5.238484228134156, "Mean Target Q": 114.65162170410156, "Mean Q1": 114.6478204345703, "Mean Q2": 114.64699627685548, "critic_loss": 10.46630563735962, "batch_reward": 1.6054452295303345, "actor_loss": -115.17470107540008, "actor_target_entropy": -1.0, "actor_entropy": 0.438517403218054, "alpha_loss": -0.037584287752848, "alpha_value": 0.17727053483187324, "duration": 108.33976340293884, "step": 17000}
{"episode_reward": 154.55524713359313, "episode": 137.0, "Q1 loss": 5.67317541885376, "Q2 loss": 5.66827463722229, "Mean Target Q": 115.23279168701171, "Mean Q1": 115.22673065185546, "Mean Q2": 115.22787243652344, "critic_loss": 11.341450054168702, "batch_reward": 1.6028771543502807, "actor_loss": -115.74257345048208, "actor_target_entropy": -1.0, "actor_entropy": 0.46114163502814276, "alpha_loss": -0.039223473171688734, "alpha_value": 0.1780959697866748, "duration": 113.65809917449951, "step": 17125}
{"episode_reward": 242.90001147537723, "episode": 138.0, "Q1 loss": 5.296651027679443, "Q2 loss": 5.304472242355347, "Mean Target Q": 115.772017578125, "Mean Q1": 115.77295068359375, "Mean Q2": 115.77252380371094, "critic_loss": 10.60112327194214, "batch_reward": 1.5986937303543092, "actor_loss": -116.30151157994425, "actor_target_entropy": -1.0, "actor_entropy": 0.4557617998892261, "alpha_loss": -0.04122117785136065, "alpha_value": 0.1789962843855976, "duration": 103.57362651824951, "step": 17250}
{"episode_reward": 196.02542570784286, "episode": 139.0, "Q1 loss": 5.391852540969849, "Q2 loss": 5.3836680564880375, "Mean Target Q": 116.38431842041015, "Mean Q1": 116.38076049804687, "Mean Q2": 116.3810126953125, "critic_loss": 10.775520626068115, "batch_reward": 1.6052544164657592, "actor_loss": -116.84594496469649, "actor_target_entropy": -1.0, "actor_entropy": 0.44566647542847526, "alpha_loss": -0.03830839835646902, "alpha_value": 0.17984947027577908, "duration": 112.08349847793579, "step": 17375}
{"episode_reward": 255.98065440932842, "episode": 140.0, "Q1 loss": 5.389515285491943, "Q2 loss": 5.398919050216675, "Mean Target Q": 116.97454846191407, "Mean Q1": 116.97185357666015, "Mean Q2": 116.9720298461914, "critic_loss": 10.788434322357178, "batch_reward": 1.6045764513015748, "actor_loss": -117.4970345035676, "actor_target_entropy": -1.0, "actor_entropy": 0.43079188225730775, "alpha_loss": -0.03802835025764521, "alpha_value": 0.1807299604111692, "duration": 104.57284545898438, "step": 17500}
{"episode_reward": 260.606179521637, "episode": 141.0, "Q1 loss": 5.439944463729859, "Q2 loss": 5.451897598266601, "Mean Target Q": 117.59495404052734, "Mean Q1": 117.59586578369141, "Mean Q2": 117.59616009521484, "critic_loss": 10.891842052459717, "batch_reward": 1.606835536956787, "actor_loss": -118.11715116954986, "actor_target_entropy": -1.0, "actor_entropy": 0.46593180014973595, "alpha_loss": -0.03762953274602455, "alpha_value": 0.18152925214323823, "duration": 126.95419096946716, "step": 17625}
{"episode_reward": 203.54676987473556, "episode": 142.0, "Q1 loss": 5.557421329498291, "Q2 loss": 5.522519004821778, "Mean Target Q": 118.1629213256836, "Mean Q1": 118.15700213623047, "Mean Q2": 118.15712689208985, "critic_loss": 11.079940361022949, "batch_reward": 1.603905382156372, "actor_loss": -118.65332449636152, "actor_target_entropy": -1.0, "actor_entropy": 0.4383647100579354, "alpha_loss": -0.04116166587318144, "alpha_value": 0.18245102473432248, "duration": 138.84844374656677, "step": 17750}
{"episode_reward": 248.2857581029921, "episode": 143.0, "Q1 loss": 5.676604846954346, "Q2 loss": 5.679608751296997, "Mean Target Q": 118.71805084228515, "Mean Q1": 118.71493469238281, "Mean Q2": 118.71489880371094, "critic_loss": 11.356213584899903, "batch_reward": 1.6123646936416627, "actor_loss": -119.20320807562933, "actor_target_entropy": -1.0, "actor_entropy": 0.45534098006430124, "alpha_loss": -0.030697316127193588, "alpha_value": 0.18326761100467265, "duration": 122.64440035820007, "step": 17875}
{"episode_reward": 217.46012141810692, "episode": 144.0, "Q1 loss": 5.423772727966308, "Q2 loss": 5.378342594146728, "Mean Target Q": 119.23417987060547, "Mean Q1": 119.2329341430664, "Mean Q2": 119.23227813720703, "critic_loss": 10.802115303039551, "batch_reward": 1.6062058095932006, "actor_loss": -119.74954063661637, "actor_target_entropy": -1.0, "actor_entropy": 0.4606980989056249, "alpha_loss": -0.033414041458238515, "alpha_value": 0.18410106537052315, "duration": 140.04642868041992, "step": 18000}
{"episode_reward": 208.71504534775357, "episode": 145.0, "Q1 loss": 5.34281990814209, "Q2 loss": 5.335382577896119, "Mean Target Q": 119.71694409179688, "Mean Q1": 119.7154165649414, "Mean Q2": 119.71477630615234, "critic_loss": 10.678202487945557, "batch_reward": 1.6065351209640504, "actor_loss": -120.20822204105438, "actor_target_entropy": -1.0, "actor_entropy": 0.4376764680658068, "alpha_loss": -0.032674309738453415, "alpha_value": 0.18481649740164513, "duration": 137.5678150653839, "step": 18125}
{"episode_reward": 239.07968904268094, "episode": 146.0, "Q1 loss": 5.447059970855713, "Q2 loss": 5.4557346286773685, "Mean Target Q": 120.41181481933594, "Mean Q1": 120.40976641845702, "Mean Q2": 120.41025170898438, "critic_loss": 10.902794620513916, "batch_reward": 1.6133403482437134, "actor_loss": -120.9436283726846, "actor_target_entropy": -1.0, "actor_entropy": 0.45282699984888874, "alpha_loss": -0.03340956144740865, "alpha_value": 0.18567495880475635, "duration": 135.2968831062317, "step": 18250}
{"episode_reward": 249.95858287420614, "episode": 147.0, "Q1 loss": 5.377330135345459, "Q2 loss": 5.401895696640015, "Mean Target Q": 120.89183514404297, "Mean Q1": 120.88948858642578, "Mean Q2": 120.88845977783203, "critic_loss": 10.779225860595703, "batch_reward": 1.605802201271057, "actor_loss": -121.37656560019842, "actor_target_entropy": -1.0, "actor_entropy": 0.44010323711803984, "alpha_loss": -0.031305635739709174, "alpha_value": 0.18648327211074636, "duration": 137.66152501106262, "step": 18375}
{"episode_reward": 174.15397500311437, "episode": 148.0, "Q1 loss": 5.794333282470703, "Q2 loss": 5.792054388046265, "Mean Target Q": 121.53453289794922, "Mean Q1": 121.52855114746093, "Mean Q2": 121.52834265136718, "critic_loss": 11.586387649536134, "batch_reward": 1.6210194911956788, "actor_loss": -122.05824895058909, "actor_target_entropy": -1.0, "actor_entropy": 0.4820478957506918, "alpha_loss": -0.02596616060022385, "alpha_value": 0.18717989396554652, "duration": 142.11036348342896, "step": 18500}
{"episode_reward": 219.13014831967007, "episode": 149.0, "Q1 loss": 5.71589621925354, "Q2 loss": 5.708548542022705, "Mean Target Q": 121.97470050048828, "Mean Q1": 121.97239056396485, "Mean Q2": 121.97289666748047, "critic_loss": 11.424444766998292, "batch_reward": 1.610664689064026, "actor_loss": -122.47499580988809, "actor_target_entropy": -1.0, "actor_entropy": 0.4470269046132527, "alpha_loss": -0.026837081278836918, "alpha_value": 0.18783118669006466, "duration": 109.23608064651489, "step": 18625}
{"episode_reward": 212.8571149716346, "episode": 150.0, "Q1 loss": 5.285754686355591, "Q2 loss": 5.284715562820435, "Mean Target Q": 122.5015936279297, "Mean Q1": 122.49649371337891, "Mean Q2": 122.49707006835938, "critic_loss": 10.570470283508302, "batch_reward": 1.612050503730774, "actor_loss": -122.92154595159715, "actor_target_entropy": -1.0, "actor_entropy": 0.47325886689847513, "alpha_loss": -0.02560789124559491, "alpha_value": 0.1885316797613045, "duration": 106.97755360603333, "step": 18750}
{"episode_reward": 253.37424273158427, "episode": 151.0, "Q1 loss": 5.524761692047119, "Q2 loss": 5.538590297698975, "Mean Target Q": 123.11692669677734, "Mean Q1": 123.1132431640625, "Mean Q2": 123.11393957519532, "critic_loss": 11.063352005004884, "batch_reward": 1.6245428895950318, "actor_loss": -123.62511310880146, "actor_target_entropy": -1.0, "actor_entropy": 0.4574594587560684, "alpha_loss": -0.02901618353401621, "alpha_value": 0.18926380234245274, "duration": 130.3714063167572, "step": 18875}
{"episode_reward": 215.37951719511113, "episode": 152.0, "Q1 loss": 5.337436769485474, "Q2 loss": 5.313041620254516, "Mean Target Q": 123.67728375244141, "Mean Q1": 123.67814685058593, "Mean Q2": 123.67778100585937, "critic_loss": 10.650478298187256, "batch_reward": 1.6344363775253297, "actor_loss": -124.18800329392955, "actor_target_entropy": -1.0, "actor_entropy": 0.45771287045171183, "alpha_loss": -0.028858888210848935, "alpha_value": 0.19005378515009466, "duration": 105.78118348121643, "step": 19000}
{"episode_reward": 195.69491252033578, "episode": 153.0, "Q1 loss": 5.226835510253906, "Q2 loss": 5.215889669418335, "Mean Target Q": 124.1268021850586, "Mean Q1": 124.12255700683593, "Mean Q2": 124.12367803955078, "critic_loss": 10.442725200653076, "batch_reward": 1.6189638013839722, "actor_loss": -124.65223148890904, "actor_target_entropy": -1.0, "actor_entropy": 0.45710239382017226, "alpha_loss": -0.026079416456114914, "alpha_value": 0.1908159054479491, "duration": 122.40087389945984, "step": 19125}
{"episode_reward": 226.52353206263192, "episode": 154.0, "Q1 loss": 5.201924890518188, "Q2 loss": 5.181074693679809, "Mean Target Q": 124.72050476074219, "Mean Q1": 124.71940020751953, "Mean Q2": 124.71764349365235, "critic_loss": 10.382999599456786, "batch_reward": 1.6152398614883423, "actor_loss": -125.21008214642924, "actor_target_entropy": -1.0, "actor_entropy": 0.4383176666113638, "alpha_loss": -0.027530980780870924, "alpha_value": 0.19161134351452974, "duration": 102.0970070362091, "step": 19250}
{"episode_reward": 205.10688351829415, "episode": 155.0, "Q1 loss": 5.501346502304077, "Q2 loss": 5.504544277191162, "Mean Target Q": 125.25020880126954, "Mean Q1": 125.24690698242188, "Mean Q2": 125.24823590087891, "critic_loss": 11.005890789031982, "batch_reward": 1.6271312551498414, "actor_loss": -125.7102807665628, "actor_target_entropy": -1.0, "actor_entropy": 0.45153703623347813, "alpha_loss": -0.024096273842992053, "alpha_value": 0.19232045761258423, "duration": 108.13874793052673, "step": 19375}
{"episode_reward": 207.06131058120846, "episode": 156.0, "Q1 loss": 5.4223895969390865, "Q2 loss": 5.416419090270996, "Mean Target Q": 125.77430584716797, "Mean Q1": 125.77550360107422, "Mean Q2": 125.7735609741211, "critic_loss": 10.83880862045288, "batch_reward": 1.6196868238449096, "actor_loss": -126.24070345970893, "actor_target_entropy": -1.0, "actor_entropy": 0.46853726188982686, "alpha_loss": -0.018700014341682676, "alpha_value": 0.19291075846478148, "duration": 102.9695234298706, "step": 19500}
{"episode_reward": 269.18136177356075, "episode": 157.0, "Q1 loss": 5.1293723583221436, "Q2 loss": 5.099826681137085, "Mean Target Q": 126.30519665527343, "Mean Q1": 126.30048022460937, "Mean Q2": 126.3024408569336, "critic_loss": 10.229199085235596, "batch_reward": 1.624565936088562, "actor_loss": -126.73403809562562, "actor_target_entropy": -1.0, "actor_entropy": 0.4595546443310995, "alpha_loss": -0.01863854515018858, "alpha_value": 0.1934877324663516, "duration": 103.18215608596802, "step": 19625}
{"episode_reward": 229.8111369866001, "episode": 158.0, "Q1 loss": 5.287270851135254, "Q2 loss": 5.293548210144043, "Mean Target Q": 126.82315759277344, "Mean Q1": 126.81765795898437, "Mean Q2": 126.81685394287109, "critic_loss": 10.580819038391112, "batch_reward": 1.6282748470306396, "actor_loss": -127.24230883198399, "actor_target_entropy": -1.0, "actor_entropy": 0.4210474683392432, "alpha_loss": -0.013559283191082818, "alpha_value": 0.19394934099873706, "duration": 122.0488452911377, "step": 19750}
{"episode_reward": 229.42151609376097, "episode": 159.0, "Q1 loss": 5.278762039184571, "Q2 loss": 5.286257425308228, "Mean Target Q": 127.2637660522461, "Mean Q1": 127.2648076171875, "Mean Q2": 127.26355340576171, "critic_loss": 10.565019462585449, "batch_reward": 1.6192482118606568, "actor_loss": -127.78003014458551, "actor_target_entropy": -1.0, "actor_entropy": 0.4477072088491349, "alpha_loss": -0.024664638253549736, "alpha_value": 0.19453322584863675, "duration": 108.721346616745, "step": 19875}
{"episode_reward": 194.4303512008406, "episode": 160.0, "Q1 loss": 5.480961889266967, "Q2 loss": 5.468761686325073, "Mean Target Q": 127.78888299560546, "Mean Q1": 127.78684753417969, "Mean Q2": 127.78756481933594, "critic_loss": 10.949723594665528, "batch_reward": 1.6277164087295533, "actor_loss": -128.25213918378276, "actor_target_entropy": -1.0, "actor_entropy": 0.45707124760074, "alpha_loss": -0.0240374714128613, "alpha_value": 0.19531044785004043, "step": 20000}
{"duration": 129.2861852645874, "step": 20000}
{"episode_reward": 220.96148723808372, "episode": 161.0, "Q1 loss": 5.325362871170044, "Q2 loss": 5.377620506286621, "Mean Target Q": 128.15624621582032, "Mean Q1": 128.15600811767578, "Mean Q2": 128.15595263671875, "critic_loss": 10.702983364105224, "batch_reward": 1.6322103900909424, "actor_loss": -128.57499501061818, "actor_target_entropy": -1.0, "actor_entropy": 0.44954548657886567, "alpha_loss": -0.020730455428184497, "alpha_value": 0.1960844010224128, "duration": 110.73733377456665, "step": 20125}
{"episode_reward": 212.35402015258913, "episode": 162.0, "Q1 loss": 5.466442274093628, "Q2 loss": 5.453889122009278, "Mean Target Q": 128.77123162841798, "Mean Q1": 128.76545111083985, "Mean Q2": 128.76504949951172, "critic_loss": 10.92033141708374, "batch_reward": 1.6293575849533082, "actor_loss": -129.17753256520916, "actor_target_entropy": -1.0, "actor_entropy": 0.4686995831228072, "alpha_loss": -0.015240663880362146, "alpha_value": 0.19661532059943132, "duration": 106.18230748176575, "step": 20250}
{"episode_reward": 234.12365277096262, "episode": 163.0, "Q1 loss": 5.459522926330567, "Q2 loss": 5.463543497085571, "Mean Target Q": 129.26371948242186, "Mean Q1": 129.26100238037108, "Mean Q2": 129.26191052246094, "critic_loss": 10.92306640625, "batch_reward": 1.6274162435531616, "actor_loss": -129.7312975686694, "actor_target_entropy": -1.0, "actor_entropy": 0.4937104294224391, "alpha_loss": -0.014200570394418069, "alpha_value": 0.19715988622963482, "duration": 115.89222311973572, "step": 20375}
{"episode_reward": 197.58068013021625, "episode": 164.0, "Q1 loss": 5.4135840892791744, "Q2 loss": 5.4167241325378415, "Mean Target Q": 129.62985498046876, "Mean Q1": 129.6247878417969, "Mean Q2": 129.6243659667969, "critic_loss": 10.830308235168458, "batch_reward": 1.627598232269287, "actor_loss": -130.06981363604146, "actor_target_entropy": -1.0, "actor_entropy": 0.47577201502938427, "alpha_loss": -0.014317008062085558, "alpha_value": 0.19760430692064204, "duration": 116.68857383728027, "step": 20500}
{"episode_reward": 244.9917254952995, "episode": 165.0, "Q1 loss": 5.715463033676148, "Q2 loss": 5.739713611602784, "Mean Target Q": 130.16471936035157, "Mean Q1": 130.16369470214843, "Mean Q2": 130.16316430664062, "critic_loss": 11.455176651000977, "batch_reward": 1.6326219463348388, "actor_loss": -130.62728857615636, "actor_target_entropy": -1.0, "actor_entropy": 0.47465019424756366, "alpha_loss": -0.008056460859416614, "alpha_value": 0.19798357474702366, "duration": 117.8970263004303, "step": 20625}
{"episode_reward": 235.22648821386827, "episode": 166.0, "Q1 loss": 5.4452874450683595, "Q2 loss": 5.4588991756439205, "Mean Target Q": 130.6567410888672, "Mean Q1": 130.65182678222655, "Mean Q2": 130.65171899414062, "critic_loss": 10.904186618804932, "batch_reward": 1.6372444047927857, "actor_loss": -131.16271431215347, "actor_target_entropy": -1.0, "actor_entropy": 0.4552815998754194, "alpha_loss": -0.016341251805574903, "alpha_value": 0.19841082057854625, "duration": 78.34566354751587, "step": 20750}
{"episode_reward": 221.21284441332116, "episode": 167.0, "Q1 loss": 5.51419694519043, "Q2 loss": 5.514567794799805, "Mean Target Q": 131.08992749023437, "Mean Q1": 131.0919970703125, "Mean Q2": 131.09216455078126, "critic_loss": 11.028764755249023, "batch_reward": 1.6276881847381592, "actor_loss": -131.5054691859654, "actor_target_entropy": -1.0, "actor_entropy": 0.4703073085300506, "alpha_loss": -0.021422969465631814, "alpha_value": 0.199175632937585, "duration": 63.56736350059509, "step": 20875}
{"episode_reward": 233.05842956383302, "episode": 168.0, "Q1 loss": 5.5908671016693114, "Q2 loss": 5.590438291549683, "Mean Target Q": 131.64506188964845, "Mean Q1": 131.64206604003905, "Mean Q2": 131.64183569335938, "critic_loss": 11.181305419921875, "batch_reward": 1.6322873497009278, "actor_loss": -132.17063780753844, "actor_target_entropy": -1.0, "actor_entropy": 0.4774592638977112, "alpha_loss": -0.015875832433061253, "alpha_value": 0.19985497034175878, "duration": 63.665976762771606, "step": 21000}
{"episode_reward": 243.60694527287833, "episode": 169.0, "Q1 loss": 5.293041641235352, "Q2 loss": 5.2904403743743895, "Mean Target Q": 132.10310339355468, "Mean Q1": 132.1007939453125, "Mean Q2": 132.10079650878907, "critic_loss": 10.583482040405274, "batch_reward": 1.6327413063049316, "actor_loss": -132.5531189933656, "actor_target_entropy": -1.0, "actor_entropy": 0.46707678125018165, "alpha_loss": -0.015391830181229919, "alpha_value": 0.20047107635407282, "duration": 70.84575748443604, "step": 21125}
{"episode_reward": 176.7987102593463, "episode": 170.0, "Q1 loss": 5.135239349365234, "Q2 loss": 5.135202028274536, "Mean Target Q": 132.53046740722655, "Mean Q1": 132.5280848388672, "Mean Q2": 132.52837951660158, "critic_loss": 10.270441360473633, "batch_reward": 1.6406688480377196, "actor_loss": -133.00240202872985, "actor_target_entropy": -1.0, "actor_entropy": 0.4920023122141438, "alpha_loss": -0.014165821432646724, "alpha_value": 0.2009935289632675, "duration": 61.151450395584106, "step": 21250}
{"episode_reward": 202.71432359502288, "episode": 171.0, "Q1 loss": 5.732091167449951, "Q2 loss": 5.704431568145752, "Mean Target Q": 132.95813403320312, "Mean Q1": 132.95853137207033, "Mean Q2": 132.95641540527345, "critic_loss": 11.436522735595704, "batch_reward": 1.6372608213424682, "actor_loss": -133.4214828733414, "actor_target_entropy": -1.0, "actor_entropy": 0.48659652518847635, "alpha_loss": -0.009001338440510962, "alpha_value": 0.2014512614542301, "duration": 65.76397180557251, "step": 21375}
{"episode_reward": 238.1573714769576, "episode": 172.0, "Q1 loss": 5.5414575004577635, "Q2 loss": 5.57093413734436, "Mean Target Q": 133.40855786132812, "Mean Q1": 133.40017395019532, "Mean Q2": 133.4028135986328, "critic_loss": 11.112391674041747, "batch_reward": 1.6356469011306762, "actor_loss": -133.85788062310988, "actor_target_entropy": -1.0, "actor_entropy": 0.4965887978192299, "alpha_loss": -0.009698961395770311, "alpha_value": 0.20184099483259926, "duration": 65.2102210521698, "step": 21500}
{"episode_reward": 261.4822119337003, "episode": 173.0, "Q1 loss": 5.223951124191284, "Q2 loss": 5.202115148544311, "Mean Target Q": 133.79945861816407, "Mean Q1": 133.80239306640624, "Mean Q2": 133.8028251953125, "critic_loss": 10.426066246032715, "batch_reward": 1.6459565734863282, "actor_loss": -134.2524644155351, "actor_target_entropy": -1.0, "actor_entropy": 0.4719762102005974, "alpha_loss": -0.017286418759751888, "alpha_value": 0.20234839978279082, "duration": 70.45821070671082, "step": 21625}
{"episode_reward": 205.5247776873707, "episode": 174.0, "Q1 loss": 5.2381823501586915, "Q2 loss": 5.260183050155639, "Mean Target Q": 134.31058020019532, "Mean Q1": 134.3075909423828, "Mean Q2": 134.30610632324218, "critic_loss": 10.49836540222168, "batch_reward": 1.639542956352234, "actor_loss": -134.782229515814, "actor_target_entropy": -1.0, "actor_entropy": 0.48947717153256937, "alpha_loss": -0.006138598244081462, "alpha_value": 0.2028549908303916, "duration": 69.43389344215393, "step": 21750}
{"episode_reward": 269.4960483143212, "episode": 175.0, "Q1 loss": 5.440852682113648, "Q2 loss": 5.454041753768921, "Mean Target Q": 134.70096398925782, "Mean Q1": 134.69922229003907, "Mean Q2": 134.6997227783203, "critic_loss": 10.894894435882568, "batch_reward": 1.6368680086135865, "actor_loss": -135.15766034807478, "actor_target_entropy": -1.0, "actor_entropy": 0.4748385435058957, "alpha_loss": -0.010984844047694451, "alpha_value": 0.2031890292643647, "duration": 73.18604803085327, "step": 21875}
{"episode_reward": 191.2239289648739, "episode": 176.0, "Q1 loss": 5.20942494392395, "Q2 loss": 5.210214406967163, "Mean Target Q": 135.1957060546875, "Mean Q1": 135.1956181640625, "Mean Q2": 135.19579479980467, "critic_loss": 10.419639347076416, "batch_reward": 1.6444449796676637, "actor_loss": -135.68490895917338, "actor_target_entropy": -1.0, "actor_entropy": 0.46935410461118143, "alpha_loss": -0.010680382230108785, "alpha_value": 0.20371263405300463, "duration": 73.24179863929749, "step": 22000}
{"episode_reward": 243.78016107569584, "episode": 177.0, "Q1 loss": 5.867637397766114, "Q2 loss": 5.867334157943725, "Mean Target Q": 135.56749584960937, "Mean Q1": 135.55885607910156, "Mean Q2": 135.55907080078126, "critic_loss": 11.73497155380249, "batch_reward": 1.6360170049667357, "actor_loss": -136.091067359561, "actor_target_entropy": -1.0, "actor_entropy": 0.426532690014158, "alpha_loss": -0.012726886582279962, "alpha_value": 0.20425213399425274, "duration": 74.28831243515015, "step": 22125}
{"episode_reward": 295.52595513454696, "episode": 178.0, "Q1 loss": 5.493888034820556, "Q2 loss": 5.526501386642456, "Mean Target Q": 135.98918298339845, "Mean Q1": 135.98978100585938, "Mean Q2": 135.98984875488281, "critic_loss": 11.020389434814453, "batch_reward": 1.6373248844146728, "actor_loss": -136.41690088087512, "actor_target_entropy": -1.0, "actor_entropy": 0.47504254454566586, "alpha_loss": -0.010533706412740772, "alpha_value": 0.20472039951275545, "duration": 66.42156553268433, "step": 22250}
{"episode_reward": 230.34274803815342, "episode": 179.0, "Q1 loss": 5.7676416187286375, "Q2 loss": 5.756044063568115, "Mean Target Q": 136.49561401367188, "Mean Q1": 136.49413391113282, "Mean Q2": 136.49286779785157, "critic_loss": 11.523685718536377, "batch_reward": 1.642450942993164, "actor_loss": -136.9857168046255, "actor_target_entropy": -1.0, "actor_entropy": 0.478278423585589, "alpha_loss": -0.010476386786201998, "alpha_value": 0.20523940547602101, "duration": 74.04974150657654, "step": 22375}
{"episode_reward": 205.17147296827468, "episode": 180.0, "Q1 loss": 5.719318145751953, "Q2 loss": 5.722571319580078, "Mean Target Q": 137.01531872558593, "Mean Q1": 137.01598400878908, "Mean Q2": 137.01595336914062, "critic_loss": 11.441889400482177, "batch_reward": 1.657102071762085, "actor_loss": -137.44266854563068, "actor_target_entropy": -1.0, "actor_entropy": 0.5031873737612078, "alpha_loss": -0.008174363121901068, "alpha_value": 0.2057124200329695, "duration": 74.3811514377594, "step": 22500}
{"episode_reward": 282.63114796955614, "episode": 181.0, "Q1 loss": 5.449331405639648, "Q2 loss": 5.43766266822815, "Mean Target Q": 137.41440942382812, "Mean Q1": 137.4081190185547, "Mean Q2": 137.4088057861328, "critic_loss": 10.88699402999878, "batch_reward": 1.6520758485794067, "actor_loss": -137.86753869435145, "actor_target_entropy": -1.0, "actor_entropy": 0.5008989695518736, "alpha_loss": -0.01491483936219343, "alpha_value": 0.20614850462450254, "duration": 94.89044618606567, "step": 22625}
{"episode_reward": 249.92694691283322, "episode": 182.0, "Q1 loss": 5.579034954071045, "Q2 loss": 5.552437788009644, "Mean Target Q": 137.86476794433594, "Mean Q1": 137.86489880371093, "Mean Q2": 137.86463598632812, "critic_loss": 11.131472751617432, "batch_reward": 1.6482919416427613, "actor_loss": -138.35242166826802, "actor_target_entropy": -1.0, "actor_entropy": 0.4864847698519307, "alpha_loss": -0.010606413406710471, "alpha_value": 0.20685215272486718, "duration": 105.3108823299408, "step": 22750}
{"episode_reward": 253.90731894500595, "episode": 183.0, "Q1 loss": 5.538184282302857, "Q2 loss": 5.555731517791748, "Mean Target Q": 138.22252709960938, "Mean Q1": 138.21654577636718, "Mean Q2": 138.2170830078125, "critic_loss": 11.093915794372558, "batch_reward": 1.6608500480651855, "actor_loss": -138.751949249752, "actor_target_entropy": -1.0, "actor_entropy": 0.47582413421736824, "alpha_loss": -0.017556752473677672, "alpha_value": 0.2074930577653374, "duration": 108.46235609054565, "step": 22875}
{"episode_reward": 266.44930998133475, "episode": 184.0, "Q1 loss": 5.739382431030274, "Q2 loss": 5.69082883644104, "Mean Target Q": 138.72193017578124, "Mean Q1": 138.7222921142578, "Mean Q2": 138.72246459960937, "critic_loss": 11.430211269378661, "batch_reward": 1.6635885934829713, "actor_loss": -139.13205029887538, "actor_target_entropy": -1.0, "actor_entropy": 0.49724652546067394, "alpha_loss": -0.007382635057212845, "alpha_value": 0.20804334801764862, "duration": 91.74056649208069, "step": 23000}
{"episode_reward": 246.08235010876822, "episode": 185.0, "Q1 loss": 5.860350154876709, "Q2 loss": 5.863221477508545, "Mean Target Q": 139.21407177734375, "Mean Q1": 139.20836242675782, "Mean Q2": 139.2067423095703, "critic_loss": 11.723571613311767, "batch_reward": 1.6702573385238648, "actor_loss": -139.67349897112166, "actor_target_entropy": -1.0, "actor_entropy": 0.4964117284805056, "alpha_loss": -0.0018938580187894995, "alpha_value": 0.20829728819632257, "duration": 69.03467512130737, "step": 23125}
{"episode_reward": 306.29085100287585, "episode": 186.0, "Q1 loss": 5.769131713867187, "Q2 loss": 5.767096548080445, "Mean Target Q": 139.70362756347657, "Mean Q1": 139.70579357910157, "Mean Q2": 139.7073123779297, "critic_loss": 11.536228256225586, "batch_reward": 1.6718584394454956, "actor_loss": -140.17209699076992, "actor_target_entropy": -1.0, "actor_entropy": 0.4837421121135835, "alpha_loss": -0.00956801800507932, "alpha_value": 0.2086060052264189, "duration": 69.35874271392822, "step": 23250}
{"episode_reward": 203.76640582854407, "episode": 187.0, "Q1 loss": 5.867689249038697, "Q2 loss": 5.8601685199737545, "Mean Target Q": 139.9917822265625, "Mean Q1": 139.9857442626953, "Mean Q2": 139.98571154785157, "critic_loss": 11.727857780456542, "batch_reward": 1.6639461278915406, "actor_loss": -140.46212453690785, "actor_target_entropy": -1.0, "actor_entropy": 0.49338205513500033, "alpha_loss": -0.012395995561890895, "alpha_value": 0.20910175904811684, "duration": 60.73890542984009, "step": 23375}
{"episode_reward": 308.4902353586043, "episode": 188.0, "Q1 loss": 5.7789358768463135, "Q2 loss": 5.744662179946899, "Mean Target Q": 140.4793243408203, "Mean Q1": 140.4825693359375, "Mean Q2": 140.48272314453126, "critic_loss": 11.523598072052001, "batch_reward": 1.6815145320892333, "actor_loss": -140.89534365746283, "actor_target_entropy": -1.0, "actor_entropy": 0.5075132745888925, "alpha_loss": -0.00988498897922616, "alpha_value": 0.20977303129181557, "duration": 74.85487723350525, "step": 23500}
{"episode_reward": 197.16402989404585, "episode": 189.0, "Q1 loss": 5.981145738601684, "Q2 loss": 5.957499845504761, "Mean Target Q": 140.88068359375, "Mean Q1": 140.8712987060547, "Mean Q2": 140.87039904785155, "critic_loss": 11.938645572662354, "batch_reward": 1.6689035835266113, "actor_loss": -141.37372891865078, "actor_target_entropy": -1.0, "actor_entropy": 0.48302246417318073, "alpha_loss": -0.01059691335577222, "alpha_value": 0.2102936492933726, "duration": 62.1526460647583, "step": 23625}
{"episode_reward": 292.36404057189776, "episode": 190.0, "Q1 loss": 5.651591663360596, "Q2 loss": 5.683431190490722, "Mean Target Q": 141.36632861328124, "Mean Q1": 141.37012670898437, "Mean Q2": 141.3703712158203, "critic_loss": 11.335022888183595, "batch_reward": 1.6764106311798095, "actor_loss": -141.80602461291897, "actor_target_entropy": -1.0, "actor_entropy": 0.4853646586979589, "alpha_loss": -0.018500988612011555, "alpha_value": 0.21095795765869668, "duration": 61.433555126190186, "step": 23750}
{"episode_reward": 199.61615356729763, "episode": 191.0, "Q1 loss": 5.874897134780884, "Q2 loss": 5.868589660644531, "Mean Target Q": 141.72096398925783, "Mean Q1": 141.71735559082032, "Mean Q2": 141.71642724609376, "critic_loss": 11.74348675918579, "batch_reward": 1.6826473245620728, "actor_loss": -142.2264893546937, "actor_target_entropy": -1.0, "actor_entropy": 0.4909331860050323, "alpha_loss": -0.01431624855225285, "alpha_value": 0.21186239013909444, "duration": 86.06947922706604, "step": 23875}
{"episode_reward": 200.06151769586916, "episode": 192.0, "Q1 loss": 5.861888849258423, "Q2 loss": 5.878074014663697, "Mean Target Q": 142.24078161621094, "Mean Q1": 142.238689453125, "Mean Q2": 142.24030212402343, "critic_loss": 11.739962841033936, "batch_reward": 1.671748617172241, "actor_loss": -142.70533949329007, "actor_target_entropy": -1.0, "actor_entropy": 0.5110358389154557, "alpha_loss": -0.002251434697574305, "alpha_value": 0.21245956732621862, "duration": 107.68557167053223, "step": 24000}
{"episode_reward": 206.97711107249708, "episode": 193.0, "Q1 loss": 6.092756837844848, "Q2 loss": 6.087942337036133, "Mean Target Q": 142.64028479003906, "Mean Q1": 142.6368758544922, "Mean Q2": 142.63570764160156, "critic_loss": 12.180699188232422, "batch_reward": 1.676066089630127, "actor_loss": -143.08258831690227, "actor_target_entropy": -1.0, "actor_entropy": 0.4758145161091335, "alpha_loss": -0.013562809154834776, "alpha_value": 0.21289818706461913, "duration": 128.23889112472534, "step": 24125}
{"episode_reward": 216.5668863760649, "episode": 194.0, "Q1 loss": 5.7538212928771975, "Q2 loss": 5.789055330276489, "Mean Target Q": 142.9572724609375, "Mean Q1": 142.95686376953125, "Mean Q2": 142.9573203125, "critic_loss": 11.542876617431642, "batch_reward": 1.680299584388733, "actor_loss": -143.4058343210528, "actor_target_entropy": -1.0, "actor_entropy": 0.4910735632142713, "alpha_loss": -0.014267443799443783, "alpha_value": 0.21361705156692637, "duration": 131.48627400398254, "step": 24250}
{"episode_reward": 265.57230299642566, "episode": 195.0, "Q1 loss": 5.623164451599121, "Q2 loss": 5.6364261894226075, "Mean Target Q": 143.37120056152344, "Mean Q1": 143.36781640625, "Mean Q2": 143.36849743652343, "critic_loss": 11.259590621948242, "batch_reward": 1.667216731071472, "actor_loss": -143.8567163376581, "actor_target_entropy": -1.0, "actor_entropy": 0.49983001086446976, "alpha_loss": -0.014334300939466745, "alpha_value": 0.214278564059967, "duration": 124.39531397819519, "step": 24375}
{"episode_reward": 226.49593637857598, "episode": 196.0, "Q1 loss": 6.175250816345215, "Q2 loss": 6.202388416290283, "Mean Target Q": 143.78142626953124, "Mean Q1": 143.77970178222657, "Mean Q2": 143.77939318847658, "critic_loss": 12.377639213562011, "batch_reward": 1.6779921159744262, "actor_loss": -144.2282722227035, "actor_target_entropy": -1.0, "actor_entropy": 0.47791102095957727, "alpha_loss": -0.014884415120186826, "alpha_value": 0.21527644917158675, "duration": 91.18079900741577, "step": 24500}
{"episode_reward": 223.94034926350724, "episode": 197.0, "Q1 loss": 6.031333755493164, "Q2 loss": 6.045265018463135, "Mean Target Q": 144.201326171875, "Mean Q1": 144.19984631347657, "Mean Q2": 144.19872875976563, "critic_loss": 12.076598789215089, "batch_reward": 1.6765267839431763, "actor_loss": -144.64852009122333, "actor_target_entropy": -1.0, "actor_entropy": 0.5159100890159607, "alpha_loss": -0.0057012321693556646, "alpha_value": 0.2156597409471672, "duration": 108.53913235664368, "step": 24625}
{"episode_reward": 195.5374639960539, "episode": 198.0, "Q1 loss": 5.751944860458374, "Q2 loss": 5.720764667510986, "Mean Target Q": 144.53879724121094, "Mean Q1": 144.53889892578124, "Mean Q2": 144.5394864501953, "critic_loss": 11.472709468841552, "batch_reward": 1.6760183029174804, "actor_loss": -145.03873099050213, "actor_target_entropy": -1.0, "actor_entropy": 0.49294831868140926, "alpha_loss": -0.004165425325833982, "alpha_value": 0.2160810856192697, "duration": 128.07404470443726, "step": 24750}
{"episode_reward": 196.3658022646439, "episode": 199.0, "Q1 loss": 5.66252885055542, "Q2 loss": 5.654305717468262, "Mean Target Q": 144.9966903076172, "Mean Q1": 144.99249487304687, "Mean Q2": 144.99300463867186, "critic_loss": 11.316834609985351, "batch_reward": 1.6800469818115233, "actor_loss": -145.36086939251612, "actor_target_entropy": -1.0, "actor_entropy": 0.5117818344207037, "alpha_loss": -0.001074745558157918, "alpha_value": 0.2162151470554698, "duration": 114.2929162979126, "step": 24875}
{"episode_reward": 175.4836950140286, "episode": 200.0, "Q1 loss": 6.020109226226807, "Q2 loss": 6.0179768123626705, "Mean Target Q": 145.30124987792968, "Mean Q1": 145.29949853515626, "Mean Q2": 145.29822607421875, "critic_loss": 12.038086051940917, "batch_reward": 1.6781665210723877, "actor_loss": -145.7881563248173, "actor_target_entropy": -1.0, "actor_entropy": 0.5062223994924177, "alpha_loss": -0.006682435264660706, "alpha_value": 0.2164662834299914, "step": 25000}
{"duration": 144.3994801044464, "step": 25000}
{"episode_reward": 202.60902182298855, "episode": 201.0, "Q1 loss": 6.086125959396362, "Q2 loss": 6.093216239929199, "Mean Target Q": 145.75427392578126, "Mean Q1": 145.74721716308593, "Mean Q2": 145.7481318359375, "critic_loss": 12.179342193603516, "batch_reward": 1.6758364343643188, "actor_loss": -146.2171168251643, "actor_target_entropy": -1.0, "actor_entropy": 0.49125958293203326, "alpha_loss": -0.0025934801466526492, "alpha_value": 0.2167565618067574, "duration": 139.36533761024475, "step": 25125}
{"episode_reward": 219.93436055024762, "episode": 202.0, "Q1 loss": 5.93590905380249, "Q2 loss": 5.942421037673951, "Mean Target Q": 146.094376953125, "Mean Q1": 146.0973465576172, "Mean Q2": 146.09628552246093, "critic_loss": 11.878330104827882, "batch_reward": 1.676935224533081, "actor_loss": -146.59626966907132, "actor_target_entropy": -1.0, "actor_entropy": 0.484908141916798, "alpha_loss": -0.005987406220106828, "alpha_value": 0.21698954623833705, "duration": 129.74693751335144, "step": 25250}
{"episode_reward": 156.07587398314382, "episode": 203.0, "Q1 loss": 5.7975292472839355, "Q2 loss": 5.775140542984008, "Mean Target Q": 146.41538427734375, "Mean Q1": 146.41669104003907, "Mean Q2": 146.41722424316407, "critic_loss": 11.572669826507568, "batch_reward": 1.6738175840377807, "actor_loss": -146.82402983165923, "actor_target_entropy": -1.0, "actor_entropy": 0.5048102268150875, "alpha_loss": 0.002381812466958922, "alpha_value": 0.2170420075809973, "duration": 134.0574915409088, "step": 25375}
{"episode_reward": 193.66941071430213, "episode": 204.0, "Q1 loss": 5.824908111572266, "Q2 loss": 5.838432064056397, "Mean Target Q": 146.8378721923828, "Mean Q1": 146.8303435058594, "Mean Q2": 146.83099450683594, "critic_loss": 11.663340183258057, "batch_reward": 1.6650611419677734, "actor_loss": -147.24686407273816, "actor_target_entropy": -1.0, "actor_entropy": 0.49016659298250753, "alpha_loss": -0.005434345679297563, "alpha_value": 0.21719535668329046, "duration": 144.51094388961792, "step": 25500}
{"episode_reward": 230.54250853149145, "episode": 205.0, "Q1 loss": 5.746884141921997, "Q2 loss": 5.722307737350464, "Mean Target Q": 147.162375, "Mean Q1": 147.1595321044922, "Mean Q2": 147.1586779785156, "critic_loss": 11.469191902160645, "batch_reward": 1.670884985923767, "actor_loss": -147.6150176033141, "actor_target_entropy": -1.0, "actor_entropy": 0.48960011535220677, "alpha_loss": 0.0013650264701850357, "alpha_value": 0.21730891717707793, "duration": 124.23745250701904, "step": 25625}
{"episode_reward": 277.4978738988392, "episode": 206.0, "Q1 loss": 5.626229822158813, "Q2 loss": 5.6445247764587405, "Mean Target Q": 147.53402172851563, "Mean Q1": 147.53003369140626, "Mean Q2": 147.52964624023437, "critic_loss": 11.270754573822021, "batch_reward": 1.6731877574920655, "actor_loss": -147.99579103531377, "actor_target_entropy": -1.0, "actor_entropy": 0.5126858190182717, "alpha_loss": 0.0005506580815680565, "alpha_value": 0.21719671816793845, "duration": 139.79996252059937, "step": 25750}
{"episode_reward": 203.46381593914927, "episode": 207.0, "Q1 loss": 6.12351127243042, "Q2 loss": 6.140522340774536, "Mean Target Q": 147.8959822998047, "Mean Q1": 147.89932373046875, "Mean Q2": 147.89970434570313, "critic_loss": 12.264033668518067, "batch_reward": 1.6695086812973023, "actor_loss": -148.3650372217572, "actor_target_entropy": -1.0, "actor_entropy": 0.5026651318111117, "alpha_loss": 0.006006412152644424, "alpha_value": 0.21698765974668516, "duration": 138.63092160224915, "step": 25875}
{"episode_reward": 197.09341702746806, "episode": 208.0, "Q1 loss": 6.120737440109253, "Q2 loss": 6.1127356338500975, "Mean Target Q": 148.30512414550782, "Mean Q1": 148.30173291015626, "Mean Q2": 148.30172229003907, "critic_loss": 12.233473098754883, "batch_reward": 1.6803639307022096, "actor_loss": -148.66416980374245, "actor_target_entropy": -1.0, "actor_entropy": 0.5001186488136169, "alpha_loss": -0.00032787467728579236, "alpha_value": 0.21678976537018743, "duration": 135.7539780139923, "step": 26000}
{"episode_reward": 242.26964738211763, "episode": 209.0, "Q1 loss": 6.035698490142822, "Q2 loss": 5.991410566329956, "Mean Target Q": 148.65850061035155, "Mean Q1": 148.65602014160157, "Mean Q2": 148.65516564941407, "critic_loss": 12.027109046936035, "batch_reward": 1.6818742141723633, "actor_loss": -149.11242046053448, "actor_target_entropy": -1.0, "actor_entropy": 0.48538689953940256, "alpha_loss": 0.002000578401965045, "alpha_value": 0.21670499598079274, "duration": 134.1776955127716, "step": 26125}
{"episode_reward": 277.6729393885238, "episode": 210.0, "Q1 loss": 5.916378238677979, "Q2 loss": 5.934001781463623, "Mean Target Q": 148.97128308105468, "Mean Q1": 148.9688087158203, "Mean Q2": 148.97054272460937, "critic_loss": 11.850380058288573, "batch_reward": 1.6855930423736571, "actor_loss": -149.4209215717931, "actor_target_entropy": -1.0, "actor_entropy": 0.480445132620873, "alpha_loss": -0.002787652286520648, "alpha_value": 0.2167967143284388, "duration": 116.68535208702087, "step": 26250}
{"episode_reward": 232.60938545340596, "episode": 211.0, "Q1 loss": 6.042002899169922, "Q2 loss": 6.059134870529175, "Mean Target Q": 149.34737536621094, "Mean Q1": 149.34288403320312, "Mean Q2": 149.34169982910157, "critic_loss": 12.101137756347656, "batch_reward": 1.6818015213012696, "actor_loss": -149.7694588313027, "actor_target_entropy": -1.0, "actor_entropy": 0.5021927063427274, "alpha_loss": -0.003890564181058416, "alpha_value": 0.21703203577501645, "duration": 131.8947594165802, "step": 26375}
{"episode_reward": 239.32136943008234, "episode": 212.0, "Q1 loss": 5.824333127975464, "Q2 loss": 5.84144376373291, "Mean Target Q": 149.77382312011719, "Mean Q1": 149.77240698242187, "Mean Q2": 149.77188305664063, "critic_loss": 11.665776889801025, "batch_reward": 1.6843020830154418, "actor_loss": -150.2302775229177, "actor_target_entropy": -1.0, "actor_entropy": 0.4843375572273808, "alpha_loss": -0.0015854020678107777, "alpha_value": 0.21716403915059354, "duration": 135.20915150642395, "step": 26500}
{"episode_reward": 241.09742186997838, "episode": 213.0, "Q1 loss": 5.728966747283936, "Q2 loss": 5.699526803970337, "Mean Target Q": 150.1268048095703, "Mean Q1": 150.12231530761719, "Mean Q2": 150.1224338378906, "critic_loss": 11.428493576049805, "batch_reward": 1.6788539247512817, "actor_loss": -150.5854722280351, "actor_target_entropy": -1.0, "actor_entropy": 0.4892216906661079, "alpha_loss": 0.0032597623418070495, "alpha_value": 0.21717807990311638, "duration": 138.89123558998108, "step": 26625}
{"episode_reward": 214.58340046479046, "episode": 214.0, "Q1 loss": 6.007975017547607, "Q2 loss": 5.998050437927246, "Mean Target Q": 150.5623985595703, "Mean Q1": 150.56874560546876, "Mean Q2": 150.5694073486328, "critic_loss": 12.006025485992431, "batch_reward": 1.6791460876464843, "actor_loss": -150.997316422001, "actor_target_entropy": -1.0, "actor_entropy": 0.4858285251163667, "alpha_loss": 0.00029748926059372966, "alpha_value": 0.2169844974430591, "duration": 148.1734414100647, "step": 26750}
{"episode_reward": 250.10825585364773, "episode": 215.0, "Q1 loss": 5.752676509857178, "Q2 loss": 5.79185920715332, "Mean Target Q": 150.87909448242186, "Mean Q1": 150.87370141601562, "Mean Q2": 150.87446655273436, "critic_loss": 11.544535705566407, "batch_reward": 1.6882086963653564, "actor_loss": -151.34698389446925, "actor_target_entropy": -1.0, "actor_entropy": 0.5049961218758235, "alpha_loss": 0.003295285841597924, "alpha_value": 0.2168441928501751, "duration": 132.64570307731628, "step": 26875}
{"episode_reward": 190.73719586402072, "episode": 216.0, "Q1 loss": 6.05237515258789, "Q2 loss": 6.05593705368042, "Mean Target Q": 151.25221179199218, "Mean Q1": 151.24764489746093, "Mean Q2": 151.24780615234374, "critic_loss": 12.108312229156494, "batch_reward": 1.6894878969192504, "actor_loss": -151.6609868695659, "actor_target_entropy": -1.0, "actor_entropy": 0.5001242521309084, "alpha_loss": 0.0012011863572913553, "alpha_value": 0.21678355926503826, "duration": 141.50373148918152, "step": 27000}
{"episode_reward": 201.73955263618177, "episode": 217.0, "Q1 loss": 6.223909778594971, "Q2 loss": 6.233523281097412, "Mean Target Q": 151.4423116455078, "Mean Q1": 151.44174560546875, "Mean Q2": 151.44177587890624, "critic_loss": 12.457432998657227, "batch_reward": 1.6776892538070678, "actor_loss": -151.91995965866815, "actor_target_entropy": -1.0, "actor_entropy": 0.480556327199179, "alpha_loss": -0.00010005926107248617, "alpha_value": 0.21656661314064185, "duration": 121.86919713020325, "step": 27125}
{"episode_reward": 235.00705253845302, "episode": 218.0, "Q1 loss": 6.018268775939942, "Q2 loss": 5.996614210128784, "Mean Target Q": 151.8688620605469, "Mean Q1": 151.86137170410157, "Mean Q2": 151.86065100097656, "critic_loss": 12.014882957458497, "batch_reward": 1.6792830333709716, "actor_loss": -152.34135141680318, "actor_target_entropy": -1.0, "actor_entropy": 0.49821597674200613, "alpha_loss": 0.0013956630925437616, "alpha_value": 0.21671446367031547, "duration": 127.43914937973022, "step": 27250}
{"episode_reward": 236.18089683899396, "episode": 219.0, "Q1 loss": 6.102257785797119, "Q2 loss": 6.074808425903321, "Mean Target Q": 152.18756970214844, "Mean Q1": 152.18973608398437, "Mean Q2": 152.18996423339843, "critic_loss": 12.177066165924073, "batch_reward": 1.6915548706054688, "actor_loss": -152.70082625131758, "actor_target_entropy": -1.0, "actor_entropy": 0.5013612310091654, "alpha_loss": -0.002238490023753709, "alpha_value": 0.21674278056088797, "duration": 134.7983729839325, "step": 27375}
{"episode_reward": 305.71131173902313, "episode": 220.0, "Q1 loss": 5.979433212280274, "Q2 loss": 5.999271364212036, "Mean Target Q": 152.60193676757814, "Mean Q1": 152.59675061035156, "Mean Q2": 152.59668029785155, "critic_loss": 11.978704582214355, "batch_reward": 1.6873374271392823, "actor_loss": -153.10572002780052, "actor_target_entropy": -1.0, "actor_entropy": 0.4670629765718214, "alpha_loss": -0.004869020615343845, "alpha_value": 0.21699218928334563, "duration": 120.52964878082275, "step": 27500}
{"episode_reward": 260.4403515617106, "episode": 221.0, "Q1 loss": 6.021971229553222, "Q2 loss": 6.020962856292725, "Mean Target Q": 153.00886865234375, "Mean Q1": 153.01138061523437, "Mean Q2": 153.01172473144533, "critic_loss": 12.042934047698974, "batch_reward": 1.6915017700195312, "actor_loss": -153.49190291147383, "actor_target_entropy": -1.0, "actor_entropy": 0.4971415414696648, "alpha_loss": -0.0010061382190398281, "alpha_value": 0.21707595250825468, "duration": 113.17456316947937, "step": 27625}
{"episode_reward": 227.68378957109925, "episode": 222.0, "Q1 loss": 6.252202796936035, "Q2 loss": 6.256411430358887, "Mean Target Q": 153.1870401611328, "Mean Q1": 153.1862479248047, "Mean Q2": 153.18490991210936, "critic_loss": 12.508614212036132, "batch_reward": 1.6836526527404785, "actor_loss": -153.67025363060736, "actor_target_entropy": -1.0, "actor_entropy": 0.5032367283298124, "alpha_loss": -0.0028467947286703894, "alpha_value": 0.2172210951721791, "duration": 86.045969247818, "step": 27750}
{"episode_reward": 219.69234163934613, "episode": 223.0, "Q1 loss": 6.267408992767334, "Q2 loss": 6.299790319442749, "Mean Target Q": 153.64129345703125, "Mean Q1": 153.63407763671876, "Mean Q2": 153.63452197265624, "critic_loss": 12.567199329376221, "batch_reward": 1.685689679145813, "actor_loss": -154.06134057423426, "actor_target_entropy": -1.0, "actor_entropy": 0.47179091449767824, "alpha_loss": -0.0034725666970073705, "alpha_value": 0.21745150523834392, "duration": 65.40649461746216, "step": 27875}
{"episode_reward": 255.76616513651567, "episode": 224.0, "Q1 loss": 5.945663732528686, "Q2 loss": 5.999375799179077, "Mean Target Q": 153.92607641601563, "Mean Q1": 153.92539294433593, "Mean Q2": 153.92587316894532, "critic_loss": 11.945039485931396, "batch_reward": 1.6935300512313842, "actor_loss": -154.43008841237713, "actor_target_entropy": -1.0, "actor_entropy": 0.4742161799823084, "alpha_loss": 0.005744975856355121, "alpha_value": 0.21749504104538978, "duration": 90.09964919090271, "step": 28000}
{"episode_reward": 214.31413080412327, "episode": 225.0, "Q1 loss": 5.916351573944092, "Q2 loss": 5.8878440685272215, "Mean Target Q": 154.2744617919922, "Mean Q1": 154.27100561523437, "Mean Q2": 154.26960888671874, "critic_loss": 11.804195693969726, "batch_reward": 1.6792061595916747, "actor_loss": -154.73595174153647, "actor_target_entropy": -1.0, "actor_entropy": 0.4690294090717558, "alpha_loss": -0.00015790414966879382, "alpha_value": 0.21721813917664592, "duration": 113.32002472877502, "step": 28125}
{"episode_reward": 193.53189380514527, "episode": 226.0, "Q1 loss": 6.2087184429168705, "Q2 loss": 6.230010847091675, "Mean Target Q": 154.5828543701172, "Mean Q1": 154.58142895507814, "Mean Q2": 154.58355859375, "critic_loss": 12.438729309082031, "batch_reward": 1.6946645574569703, "actor_loss": -155.06138906171245, "actor_target_entropy": -1.0, "actor_entropy": 0.5100473857695057, "alpha_loss": 0.00042862425212778394, "alpha_value": 0.2171134724115833, "duration": 102.8179440498352, "step": 28250}
{"episode_reward": 276.855475271848, "episode": 227.0, "Q1 loss": 5.835764068603516, "Q2 loss": 5.818502777099609, "Mean Target Q": 154.9126749267578, "Mean Q1": 154.90994763183593, "Mean Q2": 154.90950915527344, "critic_loss": 11.654266860961915, "batch_reward": 1.68573100566864, "actor_loss": -155.37538243853857, "actor_target_entropy": -1.0, "actor_entropy": 0.4839319818549686, "alpha_loss": -0.006024992669976893, "alpha_value": 0.2173489221296798, "duration": 105.38194632530212, "step": 28375}
{"episode_reward": 244.79377539960905, "episode": 228.0, "Q1 loss": 6.184824087142944, "Q2 loss": 6.189032835006714, "Mean Target Q": 155.3378194580078, "Mean Q1": 155.34193408203126, "Mean Q2": 155.3408760986328, "critic_loss": 12.373856941223144, "batch_reward": 1.6989163570404053, "actor_loss": -155.77354947982295, "actor_target_entropy": -1.0, "actor_entropy": 0.47746634819815237, "alpha_loss": -0.0037507971883901665, "alpha_value": 0.21773004877074548, "duration": 67.62918424606323, "step": 28500}
{"episode_reward": 236.97964654377728, "episode": 229.0, "Q1 loss": 6.3982079906463625, "Q2 loss": 6.433380863189697, "Mean Target Q": 155.6393330078125, "Mean Q1": 155.63004370117187, "Mean Q2": 155.62929296875, "critic_loss": 12.831588844299317, "batch_reward": 1.6968198051452636, "actor_loss": -156.1423642597501, "actor_target_entropy": -1.0, "actor_entropy": 0.4708380377481854, "alpha_loss": 0.003053807840120816, "alpha_value": 0.21780817178252473, "duration": 72.93329954147339, "step": 28625}
{"episode_reward": 247.1590699984506, "episode": 230.0, "Q1 loss": 6.190272258758545, "Q2 loss": 6.134273229598999, "Mean Target Q": 155.90155541992186, "Mean Q1": 155.90129248046875, "Mean Q2": 155.9023779296875, "critic_loss": 12.324545455932617, "batch_reward": 1.6917031230926514, "actor_loss": -156.36929419732863, "actor_target_entropy": -1.0, "actor_entropy": 0.4910457004462519, "alpha_loss": -0.004073186172923494, "alpha_value": 0.21775818994885524, "duration": 66.32566809654236, "step": 28750}
{"episode_reward": 210.51662268437826, "episode": 231.0, "Q1 loss": 6.1247697315216065, "Q2 loss": 6.115918466567993, "Mean Target Q": 156.20153356933594, "Mean Q1": 156.20433251953125, "Mean Q2": 156.20384020996093, "critic_loss": 12.240688194274902, "batch_reward": 1.68720742893219, "actor_loss": -156.6644543844556, "actor_target_entropy": -1.0, "actor_entropy": 0.4616483033649505, "alpha_loss": -0.006992835449867897, "alpha_value": 0.21823574046439284, "duration": 69.7777316570282, "step": 28875}
{"episode_reward": 146.30018101786902, "episode": 232.0, "Q1 loss": 6.262040496826172, "Q2 loss": 6.270959815979004, "Mean Target Q": 156.58656079101561, "Mean Q1": 156.5801531982422, "Mean Q2": 156.58056091308595, "critic_loss": 12.533000316619873, "batch_reward": 1.6986555585861205, "actor_loss": -157.0061542141822, "actor_target_entropy": -1.0, "actor_entropy": 0.45502702315007487, "alpha_loss": 0.0018716632358489497, "alpha_value": 0.2184570080435727, "duration": 66.25661945343018, "step": 29000}
{"episode_reward": 238.50807302636173, "episode": 233.0, "Q1 loss": 6.137655967712402, "Q2 loss": 6.121578615188598, "Mean Target Q": 156.99244348144532, "Mean Q1": 156.991439453125, "Mean Q2": 156.9931027832031, "critic_loss": 12.25923456954956, "batch_reward": 1.7036562118530274, "actor_loss": -157.48747180757067, "actor_target_entropy": -1.0, "actor_entropy": 0.45316385986312985, "alpha_loss": -0.0024547059872438983, "alpha_value": 0.21846473386035584, "duration": 112.89281439781189, "step": 29125}
{"episode_reward": 243.15520133089825, "episode": 234.0, "Q1 loss": 5.971901020050049, "Q2 loss": 6.004239213943482, "Mean Target Q": 157.20597326660157, "Mean Q1": 157.20534204101563, "Mean Q2": 157.20471826171874, "critic_loss": 11.976140197753907, "batch_reward": 1.6958624601364136, "actor_loss": -157.69073117163873, "actor_target_entropy": -1.0, "actor_entropy": 0.4617389575127632, "alpha_loss": 0.0006622028078943972, "alpha_value": 0.21844497112254696, "duration": 120.35447001457214, "step": 29250}
{"episode_reward": 251.75577901087033, "episode": 235.0, "Q1 loss": 6.074619346618652, "Q2 loss": 6.0542938575744625, "Mean Target Q": 157.577076171875, "Mean Q1": 157.569501953125, "Mean Q2": 157.569498046875, "critic_loss": 12.128913215637207, "batch_reward": 1.6988591556549073, "actor_loss": -158.04235815623449, "actor_target_entropy": -1.0, "actor_entropy": 0.4685660789883326, "alpha_loss": -0.005543212417424435, "alpha_value": 0.21854156816197978, "duration": 132.01337552070618, "step": 29375}
{"episode_reward": 218.66220143065772, "episode": 236.0, "Q1 loss": 6.343237209320068, "Q2 loss": 6.312277109146118, "Mean Target Q": 157.8919923095703, "Mean Q1": 157.89400390625, "Mean Q2": 157.8948701171875, "critic_loss": 12.655514335632324, "batch_reward": 1.6975563383102417, "actor_loss": -158.37303973782448, "actor_target_entropy": -1.0, "actor_entropy": 0.4913908036485795, "alpha_loss": -0.0018248684974687716, "alpha_value": 0.218894537356454, "duration": 120.82523107528687, "step": 29500}
{"episode_reward": 228.08588273421785, "episode": 237.0, "Q1 loss": 6.032692378997803, "Q2 loss": 6.089682605743408, "Mean Target Q": 158.13656701660156, "Mean Q1": 158.1313319091797, "Mean Q2": 158.13052197265625, "critic_loss": 12.122374961853028, "batch_reward": 1.7044844827651977, "actor_loss": -158.54624551440043, "actor_target_entropy": -1.0, "actor_entropy": 0.4610570976658473, "alpha_loss": -0.0016454399179016788, "alpha_value": 0.2190064101096067, "duration": 108.48075604438782, "step": 29625}
{"episode_reward": 260.8378561672037, "episode": 238.0, "Q1 loss": 6.432247245788575, "Q2 loss": 6.422363767623901, "Mean Target Q": 158.53652001953125, "Mean Q1": 158.5358701171875, "Mean Q2": 158.53568981933594, "critic_loss": 12.854610984802246, "batch_reward": 1.6974601583480835, "actor_loss": -158.98907938311177, "actor_target_entropy": -1.0, "actor_entropy": 0.4924373992027775, "alpha_loss": -0.002890072364900862, "alpha_value": 0.21920795153231282, "duration": 117.46631455421448, "step": 29750}
{"episode_reward": 191.24823141171694, "episode": 239.0, "Q1 loss": 5.899619411468506, "Q2 loss": 5.878148817062378, "Mean Target Q": 158.76239318847655, "Mean Q1": 158.76626293945313, "Mean Q2": 158.76512133789063, "critic_loss": 11.7777682762146, "batch_reward": 1.701748257637024, "actor_loss": -159.1788066076854, "actor_target_entropy": -1.0, "actor_entropy": 0.4584211115799253, "alpha_loss": -0.005164381663595874, "alpha_value": 0.2194275131497524, "duration": 111.59771919250488, "step": 29875}
{"episode_reward": 254.3601056977896, "episode": 240.0, "Q1 loss": 6.1179851722717284, "Q2 loss": 6.14348656463623, "Mean Target Q": 159.1405108642578, "Mean Q1": 159.13267443847656, "Mean Q2": 159.13473022460937, "critic_loss": 12.26147176361084, "batch_reward": 1.709038682937622, "actor_loss": -159.5929887833134, "actor_target_entropy": -1.0, "actor_entropy": 0.46561800520266255, "alpha_loss": -0.006145559499160417, "alpha_value": 0.21981509864133209, "step": 30000}
{"duration": 116.12750601768494, "step": 30000}
{"episode_reward": 257.2769200495398, "episode": 241.0, "Q1 loss": 5.899888303756714, "Q2 loss": 5.934692926406861, "Mean Target Q": 159.43167919921876, "Mean Q1": 159.43638916015624, "Mean Q2": 159.4351729736328, "critic_loss": 11.834581256866455, "batch_reward": 1.7031395950317383, "actor_loss": -159.90825689406623, "actor_target_entropy": -1.0, "actor_entropy": 0.48690930623856804, "alpha_loss": 0.0033727408948517035, "alpha_value": 0.2200246702467254, "duration": 135.0017602443695, "step": 30125}
{"episode_reward": 268.2751204702866, "episode": 242.0, "Q1 loss": 6.3767753658294675, "Q2 loss": 6.38505460357666, "Mean Target Q": 159.76006396484374, "Mean Q1": 159.74858276367186, "Mean Q2": 159.74849267578125, "critic_loss": 12.761829986572266, "batch_reward": 1.7070116357803344, "actor_loss": -160.21164358815838, "actor_target_entropy": -1.0, "actor_entropy": 0.46979935274970147, "alpha_loss": 0.0017190172934093543, "alpha_value": 0.2198730237064508, "duration": 141.13474011421204, "step": 30250}
{"episode_reward": 248.7613219912602, "episode": 243.0, "Q1 loss": 6.178917314529419, "Q2 loss": 6.172849382400512, "Mean Target Q": 159.970548828125, "Mean Q1": 159.97236242675783, "Mean Q2": 159.97111254882813, "critic_loss": 12.351766696929932, "batch_reward": 1.700535111427307, "actor_loss": -160.48039754231772, "actor_target_entropy": -1.0, "actor_entropy": 0.46724524147926816, "alpha_loss": 0.00017716776623967148, "alpha_value": 0.21959911092201903, "duration": 108.6299102306366, "step": 30375}
{"episode_reward": 196.26577039243534, "episode": 244.0, "Q1 loss": 6.026127231597901, "Q2 loss": 6.026008289337158, "Mean Target Q": 160.3982784423828, "Mean Q1": 160.39475769042969, "Mean Q2": 160.39575170898436, "critic_loss": 12.052135513305664, "batch_reward": 1.7064187870025636, "actor_loss": -160.82664957354146, "actor_target_entropy": -1.0, "actor_entropy": 0.49079369200814155, "alpha_loss": -0.00303274116689159, "alpha_value": 0.21975589104144197, "duration": 139.7368791103363, "step": 30500}
{"episode_reward": 213.90296854195088, "episode": 245.0, "Q1 loss": 6.214408046722412, "Q2 loss": 6.193916118621826, "Mean Target Q": 160.72030505371094, "Mean Q1": 160.72169360351563, "Mean Q2": 160.72184289550782, "critic_loss": 12.40832416152954, "batch_reward": 1.7092631950378419, "actor_loss": -161.20176575675842, "actor_target_entropy": -1.0, "actor_entropy": 0.4539400575652955, "alpha_loss": -0.005208524143589395, "alpha_value": 0.2199836585236343, "duration": 135.5942199230194, "step": 30625}
{"episode_reward": 192.50757790668757, "episode": 246.0, "Q1 loss": 6.254816913604737, "Q2 loss": 6.222195596694946, "Mean Target Q": 161.06557861328125, "Mean Q1": 161.0607987060547, "Mean Q2": 161.06084069824217, "critic_loss": 12.47701252746582, "batch_reward": 1.7124584283828734, "actor_loss": -161.53865814208984, "actor_target_entropy": -1.0, "actor_entropy": 0.4507709265716614, "alpha_loss": -0.0024673032213843636, "alpha_value": 0.22029653621519574, "duration": 131.29561591148376, "step": 30750}
{"episode_reward": 192.19427954789302, "episode": 247.0, "Q1 loss": 6.189873237609863, "Q2 loss": 6.1990882396698, "Mean Target Q": 161.27121008300782, "Mean Q1": 161.27269677734375, "Mean Q2": 161.2726094970703, "critic_loss": 12.388961448669434, "batch_reward": 1.7019499044418336, "actor_loss": -161.7096409873357, "actor_target_entropy": -1.0, "actor_entropy": 0.4587364315040528, "alpha_loss": -0.001919631790813236, "alpha_value": 0.22050509927061704, "duration": 119.26954054832458, "step": 30875}
{"episode_reward": 227.23292874511955, "episode": 248.0, "Q1 loss": 5.97256409072876, "Q2 loss": 5.961302978515625, "Mean Target Q": 161.56924194335937, "Mean Q1": 161.56713403320313, "Mean Q2": 161.5678155517578, "critic_loss": 11.933867092132568, "batch_reward": 1.7190183181762695, "actor_loss": -162.10549089985508, "actor_target_entropy": -1.0, "actor_entropy": 0.4396175338375953, "alpha_loss": 4.8305704108169e-05, "alpha_value": 0.2205162224861999, "duration": 111.83121109008789, "step": 31000}
{"episode_reward": 202.2509023541154, "episode": 249.0, "Q1 loss": 6.257820209503174, "Q2 loss": 6.260291591644287, "Mean Target Q": 161.79627001953125, "Mean Q1": 161.7908778076172, "Mean Q2": 161.78978308105468, "critic_loss": 12.518111743927001, "batch_reward": 1.7055046138763428, "actor_loss": -162.2628159295945, "actor_target_entropy": -1.0, "actor_entropy": 0.46877317627271015, "alpha_loss": -7.592767314423644e-05, "alpha_value": 0.2205484374668816, "duration": 114.84683132171631, "step": 31125}
{"episode_reward": 194.8368831830963, "episode": 250.0, "Q1 loss": 6.1805186920166015, "Q2 loss": 6.190686866760254, "Mean Target Q": 162.12044177246094, "Mean Q1": 162.12295593261717, "Mean Q2": 162.12380529785156, "critic_loss": 12.37120556640625, "batch_reward": 1.7074663276672364, "actor_loss": -162.55799348892705, "actor_target_entropy": -1.0, "actor_entropy": 0.4683231807524158, "alpha_loss": -0.005640067216459542, "alpha_value": 0.22076624424824048, "duration": 112.70888233184814, "step": 31250}
{"episode_reward": 228.23057244481964, "episode": 251.0, "Q1 loss": 6.1476904296875, "Q2 loss": 6.167232286453247, "Mean Target Q": 162.36718334960938, "Mean Q1": 162.36288720703126, "Mean Q2": 162.36251892089842, "critic_loss": 12.314922698974609, "batch_reward": 1.6973372821807862, "actor_loss": -162.8064434717572, "actor_target_entropy": -1.0, "actor_entropy": 0.48072225091949344, "alpha_loss": 0.005270443938022095, "alpha_value": 0.22080500840257236, "duration": 98.34888005256653, "step": 31375}
{"episode_reward": 219.11069335177515, "episode": 252.0, "Q1 loss": 6.123067687988281, "Q2 loss": 6.151290290832519, "Mean Target Q": 162.64440966796874, "Mean Q1": 162.64279846191405, "Mean Q2": 162.6424794921875, "critic_loss": 12.274358047485352, "batch_reward": 1.6978694429397583, "actor_loss": -163.06656843616116, "actor_target_entropy": -1.0, "actor_entropy": 0.4618597054673779, "alpha_loss": 0.004120781848717841, "alpha_value": 0.2205744992777151, "duration": 119.40594124794006, "step": 31500}
{"episode_reward": 210.8940532022574, "episode": 253.0, "Q1 loss": 6.157628738403321, "Q2 loss": 6.17438212966919, "Mean Target Q": 162.94125744628906, "Mean Q1": 162.93887084960937, "Mean Q2": 162.93792236328125, "critic_loss": 12.33201082611084, "batch_reward": 1.7023758678436278, "actor_loss": -163.357662624783, "actor_target_entropy": -1.0, "actor_entropy": 0.4730930635853419, "alpha_loss": 0.011128791227256732, "alpha_value": 0.21989162638448032, "duration": 104.84914302825928, "step": 31625}
{"episode_reward": 208.42822002863574, "episode": 254.0, "Q1 loss": 6.136925878524781, "Q2 loss": 6.099638599395752, "Mean Target Q": 163.14287365722657, "Mean Q1": 163.14383190917968, "Mean Q2": 163.14522473144532, "critic_loss": 12.236564487457276, "batch_reward": 1.700080348968506, "actor_loss": -163.55949229578817, "actor_target_entropy": -1.0, "actor_entropy": 0.4889970229518029, "alpha_loss": 0.0006391396915029374, "alpha_value": 0.21954752500142025, "duration": 81.3023271560669, "step": 31750}
{"episode_reward": 242.4086111247174, "episode": 255.0, "Q1 loss": 6.032770124435425, "Q2 loss": 6.009597799301147, "Mean Target Q": 163.4649796142578, "Mean Q1": 163.46299157714844, "Mean Q2": 163.46205541992188, "critic_loss": 12.042367950439454, "batch_reward": 1.7019574184417725, "actor_loss": -163.88827441987536, "actor_target_entropy": -1.0, "actor_entropy": 0.49395739795669674, "alpha_loss": -0.0035506534419717296, "alpha_value": 0.21959615905869886, "duration": 68.10879945755005, "step": 31875}
{"episode_reward": 190.80989199142724, "episode": 256.0, "Q1 loss": 5.999529935836792, "Q2 loss": 5.982276685714722, "Mean Target Q": 163.72154602050782, "Mean Q1": 163.7160721435547, "Mean Q2": 163.7156817626953, "critic_loss": 11.981806583404541, "batch_reward": 1.7140612087249756, "actor_loss": -164.11945096908076, "actor_target_entropy": -1.0, "actor_entropy": 0.49136973244528614, "alpha_loss": -0.003674710481127183, "alpha_value": 0.21986712789202947, "duration": 58.9329514503479, "step": 32000}
{"episode_reward": 264.9600648486275, "episode": 257.0, "Q1 loss": 6.1846491107940675, "Q2 loss": 6.1704426097869876, "Mean Target Q": 163.96132641601562, "Mean Q1": 163.9585946044922, "Mean Q2": 163.95848498535156, "critic_loss": 12.355091751098632, "batch_reward": 1.7133942861557008, "actor_loss": -164.39107041131882, "actor_target_entropy": -1.0, "actor_entropy": 0.4747965321654365, "alpha_loss": -0.004080438642718252, "alpha_value": 0.22020007701484426, "duration": 96.39964365959167, "step": 32125}
{"episode_reward": 198.55452567629658, "episode": 258.0, "Q1 loss": 6.1822520523071285, "Q2 loss": 6.190377187728882, "Mean Target Q": 164.30525256347656, "Mean Q1": 164.3014970703125, "Mean Q2": 164.30292700195312, "critic_loss": 12.372629203796386, "batch_reward": 1.7023224954605103, "actor_loss": -164.6891873267389, "actor_target_entropy": -1.0, "actor_entropy": 0.48288869232900683, "alpha_loss": 0.008346955198043536, "alpha_value": 0.21992264383162216, "duration": 111.87634778022766, "step": 32250}
{"episode_reward": 208.8411596231726, "episode": 259.0, "Q1 loss": 6.200825037002564, "Q2 loss": 6.172028200149536, "Mean Target Q": 164.55728112792968, "Mean Q1": 164.56037255859374, "Mean Q2": 164.55996813964845, "critic_loss": 12.372853206634522, "batch_reward": 1.7112163953781128, "actor_loss": -165.03334263392858, "actor_target_entropy": -1.0, "actor_entropy": 0.4734471752530053, "alpha_loss": -0.0008180050866767054, "alpha_value": 0.21969976148366288, "duration": 110.97251915931702, "step": 32375}
{"episode_reward": 261.70190345020995, "episode": 260.0, "Q1 loss": 6.375664524078369, "Q2 loss": 6.393773052215576, "Mean Target Q": 164.80511608886718, "Mean Q1": 164.8014903564453, "Mean Q2": 164.80250988769532, "critic_loss": 12.76943759918213, "batch_reward": 1.706702946662903, "actor_loss": -165.19992976034843, "actor_target_entropy": -1.0, "actor_entropy": 0.462993057504777, "alpha_loss": -6.587293014050491e-05, "alpha_value": 0.21978428948873435, "duration": 128.2448606491089, "step": 32500}
{"episode_reward": 230.47488741971398, "episode": 261.0, "Q1 loss": 6.423267353057861, "Q2 loss": 6.3564924736022945, "Mean Target Q": 165.05155346679686, "Mean Q1": 165.04978857421875, "Mean Q2": 165.04901391601564, "critic_loss": 12.779759826660156, "batch_reward": 1.7023375520706177, "actor_loss": -165.44554428827195, "actor_target_entropy": -1.0, "actor_entropy": 0.47819189750959, "alpha_loss": -0.0034412822043079706, "alpha_value": 0.21994172221860187, "duration": 138.5809633731842, "step": 32625}
{"episode_reward": 235.381712283276, "episode": 262.0, "Q1 loss": 6.13698316192627, "Q2 loss": 6.143593723297119, "Mean Target Q": 165.32189562988282, "Mean Q1": 165.32029565429687, "Mean Q2": 165.32075830078125, "critic_loss": 12.280576938629151, "batch_reward": 1.7069116888046265, "actor_loss": -165.6761979133852, "actor_target_entropy": -1.0, "actor_entropy": 0.4594802827604355, "alpha_loss": 0.005449628048095732, "alpha_value": 0.2197107320491713, "duration": 110.15147876739502, "step": 32750}
{"episode_reward": 191.4827695979749, "episode": 263.0, "Q1 loss": 6.163734411239624, "Q2 loss": 6.148290306091309, "Mean Target Q": 165.67491516113282, "Mean Q1": 165.66710473632813, "Mean Q2": 165.66656127929687, "critic_loss": 12.312024707794189, "batch_reward": 1.707240704536438, "actor_loss": -166.04992700001551, "actor_target_entropy": -1.0, "actor_entropy": 0.4670423978850955, "alpha_loss": 0.0019197603706122628, "alpha_value": 0.21953921591906467, "duration": 112.4784049987793, "step": 32875}
{"episode_reward": 179.15612137204457, "episode": 264.0, "Q1 loss": 5.963275159835815, "Q2 loss": 5.992327785491943, "Mean Target Q": 165.86893103027344, "Mean Q1": 165.8733546142578, "Mean Q2": 165.8748330078125, "critic_loss": 11.955602966308593, "batch_reward": 1.7095343494415283, "actor_loss": -166.27674028950352, "actor_target_entropy": -1.0, "actor_entropy": 0.45148588765052056, "alpha_loss": -9.014864542311237e-06, "alpha_value": 0.21945668734218804, "duration": 111.74981880187988, "step": 33000}
{"episode_reward": 251.0342229865772, "episode": 265.0, "Q1 loss": 6.517276931762695, "Q2 loss": 6.553786701202393, "Mean Target Q": 166.07180725097658, "Mean Q1": 166.07051110839845, "Mean Q2": 166.06819104003907, "critic_loss": 13.071063594818115, "batch_reward": 1.7031119222640991, "actor_loss": -166.52910359700522, "actor_target_entropy": -1.0, "actor_entropy": 0.45854197276963127, "alpha_loss": 0.001887905289463344, "alpha_value": 0.21940662217545148, "duration": 141.53098154067993, "step": 33125}
{"episode_reward": 219.11644476407628, "episode": 266.0, "Q1 loss": 6.2964229469299315, "Q2 loss": 6.291439010620117, "Mean Target Q": 166.33778466796875, "Mean Q1": 166.33437365722656, "Mean Q2": 166.33582397460938, "critic_loss": 12.587861846923827, "batch_reward": 1.7112887878417968, "actor_loss": -166.75505730413622, "actor_target_entropy": -1.0, "actor_entropy": 0.4278045960011021, "alpha_loss": -0.004395771854286713, "alpha_value": 0.21944196225996673, "duration": 121.74697947502136, "step": 33250}
{"episode_reward": 276.24687817429657, "episode": 267.0, "Q1 loss": 5.931015480041504, "Q2 loss": 5.9006979999542235, "Mean Target Q": 166.59328918457032, "Mean Q1": 166.5927791748047, "Mean Q2": 166.592220703125, "critic_loss": 11.831713481903076, "batch_reward": 1.7104703903198242, "actor_loss": -167.0378706190321, "actor_target_entropy": -1.0, "actor_entropy": 0.47038293357879396, "alpha_loss": 0.0022518987811747052, "alpha_value": 0.21956653687209202, "duration": 102.95470786094666, "step": 33375}
{"episode_reward": 243.3087709355307, "episode": 268.0, "Q1 loss": 6.173360614776612, "Q2 loss": 6.133558631896973, "Mean Target Q": 166.76713708496095, "Mean Q1": 166.76426123046875, "Mean Q2": 166.76272082519532, "critic_loss": 12.30691925430298, "batch_reward": 1.7076612377166749, "actor_loss": -167.23588094403667, "actor_target_entropy": -1.0, "actor_entropy": 0.47288250346337596, "alpha_loss": 0.002268868558589489, "alpha_value": 0.21945706454043992, "duration": 106.37480282783508, "step": 33500}
{"episode_reward": 220.41075800669321, "episode": 269.0, "Q1 loss": 5.943319507598877, "Q2 loss": 5.9444338359832765, "Mean Target Q": 167.0492365722656, "Mean Q1": 167.05039807128907, "Mean Q2": 167.04951708984376, "critic_loss": 11.887753387451172, "batch_reward": 1.7112673645019532, "actor_loss": -167.52676343160962, "actor_target_entropy": -1.0, "actor_entropy": 0.4696355093093145, "alpha_loss": 0.00396552563290156, "alpha_value": 0.2191919851346653, "duration": 120.27822494506836, "step": 33625}
{"episode_reward": 258.19632815118075, "episode": 270.0, "Q1 loss": 5.936548824310303, "Q2 loss": 5.918150506973267, "Mean Target Q": 167.2956358642578, "Mean Q1": 167.2898017578125, "Mean Q2": 167.29061328125, "critic_loss": 11.854699348449707, "batch_reward": 1.7089428777694702, "actor_loss": -167.71597560759514, "actor_target_entropy": -1.0, "actor_entropy": 0.45860871384220736, "alpha_loss": 0.002727109503241316, "alpha_value": 0.2189791027062183, "duration": 125.44464707374573, "step": 33750}
{"episode_reward": 249.2373588430228, "episode": 271.0, "Q1 loss": 5.899732591629029, "Q2 loss": 5.892794555664063, "Mean Target Q": 167.57540795898439, "Mean Q1": 167.57122937011718, "Mean Q2": 167.57176770019532, "critic_loss": 11.792527240753174, "batch_reward": 1.7130851774215698, "actor_loss": -167.98995656815785, "actor_target_entropy": -1.0, "actor_entropy": 0.4867178168561723, "alpha_loss": 0.0067110869013482614, "alpha_value": 0.21852387657226835, "duration": 127.75402784347534, "step": 33875}
{"episode_reward": 232.29483338196985, "episode": 272.0, "Q1 loss": 6.074203350067139, "Q2 loss": 6.080502153396607, "Mean Target Q": 167.879587890625, "Mean Q1": 167.88058410644533, "Mean Q2": 167.88045202636718, "critic_loss": 12.154705528259278, "batch_reward": 1.7163042068481444, "actor_loss": -168.32850843860257, "actor_target_entropy": -1.0, "actor_entropy": 0.4500045209161697, "alpha_loss": 0.00037329672693064617, "alpha_value": 0.2182433876584791, "duration": 120.18967366218567, "step": 34000}
{"episode_reward": 144.8363701664147, "episode": 273.0, "Q1 loss": 6.127766805648804, "Q2 loss": 6.122767681121826, "Mean Target Q": 168.06275268554688, "Mean Q1": 168.063658203125, "Mean Q2": 168.0637364501953, "critic_loss": 12.25053450012207, "batch_reward": 1.7228677291870118, "actor_loss": -168.499999515594, "actor_target_entropy": -1.0, "actor_entropy": 0.4568026401693859, "alpha_loss": 0.0022889551011815905, "alpha_value": 0.21824158573371413, "duration": 131.6835503578186, "step": 34125}
{"episode_reward": 221.54130180921447, "episode": 274.0, "Q1 loss": 6.183550876617431, "Q2 loss": 6.187486404418945, "Mean Target Q": 168.3254796142578, "Mean Q1": 168.31960961914064, "Mean Q2": 168.31842041015625, "critic_loss": 12.371037273406982, "batch_reward": 1.7055910921096802, "actor_loss": -168.7951187626008, "actor_target_entropy": -1.0, "actor_entropy": 0.4623377299116504, "alpha_loss": 0.00040368439306715323, "alpha_value": 0.21813364325567064, "duration": 132.90591764450073, "step": 34250}
{"episode_reward": 260.0706301174319, "episode": 275.0, "Q1 loss": 5.953387928009033, "Q2 loss": 5.959119359970093, "Mean Target Q": 168.59802001953125, "Mean Q1": 168.60063122558594, "Mean Q2": 168.60156860351563, "critic_loss": 11.91250732421875, "batch_reward": 1.7092083969116212, "actor_loss": -168.9449482266865, "actor_target_entropy": -1.0, "actor_entropy": 0.47941444459415616, "alpha_loss": -0.002570444093425832, "alpha_value": 0.21821980878581151, "duration": 115.09085869789124, "step": 34375}
{"episode_reward": 186.7795509843386, "episode": 276.0, "Q1 loss": 5.71214172744751, "Q2 loss": 5.702242725372314, "Mean Target Q": 168.7721317138672, "Mean Q1": 168.76864672851562, "Mean Q2": 168.76999182128907, "critic_loss": 11.414384426116943, "batch_reward": 1.710919945716858, "actor_loss": -169.13798449116368, "actor_target_entropy": -1.0, "actor_entropy": 0.4728608400590958, "alpha_loss": 0.0066378667289691586, "alpha_value": 0.2179672203771781, "duration": 147.9664604663849, "step": 34500}
{"episode_reward": 137.54519029802623, "episode": 277.0, "Q1 loss": 6.469035202026367, "Q2 loss": 6.4617721118927, "Mean Target Q": 168.96506298828126, "Mean Q1": 168.96291442871095, "Mean Q2": 168.9612686767578, "critic_loss": 12.930807373046875, "batch_reward": 1.7046649131774902, "actor_loss": -169.39616054958768, "actor_target_entropy": -1.0, "actor_entropy": 0.4710448062609112, "alpha_loss": -1.0450159953463645e-05, "alpha_value": 0.2178088387564652, "duration": 123.56743383407593, "step": 34625}
{"episode_reward": 274.27890202761483, "episode": 278.0, "Q1 loss": 6.5156884803771975, "Q2 loss": 6.525620372772217, "Mean Target Q": 169.11969177246092, "Mean Q1": 169.11946276855468, "Mean Q2": 169.12028784179688, "critic_loss": 13.041308853149413, "batch_reward": 1.7024111614227295, "actor_loss": -169.55406878071446, "actor_target_entropy": -1.0, "actor_entropy": 0.46595811459325975, "alpha_loss": -0.005953230853793362, "alpha_value": 0.21800647881974838, "duration": 139.41861867904663, "step": 34750}
{"episode_reward": 124.88291339365082, "episode": 279.0, "Q1 loss": 6.351880222320557, "Q2 loss": 6.359154178619384, "Mean Target Q": 169.3908875732422, "Mean Q1": 169.3890460205078, "Mean Q2": 169.39011328125, "critic_loss": 12.711034404754638, "batch_reward": 1.7150480995178223, "actor_loss": -169.81122310577877, "actor_target_entropy": -1.0, "actor_entropy": 0.46358594203752185, "alpha_loss": -0.001397788188316756, "alpha_value": 0.21836237520822221, "duration": 118.91889548301697, "step": 34875}
{"episode_reward": 273.54216544607186, "episode": 280.0, "Q1 loss": 6.649806526184082, "Q2 loss": 6.662987632751465, "Mean Target Q": 169.61532971191406, "Mean Q1": 169.6120244140625, "Mean Q2": 169.61115258789061, "critic_loss": 13.312794174194336, "batch_reward": 1.7118975458145143, "actor_loss": -170.05319336921937, "actor_target_entropy": -1.0, "actor_entropy": 0.48780568713142025, "alpha_loss": -0.003193602442831522, "alpha_value": 0.21854670972580448, "step": 35000}
{"duration": 130.64710474014282, "step": 35000}
{"episode_reward": 140.34995871087588, "episode": 281.0, "Q1 loss": 6.304068946838379, "Q2 loss": 6.297141265869141, "Mean Target Q": 169.67330334472655, "Mean Q1": 169.67389672851561, "Mean Q2": 169.67303588867188, "critic_loss": 12.601210166931152, "batch_reward": 1.7050329303741456, "actor_loss": -170.07614184182788, "actor_target_entropy": -1.0, "actor_entropy": 0.4892318466353038, "alpha_loss": 0.0037735050751103293, "alpha_value": 0.2184623078614454, "duration": 134.64016222953796, "step": 35125}
{"episode_reward": 237.0932745512123, "episode": 282.0, "Q1 loss": 6.280371366500854, "Q2 loss": 6.285598909378051, "Mean Target Q": 169.96428173828124, "Mean Q1": 169.95650390625, "Mean Q2": 169.95771057128906, "critic_loss": 12.565970233917236, "batch_reward": 1.7062072505950927, "actor_loss": -170.3684079570155, "actor_target_entropy": -1.0, "actor_entropy": 0.4592616567688604, "alpha_loss": 0.011113288515668002, "alpha_value": 0.2178938029854656, "duration": 137.36282014846802, "step": 35250}
{"episode_reward": 260.4488803808478, "episode": 283.0, "Q1 loss": 6.322162799835205, "Q2 loss": 6.356723960876465, "Mean Target Q": 170.252287109375, "Mean Q1": 170.25806311035157, "Mean Q2": 170.25700964355468, "critic_loss": 12.678886734008788, "batch_reward": 1.7152454347610473, "actor_loss": -170.62873428586929, "actor_target_entropy": -1.0, "actor_entropy": 0.46732847889264423, "alpha_loss": 0.011039142526449665, "alpha_value": 0.21711292822380399, "duration": 124.27646803855896, "step": 35375}
{"episode_reward": 272.45252693070864, "episode": 284.0, "Q1 loss": 6.279497417449951, "Q2 loss": 6.276673452377319, "Mean Target Q": 170.37365795898438, "Mean Q1": 170.36613012695312, "Mean Q2": 170.36557312011718, "critic_loss": 12.556170886993408, "batch_reward": 1.7125326900482178, "actor_loss": -170.84036033384263, "actor_target_entropy": -1.0, "actor_entropy": 0.47983957009930767, "alpha_loss": 0.004768003127537668, "alpha_value": 0.21668513106931298, "duration": 141.22089338302612, "step": 35500}
{"episode_reward": 246.69709944216575, "episode": 285.0, "Q1 loss": 6.229746490478516, "Q2 loss": 6.249428857803345, "Mean Target Q": 170.5931024169922, "Mean Q1": 170.59115295410157, "Mean Q2": 170.59195227050782, "critic_loss": 12.479175365447999, "batch_reward": 1.7125864114761353, "actor_loss": -170.9148419092572, "actor_target_entropy": -1.0, "actor_entropy": 0.48383089568879867, "alpha_loss": 0.0030964557968434833, "alpha_value": 0.21625462197312065, "duration": 127.12127685546875, "step": 35625}
{"episode_reward": 235.73972290005133, "episode": 286.0, "Q1 loss": 6.155467836380005, "Q2 loss": 6.172505819320679, "Mean Target Q": 170.80611682128907, "Mean Q1": 170.8037744140625, "Mean Q2": 170.80430969238282, "critic_loss": 12.327973705291749, "batch_reward": 1.712812638282776, "actor_loss": -171.16986945367628, "actor_target_entropy": -1.0, "actor_entropy": 0.4805611530619283, "alpha_loss": 0.006369335193847937, "alpha_value": 0.21589057048739596, "duration": 134.80221581459045, "step": 35750}
{"episode_reward": 257.15295332852526, "episode": 287.0, "Q1 loss": 6.045289896011353, "Q2 loss": 6.02813204574585, "Mean Target Q": 171.0885596923828, "Mean Q1": 171.09085009765624, "Mean Q2": 171.09069702148437, "critic_loss": 12.073421867370605, "batch_reward": 1.7125339756011964, "actor_loss": -171.4573504735553, "actor_target_entropy": -1.0, "actor_entropy": 0.4565671223496634, "alpha_loss": 0.005048900083195241, "alpha_value": 0.21548966136109657, "duration": 125.43674874305725, "step": 35875}
{"episode_reward": 202.8907113604601, "episode": 288.0, "Q1 loss": 6.297535634994507, "Q2 loss": 6.28042911529541, "Mean Target Q": 171.25899694824218, "Mean Q1": 171.25561462402345, "Mean Q2": 171.2545791015625, "critic_loss": 12.577964744567872, "batch_reward": 1.695825963973999, "actor_loss": -171.62430252567415, "actor_target_entropy": -1.0, "actor_entropy": 0.4782172801994508, "alpha_loss": -0.006951652241930846, "alpha_value": 0.21559216056926578, "duration": 141.14247345924377, "step": 36000}
{"episode_reward": 235.69141575224216, "episode": 289.0, "Q1 loss": 5.867929489135742, "Q2 loss": 5.833150741577149, "Mean Target Q": 171.5264100341797, "Mean Q1": 171.5239522705078, "Mean Q2": 171.52371936035155, "critic_loss": 11.70108023071289, "batch_reward": 1.7132986974716187, "actor_loss": -171.88536386641246, "actor_target_entropy": -1.0, "actor_entropy": 0.4617198984774332, "alpha_loss": -0.0031159870725657257, "alpha_value": 0.21591683655459395, "duration": 109.17836427688599, "step": 36125}
{"episode_reward": 247.24620757633193, "episode": 290.0, "Q1 loss": 6.411446189880371, "Q2 loss": 6.382082813262939, "Mean Target Q": 171.78172863769532, "Mean Q1": 171.78023046875, "Mean Q2": 171.7798165283203, "critic_loss": 12.793529022216797, "batch_reward": 1.7025847778320313, "actor_loss": -172.22243056758757, "actor_target_entropy": -1.0, "actor_entropy": 0.46051888215926384, "alpha_loss": -0.003048992611565477, "alpha_value": 0.21621602896069755, "duration": 97.82953143119812, "step": 36250}
{"episode_reward": 252.1087062519466, "episode": 291.0, "Q1 loss": 6.214643232345581, "Q2 loss": 6.21941134262085, "Mean Target Q": 171.95708337402343, "Mean Q1": 171.95886059570313, "Mean Q2": 171.95946069335938, "critic_loss": 12.434054611206054, "batch_reward": 1.7274039945602417, "actor_loss": -172.42260669526598, "actor_target_entropy": -1.0, "actor_entropy": 0.47952452065452694, "alpha_loss": 0.0012507732100193463, "alpha_value": 0.2164527171670042, "duration": 142.16791462898254, "step": 36375}
{"episode_reward": 252.23988901385837, "episode": 292.0, "Q1 loss": 6.170241817474365, "Q2 loss": 6.204229530334473, "Mean Target Q": 172.11244616699219, "Mean Q1": 172.10864855957033, "Mean Q2": 172.10899487304687, "critic_loss": 12.374471290588378, "batch_reward": 1.7218680448532104, "actor_loss": -172.51344668480658, "actor_target_entropy": -1.0, "actor_entropy": 0.46965505807630475, "alpha_loss": -0.0034522386943741192, "alpha_value": 0.21639842263904924, "duration": 122.56366205215454, "step": 36500}
{"episode_reward": 274.7142727128726, "episode": 293.0, "Q1 loss": 6.291651512145996, "Q2 loss": 6.318793251037597, "Mean Target Q": 172.338478515625, "Mean Q1": 172.33236120605468, "Mean Q2": 172.33103393554688, "critic_loss": 12.610444770812988, "batch_reward": 1.7202228107452393, "actor_loss": -172.78023516942585, "actor_target_entropy": -1.0, "actor_entropy": 0.4417723474048433, "alpha_loss": -0.011126354806095598, "alpha_value": 0.2168060904796369, "duration": 127.59812903404236, "step": 36625}
{"episode_reward": 178.35883569713295, "episode": 294.0, "Q1 loss": 6.461831764221191, "Q2 loss": 6.433381713867187, "Mean Target Q": 172.55970715332032, "Mean Q1": 172.56772924804687, "Mean Q2": 172.56707763671875, "critic_loss": 12.895213489532471, "batch_reward": 1.7277034845352173, "actor_loss": -172.9593983311807, "actor_target_entropy": -1.0, "actor_entropy": 0.44424594169662845, "alpha_loss": 5.0415752470613486e-05, "alpha_value": 0.2172477412082926, "duration": 129.55522227287292, "step": 36750}
{"episode_reward": 293.1856550879614, "episode": 295.0, "Q1 loss": 6.373380020141601, "Q2 loss": 6.368485359191895, "Mean Target Q": 172.83506591796876, "Mean Q1": 172.82683471679687, "Mean Q2": 172.82697241210937, "critic_loss": 12.741865409851075, "batch_reward": 1.7276957864761353, "actor_loss": -173.2648438953218, "actor_target_entropy": -1.0, "actor_entropy": 0.4429302579826779, "alpha_loss": -0.0030630620728646007, "alpha_value": 0.21744630585180078, "duration": 132.80783224105835, "step": 36875}
{"episode_reward": 249.80280381911766, "episode": 296.0, "Q1 loss": 6.263141925811768, "Q2 loss": 6.258936836242675, "Mean Target Q": 172.9323887939453, "Mean Q1": 172.92694921875, "Mean Q2": 172.9285430908203, "critic_loss": 12.522078716278076, "batch_reward": 1.7136275491714477, "actor_loss": -173.31334243282194, "actor_target_entropy": -1.0, "actor_entropy": 0.4761376227101972, "alpha_loss": -0.0012689563445746899, "alpha_value": 0.21747203601712942, "duration": 134.86227107048035, "step": 37000}
{"episode_reward": 275.24384437178077, "episode": 297.0, "Q1 loss": 6.432558620452881, "Q2 loss": 6.4427831192016605, "Mean Target Q": 173.01556909179686, "Mean Q1": 173.0201544189453, "Mean Q2": 173.01913891601563, "critic_loss": 12.875341712951661, "batch_reward": 1.7331737957000732, "actor_loss": -173.43875436934215, "actor_target_entropy": -1.0, "actor_entropy": 0.47353854964649866, "alpha_loss": 0.00119900716734784, "alpha_value": 0.21746168972587968, "duration": 118.87904620170593, "step": 37125}
{"episode_reward": 231.88313258095067, "episode": 298.0, "Q1 loss": 6.202530471801758, "Q2 loss": 6.25293404006958, "Mean Target Q": 173.297107421875, "Mean Q1": 173.2956971435547, "Mean Q2": 173.2952824707031, "critic_loss": 12.455464553833007, "batch_reward": 1.7234197149276733, "actor_loss": -173.71420165031188, "actor_target_entropy": -1.0, "actor_entropy": 0.46207940386187646, "alpha_loss": -0.0010742386953244286, "alpha_value": 0.21758753001533715, "duration": 120.71834015846252, "step": 37250}
{"episode_reward": 209.19802331786624, "episode": 299.0, "Q1 loss": 6.291285301208496, "Q2 loss": 6.274438976287842, "Mean Target Q": 173.55045324707032, "Mean Q1": 173.547755859375, "Mean Q2": 173.54776708984375, "critic_loss": 12.56572428894043, "batch_reward": 1.727285530090332, "actor_loss": -173.9444352407304, "actor_target_entropy": -1.0, "actor_entropy": 0.4905194171837398, "alpha_loss": 0.005950864350851921, "alpha_value": 0.21736135676766224, "duration": 129.3069829940796, "step": 37375}
{"episode_reward": 224.52669608777, "episode": 300.0, "Q1 loss": 6.64331763458252, "Q2 loss": 6.630340347290039, "Mean Target Q": 173.70284497070313, "Mean Q1": 173.69775988769533, "Mean Q2": 173.6989404296875, "critic_loss": 13.27365795135498, "batch_reward": 1.7345813493728637, "actor_loss": -174.10668354649698, "actor_target_entropy": -1.0, "actor_entropy": 0.47197975074091264, "alpha_loss": -0.0018094323890944643, "alpha_value": 0.2171386250276526, "duration": 132.31991600990295, "step": 37500}
{"episode_reward": 224.72628177956474, "episode": 301.0, "Q1 loss": 6.4759459323883055, "Q2 loss": 6.493716339111328, "Mean Target Q": 173.87782421875, "Mean Q1": 173.8824892578125, "Mean Q2": 173.88128869628906, "critic_loss": 12.96966226196289, "batch_reward": 1.7261111040115356, "actor_loss": -174.25724235413566, "actor_target_entropy": -1.0, "actor_entropy": 0.46432741956105306, "alpha_loss": 0.0026454654197016407, "alpha_value": 0.2170647615254694, "duration": 143.8183672428131, "step": 37625}
{"episode_reward": 276.55007967689755, "episode": 302.0, "Q1 loss": 6.144296733856201, "Q2 loss": 6.183080623626709, "Mean Target Q": 174.12735119628906, "Mean Q1": 174.1209187011719, "Mean Q2": 174.1227587890625, "critic_loss": 12.327377353668213, "batch_reward": 1.723950276374817, "actor_loss": -174.55826125606413, "actor_target_entropy": -1.0, "actor_entropy": 0.44896452128887177, "alpha_loss": -0.0012022261958449117, "alpha_value": 0.21710711754313813, "duration": 132.02268767356873, "step": 37750}
{"episode_reward": 225.19983982865787, "episode": 303.0, "Q1 loss": 6.699090591430664, "Q2 loss": 6.737963094711303, "Mean Target Q": 174.39821154785156, "Mean Q1": 174.39685302734375, "Mean Q2": 174.39608825683592, "critic_loss": 13.437053695678712, "batch_reward": 1.7463945455551146, "actor_loss": -174.78306555369542, "actor_target_entropy": -1.0, "actor_entropy": 0.4457572206618294, "alpha_loss": -0.0031627708203381018, "alpha_value": 0.21730468642071582, "duration": 88.95053434371948, "step": 37875}
{"episode_reward": 207.72006434862038, "episode": 304.0, "Q1 loss": 6.250876749038697, "Q2 loss": 6.228482845306396, "Mean Target Q": 174.3996932373047, "Mean Q1": 174.39591088867186, "Mean Q2": 174.39606701660156, "critic_loss": 12.479359596252442, "batch_reward": 1.7155138864517212, "actor_loss": -174.85559771137852, "actor_target_entropy": -1.0, "actor_entropy": 0.4700285811578074, "alpha_loss": -0.0002847520499339988, "alpha_value": 0.21745772014246795, "duration": 124.75786638259888, "step": 38000}
{"episode_reward": 284.2245242431927, "episode": 305.0, "Q1 loss": 6.231465480804443, "Q2 loss": 6.219473527908325, "Mean Target Q": 174.66284814453124, "Mean Q1": 174.65869543457032, "Mean Q2": 174.65779602050782, "critic_loss": 12.450939041137696, "batch_reward": 1.7252882127761842, "actor_loss": -175.05618940080916, "actor_target_entropy": -1.0, "actor_entropy": 0.4688100649250878, "alpha_loss": 0.002909806231775927, "alpha_value": 0.21733397019832718, "duration": 142.85111141204834, "step": 38125}
{"episode_reward": 142.4944270749517, "episode": 306.0, "Q1 loss": 6.097983108520507, "Q2 loss": 6.134704582214355, "Mean Target Q": 174.87045959472655, "Mean Q1": 174.87274841308593, "Mean Q2": 174.87351684570314, "critic_loss": 12.232687686920166, "batch_reward": 1.729341326713562, "actor_loss": -175.2958922847625, "actor_target_entropy": -1.0, "actor_entropy": 0.4583567847167292, "alpha_loss": -0.00015952282269755678, "alpha_value": 0.21712357454199144, "duration": 143.8272967338562, "step": 38250}
{"episode_reward": 225.75021309600874, "episode": 307.0, "Q1 loss": 6.448642456054688, "Q2 loss": 6.39976937866211, "Mean Target Q": 175.09832116699218, "Mean Q1": 175.09960400390625, "Mean Q2": 175.09994409179689, "critic_loss": 12.84841187286377, "batch_reward": 1.7333126001358032, "actor_loss": -175.46773807586186, "actor_target_entropy": -1.0, "actor_entropy": 0.4513684402382563, "alpha_loss": 0.005667396499553607, "alpha_value": 0.21700996374750822, "duration": 133.7896649837494, "step": 38375}
{"episode_reward": 225.60808768213346, "episode": 308.0, "Q1 loss": 6.046189514160156, "Q2 loss": 6.052094514846802, "Mean Target Q": 175.19869689941407, "Mean Q1": 175.18947106933595, "Mean Q2": 175.19018115234374, "critic_loss": 12.098284042358399, "batch_reward": 1.7216640729904176, "actor_loss": -175.63827933034588, "actor_target_entropy": -1.0, "actor_entropy": 0.4722066819667816, "alpha_loss": -0.000985570790831961, "alpha_value": 0.2168781304830976, "duration": 119.4559473991394, "step": 38500}
{"episode_reward": 225.8035505891895, "episode": 309.0, "Q1 loss": 6.1173200569152835, "Q2 loss": 6.146282466888428, "Mean Target Q": 175.46993786621093, "Mean Q1": 175.47492822265625, "Mean Q2": 175.4743038330078, "critic_loss": 12.26360249710083, "batch_reward": 1.721380786895752, "actor_loss": -175.95492311507937, "actor_target_entropy": -1.0, "actor_entropy": 0.4447017513097279, "alpha_loss": -0.009842514548273314, "alpha_value": 0.21716642999186275, "duration": 138.0208704471588, "step": 38625}
{"episode_reward": 142.16891323628184, "episode": 310.0, "Q1 loss": 6.211743684768677, "Q2 loss": 6.225468433380127, "Mean Target Q": 175.51969409179688, "Mean Q1": 175.51447424316407, "Mean Q2": 175.51444787597657, "critic_loss": 12.437212104797362, "batch_reward": 1.7171588220596314, "actor_loss": -175.84707346270162, "actor_target_entropy": -1.0, "actor_entropy": 0.4813184118078601, "alpha_loss": 0.0024151360135405294, "alpha_value": 0.21767473612900282, "duration": 124.3975203037262, "step": 38750}
{"episode_reward": 248.4316018508155, "episode": 311.0, "Q1 loss": 6.648841190338135, "Q2 loss": 6.7209674186706545, "Mean Target Q": 175.68584033203126, "Mean Q1": 175.6812313232422, "Mean Q2": 175.68122839355468, "critic_loss": 13.36980859375, "batch_reward": 1.7245912675857544, "actor_loss": -176.12879798525856, "actor_target_entropy": -1.0, "actor_entropy": 0.47603649989007013, "alpha_loss": -0.00021784710476086255, "alpha_value": 0.21752886984810024, "duration": 98.10870218276978, "step": 38875}
{"episode_reward": 191.69947233963939, "episode": 312.0, "Q1 loss": 6.559012557983398, "Q2 loss": 6.565835567474365, "Mean Target Q": 175.8829737548828, "Mean Q1": 175.8838916015625, "Mean Q2": 175.88419384765626, "critic_loss": 13.124848114013671, "batch_reward": 1.7223730201721192, "actor_loss": -176.29328155517578, "actor_target_entropy": -1.0, "actor_entropy": 0.46732302731083286, "alpha_loss": -0.0026368850263796986, "alpha_value": 0.21763144156771913, "duration": 131.3786277770996, "step": 39000}
{"episode_reward": 282.257739861587, "episode": 313.0, "Q1 loss": 6.300079936981201, "Q2 loss": 6.35570358467102, "Mean Target Q": 176.06971252441406, "Mean Q1": 176.06793811035158, "Mean Q2": 176.06746142578126, "critic_loss": 12.655783576965332, "batch_reward": 1.731907416343689, "actor_loss": -176.41882445320252, "actor_target_entropy": -1.0, "actor_entropy": 0.4905077294697837, "alpha_loss": -0.001495249700614266, "alpha_value": 0.21772590024417793, "duration": 138.42647504806519, "step": 39125}
{"episode_reward": 232.37143654220097, "episode": 314.0, "Q1 loss": 6.433913175582886, "Q2 loss": 6.380182800292968, "Mean Target Q": 176.26402270507813, "Mean Q1": 176.2665782470703, "Mean Q2": 176.26594763183593, "critic_loss": 12.814095962524414, "batch_reward": 1.723750958442688, "actor_loss": -176.61280035203504, "actor_target_entropy": -1.0, "actor_entropy": 0.46912625624287513, "alpha_loss": 0.00017393585069165114, "alpha_value": 0.21795641070705898, "duration": 122.79372644424438, "step": 39250}
{"episode_reward": 243.99435747050646, "episode": 315.0, "Q1 loss": 6.427350437164306, "Q2 loss": 6.425631931304932, "Mean Target Q": 176.46307385253905, "Mean Q1": 176.4536024169922, "Mean Q2": 176.45403576660155, "critic_loss": 12.852982353210448, "batch_reward": 1.7415379486083984, "actor_loss": -176.77718680245536, "actor_target_entropy": -1.0, "actor_entropy": 0.4565784784536513, "alpha_loss": 0.005101756370138554, "alpha_value": 0.21756756289589557, "duration": 145.1475350856781, "step": 39375}
{"episode_reward": 200.72834293852674, "episode": 316.0, "Q1 loss": 6.268642553329467, "Q2 loss": 6.254290256500244, "Mean Target Q": 176.6376951904297, "Mean Q1": 176.63917321777345, "Mean Q2": 176.63846508789064, "critic_loss": 12.522932800292969, "batch_reward": 1.734648512840271, "actor_loss": -177.05864838630922, "actor_target_entropy": -1.0, "actor_entropy": 0.47581218615654974, "alpha_loss": -0.0015796349278741305, "alpha_value": 0.2173240933918378, "duration": 138.5112385749817, "step": 39500}
{"episode_reward": 280.7417612958579, "episode": 317.0, "Q1 loss": 6.454144832611084, "Q2 loss": 6.467258678436279, "Mean Target Q": 176.7491827392578, "Mean Q1": 176.74665197753907, "Mean Q2": 176.74623254394533, "critic_loss": 12.921403438568115, "batch_reward": 1.729709041595459, "actor_loss": -177.12899150545636, "actor_target_entropy": -1.0, "actor_entropy": 0.4755134539944785, "alpha_loss": -0.0022180992777326275, "alpha_value": 0.21743055628906308, "duration": 107.99901533126831, "step": 39625}
{"episode_reward": 221.7976905160925, "episode": 318.0, "Q1 loss": 6.2530681400299075, "Q2 loss": 6.253837139129638, "Mean Target Q": 176.967548828125, "Mean Q1": 176.9703153076172, "Mean Q2": 176.9698067626953, "critic_loss": 12.506905319213868, "batch_reward": 1.7357148122787476, "actor_loss": -177.37282291535408, "actor_target_entropy": -1.0, "actor_entropy": 0.47953925209660686, "alpha_loss": 0.0005843602590292933, "alpha_value": 0.2175902149862203, "duration": 122.90780091285706, "step": 39750}
{"episode_reward": 223.52500100155507, "episode": 319.0, "Q1 loss": 6.225792381286621, "Q2 loss": 6.221180828094482, "Mean Target Q": 177.13037048339845, "Mean Q1": 177.12836315917968, "Mean Q2": 177.1304298095703, "critic_loss": 12.446973217010498, "batch_reward": 1.7374746656417848, "actor_loss": -177.56124659946985, "actor_target_entropy": -1.0, "actor_entropy": 0.4723476507360973, "alpha_loss": 0.0028943527611859496, "alpha_value": 0.21758041404286124, "duration": 131.60026335716248, "step": 39875}
{"episode_reward": 206.06262152038985, "episode": 320.0, "Q1 loss": 6.413372900009155, "Q2 loss": 6.390968608856201, "Mean Target Q": 177.3490225830078, "Mean Q1": 177.34711059570313, "Mean Q2": 177.3468444824219, "critic_loss": 12.804341499328613, "batch_reward": 1.7338763084411621, "actor_loss": -177.73995504071635, "actor_target_entropy": -1.0, "actor_entropy": 0.473914667483299, "alpha_loss": -0.0025809011196777703, "alpha_value": 0.21753682268254315, "step": 40000}
{"duration": 146.06008052825928, "step": 40000}
{"episode_reward": 337.201570096235, "episode": 321.0, "Q1 loss": 6.582026151657105, "Q2 loss": 6.643133224487305, "Mean Target Q": 177.51626245117188, "Mean Q1": 177.5165167236328, "Mean Q2": 177.5158077392578, "critic_loss": 13.225159408569336, "batch_reward": 1.7396780443191528, "actor_loss": -177.94532751658605, "actor_target_entropy": -1.0, "actor_entropy": 0.42694659401026985, "alpha_loss": -0.005071131956009637, "alpha_value": 0.21773642654967904, "duration": 126.61235880851746, "step": 40125}
{"episode_reward": 277.92158345894217, "episode": 322.0, "Q1 loss": 6.4532296772003175, "Q2 loss": 6.477618995666504, "Mean Target Q": 177.68616906738282, "Mean Q1": 177.67823120117188, "Mean Q2": 177.67753405761718, "critic_loss": 12.930848670959472, "batch_reward": 1.7263921575546264, "actor_loss": -178.0564695788968, "actor_target_entropy": -1.0, "actor_entropy": 0.4726322394224905, "alpha_loss": 0.003838185784256747, "alpha_value": 0.21770787841640213, "duration": 119.79533267021179, "step": 40250}
{"episode_reward": 194.55123933965018, "episode": 323.0, "Q1 loss": 6.362168926239014, "Q2 loss": 6.361724349975586, "Mean Target Q": 177.86485375976562, "Mean Q1": 177.87172033691405, "Mean Q2": 177.87214233398439, "critic_loss": 12.72389331817627, "batch_reward": 1.7248693113327027, "actor_loss": -178.2160174657428, "actor_target_entropy": -1.0, "actor_entropy": 0.46676784564578344, "alpha_loss": -0.0010106022144475626, "alpha_value": 0.21768143641305898, "duration": 128.12884831428528, "step": 40375}
{"episode_reward": 216.26440463036178, "episode": 324.0, "Q1 loss": 6.690173337936401, "Q2 loss": 6.7560787124633785, "Mean Target Q": 178.10465600585937, "Mean Q1": 178.0968712158203, "Mean Q2": 178.09691125488283, "critic_loss": 13.44625204849243, "batch_reward": 1.7322760391235352, "actor_loss": -178.5143326790102, "actor_target_entropy": -1.0, "actor_entropy": 0.4534943646961643, "alpha_loss": -0.001977504366227696, "alpha_value": 0.21778961810904707, "duration": 135.39949989318848, "step": 40500}
{"episode_reward": 278.44468716895216, "episode": 325.0, "Q1 loss": 6.390921152114868, "Q2 loss": 6.357121194839477, "Mean Target Q": 178.23281628417968, "Mean Q1": 178.2316629638672, "Mean Q2": 178.23250134277345, "critic_loss": 12.748042388916016, "batch_reward": 1.7261139183044434, "actor_loss": -178.65645732576886, "actor_target_entropy": -1.0, "actor_entropy": 0.4805137108242701, "alpha_loss": -0.002222010474060736, "alpha_value": 0.2179311589941004, "duration": 139.03794074058533, "step": 40625}
{"episode_reward": 249.26875130248175, "episode": 326.0, "Q1 loss": 6.120185501098633, "Q2 loss": 6.105434755325318, "Mean Target Q": 178.32488720703125, "Mean Q1": 178.32360729980468, "Mean Q2": 178.3225673828125, "critic_loss": 12.225620296478272, "batch_reward": 1.7409179458618165, "actor_loss": -178.70802159463204, "actor_target_entropy": -1.0, "actor_entropy": 0.4574712971525808, "alpha_loss": -0.0012712546571668599, "alpha_value": 0.2180680956889332, "duration": 144.213445186615, "step": 40750}
{"episode_reward": 289.1864922056379, "episode": 327.0, "Q1 loss": 6.478420333862305, "Q2 loss": 6.4573541965484615, "Mean Target Q": 178.5427637939453, "Mean Q1": 178.54087548828124, "Mean Q2": 178.54179443359374, "critic_loss": 12.935774520874023, "batch_reward": 1.7433735427856445, "actor_loss": -178.9400891500806, "actor_target_entropy": -1.0, "actor_entropy": 0.4843300003854055, "alpha_loss": -0.006710391912964128, "alpha_value": 0.21834023161726396, "duration": 134.057936668396, "step": 40875}
{"episode_reward": 249.90786530735346, "episode": 328.0, "Q1 loss": 6.225531354904175, "Q2 loss": 6.240990800857544, "Mean Target Q": 178.7754383544922, "Mean Q1": 178.7750498046875, "Mean Q2": 178.7748811035156, "critic_loss": 12.4665221824646, "batch_reward": 1.7401566677093505, "actor_loss": -179.11158555553806, "actor_target_entropy": -1.0, "actor_entropy": 0.46839217697420427, "alpha_loss": 0.003949954632609602, "alpha_value": 0.2186306728635577, "duration": 118.89933133125305, "step": 41000}
{"episode_reward": 223.5562993337995, "episode": 329.0, "Q1 loss": 6.3843391914367675, "Q2 loss": 6.440187713623047, "Mean Target Q": 178.83906298828126, "Mean Q1": 178.8331325683594, "Mean Q2": 178.83175842285155, "critic_loss": 12.82452685546875, "batch_reward": 1.734812707901001, "actor_loss": -179.20076933361236, "actor_target_entropy": -1.0, "actor_entropy": 0.4675696837523627, "alpha_loss": -0.004438727543438001, "alpha_value": 0.2184701544177765, "duration": 115.87418794631958, "step": 41125}
{"episode_reward": 241.445918489315, "episode": 330.0, "Q1 loss": 6.312741540908814, "Q2 loss": 6.298681070327759, "Mean Target Q": 179.04254919433595, "Mean Q1": 179.04434997558593, "Mean Q2": 179.04517150878905, "critic_loss": 12.61142259979248, "batch_reward": 1.7434116878509522, "actor_loss": -179.4174802226405, "actor_target_entropy": -1.0, "actor_entropy": 0.45085828150472335, "alpha_loss": 0.0002796249914794199, "alpha_value": 0.21870002866636684, "duration": 133.4587848186493, "step": 41250}
{"episode_reward": 312.7819569701037, "episode": 331.0, "Q1 loss": 6.215223937988282, "Q2 loss": 6.165055898666382, "Mean Target Q": 179.24764196777343, "Mean Q1": 179.24597717285155, "Mean Q2": 179.246064453125, "critic_loss": 12.3802798538208, "batch_reward": 1.75120880317688, "actor_loss": -179.63692098950582, "actor_target_entropy": -1.0, "actor_entropy": 0.45921543193241904, "alpha_loss": 0.004196677231303756, "alpha_value": 0.21852615313455173, "duration": 120.5201301574707, "step": 41375}
{"episode_reward": 253.24485387154098, "episode": 332.0, "Q1 loss": 6.442965980529785, "Q2 loss": 6.493157703399659, "Mean Target Q": 179.37818041992188, "Mean Q1": 179.37406274414062, "Mean Q2": 179.37430822753907, "critic_loss": 12.936123626708984, "batch_reward": 1.7447926778793335, "actor_loss": -179.78633683727634, "actor_target_entropy": -1.0, "actor_entropy": 0.4562238147181849, "alpha_loss": 0.0007569731040407092, "alpha_value": 0.21832917247894987, "duration": 123.90331554412842, "step": 41500}
{"episode_reward": 228.45852786585658, "episode": 333.0, "Q1 loss": 6.40067338180542, "Q2 loss": 6.407242811203003, "Mean Target Q": 179.4684532470703, "Mean Q1": 179.4726845703125, "Mean Q2": 179.47209802246093, "critic_loss": 12.807916206359863, "batch_reward": 1.7409192838668823, "actor_loss": -179.83350408644904, "actor_target_entropy": -1.0, "actor_entropy": 0.48645784552135163, "alpha_loss": 0.0001902061492382061, "alpha_value": 0.21822753750402027, "duration": 136.68935799598694, "step": 41625}
{"episode_reward": 254.92046508447268, "episode": 334.0, "Q1 loss": 6.301149787902832, "Q2 loss": 6.302913228988648, "Mean Target Q": 179.6821044921875, "Mean Q1": 179.67633837890625, "Mean Q2": 179.67671838378905, "critic_loss": 12.604062984466553, "batch_reward": 1.7399382791519165, "actor_loss": -180.061895801175, "actor_target_entropy": -1.0, "actor_entropy": 0.4778341699031092, "alpha_loss": 0.002437389421937687, "alpha_value": 0.21818612431800458, "duration": 135.2804799079895, "step": 41750}
{"episode_reward": 273.33658298899513, "episode": 335.0, "Q1 loss": 6.357234992980957, "Q2 loss": 6.4022604179382325, "Mean Target Q": 179.9255750732422, "Mean Q1": 179.92907653808595, "Mean Q2": 179.92847338867188, "critic_loss": 12.759495502471923, "batch_reward": 1.7441825923919678, "actor_loss": -180.27609034946985, "actor_target_entropy": -1.0, "actor_entropy": 0.4544264759336199, "alpha_loss": -0.002651125854176898, "alpha_value": 0.21820595918549535, "duration": 142.12539744377136, "step": 41875}
{"episode_reward": 220.85152777552725, "episode": 336.0, "Q1 loss": 6.37947278213501, "Q2 loss": 6.362473148345948, "Mean Target Q": 180.07174145507813, "Mean Q1": 180.0656737060547, "Mean Q2": 180.06556689453126, "critic_loss": 12.741945896148682, "batch_reward": 1.7468204069137574, "actor_loss": -180.4524454916677, "actor_target_entropy": -1.0, "actor_entropy": 0.4783341322214373, "alpha_loss": 0.0016960626573211725, "alpha_value": 0.21816394740052164, "duration": 125.07681441307068, "step": 42000}
{"episode_reward": 197.0604383012319, "episode": 337.0, "Q1 loss": 6.60292784500122, "Q2 loss": 6.601664958953857, "Mean Target Q": 180.20040869140624, "Mean Q1": 180.19490307617187, "Mean Q2": 180.19584436035157, "critic_loss": 13.204592826843262, "batch_reward": 1.7268231287002564, "actor_loss": -180.55604625883558, "actor_target_entropy": -1.0, "actor_entropy": 0.46328499392857625, "alpha_loss": 0.00610045371170614, "alpha_value": 0.21790371807289485, "duration": 141.69747304916382, "step": 42125}
{"episode_reward": 251.23535898987535, "episode": 338.0, "Q1 loss": 6.479200618743897, "Q2 loss": 6.4996937599182125, "Mean Target Q": 180.51267224121094, "Mean Q1": 180.5092724609375, "Mean Q2": 180.50762927246095, "critic_loss": 12.978894466400147, "batch_reward": 1.7443511123657227, "actor_loss": -180.9477827010616, "actor_target_entropy": -1.0, "actor_entropy": 0.45263031173136925, "alpha_loss": 0.002028384287240765, "alpha_value": 0.21767894696139287, "duration": 121.84516596794128, "step": 42250}
{"episode_reward": 265.4301080149786, "episode": 339.0, "Q1 loss": 6.544055084228516, "Q2 loss": 6.519831935882569, "Mean Target Q": 180.57842602539063, "Mean Q1": 180.5829659423828, "Mean Q2": 180.5833203125, "critic_loss": 13.063887084960937, "batch_reward": 1.7457710227966308, "actor_loss": -180.98056926424542, "actor_target_entropy": -1.0, "actor_entropy": 0.4806913208393824, "alpha_loss": -0.0027477924031988968, "alpha_value": 0.2176376123250404, "duration": 118.72662329673767, "step": 42375}
{"episode_reward": 245.34986766173833, "episode": 340.0, "Q1 loss": 6.391147327423096, "Q2 loss": 6.38030966758728, "Mean Target Q": 180.7885108642578, "Mean Q1": 180.7869796142578, "Mean Q2": 180.7872628173828, "critic_loss": 12.771456993103028, "batch_reward": 1.755466477394104, "actor_loss": -181.152710699266, "actor_target_entropy": -1.0, "actor_entropy": 0.43982882941922835, "alpha_loss": 0.001988272809784018, "alpha_value": 0.21762497960526347, "duration": 145.67866706848145, "step": 42500}
{"episode_reward": 186.64555896321497, "episode": 341.0, "Q1 loss": 6.492827152252198, "Q2 loss": 6.499649953842163, "Mean Target Q": 180.8489666748047, "Mean Q1": 180.8514825439453, "Mean Q2": 180.8517296142578, "critic_loss": 12.992477127075196, "batch_reward": 1.7544702577590943, "actor_loss": -181.20032392229353, "actor_target_entropy": -1.0, "actor_entropy": 0.4435048257074659, "alpha_loss": 0.003688684470641116, "alpha_value": 0.21748841421404277, "duration": 132.96249270439148, "step": 42625}
{"episode_reward": 223.12353091459897, "episode": 342.0, "Q1 loss": 6.579111434936523, "Q2 loss": 6.582991958618164, "Mean Target Q": 181.07296911621094, "Mean Q1": 181.06955187988282, "Mean Q2": 181.06885595703125, "critic_loss": 13.162103370666504, "batch_reward": 1.7303810863494873, "actor_loss": -181.48917659636467, "actor_target_entropy": -1.0, "actor_entropy": 0.46916301740754035, "alpha_loss": -0.00015299737213119385, "alpha_value": 0.2173400517747312, "duration": 120.59659075737, "step": 42750}
{"episode_reward": 195.94872359258707, "episode": 343.0, "Q1 loss": 6.399997314453125, "Q2 loss": 6.405388206481933, "Mean Target Q": 181.27815747070312, "Mean Q1": 181.28013830566405, "Mean Q2": 181.27941088867186, "critic_loss": 12.805385540008546, "batch_reward": 1.7407704973220826, "actor_loss": -181.68467809283544, "actor_target_entropy": -1.0, "actor_entropy": 0.4600525488929143, "alpha_loss": 0.004925901565464243, "alpha_value": 0.21716524111153623, "duration": 139.54408311843872, "step": 42875}
{"episode_reward": 230.51898326833526, "episode": 344.0, "Q1 loss": 6.438544788360596, "Q2 loss": 6.417359882354736, "Mean Target Q": 181.40193603515624, "Mean Q1": 181.39259631347656, "Mean Q2": 181.3938406982422, "critic_loss": 12.855904678344727, "batch_reward": 1.7465805034637452, "actor_loss": -181.75045382591986, "actor_target_entropy": -1.0, "actor_entropy": 0.46694320007678003, "alpha_loss": 0.004153318019703992, "alpha_value": 0.21691221381068276, "duration": 131.0330832004547, "step": 43000}
{"episode_reward": 223.60751690216497, "episode": 345.0, "Q1 loss": 6.54039175605774, "Q2 loss": 6.5316133880615235, "Mean Target Q": 181.54806616210936, "Mean Q1": 181.5548497314453, "Mean Q2": 181.55503735351562, "critic_loss": 13.072005180358886, "batch_reward": 1.740190040588379, "actor_loss": -181.8996383424789, "actor_target_entropy": -1.0, "actor_entropy": 0.4371754427750905, "alpha_loss": 0.002596477722926509, "alpha_value": 0.21656780232697756, "duration": 140.33511757850647, "step": 43125}
{"episode_reward": 281.8604930515181, "episode": 346.0, "Q1 loss": 6.395946918487549, "Q2 loss": 6.4193756980896, "Mean Target Q": 181.65903125, "Mean Q1": 181.64923876953125, "Mean Q2": 181.64773413085936, "critic_loss": 12.815322597503663, "batch_reward": 1.7598967056274415, "actor_loss": -181.98543277863533, "actor_target_entropy": -1.0, "actor_entropy": 0.46902962269321563, "alpha_loss": 0.0015446810810376078, "alpha_value": 0.21638156742468242, "duration": 127.84181523323059, "step": 43250}
{"episode_reward": 232.37858884413143, "episode": 347.0, "Q1 loss": 6.457320442199707, "Q2 loss": 6.4398942565917965, "Mean Target Q": 181.8763212890625, "Mean Q1": 181.87583642578124, "Mean Q2": 181.8768897705078, "critic_loss": 12.897214618682861, "batch_reward": 1.748858461380005, "actor_loss": -182.22640531025235, "actor_target_entropy": -1.0, "actor_entropy": 0.47102586428324383, "alpha_loss": 0.008824248295573016, "alpha_value": 0.21606734067362765, "duration": 113.6711676120758, "step": 43375}
{"episode_reward": 298.30348965306365, "episode": 348.0, "Q1 loss": 6.6169724388122555, "Q2 loss": 6.604505899429321, "Mean Target Q": 181.93703137207032, "Mean Q1": 181.93424645996095, "Mean Q2": 181.9348865966797, "critic_loss": 13.221478340148925, "batch_reward": 1.7591202602386475, "actor_loss": -182.29143721057522, "actor_target_entropy": -1.0, "actor_entropy": 0.45484927488911536, "alpha_loss": 0.0017919515206989262, "alpha_value": 0.21566791093660537, "duration": 114.85228323936462, "step": 43500}
{"episode_reward": 247.38235471313365, "episode": 349.0, "Q1 loss": 6.650836738586426, "Q2 loss": 6.677460851669312, "Mean Target Q": 182.18770275878907, "Mean Q1": 182.18982153320312, "Mean Q2": 182.188587890625, "critic_loss": 13.328297584533692, "batch_reward": 1.7474845142364501, "actor_loss": -182.56215074327258, "actor_target_entropy": -1.0, "actor_entropy": 0.46324257860108026, "alpha_loss": 0.002472604148178583, "alpha_value": 0.21556679140841492, "duration": 140.48909187316895, "step": 43625}
{"episode_reward": 232.81368453044183, "episode": 350.0, "Q1 loss": 6.743550973892212, "Q2 loss": 6.7236632614135745, "Mean Target Q": 182.23145263671876, "Mean Q1": 182.22528540039062, "Mean Q2": 182.22667797851562, "critic_loss": 13.467214233398437, "batch_reward": 1.7592586450576781, "actor_loss": -182.59210648075228, "actor_target_entropy": -1.0, "actor_entropy": 0.45196489701347964, "alpha_loss": 0.0035791225307020206, "alpha_value": 0.21527539247319485, "duration": 133.01843547821045, "step": 43750}
{"episode_reward": 270.9791163906094, "episode": 351.0, "Q1 loss": 6.382851448059082, "Q2 loss": 6.377585830688477, "Mean Target Q": 182.3970596923828, "Mean Q1": 182.3993985595703, "Mean Q2": 182.39784411621093, "critic_loss": 12.76043726348877, "batch_reward": 1.7461556615829468, "actor_loss": -182.80467781187997, "actor_target_entropy": -1.0, "actor_entropy": 0.46722118012488834, "alpha_loss": 0.0009552176176969494, "alpha_value": 0.21511842725329658, "duration": 108.76195120811462, "step": 43875}
{"episode_reward": 206.63663530083892, "episode": 352.0, "Q1 loss": 6.282726865768432, "Q2 loss": 6.294613298416138, "Mean Target Q": 182.59594067382812, "Mean Q1": 182.59161059570312, "Mean Q2": 182.59310290527344, "critic_loss": 12.577340209960937, "batch_reward": 1.741184525489807, "actor_loss": -182.99964215678554, "actor_target_entropy": -1.0, "actor_entropy": 0.45486470143641194, "alpha_loss": 0.01001210030799191, "alpha_value": 0.21464179903083594, "duration": 112.03178143501282, "step": 44000}
{"episode_reward": 213.0434949079205, "episode": 353.0, "Q1 loss": 6.131537433624268, "Q2 loss": 6.111705602645874, "Mean Target Q": 182.72601037597656, "Mean Q1": 182.7208045654297, "Mean Q2": 182.72003491210938, "critic_loss": 12.243243034362793, "batch_reward": 1.7430821495056152, "actor_loss": -183.09483894469247, "actor_target_entropy": -1.0, "actor_entropy": 0.46739311634548125, "alpha_loss": 0.004016182566475537, "alpha_value": 0.21416749582336408, "duration": 122.91767072677612, "step": 44125}
{"episode_reward": 194.0346995647535, "episode": 354.0, "Q1 loss": 6.324199926376343, "Q2 loss": 6.389266008377075, "Mean Target Q": 182.8232374267578, "Mean Q1": 182.82731127929688, "Mean Q2": 182.82801391601564, "critic_loss": 12.713465995788575, "batch_reward": 1.7507179346084594, "actor_loss": -183.25950868668096, "actor_target_entropy": -1.0, "actor_entropy": 0.4909260998810491, "alpha_loss": 0.010287799797351322, "alpha_value": 0.21364257127463926, "duration": 115.51275420188904, "step": 44250}
{"episode_reward": 222.73780357835997, "episode": 355.0, "Q1 loss": 6.062465944290161, "Q2 loss": 6.060677085876465, "Mean Target Q": 183.01580810546875, "Mean Q1": 183.00885290527344, "Mean Q2": 183.0083681640625, "critic_loss": 12.123142971038819, "batch_reward": 1.7531875028610229, "actor_loss": -183.3949660043868, "actor_target_entropy": -1.0, "actor_entropy": 0.46303167040385895, "alpha_loss": 0.0026941645968084535, "alpha_value": 0.2130510816512304, "duration": 131.93594026565552, "step": 44375}
{"episode_reward": 257.84928892017393, "episode": 356.0, "Q1 loss": 6.275230285644532, "Q2 loss": 6.297820304870606, "Mean Target Q": 183.13613854980468, "Mean Q1": 183.13008825683593, "Mean Q2": 183.12975109863282, "critic_loss": 12.573050605773926, "batch_reward": 1.7413035459518433, "actor_loss": -183.44448852539062, "actor_target_entropy": -1.0, "actor_entropy": 0.43528283026910597, "alpha_loss": 0.0014775163126027873, "alpha_value": 0.21288609659131694, "duration": 107.32552170753479, "step": 44500}
{"episode_reward": 171.34807689406557, "episode": 357.0, "Q1 loss": 6.403830612182618, "Q2 loss": 6.382883205413818, "Mean Target Q": 183.2906417236328, "Mean Q1": 183.29981787109375, "Mean Q2": 183.30044091796876, "critic_loss": 12.786713806152344, "batch_reward": 1.7515235414505006, "actor_loss": -183.64490157838853, "actor_target_entropy": -1.0, "actor_entropy": 0.45310791711958626, "alpha_loss": 0.001188531804401132, "alpha_value": 0.2127497371814348, "duration": 135.01906180381775, "step": 44625}
{"episode_reward": 209.49447551702193, "episode": 358.0, "Q1 loss": 6.293836751937866, "Q2 loss": 6.332348072052002, "Mean Target Q": 183.51543286132812, "Mean Q1": 183.51980993652344, "Mean Q2": 183.519033203125, "critic_loss": 12.62618482208252, "batch_reward": 1.7567995853424072, "actor_loss": -183.86802722561745, "actor_target_entropy": -1.0, "actor_entropy": 0.4584498910173293, "alpha_loss": 0.004045793850485596, "alpha_value": 0.21270111164346775, "duration": 140.34086322784424, "step": 44750}
{"episode_reward": 245.72727793756465, "episode": 359.0, "Q1 loss": 6.197543905258179, "Q2 loss": 6.144145042419433, "Mean Target Q": 183.57900634765625, "Mean Q1": 183.5692373046875, "Mean Q2": 183.5698614501953, "critic_loss": 12.341688961029053, "batch_reward": 1.7470071907043456, "actor_loss": -183.94246177067834, "actor_target_entropy": -1.0, "actor_entropy": 0.4639493033053383, "alpha_loss": 0.004488625748467351, "alpha_value": 0.2124825494120677, "duration": 138.29168248176575, "step": 44875}
{"episode_reward": 193.31843116738497, "episode": 360.0, "Q1 loss": 6.348335918426514, "Q2 loss": 6.337813999176025, "Mean Target Q": 183.67487145996094, "Mean Q1": 183.670599609375, "Mean Q2": 183.67093310546875, "critic_loss": 12.686149898529052, "batch_reward": 1.7519183921813966, "actor_loss": -184.00705866659843, "actor_target_entropy": -1.0, "actor_entropy": 0.45620284205482853, "alpha_loss": 0.0014074863190011633, "alpha_value": 0.21207680979409999, "step": 45000}
{"duration": 145.0422351360321, "step": 45000}
{"episode_reward": 204.98155064052074, "episode": 361.0, "Q1 loss": 6.243477552413941, "Q2 loss": 6.251019737243652, "Mean Target Q": 183.865908203125, "Mean Q1": 183.8716112060547, "Mean Q2": 183.87160961914063, "critic_loss": 12.49449730682373, "batch_reward": 1.753570468902588, "actor_loss": -184.28925093393477, "actor_target_entropy": -1.0, "actor_entropy": 0.4578919443819258, "alpha_loss": 0.006203927280795243, "alpha_value": 0.21163509040316436, "duration": 119.1511504650116, "step": 45125}
{"episode_reward": 257.58769864244806, "episode": 362.0, "Q1 loss": 6.450629550933838, "Q2 loss": 6.424061248779297, "Mean Target Q": 183.9712258300781, "Mean Q1": 183.962919921875, "Mean Q2": 183.96324389648439, "critic_loss": 12.8746908493042, "batch_reward": 1.7380817203521728, "actor_loss": -184.33663866596837, "actor_target_entropy": -1.0, "actor_entropy": 0.44425555679105944, "alpha_loss": 0.0033327992967960816, "alpha_value": 0.21146014467800273, "duration": 134.58552980422974, "step": 45250}
{"episode_reward": 250.296641134806, "episode": 363.0, "Q1 loss": 6.522934419631958, "Q2 loss": 6.501906755447387, "Mean Target Q": 184.03376123046874, "Mean Q1": 184.02994470214844, "Mean Q2": 184.03008459472656, "critic_loss": 13.024841194152833, "batch_reward": 1.7470408506393433, "actor_loss": -184.3776170034257, "actor_target_entropy": -1.0, "actor_entropy": 0.4567605777392312, "alpha_loss": 0.001842717466402858, "alpha_value": 0.2112327446598904, "duration": 141.6638855934143, "step": 45375}
{"episode_reward": 228.8685102130142, "episode": 364.0, "Q1 loss": 6.528337045669556, "Q2 loss": 6.5530629692077635, "Mean Target Q": 184.28837548828125, "Mean Q1": 184.2875537109375, "Mean Q2": 184.2871729736328, "critic_loss": 13.081400066375732, "batch_reward": 1.7571334466934203, "actor_loss": -184.69642639160156, "actor_target_entropy": -1.0, "actor_entropy": 0.4414622019375524, "alpha_loss": 0.0019812275479066995, "alpha_value": 0.21108452664780333, "duration": 130.85307598114014, "step": 45500}
{"episode_reward": 259.1948300027425, "episode": 365.0, "Q1 loss": 6.466150484085083, "Q2 loss": 6.451877019882202, "Mean Target Q": 184.42133044433595, "Mean Q1": 184.4258270263672, "Mean Q2": 184.42632116699218, "critic_loss": 12.918027503967284, "batch_reward": 1.7657316827774048, "actor_loss": -184.88715568421378, "actor_target_entropy": -1.0, "actor_entropy": 0.49214164699826923, "alpha_loss": 0.008287918763161296, "alpha_value": 0.21076639308188694, "duration": 124.58705568313599, "step": 45625}
{"episode_reward": 241.84291399251617, "episode": 366.0, "Q1 loss": 6.437616680145264, "Q2 loss": 6.468127563476562, "Mean Target Q": 184.57223742675782, "Mean Q1": 184.57247302246094, "Mean Q2": 184.5721541748047, "critic_loss": 12.905744266510009, "batch_reward": 1.7512040510177613, "actor_loss": -184.91800985028667, "actor_target_entropy": -1.0, "actor_entropy": 0.47885950390369664, "alpha_loss": 0.002968149387367791, "alpha_value": 0.21024175057112482, "duration": 105.627028465271, "step": 45750}
{"episode_reward": 223.0239126120181, "episode": 367.0, "Q1 loss": 6.144662975311279, "Q2 loss": 6.156087488174438, "Mean Target Q": 184.69739208984376, "Mean Q1": 184.69059301757812, "Mean Q2": 184.6899305419922, "critic_loss": 12.300750370025634, "batch_reward": 1.759406129837036, "actor_loss": -185.0963825044178, "actor_target_entropy": -1.0, "actor_entropy": 0.4366297371803768, "alpha_loss": 0.0028467085378776702, "alpha_value": 0.21009228064741842, "duration": 130.3637182712555, "step": 45875}
{"episode_reward": 226.72068203997065, "episode": 368.0, "Q1 loss": 6.396626342773438, "Q2 loss": 6.3943689384460445, "Mean Target Q": 184.76331103515625, "Mean Q1": 184.7592645263672, "Mean Q2": 184.75965100097656, "critic_loss": 12.790995353698731, "batch_reward": 1.7450605926513671, "actor_loss": -185.14367405060798, "actor_target_entropy": -1.0, "actor_entropy": 0.4552029491432251, "alpha_loss": 0.0017858292389240477, "alpha_value": 0.20984566839117055, "duration": 124.24893164634705, "step": 46000}
{"episode_reward": 282.9382207893491, "episode": 369.0, "Q1 loss": 6.279839424133301, "Q2 loss": 6.2491215934753415, "Mean Target Q": 184.91538146972655, "Mean Q1": 184.91562060546875, "Mean Q2": 184.9155881347656, "critic_loss": 12.528961044311524, "batch_reward": 1.756379358291626, "actor_loss": -185.29483831496466, "actor_target_entropy": -1.0, "actor_entropy": 0.4696232123034341, "alpha_loss": 0.0015888416747902594, "alpha_value": 0.20970476206752536, "duration": 112.49607110023499, "step": 46125}
{"episode_reward": 281.97965162801063, "episode": 370.0, "Q1 loss": 6.3583771572113035, "Q2 loss": 6.3033171520233156, "Mean Target Q": 185.1202216796875, "Mean Q1": 185.12289721679687, "Mean Q2": 185.12350329589844, "critic_loss": 12.661694358825683, "batch_reward": 1.7556849451065064, "actor_loss": -185.43860823108304, "actor_target_entropy": -1.0, "actor_entropy": 0.4246541896174031, "alpha_loss": 0.0014149855987559403, "alpha_value": 0.20974000518388566, "duration": 148.78228282928467, "step": 46250}
{"episode_reward": 260.5196324226037, "episode": 371.0, "Q1 loss": 6.197289375305176, "Q2 loss": 6.204182712554932, "Mean Target Q": 185.2247950439453, "Mean Q1": 185.22297290039063, "Mean Q2": 185.22228332519532, "critic_loss": 12.40147211074829, "batch_reward": 1.7639319677352905, "actor_loss": -185.57915387834822, "actor_target_entropy": -1.0, "actor_entropy": 0.4588386719188993, "alpha_loss": -0.004563247818233711, "alpha_value": 0.20980452901243435, "duration": 134.3787546157837, "step": 46375}
{"episode_reward": 197.8032955135562, "episode": 372.0, "Q1 loss": 6.482228229522705, "Q2 loss": 6.499844263076782, "Mean Target Q": 185.36709313964843, "Mean Q1": 185.36761962890625, "Mean Q2": 185.36856921386718, "critic_loss": 12.982072463989258, "batch_reward": 1.7634430656433104, "actor_loss": -185.79715482650263, "actor_target_entropy": -1.0, "actor_entropy": 0.4408966350939966, "alpha_loss": 0.0026927634025923908, "alpha_value": 0.20977555523962235, "duration": 140.57713198661804, "step": 46500}
{"episode_reward": 314.6853891740476, "episode": 373.0, "Q1 loss": 6.614866613388061, "Q2 loss": 6.573729871749878, "Mean Target Q": 185.5398770751953, "Mean Q1": 185.53132482910155, "Mean Q2": 185.5308739013672, "critic_loss": 13.188596565246582, "batch_reward": 1.7675238695144653, "actor_loss": -185.9496786934989, "actor_target_entropy": -1.0, "actor_entropy": 0.4480935978511023, "alpha_loss": -0.002470482787531283, "alpha_value": 0.20991747485797962, "duration": 141.21162247657776, "step": 46625}
{"episode_reward": 221.55119975859384, "episode": 374.0, "Q1 loss": 6.5255493068695065, "Q2 loss": 6.523640205383301, "Mean Target Q": 185.60187377929688, "Mean Q1": 185.59800512695313, "Mean Q2": 185.5978975830078, "critic_loss": 13.049189498901367, "batch_reward": 1.7598539505004882, "actor_loss": -186.04664439539755, "actor_target_entropy": -1.0, "actor_entropy": 0.4626436262361465, "alpha_loss": 0.002747991332604039, "alpha_value": 0.20978348309151362, "duration": 138.28449392318726, "step": 46750}
{"episode_reward": 226.5176714730311, "episode": 375.0, "Q1 loss": 6.337068525314331, "Q2 loss": 6.338783821105957, "Mean Target Q": 185.81968249511718, "Mean Q1": 185.82134729003906, "Mean Q2": 185.82134741210936, "critic_loss": 12.675852333068848, "batch_reward": 1.7521506414413452, "actor_loss": -186.18774244520398, "actor_target_entropy": -1.0, "actor_entropy": 0.45461010838311816, "alpha_loss": 0.0011700243090412446, "alpha_value": 0.20966916748602865, "duration": 119.2912368774414, "step": 46875}
{"episode_reward": 252.95950263800492, "episode": 376.0, "Q1 loss": 6.356937072753906, "Q2 loss": 6.338184371948242, "Mean Target Q": 185.8914796142578, "Mean Q1": 185.88901818847657, "Mean Q2": 185.88857788085937, "critic_loss": 12.695121425628662, "batch_reward": 1.7497735319137573, "actor_loss": -186.30720716907132, "actor_target_entropy": -1.0, "actor_entropy": 0.4648742247973719, "alpha_loss": 0.0015641024933316775, "alpha_value": 0.20961283958018545, "duration": 129.47264981269836, "step": 47000}
{"episode_reward": 213.74991859125612, "episode": 377.0, "Q1 loss": 6.172960334777832, "Q2 loss": 6.128661460876465, "Mean Target Q": 186.04576831054686, "Mean Q1": 186.04903491210936, "Mean Q2": 186.04934143066407, "critic_loss": 12.301621753692627, "batch_reward": 1.7643986301422119, "actor_loss": -186.3825986347501, "actor_target_entropy": -1.0, "actor_entropy": 0.44141326206071035, "alpha_loss": 0.0014182420240508185, "alpha_value": 0.2095608051652013, "duration": 112.46065163612366, "step": 47125}
{"episode_reward": 188.48150755581085, "episode": 378.0, "Q1 loss": 6.2717194042205815, "Q2 loss": 6.2847479000091555, "Mean Target Q": 186.13484838867188, "Mean Q1": 186.12834460449218, "Mean Q2": 186.12849096679687, "critic_loss": 12.556467319488526, "batch_reward": 1.763551501274109, "actor_loss": -186.53770840552545, "actor_target_entropy": -1.0, "actor_entropy": 0.4755662198989622, "alpha_loss": -0.0030710942397314694, "alpha_value": 0.2095008318015942, "duration": 132.5470712184906, "step": 47250}
{"episode_reward": 357.24327030633447, "episode": 379.0, "Q1 loss": 6.789971282958985, "Q2 loss": 6.764458469390869, "Mean Target Q": 186.3541787109375, "Mean Q1": 186.35460327148436, "Mean Q2": 186.3558905029297, "critic_loss": 13.554429740905762, "batch_reward": 1.7705971870422363, "actor_loss": -186.77095298161584, "actor_target_entropy": -1.0, "actor_entropy": 0.44770654799446225, "alpha_loss": -0.005199328421555933, "alpha_value": 0.20992448437751363, "duration": 132.37783193588257, "step": 47375}
{"episode_reward": 255.98421579404928, "episode": 380.0, "Q1 loss": 6.472534229278565, "Q2 loss": 6.498090675354004, "Mean Target Q": 186.37213671875, "Mean Q1": 186.3689949951172, "Mean Q2": 186.36800708007812, "critic_loss": 12.970624870300293, "batch_reward": 1.7672188901901245, "actor_loss": -186.75288711055632, "actor_target_entropy": -1.0, "actor_entropy": 0.44491978566492757, "alpha_loss": 0.0028775578116877905, "alpha_value": 0.2100231541270505, "duration": 118.58417224884033, "step": 47500}
{"episode_reward": 273.0335649557321, "episode": 381.0, "Q1 loss": 6.818765151977539, "Q2 loss": 6.854944669723511, "Mean Target Q": 186.44424938964843, "Mean Q1": 186.44390563964845, "Mean Q2": 186.44367736816406, "critic_loss": 13.673709854125976, "batch_reward": 1.7647996845245362, "actor_loss": -186.80774385966953, "actor_target_entropy": -1.0, "actor_entropy": 0.4758998817867703, "alpha_loss": 0.0005737875166925646, "alpha_value": 0.20986503584662242, "duration": 151.15228462219238, "step": 47625}
{"episode_reward": 236.843589511688, "episode": 382.0, "Q1 loss": 6.780942043304443, "Q2 loss": 6.804984188079834, "Mean Target Q": 186.58132385253907, "Mean Q1": 186.58054150390626, "Mean Q2": 186.57965734863282, "critic_loss": 13.585926216125488, "batch_reward": 1.7833193702697754, "actor_loss": -186.90726323281564, "actor_target_entropy": -1.0, "actor_entropy": 0.44929128068108715, "alpha_loss": 0.0032721557316460438, "alpha_value": 0.20975910284077243, "duration": 139.31502270698547, "step": 47750}
{"episode_reward": 264.76721972837515, "episode": 383.0, "Q1 loss": 6.544170972824097, "Q2 loss": 6.512027580261231, "Mean Target Q": 186.65773583984375, "Mean Q1": 186.65782275390626, "Mean Q2": 186.6588371582031, "critic_loss": 13.056198554992676, "batch_reward": 1.758895962715149, "actor_loss": -186.95957970997645, "actor_target_entropy": -1.0, "actor_entropy": 0.46618360091769506, "alpha_loss": -0.0005980393339303278, "alpha_value": 0.20957980397075107, "duration": 129.08643126487732, "step": 47875}
{"episode_reward": 284.65205255402316, "episode": 384.0, "Q1 loss": 6.5024255275726315, "Q2 loss": 6.530225086212158, "Mean Target Q": 186.90677160644532, "Mean Q1": 186.9050955810547, "Mean Q2": 186.9043018798828, "critic_loss": 13.032650550842286, "batch_reward": 1.7777800722122192, "actor_loss": -187.2436540665165, "actor_target_entropy": -1.0, "actor_entropy": 0.45779420771906454, "alpha_loss": -0.0033464749858173872, "alpha_value": 0.20969784998276306, "duration": 112.5280191898346, "step": 48000}
{"episode_reward": 218.1256304367108, "episode": 385.0, "Q1 loss": 6.542048648834228, "Q2 loss": 6.534564884185791, "Mean Target Q": 187.05503845214844, "Mean Q1": 187.05152819824218, "Mean Q2": 187.05115966796876, "critic_loss": 13.076613529205321, "batch_reward": 1.7582504091262818, "actor_loss": -187.45154559423054, "actor_target_entropy": -1.0, "actor_entropy": 0.4505716538618481, "alpha_loss": 0.004418896450217636, "alpha_value": 0.2098105560836309, "duration": 127.66781735420227, "step": 48125}
{"episode_reward": 261.5467762541009, "episode": 386.0, "Q1 loss": 6.371576507568359, "Q2 loss": 6.366270845413208, "Mean Target Q": 187.09893872070313, "Mean Q1": 187.10236804199218, "Mean Q2": 187.10321960449218, "critic_loss": 12.737847351074219, "batch_reward": 1.7766421327590942, "actor_loss": -187.4336412491337, "actor_target_entropy": -1.0, "actor_entropy": 0.44128919464926564, "alpha_loss": -0.006919712083594453, "alpha_value": 0.20968862103176097, "duration": 121.21409940719604, "step": 48250}
{"episode_reward": 314.3484259184018, "episode": 387.0, "Q1 loss": 6.6503551502227785, "Q2 loss": 6.626853298187256, "Mean Target Q": 187.31715881347657, "Mean Q1": 187.3139539794922, "Mean Q2": 187.3131962890625, "critic_loss": 13.277208419799805, "batch_reward": 1.776841194152832, "actor_loss": -187.64721049959698, "actor_target_entropy": -1.0, "actor_entropy": 0.44609848752854364, "alpha_loss": 0.00319255061358923, "alpha_value": 0.20992072212874177, "duration": 123.2965362071991, "step": 48375}
{"episode_reward": 201.5187203462561, "episode": 388.0, "Q1 loss": 6.376598873138428, "Q2 loss": 6.371908420562744, "Mean Target Q": 187.37015344238282, "Mean Q1": 187.36618127441406, "Mean Q2": 187.36611926269532, "critic_loss": 12.748507286071778, "batch_reward": 1.7755772762298585, "actor_loss": -187.80169234737272, "actor_target_entropy": -1.0, "actor_entropy": 0.42746454044695825, "alpha_loss": -0.0008712670795859829, "alpha_value": 0.20974746452220996, "duration": 135.56818318367004, "step": 48500}
{"episode_reward": 232.69512251332972, "episode": 389.0, "Q1 loss": 6.64528744506836, "Q2 loss": 6.598669364929199, "Mean Target Q": 187.5566807861328, "Mean Q1": 187.55633740234376, "Mean Q2": 187.55624633789063, "critic_loss": 13.243956832885742, "batch_reward": 1.7779710302352905, "actor_loss": -187.8144037155878, "actor_target_entropy": -1.0, "actor_entropy": 0.44925459746330504, "alpha_loss": 0.0027703892546779817, "alpha_value": 0.20974731272896607, "duration": 137.6104657649994, "step": 48625}
{"episode_reward": 290.1936570006872, "episode": 390.0, "Q1 loss": 6.516989988327026, "Q2 loss": 6.458787593841553, "Mean Target Q": 187.56220935058593, "Mean Q1": 187.56062292480468, "Mean Q2": 187.56234167480468, "critic_loss": 12.97577758026123, "batch_reward": 1.7740139722824098, "actor_loss": -187.93172479444934, "actor_target_entropy": -1.0, "actor_entropy": 0.44526068337502017, "alpha_loss": -0.002822075302021638, "alpha_value": 0.20981518241797056, "duration": 131.2797863483429, "step": 48750}
{"episode_reward": 178.93658721144064, "episode": 391.0, "Q1 loss": 6.535248226165772, "Q2 loss": 6.527628623962403, "Mean Target Q": 187.82841662597656, "Mean Q1": 187.8269765625, "Mean Q2": 187.82647290039063, "critic_loss": 13.062876899719239, "batch_reward": 1.7692521057128907, "actor_loss": -188.17730930873327, "actor_target_entropy": -1.0, "actor_entropy": 0.44102541889463154, "alpha_loss": -0.0005782486220437383, "alpha_value": 0.20990447262076822, "duration": 139.07445168495178, "step": 48875}
{"episode_reward": 227.2787807874486, "episode": 392.0, "Q1 loss": 6.298453077316284, "Q2 loss": 6.284755853652954, "Mean Target Q": 187.8517274169922, "Mean Q1": 187.84603662109376, "Mean Q2": 187.845412109375, "critic_loss": 12.583208797454834, "batch_reward": 1.7654026403427123, "actor_loss": -188.16218025453628, "actor_target_entropy": -1.0, "actor_entropy": 0.4303168591953093, "alpha_loss": 0.00437410879361954, "alpha_value": 0.20970572541948307, "duration": 131.74835419654846, "step": 49000}
{"episode_reward": 218.9512581487347, "episode": 393.0, "Q1 loss": 6.502320596694946, "Q2 loss": 6.569468318939209, "Mean Target Q": 188.01371118164062, "Mean Q1": 188.011498046875, "Mean Q2": 188.01099304199218, "critic_loss": 13.071788917541504, "batch_reward": 1.7737521848678588, "actor_loss": -188.43004378061445, "actor_target_entropy": -1.0, "actor_entropy": 0.43436891171667313, "alpha_loss": -0.002111128596071568, "alpha_value": 0.20960952973179325, "duration": 153.10525178909302, "step": 49125}
{"episode_reward": 254.42289083894488, "episode": 394.0, "Q1 loss": 6.49269927406311, "Q2 loss": 6.536651842117309, "Mean Target Q": 188.11721813964843, "Mean Q1": 188.11894274902343, "Mean Q2": 188.11943811035155, "critic_loss": 13.029351135253906, "batch_reward": 1.7794788303375244, "actor_loss": -188.4596444406817, "actor_target_entropy": -1.0, "actor_entropy": 0.45620738931240573, "alpha_loss": 0.003743314892128711, "alpha_value": 0.20974668895608797, "duration": 144.52518248558044, "step": 49250}
{"episode_reward": 237.06718909032557, "episode": 395.0, "Q1 loss": 6.545569869995117, "Q2 loss": 6.532705076217652, "Mean Target Q": 188.2000233154297, "Mean Q1": 188.19963610839844, "Mean Q2": 188.1996865234375, "critic_loss": 13.078274917602538, "batch_reward": 1.772205472946167, "actor_loss": -188.6456059047154, "actor_target_entropy": -1.0, "actor_entropy": 0.43462211413988994, "alpha_loss": 0.0021415432833785577, "alpha_value": 0.209382755929246, "duration": 131.05210661888123, "step": 49375}
{"episode_reward": 293.4660391724413, "episode": 396.0, "Q1 loss": 6.665776124954224, "Q2 loss": 6.653701177597046, "Mean Target Q": 188.45418908691406, "Mean Q1": 188.45246252441407, "Mean Q2": 188.45229626464842, "critic_loss": 13.31947730255127, "batch_reward": 1.770865559577942, "actor_loss": -188.76388008363784, "actor_target_entropy": -1.0, "actor_entropy": 0.46048967444127603, "alpha_loss": 0.001814584491864568, "alpha_value": 0.20925083778161005, "duration": 138.4580945968628, "step": 49500}
{"episode_reward": 204.3863888883527, "episode": 397.0, "Q1 loss": 6.610695556640625, "Q2 loss": 6.623779052734375, "Mean Target Q": 188.55196850585938, "Mean Q1": 188.5474832763672, "Mean Q2": 188.548685546875, "critic_loss": 13.234474605560303, "batch_reward": 1.770733533859253, "actor_loss": -188.95134626116072, "actor_target_entropy": -1.0, "actor_entropy": 0.42136910037388875, "alpha_loss": 0.0003937867022902956, "alpha_value": 0.20918632882982222, "duration": 142.9511284828186, "step": 49625}
{"episode_reward": 328.54808667379547, "episode": 398.0, "Q1 loss": 6.712080821990967, "Q2 loss": 6.749573001861572, "Mean Target Q": 188.62453698730468, "Mean Q1": 188.62770776367188, "Mean Q2": 188.6275098876953, "critic_loss": 13.461653800964356, "batch_reward": 1.7648895053863525, "actor_loss": -188.88766454881238, "actor_target_entropy": -1.0, "actor_entropy": 0.42812412352331225, "alpha_loss": 0.006308779539164876, "alpha_value": 0.20893279567579393, "duration": 119.88171672821045, "step": 49750}
{"episode_reward": 203.03807251727747, "episode": 399.0, "Q1 loss": 6.514864624023438, "Q2 loss": 6.528924396514893, "Mean Target Q": 188.75554321289061, "Mean Q1": 188.75003112792967, "Mean Q2": 188.74918408203126, "critic_loss": 13.043788986206055, "batch_reward": 1.7698575410842896, "actor_loss": -189.18264867389013, "actor_target_entropy": -1.0, "actor_entropy": 0.40877707420833526, "alpha_loss": -0.0030942557265035927, "alpha_value": 0.20888569083531092, "duration": 134.85097455978394, "step": 49875}
{"episode_reward": 197.06991056202173, "episode": 400.0, "Q1 loss": 6.617905864715576, "Q2 loss": 6.606044317245483, "Mean Target Q": 188.89709411621095, "Mean Q1": 188.8963154296875, "Mean Q2": 188.8957578125, "critic_loss": 13.223950119018555, "batch_reward": 1.7675732879638673, "actor_loss": -189.317989964639, "actor_target_entropy": -1.0, "actor_entropy": 0.42884115153743374, "alpha_loss": 0.0037194342190970575, "alpha_value": 0.20877938291427736, "step": 50000}
{"duration": 159.56568956375122, "step": 50000}
{"episode_reward": 215.0439744616014, "episode": 401.0, "Q1 loss": 6.833223154067993, "Q2 loss": 6.819287750244141, "Mean Target Q": 189.0468125, "Mean Q1": 189.04726513671875, "Mean Q2": 189.04830737304687, "critic_loss": 13.652510902404785, "batch_reward": 1.7792139492034913, "actor_loss": -189.39478653196304, "actor_target_entropy": -1.0, "actor_entropy": 0.44281029275485445, "alpha_loss": 0.003575386268840659, "alpha_value": 0.2086234600024118, "duration": 126.36028099060059, "step": 50125}
{"episode_reward": 162.22679092915507, "episode": 402.0, "Q1 loss": 6.376658967971801, "Q2 loss": 6.386224357604981, "Mean Target Q": 189.14179858398438, "Mean Q1": 189.1375255126953, "Mean Q2": 189.1370634765625, "critic_loss": 12.762883316040039, "batch_reward": 1.7862255992889404, "actor_loss": -189.48252893263293, "actor_target_entropy": -1.0, "actor_entropy": 0.4553842482066924, "alpha_loss": 0.006662694371170214, "alpha_value": 0.20827196046606117, "duration": 134.49070525169373, "step": 50250}
{"episode_reward": 199.88419534271935, "episode": 403.0, "Q1 loss": 6.424317750930786, "Q2 loss": 6.420746826171875, "Mean Target Q": 189.16305615234376, "Mean Q1": 189.16211303710938, "Mean Q2": 189.16257543945312, "critic_loss": 12.84506457901001, "batch_reward": 1.780444842338562, "actor_loss": -189.52688816615515, "actor_target_entropy": -1.0, "actor_entropy": 0.41762890654896934, "alpha_loss": 0.0035316258232804044, "alpha_value": 0.2076517194021279, "duration": 135.52015471458435, "step": 50375}
{"episode_reward": 225.88974864221396, "episode": 404.0, "Q1 loss": 6.998818212509155, "Q2 loss": 6.963542490005493, "Mean Target Q": 189.23437048339844, "Mean Q1": 189.23380200195314, "Mean Q2": 189.233037109375, "critic_loss": 13.962360755920411, "batch_reward": 1.763608286857605, "actor_loss": -189.5751232024162, "actor_target_entropy": -1.0, "actor_entropy": 0.4304834883059225, "alpha_loss": -0.0013201102734573425, "alpha_value": 0.20766719145319712, "duration": 135.90078282356262, "step": 50500}
{"episode_reward": 238.49328849475407, "episode": 405.0, "Q1 loss": 6.6608800811767575, "Q2 loss": 6.663172573089599, "Mean Target Q": 189.36239147949217, "Mean Q1": 189.36475012207032, "Mean Q2": 189.36539465332032, "critic_loss": 13.324052619934083, "batch_reward": 1.7832177591323852, "actor_loss": -189.74885631742933, "actor_target_entropy": -1.0, "actor_entropy": 0.43724527955055237, "alpha_loss": 0.002527576509035296, "alpha_value": 0.20770841334418963, "duration": 143.24363470077515, "step": 50625}
{"episode_reward": 231.67469415731352, "episode": 406.0, "Q1 loss": 6.893024822235107, "Q2 loss": 6.850549808502198, "Mean Target Q": 189.43870629882812, "Mean Q1": 189.4341036376953, "Mean Q2": 189.43486462402345, "critic_loss": 13.743574642181397, "batch_reward": 1.756027816772461, "actor_loss": -189.7817660916236, "actor_target_entropy": -1.0, "actor_entropy": 0.4326035192897243, "alpha_loss": 0.002652417278788503, "alpha_value": 0.2074219764817822, "duration": 133.66513872146606, "step": 50750}
{"episode_reward": 251.51070472946972, "episode": 407.0, "Q1 loss": 6.666644542694092, "Q2 loss": 6.647700202941895, "Mean Target Q": 189.58335546875, "Mean Q1": 189.5797869873047, "Mean Q2": 189.5782314453125, "critic_loss": 13.314344711303711, "batch_reward": 1.772106864929199, "actor_loss": -189.96164933461992, "actor_target_entropy": -1.0, "actor_entropy": 0.4204691080819993, "alpha_loss": -2.582769633995162e-05, "alpha_value": 0.20745419199023207, "duration": 140.0284960269928, "step": 50875}
{"episode_reward": 223.95493241416568, "episode": 408.0, "Q1 loss": 6.943874691009522, "Q2 loss": 6.9333129920959475, "Mean Target Q": 189.70793286132812, "Mean Q1": 189.71129931640624, "Mean Q2": 189.71091088867186, "critic_loss": 13.877187644958497, "batch_reward": 1.775225372314453, "actor_loss": -190.08948762955205, "actor_target_entropy": -1.0, "actor_entropy": 0.43670725630175683, "alpha_loss": 0.0006558929134400621, "alpha_value": 0.20725758616173995, "duration": 153.5175974369049, "step": 51000}
{"episode_reward": 235.7090222406888, "episode": 409.0, "Q1 loss": 6.701422393798828, "Q2 loss": 6.690879871368408, "Mean Target Q": 189.83215307617186, "Mean Q1": 189.82739636230468, "Mean Q2": 189.82718005371095, "critic_loss": 13.392302307128906, "batch_reward": 1.7812156248092652, "actor_loss": -190.17071678524925, "actor_target_entropy": -1.0, "actor_entropy": 0.44012225336498684, "alpha_loss": -0.0008130164277399816, "alpha_value": 0.20737829254813256, "duration": 146.26711225509644, "step": 51125}
{"episode_reward": 229.38580743677943, "episode": 410.0, "Q1 loss": 6.8499289283752445, "Q2 loss": 6.8891396484375, "Mean Target Q": 189.9214825439453, "Mean Q1": 189.92175524902345, "Mean Q2": 189.92330004882814, "critic_loss": 13.73906859588623, "batch_reward": 1.769657790184021, "actor_loss": -190.24651508946573, "actor_target_entropy": -1.0, "actor_entropy": 0.4510858020474834, "alpha_loss": -0.004473953954725256, "alpha_value": 0.2075598568959009, "duration": 131.88684368133545, "step": 51250}
{"episode_reward": 187.1704747759705, "episode": 411.0, "Q1 loss": 7.061118160247803, "Q2 loss": 7.031012950897217, "Mean Target Q": 190.01657092285157, "Mean Q1": 190.01075915527343, "Mean Q2": 190.0104630126953, "critic_loss": 14.092131099700929, "batch_reward": 1.7807096223831176, "actor_loss": -190.34127105228484, "actor_target_entropy": -1.0, "actor_entropy": 0.4293453844766768, "alpha_loss": 0.002200310831771247, "alpha_value": 0.20761967472935133, "duration": 148.76755023002625, "step": 51375}
{"episode_reward": 172.0037251187876, "episode": 412.0, "Q1 loss": 7.1236727352142335, "Q2 loss": 7.139611354827881, "Mean Target Q": 190.0340231933594, "Mean Q1": 190.03570239257812, "Mean Q2": 190.03676000976563, "critic_loss": 14.26328411102295, "batch_reward": 1.7839346389770507, "actor_loss": -190.3901829873362, "actor_target_entropy": -1.0, "actor_entropy": 0.43897096332042446, "alpha_loss": 0.0059351094251108025, "alpha_value": 0.2073003001250049, "duration": 134.88045191764832, "step": 51500}
{"episode_reward": 229.64724496062217, "episode": 413.0, "Q1 loss": 6.954296096801758, "Q2 loss": 6.963474536895752, "Mean Target Q": 190.24812536621093, "Mean Q1": 190.24829553222656, "Mean Q2": 190.24662329101562, "critic_loss": 13.917770629882812, "batch_reward": 1.772482310295105, "actor_loss": -190.61835685608878, "actor_target_entropy": -1.0, "actor_entropy": 0.4136785954710037, "alpha_loss": -0.005020017565656749, "alpha_value": 0.20725857967993563, "duration": 143.90552377700806, "step": 51625}
{"episode_reward": 323.98036481812767, "episode": 414.0, "Q1 loss": 6.571808116912842, "Q2 loss": 6.587116497039795, "Mean Target Q": 190.20741345214844, "Mean Q1": 190.2038651123047, "Mean Q2": 190.20373449707031, "critic_loss": 13.158924591064453, "batch_reward": 1.7794722890853882, "actor_loss": -190.54849341607863, "actor_target_entropy": -1.0, "actor_entropy": 0.42751752320797215, "alpha_loss": -0.00108253569229536, "alpha_value": 0.20770779710327075, "duration": 152.63707494735718, "step": 51750}
{"episode_reward": 232.81512167173244, "episode": 415.0, "Q1 loss": 6.88747583770752, "Q2 loss": 6.843486034393311, "Mean Target Q": 190.36697680664062, "Mean Q1": 190.36592016601563, "Mean Q2": 190.36719372558593, "critic_loss": 13.73096183013916, "batch_reward": 1.775447211265564, "actor_loss": -190.7683841765873, "actor_target_entropy": -1.0, "actor_entropy": 0.4443937317719535, "alpha_loss": -0.0014687205132629191, "alpha_value": 0.2076390786447438, "duration": 145.78646326065063, "step": 51875}
{"episode_reward": 267.16005010012725, "episode": 416.0, "Q1 loss": 6.607692680358887, "Q2 loss": 6.569099618911743, "Mean Target Q": 190.49319921875, "Mean Q1": 190.48996276855468, "Mean Q2": 190.4888172607422, "critic_loss": 13.17679224395752, "batch_reward": 1.7650598306655885, "actor_loss": -190.83414754559917, "actor_target_entropy": -1.0, "actor_entropy": 0.4286991684667526, "alpha_loss": -0.00046871251223849195, "alpha_value": 0.20773203225942855, "duration": 142.88920736312866, "step": 52000}
{"episode_reward": 378.9353021325028, "episode": 417.0, "Q1 loss": 6.890176410675049, "Q2 loss": 6.843792778015136, "Mean Target Q": 190.6019482421875, "Mean Q1": 190.5990811767578, "Mean Q2": 190.59955712890624, "critic_loss": 13.733969207763671, "batch_reward": 1.7827551536560058, "actor_loss": -190.95306832449776, "actor_target_entropy": -1.0, "actor_entropy": 0.4313558500910562, "alpha_loss": -0.001571300443232296, "alpha_value": 0.20774962388964924, "duration": 135.93162178993225, "step": 52125}
{"episode_reward": 234.07984911015225, "episode": 418.0, "Q1 loss": 6.4397965354919435, "Q2 loss": 6.419888509750367, "Mean Target Q": 190.7683475341797, "Mean Q1": 190.7705107421875, "Mean Q2": 190.77004211425782, "critic_loss": 12.859685050964355, "batch_reward": 1.7803833150863648, "actor_loss": -191.08316483036165, "actor_target_entropy": -1.0, "actor_entropy": 0.43668973205551026, "alpha_loss": -8.846910655378334e-05, "alpha_value": 0.20788539753382473, "duration": 138.6175878047943, "step": 52250}
{"episode_reward": 218.2323327080647, "episode": 419.0, "Q1 loss": 6.785393074035644, "Q2 loss": 6.833560401916504, "Mean Target Q": 190.80503698730467, "Mean Q1": 190.80358227539062, "Mean Q2": 190.80466723632813, "critic_loss": 13.618953483581542, "batch_reward": 1.787903374671936, "actor_loss": -191.14566427563864, "actor_target_entropy": -1.0, "actor_entropy": 0.4131605487967294, "alpha_loss": 0.005699870908366782, "alpha_value": 0.20754852272437624, "duration": 144.70301342010498, "step": 52375}
{"episode_reward": 291.8611313667029, "episode": 420.0, "Q1 loss": 6.642796733856201, "Q2 loss": 6.659726383209229, "Mean Target Q": 190.89644702148436, "Mean Q1": 190.8858614501953, "Mean Q2": 190.8851287841797, "critic_loss": 13.302523124694824, "batch_reward": 1.7747252740859984, "actor_loss": -191.31817577731223, "actor_target_entropy": -1.0, "actor_entropy": 0.4220308320176217, "alpha_loss": 0.005849181533595847, "alpha_value": 0.20734734603431032, "duration": 139.84315657615662, "step": 52500}
{"episode_reward": 230.13552005173398, "episode": 421.0, "Q1 loss": 6.665586135864258, "Q2 loss": 6.641373258590698, "Mean Target Q": 191.0555126953125, "Mean Q1": 191.05738037109376, "Mean Q2": 191.057650390625, "critic_loss": 13.306959373474122, "batch_reward": 1.7825368709564209, "actor_loss": -191.41782415480841, "actor_target_entropy": -1.0, "actor_entropy": 0.43083957121485755, "alpha_loss": 0.006633496098589921, "alpha_value": 0.20660719451048906, "duration": 125.82523036003113, "step": 52625}
{"episode_reward": 217.1985769922421, "episode": 422.0, "Q1 loss": 6.768547737121582, "Q2 loss": 6.757985012054443, "Mean Target Q": 191.12495471191406, "Mean Q1": 191.12606616210937, "Mean Q2": 191.1269013671875, "critic_loss": 13.526532768249512, "batch_reward": 1.7849132328033448, "actor_loss": -191.42789040842365, "actor_target_entropy": -1.0, "actor_entropy": 0.4509543372738746, "alpha_loss": 0.0017490614967931423, "alpha_value": 0.20642988519073183, "duration": 129.60379910469055, "step": 52750}
{"episode_reward": 195.83442659751944, "episode": 423.0, "Q1 loss": 6.910639686584473, "Q2 loss": 6.873601196289062, "Mean Target Q": 191.246515625, "Mean Q1": 191.24415270996093, "Mean Q2": 191.24169946289064, "critic_loss": 13.784240886688233, "batch_reward": 1.7866269464492799, "actor_loss": -191.64392937554254, "actor_target_entropy": -1.0, "actor_entropy": 0.4158875696242802, "alpha_loss": -0.0017144268319483787, "alpha_value": 0.20637234393920878, "duration": 138.4889521598816, "step": 52875}
{"episode_reward": 167.33156019348448, "episode": 424.0, "Q1 loss": 6.595567092895508, "Q2 loss": 6.636805908203125, "Mean Target Q": 191.31370666503906, "Mean Q1": 191.3160810546875, "Mean Q2": 191.31738391113282, "critic_loss": 13.23237299346924, "batch_reward": 1.778035882949829, "actor_loss": -191.68440664968182, "actor_target_entropy": -1.0, "actor_entropy": 0.4390376907202505, "alpha_loss": 0.0037780437963984667, "alpha_value": 0.20644221591178297, "duration": 130.94952702522278, "step": 53000}
{"episode_reward": 238.4970705872763, "episode": 425.0, "Q1 loss": 6.636854290008545, "Q2 loss": 6.6490524444580075, "Mean Target Q": 191.37667639160156, "Mean Q1": 191.37287023925782, "Mean Q2": 191.37219995117186, "critic_loss": 13.28590673828125, "batch_reward": 1.7845964183807372, "actor_loss": -191.74527437724765, "actor_target_entropy": -1.0, "actor_entropy": 0.4072282640706925, "alpha_loss": 0.0027994916086927766, "alpha_value": 0.20602056093198234, "duration": 138.8917317390442, "step": 53125}
{"episode_reward": 232.6166346961291, "episode": 426.0, "Q1 loss": 6.349375448226929, "Q2 loss": 6.386462158203125, "Mean Target Q": 191.46864208984374, "Mean Q1": 191.4668956298828, "Mean Q2": 191.4675068359375, "critic_loss": 12.735837604522706, "batch_reward": 1.782802477836609, "actor_loss": -191.9203380461662, "actor_target_entropy": -1.0, "actor_entropy": 0.4308921041027192, "alpha_loss": 0.0023541740562406277, "alpha_value": 0.2059808022459297, "duration": 126.08308124542236, "step": 53250}
{"episode_reward": 300.4291400569087, "episode": 427.0, "Q1 loss": 6.81659754562378, "Q2 loss": 6.860977336883545, "Mean Target Q": 191.5141739501953, "Mean Q1": 191.51069677734375, "Mean Q2": 191.51081213378907, "critic_loss": 13.677574848175048, "batch_reward": 1.786585238456726, "actor_loss": -191.90985034760973, "actor_target_entropy": -1.0, "actor_entropy": 0.412451876534356, "alpha_loss": -0.002214950258060107, "alpha_value": 0.20602959968292178, "duration": 123.25220370292664, "step": 53375}
{"episode_reward": 244.5000784191704, "episode": 428.0, "Q1 loss": 6.656885643005371, "Q2 loss": 6.664133619308472, "Mean Target Q": 191.64803198242188, "Mean Q1": 191.65202709960937, "Mean Q2": 191.65187536621093, "critic_loss": 13.321019271850586, "batch_reward": 1.775377456665039, "actor_loss": -192.04450151997227, "actor_target_entropy": -1.0, "actor_entropy": 0.4142493471022575, "alpha_loss": 0.003384173141732331, "alpha_value": 0.20605515852188672, "duration": 139.35529017448425, "step": 53500}
{"episode_reward": 213.20429517009626, "episode": 429.0, "Q1 loss": 6.421078552246094, "Q2 loss": 6.4097274284362795, "Mean Target Q": 191.80835656738282, "Mean Q1": 191.80279467773437, "Mean Q2": 191.80180505371095, "critic_loss": 12.83080602645874, "batch_reward": 1.7848258543014526, "actor_loss": -192.18027532668341, "actor_target_entropy": -1.0, "actor_entropy": 0.4047912009178646, "alpha_loss": -0.0003556195805440583, "alpha_value": 0.20588860657082644, "duration": 134.73563694953918, "step": 53625}
{"episode_reward": 297.19133232437486, "episode": 430.0, "Q1 loss": 6.7352228927612305, "Q2 loss": 6.7679244270324705, "Mean Target Q": 191.8666063232422, "Mean Q1": 191.86694519042967, "Mean Q2": 191.86785876464845, "critic_loss": 13.50314736175537, "batch_reward": 1.7815410814285277, "actor_loss": -192.25675250637917, "actor_target_entropy": -1.0, "actor_entropy": 0.4243207213378722, "alpha_loss": -0.0004096612007537436, "alpha_value": 0.2059785519974646, "duration": 124.02198839187622, "step": 53750}
{"episode_reward": 198.20665639280546, "episode": 431.0, "Q1 loss": 6.640884176254272, "Q2 loss": 6.6669466686248775, "Mean Target Q": 192.04218212890626, "Mean Q1": 192.04277209472656, "Mean Q2": 192.04330212402343, "critic_loss": 13.307830856323243, "batch_reward": 1.7808192491531372, "actor_loss": -192.41564239017546, "actor_target_entropy": -1.0, "actor_entropy": 0.4168582856655121, "alpha_loss": -0.000416653094044517, "alpha_value": 0.2059381728285307, "duration": 143.9092082977295, "step": 53875}
{"episode_reward": 254.62709054871058, "episode": 432.0, "Q1 loss": 6.827482395172119, "Q2 loss": 6.7274331283569335, "Mean Target Q": 192.04440026855468, "Mean Q1": 192.03764318847655, "Mean Q2": 192.03792529296874, "critic_loss": 13.554915519714356, "batch_reward": 1.787155029296875, "actor_loss": -192.398927750126, "actor_target_entropy": -1.0, "actor_entropy": 0.4026908220783357, "alpha_loss": -0.0022725605278185778, "alpha_value": 0.2059308885876882, "duration": 143.6926028728485, "step": 54000}
{"episode_reward": 218.04072500670176, "episode": 433.0, "Q1 loss": 6.811174680709839, "Q2 loss": 6.815243347167969, "Mean Target Q": 192.21075573730468, "Mean Q1": 192.21393237304687, "Mean Q2": 192.21463708496094, "critic_loss": 13.626418029785157, "batch_reward": 1.7899430894851684, "actor_loss": -192.51881844656808, "actor_target_entropy": -1.0, "actor_entropy": 0.43036988377571106, "alpha_loss": -0.0026460352671583967, "alpha_value": 0.20601313466523927, "duration": 137.40651631355286, "step": 54125}
{"episode_reward": 247.70734840709167, "episode": 434.0, "Q1 loss": 6.945392654418946, "Q2 loss": 6.973360218048096, "Mean Target Q": 192.35845288085937, "Mean Q1": 192.35294189453126, "Mean Q2": 192.352595703125, "critic_loss": 13.91875291442871, "batch_reward": 1.7906354885101319, "actor_loss": -192.72931671142578, "actor_target_entropy": -1.0, "actor_entropy": 0.450330461225202, "alpha_loss": 0.0007201712860185052, "alpha_value": 0.20616645049729349, "duration": 139.2312183380127, "step": 54250}
{"episode_reward": 209.71443498011735, "episode": 435.0, "Q1 loss": 6.693879962921143, "Q2 loss": 6.687279109954834, "Mean Target Q": 192.37031408691405, "Mean Q1": 192.36939428710937, "Mean Q2": 192.36912390136717, "critic_loss": 13.381159076690674, "batch_reward": 1.7796796894073486, "actor_loss": -192.73922220865884, "actor_target_entropy": -1.0, "actor_entropy": 0.41370456228180535, "alpha_loss": -0.003022756540246071, "alpha_value": 0.206321340972266, "duration": 134.21313667297363, "step": 54375}
{"episode_reward": 243.9233301272375, "episode": 436.0, "Q1 loss": 6.558201789855957, "Q2 loss": 6.5761048698425295, "Mean Target Q": 192.46008544921875, "Mean Q1": 192.4614041748047, "Mean Q2": 192.46066149902344, "critic_loss": 13.134306648254395, "batch_reward": 1.7777751369476318, "actor_loss": -192.89234161376953, "actor_target_entropy": -1.0, "actor_entropy": 0.4167962603030666, "alpha_loss": 0.0005530027161923147, "alpha_value": 0.20631651897039935, "duration": 149.81072854995728, "step": 54500}
{"episode_reward": 314.7240481962982, "episode": 437.0, "Q1 loss": 6.720672969818115, "Q2 loss": 6.697300956726075, "Mean Target Q": 192.62481970214844, "Mean Q1": 192.62330993652344, "Mean Q2": 192.62528369140625, "critic_loss": 13.417973960876465, "batch_reward": 1.7801409292221069, "actor_loss": -192.99911402142237, "actor_target_entropy": -1.0, "actor_entropy": 0.4167342644835275, "alpha_loss": 0.0030752324262663484, "alpha_value": 0.2061460259836589, "duration": 138.6504065990448, "step": 54625}
{"episode_reward": 224.73175913373416, "episode": 438.0, "Q1 loss": 6.79259302520752, "Q2 loss": 6.788970031738281, "Mean Target Q": 192.7197265625, "Mean Q1": 192.71886096191406, "Mean Q2": 192.71723767089844, "critic_loss": 13.581563018798828, "batch_reward": 1.7789996404647828, "actor_loss": -193.05518537952054, "actor_target_entropy": -1.0, "actor_entropy": 0.4134416344665712, "alpha_loss": -0.00026088007049815306, "alpha_value": 0.20613080369374337, "duration": 144.64131832122803, "step": 54750}
{"episode_reward": 249.7107955042425, "episode": 439.0, "Q1 loss": 6.686124382019043, "Q2 loss": 6.673785469055176, "Mean Target Q": 192.75380712890626, "Mean Q1": 192.75119189453125, "Mean Q2": 192.75007238769533, "critic_loss": 13.359909832000733, "batch_reward": 1.7805923976898193, "actor_loss": -193.22545514787947, "actor_target_entropy": -1.0, "actor_entropy": 0.41618364954751635, "alpha_loss": 0.0019283869658552465, "alpha_value": 0.20604314349891303, "duration": 137.81280732154846, "step": 54875}
{"episode_reward": 170.1651132299093, "episode": 440.0, "Q1 loss": 6.679837669372558, "Q2 loss": 6.658882263183593, "Mean Target Q": 192.81794299316405, "Mean Q1": 192.81945446777343, "Mean Q2": 192.81962329101563, "critic_loss": 13.338719894409179, "batch_reward": 1.7818092260360718, "actor_loss": -193.14695567469442, "actor_target_entropy": -1.0, "actor_entropy": 0.40387436795619225, "alpha_loss": -0.0018149343799919852, "alpha_value": 0.20602386048946428, "step": 55000}
{"duration": 145.1982913017273, "step": 55000}
{"episode_reward": 281.0564832699608, "episode": 441.0, "Q1 loss": 6.637336368560791, "Q2 loss": 6.629517612457275, "Mean Target Q": 192.9083272705078, "Mean Q1": 192.90422875976563, "Mean Q2": 192.90549584960937, "critic_loss": 13.266853958129882, "batch_reward": 1.78329034614563, "actor_loss": -193.20369393484933, "actor_target_entropy": -1.0, "actor_entropy": 0.4386854223788731, "alpha_loss": 0.002181928094831251, "alpha_value": 0.20616259192369032, "duration": 145.158456325531, "step": 55125}
{"episode_reward": 161.96440493137695, "episode": 442.0, "Q1 loss": 6.584068050384522, "Q2 loss": 6.664010231018066, "Mean Target Q": 193.04857592773436, "Mean Q1": 193.05332873535156, "Mean Q2": 193.05299865722657, "critic_loss": 13.248078269958496, "batch_reward": 1.7766312112808227, "actor_loss": -193.38464700022053, "actor_target_entropy": -1.0, "actor_entropy": 0.4319026422116064, "alpha_loss": -0.002392812188894999, "alpha_value": 0.20609606175798653, "duration": 136.77763438224792, "step": 55250}
{"episode_reward": 303.4493591988552, "episode": 443.0, "Q1 loss": 6.6582137489318844, "Q2 loss": 6.6676775856018065, "Mean Target Q": 193.09585668945311, "Mean Q1": 193.09488647460938, "Mean Q2": 193.0948145751953, "critic_loss": 13.325891311645508, "batch_reward": 1.7846269283294678, "actor_loss": -193.4178755018446, "actor_target_entropy": -1.0, "actor_entropy": 0.4113008550235203, "alpha_loss": -0.0005269661279661315, "alpha_value": 0.20608378420890477, "duration": 139.16328358650208, "step": 55375}
{"episode_reward": 320.0947935972198, "episode": 444.0, "Q1 loss": 6.716730533599853, "Q2 loss": 6.768410732269287, "Mean Target Q": 193.16187231445312, "Mean Q1": 193.15687084960936, "Mean Q2": 193.15642077636718, "critic_loss": 13.485141273498535, "batch_reward": 1.7852265253067017, "actor_loss": -193.5931179908014, "actor_target_entropy": -1.0, "actor_entropy": 0.40697586199929636, "alpha_loss": -0.0004185950383543968, "alpha_value": 0.2060593075778962, "duration": 131.7920434474945, "step": 55500}
{"episode_reward": 192.61507936553625, "episode": 445.0, "Q1 loss": 7.187276592254639, "Q2 loss": 7.258099212646484, "Mean Target Q": 193.27410412597655, "Mean Q1": 193.27685498046876, "Mean Q2": 193.2759677734375, "critic_loss": 14.445375785827636, "batch_reward": 1.7800614757537843, "actor_loss": -193.6324482266865, "actor_target_entropy": -1.0, "actor_entropy": 0.43767893503582667, "alpha_loss": 0.0024828410980897763, "alpha_value": 0.20605642355253903, "duration": 129.27230596542358, "step": 55625}
{"episode_reward": 257.79278057648656, "episode": 446.0, "Q1 loss": 6.881959743499756, "Q2 loss": 6.86850270652771, "Mean Target Q": 193.37916369628905, "Mean Q1": 193.37223571777344, "Mean Q2": 193.37259118652344, "critic_loss": 13.750462409973144, "batch_reward": 1.7821607217788695, "actor_loss": -193.76334996377267, "actor_target_entropy": -1.0, "actor_entropy": 0.4062877605038305, "alpha_loss": -0.0025747965330318095, "alpha_value": 0.20613224813973463, "duration": 135.18580675125122, "step": 55750}
{"episode_reward": 207.5077793491079, "episode": 447.0, "Q1 loss": 7.177959815979004, "Q2 loss": 7.1531631317138675, "Mean Target Q": 193.497583984375, "Mean Q1": 193.49500927734374, "Mean Q2": 193.49512536621094, "critic_loss": 14.331123001098632, "batch_reward": 1.7887720308303834, "actor_loss": -193.83572484576513, "actor_target_entropy": -1.0, "actor_entropy": 0.40718155815487816, "alpha_loss": -0.002760015182300574, "alpha_value": 0.20638641097522148, "duration": 131.0701003074646, "step": 55875}
{"episode_reward": 243.18944724710792, "episode": 448.0, "Q1 loss": 6.741207082748413, "Q2 loss": 6.6731986179351805, "Mean Target Q": 193.56795935058594, "Mean Q1": 193.57059497070313, "Mean Q2": 193.57042224121093, "critic_loss": 13.414405696868897, "batch_reward": 1.7859448728561402, "actor_loss": -193.9337864537393, "actor_target_entropy": -1.0, "actor_entropy": 0.4056977254729117, "alpha_loss": -0.004994591979700471, "alpha_value": 0.20665030608549953, "duration": 140.30904817581177, "step": 56000}
{"episode_reward": 234.9461983771304, "episode": 449.0, "Q1 loss": 6.868648807525635, "Q2 loss": 6.84901099395752, "Mean Target Q": 193.67914025878906, "Mean Q1": 193.67145959472657, "Mean Q2": 193.67129516601562, "critic_loss": 13.717659790039063, "batch_reward": 1.7925329179763794, "actor_loss": -194.0936800033327, "actor_target_entropy": -1.0, "actor_entropy": 0.39805609981218976, "alpha_loss": 0.0007823191653375351, "alpha_value": 0.2067704783841196, "duration": 125.52745819091797, "step": 56125}
{"episode_reward": 266.680957504161, "episode": 450.0, "Q1 loss": 6.934148468017578, "Q2 loss": 6.967577724456787, "Mean Target Q": 193.69096154785157, "Mean Q1": 193.69252014160156, "Mean Q2": 193.69281506347656, "critic_loss": 13.90172617340088, "batch_reward": 1.7808927536010741, "actor_loss": -194.07686221215033, "actor_target_entropy": -1.0, "actor_entropy": 0.4282990021090354, "alpha_loss": 0.00020215183030813932, "alpha_value": 0.20676205178309714, "duration": 115.20088148117065, "step": 56250}
{"episode_reward": 204.90506262733658, "episode": 451.0, "Q1 loss": 7.0730317726135254, "Q2 loss": 7.08278401184082, "Mean Target Q": 193.8626875, "Mean Q1": 193.86413757324217, "Mean Q2": 193.8645889892578, "critic_loss": 14.155815795898437, "batch_reward": 1.7915564670562745, "actor_loss": -194.21122426835316, "actor_target_entropy": -1.0, "actor_entropy": 0.38725861883352675, "alpha_loss": 0.0004944462506544022, "alpha_value": 0.2066390124533825, "duration": 126.49266767501831, "step": 56375}
{"episode_reward": 201.23775441058447, "episode": 452.0, "Q1 loss": 6.70228881072998, "Q2 loss": 6.699927947998047, "Mean Target Q": 193.92647424316405, "Mean Q1": 193.92197790527345, "Mean Q2": 193.9209971923828, "critic_loss": 13.402216777801513, "batch_reward": 1.7984093294143677, "actor_loss": -194.31332151351435, "actor_target_entropy": -1.0, "actor_entropy": 0.4273911887599576, "alpha_loss": 0.0023186524255922243, "alpha_value": 0.2066468509885902, "duration": 132.00593042373657, "step": 56500}
{"episode_reward": 220.4924895109883, "episode": 453.0, "Q1 loss": 6.95992512512207, "Q2 loss": 6.892422361373901, "Mean Target Q": 193.95064221191407, "Mean Q1": 193.954302734375, "Mean Q2": 193.95431420898439, "critic_loss": 13.852347457885742, "batch_reward": 1.779487741470337, "actor_loss": -194.2995813763331, "actor_target_entropy": -1.0, "actor_entropy": 0.4222221951636057, "alpha_loss": -0.0026424045356670542, "alpha_value": 0.2066656153866614, "duration": 126.71051168441772, "step": 56625}
{"episode_reward": 226.48922044645215, "episode": 454.0, "Q1 loss": 6.83600496673584, "Q2 loss": 6.847019035339356, "Mean Target Q": 194.12861401367186, "Mean Q1": 194.12341259765626, "Mean Q2": 194.12361328125, "critic_loss": 13.683024032592773, "batch_reward": 1.7914419746398926, "actor_loss": -194.5094742313508, "actor_target_entropy": -1.0, "actor_entropy": 0.37802203864820544, "alpha_loss": -0.004328561267034421, "alpha_value": 0.20675165830808265, "duration": 110.09526371955872, "step": 56750}
{"episode_reward": 310.8476501983433, "episode": 455.0, "Q1 loss": 6.86470394897461, "Q2 loss": 6.845363422393799, "Mean Target Q": 194.17755786132813, "Mean Q1": 194.1792373046875, "Mean Q2": 194.1795206298828, "critic_loss": 13.710067329406739, "batch_reward": 1.785891276359558, "actor_loss": -194.55243137904577, "actor_target_entropy": -1.0, "actor_entropy": 0.40365006620921784, "alpha_loss": -0.0006180888352294763, "alpha_value": 0.2069839466359412, "duration": 112.76152300834656, "step": 56875}
{"episode_reward": 158.43701997380558, "episode": 456.0, "Q1 loss": 7.185377689361572, "Q2 loss": 7.226315799713134, "Mean Target Q": 194.29629565429687, "Mean Q1": 194.2906767578125, "Mean Q2": 194.2920086669922, "critic_loss": 14.411693481445312, "batch_reward": 1.781319362640381, "actor_loss": -194.65682417346585, "actor_target_entropy": -1.0, "actor_entropy": 0.3816517283839564, "alpha_loss": -0.0035228136656505447, "alpha_value": 0.20704946388395343, "duration": 127.86462736129761, "step": 57000}
{"episode_reward": 276.98887028063086, "episode": 457.0, "Q1 loss": 6.721716781616211, "Q2 loss": 6.745796852111816, "Mean Target Q": 194.3504962158203, "Mean Q1": 194.35402978515626, "Mean Q2": 194.35476342773438, "critic_loss": 13.467513595581055, "batch_reward": 1.7805603351593018, "actor_loss": -194.7475111219618, "actor_target_entropy": -1.0, "actor_entropy": 0.4269051376789335, "alpha_loss": 0.002970182891225531, "alpha_value": 0.2072447964887892, "duration": 126.14099645614624, "step": 57125}
{"episode_reward": 271.9031106997096, "episode": 458.0, "Q1 loss": 6.951979640960693, "Q2 loss": 6.982563449859619, "Mean Target Q": 194.50763696289061, "Mean Q1": 194.50096813964845, "Mean Q2": 194.49969860839843, "critic_loss": 13.934543060302735, "batch_reward": 1.7961566553115844, "actor_loss": -194.91329168504285, "actor_target_entropy": -1.0, "actor_entropy": 0.426012005536787, "alpha_loss": 0.001999571739185241, "alpha_value": 0.20701862500987617, "duration": 116.65613031387329, "step": 57250}
{"episode_reward": 270.2707996162616, "episode": 459.0, "Q1 loss": 7.068861841201782, "Q2 loss": 7.0395214653015135, "Mean Target Q": 194.5290919189453, "Mean Q1": 194.52573852539064, "Mean Q2": 194.52567529296874, "critic_loss": 14.108383354187012, "batch_reward": 1.7818634090423584, "actor_loss": -194.90686689104353, "actor_target_entropy": -1.0, "actor_entropy": 0.43049297919349067, "alpha_loss": 0.005808302053501682, "alpha_value": 0.20668937675786744, "duration": 113.7938585281372, "step": 57375}
{"episode_reward": 320.589615939885, "episode": 460.0, "Q1 loss": 7.1137798881530765, "Q2 loss": 7.099412437438965, "Mean Target Q": 194.62434875488282, "Mean Q1": 194.62514184570313, "Mean Q2": 194.62524328613281, "critic_loss": 14.213192337036133, "batch_reward": 1.7821849784851074, "actor_loss": -195.0242452313823, "actor_target_entropy": -1.0, "actor_entropy": 0.37065055677967684, "alpha_loss": -0.004433579044416547, "alpha_value": 0.20667913242849772, "duration": 134.75911736488342, "step": 57500}
{"episode_reward": 249.2148072253222, "episode": 461.0, "Q1 loss": 7.140792030334473, "Q2 loss": 7.1526499938964845, "Mean Target Q": 194.80230590820312, "Mean Q1": 194.80232934570313, "Mean Q2": 194.80334594726563, "critic_loss": 14.293442104339599, "batch_reward": 1.7957656984329224, "actor_loss": -195.19790407211062, "actor_target_entropy": -1.0, "actor_entropy": 0.39220312900013393, "alpha_loss": -0.0062202279980752674, "alpha_value": 0.20702348985666882, "duration": 123.06039834022522, "step": 57625}
{"episode_reward": 221.35259464185927, "episode": 462.0, "Q1 loss": 6.751513269424438, "Q2 loss": 6.772393724441528, "Mean Target Q": 194.81351586914062, "Mean Q1": 194.8110037841797, "Mean Q2": 194.80980590820312, "critic_loss": 13.523906917572022, "batch_reward": 1.789838342666626, "actor_loss": -195.2049319359564, "actor_target_entropy": -1.0, "actor_entropy": 0.44484908638461945, "alpha_loss": -0.003907809465853197, "alpha_value": 0.20755327957838018, "duration": 133.59714937210083, "step": 57750}
{"episode_reward": 247.64790010318353, "episode": 463.0, "Q1 loss": 6.970227691650391, "Q2 loss": 6.96663151550293, "Mean Target Q": 194.95390502929686, "Mean Q1": 194.95372814941408, "Mean Q2": 194.95330090332033, "critic_loss": 13.936859260559082, "batch_reward": 1.7857342329025268, "actor_loss": -195.28807188972596, "actor_target_entropy": -1.0, "actor_entropy": 0.42665338421624804, "alpha_loss": -0.000281431143068605, "alpha_value": 0.2074697454136076, "duration": 132.10258603096008, "step": 57875}
{"episode_reward": 272.38160727092486, "episode": 464.0, "Q1 loss": 6.7197692527771, "Q2 loss": 6.738280872344971, "Mean Target Q": 194.95278540039064, "Mean Q1": 194.95546398925782, "Mean Q2": 194.95576123046874, "critic_loss": 13.45805007171631, "batch_reward": 1.7973037118911743, "actor_loss": -195.33016131001133, "actor_target_entropy": -1.0, "actor_entropy": 0.39785728627635586, "alpha_loss": -0.0030399433096810697, "alpha_value": 0.2077033062189732, "duration": 127.8467960357666, "step": 58000}
{"episode_reward": 174.27361771672932, "episode": 465.0, "Q1 loss": 6.8995855598449705, "Q2 loss": 6.893322185516357, "Mean Target Q": 195.07524938964843, "Mean Q1": 195.069984375, "Mean Q2": 195.0697742919922, "critic_loss": 13.79290773010254, "batch_reward": 1.794527024269104, "actor_loss": -195.50268191382997, "actor_target_entropy": -1.0, "actor_entropy": 0.4169916794413612, "alpha_loss": -0.0011557178970958506, "alpha_value": 0.20795700930079303, "duration": 118.92724919319153, "step": 58125}
{"episode_reward": 215.37175654034888, "episode": 466.0, "Q1 loss": 7.133757503509521, "Q2 loss": 7.115992761611938, "Mean Target Q": 195.1744219970703, "Mean Q1": 195.1673466796875, "Mean Q2": 195.1676346435547, "critic_loss": 14.249750259399415, "batch_reward": 1.7796122722625733, "actor_loss": -195.54222968316847, "actor_target_entropy": -1.0, "actor_entropy": 0.4188006169372989, "alpha_loss": 0.0013701414366463019, "alpha_value": 0.20783268915593398, "duration": 138.35368824005127, "step": 58250}
{"episode_reward": 278.76169784889777, "episode": 467.0, "Q1 loss": 6.700785205841065, "Q2 loss": 6.710228401184082, "Mean Target Q": 195.288962890625, "Mean Q1": 195.29160681152345, "Mean Q2": 195.29188500976562, "critic_loss": 13.41101360321045, "batch_reward": 1.7936039037704468, "actor_loss": -195.61460973346044, "actor_target_entropy": -1.0, "actor_entropy": 0.4016753676391783, "alpha_loss": 0.002018664309400178, "alpha_value": 0.20776485679148657, "duration": 129.77023673057556, "step": 58375}
{"episode_reward": 256.07719901813084, "episode": 468.0, "Q1 loss": 6.882271858215332, "Q2 loss": 6.925483409881592, "Mean Target Q": 195.4351689453125, "Mean Q1": 195.43264611816406, "Mean Q2": 195.4330812988281, "critic_loss": 13.807755233764649, "batch_reward": 1.78935080909729, "actor_loss": -195.69432215536796, "actor_target_entropy": -1.0, "actor_entropy": 0.42138437301881854, "alpha_loss": 0.0005340588508143781, "alpha_value": 0.20775086290766764, "duration": 112.74306106567383, "step": 58500}
{"episode_reward": 276.17563755947816, "episode": 469.0, "Q1 loss": 6.812272190093994, "Q2 loss": 6.81448970413208, "Mean Target Q": 195.41847985839843, "Mean Q1": 195.42016003417967, "Mean Q2": 195.42065612792967, "critic_loss": 13.626761810302735, "batch_reward": 1.7984771709442138, "actor_loss": -195.8320070296999, "actor_target_entropy": -1.0, "actor_entropy": 0.3803700293813433, "alpha_loss": -0.008896506620600583, "alpha_value": 0.20804061932831072, "duration": 136.4045696258545, "step": 58625}
{"episode_reward": 191.7353752218011, "episode": 470.0, "Q1 loss": 7.119151767730713, "Q2 loss": 7.102984592437744, "Mean Target Q": 195.58325122070312, "Mean Q1": 195.57973413085938, "Mean Q2": 195.57887622070314, "critic_loss": 14.22213639831543, "batch_reward": 1.8050707111358641, "actor_loss": -195.92994566886657, "actor_target_entropy": -1.0, "actor_entropy": 0.40296174393546197, "alpha_loss": -0.00354651796946963, "alpha_value": 0.20842841961548783, "duration": 139.87596130371094, "step": 58750}
{"episode_reward": 235.00524619274861, "episode": 471.0, "Q1 loss": 6.765404426574707, "Q2 loss": 6.766825607299805, "Mean Target Q": 195.64629541015626, "Mean Q1": 195.64517053222656, "Mean Q2": 195.64477172851562, "critic_loss": 13.532230018615722, "batch_reward": 1.7954337911605835, "actor_loss": -196.0140395391555, "actor_target_entropy": -1.0, "actor_entropy": 0.39289045854220317, "alpha_loss": -0.0014432558738109139, "alpha_value": 0.2086999681802184, "duration": 136.97852301597595, "step": 58875}
{"episode_reward": 260.03363054352013, "episode": 472.0, "Q1 loss": 6.835953311920166, "Q2 loss": 6.808933097839356, "Mean Target Q": 195.6910262451172, "Mean Q1": 195.69060192871095, "Mean Q2": 195.69038452148436, "critic_loss": 13.644886459350586, "batch_reward": 1.7970362300872802, "actor_loss": -196.0413092336347, "actor_target_entropy": -1.0, "actor_entropy": 0.38251167103167505, "alpha_loss": 0.00040816409032671684, "alpha_value": 0.20880128821154825, "duration": 115.42908382415771, "step": 59000}
{"episode_reward": 200.9620264163214, "episode": 473.0, "Q1 loss": 6.894927402496338, "Q2 loss": 6.943579307556153, "Mean Target Q": 195.8823850097656, "Mean Q1": 195.8787626953125, "Mean Q2": 195.87875256347655, "critic_loss": 13.838506729125976, "batch_reward": 1.7895982360839844, "actor_loss": -196.29351273794023, "actor_target_entropy": -1.0, "actor_entropy": 0.41377170312972295, "alpha_loss": -0.0021674405517322676, "alpha_value": 0.20872834795407696, "duration": 125.47272825241089, "step": 59125}
{"episode_reward": 207.25386987866267, "episode": 474.0, "Q1 loss": 7.070126426696778, "Q2 loss": 7.089949600219726, "Mean Target Q": 195.98198205566408, "Mean Q1": 195.98356506347656, "Mean Q2": 195.98280053710937, "critic_loss": 14.160076080322266, "batch_reward": 1.7912243280410767, "actor_loss": -196.40060080251385, "actor_target_entropy": -1.0, "actor_entropy": 0.3848517854367533, "alpha_loss": -0.0005148759641263994, "alpha_value": 0.20899178935805032, "duration": 143.11422896385193, "step": 59250}
{"episode_reward": 299.73891177020846, "episode": 475.0, "Q1 loss": 6.776255096435547, "Q2 loss": 6.848440410614014, "Mean Target Q": 196.0280184326172, "Mean Q1": 196.02890808105468, "Mean Q2": 196.02933728027344, "critic_loss": 13.624695503234863, "batch_reward": 1.793426544189453, "actor_loss": -196.4136216905382, "actor_target_entropy": -1.0, "actor_entropy": 0.41282717292270965, "alpha_loss": 0.0010085429974077713, "alpha_value": 0.20903023485624794, "duration": 125.09632587432861, "step": 59375}
{"episode_reward": 244.4400517208616, "episode": 476.0, "Q1 loss": 6.9467000522613525, "Q2 loss": 6.948720853805542, "Mean Target Q": 196.09866345214843, "Mean Q1": 196.09184936523437, "Mean Q2": 196.0917255859375, "critic_loss": 13.895420906066894, "batch_reward": 1.8032373266220092, "actor_loss": -196.36531583724482, "actor_target_entropy": -1.0, "actor_entropy": 0.4130790560476242, "alpha_loss": -0.0017977379067170044, "alpha_value": 0.20881316275034512, "duration": 137.50680494308472, "step": 59500}
{"episode_reward": 219.70743093453012, "episode": 477.0, "Q1 loss": 6.98506635093689, "Q2 loss": 6.988718757629394, "Mean Target Q": 196.19330212402343, "Mean Q1": 196.19387768554688, "Mean Q2": 196.19496423339845, "critic_loss": 13.97378508758545, "batch_reward": 1.7985669870376586, "actor_loss": -196.60406881665426, "actor_target_entropy": -1.0, "actor_entropy": 0.4089549056121281, "alpha_loss": 0.0008805481151544622, "alpha_value": 0.20891272727027274, "duration": 126.94086146354675, "step": 59625}
{"episode_reward": 198.55471181278037, "episode": 478.0, "Q1 loss": 6.746153564453125, "Q2 loss": 6.73803678894043, "Mean Target Q": 196.14189770507812, "Mean Q1": 196.13865075683594, "Mean Q2": 196.13885864257813, "critic_loss": 13.484190414428712, "batch_reward": 1.7980524110794067, "actor_loss": -196.5415762624433, "actor_target_entropy": -1.0, "actor_entropy": 0.4294343903180092, "alpha_loss": -0.0009365634384354757, "alpha_value": 0.20893482976638988, "duration": 108.78677654266357, "step": 59750}
{"episode_reward": 237.83203559313176, "episode": 479.0, "Q1 loss": 6.770405445098877, "Q2 loss": 6.786255168914795, "Mean Target Q": 196.41863879394532, "Mean Q1": 196.42598693847657, "Mean Q2": 196.42509533691407, "critic_loss": 13.556660583496093, "batch_reward": 1.8123991479873658, "actor_loss": -196.8067641485305, "actor_target_entropy": -1.0, "actor_entropy": 0.39621534990885904, "alpha_loss": -0.0015208238055781714, "alpha_value": 0.2090945906156923, "duration": 108.53920435905457, "step": 59875}
{"episode_reward": 213.69713107288734, "episode": 480.0, "Q1 loss": 6.855529693603516, "Q2 loss": 6.876567901611328, "Mean Target Q": 196.3534997558594, "Mean Q1": 196.34604125976563, "Mean Q2": 196.34662768554688, "critic_loss": 13.732097686767577, "batch_reward": 1.791783392906189, "actor_loss": -196.77769248716294, "actor_target_entropy": -1.0, "actor_entropy": 0.43076953772575627, "alpha_loss": 0.0014638780135541193, "alpha_value": 0.2091227383742333, "step": 60000}
{"duration": 123.97990655899048, "step": 60000}
{"episode_reward": 200.89438912834072, "episode": 481.0, "Q1 loss": 7.113439239501953, "Q2 loss": 7.141055721282959, "Mean Target Q": 196.39843041992188, "Mean Q1": 196.39629162597657, "Mean Q2": 196.39528845214843, "critic_loss": 14.254495018005372, "batch_reward": 1.7845969591140747, "actor_loss": -196.82908509269592, "actor_target_entropy": -1.0, "actor_entropy": 0.38355480205445064, "alpha_loss": -0.00023450149548432184, "alpha_value": 0.20890407564204663, "duration": 123.70061206817627, "step": 60125}
{"episode_reward": 207.05485047185988, "episode": 482.0, "Q1 loss": 7.104021663665772, "Q2 loss": 7.072297100067138, "Mean Target Q": 196.5764404296875, "Mean Q1": 196.5757440185547, "Mean Q2": 196.57659057617187, "critic_loss": 14.176318794250488, "batch_reward": 1.7899671096801757, "actor_loss": -196.90956509497857, "actor_target_entropy": -1.0, "actor_entropy": 0.40813550112708924, "alpha_loss": -8.073650796206729e-05, "alpha_value": 0.20904235795884746, "duration": 98.70317816734314, "step": 60250}
{"episode_reward": 323.67206897053046, "episode": 483.0, "Q1 loss": 6.992612442016601, "Q2 loss": 7.039472721099854, "Mean Target Q": 196.6112752685547, "Mean Q1": 196.60873217773437, "Mean Q2": 196.60923315429687, "critic_loss": 14.032085189819336, "batch_reward": 1.7954425239562988, "actor_loss": -196.9448048425099, "actor_target_entropy": -1.0, "actor_entropy": 0.37697160575124955, "alpha_loss": 0.00010552920681971406, "alpha_value": 0.20898310873073617, "duration": 100.33792471885681, "step": 60375}
{"episode_reward": 237.64699020582245, "episode": 484.0, "Q1 loss": 6.7740403785705565, "Q2 loss": 6.790650325775147, "Mean Target Q": 196.7500577392578, "Mean Q1": 196.74886645507812, "Mean Q2": 196.7478270263672, "critic_loss": 13.564690700531006, "batch_reward": 1.7914370698928832, "actor_loss": -197.1115488852224, "actor_target_entropy": -1.0, "actor_entropy": 0.411568007642223, "alpha_loss": 0.0014529945441491663, "alpha_value": 0.2089357315890303, "duration": 94.81987404823303, "step": 60500}
{"episode_reward": 217.97265303729117, "episode": 485.0, "Q1 loss": 7.0169916915893555, "Q2 loss": 6.981926807403564, "Mean Target Q": 196.72955456542968, "Mean Q1": 196.72809436035158, "Mean Q2": 196.72840234375, "critic_loss": 13.998918525695801, "batch_reward": 1.7981029691696166, "actor_loss": -197.10342479887464, "actor_target_entropy": -1.0, "actor_entropy": 0.4164593971910931, "alpha_loss": 0.007860371583355738, "alpha_value": 0.20849189531852907, "duration": 72.4523766040802, "step": 60625}
{"episode_reward": 297.45354829266006, "episode": 486.0, "Q1 loss": 6.847614448547363, "Q2 loss": 6.838398445129394, "Mean Target Q": 196.90813708496094, "Mean Q1": 196.90761047363281, "Mean Q2": 196.9092996826172, "critic_loss": 13.68601287841797, "batch_reward": 1.806990605354309, "actor_loss": -197.2141413534841, "actor_target_entropy": -1.0, "actor_entropy": 0.4100443711203913, "alpha_loss": 0.0031630450168684604, "alpha_value": 0.2081679191729521, "duration": 73.1075439453125, "step": 60750}
{"episode_reward": 329.92984375526345, "episode": 487.0, "Q1 loss": 6.977075885772705, "Q2 loss": 6.986537204742431, "Mean Target Q": 196.94072412109375, "Mean Q1": 196.94248547363281, "Mean Q2": 196.9397852783203, "critic_loss": 13.963613128662109, "batch_reward": 1.8025713548660278, "actor_loss": -197.28184218633743, "actor_target_entropy": -1.0, "actor_entropy": 0.40665225755600704, "alpha_loss": 0.002080989144151173, "alpha_value": 0.20798744052307647, "duration": 98.27351021766663, "step": 60875}
{"episode_reward": 316.7061957618011, "episode": 488.0, "Q1 loss": 6.933703132629395, "Q2 loss": 6.939123001098633, "Mean Target Q": 197.0398826904297, "Mean Q1": 197.03440209960937, "Mean Q2": 197.0361953125, "critic_loss": 13.87282607269287, "batch_reward": 1.8145321044921876, "actor_loss": -197.41814939437373, "actor_target_entropy": -1.0, "actor_entropy": 0.37525682776205, "alpha_loss": -0.0050812615194327886, "alpha_value": 0.2080353205655453, "duration": 114.11764597892761, "step": 61000}
{"episode_reward": 242.33166605977198, "episode": 489.0, "Q1 loss": 7.117151376724244, "Q2 loss": 7.119067497253418, "Mean Target Q": 197.11653979492186, "Mean Q1": 197.12015319824218, "Mean Q2": 197.11940771484376, "critic_loss": 14.236218872070312, "batch_reward": 1.810019281387329, "actor_loss": -197.48524862622457, "actor_target_entropy": -1.0, "actor_entropy": 0.41994345235446146, "alpha_loss": 0.0056139463817493785, "alpha_value": 0.2080669568628421, "duration": 101.17853283882141, "step": 61125}
{"episode_reward": 190.3015116101251, "episode": 490.0, "Q1 loss": 7.232752849578858, "Q2 loss": 7.1978029403686525, "Mean Target Q": 197.18704150390624, "Mean Q1": 197.18249426269531, "Mean Q2": 197.18261328125, "critic_loss": 14.430555801391602, "batch_reward": 1.8052269105911254, "actor_loss": -197.56693612375568, "actor_target_entropy": -1.0, "actor_entropy": 0.42648634410673575, "alpha_loss": 0.0009572285475329526, "alpha_value": 0.20788423444324433, "duration": 112.7997395992279, "step": 61250}
{"episode_reward": 293.7502284480002, "episode": 491.0, "Q1 loss": 7.2446282215118405, "Q2 loss": 7.253037734985352, "Mean Target Q": 197.21167907714843, "Mean Q1": 197.21041882324218, "Mean Q2": 197.21014782714843, "critic_loss": 14.497665954589843, "batch_reward": 1.7940952558517456, "actor_loss": -197.4835711282397, "actor_target_entropy": -1.0, "actor_entropy": 0.3919852144188351, "alpha_loss": -0.00044382774337594, "alpha_value": 0.20791362542072586, "duration": 129.17716717720032, "step": 61375}
{"episode_reward": 267.26238931966066, "episode": 492.0, "Q1 loss": 7.0433240966796875, "Q2 loss": 7.001483211517334, "Mean Target Q": 197.18188549804688, "Mean Q1": 197.18030505371092, "Mean Q2": 197.1796184082031, "critic_loss": 14.044807235717773, "batch_reward": 1.7828299560546874, "actor_loss": -197.5853776008852, "actor_target_entropy": -1.0, "actor_entropy": 0.4108578029178804, "alpha_loss": 0.0023961664635627983, "alpha_value": 0.20759493590968855, "duration": 138.43176007270813, "step": 61500}
{"episode_reward": 232.61266633794298, "episode": 493.0, "Q1 loss": 7.048621032714844, "Q2 loss": 7.1032774505615235, "Mean Target Q": 197.44918713378905, "Mean Q1": 197.44801330566406, "Mean Q2": 197.44864172363282, "critic_loss": 14.151898506164551, "batch_reward": 1.8005208654403686, "actor_loss": -197.85406421479723, "actor_target_entropy": -1.0, "actor_entropy": 0.3952590170360747, "alpha_loss": 0.0022466857289333664, "alpha_value": 0.2075311884306501, "duration": 117.27081847190857, "step": 61625}
{"episode_reward": 250.31768334711956, "episode": 494.0, "Q1 loss": 6.833221954345703, "Q2 loss": 6.830247257232666, "Mean Target Q": 197.4434102783203, "Mean Q1": 197.44564404296875, "Mean Q2": 197.44537365722655, "critic_loss": 13.663469200134278, "batch_reward": 1.8059448661804198, "actor_loss": -197.90166153446322, "actor_target_entropy": -1.0, "actor_entropy": 0.3805296613324073, "alpha_loss": 0.0005501670154532598, "alpha_value": 0.20737972900235904, "duration": 102.93550753593445, "step": 61750}
{"episode_reward": 263.6127920259353, "episode": 495.0, "Q1 loss": 6.925820220947266, "Q2 loss": 6.887160190582275, "Mean Target Q": 197.52001330566407, "Mean Q1": 197.51101013183595, "Mean Q2": 197.51227270507812, "critic_loss": 13.812980422973633, "batch_reward": 1.8078323621749879, "actor_loss": -197.9167226155599, "actor_target_entropy": -1.0, "actor_entropy": 0.4021337495909797, "alpha_loss": 0.0038660188345977712, "alpha_value": 0.20727781214785487, "duration": 116.8233654499054, "step": 61875}
{"episode_reward": 191.41634565035014, "episode": 496.0, "Q1 loss": 6.7301620063781735, "Q2 loss": 6.726991588592529, "Mean Target Q": 197.57828540039063, "Mean Q1": 197.5822919921875, "Mean Q2": 197.58005639648437, "critic_loss": 13.457153610229492, "batch_reward": 1.807476700782776, "actor_loss": -197.92728153351814, "actor_target_entropy": -1.0, "actor_entropy": 0.417308198828851, "alpha_loss": 0.00399123344780697, "alpha_value": 0.20695102175803431, "duration": 129.6661274433136, "step": 62000}
{"episode_reward": 244.67711948153203, "episode": 497.0, "Q1 loss": 6.587497528076172, "Q2 loss": 6.624284917831421, "Mean Target Q": 197.56650573730468, "Mean Q1": 197.56712683105468, "Mean Q2": 197.56751245117186, "critic_loss": 13.211782424926758, "batch_reward": 1.8097242326736451, "actor_loss": -197.92617555648562, "actor_target_entropy": -1.0, "actor_entropy": 0.3908770221566397, "alpha_loss": 0.0015753407460001726, "alpha_value": 0.20667239102242443, "duration": 130.9503993988037, "step": 62125}
{"episode_reward": 212.78889872487647, "episode": 498.0, "Q1 loss": 6.854409841537476, "Q2 loss": 6.848895572662354, "Mean Target Q": 197.70675048828124, "Mean Q1": 197.70331945800783, "Mean Q2": 197.70445068359376, "critic_loss": 13.703305404663086, "batch_reward": 1.812034740447998, "actor_loss": -198.07791531470514, "actor_target_entropy": -1.0, "actor_entropy": 0.385885841904148, "alpha_loss": 0.007475194111917048, "alpha_value": 0.2063196042677782, "duration": 111.09934258460999, "step": 62250}
{"episode_reward": 173.75174799751431, "episode": 499.0, "Q1 loss": 6.665223022460937, "Q2 loss": 6.627954410552978, "Mean Target Q": 197.66600122070312, "Mean Q1": 197.66719848632812, "Mean Q2": 197.66680249023437, "critic_loss": 13.29317738342285, "batch_reward": 1.7994912710189819, "actor_loss": -198.03983706519716, "actor_target_entropy": -1.0, "actor_entropy": 0.3730265786723485, "alpha_loss": -0.00013285145230059112, "alpha_value": 0.20599067206981098, "duration": 138.60889673233032, "step": 62375}
{"episode_reward": 202.77242409782227, "episode": 500.0, "Q1 loss": 6.8270288200378415, "Q2 loss": 6.849303020477295, "Mean Target Q": 197.8140626220703, "Mean Q1": 197.80548681640624, "Mean Q2": 197.80521520996095, "critic_loss": 13.676331840515136, "batch_reward": 1.7958023920059205, "actor_loss": -198.22940851026965, "actor_target_entropy": -1.0, "actor_entropy": 0.3973284003234679, "alpha_loss": 0.006062108820544616, "alpha_value": 0.20595618953216918, "duration": 116.98586702346802, "step": 62500}
{"episode_reward": 270.9683885077942, "episode": 501.0, "Q1 loss": 6.590710590362549, "Q2 loss": 6.592980312347412, "Mean Target Q": 197.83128735351562, "Mean Q1": 197.83559912109374, "Mean Q2": 197.835869140625, "critic_loss": 13.183690849304199, "batch_reward": 1.8101879692077636, "actor_loss": -198.10834854368179, "actor_target_entropy": -1.0, "actor_entropy": 0.3979892931760304, "alpha_loss": 0.00577680810931183, "alpha_value": 0.20558730602315128, "duration": 137.75089693069458, "step": 62625}
{"episode_reward": 272.9088715184985, "episode": 502.0, "Q1 loss": 6.943107963562012, "Q2 loss": 6.978397148132324, "Mean Target Q": 197.8564725341797, "Mean Q1": 197.85479040527343, "Mean Q2": 197.8546612548828, "critic_loss": 13.92150510787964, "batch_reward": 1.8013891487121583, "actor_loss": -198.27318351499497, "actor_target_entropy": -1.0, "actor_entropy": 0.38342450366866204, "alpha_loss": 0.005345359699980867, "alpha_value": 0.20510779873446583, "duration": 130.2269971370697, "step": 62750}
{"episode_reward": 232.2020468346246, "episode": 503.0, "Q1 loss": 6.805096862792968, "Q2 loss": 6.7893000831604, "Mean Target Q": 197.99865063476562, "Mean Q1": 197.9982596435547, "Mean Q2": 197.99874829101563, "critic_loss": 13.59439697265625, "batch_reward": 1.7964223318099977, "actor_loss": -198.3916233607701, "actor_target_entropy": -1.0, "actor_entropy": 0.37302259556830875, "alpha_loss": 0.0046322346583659215, "alpha_value": 0.2045739413921719, "duration": 121.50824499130249, "step": 62875}
{"episode_reward": 222.42206754400559, "episode": 504.0, "Q1 loss": 7.138655788421631, "Q2 loss": 7.1438910446167, "Mean Target Q": 197.97467822265625, "Mean Q1": 197.97091235351562, "Mean Q2": 197.97159594726563, "critic_loss": 14.282546905517577, "batch_reward": 1.7994386739730834, "actor_loss": -198.36473600326045, "actor_target_entropy": -1.0, "actor_entropy": 0.4013047879261355, "alpha_loss": 0.006521729808751374, "alpha_value": 0.20418920525294332, "duration": 126.45284533500671, "step": 63000}
{"episode_reward": 199.93645740352943, "episode": 505.0, "Q1 loss": 6.75714013671875, "Q2 loss": 6.781537300109863, "Mean Target Q": 198.09870727539064, "Mean Q1": 198.10250329589843, "Mean Q2": 198.10189599609376, "critic_loss": 13.538677474975586, "batch_reward": 1.7980182666778564, "actor_loss": -198.45689585852244, "actor_target_entropy": -1.0, "actor_entropy": 0.4000596621679881, "alpha_loss": 0.0017220742727023742, "alpha_value": 0.2037821882811204, "duration": 126.9663462638855, "step": 63125}
{"episode_reward": 231.773836700089, "episode": 506.0, "Q1 loss": 6.7878316802978516, "Q2 loss": 6.776905242919922, "Mean Target Q": 198.09746459960937, "Mean Q1": 198.09127600097656, "Mean Q2": 198.09122985839844, "critic_loss": 13.564736919403076, "batch_reward": 1.7996883325576782, "actor_loss": -198.4600091749622, "actor_target_entropy": -1.0, "actor_entropy": 0.3799642627277682, "alpha_loss": 0.0019730793071850656, "alpha_value": 0.20373137621451606, "duration": 121.85206985473633, "step": 63250}
{"episode_reward": 212.13524581706227, "episode": 507.0, "Q1 loss": 6.773824546813965, "Q2 loss": 6.765429714202881, "Mean Target Q": 198.23981640625, "Mean Q1": 198.24195141601564, "Mean Q2": 198.24156274414062, "critic_loss": 13.539254257202149, "batch_reward": 1.803997778892517, "actor_loss": -198.6601845877511, "actor_target_entropy": -1.0, "actor_entropy": 0.37065151523029993, "alpha_loss": -0.003350812228514798, "alpha_value": 0.2038669154206514, "duration": 143.05630588531494, "step": 63375}
{"episode_reward": 214.81666731066264, "episode": 508.0, "Q1 loss": 6.921148200988769, "Q2 loss": 6.967993064880371, "Mean Target Q": 198.36361987304687, "Mean Q1": 198.35565295410157, "Mean Q2": 198.35509826660157, "critic_loss": 13.889141300201416, "batch_reward": 1.7998409643173219, "actor_loss": -198.80777149815714, "actor_target_entropy": -1.0, "actor_entropy": 0.367893343490939, "alpha_loss": 0.0006918103411613453, "alpha_value": 0.20387169125265797, "duration": 136.4183657169342, "step": 63500}
{"episode_reward": 244.15480784659908, "episode": 509.0, "Q1 loss": 6.875208618164063, "Q2 loss": 6.9196006813049316, "Mean Target Q": 198.3741201171875, "Mean Q1": 198.37854370117188, "Mean Q2": 198.37990222167969, "critic_loss": 13.79480931854248, "batch_reward": 1.8021811084747315, "actor_loss": -198.66682870047433, "actor_target_entropy": -1.0, "actor_entropy": 0.41440427776366945, "alpha_loss": 0.0025878463066109116, "alpha_value": 0.20375464835992702, "duration": 110.32136917114258, "step": 63625}
{"episode_reward": 201.20375441405807, "episode": 510.0, "Q1 loss": 6.898109603881836, "Q2 loss": 6.885762134552002, "Mean Target Q": 198.479759765625, "Mean Q1": 198.47733544921874, "Mean Q2": 198.476259765625, "critic_loss": 13.78387173461914, "batch_reward": 1.817271279335022, "actor_loss": -198.8108200565461, "actor_target_entropy": -1.0, "actor_entropy": 0.3998720299813055, "alpha_loss": 0.0020134909840811405, "alpha_value": 0.203531578966081, "duration": 120.95727324485779, "step": 63750}
{"episode_reward": 278.40672911803546, "episode": 511.0, "Q1 loss": 6.747240863800049, "Q2 loss": 6.790279850006104, "Mean Target Q": 198.463255859375, "Mean Q1": 198.456673828125, "Mean Q2": 198.45763208007813, "critic_loss": 13.537520683288575, "batch_reward": 1.7992354402542114, "actor_loss": -198.8857957143632, "actor_target_entropy": -1.0, "actor_entropy": 0.36634304741072277, "alpha_loss": 0.007924307243055886, "alpha_value": 0.20329892535937047, "duration": 118.05658292770386, "step": 63875}
{"episode_reward": 256.3769570099012, "episode": 512.0, "Q1 loss": 7.001913925170898, "Q2 loss": 6.9794087409973145, "Mean Target Q": 198.58317346191407, "Mean Q1": 198.58049182128906, "Mean Q2": 198.57989660644532, "critic_loss": 13.98132271194458, "batch_reward": 1.7995378923416139, "actor_loss": -198.89851847002583, "actor_target_entropy": -1.0, "actor_entropy": 0.38186321143181096, "alpha_loss": -0.0018549157727149226, "alpha_value": 0.2029739813452562, "duration": 133.05577063560486, "step": 64000}
{"episode_reward": 235.1854297132146, "episode": 513.0, "Q1 loss": 6.885010505676269, "Q2 loss": 6.874715824127197, "Mean Target Q": 198.66906579589843, "Mean Q1": 198.6684298095703, "Mean Q2": 198.6686005859375, "critic_loss": 13.759726287841797, "batch_reward": 1.8043779287338257, "actor_loss": -199.06279548766122, "actor_target_entropy": -1.0, "actor_entropy": 0.36191946031555294, "alpha_loss": -0.00016324449005344557, "alpha_value": 0.20300973075175952, "duration": 129.3205270767212, "step": 64125}
{"episode_reward": 338.0059674519947, "episode": 514.0, "Q1 loss": 6.965001903533936, "Q2 loss": 7.010929954528809, "Mean Target Q": 198.64810803222656, "Mean Q1": 198.65146118164063, "Mean Q2": 198.65163391113282, "critic_loss": 13.975931869506836, "batch_reward": 1.8045596828460693, "actor_loss": -198.9996815343057, "actor_target_entropy": -1.0, "actor_entropy": 0.37594229655881084, "alpha_loss": 0.0005551657579358547, "alpha_value": 0.2030329280841256, "duration": 118.52541971206665, "step": 64250}
{"episode_reward": 238.61968032669833, "episode": 515.0, "Q1 loss": 7.02952897644043, "Q2 loss": 7.07281799697876, "Mean Target Q": 198.77771801757814, "Mean Q1": 198.77552001953126, "Mean Q2": 198.77471789550782, "critic_loss": 14.10234700012207, "batch_reward": 1.8047861499786377, "actor_loss": -199.1980474562872, "actor_target_entropy": -1.0, "actor_entropy": 0.38280265198813546, "alpha_loss": -0.003397556808998897, "alpha_value": 0.2030776773288757, "duration": 107.1939685344696, "step": 64375}
{"episode_reward": 299.2040169269915, "episode": 516.0, "Q1 loss": 7.016318840026855, "Q2 loss": 6.99591015625, "Mean Target Q": 198.92634045410156, "Mean Q1": 198.92497485351564, "Mean Q2": 198.9268603515625, "critic_loss": 14.012229019165039, "batch_reward": 1.8102085313796996, "actor_loss": -199.32739996141004, "actor_target_entropy": -1.0, "actor_entropy": 0.37829498898598457, "alpha_loss": -0.002130926455250911, "alpha_value": 0.2033743647901166, "duration": 144.02713680267334, "step": 64500}
{"episode_reward": 283.156772909717, "episode": 517.0, "Q1 loss": 6.699305355072021, "Q2 loss": 6.738387168884278, "Mean Target Q": 198.9569560546875, "Mean Q1": 198.95627221679686, "Mean Q2": 198.95544067382812, "critic_loss": 13.437692581176758, "batch_reward": 1.8128628959655761, "actor_loss": -199.2742636544364, "actor_target_entropy": -1.0, "actor_entropy": 0.4023423864254876, "alpha_loss": 0.004505422128926194, "alpha_value": 0.203325378194806, "duration": 122.54005694389343, "step": 64625}
{"episode_reward": 202.93853791334385, "episode": 518.0, "Q1 loss": 7.241327404022217, "Q2 loss": 7.223529132843018, "Mean Target Q": 198.93068627929688, "Mean Q1": 198.92847534179688, "Mean Q2": 198.92813122558593, "critic_loss": 14.464856468200683, "batch_reward": 1.8063003120422363, "actor_loss": -199.30700535928048, "actor_target_entropy": -1.0, "actor_entropy": 0.3938756339973019, "alpha_loss": 0.004063263084859618, "alpha_value": 0.20296681782300158, "duration": 125.70705223083496, "step": 64750}
{"episode_reward": 183.81350975252778, "episode": 519.0, "Q1 loss": 7.019278079986572, "Q2 loss": 7.002278045654297, "Mean Target Q": 199.04976721191406, "Mean Q1": 199.05008654785155, "Mean Q2": 199.05109240722658, "critic_loss": 14.021556144714355, "batch_reward": 1.8175268077850342, "actor_loss": -199.35847812228732, "actor_target_entropy": -1.0, "actor_entropy": 0.4044146367481777, "alpha_loss": 0.0019530236299726226, "alpha_value": 0.20265390610911885, "duration": 124.21398377418518, "step": 64875}
{"episode_reward": 199.63027499350713, "episode": 520.0, "Q1 loss": 6.812352462768555, "Q2 loss": 6.8182082328796385, "Mean Target Q": 199.0916671142578, "Mean Q1": 199.09039965820313, "Mean Q2": 199.08940576171875, "critic_loss": 13.630560653686523, "batch_reward": 1.8017864875793457, "actor_loss": -199.5017350719821, "actor_target_entropy": -1.0, "actor_entropy": 0.37288376208274593, "alpha_loss": -0.005304689631767331, "alpha_value": 0.20274870347234658, "step": 65000}
{"duration": 134.28093552589417, "step": 65000}
{"episode_reward": 198.3602689504012, "episode": 521.0, "Q1 loss": 6.745657371520996, "Q2 loss": 6.7787205009460445, "Mean Target Q": 199.2527014160156, "Mean Q1": 199.24771484375, "Mean Q2": 199.24598791503905, "critic_loss": 13.524377822875977, "batch_reward": 1.8224040374755859, "actor_loss": -199.57479301331534, "actor_target_entropy": -1.0, "actor_entropy": 0.38381133334977285, "alpha_loss": -0.0017941475786741763, "alpha_value": 0.2031061625857055, "duration": 134.68518090248108, "step": 65125}
{"episode_reward": 246.80896374769083, "episode": 522.0, "Q1 loss": 7.063285037994385, "Q2 loss": 7.0125655250549315, "Mean Target Q": 199.17689013671875, "Mean Q1": 199.18243298339843, "Mean Q2": 199.18392663574218, "critic_loss": 14.075850578308106, "batch_reward": 1.8064470376968385, "actor_loss": -199.5121046496976, "actor_target_entropy": -1.0, "actor_entropy": 0.375756680484741, "alpha_loss": 9.95506171978289e-05, "alpha_value": 0.20308061210404207, "duration": 129.2244007587433, "step": 65250}
{"episode_reward": 294.89677045173505, "episode": 523.0, "Q1 loss": 7.184865440368652, "Q2 loss": 7.223203498840332, "Mean Target Q": 199.34505224609376, "Mean Q1": 199.33597717285156, "Mean Q2": 199.33557067871095, "critic_loss": 14.408068939208984, "batch_reward": 1.818761881828308, "actor_loss": -199.6839410691034, "actor_target_entropy": -1.0, "actor_entropy": 0.3810405054735759, "alpha_loss": -0.0020468165739513343, "alpha_value": 0.2031823525322743, "duration": 136.96911883354187, "step": 65375}
{"episode_reward": 244.9031288083928, "episode": 524.0, "Q1 loss": 6.910989795684815, "Q2 loss": 6.939298377990722, "Mean Target Q": 199.32366296386718, "Mean Q1": 199.33067993164062, "Mean Q2": 199.3308212890625, "critic_loss": 13.850288192749023, "batch_reward": 1.801583631515503, "actor_loss": -199.6628166937059, "actor_target_entropy": -1.0, "actor_entropy": 0.3699803847459055, "alpha_loss": -0.004171103490666757, "alpha_value": 0.20342481284447775, "duration": 121.6416745185852, "step": 65500}
{"episode_reward": 217.54596895518603, "episode": 525.0, "Q1 loss": 7.231184955596924, "Q2 loss": 7.208810485839844, "Mean Target Q": 199.4296746826172, "Mean Q1": 199.42271069335936, "Mean Q2": 199.42306811523437, "critic_loss": 14.43999543762207, "batch_reward": 1.8064238414764404, "actor_loss": -199.76708160884797, "actor_target_entropy": -1.0, "actor_entropy": 0.39066739262096467, "alpha_loss": -0.008843100452352138, "alpha_value": 0.20389182745296777, "duration": 141.02516841888428, "step": 65625}
{"episode_reward": 213.80065625788635, "episode": 526.0, "Q1 loss": 7.330893341064453, "Q2 loss": 7.361307292938233, "Mean Target Q": 199.42114404296876, "Mean Q1": 199.42204528808594, "Mean Q2": 199.42209423828126, "critic_loss": 14.692200630187989, "batch_reward": 1.8004328336715698, "actor_loss": -199.82394187681138, "actor_target_entropy": -1.0, "actor_entropy": 0.39540865104044637, "alpha_loss": 0.00014395837394160128, "alpha_value": 0.2043011088322513, "duration": 135.79124402999878, "step": 65750}
{"episode_reward": 315.3640697101583, "episode": 527.0, "Q1 loss": 6.920907707214355, "Q2 loss": 6.925417835235596, "Mean Target Q": 199.56395190429689, "Mean Q1": 199.56167578125, "Mean Q2": 199.56125451660157, "critic_loss": 13.846325561523438, "batch_reward": 1.806247368812561, "actor_loss": -199.90318952287947, "actor_target_entropy": -1.0, "actor_entropy": 0.3866715691392384, "alpha_loss": 0.0013794496023495282, "alpha_value": 0.20423679455928068, "duration": 128.17728757858276, "step": 65875}
{"episode_reward": 224.94946073245217, "episode": 528.0, "Q1 loss": 7.2980132484436036, "Q2 loss": 7.320656894683838, "Mean Target Q": 199.5264051513672, "Mean Q1": 199.52406823730468, "Mean Q2": 199.52425158691406, "critic_loss": 14.61867011642456, "batch_reward": 1.8109453287124633, "actor_loss": -199.97997480823147, "actor_target_entropy": -1.0, "actor_entropy": 0.38664370294540157, "alpha_loss": -0.0013097764420953969, "alpha_value": 0.20417568848869608, "duration": 111.12996339797974, "step": 66000}
{"episode_reward": 249.96461204173593, "episode": 529.0, "Q1 loss": 6.865923000335694, "Q2 loss": 6.849606086730957, "Mean Target Q": 199.50495458984375, "Mean Q1": 199.50514782714845, "Mean Q2": 199.50487573242188, "critic_loss": 13.715529136657715, "batch_reward": 1.8041169185638428, "actor_loss": -199.9246126205202, "actor_target_entropy": -1.0, "actor_entropy": 0.3859575494887337, "alpha_loss": -0.0008974458046612286, "alpha_value": 0.2042979740443378, "duration": 111.77784085273743, "step": 66125}
{"episode_reward": 234.19584574488886, "episode": 530.0, "Q1 loss": 6.978960941314697, "Q2 loss": 6.929744987487793, "Mean Target Q": 199.58390637207032, "Mean Q1": 199.58342944335936, "Mean Q2": 199.58298559570312, "critic_loss": 13.908705947875976, "batch_reward": 1.8031096534729003, "actor_loss": -199.90950824368386, "actor_target_entropy": -1.0, "actor_entropy": 0.3851863020850766, "alpha_loss": 0.008472836508806194, "alpha_value": 0.20404166793355075, "duration": 122.19447088241577, "step": 66250}
{"episode_reward": 234.87488036308758, "episode": 531.0, "Q1 loss": 6.9604883346557616, "Q2 loss": 6.9268761672973636, "Mean Target Q": 199.74040270996093, "Mean Q1": 199.7378408203125, "Mean Q2": 199.7382039794922, "critic_loss": 13.88736450958252, "batch_reward": 1.8187400588989258, "actor_loss": -200.07411872016058, "actor_target_entropy": -1.0, "actor_entropy": 0.3932221465640598, "alpha_loss": 0.0012577210057763354, "alpha_value": 0.2036393181985451, "duration": 130.19917726516724, "step": 66375}
{"episode_reward": 184.40721238756188, "episode": 532.0, "Q1 loss": 6.947836769104004, "Q2 loss": 6.933438545227051, "Mean Target Q": 199.70382153320313, "Mean Q1": 199.70091271972657, "Mean Q2": 199.70152966308595, "critic_loss": 13.88127532196045, "batch_reward": 1.7992370748519897, "actor_loss": -200.0288053943265, "actor_target_entropy": -1.0, "actor_entropy": 0.40486137857360227, "alpha_loss": -0.0010710143889751166, "alpha_value": 0.20375957853456048, "duration": 129.2415952682495, "step": 66500}
{"episode_reward": 206.41851851405096, "episode": 533.0, "Q1 loss": 7.0983062133789065, "Q2 loss": 7.080611362457275, "Mean Target Q": 199.82854797363282, "Mean Q1": 199.82704077148438, "Mean Q2": 199.8271140136719, "critic_loss": 14.178917575836183, "batch_reward": 1.813758436203003, "actor_loss": -200.18616497705852, "actor_target_entropy": -1.0, "actor_entropy": 0.3677813836506435, "alpha_loss": 0.0026868695119721077, "alpha_value": 0.20361542096136775, "duration": 109.4694356918335, "step": 66625}
{"episode_reward": 239.9962335051705, "episode": 534.0, "Q1 loss": 7.002853298187256, "Q2 loss": 7.018700374603272, "Mean Target Q": 199.86457055664061, "Mean Q1": 199.85843798828125, "Mean Q2": 199.85828820800782, "critic_loss": 14.02155362701416, "batch_reward": 1.8134625091552734, "actor_loss": -200.12581486855782, "actor_target_entropy": -1.0, "actor_entropy": 0.39657724816952983, "alpha_loss": 0.0004909313537345658, "alpha_value": 0.20348615643748325, "duration": 131.01307845115662, "step": 66750}
{"episode_reward": 290.34904039884736, "episode": 535.0, "Q1 loss": 7.246834533691406, "Q2 loss": 7.288586574554444, "Mean Target Q": 199.96015100097657, "Mean Q1": 199.96243566894532, "Mean Q2": 199.9622565917969, "critic_loss": 14.535421180725098, "batch_reward": 1.8009898834228515, "actor_loss": -200.24358840215774, "actor_target_entropy": -1.0, "actor_entropy": 0.3741934824557531, "alpha_loss": 0.0027199144334724497, "alpha_value": 0.20332421236154233, "duration": 124.55237460136414, "step": 66875}
{"episode_reward": 224.19976514714565, "episode": 536.0, "Q1 loss": 6.946147815704346, "Q2 loss": 6.947981178283691, "Mean Target Q": 200.04756115722657, "Mean Q1": 200.04782189941406, "Mean Q2": 200.04814819335937, "critic_loss": 13.894129035949707, "batch_reward": 1.816533356666565, "actor_loss": -200.38861231650077, "actor_target_entropy": -1.0, "actor_entropy": 0.3631714462272583, "alpha_loss": 0.0002639327994397571, "alpha_value": 0.20320595101767594, "duration": 106.86449313163757, "step": 67000}
{"episode_reward": 213.49200997768705, "episode": 537.0, "Q1 loss": 6.956895530700684, "Q2 loss": 6.947039031982422, "Mean Target Q": 200.04995959472657, "Mean Q1": 200.05114147949217, "Mean Q2": 200.05084399414062, "critic_loss": 13.903934577941895, "batch_reward": 1.8041456117630006, "actor_loss": -200.381595187717, "actor_target_entropy": -1.0, "actor_entropy": 0.3759702992817712, "alpha_loss": 0.00020181678516405916, "alpha_value": 0.20318999779275707, "duration": 124.53562951087952, "step": 67125}
{"episode_reward": 205.10317145971604, "episode": 538.0, "Q1 loss": 7.04584390258789, "Q2 loss": 7.079205097198487, "Mean Target Q": 200.10941015625, "Mean Q1": 200.1042412109375, "Mean Q2": 200.1041416015625, "critic_loss": 14.125048973083496, "batch_reward": 1.810481068611145, "actor_loss": -200.49331812704764, "actor_target_entropy": -1.0, "actor_entropy": 0.3755105930951334, "alpha_loss": 0.0027547330434073603, "alpha_value": 0.2030632733233006, "duration": 127.9111590385437, "step": 67250}
{"episode_reward": 221.6932178260268, "episode": 539.0, "Q1 loss": 7.104291709899902, "Q2 loss": 7.102498712539673, "Mean Target Q": 200.1104873046875, "Mean Q1": 200.1067537841797, "Mean Q2": 200.10627880859374, "critic_loss": 14.206790428161622, "batch_reward": 1.8173690576553345, "actor_loss": -200.48615616086929, "actor_target_entropy": -1.0, "actor_entropy": 0.3558139427313729, "alpha_loss": -0.005743358389563149, "alpha_value": 0.20311444157040479, "duration": 127.69202828407288, "step": 67375}
{"episode_reward": 212.54746536461286, "episode": 540.0, "Q1 loss": 7.495274909973144, "Q2 loss": 7.52225191116333, "Mean Target Q": 200.25063317871093, "Mean Q1": 200.25309326171876, "Mean Q2": 200.25427612304688, "critic_loss": 15.017526893615722, "batch_reward": 1.8063817501068116, "actor_loss": -200.6152530793221, "actor_target_entropy": -1.0, "actor_entropy": 0.37465575842126725, "alpha_loss": -0.0009088357797853889, "alpha_value": 0.20344267660423754, "duration": 108.10585761070251, "step": 67500}
{"episode_reward": 160.1839936905477, "episode": 541.0, "Q1 loss": 7.218655689239502, "Q2 loss": 7.2249796714782715, "Mean Target Q": 200.25227197265625, "Mean Q1": 200.25090856933593, "Mean Q2": 200.24941625976564, "critic_loss": 14.4436353225708, "batch_reward": 1.7999195671081543, "actor_loss": -200.5766875251891, "actor_target_entropy": -1.0, "actor_entropy": 0.39662502706050873, "alpha_loss": 0.0002788348337783227, "alpha_value": 0.20340470760332174, "duration": 113.02555799484253, "step": 67625}
{"episode_reward": 238.58870240000246, "episode": 542.0, "Q1 loss": 7.167303283691406, "Q2 loss": 7.152457834243775, "Mean Target Q": 200.38878479003907, "Mean Q1": 200.38744396972658, "Mean Q2": 200.38788159179688, "critic_loss": 14.319761138916016, "batch_reward": 1.8142559375762939, "actor_loss": -200.8658715524981, "actor_target_entropy": -1.0, "actor_entropy": 0.39493763302603074, "alpha_loss": -0.0007863534715837769, "alpha_value": 0.20342874279209663, "duration": 105.63672184944153, "step": 67750}
{"episode_reward": 310.81161495420844, "episode": 543.0, "Q1 loss": 7.380049514770508, "Q2 loss": 7.364201442718506, "Mean Target Q": 200.42049401855468, "Mean Q1": 200.41877453613282, "Mean Q2": 200.41849536132813, "critic_loss": 14.744250961303711, "batch_reward": 1.8115458335876464, "actor_loss": -200.83262973361545, "actor_target_entropy": -1.0, "actor_entropy": 0.39042324253490995, "alpha_loss": -0.0037966739231099686, "alpha_value": 0.2036493571539965, "duration": 113.6039891242981, "step": 67875}
{"episode_reward": 246.35828473987783, "episode": 544.0, "Q1 loss": 7.262438987731934, "Q2 loss": 7.237397834777832, "Mean Target Q": 200.44185388183593, "Mean Q1": 200.4472843017578, "Mean Q2": 200.44754125976561, "critic_loss": 14.499836875915527, "batch_reward": 1.8071173849105835, "actor_loss": -200.78774015365107, "actor_target_entropy": -1.0, "actor_entropy": 0.3924372912414612, "alpha_loss": 0.0013444259473603338, "alpha_value": 0.20363163018902625, "duration": 108.73698925971985, "step": 68000}
{"episode_reward": 259.5259809139513, "episode": 545.0, "Q1 loss": 6.964490587234497, "Q2 loss": 6.944999797821045, "Mean Target Q": 200.60245837402343, "Mean Q1": 200.59652893066405, "Mean Q2": 200.59609924316408, "critic_loss": 13.909490310668945, "batch_reward": 1.8121220388412476, "actor_loss": -201.0214371454148, "actor_target_entropy": -1.0, "actor_entropy": 0.38551099669365657, "alpha_loss": 0.002682234132884159, "alpha_value": 0.20361525165303193, "duration": 118.14109206199646, "step": 68125}
{"episode_reward": 283.59118923606763, "episode": 546.0, "Q1 loss": 6.916190029144287, "Q2 loss": 6.905592319488526, "Mean Target Q": 200.64269140625, "Mean Q1": 200.6384962158203, "Mean Q2": 200.63963427734376, "critic_loss": 13.821782417297364, "batch_reward": 1.8161105241775513, "actor_loss": -201.01087877827305, "actor_target_entropy": -1.0, "actor_entropy": 0.36171325728777914, "alpha_loss": 0.0009058621325229685, "alpha_value": 0.2036077248691054, "duration": 119.51952981948853, "step": 68250}
{"episode_reward": 196.03007213472927, "episode": 547.0, "Q1 loss": 6.955162292480469, "Q2 loss": 6.899971565246582, "Mean Target Q": 200.69330541992187, "Mean Q1": 200.69510510253906, "Mean Q2": 200.6947022705078, "critic_loss": 13.855133880615234, "batch_reward": 1.8162130060195922, "actor_loss": -201.0745098780072, "actor_target_entropy": -1.0, "actor_entropy": 0.36067292661893935, "alpha_loss": -0.0018513179236342983, "alpha_value": 0.20356104453626225, "duration": 121.33527994155884, "step": 68375}
{"episode_reward": 315.47025442096583, "episode": 548.0, "Q1 loss": 7.13504935836792, "Q2 loss": 7.14889682006836, "Mean Target Q": 200.7597227783203, "Mean Q1": 200.75542700195314, "Mean Q2": 200.75477807617187, "critic_loss": 14.283946182250977, "batch_reward": 1.8214150667190552, "actor_loss": -201.05111571281188, "actor_target_entropy": -1.0, "actor_entropy": 0.40828932533341067, "alpha_loss": 0.008358558095360716, "alpha_value": 0.2034038308188309, "duration": 139.0072946548462, "step": 68500}
{"episode_reward": 262.6544584292265, "episode": 549.0, "Q1 loss": 6.91180432510376, "Q2 loss": 6.935811397552491, "Mean Target Q": 200.79017626953126, "Mean Q1": 200.78913818359376, "Mean Q2": 200.7906260986328, "critic_loss": 13.84761570739746, "batch_reward": 1.813055814743042, "actor_loss": -201.1202646891276, "actor_target_entropy": -1.0, "actor_entropy": 0.39363610602560495, "alpha_loss": 0.007544313346789707, "alpha_value": 0.2026300633695577, "duration": 130.93930768966675, "step": 68625}
{"episode_reward": 229.61883563790408, "episode": 550.0, "Q1 loss": 7.0365578498840335, "Q2 loss": 7.059899978637695, "Mean Target Q": 200.81940783691405, "Mean Q1": 200.81585607910156, "Mean Q2": 200.8144803466797, "critic_loss": 14.096457847595214, "batch_reward": 1.8161367139816285, "actor_loss": -201.18027250228388, "actor_target_entropy": -1.0, "actor_entropy": 0.3768097666963454, "alpha_loss": 0.005733837337879044, "alpha_value": 0.20224390052654248, "duration": 118.73293542861938, "step": 68750}
{"episode_reward": 238.2872508744646, "episode": 551.0, "Q1 loss": 7.263154357910156, "Q2 loss": 7.249051931381225, "Mean Target Q": 200.91294665527343, "Mean Q1": 200.91473864746095, "Mean Q2": 200.91421716308594, "critic_loss": 14.512206321716308, "batch_reward": 1.8086742000579834, "actor_loss": -201.28638518802703, "actor_target_entropy": -1.0, "actor_entropy": 0.3579860812141782, "alpha_loss": -0.004104398712072344, "alpha_value": 0.20221235486739872, "duration": 112.29350471496582, "step": 68875}
{"episode_reward": 169.30089638197873, "episode": 552.0, "Q1 loss": 7.210199440002442, "Q2 loss": 7.234158809661865, "Mean Target Q": 200.94571362304688, "Mean Q1": 200.9454052734375, "Mean Q2": 200.94635791015625, "critic_loss": 14.444358276367188, "batch_reward": 1.8086686668395997, "actor_loss": -201.2386710874496, "actor_target_entropy": -1.0, "actor_entropy": 0.37490345753969684, "alpha_loss": 0.0035857149839190945, "alpha_value": 0.2021667425279717, "duration": 143.55390763282776, "step": 69000}
{"episode_reward": 214.02583222222393, "episode": 553.0, "Q1 loss": 7.005522197723389, "Q2 loss": 7.05515079498291, "Mean Target Q": 200.96112707519532, "Mean Q1": 200.95711791992187, "Mean Q2": 200.95656225585938, "critic_loss": 14.060672988891602, "batch_reward": 1.8126918287277223, "actor_loss": -201.28721085805742, "actor_target_entropy": -1.0, "actor_entropy": 0.36267515685823226, "alpha_loss": 0.0056627901485337626, "alpha_value": 0.2017804858284235, "duration": 121.16678953170776, "step": 69125}
{"episode_reward": 338.0189373946677, "episode": 554.0, "Q1 loss": 7.13213402557373, "Q2 loss": 7.158643672943115, "Mean Target Q": 201.02863940429688, "Mean Q1": 201.03362561035155, "Mean Q2": 201.03319116210938, "critic_loss": 14.290777698516846, "batch_reward": 1.8261606426239014, "actor_loss": -201.35988124724358, "actor_target_entropy": -1.0, "actor_entropy": 0.3774908627233198, "alpha_loss": 0.006462065424139221, "alpha_value": 0.20140788963021994, "duration": 141.51984453201294, "step": 69250}
{"episode_reward": 235.66727662508524, "episode": 555.0, "Q1 loss": 7.130665454864502, "Q2 loss": 7.086795993804932, "Mean Target Q": 201.108111328125, "Mean Q1": 201.10233349609376, "Mean Q2": 201.1031973876953, "critic_loss": 14.217461380004883, "batch_reward": 1.823125539779663, "actor_loss": -201.46087476942273, "actor_target_entropy": -1.0, "actor_entropy": 0.356241542905096, "alpha_loss": 0.0006764768253243159, "alpha_value": 0.2011234320206232, "duration": 136.98309183120728, "step": 69375}
{"episode_reward": 333.8321440255249, "episode": 556.0, "Q1 loss": 6.984999202728272, "Q2 loss": 6.967440044403076, "Mean Target Q": 201.00946655273438, "Mean Q1": 201.0099567871094, "Mean Q2": 201.01040979003906, "critic_loss": 13.952439239501953, "batch_reward": 1.808622155189514, "actor_loss": -201.3357635005828, "actor_target_entropy": -1.0, "actor_entropy": 0.3585259775000234, "alpha_loss": -0.0014036534947433298, "alpha_value": 0.20115595637119552, "duration": 147.34799790382385, "step": 69500}
{"episode_reward": 278.6228176639891, "episode": 557.0, "Q1 loss": 6.891796848297119, "Q2 loss": 6.825954074859619, "Mean Target Q": 201.18986743164064, "Mean Q1": 201.18960571289062, "Mean Q2": 201.18812170410158, "critic_loss": 13.717750961303711, "batch_reward": 1.8154438371658326, "actor_loss": -201.57468595958892, "actor_target_entropy": -1.0, "actor_entropy": 0.38950067947781275, "alpha_loss": -0.0010998629454878114, "alpha_value": 0.20129868518622784, "duration": 122.62196588516235, "step": 69625}
{"episode_reward": 234.96878337066306, "episode": 558.0, "Q1 loss": 7.168319534301758, "Q2 loss": 7.1768985252380375, "Mean Target Q": 201.2682069091797, "Mean Q1": 201.26780432128905, "Mean Q2": 201.26923254394532, "critic_loss": 14.34521810913086, "batch_reward": 1.8021057653427124, "actor_loss": -201.55990108366936, "actor_target_entropy": -1.0, "actor_entropy": 0.36629388217003117, "alpha_loss": -0.0021340549048486975, "alpha_value": 0.2013995641071406, "duration": 123.34534192085266, "step": 69750}
{"episode_reward": 162.8905079552844, "episode": 559.0, "Q1 loss": 7.404135297775269, "Q2 loss": 7.40671891784668, "Mean Target Q": 201.41552478027344, "Mean Q1": 201.40780297851563, "Mean Q2": 201.40690942382813, "critic_loss": 14.810854270935058, "batch_reward": 1.8082074756622315, "actor_loss": -201.7621365501767, "actor_target_entropy": -1.0, "actor_entropy": 0.3568802901676723, "alpha_loss": 0.0023993278247496437, "alpha_value": 0.20126142661665647, "duration": 140.867938041687, "step": 69875}
{"episode_reward": 360.6533924073613, "episode": 560.0, "Q1 loss": 6.96935221862793, "Q2 loss": 6.97459118270874, "Mean Target Q": 201.40999597167968, "Mean Q1": 201.41289050292968, "Mean Q2": 201.41296325683595, "critic_loss": 13.943943382263184, "batch_reward": 1.8247686834335328, "actor_loss": -201.78258735902847, "actor_target_entropy": -1.0, "actor_entropy": 0.35607078719523644, "alpha_loss": -0.004947931847474989, "alpha_value": 0.20146398345029906, "step": 70000}
{"duration": 139.4232883453369, "step": 70000}
{"episode_reward": 310.3245003588079, "episode": 561.0, "Q1 loss": 6.974004314422608, "Q2 loss": 6.9737362365722655, "Mean Target Q": 201.38907360839843, "Mean Q1": 201.38858605957032, "Mean Q2": 201.38796630859375, "critic_loss": 13.947740535736084, "batch_reward": 1.813195951461792, "actor_loss": -201.71242486862909, "actor_target_entropy": -1.0, "actor_entropy": 0.3883898594076671, "alpha_loss": 0.0015864814077282236, "alpha_value": 0.20149371286410722, "duration": 128.27029395103455, "step": 70125}
{"episode_reward": 154.48946513257255, "episode": 562.0, "Q1 loss": 7.451476467132569, "Q2 loss": 7.512134780883789, "Mean Target Q": 201.63524572753906, "Mean Q1": 201.63136999511718, "Mean Q2": 201.63169787597656, "critic_loss": 14.963611221313476, "batch_reward": 1.8281273107528686, "actor_loss": -201.99663322202622, "actor_target_entropy": -1.0, "actor_entropy": 0.35117730978996525, "alpha_loss": 9.60222490492367e-06, "alpha_value": 0.20154956281683253, "duration": 119.50130152702332, "step": 70250}
{"episode_reward": 246.56417389384558, "episode": 563.0, "Q1 loss": 6.9772617015838625, "Q2 loss": 6.955960319519043, "Mean Target Q": 201.6115272216797, "Mean Q1": 201.61162060546874, "Mean Q2": 201.61165661621095, "critic_loss": 13.933222038269044, "batch_reward": 1.8177885360717774, "actor_loss": -202.00898185608878, "actor_target_entropy": -1.0, "actor_entropy": 0.37901890325167825, "alpha_loss": 0.005218414190624442, "alpha_value": 0.2012555505512662, "duration": 107.27156114578247, "step": 70375}
{"episode_reward": 218.5766344170604, "episode": 564.0, "Q1 loss": 7.29743839263916, "Q2 loss": 7.2911760673522945, "Mean Target Q": 201.68237109375, "Mean Q1": 201.68119653320312, "Mean Q2": 201.68196484375, "critic_loss": 14.588614418029785, "batch_reward": 1.8194312725067139, "actor_loss": -202.00817748039, "actor_target_entropy": -1.0, "actor_entropy": 0.36573312695949306, "alpha_loss": 0.0013943899332755996, "alpha_value": 0.2011376532133397, "duration": 88.91656684875488, "step": 70500}
{"episode_reward": 246.97565392030756, "episode": 565.0, "Q1 loss": 7.140499645233154, "Q2 loss": 7.175562370300293, "Mean Target Q": 201.73310205078124, "Mean Q1": 201.73278698730468, "Mean Q2": 201.73243103027343, "critic_loss": 14.316062057495117, "batch_reward": 1.8220889263153077, "actor_loss": -202.08650570824034, "actor_target_entropy": -1.0, "actor_entropy": 0.3574195693409632, "alpha_loss": 0.001811164590190091, "alpha_value": 0.2008824540772738, "duration": 91.92705416679382, "step": 70625}
{"episode_reward": 255.9692440830966, "episode": 566.0, "Q1 loss": 7.226646244049072, "Q2 loss": 7.238625873565674, "Mean Target Q": 201.85705493164062, "Mean Q1": 201.85772583007812, "Mean Q2": 201.85744067382814, "critic_loss": 14.465272064208984, "batch_reward": 1.8173906488418579, "actor_loss": -202.28489881946194, "actor_target_entropy": -1.0, "actor_entropy": 0.33457062153085587, "alpha_loss": -0.0011426033020289915, "alpha_value": 0.2008192638124823, "duration": 127.59528470039368, "step": 70750}
{"episode_reward": 257.23738251443956, "episode": 567.0, "Q1 loss": 7.4171604347229, "Q2 loss": 7.493787338256836, "Mean Target Q": 201.71564819335939, "Mean Q1": 201.7104200439453, "Mean Q2": 201.71094189453126, "critic_loss": 14.910947761535645, "batch_reward": 1.819033660888672, "actor_loss": -202.0650138249473, "actor_target_entropy": -1.0, "actor_entropy": 0.36373447189255365, "alpha_loss": 0.0017050212020024893, "alpha_value": 0.20079697148279932, "duration": 123.42311525344849, "step": 70875}
{"episode_reward": 244.55724010926403, "episode": 568.0, "Q1 loss": 7.2456946983337405, "Q2 loss": 7.262000350952149, "Mean Target Q": 201.95275036621095, "Mean Q1": 201.95695556640624, "Mean Q2": 201.95687060546874, "critic_loss": 14.507695095062257, "batch_reward": 1.8456733150482179, "actor_loss": -202.2851085047568, "actor_target_entropy": -1.0, "actor_entropy": 0.35535054750019507, "alpha_loss": -0.0005026815399046868, "alpha_value": 0.2006786097214599, "duration": 136.88334608078003, "step": 71000}
{"episode_reward": 248.39083638677064, "episode": 569.0, "Q1 loss": 7.167800313949585, "Q2 loss": 7.162938077926635, "Mean Target Q": 201.88953564453124, "Mean Q1": 201.88915795898438, "Mean Q2": 201.88793029785157, "critic_loss": 14.330738418579102, "batch_reward": 1.8136534996032714, "actor_loss": -202.23980446467323, "actor_target_entropy": -1.0, "actor_entropy": 0.3866887414266193, "alpha_loss": -0.0011627901463754594, "alpha_value": 0.2009966654036787, "duration": 130.5803461074829, "step": 71125}
{"episode_reward": 258.0119117452074, "episode": 570.0, "Q1 loss": 7.2450815849304195, "Q2 loss": 7.278169082641601, "Mean Target Q": 202.0212908935547, "Mean Q1": 202.01918176269533, "Mean Q2": 202.01999291992186, "critic_loss": 14.523250648498536, "batch_reward": 1.8133863983154297, "actor_loss": -202.39507958196825, "actor_target_entropy": -1.0, "actor_entropy": 0.34963718585429654, "alpha_loss": 0.003447934085758583, "alpha_value": 0.20093093789118024, "duration": 124.93733024597168, "step": 71250}
{"episode_reward": 325.6162888825224, "episode": 571.0, "Q1 loss": 7.27707612991333, "Q2 loss": 7.261150615692139, "Mean Target Q": 202.08403674316406, "Mean Q1": 202.08286547851563, "Mean Q2": 202.08379833984375, "critic_loss": 14.538226715087891, "batch_reward": 1.8134992532730103, "actor_loss": -202.3407445029607, "actor_target_entropy": -1.0, "actor_entropy": 0.37926754308125327, "alpha_loss": 0.0009278296067985514, "alpha_value": 0.20059344983716348, "duration": 123.36252737045288, "step": 71375}
{"episode_reward": 206.16127821744493, "episode": 572.0, "Q1 loss": 7.123280815124511, "Q2 loss": 7.12678804397583, "Mean Target Q": 202.08179724121095, "Mean Q1": 202.07865991210937, "Mean Q2": 202.07863793945313, "critic_loss": 14.250068916320801, "batch_reward": 1.815607328414917, "actor_loss": -202.4624210480721, "actor_target_entropy": -1.0, "actor_entropy": 0.38964784145355225, "alpha_loss": -0.0008700381337304509, "alpha_value": 0.20064528571564538, "duration": 127.9914448261261, "step": 71500}
{"episode_reward": 264.955415249731, "episode": 573.0, "Q1 loss": 7.236468299865723, "Q2 loss": 7.251734130859375, "Mean Target Q": 202.20457189941405, "Mean Q1": 202.2047360839844, "Mean Q2": 202.2032362060547, "critic_loss": 14.488202423095704, "batch_reward": 1.8272533159255981, "actor_loss": -202.54818338061136, "actor_target_entropy": -1.0, "actor_entropy": 0.34996951714394586, "alpha_loss": -0.004271740182524636, "alpha_value": 0.2008496349222312, "duration": 133.20916104316711, "step": 71625}
{"episode_reward": 213.39342017250362, "episode": 574.0, "Q1 loss": 7.058670993804932, "Q2 loss": 7.03154411315918, "Mean Target Q": 202.21055517578125, "Mean Q1": 202.20975061035156, "Mean Q2": 202.20941162109375, "critic_loss": 14.090215103149415, "batch_reward": 1.8245219535827637, "actor_loss": -202.57769553892075, "actor_target_entropy": -1.0, "actor_entropy": 0.3703895098259372, "alpha_loss": -0.005571525119575521, "alpha_value": 0.201318893843164, "duration": 126.30443072319031, "step": 71750}
{"episode_reward": 320.32339084087636, "episode": 575.0, "Q1 loss": 7.2422177124023435, "Q2 loss": 7.240474449157714, "Mean Target Q": 202.3271123046875, "Mean Q1": 202.32099377441406, "Mean Q2": 202.32106958007813, "critic_loss": 14.482692237854003, "batch_reward": 1.8256119003295899, "actor_loss": -202.6502450609964, "actor_target_entropy": -1.0, "actor_entropy": 0.34381673402256435, "alpha_loss": -0.004000076495613607, "alpha_value": 0.2014742001020792, "duration": 125.38145923614502, "step": 71875}
{"episode_reward": 316.4234736839853, "episode": 576.0, "Q1 loss": 7.279865810394287, "Q2 loss": 7.244041847229004, "Mean Target Q": 202.4264161376953, "Mean Q1": 202.42780212402343, "Mean Q2": 202.4287568359375, "critic_loss": 14.523907646179198, "batch_reward": 1.8186166267395019, "actor_loss": -202.74889299946446, "actor_target_entropy": -1.0, "actor_entropy": 0.3744819265219473, "alpha_loss": 0.00032180761768212243, "alpha_value": 0.20184949544511513, "duration": 130.8206069469452, "step": 72000}
{"episode_reward": 188.81451134273084, "episode": 577.0, "Q1 loss": 7.357335063934326, "Q2 loss": 7.352243183135986, "Mean Target Q": 202.50407299804687, "Mean Q1": 202.49910192871093, "Mean Q2": 202.49935095214843, "critic_loss": 14.709578292846679, "batch_reward": 1.8254508171081543, "actor_loss": -202.839106968471, "actor_target_entropy": -1.0, "actor_entropy": 0.3820080463848417, "alpha_loss": -0.0009244466163513679, "alpha_value": 0.20178831685254056, "duration": 135.846271276474, "step": 72125}
{"episode_reward": 250.41669970315968, "episode": 578.0, "Q1 loss": 7.0853773231506345, "Q2 loss": 7.080545173645019, "Mean Target Q": 202.49870532226564, "Mean Q1": 202.49977416992186, "Mean Q2": 202.49842053222656, "critic_loss": 14.165922523498535, "batch_reward": 1.8328565483093262, "actor_loss": -202.82594250094505, "actor_target_entropy": -1.0, "actor_entropy": 0.38419900786492134, "alpha_loss": 0.0023792475356810517, "alpha_value": 0.20162384966944716, "duration": 147.53749299049377, "step": 72250}
{"episode_reward": 275.7677780077827, "episode": 579.0, "Q1 loss": 7.216242572784424, "Q2 loss": 7.198796215057373, "Mean Target Q": 202.56854370117188, "Mean Q1": 202.57041784667967, "Mean Q2": 202.57111462402344, "critic_loss": 14.415038795471192, "batch_reward": 1.807970685005188, "actor_loss": -202.9081285264757, "actor_target_entropy": -1.0, "actor_entropy": 0.35818867740176974, "alpha_loss": -0.0017531202766039068, "alpha_value": 0.2016447570641754, "duration": 143.49334263801575, "step": 72375}
{"episode_reward": 267.06698320985936, "episode": 580.0, "Q1 loss": 7.007065296173096, "Q2 loss": 6.9918522491455075, "Mean Target Q": 202.68198461914062, "Mean Q1": 202.67521545410156, "Mean Q2": 202.67583850097657, "critic_loss": 13.998917556762695, "batch_reward": 1.8350369920730591, "actor_loss": -203.00184016073905, "actor_target_entropy": -1.0, "actor_entropy": 0.36874270823694044, "alpha_loss": 0.0016725777362984035, "alpha_value": 0.20162473475195827, "duration": 134.95357084274292, "step": 72500}
{"episode_reward": 208.73964820805915, "episode": 581.0, "Q1 loss": 6.8459562530517575, "Q2 loss": 6.840613918304443, "Mean Target Q": 202.71284765625, "Mean Q1": 202.712330078125, "Mean Q2": 202.7119171142578, "critic_loss": 13.686570167541504, "batch_reward": 1.826659317970276, "actor_loss": -203.07165406242248, "actor_target_entropy": -1.0, "actor_entropy": 0.38402615842365084, "alpha_loss": 0.0044041344496820655, "alpha_value": 0.2015435145752132, "duration": 127.7430408000946, "step": 72625}
{"episode_reward": 214.73993049100764, "episode": 582.0, "Q1 loss": 7.1007981224060055, "Q2 loss": 7.076817276000977, "Mean Target Q": 202.82519641113282, "Mean Q1": 202.82705505371095, "Mean Q2": 202.82606726074218, "critic_loss": 14.17761533355713, "batch_reward": 1.8096248321533204, "actor_loss": -203.17415225121283, "actor_target_entropy": -1.0, "actor_entropy": 0.35110037894018237, "alpha_loss": 0.005247177398433128, "alpha_value": 0.20114647965065366, "duration": 135.1904501914978, "step": 72750}
{"episode_reward": 222.338586888382, "episode": 583.0, "Q1 loss": 6.792459133148193, "Q2 loss": 6.834511962890625, "Mean Target Q": 202.85700561523439, "Mean Q1": 202.85476708984376, "Mean Q2": 202.8551044921875, "critic_loss": 13.626971130371095, "batch_reward": 1.8176103773117065, "actor_loss": -203.24415443057106, "actor_target_entropy": -1.0, "actor_entropy": 0.36528597370026605, "alpha_loss": 0.006018710622031774, "alpha_value": 0.20060737673336676, "duration": 134.90727543830872, "step": 72875}
{"episode_reward": 245.46319800226755, "episode": 584.0, "Q1 loss": 6.891735698699951, "Q2 loss": 6.850176544189453, "Mean Target Q": 202.8498800048828, "Mean Q1": 202.84995275878907, "Mean Q2": 202.84968688964844, "critic_loss": 13.74191223526001, "batch_reward": 1.81098370552063, "actor_loss": -203.2389186736076, "actor_target_entropy": -1.0, "actor_entropy": 0.3763814741565335, "alpha_loss": -0.0017815722760954691, "alpha_value": 0.20048440079691174, "duration": 135.01256704330444, "step": 73000}
{"episode_reward": 172.88410560136225, "episode": 585.0, "Q1 loss": 7.082657329559326, "Q2 loss": 7.125604366302491, "Mean Target Q": 202.93184875488282, "Mean Q1": 202.92534228515626, "Mean Q2": 202.92519299316407, "critic_loss": 14.208261711120606, "batch_reward": 1.8193164596557616, "actor_loss": -203.26974729507688, "actor_target_entropy": -1.0, "actor_entropy": 0.37280106024136617, "alpha_loss": 0.002024813237348719, "alpha_value": 0.20041610813171146, "duration": 136.9757890701294, "step": 73125}
{"episode_reward": 265.96134198978416, "episode": 586.0, "Q1 loss": 6.941760303497315, "Q2 loss": 6.9214115295410155, "Mean Target Q": 203.03251623535155, "Mean Q1": 203.03688159179688, "Mean Q2": 203.0370595703125, "critic_loss": 13.863171852111817, "batch_reward": 1.8211325197219848, "actor_loss": -203.35890370030558, "actor_target_entropy": -1.0, "actor_entropy": 0.37779189934653623, "alpha_loss": 0.001813933948024867, "alpha_value": 0.20036851288963436, "duration": 144.6304714679718, "step": 73250}
{"episode_reward": 210.41085607207094, "episode": 587.0, "Q1 loss": 7.244186447143555, "Q2 loss": 7.219644100189209, "Mean Target Q": 202.95706701660157, "Mean Q1": 202.95825622558593, "Mean Q2": 202.95875158691408, "critic_loss": 14.4638304977417, "batch_reward": 1.8151787805557251, "actor_loss": -203.26967100113157, "actor_target_entropy": -1.0, "actor_entropy": 0.35792365291761974, "alpha_loss": 0.00449615858850025, "alpha_value": 0.2000113076307976, "duration": 144.797278881073, "step": 73375}
{"episode_reward": 223.28979709736916, "episode": 588.0, "Q1 loss": 7.052081924438476, "Q2 loss": 7.0473446311950685, "Mean Target Q": 203.14556994628907, "Mean Q1": 203.14169665527345, "Mean Q2": 203.14093493652345, "critic_loss": 14.099426666259765, "batch_reward": 1.8348830394744873, "actor_loss": -203.46236025902533, "actor_target_entropy": -1.0, "actor_entropy": 0.34779251438956105, "alpha_loss": 0.004542614723886213, "alpha_value": 0.19978256881619505, "duration": 122.41558456420898, "step": 73500}
{"episode_reward": 232.83168092843366, "episode": 589.0, "Q1 loss": 7.028507322311401, "Q2 loss": 7.050986879348755, "Mean Target Q": 203.0809835205078, "Mean Q1": 203.07692907714843, "Mean Q2": 203.07787866210938, "critic_loss": 14.07949422454834, "batch_reward": 1.8135837001800537, "actor_loss": -203.44444202241442, "actor_target_entropy": -1.0, "actor_entropy": 0.3572164419151488, "alpha_loss": 0.005561975522025946, "alpha_value": 0.19922223015177937, "duration": 134.56143712997437, "step": 73625}
{"episode_reward": 260.1344358330869, "episode": 590.0, "Q1 loss": 6.88141206741333, "Q2 loss": 6.894296653747559, "Mean Target Q": 203.17208349609376, "Mean Q1": 203.17086596679687, "Mean Q2": 203.17096533203124, "critic_loss": 13.775708713531493, "batch_reward": 1.8142265920639038, "actor_loss": -203.50455425631614, "actor_target_entropy": -1.0, "actor_entropy": 0.38014856990306606, "alpha_loss": 0.004865138188770581, "alpha_value": 0.1988771258110463, "duration": 136.5781192779541, "step": 73750}
{"episode_reward": 221.23174008752267, "episode": 591.0, "Q1 loss": 6.678031768798828, "Q2 loss": 6.6553945732116695, "Mean Target Q": 203.21657885742187, "Mean Q1": 203.21592846679687, "Mean Q2": 203.21556909179688, "critic_loss": 13.333426345825195, "batch_reward": 1.827090524673462, "actor_loss": -203.63633558485242, "actor_target_entropy": -1.0, "actor_entropy": 0.3698880301108436, "alpha_loss": -0.0022538574763558924, "alpha_value": 0.19864754085413472, "duration": 125.93902897834778, "step": 73875}
{"episode_reward": 241.33374708044923, "episode": 592.0, "Q1 loss": 6.78676477432251, "Q2 loss": 6.763431507110596, "Mean Target Q": 203.34308862304687, "Mean Q1": 203.34032006835938, "Mean Q2": 203.3412049560547, "critic_loss": 13.55019627380371, "batch_reward": 1.832098027229309, "actor_loss": -203.71280867053616, "actor_target_entropy": -1.0, "actor_entropy": 0.35920508253958916, "alpha_loss": 0.0021172670700076606, "alpha_value": 0.1986528565942333, "duration": 151.30575680732727, "step": 74000}
{"episode_reward": 309.61187381597574, "episode": 593.0, "Q1 loss": 6.9126907081604, "Q2 loss": 6.872561759948731, "Mean Target Q": 203.33646398925782, "Mean Q1": 203.33867553710937, "Mean Q2": 203.33828833007811, "critic_loss": 13.78525244140625, "batch_reward": 1.825806827545166, "actor_loss": -203.73663184756325, "actor_target_entropy": -1.0, "actor_entropy": 0.36978485376115827, "alpha_loss": 0.0009746481701436024, "alpha_value": 0.19861656268505604, "duration": 147.28300023078918, "step": 74125}
{"episode_reward": 247.4222590680267, "episode": 594.0, "Q1 loss": 6.875404567718506, "Q2 loss": 6.8723125171661374, "Mean Target Q": 203.29138049316407, "Mean Q1": 203.2878839111328, "Mean Q2": 203.28764965820312, "critic_loss": 13.747717071533204, "batch_reward": 1.8136428594589233, "actor_loss": -203.59391686224168, "actor_target_entropy": -1.0, "actor_entropy": 0.3713472173098595, "alpha_loss": 0.0012087465278924473, "alpha_value": 0.19860653123910377, "duration": 133.3314175605774, "step": 74250}
{"episode_reward": 241.5485067563767, "episode": 595.0, "Q1 loss": 6.731813293457031, "Q2 loss": 6.729022026062012, "Mean Target Q": 203.29478723144533, "Mean Q1": 203.29373291015625, "Mean Q2": 203.29239331054688, "critic_loss": 13.460835334777832, "batch_reward": 1.8056692428588867, "actor_loss": -203.5979461669922, "actor_target_entropy": -1.0, "actor_entropy": 0.3669463552179791, "alpha_loss": 0.0033748267599130197, "alpha_value": 0.19844678888348677, "duration": 139.4466986656189, "step": 74375}
{"episode_reward": 223.8337376973179, "episode": 596.0, "Q1 loss": 7.2493289222717285, "Q2 loss": 7.275218936920166, "Mean Target Q": 203.41991748046874, "Mean Q1": 203.41811096191407, "Mean Q2": 203.41961193847655, "critic_loss": 14.52454783630371, "batch_reward": 1.8222630672454834, "actor_loss": -203.72426162227507, "actor_target_entropy": -1.0, "actor_entropy": 0.33930823303038077, "alpha_loss": 0.003915834469690679, "alpha_value": 0.19815923915079123, "duration": 137.65871667861938, "step": 74500}
{"episode_reward": 255.2356124234226, "episode": 597.0, "Q1 loss": 7.108606826782227, "Q2 loss": 7.094884704589844, "Mean Target Q": 203.47526806640624, "Mean Q1": 203.47609655761718, "Mean Q2": 203.47569104003907, "critic_loss": 14.203491554260253, "batch_reward": 1.8224125537872315, "actor_loss": -203.8223126123822, "actor_target_entropy": -1.0, "actor_entropy": 0.3456499373155927, "alpha_loss": -0.0013708984996709558, "alpha_value": 0.19808027177619555, "duration": 142.9576804637909, "step": 74625}
{"episode_reward": 194.14096400471635, "episode": 598.0, "Q1 loss": 7.1283714294433596, "Q2 loss": 7.097195007324219, "Mean Target Q": 203.48635705566406, "Mean Q1": 203.4822947998047, "Mean Q2": 203.48297985839844, "critic_loss": 14.225566413879395, "batch_reward": 1.8224329624176026, "actor_loss": -203.8378923477665, "actor_target_entropy": -1.0, "actor_entropy": 0.36875219835389045, "alpha_loss": 0.0032536530146195044, "alpha_value": 0.19793401221787493, "duration": 140.37956309318542, "step": 74750}
{"episode_reward": 176.84074123786905, "episode": 599.0, "Q1 loss": 7.290643283843994, "Q2 loss": 7.224356632232666, "Mean Target Q": 203.5316075439453, "Mean Q1": 203.52740893554687, "Mean Q2": 203.52437744140624, "critic_loss": 14.514999870300294, "batch_reward": 1.8243280000686646, "actor_loss": -203.92050122457837, "actor_target_entropy": -1.0, "actor_entropy": 0.3532171469359171, "alpha_loss": -0.004228082115924548, "alpha_value": 0.1978876484349708, "duration": 126.76920557022095, "step": 74875}
{"episode_reward": 252.3419523244158, "episode": 600.0, "Q1 loss": 6.8533407440185545, "Q2 loss": 6.910127222061157, "Mean Target Q": 203.67281042480468, "Mean Q1": 203.68013818359375, "Mean Q2": 203.68373022460938, "critic_loss": 13.763468002319335, "batch_reward": 1.8252551622390747, "actor_loss": -204.01473285305886, "actor_target_entropy": -1.0, "actor_entropy": 0.3712464835374586, "alpha_loss": 0.008235926768036498, "alpha_value": 0.1976914926024155, "step": 75000}
{"duration": 155.25533771514893, "step": 75000}
{"episode_reward": 200.25481005006074, "episode": 601.0, "Q1 loss": 7.286736766815186, "Q2 loss": 7.253034069061279, "Mean Target Q": 203.76116772460938, "Mean Q1": 203.75573559570313, "Mean Q2": 203.75459155273438, "critic_loss": 14.539770858764648, "batch_reward": 1.8360812845230103, "actor_loss": -204.1107148670015, "actor_target_entropy": -1.0, "actor_entropy": 0.38565892738009255, "alpha_loss": 4.928150317735142e-05, "alpha_value": 0.1974566977248752, "duration": 131.4988763332367, "step": 75125}
{"episode_reward": 263.7150110506351, "episode": 602.0, "Q1 loss": 7.190084091186524, "Q2 loss": 7.216397930145264, "Mean Target Q": 203.6552431640625, "Mean Q1": 203.65939233398439, "Mean Q2": 203.65854150390626, "critic_loss": 14.406482040405274, "batch_reward": 1.8271928777694701, "actor_loss": -203.95547066965412, "actor_target_entropy": -1.0, "actor_entropy": 0.3616560918669547, "alpha_loss": 0.003340058943121544, "alpha_value": 0.19742937099627828, "duration": 132.86390209197998, "step": 75250}
{"episode_reward": 252.87745546836584, "episode": 603.0, "Q1 loss": 7.684613342285156, "Q2 loss": 7.691895622253418, "Mean Target Q": 203.77772937011719, "Mean Q1": 203.7701064453125, "Mean Q2": 203.76997424316406, "critic_loss": 15.376508972167969, "batch_reward": 1.823633363723755, "actor_loss": -204.13614545549666, "actor_target_entropy": -1.0, "actor_entropy": 0.331165365046925, "alpha_loss": 0.001492115609820873, "alpha_value": 0.19723991893309747, "duration": 125.63796901702881, "step": 75375}
{"episode_reward": 324.2009702067941, "episode": 604.0, "Q1 loss": 7.15854744720459, "Q2 loss": 7.09613688659668, "Mean Target Q": 203.7470987548828, "Mean Q1": 203.74356982421875, "Mean Q2": 203.74298742675782, "critic_loss": 14.254684387207032, "batch_reward": 1.8310033044815064, "actor_loss": -204.0674539381458, "actor_target_entropy": -1.0, "actor_entropy": 0.36525411134765995, "alpha_loss": 0.006373716912592852, "alpha_value": 0.19685922866120306, "duration": 136.2659010887146, "step": 75500}
{"episode_reward": 223.65983241889955, "episode": 605.0, "Q1 loss": 7.254630006790161, "Q2 loss": 7.2249247856140135, "Mean Target Q": 203.79591247558594, "Mean Q1": 203.7961827392578, "Mean Q2": 203.7975653076172, "critic_loss": 14.479554779052734, "batch_reward": 1.8292661714553833, "actor_loss": -204.12217833503846, "actor_target_entropy": -1.0, "actor_entropy": 0.35911301819104996, "alpha_loss": 0.0013769706489429588, "alpha_value": 0.1965996122971913, "duration": 138.78407907485962, "step": 75625}
{"episode_reward": 278.2228239079543, "episode": 606.0, "Q1 loss": 6.756722948074341, "Q2 loss": 6.823470050811768, "Mean Target Q": 203.92358581542967, "Mean Q1": 203.9221483154297, "Mean Q2": 203.9216817626953, "critic_loss": 13.580192977905273, "batch_reward": 1.8320543394088744, "actor_loss": -204.25825648153983, "actor_target_entropy": -1.0, "actor_entropy": 0.3486678472930385, "alpha_loss": -4.7399730031048096e-05, "alpha_value": 0.19642660142206628, "duration": 138.25746059417725, "step": 75750}
{"episode_reward": 240.74227175073298, "episode": 607.0, "Q1 loss": 7.236495616912841, "Q2 loss": 7.281770606994629, "Mean Target Q": 203.92634765625, "Mean Q1": 203.9234249267578, "Mean Q2": 203.92419873046876, "critic_loss": 14.518266159057617, "batch_reward": 1.8214741773605347, "actor_loss": -204.27255491226438, "actor_target_entropy": -1.0, "actor_entropy": 0.3720294327016861, "alpha_loss": 0.003966392675739905, "alpha_value": 0.19647033256224358, "duration": 132.07390522956848, "step": 75875}
{"episode_reward": 210.49066350552704, "episode": 608.0, "Q1 loss": 7.110654903411866, "Q2 loss": 7.0907315788269045, "Mean Target Q": 203.95377770996095, "Mean Q1": 203.95930932617188, "Mean Q2": 203.95713635253907, "critic_loss": 14.201386512756347, "batch_reward": 1.8228116102218628, "actor_loss": -204.28516264884703, "actor_target_entropy": -1.0, "actor_entropy": 0.3612800947120113, "alpha_loss": 0.002111007534568348, "alpha_value": 0.1960034719819937, "duration": 125.9901967048645, "step": 76000}
{"episode_reward": 246.52936064617947, "episode": 609.0, "Q1 loss": 7.079497375488281, "Q2 loss": 7.0188743019104, "Mean Target Q": 204.0458328857422, "Mean Q1": 204.04158642578125, "Mean Q2": 204.0436903076172, "critic_loss": 14.098371643066406, "batch_reward": 1.82677250289917, "actor_loss": -204.36139158218626, "actor_target_entropy": -1.0, "actor_entropy": 0.36746567866158864, "alpha_loss": -0.0007371912241011621, "alpha_value": 0.19599797061365845, "duration": 136.65639448165894, "step": 76125}
{"episode_reward": 142.58323067860988, "episode": 610.0, "Q1 loss": 7.311603984832764, "Q2 loss": 7.370110893249512, "Mean Target Q": 203.9884197998047, "Mean Q1": 203.98357885742186, "Mean Q2": 203.9824930419922, "critic_loss": 14.681714851379395, "batch_reward": 1.8303101720809936, "actor_loss": -204.3003188102476, "actor_target_entropy": -1.0, "actor_entropy": 0.3378716123200232, "alpha_loss": -0.0024484219883884033, "alpha_value": 0.19616840551551787, "duration": 139.32119035720825, "step": 76250}
{"episode_reward": 167.22889321477368, "episode": 611.0, "Q1 loss": 7.220586189270019, "Q2 loss": 7.180402450561523, "Mean Target Q": 204.11879968261718, "Mean Q1": 204.11914123535155, "Mean Q2": 204.11978430175782, "critic_loss": 14.40098868560791, "batch_reward": 1.8396790685653686, "actor_loss": -204.46666293674045, "actor_target_entropy": -1.0, "actor_entropy": 0.357441497700555, "alpha_loss": -0.002936665438086031, "alpha_value": 0.19645043438979604, "duration": 135.12026143074036, "step": 76375}
{"episode_reward": 237.78940794110318, "episode": 612.0, "Q1 loss": 7.515321113586426, "Q2 loss": 7.496894332885742, "Mean Target Q": 204.152669921875, "Mean Q1": 204.15375073242188, "Mean Q2": 204.15396252441406, "critic_loss": 15.012215431213379, "batch_reward": 1.8303858251571656, "actor_loss": -204.46268069359564, "actor_target_entropy": -1.0, "actor_entropy": 0.36189095411569844, "alpha_loss": -0.002364922160913627, "alpha_value": 0.196677397440929, "duration": 139.27158164978027, "step": 76500}
{"episode_reward": 233.65674034447468, "episode": 613.0, "Q1 loss": 7.239008975982666, "Q2 loss": 7.230419521331787, "Mean Target Q": 204.17566870117187, "Mean Q1": 204.17550830078125, "Mean Q2": 204.17502404785157, "critic_loss": 14.469428550720215, "batch_reward": 1.8275402946472168, "actor_loss": -204.54346066429503, "actor_target_entropy": -1.0, "actor_entropy": 0.3480251935266313, "alpha_loss": -0.0035078692405174174, "alpha_value": 0.19678653476495117, "duration": 148.46569919586182, "step": 76625}
{"episode_reward": 270.48486821218455, "episode": 614.0, "Q1 loss": 7.194208236694336, "Q2 loss": 7.131749095916748, "Mean Target Q": 204.3097559814453, "Mean Q1": 204.31145385742187, "Mean Q2": 204.3106876220703, "critic_loss": 14.325957412719726, "batch_reward": 1.8290644359588624, "actor_loss": -204.62220641105407, "actor_target_entropy": -1.0, "actor_entropy": 0.342308865199166, "alpha_loss": 0.003110686660699186, "alpha_value": 0.19696699359428352, "duration": 139.1243371963501, "step": 76750}
{"episode_reward": 222.1541042119216, "episode": 615.0, "Q1 loss": 6.83929434967041, "Q2 loss": 6.8517975463867185, "Mean Target Q": 204.37405969238282, "Mean Q1": 204.37112841796875, "Mean Q2": 204.37169702148438, "critic_loss": 13.691091941833497, "batch_reward": 1.8344427585601806, "actor_loss": -204.7363995748853, "actor_target_entropy": -1.0, "actor_entropy": 0.35253287355105084, "alpha_loss": -0.002593639580207685, "alpha_value": 0.19681324700764827, "duration": 127.4672064781189, "step": 76875}
{"episode_reward": 230.16905712444776, "episode": 616.0, "Q1 loss": 7.163445201873779, "Q2 loss": 7.203158832550049, "Mean Target Q": 204.3612537841797, "Mean Q1": 204.35331787109374, "Mean Q2": 204.35265148925782, "critic_loss": 14.366604034423828, "batch_reward": 1.8321317720413208, "actor_loss": -204.73576182703817, "actor_target_entropy": -1.0, "actor_entropy": 0.34074397216881475, "alpha_loss": -0.0015133045944235018, "alpha_value": 0.1971371704514413, "duration": 140.10893201828003, "step": 77000}
{"episode_reward": 219.94138915814537, "episode": 617.0, "Q1 loss": 7.381355556488037, "Q2 loss": 7.383170555114746, "Mean Target Q": 204.34015893554687, "Mean Q1": 204.34124621582032, "Mean Q2": 204.34116674804687, "critic_loss": 14.764526161193848, "batch_reward": 1.8045767707824707, "actor_loss": -204.6801241920108, "actor_target_entropy": -1.0, "actor_entropy": 0.36862803546209183, "alpha_loss": -0.002256387859464638, "alpha_value": 0.19707818985817413, "duration": 124.95456218719482, "step": 77125}
{"episode_reward": 211.08865989296427, "episode": 618.0, "Q1 loss": 7.049674716949463, "Q2 loss": 7.082260910034179, "Mean Target Q": 204.40311462402343, "Mean Q1": 204.40626794433595, "Mean Q2": 204.40634130859374, "critic_loss": 14.131935638427734, "batch_reward": 1.8226109628677367, "actor_loss": -204.776981722924, "actor_target_entropy": -1.0, "actor_entropy": 0.35936880255899123, "alpha_loss": 0.0019716334551753054, "alpha_value": 0.19714374735937248, "duration": 143.06489372253418, "step": 77250}
{"episode_reward": 277.9264924062317, "episode": 619.0, "Q1 loss": 7.280972980499268, "Q2 loss": 7.266125621795655, "Mean Target Q": 204.47982666015625, "Mean Q1": 204.47423571777344, "Mean Q2": 204.47475341796874, "critic_loss": 14.547098571777344, "batch_reward": 1.8379695119857788, "actor_loss": -204.86134919666108, "actor_target_entropy": -1.0, "actor_entropy": 0.36940455578622367, "alpha_loss": -0.004582379933535343, "alpha_value": 0.19733499286777995, "duration": 150.71575903892517, "step": 77375}
{"episode_reward": 263.03517583887367, "episode": 620.0, "Q1 loss": 7.3524645271301265, "Q2 loss": 7.303280029296875, "Mean Target Q": 204.41563171386719, "Mean Q1": 204.41554528808595, "Mean Q2": 204.41564855957031, "critic_loss": 14.655744537353515, "batch_reward": 1.8200495834350585, "actor_loss": -204.84554930656188, "actor_target_entropy": -1.0, "actor_entropy": 0.34261931959659825, "alpha_loss": -0.008120833283981247, "alpha_value": 0.1978015509790779, "duration": 136.89973402023315, "step": 77500}
{"episode_reward": 249.71173893697176, "episode": 621.0, "Q1 loss": 7.342920337677002, "Q2 loss": 7.342226432800293, "Mean Target Q": 204.54017150878906, "Mean Q1": 204.53836254882813, "Mean Q2": 204.53781994628906, "critic_loss": 14.68514680480957, "batch_reward": 1.825903151512146, "actor_loss": -204.92275104825458, "actor_target_entropy": -1.0, "actor_entropy": 0.34624308229438844, "alpha_loss": 0.005671590123148192, "alpha_value": 0.19787254937922835, "duration": 125.23072052001953, "step": 77625}
{"episode_reward": 249.10281384108944, "episode": 622.0, "Q1 loss": 7.314823112487793, "Q2 loss": 7.357841354370117, "Mean Target Q": 204.49089636230468, "Mean Q1": 204.49638354492188, "Mean Q2": 204.49577001953125, "critic_loss": 14.672664375305176, "batch_reward": 1.827727954864502, "actor_loss": -204.85895070722026, "actor_target_entropy": -1.0, "actor_entropy": 0.3618446684652759, "alpha_loss": 0.0016321665306966151, "alpha_value": 0.19760599630381606, "duration": 141.56303453445435, "step": 77750}
{"episode_reward": 286.5981411640875, "episode": 623.0, "Q1 loss": 7.152736488342285, "Q2 loss": 7.124231311798096, "Mean Target Q": 204.58513732910157, "Mean Q1": 204.57550231933592, "Mean Q2": 204.57570849609374, "critic_loss": 14.276967826843261, "batch_reward": 1.8356901559829713, "actor_loss": -204.9609081934369, "actor_target_entropy": -1.0, "actor_entropy": 0.36288398646173026, "alpha_loss": -0.0026441115982061814, "alpha_value": 0.19759044066088954, "duration": 132.11588883399963, "step": 77875}
{"episode_reward": 189.20059136676167, "episode": 624.0, "Q1 loss": 7.138370182037353, "Q2 loss": 7.167979316711426, "Mean Target Q": 204.6750489501953, "Mean Q1": 204.67922119140624, "Mean Q2": 204.6789793701172, "critic_loss": 14.306349594116211, "batch_reward": 1.834625475883484, "actor_loss": -204.98226830267137, "actor_target_entropy": -1.0, "actor_entropy": 0.3218888452937526, "alpha_loss": 0.0008522524731233716, "alpha_value": 0.19772581711875692, "duration": 134.19132542610168, "step": 78000}
{"episode_reward": 253.39950148739408, "episode": 625.0, "Q1 loss": 7.182960075378418, "Q2 loss": 7.2174170799255375, "Mean Target Q": 204.62240295410157, "Mean Q1": 204.6187423095703, "Mean Q2": 204.619365234375, "critic_loss": 14.40037713623047, "batch_reward": 1.8290340843200683, "actor_loss": -205.02628629169766, "actor_target_entropy": -1.0, "actor_entropy": 0.3464383033532945, "alpha_loss": 0.00038066361882975176, "alpha_value": 0.1975485259166343, "duration": 137.81541967391968, "step": 78125}
{"episode_reward": 276.90463845377906, "episode": 626.0, "Q1 loss": 6.959435081481933, "Q2 loss": 6.9462591133117675, "Mean Target Q": 204.71965234375, "Mean Q1": 204.72290502929687, "Mean Q2": 204.72234753417968, "critic_loss": 13.905694160461426, "batch_reward": 1.8297321720123292, "actor_loss": -205.03190071352066, "actor_target_entropy": -1.0, "actor_entropy": 0.3575093428934774, "alpha_loss": 0.002113453803523894, "alpha_value": 0.1975633397411715, "duration": 132.98142790794373, "step": 78250}
{"episode_reward": 192.3253538674897, "episode": 627.0, "Q1 loss": 7.1750087890625, "Q2 loss": 7.221152088165283, "Mean Target Q": 204.71730529785157, "Mean Q1": 204.71244982910156, "Mean Q2": 204.71269885253906, "critic_loss": 14.396160942077637, "batch_reward": 1.8349294919967651, "actor_loss": -205.06558615063864, "actor_target_entropy": -1.0, "actor_entropy": 0.36518736538432894, "alpha_loss": 2.864100748584384e-05, "alpha_value": 0.1973564082276174, "duration": 142.565092086792, "step": 78375}
{"episode_reward": 235.93500813969715, "episode": 628.0, "Q1 loss": 6.889068946838379, "Q2 loss": 6.919670055389404, "Mean Target Q": 204.82134313964843, "Mean Q1": 204.8222236328125, "Mean Q2": 204.82198669433595, "critic_loss": 13.808739028930663, "batch_reward": 1.8333115005493164, "actor_loss": -205.20694954164566, "actor_target_entropy": -1.0, "actor_entropy": 0.34805157876783804, "alpha_loss": 0.003989066613177138, "alpha_value": 0.19726420302429717, "duration": 148.09204053878784, "step": 78500}
{"episode_reward": 284.5602675085695, "episode": 629.0, "Q1 loss": 7.2231785087585445, "Q2 loss": 7.21167077255249, "Mean Target Q": 204.83018701171875, "Mean Q1": 204.82939575195311, "Mean Q2": 204.82924438476562, "critic_loss": 14.434849266052247, "batch_reward": 1.8342889041900634, "actor_loss": -205.1569298638238, "actor_target_entropy": -1.0, "actor_entropy": 0.3491296732709521, "alpha_loss": -0.0007196580325918538, "alpha_value": 0.1972951110449977, "duration": 146.74660873413086, "step": 78625}
{"episode_reward": 245.91783956364546, "episode": 630.0, "Q1 loss": 6.81191739654541, "Q2 loss": 6.785818027496338, "Mean Target Q": 204.99067028808594, "Mean Q1": 204.9909530029297, "Mean Q2": 204.9908341064453, "critic_loss": 13.597735404968262, "batch_reward": 1.831660140991211, "actor_loss": -205.25902262041646, "actor_target_entropy": -1.0, "actor_entropy": 0.36390082730400947, "alpha_loss": 0.004599816109534473, "alpha_value": 0.19694425456427705, "duration": 151.58611750602722, "step": 78750}
{"episode_reward": 198.62680541291152, "episode": 631.0, "Q1 loss": 6.698664758682251, "Q2 loss": 6.709551578521729, "Mean Target Q": 204.93664697265626, "Mean Q1": 204.93228405761718, "Mean Q2": 204.93261633300781, "critic_loss": 13.408216300964355, "batch_reward": 1.819960594177246, "actor_loss": -205.2558082701668, "actor_target_entropy": -1.0, "actor_entropy": 0.3445554432414827, "alpha_loss": -0.006706560148842751, "alpha_value": 0.19710357032628892, "duration": 127.16191267967224, "step": 78875}
{"episode_reward": 280.20694099484984, "episode": 632.0, "Q1 loss": 7.34207597732544, "Q2 loss": 7.325681949615478, "Mean Target Q": 205.04632641601563, "Mean Q1": 205.0476954345703, "Mean Q2": 205.04809765625, "critic_loss": 14.66775796508789, "batch_reward": 1.8350882606506347, "actor_loss": -205.42564490533644, "actor_target_entropy": -1.0, "actor_entropy": 0.3490338820603586, "alpha_loss": 0.0010243762967987887, "alpha_value": 0.19740012195367782, "duration": 121.63272619247437, "step": 79000}
{"episode_reward": 325.7530062721599, "episode": 633.0, "Q1 loss": 7.627839092254638, "Q2 loss": 7.675835731506347, "Mean Target Q": 204.98874560546875, "Mean Q1": 204.98521716308593, "Mean Q2": 204.98557885742187, "critic_loss": 15.303674812316894, "batch_reward": 1.8394972867965698, "actor_loss": -205.32555885920448, "actor_target_entropy": -1.0, "actor_entropy": 0.3312191681729423, "alpha_loss": 0.00020320312164369083, "alpha_value": 0.19728377838933722, "duration": 113.68076825141907, "step": 79125}
{"episode_reward": 271.569935472694, "episode": 634.0, "Q1 loss": 7.58821817779541, "Q2 loss": 7.621729553222656, "Mean Target Q": 205.01638647460936, "Mean Q1": 205.01433740234376, "Mean Q2": 205.0131114501953, "critic_loss": 15.20994775390625, "batch_reward": 1.825952283859253, "actor_loss": -205.36153854862337, "actor_target_entropy": -1.0, "actor_entropy": 0.35248109650227333, "alpha_loss": 0.000665233519318844, "alpha_value": 0.19722661596767285, "duration": 135.48228812217712, "step": 79250}
{"episode_reward": 285.36039365818647, "episode": 635.0, "Q1 loss": 7.447555854797363, "Q2 loss": 7.463290863037109, "Mean Target Q": 205.14527758789063, "Mean Q1": 205.14446801757813, "Mean Q2": 205.14471630859376, "critic_loss": 14.91084666442871, "batch_reward": 1.8391671314239502, "actor_loss": -205.4221445719401, "actor_target_entropy": -1.0, "actor_entropy": 0.3595108754105038, "alpha_loss": -0.003998825208298744, "alpha_value": 0.1973976123259484, "duration": 127.28436756134033, "step": 79375}
{"episode_reward": 235.01984654840587, "episode": 636.0, "Q1 loss": 7.173179714202881, "Q2 loss": 7.179679710388184, "Mean Target Q": 205.13227746582032, "Mean Q1": 205.13166918945313, "Mean Q2": 205.1317548828125, "critic_loss": 14.352859428405761, "batch_reward": 1.832080273628235, "actor_loss": -205.45762486611642, "actor_target_entropy": -1.0, "actor_entropy": 0.3279354327148007, "alpha_loss": 0.0014866101405312938, "alpha_value": 0.19758616738611795, "duration": 123.98897790908813, "step": 79500}
{"episode_reward": 277.6890736980748, "episode": 637.0, "Q1 loss": 6.918312915802002, "Q2 loss": 6.926914264678955, "Mean Target Q": 205.08044665527345, "Mean Q1": 205.08169274902343, "Mean Q2": 205.08106591796874, "critic_loss": 13.84522723388672, "batch_reward": 1.8234299955368043, "actor_loss": -205.40641348702567, "actor_target_entropy": -1.0, "actor_entropy": 0.3532560962060141, "alpha_loss": 0.0011910707283292025, "alpha_value": 0.19732457940846582, "duration": 109.37971186637878, "step": 79625}
{"episode_reward": 192.42117938668895, "episode": 638.0, "Q1 loss": 7.148372779846191, "Q2 loss": 7.121027309417725, "Mean Target Q": 205.2270266113281, "Mean Q1": 205.22260803222656, "Mean Q2": 205.22302380371093, "critic_loss": 14.269400024414063, "batch_reward": 1.8293957738876343, "actor_loss": -205.62667575959236, "actor_target_entropy": -1.0, "actor_entropy": 0.34366670659472864, "alpha_loss": -0.001347689205900796, "alpha_value": 0.19725325235042654, "duration": 107.83528971672058, "step": 79750}
{"episode_reward": 235.1708485869949, "episode": 639.0, "Q1 loss": 7.387622722625732, "Q2 loss": 7.363040534973145, "Mean Target Q": 205.30647314453125, "Mean Q1": 205.30517126464844, "Mean Q2": 205.30602856445313, "critic_loss": 14.750663230895997, "batch_reward": 1.8288311595916749, "actor_loss": -205.6814703562903, "actor_target_entropy": -1.0, "actor_entropy": 0.33564135432243347, "alpha_loss": 0.004286354969418238, "alpha_value": 0.19729378333433759, "duration": 121.5447940826416, "step": 79875}
{"episode_reward": 186.2005588199212, "episode": 640.0, "Q1 loss": 7.228549282073975, "Q2 loss": 7.243088451385498, "Mean Target Q": 205.32514379882812, "Mean Q1": 205.32578833007813, "Mean Q2": 205.32465087890625, "critic_loss": 14.4716376953125, "batch_reward": 1.8204183330535888, "actor_loss": -205.66346002394152, "actor_target_entropy": -1.0, "actor_entropy": 0.33186384867275914, "alpha_loss": -0.003630761654236384, "alpha_value": 0.1973602501445985, "step": 80000}
{"duration": 137.26925230026245, "step": 80000}
{"episode_reward": 218.67434336151868, "episode": 641.0, "Q1 loss": 7.194681827545166, "Q2 loss": 7.153934684753418, "Mean Target Q": 205.30542102050782, "Mean Q1": 205.30005139160156, "Mean Q2": 205.30055004882811, "critic_loss": 14.348616485595704, "batch_reward": 1.824900664329529, "actor_loss": -205.72401355561755, "actor_target_entropy": -1.0, "actor_entropy": 0.33561611317452933, "alpha_loss": -0.010485406455007337, "alpha_value": 0.19784750405300877, "duration": 107.218177318573, "step": 80125}
{"episode_reward": 314.53972850247135, "episode": 642.0, "Q1 loss": 7.164849460601807, "Q2 loss": 7.166244480133057, "Mean Target Q": 205.46594165039062, "Mean Q1": 205.46836120605468, "Mean Q2": 205.46909423828126, "critic_loss": 14.331093894958496, "batch_reward": 1.8320008602142335, "actor_loss": -205.83454993463332, "actor_target_entropy": -1.0, "actor_entropy": 0.3436931025597357, "alpha_loss": -0.0040407003158883705, "alpha_value": 0.19829783450808797, "duration": 115.61720705032349, "step": 80250}
{"episode_reward": 179.37324744220496, "episode": 643.0, "Q1 loss": 7.360259372711182, "Q2 loss": 7.388721435546875, "Mean Target Q": 205.39823461914062, "Mean Q1": 205.39488073730467, "Mean Q2": 205.39362890625, "critic_loss": 14.748980766296386, "batch_reward": 1.8334419403076172, "actor_loss": -205.74260990203373, "actor_target_entropy": -1.0, "actor_entropy": 0.3506147315104802, "alpha_loss": 0.0008130946957934943, "alpha_value": 0.19856157775859778, "duration": 121.97892594337463, "step": 80375}
{"episode_reward": 248.29108921252444, "episode": 644.0, "Q1 loss": 7.291841766357422, "Q2 loss": 7.288520988464356, "Mean Target Q": 205.449431640625, "Mean Q1": 205.4546746826172, "Mean Q2": 205.45498278808594, "critic_loss": 14.58036270904541, "batch_reward": 1.8165067348480224, "actor_loss": -205.8863043016003, "actor_target_entropy": -1.0, "actor_entropy": 0.34904738347376546, "alpha_loss": 0.0001455745190351961, "alpha_value": 0.19845873099162645, "duration": 113.14890503883362, "step": 80500}
{"episode_reward": 274.41341284300654, "episode": 645.0, "Q1 loss": 7.146126247406006, "Q2 loss": 7.128472434997558, "Mean Target Q": 205.5786710205078, "Mean Q1": 205.56994567871095, "Mean Q2": 205.56921936035155, "critic_loss": 14.274598693847656, "batch_reward": 1.8419123487472535, "actor_loss": -205.91844492109996, "actor_target_entropy": -1.0, "actor_entropy": 0.3738316124866879, "alpha_loss": 0.001479488095298173, "alpha_value": 0.19829608572833532, "duration": 127.88185214996338, "step": 80625}
{"episode_reward": 239.95143317883094, "episode": 646.0, "Q1 loss": 7.290030609130859, "Q2 loss": 7.281970573425293, "Mean Target Q": 205.4801854248047, "Mean Q1": 205.48467163085937, "Mean Q2": 205.48593676757812, "critic_loss": 14.572001213073731, "batch_reward": 1.832029041290283, "actor_loss": -205.80013939642137, "actor_target_entropy": -1.0, "actor_entropy": 0.33519874801558835, "alpha_loss": 0.008165683893997583, "alpha_value": 0.19796711878750062, "duration": 118.75536370277405, "step": 80750}
{"episode_reward": 281.5183095588532, "episode": 647.0, "Q1 loss": 7.066030654907227, "Q2 loss": 7.016147876739502, "Mean Target Q": 205.56546850585937, "Mean Q1": 205.5649943847656, "Mean Q2": 205.56357604980468, "critic_loss": 14.082178482055664, "batch_reward": 1.8258049392700195, "actor_loss": -205.88931661938864, "actor_target_entropy": -1.0, "actor_entropy": 0.3479635687101455, "alpha_loss": -0.0034664737371106944, "alpha_value": 0.19776158142187486, "duration": 134.42946600914001, "step": 80875}
{"episode_reward": 190.58157750217185, "episode": 648.0, "Q1 loss": 7.432744911193848, "Q2 loss": 7.400148105621338, "Mean Target Q": 205.7150771484375, "Mean Q1": 205.7127598876953, "Mean Q2": 205.71419763183593, "critic_loss": 14.83289298248291, "batch_reward": 1.8341749849319458, "actor_loss": -206.09365426340412, "actor_target_entropy": -1.0, "actor_entropy": 0.36966224014759064, "alpha_loss": 0.00010093743161809059, "alpha_value": 0.1979614813334591, "duration": 128.3633327484131, "step": 81000}
{"episode_reward": 184.71910878330831, "episode": 649.0, "Q1 loss": 6.9562251701354985, "Q2 loss": 6.998606605529785, "Mean Target Q": 205.66512072753906, "Mean Q1": 205.66376013183594, "Mean Q2": 205.66316979980468, "critic_loss": 13.95483180999756, "batch_reward": 1.820869791984558, "actor_loss": -206.05107867528523, "actor_target_entropy": -1.0, "actor_entropy": 0.36486338244544136, "alpha_loss": -0.00030243353519056527, "alpha_value": 0.1979893341434742, "duration": 124.9127721786499, "step": 81125}
{"episode_reward": 245.142295156385, "episode": 650.0, "Q1 loss": 6.913661411285401, "Q2 loss": 6.9695291976928715, "Mean Target Q": 205.67864709472656, "Mean Q1": 205.6698115234375, "Mean Q2": 205.6695869140625, "critic_loss": 13.883190643310547, "batch_reward": 1.843228362083435, "actor_loss": -206.06915184759325, "actor_target_entropy": -1.0, "actor_entropy": 0.343993880575703, "alpha_loss": -0.0024029116762141066, "alpha_value": 0.19823620791417665, "duration": 101.68409419059753, "step": 81250}
{"episode_reward": 250.77202678298883, "episode": 651.0, "Q1 loss": 7.1306002388000485, "Q2 loss": 7.121419254302978, "Mean Target Q": 205.75826306152345, "Mean Q1": 205.761279296875, "Mean Q2": 205.761634765625, "critic_loss": 14.252019577026367, "batch_reward": 1.8309506368637085, "actor_loss": -206.12579491024925, "actor_target_entropy": -1.0, "actor_entropy": 0.34092504613929325, "alpha_loss": -0.004695739670996628, "alpha_value": 0.19845756996945502, "duration": 104.77213668823242, "step": 81375}
{"episode_reward": 257.0965214095412, "episode": 652.0, "Q1 loss": 7.385577537536621, "Q2 loss": 7.341117366790772, "Mean Target Q": 205.7760302734375, "Mean Q1": 205.77906286621095, "Mean Q2": 205.7801964111328, "critic_loss": 14.726694961547851, "batch_reward": 1.8295450496673584, "actor_loss": -206.12443444036668, "actor_target_entropy": -1.0, "actor_entropy": 0.3583359864930953, "alpha_loss": -2.7952306423216095e-05, "alpha_value": 0.19868853524453073, "duration": 115.14038896560669, "step": 81500}
{"episode_reward": 306.60614108683114, "episode": 653.0, "Q1 loss": 7.51163886642456, "Q2 loss": 7.556647121429443, "Mean Target Q": 205.8346925048828, "Mean Q1": 205.83060498046876, "Mean Q2": 205.82916247558595, "critic_loss": 15.068285957336427, "batch_reward": 1.8370588216781616, "actor_loss": -206.12908451140873, "actor_target_entropy": -1.0, "actor_entropy": 0.3507892153565846, "alpha_loss": -0.0018496932831430246, "alpha_value": 0.19863919912597422, "duration": 121.89642572402954, "step": 81625}
{"episode_reward": 200.24199671268235, "episode": 654.0, "Q1 loss": 7.208323886871338, "Q2 loss": 7.1901895027160645, "Mean Target Q": 205.98133166503905, "Mean Q1": 205.98448095703125, "Mean Q2": 205.98489660644532, "critic_loss": 14.398513374328614, "batch_reward": 1.840148988723755, "actor_loss": -206.37017108548073, "actor_target_entropy": -1.0, "actor_entropy": 0.3469161814258945, "alpha_loss": -0.005742802046194312, "alpha_value": 0.19885851521962097, "duration": 121.51373505592346, "step": 81750}
{"episode_reward": 235.1233212786671, "episode": 655.0, "Q1 loss": 7.2534568367004395, "Q2 loss": 7.254978103637695, "Mean Target Q": 205.9063190917969, "Mean Q1": 205.89960913085937, "Mean Q2": 205.8989649658203, "critic_loss": 14.508434921264648, "batch_reward": 1.8277460298538208, "actor_loss": -206.26612442258804, "actor_target_entropy": -1.0, "actor_entropy": 0.35288799305756885, "alpha_loss": 0.005940009416672327, "alpha_value": 0.19889159524624914, "duration": 112.51810717582703, "step": 81875}
{"episode_reward": 235.27536744142864, "episode": 656.0, "Q1 loss": 7.287098537445068, "Q2 loss": 7.266889167785645, "Mean Target Q": 206.01454040527344, "Mean Q1": 206.01524926757813, "Mean Q2": 206.01583032226563, "critic_loss": 14.553987686157226, "batch_reward": 1.8404770011901856, "actor_loss": -206.41837015459615, "actor_target_entropy": -1.0, "actor_entropy": 0.3462832570075989, "alpha_loss": -0.004551498356440495, "alpha_value": 0.1988624965294382, "duration": 109.11269164085388, "step": 82000}
{"episode_reward": 276.61286313708075, "episode": 657.0, "Q1 loss": 7.007176979064941, "Q2 loss": 6.968978084564209, "Mean Target Q": 206.0454571533203, "Mean Q1": 206.04064477539063, "Mean Q2": 206.0401378173828, "critic_loss": 13.976155075073242, "batch_reward": 1.8316997022628785, "actor_loss": -206.3800501747737, "actor_target_entropy": -1.0, "actor_entropy": 0.34936448837083484, "alpha_loss": -0.0021387089029072767, "alpha_value": 0.1991038821535132, "duration": 119.2525269985199, "step": 82125}
{"episode_reward": 315.6559393159367, "episode": 658.0, "Q1 loss": 7.053672561645508, "Q2 loss": 6.988268466949463, "Mean Target Q": 206.00935888671876, "Mean Q1": 206.01255883789062, "Mean Q2": 206.01269677734376, "critic_loss": 14.041941085815429, "batch_reward": 1.8236794185638427, "actor_loss": -206.37907434278918, "actor_target_entropy": -1.0, "actor_entropy": 0.34095961191961843, "alpha_loss": -0.000897975308039496, "alpha_value": 0.19922504328363574, "duration": 138.8020374774933, "step": 82250}
{"episode_reward": 243.47509853153582, "episode": 659.0, "Q1 loss": 7.039467052459717, "Q2 loss": 7.0450689926147465, "Mean Target Q": 206.12513171386718, "Mean Q1": 206.12622155761719, "Mean Q2": 206.12598828125, "critic_loss": 14.084535995483398, "batch_reward": 1.8324285364151, "actor_loss": -206.48284500364272, "actor_target_entropy": -1.0, "actor_entropy": 0.35430883013066794, "alpha_loss": -0.004569476939708231, "alpha_value": 0.19934504490706526, "duration": 127.16967678070068, "step": 82375}
{"episode_reward": 192.62965327955632, "episode": 660.0, "Q1 loss": 7.336429588317871, "Q2 loss": 7.366319564819336, "Mean Target Q": 206.1387647705078, "Mean Q1": 206.1349346923828, "Mean Q2": 206.1360926513672, "critic_loss": 14.702749229431152, "batch_reward": 1.8382111091613769, "actor_loss": -206.49877019082345, "actor_target_entropy": -1.0, "actor_entropy": 0.3101974192165559, "alpha_loss": 0.00044269475244706677, "alpha_value": 0.1996115809070325, "duration": 122.23499870300293, "step": 82500}
{"episode_reward": 174.92936190222323, "episode": 661.0, "Q1 loss": 7.3200715637207034, "Q2 loss": 7.35868964767456, "Mean Target Q": 206.12904870605468, "Mean Q1": 206.12665490722657, "Mean Q2": 206.12540881347655, "critic_loss": 14.67876124572754, "batch_reward": 1.8361545619964599, "actor_loss": -206.58433920239645, "actor_target_entropy": -1.0, "actor_entropy": 0.3266689685128984, "alpha_loss": -0.0022486985295212696, "alpha_value": 0.19983442145006117, "duration": 130.05762648582458, "step": 82625}
{"episode_reward": 328.3519304452748, "episode": 662.0, "Q1 loss": 6.921052398681641, "Q2 loss": 6.949837795257569, "Mean Target Q": 206.301111328125, "Mean Q1": 206.30576916503907, "Mean Q2": 206.30697119140626, "critic_loss": 13.870890167236329, "batch_reward": 1.84071381855011, "actor_loss": -206.6599349975586, "actor_target_entropy": -1.0, "actor_entropy": 0.3612222606616636, "alpha_loss": -0.0006767896139213155, "alpha_value": 0.19977141647658087, "duration": 117.34081864356995, "step": 82750}
{"episode_reward": 235.7026416529344, "episode": 663.0, "Q1 loss": 7.111724514007569, "Q2 loss": 7.091233226776123, "Mean Target Q": 206.36818579101563, "Mean Q1": 206.3631300048828, "Mean Q2": 206.3616094970703, "critic_loss": 14.202957725524902, "batch_reward": 1.83358242893219, "actor_loss": -206.69974990118118, "actor_target_entropy": -1.0, "actor_entropy": 0.36561283232673764, "alpha_loss": -0.0017194428577250432, "alpha_value": 0.19985553381314902, "duration": 106.8393714427948, "step": 82875}
{"episode_reward": 260.66913960368447, "episode": 664.0, "Q1 loss": 7.521684131622314, "Q2 loss": 7.498257583618164, "Mean Target Q": 206.27686572265625, "Mean Q1": 206.2756856689453, "Mean Q2": 206.27585021972655, "critic_loss": 15.019941749572753, "batch_reward": 1.8308268575668334, "actor_loss": -206.5787838351342, "actor_target_entropy": -1.0, "actor_entropy": 0.365609729001599, "alpha_loss": -0.006408305027552189, "alpha_value": 0.20014528499645604, "duration": 119.825119972229, "step": 83000}
{"episode_reward": 256.379426633526, "episode": 665.0, "Q1 loss": 7.141661575317383, "Q2 loss": 7.137384906768799, "Mean Target Q": 206.2655283203125, "Mean Q1": 206.2666767578125, "Mean Q2": 206.26640283203125, "critic_loss": 14.27904655456543, "batch_reward": 1.825509888648987, "actor_loss": -206.59523058694506, "actor_target_entropy": -1.0, "actor_entropy": 0.33576383997523596, "alpha_loss": -0.004869315211498548, "alpha_value": 0.20051841313838073, "duration": 121.8813202381134, "step": 83125}
{"episode_reward": 285.0117023110571, "episode": 666.0, "Q1 loss": 7.134392189025879, "Q2 loss": 7.127747596740723, "Mean Target Q": 206.4788818359375, "Mean Q1": 206.47738720703126, "Mean Q2": 206.47864392089843, "critic_loss": 14.262139770507812, "batch_reward": 1.8383559331893922, "actor_loss": -206.83951937767768, "actor_target_entropy": -1.0, "actor_entropy": 0.35201016813516617, "alpha_loss": -0.0053454828260826965, "alpha_value": 0.2010799981109502, "duration": 126.34983372688293, "step": 83250}
{"episode_reward": 247.00202413177345, "episode": 667.0, "Q1 loss": 7.348320545196533, "Q2 loss": 7.3814700317382815, "Mean Target Q": 206.483443359375, "Mean Q1": 206.4784578857422, "Mean Q2": 206.47751940917968, "critic_loss": 14.729790557861328, "batch_reward": 1.8388867511749267, "actor_loss": -206.88233439127603, "actor_target_entropy": -1.0, "actor_entropy": 0.33661264630537185, "alpha_loss": 0.0040264680412494475, "alpha_value": 0.20103252618791895, "duration": 115.43934869766235, "step": 83375}
{"episode_reward": 178.5822690648406, "episode": 668.0, "Q1 loss": 7.42675570678711, "Q2 loss": 7.474737621307373, "Mean Target Q": 206.49190808105467, "Mean Q1": 206.49350329589845, "Mean Q2": 206.49308288574218, "critic_loss": 14.901493263244628, "batch_reward": 1.8371064529418946, "actor_loss": -206.8742427210654, "actor_target_entropy": -1.0, "actor_entropy": 0.33090221353115573, "alpha_loss": -0.010234606148104274, "alpha_value": 0.20126972983000935, "duration": 107.9595115184784, "step": 83500}
{"episode_reward": 234.59895563900753, "episode": 669.0, "Q1 loss": 7.377745235443116, "Q2 loss": 7.39647509765625, "Mean Target Q": 206.43158044433594, "Mean Q1": 206.42389123535156, "Mean Q2": 206.42390197753906, "critic_loss": 14.77422038269043, "batch_reward": 1.8325782690048218, "actor_loss": -206.792240203373, "actor_target_entropy": -1.0, "actor_entropy": 0.3464578357007768, "alpha_loss": -0.005874754716863944, "alpha_value": 0.2019591074449166, "duration": 115.01085329055786, "step": 83625}
{"episode_reward": 254.44453964393313, "episode": 670.0, "Q1 loss": 7.08298246383667, "Q2 loss": 7.068438899993897, "Mean Target Q": 206.5751826171875, "Mean Q1": 206.578875, "Mean Q2": 206.57886413574218, "critic_loss": 14.151421363830567, "batch_reward": 1.8389267416000366, "actor_loss": -206.98433463804184, "actor_target_entropy": -1.0, "actor_entropy": 0.35809468093418306, "alpha_loss": -0.0015378115368225882, "alpha_value": 0.2022850553850868, "duration": 116.27349328994751, "step": 83750}
{"episode_reward": 261.6903415576644, "episode": 671.0, "Q1 loss": 7.1629535064697265, "Q2 loss": 7.176369892120361, "Mean Target Q": 206.58844909667968, "Mean Q1": 206.58636877441407, "Mean Q2": 206.58613696289063, "critic_loss": 14.339323417663575, "batch_reward": 1.8291505222320557, "actor_loss": -207.0386001344711, "actor_target_entropy": -1.0, "actor_entropy": 0.35738792163985117, "alpha_loss": -0.0030655020530084296, "alpha_value": 0.20239838261215023, "duration": 121.32492280006409, "step": 83875}
{"episode_reward": 270.6424702294343, "episode": 672.0, "Q1 loss": 7.414209602355957, "Q2 loss": 7.40435823059082, "Mean Target Q": 206.67222802734375, "Mean Q1": 206.67008178710938, "Mean Q2": 206.66999243164062, "critic_loss": 14.818567802429198, "batch_reward": 1.8329834012985229, "actor_loss": -206.99283427576864, "actor_target_entropy": -1.0, "actor_entropy": 0.350706557593038, "alpha_loss": -0.0014853990700606618, "alpha_value": 0.20260288826307227, "duration": 130.30566239356995, "step": 84000}
{"episode_reward": 255.60056751858164, "episode": 673.0, "Q1 loss": 7.374090507507324, "Q2 loss": 7.351002925872803, "Mean Target Q": 206.6806063232422, "Mean Q1": 206.6787351074219, "Mean Q2": 206.6782706298828, "critic_loss": 14.725093490600585, "batch_reward": 1.8369401788711548, "actor_loss": -207.08958604600696, "actor_target_entropy": -1.0, "actor_entropy": 0.36001417679446085, "alpha_loss": -0.0017385030339013726, "alpha_value": 0.20284529548022345, "duration": 119.7992696762085, "step": 84125}
{"episode_reward": 268.7102417762373, "episode": 674.0, "Q1 loss": 7.556631610870362, "Q2 loss": 7.573334064483642, "Mean Target Q": 206.6296533203125, "Mean Q1": 206.62651403808593, "Mean Q2": 206.62799719238282, "critic_loss": 15.12996573638916, "batch_reward": 1.8363680429458618, "actor_loss": -207.02478790283203, "actor_target_entropy": -1.0, "actor_entropy": 0.3700724426777132, "alpha_loss": -0.009725830082090632, "alpha_value": 0.20302571684276438, "duration": 128.42412948608398, "step": 84250}
{"episode_reward": 268.94806398554584, "episode": 675.0, "Q1 loss": 6.959260578155518, "Q2 loss": 6.940870885848999, "Mean Target Q": 206.7698369140625, "Mean Q1": 206.77021984863282, "Mean Q2": 206.77001867675781, "critic_loss": 13.90013144683838, "batch_reward": 1.8386104564666748, "actor_loss": -207.2050013466487, "actor_target_entropy": -1.0, "actor_entropy": 0.33975025089014144, "alpha_loss": 0.0012479327999735399, "alpha_value": 0.20354985085784372, "duration": 124.40800166130066, "step": 84375}
{"episode_reward": 275.92847501686174, "episode": 676.0, "Q1 loss": 7.250384254455566, "Q2 loss": 7.240487426757812, "Mean Target Q": 206.82216125488281, "Mean Q1": 206.82324291992188, "Mean Q2": 206.82226232910156, "critic_loss": 14.490871726989747, "batch_reward": 1.837676962852478, "actor_loss": -207.15628962362968, "actor_target_entropy": -1.0, "actor_entropy": 0.3584197807696558, "alpha_loss": 0.0012892656208526704, "alpha_value": 0.2033938706684083, "duration": 120.1078269481659, "step": 84500}
{"episode_reward": 213.6724433981284, "episode": 677.0, "Q1 loss": 6.90979316329956, "Q2 loss": 6.910670757293701, "Mean Target Q": 206.83901098632813, "Mean Q1": 206.83781298828126, "Mean Q2": 206.83805114746093, "critic_loss": 13.820463943481446, "batch_reward": 1.8389772253036498, "actor_loss": -207.2262464250837, "actor_target_entropy": -1.0, "actor_entropy": 0.337417248222563, "alpha_loss": -0.003190581577770885, "alpha_value": 0.20340936628839523, "duration": 99.59493279457092, "step": 84625}
{"episode_reward": 211.32221492656376, "episode": 678.0, "Q1 loss": 7.417226432800293, "Q2 loss": 7.391622184753418, "Mean Target Q": 206.93729431152343, "Mean Q1": 206.93994226074219, "Mean Q2": 206.93965405273437, "critic_loss": 14.808848602294923, "batch_reward": 1.8527261095046996, "actor_loss": -207.3003919047694, "actor_target_entropy": -1.0, "actor_entropy": 0.3381074628522319, "alpha_loss": -6.447208204096364e-05, "alpha_value": 0.20360147085554067, "duration": 119.7514660358429, "step": 84750}
{"episode_reward": 284.9697297706484, "episode": 679.0, "Q1 loss": 7.158667350769043, "Q2 loss": 7.145634143829346, "Mean Target Q": 206.9211427001953, "Mean Q1": 206.91805297851562, "Mean Q2": 206.91879064941406, "critic_loss": 14.30430150604248, "batch_reward": 1.8337425937652587, "actor_loss": -207.3032742454892, "actor_target_entropy": -1.0, "actor_entropy": 0.3536107764830665, "alpha_loss": 0.0020515590107866694, "alpha_value": 0.20353509137844386, "duration": 121.03962063789368, "step": 84875}
{"episode_reward": 208.3562832835511, "episode": 680.0, "Q1 loss": 7.049916543960571, "Q2 loss": 7.064630363464356, "Mean Target Q": 206.9794685058594, "Mean Q1": 206.9755596923828, "Mean Q2": 206.97489599609375, "critic_loss": 14.114546897888184, "batch_reward": 1.8320639867782593, "actor_loss": -207.3288333031439, "actor_target_entropy": -1.0, "actor_entropy": 0.36273354772598515, "alpha_loss": -0.0011632781468271728, "alpha_value": 0.20356112087094247, "step": 85000}
{"duration": 135.19452095031738, "step": 85000}
{"episode_reward": 251.41180761860053, "episode": 681.0, "Q1 loss": 6.748597316741943, "Q2 loss": 6.729799758911133, "Mean Target Q": 207.00315649414063, "Mean Q1": 206.99618713378905, "Mean Q2": 206.99626208496093, "critic_loss": 13.478397087097168, "batch_reward": 1.8418429765701294, "actor_loss": -207.42254251147074, "actor_target_entropy": -1.0, "actor_entropy": 0.3344832214098128, "alpha_loss": 0.0013370409253097716, "alpha_value": 0.20348358083568927, "duration": 119.12028360366821, "step": 85125}
{"episode_reward": 261.100343146072, "episode": 682.0, "Q1 loss": 7.130977487564087, "Q2 loss": 7.113822006225586, "Mean Target Q": 207.07953857421876, "Mean Q1": 207.08489599609376, "Mean Q2": 207.08437866210937, "critic_loss": 14.244799545288085, "batch_reward": 1.8414936923980714, "actor_loss": -207.44861110564202, "actor_target_entropy": -1.0, "actor_entropy": 0.351106793649735, "alpha_loss": 0.0058791287310962234, "alpha_value": 0.20318812866702116, "duration": 123.39841485023499, "step": 85250}
{"episode_reward": 255.2767198261989, "episode": 683.0, "Q1 loss": 6.961741737365722, "Q2 loss": 6.911167083740234, "Mean Target Q": 207.18478369140624, "Mean Q1": 207.18152111816406, "Mean Q2": 207.1812479248047, "critic_loss": 13.87290881729126, "batch_reward": 1.8337170190811156, "actor_loss": -207.50207785954552, "actor_target_entropy": -1.0, "actor_entropy": 0.3706462113630204, "alpha_loss": 0.0036340828075827588, "alpha_value": 0.20281423782385588, "duration": 123.36354970932007, "step": 85375}
{"episode_reward": 243.13612060048249, "episode": 684.0, "Q1 loss": 7.264863269805908, "Q2 loss": 7.242023090362549, "Mean Target Q": 207.15545336914062, "Mean Q1": 207.1567618408203, "Mean Q2": 207.15693310546874, "critic_loss": 14.506886329650879, "batch_reward": 1.8477150564193725, "actor_loss": -207.4533423146894, "actor_target_entropy": -1.0, "actor_entropy": 0.35626510242300646, "alpha_loss": -0.004274382984506026, "alpha_value": 0.2027782755388375, "duration": 122.26921391487122, "step": 85500}
{"episode_reward": 248.7073661332038, "episode": 685.0, "Q1 loss": 7.2251839981079105, "Q2 loss": 7.155360553741455, "Mean Target Q": 207.22437780761717, "Mean Q1": 207.22152124023438, "Mean Q2": 207.2211993408203, "critic_loss": 14.38054460144043, "batch_reward": 1.8291926889419556, "actor_loss": -207.52151198614212, "actor_target_entropy": -1.0, "actor_entropy": 0.35404586650076364, "alpha_loss": 0.0011829311242474922, "alpha_value": 0.20294313110145226, "duration": 120.72372579574585, "step": 85625}
{"episode_reward": 229.0127829781776, "episode": 686.0, "Q1 loss": 7.336120346069336, "Q2 loss": 7.324514106750488, "Mean Target Q": 207.310029296875, "Mean Q1": 207.31182153320313, "Mean Q2": 207.31229943847657, "critic_loss": 14.660634468078614, "batch_reward": 1.8441769504547119, "actor_loss": -207.7317413822297, "actor_target_entropy": -1.0, "actor_entropy": 0.33705325448705303, "alpha_loss": 0.0029404636607655594, "alpha_value": 0.2028004510347646, "duration": 124.47502446174622, "step": 85750}
{"episode_reward": 230.6604306553277, "episode": 687.0, "Q1 loss": 7.067475246429443, "Q2 loss": 7.117805103302002, "Mean Target Q": 207.21890600585937, "Mean Q1": 207.21973596191407, "Mean Q2": 207.21914306640625, "critic_loss": 14.185280319213867, "batch_reward": 1.8394536409378053, "actor_loss": -207.5668199327257, "actor_target_entropy": -1.0, "actor_entropy": 0.3440457506785317, "alpha_loss": -0.0013233151819024766, "alpha_value": 0.20267679763164226, "duration": 123.70937442779541, "step": 85875}
{"episode_reward": 252.06881610643575, "episode": 688.0, "Q1 loss": 7.002650054931641, "Q2 loss": 7.018383842468261, "Mean Target Q": 207.35407275390625, "Mean Q1": 207.34795446777343, "Mean Q2": 207.34912866210936, "critic_loss": 14.021033988952636, "batch_reward": 1.8494225072860717, "actor_loss": -207.73611696304815, "actor_target_entropy": -1.0, "actor_entropy": 0.3399521513812004, "alpha_loss": -0.000545729017410908, "alpha_value": 0.20281819752883135, "duration": 121.2264244556427, "step": 86000}
{"episode_reward": 184.72476468245583, "episode": 689.0, "Q1 loss": 7.156292179107666, "Q2 loss": 7.17731700515747, "Mean Target Q": 207.3079483642578, "Mean Q1": 207.3085216064453, "Mean Q2": 207.30911254882812, "critic_loss": 14.333609169006348, "batch_reward": 1.840590895652771, "actor_loss": -207.64509970044332, "actor_target_entropy": -1.0, "actor_entropy": 0.3633104231622484, "alpha_loss": 0.0042958432616340735, "alpha_value": 0.20271067623426206, "duration": 125.84327626228333, "step": 86125}
{"episode_reward": 255.10957667801014, "episode": 690.0, "Q1 loss": 6.9828444213867185, "Q2 loss": 6.991647735595703, "Mean Target Q": 207.43731091308592, "Mean Q1": 207.43498022460938, "Mean Q2": 207.43370703125, "critic_loss": 13.974492176055907, "batch_reward": 1.828844012260437, "actor_loss": -207.78282313193046, "actor_target_entropy": -1.0, "actor_entropy": 0.3443353361179752, "alpha_loss": -0.0008645234591958504, "alpha_value": 0.2024497105349577, "duration": 120.72423720359802, "step": 86250}
{"episode_reward": 239.31231140385995, "episode": 691.0, "Q1 loss": 7.075049472808838, "Q2 loss": 7.095798816680908, "Mean Target Q": 207.4167911376953, "Mean Q1": 207.4165302734375, "Mean Q2": 207.41715100097656, "critic_loss": 14.170848258972168, "batch_reward": 1.8327184591293335, "actor_loss": -207.72225879487536, "actor_target_entropy": -1.0, "actor_entropy": 0.36968945368887884, "alpha_loss": 0.007363489200730646, "alpha_value": 0.202251746477957, "duration": 121.78560495376587, "step": 86375}
{"episode_reward": 294.62656575093536, "episode": 692.0, "Q1 loss": 7.127178089141846, "Q2 loss": 7.1449733848571775, "Mean Target Q": 207.52488500976563, "Mean Q1": 207.525013671875, "Mean Q2": 207.52559045410158, "critic_loss": 14.27215143585205, "batch_reward": 1.839085802078247, "actor_loss": -207.823977562689, "actor_target_entropy": -1.0, "actor_entropy": 0.353037997599571, "alpha_loss": 0.0019763402392967574, "alpha_value": 0.20184933929872437, "duration": 121.8116614818573, "step": 86500}
{"episode_reward": 215.76568132096816, "episode": 693.0, "Q1 loss": 6.843206001281739, "Q2 loss": 6.847939830780029, "Mean Target Q": 207.57485290527345, "Mean Q1": 207.5683565673828, "Mean Q2": 207.5679881591797, "critic_loss": 13.691145881652831, "batch_reward": 1.839288815498352, "actor_loss": -207.96786256820437, "actor_target_entropy": -1.0, "actor_entropy": 0.3474277033219262, "alpha_loss": 0.0007311278798927864, "alpha_value": 0.20178763850711595, "duration": 127.93400716781616, "step": 86625}
{"episode_reward": 254.587999768877, "episode": 694.0, "Q1 loss": 6.759764804840088, "Q2 loss": 6.757848125457763, "Mean Target Q": 207.6175264892578, "Mean Q1": 207.61661840820312, "Mean Q2": 207.61598999023437, "critic_loss": 13.517612922668457, "batch_reward": 1.8427731094360351, "actor_loss": -208.0131547989384, "actor_target_entropy": -1.0, "actor_entropy": 0.36375016863307646, "alpha_loss": 0.003638345000874852, "alpha_value": 0.20167307394106695, "duration": 122.69788646697998, "step": 86750}
{"episode_reward": 258.7662872656996, "episode": 695.0, "Q1 loss": 6.986701358795166, "Q2 loss": 6.953552116394043, "Mean Target Q": 207.6467939453125, "Mean Q1": 207.64766052246094, "Mean Q2": 207.6475849609375, "critic_loss": 13.940253463745117, "batch_reward": 1.8413918981552124, "actor_loss": -208.0345175606864, "actor_target_entropy": -1.0, "actor_entropy": 0.3133952712255811, "alpha_loss": 0.00016924244950392416, "alpha_value": 0.20149598905275914, "duration": 121.77980065345764, "step": 86875}
{"episode_reward": 266.9476769909634, "episode": 696.0, "Q1 loss": 7.057063053131103, "Q2 loss": 7.064919063568115, "Mean Target Q": 207.59104479980468, "Mean Q1": 207.5894110107422, "Mean Q2": 207.58960400390626, "critic_loss": 14.12198207092285, "batch_reward": 1.8389523105621337, "actor_loss": -207.96876771988408, "actor_target_entropy": -1.0, "actor_entropy": 0.36167232403832095, "alpha_loss": 0.0004837436248518286, "alpha_value": 0.20138427768165756, "duration": 123.38256406784058, "step": 87000}
{"episode_reward": 229.67063559217826, "episode": 697.0, "Q1 loss": 7.196843574523926, "Q2 loss": 7.243500297546387, "Mean Target Q": 207.72423828125, "Mean Q1": 207.71948095703124, "Mean Q2": 207.71980187988282, "critic_loss": 14.440343856811523, "batch_reward": 1.8438043594360352, "actor_loss": -208.06887890043714, "actor_target_entropy": -1.0, "actor_entropy": 0.3538999611896182, "alpha_loss": 0.0002561571438693338, "alpha_value": 0.20135391936283636, "duration": 121.05300188064575, "step": 87125}
{"episode_reward": 255.9349016170803, "episode": 698.0, "Q1 loss": 6.937486766815185, "Q2 loss": 6.906425640106201, "Mean Target Q": 207.76011486816407, "Mean Q1": 207.76130627441407, "Mean Q2": 207.76116455078125, "critic_loss": 13.843912406921387, "batch_reward": 1.8363335466384887, "actor_loss": -208.0541701778289, "actor_target_entropy": -1.0, "actor_entropy": 0.3591963047942808, "alpha_loss": 0.0077899572431981085, "alpha_value": 0.20103002727184655, "duration": 122.52557396888733, "step": 87250}
{"episode_reward": 274.2654951774242, "episode": 699.0, "Q1 loss": 7.123071022033692, "Q2 loss": 7.151188701629638, "Mean Target Q": 207.68568115234376, "Mean Q1": 207.68219189453126, "Mean Q2": 207.68014758300782, "critic_loss": 14.274259765625, "batch_reward": 1.8374170398712157, "actor_loss": -207.97863042922248, "actor_target_entropy": -1.0, "actor_entropy": 0.34648084782418753, "alpha_loss": 0.0010174033546169836, "alpha_value": 0.2005869829527796, "duration": 122.85350465774536, "step": 87375}
{"episode_reward": 342.466524374761, "episode": 700.0, "Q1 loss": 7.463026649475098, "Q2 loss": 7.429966709136963, "Mean Target Q": 207.83508850097655, "Mean Q1": 207.83406799316407, "Mean Q2": 207.83685205078126, "critic_loss": 14.892993370056152, "batch_reward": 1.8552497882843018, "actor_loss": -208.19474915535218, "actor_target_entropy": -1.0, "actor_entropy": 0.3609484313957153, "alpha_loss": 0.00357634368194868, "alpha_value": 0.20054616630966493, "duration": 126.36316800117493, "step": 87500}
{"episode_reward": 272.14769684173905, "episode": 701.0, "Q1 loss": 6.996263988494873, "Q2 loss": 6.997108856201172, "Mean Target Q": 207.78808703613282, "Mean Q1": 207.7878074951172, "Mean Q2": 207.78727014160157, "critic_loss": 13.993372879028321, "batch_reward": 1.843417007446289, "actor_loss": -208.10899110824343, "actor_target_entropy": -1.0, "actor_entropy": 0.3401414122846391, "alpha_loss": -0.00036549856812353174, "alpha_value": 0.20047233864394018, "duration": 121.54912376403809, "step": 87625}
{"episode_reward": 231.19191584044594, "episode": 702.0, "Q1 loss": 6.9268579559326175, "Q2 loss": 6.987408294677734, "Mean Target Q": 207.81297436523437, "Mean Q1": 207.81410961914062, "Mean Q2": 207.81419702148438, "critic_loss": 13.914266242980958, "batch_reward": 1.829640661239624, "actor_loss": -208.1254420126638, "actor_target_entropy": -1.0, "actor_entropy": 0.3509321270450469, "alpha_loss": 0.002344071801241127, "alpha_value": 0.20028551752728244, "duration": 116.83666276931763, "step": 87750}
{"episode_reward": 219.79905181228116, "episode": 703.0, "Q1 loss": 7.098613719940186, "Q2 loss": 7.088035316467285, "Mean Target Q": 207.91299755859376, "Mean Q1": 207.9093045654297, "Mean Q2": 207.90900219726564, "critic_loss": 14.186649002075196, "batch_reward": 1.8398055667877198, "actor_loss": -208.25387549021886, "actor_target_entropy": -1.0, "actor_entropy": 0.3480689459376865, "alpha_loss": 0.0012193757316304578, "alpha_value": 0.20009947356913563, "duration": 114.67607069015503, "step": 87875}
{"episode_reward": 278.5592221734698, "episode": 704.0, "Q1 loss": 6.7651690616607665, "Q2 loss": 6.744077375411988, "Mean Target Q": 207.91055834960937, "Mean Q1": 207.91401647949218, "Mean Q2": 207.91346899414063, "critic_loss": 13.50924645614624, "batch_reward": 1.8299765844345093, "actor_loss": -208.25900071667087, "actor_target_entropy": -1.0, "actor_entropy": 0.35140910023643124, "alpha_loss": -0.0005646724584362199, "alpha_value": 0.2003129009275171, "duration": 108.07184839248657, "step": 88000}
{"episode_reward": 240.00069375520877, "episode": 705.0, "Q1 loss": 7.43745760345459, "Q2 loss": 7.454341201782227, "Mean Target Q": 207.96477124023437, "Mean Q1": 207.95914611816406, "Mean Q2": 207.9603516845703, "critic_loss": 14.891798782348634, "batch_reward": 1.8443322191238403, "actor_loss": -208.320070296999, "actor_target_entropy": -1.0, "actor_entropy": 0.34065843740152935, "alpha_loss": -0.0017758214047976903, "alpha_value": 0.20011586773575848, "duration": 124.82380151748657, "step": 88125}
{"episode_reward": 294.9273997731572, "episode": 706.0, "Q1 loss": 7.263985584259033, "Q2 loss": 7.307499359130859, "Mean Target Q": 207.89067175292968, "Mean Q1": 207.88978845214845, "Mean Q2": 207.8893406982422, "critic_loss": 14.571484916687012, "batch_reward": 1.8318385934829713, "actor_loss": -208.22188838835686, "actor_target_entropy": -1.0, "actor_entropy": 0.38416799662574647, "alpha_loss": -0.0006394882295881548, "alpha_value": 0.20027326359872105, "duration": 118.11347937583923, "step": 88250}
{"episode_reward": 178.48776987024652, "episode": 707.0, "Q1 loss": 7.032605045318603, "Q2 loss": 7.0114596824646, "Mean Target Q": 208.02590551757814, "Mean Q1": 208.02802111816408, "Mean Q2": 208.02779052734374, "critic_loss": 14.044064727783203, "batch_reward": 1.8560998382568359, "actor_loss": -208.35101003495473, "actor_target_entropy": -1.0, "actor_entropy": 0.34698633967884, "alpha_loss": 0.0015307088892552115, "alpha_value": 0.20020718436718538, "duration": 121.1543197631836, "step": 88375}
{"episode_reward": 221.30080144882498, "episode": 708.0, "Q1 loss": 7.209095432281494, "Q2 loss": 7.202765251159668, "Mean Target Q": 207.9992069091797, "Mean Q1": 207.99864916992186, "Mean Q2": 207.9983331298828, "critic_loss": 14.411860733032226, "batch_reward": 1.8513323135375976, "actor_loss": -208.40127489643712, "actor_target_entropy": -1.0, "actor_entropy": 0.33221830643953815, "alpha_loss": -0.001779107279294441, "alpha_value": 0.2002151380454761, "duration": 124.96285676956177, "step": 88500}
{"episode_reward": 196.08096488335477, "episode": 709.0, "Q1 loss": 7.373896800994873, "Q2 loss": 7.379150791168213, "Mean Target Q": 208.1098875732422, "Mean Q1": 208.1096007080078, "Mean Q2": 208.10977270507811, "critic_loss": 14.753047630310059, "batch_reward": 1.8501017866134644, "actor_loss": -208.37281314910405, "actor_target_entropy": -1.0, "actor_entropy": 0.3547251893887444, "alpha_loss": 0.003498589117375631, "alpha_value": 0.20018041607977666, "duration": 119.57492876052856, "step": 88625}
{"episode_reward": 319.41379790716104, "episode": 710.0, "Q1 loss": 7.19626908493042, "Q2 loss": 7.19488472366333, "Mean Target Q": 208.13605908203124, "Mean Q1": 208.12995776367188, "Mean Q2": 208.12978649902342, "critic_loss": 14.39115380859375, "batch_reward": 1.854028172492981, "actor_loss": -208.42391992384387, "actor_target_entropy": -1.0, "actor_entropy": 0.34754051508442046, "alpha_loss": 0.0015246614047716702, "alpha_value": 0.200038394471207, "duration": 121.27015852928162, "step": 88750}
{"episode_reward": 222.14058002234137, "episode": 711.0, "Q1 loss": 7.164224060058594, "Q2 loss": 7.151994499206543, "Mean Target Q": 208.1175146484375, "Mean Q1": 208.1170408935547, "Mean Q2": 208.11658825683594, "critic_loss": 14.316218627929688, "batch_reward": 1.839084023475647, "actor_loss": -208.5098409501333, "actor_target_entropy": -1.0, "actor_entropy": 0.36998134875108324, "alpha_loss": 0.0034493912669223926, "alpha_value": 0.19969513199845998, "duration": 111.0689344406128, "step": 88875}
{"episode_reward": 188.95591533534716, "episode": 712.0, "Q1 loss": 7.118384922027588, "Q2 loss": 7.082740894317627, "Mean Target Q": 208.26606506347656, "Mean Q1": 208.26585192871093, "Mean Q2": 208.26677465820313, "critic_loss": 14.201125831604005, "batch_reward": 1.8432157144546508, "actor_loss": -208.6049319851783, "actor_target_entropy": -1.0, "actor_entropy": 0.3665052760512598, "alpha_loss": -0.0038801545930665826, "alpha_value": 0.19977395919160637, "duration": 132.43457913398743, "step": 89000}
{"episode_reward": 233.93393277280063, "episode": 713.0, "Q1 loss": 7.153019309997559, "Q2 loss": 7.0736250381469725, "Mean Target Q": 208.27132885742188, "Mean Q1": 208.2753555908203, "Mean Q2": 208.27522961425782, "critic_loss": 14.226644309997559, "batch_reward": 1.8287317600250244, "actor_loss": -208.665775359623, "actor_target_entropy": -1.0, "actor_entropy": 0.33864266697376494, "alpha_loss": -0.0009351725623543773, "alpha_value": 0.1999622019036325, "duration": 126.06751728057861, "step": 89125}
{"episode_reward": 193.838335592834, "episode": 714.0, "Q1 loss": 7.058825382232666, "Q2 loss": 7.050675510406494, "Mean Target Q": 208.28376794433595, "Mean Q1": 208.27620056152344, "Mean Q2": 208.27547326660155, "critic_loss": 14.109500915527343, "batch_reward": 1.8426724348068237, "actor_loss": -208.61299477854084, "actor_target_entropy": -1.0, "actor_entropy": 0.3595320245911998, "alpha_loss": 0.00010798913013610629, "alpha_value": 0.20013079920788246, "duration": 131.7217402458191, "step": 89250}
{"episode_reward": 247.13691843652884, "episode": 715.0, "Q1 loss": 7.398192714691162, "Q2 loss": 7.394235942840576, "Mean Target Q": 208.32735205078126, "Mean Q1": 208.32598510742187, "Mean Q2": 208.32677563476562, "critic_loss": 14.792428634643555, "batch_reward": 1.8480212049484253, "actor_loss": -208.72898840525792, "actor_target_entropy": -1.0, "actor_entropy": 0.3415577194047353, "alpha_loss": -0.0029735734117113883, "alpha_value": 0.20020275420110561, "duration": 121.43993330001831, "step": 89375}
{"episode_reward": 267.06787117706, "episode": 716.0, "Q1 loss": 7.071892169952393, "Q2 loss": 7.077714160919189, "Mean Target Q": 208.45486791992187, "Mean Q1": 208.45813623046874, "Mean Q2": 208.45743322753907, "critic_loss": 14.149606330871581, "batch_reward": 1.8533587503433226, "actor_loss": -208.832275390625, "actor_target_entropy": -1.0, "actor_entropy": 0.3447105668244823, "alpha_loss": -0.00034916794280551617, "alpha_value": 0.20038165930112828, "duration": 114.50605893135071, "step": 89500}
{"episode_reward": 232.91794359203175, "episode": 717.0, "Q1 loss": 7.446940071105957, "Q2 loss": 7.533340023040772, "Mean Target Q": 208.48252160644532, "Mean Q1": 208.4828123779297, "Mean Q2": 208.4817507324219, "critic_loss": 14.980280097961426, "batch_reward": 1.844941647529602, "actor_loss": -208.80763922797308, "actor_target_entropy": -1.0, "actor_entropy": 0.3389271932934958, "alpha_loss": 0.0010904189834873828, "alpha_value": 0.2002027747872765, "duration": 113.77612137794495, "step": 89625}
{"episode_reward": 264.57229942833084, "episode": 718.0, "Q1 loss": 7.21612100982666, "Q2 loss": 7.159220989227295, "Mean Target Q": 208.41318713378905, "Mean Q1": 208.41118518066406, "Mean Q2": 208.41154296875, "critic_loss": 14.37534196472168, "batch_reward": 1.8400947704315185, "actor_loss": -208.78509742982925, "actor_target_entropy": -1.0, "actor_entropy": 0.3346949791715991, "alpha_loss": 0.0008095297286467206, "alpha_value": 0.2001397738060494, "duration": 113.01044917106628, "step": 89750}
{"episode_reward": 243.25881609974064, "episode": 719.0, "Q1 loss": 7.5834308509826664, "Q2 loss": 7.562835231781006, "Mean Target Q": 208.4937353515625, "Mean Q1": 208.48902734375, "Mean Q2": 208.49000451660157, "critic_loss": 15.146266090393066, "batch_reward": 1.8385831365585328, "actor_loss": -208.80388387044272, "actor_target_entropy": -1.0, "actor_entropy": 0.36078255044089425, "alpha_loss": -5.992933449941495e-05, "alpha_value": 0.20028185203568535, "duration": 134.8710741996765, "step": 89875}
{"episode_reward": 294.605559603225, "episode": 720.0, "Q1 loss": 7.289303142547608, "Q2 loss": 7.266558963775635, "Mean Target Q": 208.5428328857422, "Mean Q1": 208.54317712402343, "Mean Q2": 208.54201110839844, "critic_loss": 14.555862159729005, "batch_reward": 1.8554260692596436, "actor_loss": -208.88841788999497, "actor_target_entropy": -1.0, "actor_entropy": 0.33669121154854376, "alpha_loss": 0.0013763205966942252, "alpha_value": 0.20009382335001985, "step": 90000}
{"duration": 124.65021109580994, "step": 90000}
{"episode_reward": 310.4972165821046, "episode": 721.0, "Q1 loss": 7.144400020599365, "Q2 loss": 7.11365438079834, "Mean Target Q": 208.46105822753907, "Mean Q1": 208.4611925048828, "Mean Q2": 208.46285888671875, "critic_loss": 14.258054382324218, "batch_reward": 1.8442954835891723, "actor_loss": -208.8280506436787, "actor_target_entropy": -1.0, "actor_entropy": 0.3517560942305459, "alpha_loss": -0.001848457977988772, "alpha_value": 0.2001541466013083, "duration": 108.00268864631653, "step": 90125}
{"episode_reward": 322.16513045499715, "episode": 722.0, "Q1 loss": 6.9378753242492675, "Q2 loss": 6.940229270935059, "Mean Target Q": 208.58614050292968, "Mean Q1": 208.58662072753907, "Mean Q2": 208.58722790527344, "critic_loss": 13.878104637145997, "batch_reward": 1.8403764562606812, "actor_loss": -208.98373339253087, "actor_target_entropy": -1.0, "actor_entropy": 0.32183534339551, "alpha_loss": -0.00895828737186328, "alpha_value": 0.2006117739399334, "duration": 110.08311176300049, "step": 90250}
{"episode_reward": 245.1267225342973, "episode": 723.0, "Q1 loss": 7.175186876296997, "Q2 loss": 7.215117176055908, "Mean Target Q": 208.62374743652344, "Mean Q1": 208.62105737304688, "Mean Q2": 208.6191112060547, "critic_loss": 14.39030403137207, "batch_reward": 1.844517988204956, "actor_loss": -208.96734909784226, "actor_target_entropy": -1.0, "actor_entropy": 0.3375028892168923, "alpha_loss": -0.004480084829357645, "alpha_value": 0.2010358952231303, "duration": 133.55713081359863, "step": 90375}
{"episode_reward": 205.8464367323408, "episode": 724.0, "Q1 loss": 7.308529060363769, "Q2 loss": 7.315952236175537, "Mean Target Q": 208.6368076171875, "Mean Q1": 208.63127954101563, "Mean Q2": 208.6324591064453, "critic_loss": 14.62448126220703, "batch_reward": 1.851067711830139, "actor_loss": -208.98394233949722, "actor_target_entropy": -1.0, "actor_entropy": 0.3603935957916321, "alpha_loss": 0.006177979498921383, "alpha_value": 0.20097189670307872, "duration": 129.27761721611023, "step": 90500}
{"episode_reward": 187.61551586329344, "episode": 725.0, "Q1 loss": 7.358498233795166, "Q2 loss": 7.381643760681152, "Mean Target Q": 208.5380487060547, "Mean Q1": 208.53963427734374, "Mean Q2": 208.53932116699218, "critic_loss": 14.74014192199707, "batch_reward": 1.8341958265304565, "actor_loss": -208.82864573645213, "actor_target_entropy": -1.0, "actor_entropy": 0.35723595202915254, "alpha_loss": 0.0038855824811709306, "alpha_value": 0.2007200583180213, "duration": 122.47131705284119, "step": 90625}
{"episode_reward": 189.73394298884375, "episode": 726.0, "Q1 loss": 7.583058513641357, "Q2 loss": 7.540947288513183, "Mean Target Q": 208.74835571289063, "Mean Q1": 208.74685949707032, "Mean Q2": 208.7465283203125, "critic_loss": 15.124005805969238, "batch_reward": 1.8506440382003784, "actor_loss": -209.0675523819462, "actor_target_entropy": -1.0, "actor_entropy": 0.33775121237962474, "alpha_loss": -0.0018243825874261319, "alpha_value": 0.20054951802497034, "duration": 118.6971743106842, "step": 90750}
{"episode_reward": 270.0813758920047, "episode": 727.0, "Q1 loss": 7.198604042053223, "Q2 loss": 7.20779923248291, "Mean Target Q": 208.7916417236328, "Mean Q1": 208.78782360839844, "Mean Q2": 208.78874572753907, "critic_loss": 14.40640323638916, "batch_reward": 1.8538558187484742, "actor_loss": -209.15250336177766, "actor_target_entropy": -1.0, "actor_entropy": 0.36171649893124896, "alpha_loss": 0.005670490382712275, "alpha_value": 0.2003120798439212, "duration": 124.56327772140503, "step": 90875}
{"episode_reward": 302.98379771059524, "episode": 728.0, "Q1 loss": 7.219194328308105, "Q2 loss": 7.185528293609619, "Mean Target Q": 208.80046752929687, "Mean Q1": 208.80625524902345, "Mean Q2": 208.80543591308594, "critic_loss": 14.404722595214844, "batch_reward": 1.8463663148880005, "actor_loss": -209.1242921890751, "actor_target_entropy": -1.0, "actor_entropy": 0.33933478593826294, "alpha_loss": 0.0032232786911810117, "alpha_value": 0.20000297006394607, "duration": 131.2383167743683, "step": 91000}
{"episode_reward": 289.61144385148503, "episode": 729.0, "Q1 loss": 7.488795764923096, "Q2 loss": 7.493619861602784, "Mean Target Q": 208.70386877441408, "Mean Q1": 208.69656091308593, "Mean Q2": 208.69577404785156, "critic_loss": 14.982415657043457, "batch_reward": 1.8458677825927734, "actor_loss": -209.0813974047464, "actor_target_entropy": -1.0, "actor_entropy": 0.3652294741736518, "alpha_loss": 0.01033101800925261, "alpha_value": 0.19946131951006965, "duration": 122.62036037445068, "step": 91125}
{"episode_reward": 286.92314170981837, "episode": 730.0, "Q1 loss": 7.828939064025879, "Q2 loss": 7.788606258392334, "Mean Target Q": 208.76502758789061, "Mean Q1": 208.76887121582033, "Mean Q2": 208.76955883789063, "critic_loss": 15.617545333862305, "batch_reward": 1.8534023656845093, "actor_loss": -209.19578060027092, "actor_target_entropy": -1.0, "actor_entropy": 0.3236221462007492, "alpha_loss": 0.00011881352252056522, "alpha_value": 0.19906721171551686, "duration": 129.2655816078186, "step": 91250}
{"episode_reward": 241.1933254051849, "episode": 731.0, "Q1 loss": 7.3878793640136715, "Q2 loss": 7.42323486328125, "Mean Target Q": 208.86637243652345, "Mean Q1": 208.86362463378907, "Mean Q2": 208.86422473144532, "critic_loss": 14.811114181518555, "batch_reward": 1.8511115713119506, "actor_loss": -209.21002536349826, "actor_target_entropy": -1.0, "actor_entropy": 0.3486158573438251, "alpha_loss": 0.007904180177738742, "alpha_value": 0.1987665536893619, "duration": 134.78887176513672, "step": 91375}
{"episode_reward": 273.4728212145582, "episode": 732.0, "Q1 loss": 7.502102993011475, "Q2 loss": 7.509011028289795, "Mean Target Q": 208.89198815917968, "Mean Q1": 208.89268127441406, "Mean Q2": 208.8915535888672, "critic_loss": 15.01111407470703, "batch_reward": 1.8537865991592408, "actor_loss": -209.25457714449973, "actor_target_entropy": -1.0, "actor_entropy": 0.3536868326125606, "alpha_loss": 0.0021743479432658323, "alpha_value": 0.19843109612576576, "duration": 125.96243143081665, "step": 91500}
{"episode_reward": 229.4426718310863, "episode": 733.0, "Q1 loss": 7.545852436065674, "Q2 loss": 7.543771545410157, "Mean Target Q": 208.9457236328125, "Mean Q1": 208.9428927001953, "Mean Q2": 208.94320422363282, "critic_loss": 15.089623962402344, "batch_reward": 1.8537850065231323, "actor_loss": -209.3397931295728, "actor_target_entropy": -1.0, "actor_entropy": 0.31779107900839004, "alpha_loss": 0.002171583155850096, "alpha_value": 0.19820915244533266, "duration": 119.32110357284546, "step": 91625}
{"episode_reward": 201.89742980047927, "episode": 734.0, "Q1 loss": 7.18209489440918, "Q2 loss": 7.169120365142822, "Mean Target Q": 208.9427784423828, "Mean Q1": 208.94434606933595, "Mean Q2": 208.94526000976563, "critic_loss": 14.351215248107911, "batch_reward": 1.846443404197693, "actor_loss": -209.22574812366116, "actor_target_entropy": -1.0, "actor_entropy": 0.34178937322670416, "alpha_loss": 0.007278562380721973, "alpha_value": 0.19782943527003913, "duration": 116.40250182151794, "step": 91750}
{"episode_reward": 238.50221241726996, "episode": 735.0, "Q1 loss": 7.119694164276123, "Q2 loss": 7.0925915336608885, "Mean Target Q": 209.00382482910157, "Mean Q1": 209.00333435058593, "Mean Q2": 209.00212622070313, "critic_loss": 14.21228572845459, "batch_reward": 1.8480721597671508, "actor_loss": -209.28006829155817, "actor_target_entropy": -1.0, "actor_entropy": 0.3333769083496124, "alpha_loss": 0.0014585506148813735, "alpha_value": 0.19753590232575216, "duration": 124.21347975730896, "step": 91875}
{"episode_reward": 227.61259743257338, "episode": 736.0, "Q1 loss": 7.3795352478027345, "Q2 loss": 7.403173015594483, "Mean Target Q": 208.9443992919922, "Mean Q1": 208.93991735839845, "Mean Q2": 208.93962060546875, "critic_loss": 14.78270822906494, "batch_reward": 1.8306397857666015, "actor_loss": -209.29541827786355, "actor_target_entropy": -1.0, "actor_entropy": 0.3140810853050601, "alpha_loss": 0.0008041157815304975, "alpha_value": 0.1975220965221689, "duration": 114.98600459098816, "step": 92000}
{"episode_reward": 279.3016744856885, "episode": 737.0, "Q1 loss": 7.330101566314697, "Q2 loss": 7.28177872467041, "Mean Target Q": 209.04943103027344, "Mean Q1": 209.04795764160156, "Mean Q2": 209.0481845703125, "critic_loss": 14.611880256652832, "batch_reward": 1.8560441608428955, "actor_loss": -209.320313953218, "actor_target_entropy": -1.0, "actor_entropy": 0.3461774883289186, "alpha_loss": 0.0029853518076595805, "alpha_value": 0.1974237172549505, "duration": 129.27010369300842, "step": 92125}
{"episode_reward": 211.10610480478337, "episode": 738.0, "Q1 loss": 7.68218989944458, "Q2 loss": 7.636108173370362, "Mean Target Q": 209.12996899414063, "Mean Q1": 209.12946728515624, "Mean Q2": 209.13014196777343, "critic_loss": 15.31829808807373, "batch_reward": 1.854466157913208, "actor_loss": -209.46200364635837, "actor_target_entropy": -1.0, "actor_entropy": 0.3274574065881391, "alpha_loss": -0.0005687578607560886, "alpha_value": 0.19719878437671828, "duration": 118.84581565856934, "step": 92250}
{"episode_reward": 241.5441070162455, "episode": 739.0, "Q1 loss": 6.937068138122559, "Q2 loss": 6.945116737365723, "Mean Target Q": 209.13154772949218, "Mean Q1": 209.12518176269532, "Mean Q2": 209.12435083007813, "critic_loss": 13.882184829711914, "batch_reward": 1.8572982816696166, "actor_loss": -209.50506930881076, "actor_target_entropy": -1.0, "actor_entropy": 0.3024929499342328, "alpha_loss": 0.004208181659498858, "alpha_value": 0.19708078232409576, "duration": 129.20530581474304, "step": 92375}
{"episode_reward": 276.30192441065543, "episode": 740.0, "Q1 loss": 7.168172050476074, "Q2 loss": 7.181777397155762, "Mean Target Q": 209.05242749023438, "Mean Q1": 209.05583728027344, "Mean Q2": 209.05511657714842, "critic_loss": 14.349949447631836, "batch_reward": 1.8561583042144776, "actor_loss": -209.42305607949532, "actor_target_entropy": -1.0, "actor_entropy": 0.315647859967524, "alpha_loss": 0.0012115536167496635, "alpha_value": 0.19694062952549937, "duration": 127.50457906723022, "step": 92500}
{"episode_reward": 246.44449278598117, "episode": 741.0, "Q1 loss": 7.434624889373779, "Q2 loss": 7.418436412811279, "Mean Target Q": 209.14944445800782, "Mean Q1": 209.1495310058594, "Mean Q2": 209.14970349121094, "critic_loss": 14.853061302185058, "batch_reward": 1.8563572721481323, "actor_loss": -209.49906727624318, "actor_target_entropy": -1.0, "actor_entropy": 0.34954889804597883, "alpha_loss": -0.0007634670288848972, "alpha_value": 0.19672077225372753, "duration": 123.90336036682129, "step": 92625}
{"episode_reward": 233.34768260940763, "episode": 742.0, "Q1 loss": 7.774272937774658, "Q2 loss": 7.823891288757324, "Mean Target Q": 209.13284313964843, "Mean Q1": 209.1309951171875, "Mean Q2": 209.13152136230468, "critic_loss": 15.598164176940918, "batch_reward": 1.85748783493042, "actor_loss": -209.50272812381868, "actor_target_entropy": -1.0, "actor_entropy": 0.3196198704742616, "alpha_loss": 0.0005635829668702377, "alpha_value": 0.19690958701830855, "duration": 126.09844207763672, "step": 92750}
{"episode_reward": 284.8501074049032, "episode": 743.0, "Q1 loss": 7.456854232788086, "Q2 loss": 7.446291316986084, "Mean Target Q": 209.1016484375, "Mean Q1": 209.10071960449218, "Mean Q2": 209.10034240722655, "critic_loss": 14.903145606994629, "batch_reward": 1.8558456573486328, "actor_loss": -209.47061399429563, "actor_target_entropy": -1.0, "actor_entropy": 0.3362102383185947, "alpha_loss": 0.001581689209810325, "alpha_value": 0.1967654302216696, "duration": 116.14577960968018, "step": 92875}
{"episode_reward": 393.25348220211964, "episode": 744.0, "Q1 loss": 7.6492146873474125, "Q2 loss": 7.6740190734863285, "Mean Target Q": 209.24373693847656, "Mean Q1": 209.24087585449217, "Mean Q2": 209.2409327392578, "critic_loss": 15.323233810424805, "batch_reward": 1.8622692527770996, "actor_loss": -209.62683056246848, "actor_target_entropy": -1.0, "actor_entropy": 0.34396168757830897, "alpha_loss": 0.003165012839505629, "alpha_value": 0.19659149704691364, "duration": 123.02208495140076, "step": 93000}
{"episode_reward": 225.09071440882514, "episode": 745.0, "Q1 loss": 7.36425479888916, "Q2 loss": 7.358825408935547, "Mean Target Q": 209.29404541015626, "Mean Q1": 209.29732299804687, "Mean Q2": 209.29665185546875, "critic_loss": 14.72308024597168, "batch_reward": 1.8639243402481078, "actor_loss": -209.62009926447791, "actor_target_entropy": -1.0, "actor_entropy": 0.3350781814919578, "alpha_loss": 0.0012545223155665019, "alpha_value": 0.19643791851255787, "duration": 155.3605399131775, "step": 93125}
{"episode_reward": 230.9725957600999, "episode": 746.0, "Q1 loss": 7.322605434417724, "Q2 loss": 7.337018718719483, "Mean Target Q": 209.22017993164062, "Mean Q1": 209.21592517089843, "Mean Q2": 209.2164580078125, "critic_loss": 14.65962410736084, "batch_reward": 1.8472958421707153, "actor_loss": -209.5405967466293, "actor_target_entropy": -1.0, "actor_entropy": 0.3181708044102115, "alpha_loss": 0.004777522892841409, "alpha_value": 0.19618424405339835, "duration": 258.8675618171692, "step": 93250}
{"episode_reward": 241.83482766561366, "episode": 747.0, "Q1 loss": 7.611888786315918, "Q2 loss": 7.605236343383789, "Mean Target Q": 209.21448864746094, "Mean Q1": 209.21606665039062, "Mean Q2": 209.21592529296876, "critic_loss": 15.217125129699706, "batch_reward": 1.836481761932373, "actor_loss": -209.47885277157738, "actor_target_entropy": -1.0, "actor_entropy": 0.3232895509591178, "alpha_loss": -0.0009180373837432218, "alpha_value": 0.19605233618233714, "duration": 238.30422925949097, "step": 93375}
{"episode_reward": 240.20658806353973, "episode": 748.0, "Q1 loss": 7.381745422363282, "Q2 loss": 7.4229394111633304, "Mean Target Q": 209.41992431640625, "Mean Q1": 209.41475610351563, "Mean Q2": 209.4138739013672, "critic_loss": 14.804684852600097, "batch_reward": 1.8650012550354005, "actor_loss": -209.74194089827998, "actor_target_entropy": -1.0, "actor_entropy": 0.3059324155892095, "alpha_loss": 0.00286941064686905, "alpha_value": 0.1959125787369739, "duration": 224.4158411026001, "step": 93500}
{"episode_reward": 291.14500249359537, "episode": 749.0, "Q1 loss": 7.380549446105957, "Q2 loss": 7.4031723136901855, "Mean Target Q": 209.40048754882812, "Mean Q1": 209.40083459472658, "Mean Q2": 209.401765625, "critic_loss": 14.783721672058105, "batch_reward": 1.8513343677520753, "actor_loss": -209.7286112951854, "actor_target_entropy": -1.0, "actor_entropy": 0.3376310339995793, "alpha_loss": 0.002552612980325071, "alpha_value": 0.19559497842857868, "duration": 205.9650104045868, "step": 93625}
{"episode_reward": 268.15645166263323, "episode": 750.0, "Q1 loss": 7.2167497215270995, "Q2 loss": 7.25802001953125, "Mean Target Q": 209.38652783203125, "Mean Q1": 209.38733764648438, "Mean Q2": 209.38754284667968, "critic_loss": 14.474769813537598, "batch_reward": 1.846810257911682, "actor_loss": -209.70894967356037, "actor_target_entropy": -1.0, "actor_entropy": 0.30991840482719485, "alpha_loss": -0.0017221856734625275, "alpha_value": 0.19563110146764173, "duration": 205.4578776359558, "step": 93750}
{"episode_reward": 243.6920006109959, "episode": 751.0, "Q1 loss": 7.554820150375366, "Q2 loss": 7.551614311218262, "Mean Target Q": 209.52271044921875, "Mean Q1": 209.52249194335937, "Mean Q2": 209.52093322753908, "critic_loss": 15.106434463500976, "batch_reward": 1.8705783386230468, "actor_loss": -209.8470706031436, "actor_target_entropy": -1.0, "actor_entropy": 0.3090805200830338, "alpha_loss": -0.001712721362266512, "alpha_value": 0.19581516038265248, "duration": 203.9178171157837, "step": 93875}
{"episode_reward": 331.9543329823085, "episode": 752.0, "Q1 loss": 7.4993447494506835, "Q2 loss": 7.486986839294434, "Mean Target Q": 209.50356774902343, "Mean Q1": 209.4982900390625, "Mean Q2": 209.49889245605468, "critic_loss": 14.986331596374512, "batch_reward": 1.8600633735656737, "actor_loss": -209.79717746857673, "actor_target_entropy": -1.0, "actor_entropy": 0.3431915991729306, "alpha_loss": 0.0031025578650916296, "alpha_value": 0.19560996377425716, "duration": 181.4031219482422, "step": 94000}
{"episode_reward": 299.74443703227803, "episode": 753.0, "Q1 loss": 7.139791942596435, "Q2 loss": 7.120395404815674, "Mean Target Q": 209.5959267578125, "Mean Q1": 209.59603540039063, "Mean Q2": 209.59659899902343, "critic_loss": 14.260187355041504, "batch_reward": 1.8643096714019776, "actor_loss": -209.97680930485802, "actor_target_entropy": -1.0, "actor_entropy": 0.30256672487372444, "alpha_loss": 0.00397487818854787, "alpha_value": 0.19545878966755928, "duration": 182.50252389907837, "step": 94125}
{"episode_reward": 302.34571033416387, "episode": 754.0, "Q1 loss": 7.2773381614685055, "Q2 loss": 7.276428852081299, "Mean Target Q": 209.52648840332031, "Mean Q1": 209.5243604736328, "Mean Q2": 209.5249541015625, "critic_loss": 14.553766929626464, "batch_reward": 1.8615970544815064, "actor_loss": -209.89251389042025, "actor_target_entropy": -1.0, "actor_entropy": 0.31662696551892067, "alpha_loss": 0.0006942324501822793, "alpha_value": 0.19529406115294984, "duration": 149.9956464767456, "step": 94250}
{"episode_reward": 248.63153836468422, "episode": 755.0, "Q1 loss": 7.388094627380371, "Q2 loss": 7.361954639434814, "Mean Target Q": 209.65059655761718, "Mean Q1": 209.65141076660157, "Mean Q2": 209.6515478515625, "critic_loss": 14.750049179077148, "batch_reward": 1.8677789106369018, "actor_loss": -209.9830087328714, "actor_target_entropy": -1.0, "actor_entropy": 0.31636805619512287, "alpha_loss": -0.0022262174299814636, "alpha_value": 0.19542026853143252, "duration": 150.92638874053955, "step": 94375}
{"episode_reward": 221.6291403241798, "episode": 756.0, "Q1 loss": 7.250456367492676, "Q2 loss": 7.222687292098999, "Mean Target Q": 209.59521411132812, "Mean Q1": 209.5912999267578, "Mean Q2": 209.5900654296875, "critic_loss": 14.473143669128419, "batch_reward": 1.8487831268310546, "actor_loss": -210.02540883710307, "actor_target_entropy": -1.0, "actor_entropy": 0.3183398371742618, "alpha_loss": 0.0049835106211474104, "alpha_value": 0.19512604056067026, "duration": 160.58469223976135, "step": 94500}
{"episode_reward": 306.0719683800894, "episode": 757.0, "Q1 loss": 7.226494186401367, "Q2 loss": 7.190920764923096, "Mean Target Q": 209.67784033203125, "Mean Q1": 209.67516040039064, "Mean Q2": 209.6759454345703, "critic_loss": 14.417414932250976, "batch_reward": 1.86015185546875, "actor_loss": -210.12894306485614, "actor_target_entropy": -1.0, "actor_entropy": 0.3092288105260758, "alpha_loss": -0.0016468055657155457, "alpha_value": 0.19520793933359618, "duration": 140.34918785095215, "step": 94625}
{"episode_reward": 348.3483024743655, "episode": 758.0, "Q1 loss": 7.096834171295166, "Q2 loss": 7.059718013763428, "Mean Target Q": 209.665400390625, "Mean Q1": 209.66635314941405, "Mean Q2": 209.66640405273438, "critic_loss": 14.156552200317384, "batch_reward": 1.8580270805358887, "actor_loss": -209.99206789078252, "actor_target_entropy": -1.0, "actor_entropy": 0.3000526024449256, "alpha_loss": 0.003338114384772076, "alpha_value": 0.19511235792986945, "duration": 144.7765326499939, "step": 94750}
{"episode_reward": 315.6701330591544, "episode": 759.0, "Q1 loss": 7.46790807723999, "Q2 loss": 7.407822631835938, "Mean Target Q": 209.76954565429688, "Mean Q1": 209.76940881347656, "Mean Q2": 209.76943920898438, "critic_loss": 14.87573062133789, "batch_reward": 1.8542561082839966, "actor_loss": -210.16040353926402, "actor_target_entropy": -1.0, "actor_entropy": 0.31935763193501365, "alpha_loss": 0.0010399316097535784, "alpha_value": 0.19485245494682543, "duration": 154.1665403842926, "step": 94875}
{"episode_reward": 239.113404827062, "episode": 760.0, "Q1 loss": 7.471827938079834, "Q2 loss": 7.457425945281982, "Mean Target Q": 209.83098120117188, "Mean Q1": 209.8276154785156, "Mean Q2": 209.8268436279297, "critic_loss": 14.929253898620605, "batch_reward": 1.8645163373947145, "actor_loss": -210.16234662455898, "actor_target_entropy": -1.0, "actor_entropy": 0.2993019256860979, "alpha_loss": 0.0031931255493433245, "alpha_value": 0.1947166885393795, "step": 95000}
{"duration": 184.83034205436707, "step": 95000}
{"episode_reward": 240.40856782739976, "episode": 761.0, "Q1 loss": 7.573742176055908, "Q2 loss": 7.592260807037354, "Mean Target Q": 209.95389453125, "Mean Q1": 209.95629052734375, "Mean Q2": 209.95753430175782, "critic_loss": 15.166002952575683, "batch_reward": 1.865007511138916, "actor_loss": -210.24401395283047, "actor_target_entropy": -1.0, "actor_entropy": 0.3174881748263798, "alpha_loss": 0.00043944971236799447, "alpha_value": 0.1945575191346033, "duration": 171.48891472816467, "step": 95125}
{"episode_reward": 297.79977989297, "episode": 762.0, "Q1 loss": 7.563914180755615, "Q2 loss": 7.630434307098389, "Mean Target Q": 209.91822216796874, "Mean Q1": 209.91465209960938, "Mean Q2": 209.91272729492186, "critic_loss": 15.194348495483398, "batch_reward": 1.8543833293914795, "actor_loss": -210.24658646122103, "actor_target_entropy": -1.0, "actor_entropy": 0.3225839628327277, "alpha_loss": 0.0009308530603565516, "alpha_value": 0.19447407964252098, "duration": 167.0364534854889, "step": 95250}
{"episode_reward": 254.47823746549392, "episode": 763.0, "Q1 loss": 7.441986911773681, "Q2 loss": 7.370031494140625, "Mean Target Q": 210.01489306640624, "Mean Q1": 210.01408264160156, "Mean Q2": 210.0151339111328, "critic_loss": 14.812018379211425, "batch_reward": 1.8636716594696046, "actor_loss": -210.35990033830916, "actor_target_entropy": -1.0, "actor_entropy": 0.32070612055914743, "alpha_loss": 0.005676976421714893, "alpha_value": 0.1942947115546113, "duration": 175.27731943130493, "step": 95375}
{"episode_reward": 240.74838569300508, "episode": 764.0, "Q1 loss": 7.283108427047729, "Q2 loss": 7.3243000679016115, "Mean Target Q": 209.96341857910156, "Mean Q1": 209.96711547851564, "Mean Q2": 209.96704418945313, "critic_loss": 14.607408454895019, "batch_reward": 1.8610989933013915, "actor_loss": -210.3749803112399, "actor_target_entropy": -1.0, "actor_entropy": 0.31310974806547165, "alpha_loss": -0.001307593440757163, "alpha_value": 0.19411034355368428, "duration": 155.69522523880005, "step": 95500}
{"episode_reward": 218.73614635199417, "episode": 765.0, "Q1 loss": 7.4799655876159665, "Q2 loss": 7.511100193023681, "Mean Target Q": 209.9311904296875, "Mean Q1": 209.92560229492187, "Mean Q2": 209.9249217529297, "critic_loss": 14.991065757751464, "batch_reward": 1.8670010709762572, "actor_loss": -210.25092012920078, "actor_target_entropy": -1.0, "actor_entropy": 0.3156400862194243, "alpha_loss": -0.004716374976043072, "alpha_value": 0.1942215044387118, "duration": 154.62440061569214, "step": 95625}
{"episode_reward": 192.05436968243595, "episode": 766.0, "Q1 loss": 7.333726081848145, "Q2 loss": 7.349890865325928, "Mean Target Q": 210.09055688476562, "Mean Q1": 210.0926091308594, "Mean Q2": 210.09205590820312, "critic_loss": 14.683616958618163, "batch_reward": 1.8652027597427367, "actor_loss": -210.4868599676317, "actor_target_entropy": -1.0, "actor_entropy": 0.3018704282660638, "alpha_loss": 0.0018904920791335885, "alpha_value": 0.19449032353274787, "duration": 140.37232661247253, "step": 95750}
{"episode_reward": 193.2864381735825, "episode": 767.0, "Q1 loss": 7.174395797729492, "Q2 loss": 7.184061553955078, "Mean Target Q": 210.08201196289062, "Mean Q1": 210.07478747558594, "Mean Q2": 210.07365307617187, "critic_loss": 14.358457374572755, "batch_reward": 1.8526264200210572, "actor_loss": -210.39276365249876, "actor_target_entropy": -1.0, "actor_entropy": 0.3078859297056047, "alpha_loss": 0.0019614308858142485, "alpha_value": 0.1941278299077384, "duration": 133.38481044769287, "step": 95875}
{"episode_reward": 289.2999185155444, "episode": 768.0, "Q1 loss": 7.495748725891113, "Q2 loss": 7.4838517417907715, "Mean Target Q": 210.24073583984375, "Mean Q1": 210.24510803222657, "Mean Q2": 210.245705078125, "critic_loss": 14.97960041809082, "batch_reward": 1.8621758670806885, "actor_loss": -210.61131631174396, "actor_target_entropy": -1.0, "actor_entropy": 0.30322260794139677, "alpha_loss": 0.006287013405873891, "alpha_value": 0.1939658263042225, "duration": 134.9506676197052, "step": 96000}
{"episode_reward": 239.07879056926072, "episode": 769.0, "Q1 loss": 7.419716663360596, "Q2 loss": 7.41971862411499, "Mean Target Q": 210.2691990966797, "Mean Q1": 210.2657604980469, "Mean Q2": 210.26623046875, "critic_loss": 14.839435317993164, "batch_reward": 1.867201442718506, "actor_loss": -210.62996273949034, "actor_target_entropy": -1.0, "actor_entropy": 0.3110040109308939, "alpha_loss": -4.9872807086637566e-05, "alpha_value": 0.193810384302187, "duration": 137.18945217132568, "step": 96125}
{"episode_reward": 260.4313498857281, "episode": 770.0, "Q1 loss": 7.344247924804687, "Q2 loss": 7.36149153137207, "Mean Target Q": 210.26776000976562, "Mean Q1": 210.2649854736328, "Mean Q2": 210.2652774658203, "critic_loss": 14.705739456176758, "batch_reward": 1.8607782344818116, "actor_loss": -210.6520934566375, "actor_target_entropy": -1.0, "actor_entropy": 0.33148187230671605, "alpha_loss": 0.00618235791860629, "alpha_value": 0.19349462883097554, "duration": 122.25825691223145, "step": 96250}
{"episode_reward": 210.74114826243297, "episode": 771.0, "Q1 loss": 7.364730354309082, "Q2 loss": 7.35155551147461, "Mean Target Q": 210.27187939453125, "Mean Q1": 210.2743232421875, "Mean Q2": 210.27440551757812, "critic_loss": 14.716285926818848, "batch_reward": 1.8456794805526733, "actor_loss": -210.63206942119297, "actor_target_entropy": -1.0, "actor_entropy": 0.29755695069593097, "alpha_loss": -0.001425975957693207, "alpha_value": 0.19333554804955072, "duration": 124.13929986953735, "step": 96375}
{"episode_reward": 249.51924339521386, "episode": 772.0, "Q1 loss": 7.48167032623291, "Q2 loss": 7.497295198440551, "Mean Target Q": 210.29469714355469, "Mean Q1": 210.29395068359375, "Mean Q2": 210.2939207763672, "critic_loss": 14.978965522766114, "batch_reward": 1.8596182441711426, "actor_loss": -210.66462805963332, "actor_target_entropy": -1.0, "actor_entropy": 0.31480432205623193, "alpha_loss": 0.0018394345627917397, "alpha_value": 0.19330852124353098, "duration": 130.75790786743164, "step": 96500}
{"episode_reward": 251.01120521400472, "episode": 773.0, "Q1 loss": 7.480437465667725, "Q2 loss": 7.539322692871094, "Mean Target Q": 210.4293377685547, "Mean Q1": 210.42421899414063, "Mean Q2": 210.4242685546875, "critic_loss": 15.019760093688966, "batch_reward": 1.8706710414886474, "actor_loss": -210.77977328830295, "actor_target_entropy": -1.0, "actor_entropy": 0.30501898153433726, "alpha_loss": 0.003194777123142211, "alpha_value": 0.1930508020463008, "duration": 120.49883723258972, "step": 96625}
{"episode_reward": 304.2887600105804, "episode": 774.0, "Q1 loss": 7.426607391357422, "Q2 loss": 7.399152259826661, "Mean Target Q": 210.43446716308594, "Mean Q1": 210.4337471923828, "Mean Q2": 210.43340368652343, "critic_loss": 14.825759704589844, "batch_reward": 1.8513223762512208, "actor_loss": -210.82987508466167, "actor_target_entropy": -1.0, "actor_entropy": 0.309899159977513, "alpha_loss": -0.004001233764293213, "alpha_value": 0.1931259351214335, "duration": 149.96594834327698, "step": 96750}
{"episode_reward": 226.41148677858575, "episode": 775.0, "Q1 loss": 7.226161373138428, "Q2 loss": 7.207719917297363, "Mean Target Q": 210.47734680175782, "Mean Q1": 210.4790418701172, "Mean Q2": 210.4795283203125, "critic_loss": 14.433881294250488, "batch_reward": 1.8583771419525146, "actor_loss": -210.89332556346105, "actor_target_entropy": -1.0, "actor_entropy": 0.3200724713859104, "alpha_loss": -0.0023701301524563442, "alpha_value": 0.19333486430240737, "duration": 155.28085279464722, "step": 96875}
{"episode_reward": 346.5562998291047, "episode": 776.0, "Q1 loss": 7.189124368667603, "Q2 loss": 7.23334610748291, "Mean Target Q": 210.44973193359374, "Mean Q1": 210.44630627441407, "Mean Q2": 210.4470927734375, "critic_loss": 14.422470443725587, "batch_reward": 1.8744074115753173, "actor_loss": -210.83354826896422, "actor_target_entropy": -1.0, "actor_entropy": 0.31185844973210364, "alpha_loss": 0.005040514399297535, "alpha_value": 0.19315728671850405, "duration": 154.9649474620819, "step": 97000}
{"episode_reward": 258.9826863373753, "episode": 777.0, "Q1 loss": 7.573997184753418, "Q2 loss": 7.566687362670899, "Mean Target Q": 210.57323510742188, "Mean Q1": 210.57275219726563, "Mean Q2": 210.572216796875, "critic_loss": 15.140684524536132, "batch_reward": 1.8682324953079223, "actor_loss": -210.95409187437997, "actor_target_entropy": -1.0, "actor_entropy": 0.30119764379092623, "alpha_loss": 0.003175725064624751, "alpha_value": 0.19279218281577223, "duration": 164.9397747516632, "step": 97125}
{"episode_reward": 288.42298071710024, "episode": 778.0, "Q1 loss": 7.067212333679199, "Q2 loss": 7.02436782836914, "Mean Target Q": 210.61868286132812, "Mean Q1": 210.61376770019533, "Mean Q2": 210.61472998046875, "critic_loss": 14.09158016204834, "batch_reward": 1.8666156349182128, "actor_loss": -211.04386803411668, "actor_target_entropy": -1.0, "actor_entropy": 0.338743636685033, "alpha_loss": 4.753331849051099e-05, "alpha_value": 0.1926257591192703, "duration": 154.3857970237732, "step": 97250}
{"episode_reward": 193.62003887647364, "episode": 779.0, "Q1 loss": 7.605053665161133, "Q2 loss": 7.584955024719238, "Mean Target Q": 210.59624365234376, "Mean Q1": 210.59410998535157, "Mean Q2": 210.59301293945313, "critic_loss": 15.190008750915528, "batch_reward": 1.8669571285247804, "actor_loss": -210.97991386292472, "actor_target_entropy": -1.0, "actor_entropy": 0.2796588854657279, "alpha_loss": 0.001390102378550976, "alpha_value": 0.1926582529711779, "duration": 163.3449146747589, "step": 97375}
{"episode_reward": 253.2049956636309, "episode": 780.0, "Q1 loss": 7.579199359893799, "Q2 loss": 7.588446056365966, "Mean Target Q": 210.58655676269532, "Mean Q1": 210.59181652832032, "Mean Q2": 210.59230297851562, "critic_loss": 15.167645393371583, "batch_reward": 1.8623308992385865, "actor_loss": -210.94525564870526, "actor_target_entropy": -1.0, "actor_entropy": 0.3007328144965633, "alpha_loss": -0.00207144966454155, "alpha_value": 0.19277989097525275, "duration": 154.5226035118103, "step": 97500}
{"episode_reward": 226.85784761266953, "episode": 781.0, "Q1 loss": 7.324175128936767, "Q2 loss": 7.336247478485108, "Mean Target Q": 210.5804600830078, "Mean Q1": 210.575787109375, "Mean Q2": 210.57485571289064, "critic_loss": 14.660422615051269, "batch_reward": 1.851245394706726, "actor_loss": -210.94720216781374, "actor_target_entropy": -1.0, "actor_entropy": 0.2951931409419529, "alpha_loss": -0.0006919099897560147, "alpha_value": 0.1928858929654642, "duration": 149.11494755744934, "step": 97625}
{"episode_reward": 210.0568531397994, "episode": 782.0, "Q1 loss": 7.246685356140136, "Q2 loss": 7.22899927520752, "Mean Target Q": 210.64944189453124, "Mean Q1": 210.64861547851564, "Mean Q2": 210.64931811523437, "critic_loss": 14.475684593200684, "batch_reward": 1.8494484243392944, "actor_loss": -210.94564597837388, "actor_target_entropy": -1.0, "actor_entropy": 0.32573073117002366, "alpha_loss": 0.0038712367963706774, "alpha_value": 0.19270421141686644, "duration": 154.70847296714783, "step": 97750}
{"episode_reward": 264.6601515577114, "episode": 783.0, "Q1 loss": 7.370173725128174, "Q2 loss": 7.389630786895752, "Mean Target Q": 210.69715991210938, "Mean Q1": 210.70128955078124, "Mean Q2": 210.7001123046875, "critic_loss": 14.759804512023926, "batch_reward": 1.8575822639465331, "actor_loss": -211.14891512431797, "actor_target_entropy": -1.0, "actor_entropy": 0.32286464150935884, "alpha_loss": -0.0032389892028674245, "alpha_value": 0.1927593315442838, "duration": 141.50240969657898, "step": 97875}
{"episode_reward": 225.77804872232352, "episode": 784.0, "Q1 loss": 7.452618553161621, "Q2 loss": 7.460652141571045, "Mean Target Q": 210.75049060058595, "Mean Q1": 210.74534448242187, "Mean Q2": 210.7459289550781, "critic_loss": 14.913270652770995, "batch_reward": 1.8684875860214234, "actor_loss": -211.04591394239856, "actor_target_entropy": -1.0, "actor_entropy": 0.29578312870956236, "alpha_loss": -0.00088249561527083, "alpha_value": 0.19293207049156963, "duration": 123.35247039794922, "step": 98000}
{"episode_reward": 245.67019022106876, "episode": 785.0, "Q1 loss": 7.5542266578674315, "Q2 loss": 7.565671667098999, "Mean Target Q": 210.70085803222656, "Mean Q1": 210.70235791015625, "Mean Q2": 210.70188427734374, "critic_loss": 15.119898300170899, "batch_reward": 1.8590169467926025, "actor_loss": -211.09331500341023, "actor_target_entropy": -1.0, "actor_entropy": 0.3163908123970032, "alpha_loss": -0.0022450075152197053, "alpha_value": 0.19303422858033367, "duration": 125.92997550964355, "step": 98125}
{"episode_reward": 259.30199231592104, "episode": 786.0, "Q1 loss": 7.415144203186035, "Q2 loss": 7.3897641677856445, "Mean Target Q": 210.82043286132813, "Mean Q1": 210.8170753173828, "Mean Q2": 210.818427734375, "critic_loss": 14.804908309936524, "batch_reward": 1.8703502750396728, "actor_loss": -211.1258079774918, "actor_target_entropy": -1.0, "actor_entropy": 0.306887440143093, "alpha_loss": -0.00043877334739532203, "alpha_value": 0.19308985481334331, "duration": 131.58415627479553, "step": 98250}
{"episode_reward": 266.12041105303, "episode": 787.0, "Q1 loss": 7.3869746360778805, "Q2 loss": 7.388513683319092, "Mean Target Q": 210.8590380859375, "Mean Q1": 210.8518427734375, "Mean Q2": 210.85131127929688, "critic_loss": 14.775488342285156, "batch_reward": 1.8727525682449342, "actor_loss": -211.2208009750124, "actor_target_entropy": -1.0, "actor_entropy": 0.2881472957512689, "alpha_loss": 0.0027448356813115494, "alpha_value": 0.19299818293858298, "duration": 118.98728966712952, "step": 98375}
{"episode_reward": 295.0572996874056, "episode": 788.0, "Q1 loss": 7.259972396850586, "Q2 loss": 7.256740123748779, "Mean Target Q": 210.90983044433594, "Mean Q1": 210.9122080078125, "Mean Q2": 210.91314892578126, "critic_loss": 14.516712547302246, "batch_reward": 1.8631978158950806, "actor_loss": -211.2352056195659, "actor_target_entropy": -1.0, "actor_entropy": 0.30205232241461355, "alpha_loss": 0.0009287292580871333, "alpha_value": 0.19294609199104926, "duration": 128.78531098365784, "step": 98500}
{"episode_reward": 211.22403116420145, "episode": 789.0, "Q1 loss": 7.365024406433106, "Q2 loss": 7.379835338592529, "Mean Target Q": 210.8822443847656, "Mean Q1": 210.88214697265624, "Mean Q2": 210.88177880859374, "critic_loss": 14.744859817504883, "batch_reward": 1.8727866344451904, "actor_loss": -211.20911952427454, "actor_target_entropy": -1.0, "actor_entropy": 0.2792088408318777, "alpha_loss": 0.005840200228646161, "alpha_value": 0.19260502937489712, "duration": 164.91737484931946, "step": 98625}
{"episode_reward": 261.56633651598213, "episode": 790.0, "Q1 loss": 7.191993068695068, "Q2 loss": 7.197968109130859, "Mean Target Q": 210.88266369628906, "Mean Q1": 210.88510986328126, "Mean Q2": 210.88454150390626, "critic_loss": 14.389961166381836, "batch_reward": 1.8556804218292235, "actor_loss": -211.21909726050592, "actor_target_entropy": -1.0, "actor_entropy": 0.32878632098436356, "alpha_loss": -0.0029128589442059876, "alpha_value": 0.19239717747416035, "duration": 161.82072758674622, "step": 98750}
{"episode_reward": 257.5794550387096, "episode": 791.0, "Q1 loss": 7.272478633880615, "Q2 loss": 7.239113143920898, "Mean Target Q": 210.91087609863283, "Mean Q1": 210.9095408935547, "Mean Q2": 210.90924426269532, "critic_loss": 14.511591758728027, "batch_reward": 1.8618516225814818, "actor_loss": -211.2551766047402, "actor_target_entropy": -1.0, "actor_entropy": 0.30673851924283163, "alpha_loss": -0.0006352853739545459, "alpha_value": 0.1925568007791483, "duration": 151.62510108947754, "step": 98875}
{"episode_reward": 233.09272738202796, "episode": 792.0, "Q1 loss": 7.517382110595703, "Q2 loss": 7.482804332733155, "Mean Target Q": 210.9236290283203, "Mean Q1": 210.92190356445312, "Mean Q2": 210.92370373535155, "critic_loss": 15.000186393737794, "batch_reward": 1.8566198692321778, "actor_loss": -211.28944298528856, "actor_target_entropy": -1.0, "actor_entropy": 0.312581239688781, "alpha_loss": -0.0008312342782324601, "alpha_value": 0.19274811065371444, "duration": 155.11522507667542, "step": 99000}
{"episode_reward": 274.30267189795046, "episode": 793.0, "Q1 loss": 7.166182121276855, "Q2 loss": 7.18232377243042, "Mean Target Q": 210.90523388671875, "Mean Q1": 210.9049814453125, "Mean Q2": 210.90374548339844, "critic_loss": 14.348505851745605, "batch_reward": 1.860591320037842, "actor_loss": -211.34224398173984, "actor_target_entropy": -1.0, "actor_entropy": 0.3197868892124721, "alpha_loss": -0.0014511273863414924, "alpha_value": 0.19267760881623155, "duration": 144.2841715812683, "step": 99125}
{"episode_reward": 305.13384022642435, "episode": 794.0, "Q1 loss": 7.229842323303223, "Q2 loss": 7.219207241058349, "Mean Target Q": 211.04921459960937, "Mean Q1": 211.04264611816407, "Mean Q2": 211.04246484375, "critic_loss": 14.449049613952637, "batch_reward": 1.8729132652282714, "actor_loss": -211.3502704251197, "actor_target_entropy": -1.0, "actor_entropy": 0.3378414740004847, "alpha_loss": 0.003725072641241094, "alpha_value": 0.19264252150835454, "duration": 164.70607948303223, "step": 99250}
{"episode_reward": 281.32905533581265, "episode": 795.0, "Q1 loss": 7.367498062133789, "Q2 loss": 7.3679150924682615, "Mean Target Q": 211.00728015136718, "Mean Q1": 211.0131599121094, "Mean Q2": 211.01347741699217, "critic_loss": 14.735413162231445, "batch_reward": 1.8689173498153686, "actor_loss": -211.42227463495163, "actor_target_entropy": -1.0, "actor_entropy": 0.3276597233045669, "alpha_loss": 0.0002496495606407287, "alpha_value": 0.19263699430675876, "duration": 164.05025458335876, "step": 99375}
{"episode_reward": 249.8651699587469, "episode": 796.0, "Q1 loss": 7.254067768096924, "Q2 loss": 7.273235069274902, "Mean Target Q": 211.01788830566406, "Mean Q1": 211.01222192382812, "Mean Q2": 211.01157788085936, "critic_loss": 14.527302848815918, "batch_reward": 1.8675435791015624, "actor_loss": -211.36825979909588, "actor_target_entropy": -1.0, "actor_entropy": 0.31272961487693174, "alpha_loss": 0.004940845449680402, "alpha_value": 0.19241606151739052, "duration": 131.94351315498352, "step": 99500}
{"episode_reward": 263.2010061998691, "episode": 797.0, "Q1 loss": 7.337380443572998, "Q2 loss": 7.308093776702881, "Mean Target Q": 211.13409008789063, "Mean Q1": 211.13425500488282, "Mean Q2": 211.13423315429688, "critic_loss": 14.645474197387696, "batch_reward": 1.8680603551864623, "actor_loss": -211.55706012059773, "actor_target_entropy": -1.0, "actor_entropy": 0.30176297965503873, "alpha_loss": -0.0028953170440795405, "alpha_value": 0.19229056139676687, "duration": 124.67303347587585, "step": 99625}
{"episode_reward": 217.02179516071268, "episode": 798.0, "Q1 loss": 7.549586162567139, "Q2 loss": 7.545396369934082, "Mean Target Q": 211.04985681152343, "Mean Q1": 211.04857202148438, "Mean Q2": 211.04750939941405, "critic_loss": 15.094982566833496, "batch_reward": 1.8706929340362548, "actor_loss": -211.41321883663053, "actor_target_entropy": -1.0, "actor_entropy": 0.30010443853755153, "alpha_loss": 0.0028671111457139976, "alpha_value": 0.1923248864617576, "duration": 144.11485052108765, "step": 99750}
{"episode_reward": 260.6711859460893, "episode": 799.0, "Q1 loss": 7.488673713684082, "Q2 loss": 7.458192352294922, "Mean Target Q": 211.1530526123047, "Mean Q1": 211.14986767578125, "Mean Q2": 211.1498642578125, "critic_loss": 14.946866096496581, "batch_reward": 1.8642623586654663, "actor_loss": -211.57331920805433, "actor_target_entropy": -1.0, "actor_entropy": 0.2815079568397431, "alpha_loss": -0.0040694822017694745, "alpha_value": 0.19230034914443364, "duration": 138.8208520412445, "step": 99875}
{"episode_reward": 283.09491798676, "episode": 800.0, "Q1 loss": 7.5824737856465, "Q2 loss": 7.5676614815189, "Mean Target Q": 211.16336576400263, "Mean Q1": 211.16717110910724, "Mean Q2": 211.1683441900438, "critic_loss": 15.150135247938094, "batch_reward": 1.8787747179308245, "actor_loss": -211.51643863801033, "actor_target_entropy": -1.0, "actor_entropy": 0.30837306284135385, "alpha_loss": -0.002479025553311071, "alpha_value": 0.1925743259431997, "step": 99999}
