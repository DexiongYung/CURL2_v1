{"episode_reward": 0.0, "episode": 1.0, "duration": 25.412673711776733, "step": 125}
{"episode_reward": 188.54858664024, "episode": 2.0, "duration": 0.8190720081329346, "step": 250}
{"episode_reward": 148.42677041475667, "episode": 3.0, "duration": 0.8123831748962402, "step": 375}
{"episode_reward": 96.18193741935099, "episode": 4.0, "duration": 0.8122057914733887, "step": 500}
{"episode_reward": 82.30982819659563, "episode": 5.0, "duration": 0.8110432624816895, "step": 625}
{"episode_reward": 198.98424208864233, "episode": 6.0, "duration": 0.8165445327758789, "step": 750}
{"episode_reward": 159.49821390562659, "episode": 7.0, "duration": 0.8137362003326416, "step": 875}
{"episode_reward": 113.95622178975879, "episode": 8.0, "duration": 0.8203864097595215, "step": 1000}
{"episode_reward": 89.62519938559855, "episode": 9.0, "Q1 loss": 1.728877685546875, "Q2 loss": 1.7352690839767455, "Mean Target Q": 1.9857448878288269, "Mean Q1": 1.969388471633196, "Mean Q2": 1.9699079670906068, "critic_loss": 3.464146764755249, "batch_reward": 1.1006787672042846, "actor_loss": -2.021476538171844, "actor_target_entropy": -1.0, "actor_entropy": 1.0899670076748682, "alpha_loss": 0.11492387314755766, "alpha_value": 0.09981112522416777, "duration": 167.586186170578, "step": 1125}
{"episode_reward": 173.20886845378377, "episode": 10.0, "Q1 loss": 1.6555540542602538, "Q2 loss": 1.6555684986114503, "Mean Target Q": 2.8615894088745115, "Mean Q1": 2.8566806888580323, "Mean Q2": 2.856862535476685, "critic_loss": 3.3111225509643556, "batch_reward": 1.1243561725616456, "actor_loss": -2.9497232014133083, "actor_target_entropy": -1.0, "actor_entropy": 1.1830101666911956, "alpha_loss": 0.1386964809029333, "alpha_value": 0.09921534200282818, "duration": 160.43207359313965, "step": 1250}
{"episode_reward": 193.62403104077723, "episode": 11.0, "Q1 loss": 1.0522695684432983, "Q2 loss": 1.0514130973815918, "Mean Target Q": 3.466263595581055, "Mean Q1": 3.4650146312713623, "Mean Q2": 3.4651364822387696, "critic_loss": 2.10368266248703, "batch_reward": 1.145977873802185, "actor_loss": -3.524822057239593, "actor_target_entropy": -1.0, "actor_entropy": 1.227523302275037, "alpha_loss": 0.14705087303642242, "alpha_value": 0.09860348828949586, "duration": 156.67097854614258, "step": 1375}
{"episode_reward": 165.72273541738184, "episode": 12.0, "Q1 loss": 0.5522095475196839, "Q2 loss": 0.5511925120353699, "Mean Target Q": 3.8004587955474856, "Mean Q1": 3.799154411315918, "Mean Q2": 3.799177444458008, "critic_loss": 1.1034020581245423, "batch_reward": 1.1753932332992554, "actor_loss": -3.8631349609744166, "actor_target_entropy": -1.0, "actor_entropy": 1.2296074609602652, "alpha_loss": 0.15912290974970786, "alpha_value": 0.09793418681674419, "duration": 164.93550038337708, "step": 1500}
{"episode_reward": 163.18395906796357, "episode": 13.0, "Q1 loss": 0.5795802171230316, "Q2 loss": 0.5795327498912811, "Mean Target Q": 4.2932439804077145, "Mean Q1": 4.292350074768066, "Mean Q2": 4.292284564971924, "critic_loss": 1.1591129660606385, "batch_reward": 1.139573278427124, "actor_loss": -4.349553059017848, "actor_target_entropy": -1.0, "actor_entropy": 1.2361897532902066, "alpha_loss": 0.15823676827408018, "alpha_value": 0.09728038009326485, "duration": 158.86615681648254, "step": 1625}
{"episode_reward": 4.7741352380156306, "episode": 14.0, "Q1 loss": 0.7255104744434356, "Q2 loss": 0.7239095396995544, "Mean Target Q": 4.722969989776612, "Mean Q1": 4.717666397094726, "Mean Q2": 4.717688690185547, "critic_loss": 1.4494200177192689, "batch_reward": 1.0861157279014588, "actor_loss": -4.768854787272792, "actor_target_entropy": -1.0, "actor_entropy": 1.1986191618827082, "alpha_loss": 0.15852803712890995, "alpha_value": 0.09664188788495082, "duration": 136.80654120445251, "step": 1750}
{"episode_reward": 172.60351330537628, "episode": 15.0, "Q1 loss": 0.8813348550796509, "Q2 loss": 0.8817337923049927, "Mean Target Q": 5.3055868911743165, "Mean Q1": 5.301648643493652, "Mean Q2": 5.301699398040771, "critic_loss": 1.763068645477295, "batch_reward": 1.0880975399017334, "actor_loss": -5.350756425706167, "actor_target_entropy": -1.0, "actor_entropy": 1.1854242313475836, "alpha_loss": 0.15253580680915288, "alpha_value": 0.0960215694083643, "duration": 97.13066172599792, "step": 1875}
{"episode_reward": 49.70421169783849, "episode": 16.0, "Q1 loss": 1.1119013652801513, "Q2 loss": 1.110117103099823, "Mean Target Q": 5.850251083374023, "Mean Q1": 5.847015857696533, "Mean Q2": 5.846866092681885, "critic_loss": 2.2220184659957884, "batch_reward": 1.0658278398513794, "actor_loss": -5.916614570925312, "actor_target_entropy": -1.0, "actor_entropy": 1.1649782398054678, "alpha_loss": 0.14565665419063262, "alpha_value": 0.09543428361130374, "duration": 92.09135699272156, "step": 2000}
{"episode_reward": 196.0884334526776, "episode": 17.0, "Q1 loss": 1.2108758878707886, "Q2 loss": 1.2104884357452392, "Mean Target Q": 6.509292835235596, "Mean Q1": 6.5064386405944825, "Mean Q2": 6.506776863098144, "critic_loss": 2.421364323616028, "batch_reward": 1.077313648223877, "actor_loss": -6.584338672577389, "actor_target_entropy": -1.0, "actor_entropy": 1.1047218385196866, "alpha_loss": 0.1256983806453054, "alpha_value": 0.09489873983752181, "duration": 120.03741312026978, "step": 2125}
{"episode_reward": 73.23864803145531, "episode": 18.0, "Q1 loss": 1.401497733592987, "Q2 loss": 1.4024037575721742, "Mean Target Q": 7.028167465209961, "Mean Q1": 7.025394435882569, "Mean Q2": 7.024991149902344, "critic_loss": 2.8039015045166016, "batch_reward": 1.059940911769867, "actor_loss": -7.127015413776521, "actor_target_entropy": -1.0, "actor_entropy": 1.069237312962932, "alpha_loss": 0.10763656696484934, "alpha_value": 0.09442259744565443, "duration": 115.77274060249329, "step": 2250}
{"episode_reward": 72.68047079479088, "episode": 19.0, "Q1 loss": 1.3986987667083741, "Q2 loss": 1.4006729383468628, "Mean Target Q": 7.5855130729675295, "Mean Q1": 7.582524154663086, "Mean Q2": 7.582663440704346, "critic_loss": 2.7993716955184937, "batch_reward": 1.035124346256256, "actor_loss": -7.711817733825199, "actor_target_entropy": -1.0, "actor_entropy": 1.0447180554980324, "alpha_loss": 0.09623022330185724, "alpha_value": 0.09400496672068055, "duration": 100.34946751594543, "step": 2375}
{"episode_reward": 128.08892307640983, "episode": 20.0, "Q1 loss": 1.839352557182312, "Q2 loss": 1.839705376625061, "Mean Target Q": 8.253115489959717, "Mean Q1": 8.249800983428955, "Mean Q2": 8.249655338287354, "critic_loss": 3.6790579376220705, "batch_reward": 1.0467376098632812, "actor_loss": -8.40303740193767, "actor_target_entropy": -1.0, "actor_entropy": 1.0298207354161046, "alpha_loss": 0.0848010087445859, "alpha_value": 0.09362721229422727, "duration": 98.98198699951172, "step": 2500}
{"episode_reward": 142.93745195361828, "episode": 21.0, "Q1 loss": 1.7061605467796326, "Q2 loss": 1.7055711817741395, "Mean Target Q": 8.933993194580077, "Mean Q1": 8.92898480987549, "Mean Q2": 8.929051361083985, "critic_loss": 3.4117317266464235, "batch_reward": 1.0495371623039245, "actor_loss": -9.133268235221742, "actor_target_entropy": -1.0, "actor_entropy": 1.0026632963664948, "alpha_loss": 0.06762118708519708, "alpha_value": 0.09328884533329097, "duration": 159.87166666984558, "step": 2625}
{"episode_reward": 180.19533694185293, "episode": 22.0, "Q1 loss": 1.9843136224746705, "Q2 loss": 1.9839245138168335, "Mean Target Q": 9.605999580383301, "Mean Q1": 9.601729034423828, "Mean Q2": 9.601444358825683, "critic_loss": 3.9682381162643434, "batch_reward": 1.0576241660118102, "actor_loss": -9.894887478120866, "actor_target_entropy": -1.0, "actor_entropy": 0.960469780429717, "alpha_loss": 0.05651440504457681, "alpha_value": 0.0930035991301722, "duration": 186.08109307289124, "step": 2750}
{"episode_reward": 140.977394740127, "episode": 23.0, "Q1 loss": 1.8253785495758057, "Q2 loss": 1.8259044866561889, "Mean Target Q": 10.337980529785156, "Mean Q1": 10.33259065246582, "Mean Q2": 10.332773178100586, "critic_loss": 3.651283052444458, "batch_reward": 1.056021047592163, "actor_loss": -10.653339552500892, "actor_target_entropy": -1.0, "actor_entropy": 0.9304001425939893, "alpha_loss": 0.046825751425727966, "alpha_value": 0.09276844559467572, "duration": 145.84014868736267, "step": 2875}
{"episode_reward": 8.744003184977874, "episode": 24.0, "Q1 loss": 2.033779932498932, "Q2 loss": 2.0380994086265565, "Mean Target Q": 11.044810989379883, "Mean Q1": 11.034871948242188, "Mean Q2": 11.034543968200683, "critic_loss": 4.071879334449768, "batch_reward": 1.0355353546142578, "actor_loss": -11.377207986770138, "actor_target_entropy": -1.0, "actor_entropy": 1.0080234264173815, "alpha_loss": 0.040459588800947514, "alpha_value": 0.09255009073803716, "duration": 155.92959570884705, "step": 3000}
{"episode_reward": 200.691954426482, "episode": 25.0, "Q1 loss": 2.8913968839645388, "Q2 loss": 2.8970360174179075, "Mean Target Q": 11.73176889038086, "Mean Q1": 11.729697479248047, "Mean Q2": 11.728993087768554, "critic_loss": 5.788432880401611, "batch_reward": 1.0378404598236084, "actor_loss": -12.11888561551533, "actor_target_entropy": -1.0, "actor_entropy": 1.0225755742618017, "alpha_loss": 0.02944249673450868, "alpha_value": 0.09236793736183485, "duration": 138.95856404304504, "step": 3125}
{"episode_reward": 115.7836733514812, "episode": 26.0, "Q1 loss": 2.9709187135696413, "Q2 loss": 2.973116912841797, "Mean Target Q": 12.46766830444336, "Mean Q1": 12.46284432220459, "Mean Q2": 12.463041656494141, "critic_loss": 5.94403564453125, "batch_reward": 1.0412709860801697, "actor_loss": -12.874969405512656, "actor_target_entropy": -1.0, "actor_entropy": 0.990108702451952, "alpha_loss": 0.01336353701621955, "alpha_value": 0.0922348362546868, "duration": 135.40723252296448, "step": 3250}
{"episode_reward": 155.71814686273063, "episode": 27.0, "Q1 loss": 3.011089550971985, "Q2 loss": 3.0084841690063477, "Mean Target Q": 13.193498466491699, "Mean Q1": 13.186224731445312, "Mean Q2": 13.186136474609375, "critic_loss": 6.0195737590789795, "batch_reward": 1.0446161460876464, "actor_loss": -13.673642340160551, "actor_target_entropy": -1.0, "actor_entropy": 0.8727889354266818, "alpha_loss": -0.017450968463284273, "alpha_value": 0.09224548141344326, "duration": 167.4733362197876, "step": 3375}
{"episode_reward": 132.0077227575538, "episode": 28.0, "Q1 loss": 3.0042141284942625, "Q2 loss": 3.0088226127624513, "Mean Target Q": 14.07570775604248, "Mean Q1": 14.07697127532959, "Mean Q2": 14.07717805480957, "critic_loss": 6.013036756515503, "batch_reward": 1.0484718146324157, "actor_loss": -14.655093577600294, "actor_target_entropy": -1.0, "actor_entropy": 0.8209023273760273, "alpha_loss": -0.03235197987317318, "alpha_value": 0.09240518469718903, "duration": 153.95834064483643, "step": 3500}
{"episode_reward": 122.85592968019071, "episode": 29.0, "Q1 loss": 3.1013181447982787, "Q2 loss": 3.107400668144226, "Mean Target Q": 14.894781715393066, "Mean Q1": 14.887246810913085, "Mean Q2": 14.886975006103516, "critic_loss": 6.208718788146973, "batch_reward": 1.0456290040016174, "actor_loss": -15.592993100484213, "actor_target_entropy": -1.0, "actor_entropy": 0.7644502567866492, "alpha_loss": -0.0399821215264854, "alpha_value": 0.09262275920453547, "duration": 117.13760113716125, "step": 3625}
{"episode_reward": 142.62737734184827, "episode": 30.0, "Q1 loss": 3.2112383136749267, "Q2 loss": 3.225432396888733, "Mean Target Q": 15.993249267578125, "Mean Q1": 15.987152534484864, "Mean Q2": 15.9872993850708, "critic_loss": 6.436670694351196, "batch_reward": 1.054303265094757, "actor_loss": -16.6872398161119, "actor_target_entropy": -1.0, "actor_entropy": 0.739840522889168, "alpha_loss": -0.04490541032845936, "alpha_value": 0.09289902866484519, "duration": 72.60665893554688, "step": 3750}
{"episode_reward": 111.08855507552727, "episode": 31.0, "Q1 loss": 3.3158133964538576, "Q2 loss": 3.3217520179748536, "Mean Target Q": 17.02245553588867, "Mean Q1": 17.01680561828613, "Mean Q2": 17.016661529541015, "critic_loss": 6.637565406799316, "batch_reward": 1.0548867664337158, "actor_loss": -17.828149068923224, "actor_target_entropy": -1.0, "actor_entropy": 0.6723535245373136, "alpha_loss": -0.05063874587889702, "alpha_value": 0.09320208228043075, "duration": 82.37599968910217, "step": 3875}
{"episode_reward": 189.97880737561397, "episode": 32.0, "Q1 loss": 3.604974618911743, "Q2 loss": 3.6074864082336426, "Mean Target Q": 18.1557073059082, "Mean Q1": 18.14958757019043, "Mean Q2": 18.14972750854492, "critic_loss": 7.212461036682129, "batch_reward": 1.0528586111068725, "actor_loss": -18.98279897628292, "actor_target_entropy": -1.0, "actor_entropy": 0.673557702572115, "alpha_loss": -0.054900911186010606, "alpha_value": 0.09356487401501289, "duration": 145.08253049850464, "step": 4000}
{"episode_reward": 111.45814212204372, "episode": 33.0, "Q1 loss": 3.520946912765503, "Q2 loss": 3.5252580871582033, "Mean Target Q": 19.203876892089845, "Mean Q1": 19.198704452514647, "Mean Q2": 19.198469116210937, "critic_loss": 7.046204978942871, "batch_reward": 1.0510002961158753, "actor_loss": -20.11811117141966, "actor_target_entropy": -1.0, "actor_entropy": 0.6801850833590068, "alpha_loss": -0.05641370018323263, "alpha_value": 0.09395579281131791, "duration": 141.0210452079773, "step": 4125}
{"episode_reward": 166.639395561943, "episode": 34.0, "Q1 loss": 3.4061620121002196, "Q2 loss": 3.403884078979492, "Mean Target Q": 20.397676177978514, "Mean Q1": 20.392667999267577, "Mean Q2": 20.392979598999023, "critic_loss": 6.810046077728272, "batch_reward": 1.0637716226577758, "actor_loss": -21.334685479440996, "actor_target_entropy": -1.0, "actor_entropy": 0.616473003260551, "alpha_loss": -0.06570659595872125, "alpha_value": 0.09438505940850263, "duration": 110.63438606262207, "step": 4250}
{"episode_reward": 165.7057390299126, "episode": 35.0, "Q1 loss": 3.575063953399658, "Q2 loss": 3.5653401165008547, "Mean Target Q": 21.761467742919923, "Mean Q1": 21.753358779907227, "Mean Q2": 21.752369781494142, "critic_loss": 7.140404094696045, "batch_reward": 1.0841141104698182, "actor_loss": -22.777037423754496, "actor_target_entropy": -1.0, "actor_entropy": 0.6538505260906522, "alpha_loss": -0.06245476202595802, "alpha_value": 0.09484740932078434, "duration": 115.90787148475647, "step": 4375}
{"episode_reward": 184.36187031837298, "episode": 36.0, "Q1 loss": 3.694562858581543, "Q2 loss": 3.71078786277771, "Mean Target Q": 23.015716049194335, "Mean Q1": 23.01174450683594, "Mean Q2": 23.011221435546876, "critic_loss": 7.40535071182251, "batch_reward": 1.086115451335907, "actor_loss": -24.04656450210079, "actor_target_entropy": -1.0, "actor_entropy": 0.6674770083158247, "alpha_loss": -0.07215176120160087, "alpha_value": 0.09534475054435436, "duration": 147.83235025405884, "step": 4500}
{"episode_reward": 188.93065994891316, "episode": 37.0, "Q1 loss": 3.9283218116760255, "Q2 loss": 3.932176021575928, "Mean Target Q": 24.394249725341798, "Mean Q1": 24.387500549316407, "Mean Q2": 24.387706848144532, "critic_loss": 7.860497859954834, "batch_reward": 1.1003200173377992, "actor_loss": -25.47305736844502, "actor_target_entropy": -1.0, "actor_entropy": 0.6522407843953087, "alpha_loss": -0.08040005311606423, "alpha_value": 0.0959194076726293, "duration": 165.02638244628906, "step": 4625}
{"episode_reward": 152.68895237636892, "episode": 38.0, "Q1 loss": 3.8561679782867433, "Q2 loss": 3.8626327610015867, "Mean Target Q": 25.61818879699707, "Mean Q1": 25.613452117919923, "Mean Q2": 25.612691680908203, "critic_loss": 7.718800720214844, "batch_reward": 1.0970397396087646, "actor_loss": -26.74225994848436, "actor_target_entropy": -1.0, "actor_entropy": 0.6377957919912953, "alpha_loss": -0.07848300159938874, "alpha_value": 0.09651677574405362, "duration": 159.56301712989807, "step": 4750}
{"episode_reward": 169.28360129121793, "episode": 39.0, "Q1 loss": 3.8326313343048097, "Q2 loss": 3.8445982723236085, "Mean Target Q": 27.011261993408205, "Mean Q1": 27.003187728881837, "Mean Q2": 27.00315657043457, "critic_loss": 7.677229625701904, "batch_reward": 1.1060195484161377, "actor_loss": -28.187329912942552, "actor_target_entropy": -1.0, "actor_entropy": 0.6424527064202323, "alpha_loss": -0.0823186534856047, "alpha_value": 0.09713003550652896, "duration": 159.80636858940125, "step": 4875}
{"episode_reward": 235.84512542458654, "episode": 40.0, "Q1 loss": 3.7926998653411865, "Q2 loss": 3.8097644920349123, "Mean Target Q": 28.402270614624022, "Mean Q1": 28.395561325073242, "Mean Q2": 28.395247482299805, "critic_loss": 7.602464393615723, "batch_reward": 1.1324584846496581, "actor_loss": -29.629764710703203, "actor_target_entropy": -1.0, "actor_entropy": 0.6220833043898305, "alpha_loss": -0.08685857117656738, "alpha_value": 0.09776998799777849, "step": 5000}
{"duration": 156.88129091262817, "step": 5000}
{"episode_reward": 149.8004450406081, "episode": 41.0, "Q1 loss": 3.7696035137176516, "Q2 loss": 3.767344913482666, "Mean Target Q": 29.497430740356446, "Mean Q1": 29.497919662475585, "Mean Q2": 29.49847024536133, "critic_loss": 7.536948421478272, "batch_reward": 1.1109604382514953, "actor_loss": -30.687457069518075, "actor_target_entropy": -1.0, "actor_entropy": 0.6226177877850003, "alpha_loss": -0.08775065626416888, "alpha_value": 0.09843202644190359, "duration": 140.07599329948425, "step": 5125}
{"episode_reward": 82.92419989237997, "episode": 42.0, "Q1 loss": 4.0750297203063965, "Q2 loss": 4.088667121887207, "Mean Target Q": 30.86915182495117, "Mean Q1": 30.86216246032715, "Mean Q2": 30.862566131591798, "critic_loss": 8.163696857452393, "batch_reward": 1.1152568111419678, "actor_loss": -32.08860609608312, "actor_target_entropy": -1.0, "actor_entropy": 0.636909949683374, "alpha_loss": -0.091213277270717, "alpha_value": 0.09912177399110363, "duration": 157.00507998466492, "step": 5250}
{"episode_reward": 127.71638426888107, "episode": 43.0, "Q1 loss": 4.006945859909058, "Q2 loss": 4.012965650558471, "Mean Target Q": 32.10686329650879, "Mean Q1": 32.101757110595706, "Mean Q2": 32.10133453369141, "critic_loss": 8.01991151046753, "batch_reward": 1.1245533905029297, "actor_loss": -33.37220851958744, "actor_target_entropy": -1.0, "actor_entropy": 0.6228750414318509, "alpha_loss": -0.08954315041265791, "alpha_value": 0.09980572366999203, "duration": 166.00649976730347, "step": 5375}
{"episode_reward": 167.87863504312682, "episode": 44.0, "Q1 loss": 4.244195917129517, "Q2 loss": 4.263207916259765, "Mean Target Q": 33.41254727172851, "Mean Q1": 33.40561807250977, "Mean Q2": 33.40473870849609, "critic_loss": 8.50740386581421, "batch_reward": 1.1140429515838624, "actor_loss": -34.56470926346317, "actor_target_entropy": -1.0, "actor_entropy": 0.6296709857640728, "alpha_loss": -0.08929751525002141, "alpha_value": 0.10047973747360667, "duration": 158.71310091018677, "step": 5500}
{"episode_reward": 160.7025581668541, "episode": 45.0, "Q1 loss": 4.733769636154175, "Q2 loss": 4.744495073318482, "Mean Target Q": 34.65977841186523, "Mean Q1": 34.657274810791016, "Mean Q2": 34.65770822143555, "critic_loss": 9.478264709472656, "batch_reward": 1.1290156002044678, "actor_loss": -35.827984461708674, "actor_target_entropy": -1.0, "actor_entropy": 0.62230708154421, "alpha_loss": -0.08354438728992901, "alpha_value": 0.10113537382520964, "duration": 141.4377155303955, "step": 5625}
{"episode_reward": 213.66065728789462, "episode": 46.0, "Q1 loss": 4.484621757507324, "Q2 loss": 4.495832279205322, "Mean Target Q": 36.00738839721679, "Mean Q1": 35.99536276245117, "Mean Q2": 35.995005859375, "critic_loss": 8.980454029083251, "batch_reward": 1.1405938701629639, "actor_loss": -37.2535713564965, "actor_target_entropy": -1.0, "actor_entropy": 0.6200543935260465, "alpha_loss": -0.08972860055585061, "alpha_value": 0.10180140842920331, "duration": 154.572655916214, "step": 5750}
{"episode_reward": 211.95423900938556, "episode": 47.0, "Q1 loss": 4.660759052276611, "Q2 loss": 4.675672611236572, "Mean Target Q": 37.304368286132814, "Mean Q1": 37.29874514770508, "Mean Q2": 37.298717376708986, "critic_loss": 9.336431644439697, "batch_reward": 1.1572205710411072, "actor_loss": -38.61130493406265, "actor_target_entropy": -1.0, "actor_entropy": 0.6270049961786421, "alpha_loss": -0.09666323768241065, "alpha_value": 0.10250530271306432, "duration": 175.77923107147217, "step": 5875}
{"episode_reward": 235.4374312877418, "episode": 48.0, "Q1 loss": 4.492548713684082, "Q2 loss": 4.491286548614502, "Mean Target Q": 38.54015338134766, "Mean Q1": 38.53992965698242, "Mean Q2": 38.539647521972654, "critic_loss": 8.983835224151612, "batch_reward": 1.1627484407424926, "actor_loss": -39.78018034658125, "actor_target_entropy": -1.0, "actor_entropy": 0.6528856691814238, "alpha_loss": -0.09656882832848257, "alpha_value": 0.10325033269201124, "duration": 171.61326479911804, "step": 6000}
{"episode_reward": 168.79719907841263, "episode": 49.0, "Q1 loss": 4.701738759994507, "Q2 loss": 4.711742231369018, "Mean Target Q": 39.82029312133789, "Mean Q1": 39.80862133789063, "Mean Q2": 39.80860440063476, "critic_loss": 9.41348094177246, "batch_reward": 1.1754271249771118, "actor_loss": -41.09674187312051, "actor_target_entropy": -1.0, "actor_entropy": 0.6494079222754826, "alpha_loss": -0.09837571295007827, "alpha_value": 0.10397942372257508, "duration": 160.7978870868683, "step": 6125}
{"episode_reward": 169.819750862081, "episode": 50.0, "Q1 loss": 4.760555568695068, "Q2 loss": 4.768507745742798, "Mean Target Q": 41.112556701660154, "Mean Q1": 41.1096682434082, "Mean Q2": 41.10940704345703, "critic_loss": 9.529063331604004, "batch_reward": 1.1647994375228883, "actor_loss": -42.4525263386388, "actor_target_entropy": -1.0, "actor_entropy": 0.6553007431568638, "alpha_loss": -0.0980043817431696, "alpha_value": 0.10473169407554402, "duration": 111.81367921829224, "step": 6250}
{"episode_reward": 192.46016335861134, "episode": 51.0, "Q1 loss": 4.779478120803833, "Q2 loss": 4.788429006576538, "Mean Target Q": 42.430128784179686, "Mean Q1": 42.42447894287109, "Mean Q2": 42.42465124511719, "critic_loss": 9.567907135009765, "batch_reward": 1.177306908607483, "actor_loss": -43.679991222563245, "actor_target_entropy": -1.0, "actor_entropy": 0.6483554234580388, "alpha_loss": -0.09855843772963872, "alpha_value": 0.10546030112339806, "duration": 96.39959716796875, "step": 6375}
{"episode_reward": 144.85204970333007, "episode": 52.0, "Q1 loss": 4.741495542526245, "Q2 loss": 4.747604635238647, "Mean Target Q": 43.644724609375, "Mean Q1": 43.63730776977539, "Mean Q2": 43.63720004272461, "critic_loss": 9.489100196838379, "batch_reward": 1.1813884057998658, "actor_loss": -44.92716715412755, "actor_target_entropy": -1.0, "actor_entropy": 0.6394800812967362, "alpha_loss": -0.09725343808531761, "alpha_value": 0.10619039349145923, "duration": 153.6338472366333, "step": 6500}
{"episode_reward": 159.80237202212192, "episode": 53.0, "Q1 loss": 4.837122627258301, "Q2 loss": 4.84430379486084, "Mean Target Q": 44.962998046875, "Mean Q1": 44.95756100463867, "Mean Q2": 44.95776318359375, "critic_loss": 9.681426403045654, "batch_reward": 1.1857026710510254, "actor_loss": -46.233798193553135, "actor_target_entropy": -1.0, "actor_entropy": 0.6468218006784954, "alpha_loss": -0.09926347907573457, "alpha_value": 0.10693286326079093, "duration": 164.74386835098267, "step": 6625}
{"episode_reward": 178.77177016262456, "episode": 54.0, "Q1 loss": 4.6567993755340575, "Q2 loss": 4.654183521270752, "Mean Target Q": 46.14452749633789, "Mean Q1": 46.137613494873044, "Mean Q2": 46.137381958007815, "critic_loss": 9.310982902526856, "batch_reward": 1.1732439045906067, "actor_loss": -47.33618354797363, "actor_target_entropy": -1.0, "actor_entropy": 0.6387668165468401, "alpha_loss": -0.09883471025574592, "alpha_value": 0.10766582991654464, "duration": 149.40051746368408, "step": 6750}
{"episode_reward": 130.0114136581419, "episode": 55.0, "Q1 loss": 4.610812383651734, "Q2 loss": 4.621790084838867, "Mean Target Q": 47.55031884765625, "Mean Q1": 47.54404766845703, "Mean Q2": 47.543465454101565, "critic_loss": 9.23260247039795, "batch_reward": 1.1915338201522827, "actor_loss": -48.85937112475198, "actor_target_entropy": -1.0, "actor_entropy": 0.6112002843902224, "alpha_loss": -0.09865928985296733, "alpha_value": 0.10841097525799619, "duration": 131.3133430480957, "step": 6875}
{"episode_reward": 140.29767929974054, "episode": 56.0, "Q1 loss": 4.356455623626709, "Q2 loss": 4.357071269989014, "Mean Target Q": 48.79603646850586, "Mean Q1": 48.79420120239258, "Mean Q2": 48.7949338684082, "critic_loss": 8.713526885986328, "batch_reward": 1.1848008823394776, "actor_loss": -50.01256142893145, "actor_target_entropy": -1.0, "actor_entropy": 0.613454002045816, "alpha_loss": -0.09991860125334032, "alpha_value": 0.10915746311236432, "duration": 120.20862102508545, "step": 7000}
{"episode_reward": 220.05393758042476, "episode": 57.0, "Q1 loss": 4.000418619155884, "Q2 loss": 3.995138185501099, "Mean Target Q": 50.022798828125, "Mean Q1": 50.01532312011719, "Mean Q2": 50.01574118041992, "critic_loss": 7.995556842803955, "batch_reward": 1.1891159105300904, "actor_loss": -51.27152772933718, "actor_target_entropy": -1.0, "actor_entropy": 0.6487652479656159, "alpha_loss": -0.10317745355386583, "alpha_value": 0.10992019781230919, "duration": 136.27347111701965, "step": 7125}
{"episode_reward": 142.23016591105701, "episode": 58.0, "Q1 loss": 3.8694797821044924, "Q2 loss": 3.8624308280944826, "Mean Target Q": 51.27862341308594, "Mean Q1": 51.27464749145508, "Mean Q2": 51.2745746459961, "critic_loss": 7.731910598754883, "batch_reward": 1.1960589895248412, "actor_loss": -52.51048401863344, "actor_target_entropy": -1.0, "actor_entropy": 0.62782421708107, "alpha_loss": -0.09754990990604123, "alpha_value": 0.11066666469606404, "duration": 137.55298399925232, "step": 7250}
{"episode_reward": 182.3380340591469, "episode": 59.0, "Q1 loss": 3.69735276222229, "Q2 loss": 3.704199214935303, "Mean Target Q": 52.38135635375976, "Mean Q1": 52.378863494873045, "Mean Q2": 52.37909521484375, "critic_loss": 7.401551963806153, "batch_reward": 1.198934684753418, "actor_loss": -53.525335281614275, "actor_target_entropy": -1.0, "actor_entropy": 0.6180759166914319, "alpha_loss": -0.09537331003045278, "alpha_value": 0.1113801348610053, "duration": 176.73445796966553, "step": 7375}
{"episode_reward": 200.07659173899364, "episode": 60.0, "Q1 loss": 3.6195330486297608, "Q2 loss": 3.6220182666778564, "Mean Target Q": 53.57512893676758, "Mean Q1": 53.56765139770508, "Mean Q2": 53.56755224609375, "critic_loss": 7.241551284790039, "batch_reward": 1.2079709138870238, "actor_loss": -54.77496208683137, "actor_target_entropy": -1.0, "actor_entropy": 0.6023202721149691, "alpha_loss": -0.09664322435855865, "alpha_value": 0.11209652357759169, "duration": 133.47397828102112, "step": 7500}
{"episode_reward": 264.76761134252223, "episode": 61.0, "Q1 loss": 3.4840160064697265, "Q2 loss": 3.4828050727844237, "Mean Target Q": 54.67383892822266, "Mean Q1": 54.66969235229492, "Mean Q2": 54.67002597045899, "critic_loss": 6.966821090698242, "batch_reward": 1.2040335435867309, "actor_loss": -55.90378618997241, "actor_target_entropy": -1.0, "actor_entropy": 0.6301641549382891, "alpha_loss": -0.09704788963473032, "alpha_value": 0.11282278332331393, "duration": 115.20784997940063, "step": 7625}
{"episode_reward": 83.94398351449493, "episode": 62.0, "Q1 loss": 3.541588893890381, "Q2 loss": 3.5397881107330322, "Mean Target Q": 55.82775689697266, "Mean Q1": 55.82551986694336, "Mean Q2": 55.825390747070315, "critic_loss": 7.081376991271973, "batch_reward": 1.2065227556228637, "actor_loss": -56.970857497184504, "actor_target_entropy": -1.0, "actor_entropy": 0.6194445659076014, "alpha_loss": -0.0981817873975923, "alpha_value": 0.11356559532122748, "duration": 130.45612287521362, "step": 7750}
{"episode_reward": 174.6914457104677, "episode": 63.0, "Q1 loss": 3.7807282848358152, "Q2 loss": 3.765614019393921, "Mean Target Q": 57.019492462158205, "Mean Q1": 57.012303436279296, "Mean Q2": 57.01218746948242, "critic_loss": 7.546342357635498, "batch_reward": 1.20698153591156, "actor_loss": -58.16259487091549, "actor_target_entropy": -1.0, "actor_entropy": 0.6148179523528569, "alpha_loss": -0.09472749784352287, "alpha_value": 0.11429205813006546, "duration": 187.7066617012024, "step": 7875}
{"episode_reward": 126.54833761509084, "episode": 64.0, "Q1 loss": 3.7009527626037597, "Q2 loss": 3.712291883468628, "Mean Target Q": 58.055572631835936, "Mean Q1": 58.05317614746094, "Mean Q2": 58.05295919799805, "critic_loss": 7.413244659423828, "batch_reward": 1.2041838369369506, "actor_loss": -59.230310870755105, "actor_target_entropy": -1.0, "actor_entropy": 0.635157867785423, "alpha_loss": -0.10053239798834247, "alpha_value": 0.11503645670173664, "duration": 129.32215809822083, "step": 8000}
{"episode_reward": 108.85660575450943, "episode": 65.0, "Q1 loss": 3.746130350112915, "Q2 loss": 3.7739403438568115, "Mean Target Q": 59.17746304321289, "Mean Q1": 59.16953628540039, "Mean Q2": 59.16871359252929, "critic_loss": 7.520070655822754, "batch_reward": 1.2036779146194458, "actor_loss": -60.33260950966487, "actor_target_entropy": -1.0, "actor_entropy": 0.6264780173226009, "alpha_loss": -0.09907033590097276, "alpha_value": 0.11579705192461708, "duration": 150.40119886398315, "step": 8125}
{"episode_reward": 232.31691741087707, "episode": 66.0, "Q1 loss": 3.680605869293213, "Q2 loss": 3.6849296569824217, "Mean Target Q": 60.25926168823242, "Mean Q1": 60.25711279296875, "Mean Q2": 60.25759664916992, "critic_loss": 7.36553551864624, "batch_reward": 1.2111960792541503, "actor_loss": -61.416838184479744, "actor_target_entropy": -1.0, "actor_entropy": 0.6466338336467743, "alpha_loss": -0.10282584880628894, "alpha_value": 0.11657087657481888, "duration": 184.48897910118103, "step": 8250}
{"episode_reward": 162.16844981931524, "episode": 67.0, "Q1 loss": 3.84227251625061, "Q2 loss": 3.836207263946533, "Mean Target Q": 61.34988897705078, "Mean Q1": 61.34569522094726, "Mean Q2": 61.345789123535155, "critic_loss": 7.678479766845703, "batch_reward": 1.2191489820480346, "actor_loss": -62.45004224020337, "actor_target_entropy": -1.0, "actor_entropy": 0.6477012454517304, "alpha_loss": -0.09685176173372874, "alpha_value": 0.11733518613842274, "duration": 148.81436562538147, "step": 8375}
{"episode_reward": 150.02276123757878, "episode": 68.0, "Q1 loss": 3.7648001461029055, "Q2 loss": 3.7733396949768068, "Mean Target Q": 62.32074349975586, "Mean Q1": 62.31789855957031, "Mean Q2": 62.31815014648438, "critic_loss": 7.538139892578125, "batch_reward": 1.2125452795028686, "actor_loss": -63.44455386746314, "actor_target_entropy": -1.0, "actor_entropy": 0.6198263860517933, "alpha_loss": -0.09827644798544145, "alpha_value": 0.11808116830875336, "duration": 151.19014716148376, "step": 8500}
{"episode_reward": 163.60287957232623, "episode": 69.0, "Q1 loss": 3.7670095138549806, "Q2 loss": 3.772220012664795, "Mean Target Q": 63.478150512695315, "Mean Q1": 63.47522561645508, "Mean Q2": 63.475637664794924, "critic_loss": 7.539229530334473, "batch_reward": 1.2163417339324951, "actor_loss": -64.6183580671038, "actor_target_entropy": -1.0, "actor_entropy": 0.6502831606637864, "alpha_loss": -0.10204311140945979, "alpha_value": 0.11886205261311977, "duration": 131.1754322052002, "step": 8625}
{"episode_reward": 165.57473322219275, "episode": 70.0, "Q1 loss": 3.694979587554932, "Q2 loss": 3.7083678874969483, "Mean Target Q": 64.50481008911133, "Mean Q1": 64.49859686279297, "Mean Q2": 64.49820715332031, "critic_loss": 7.403347465515137, "batch_reward": 1.2318334732055665, "actor_loss": -65.68398149551884, "actor_target_entropy": -1.0, "actor_entropy": 0.6215715600598243, "alpha_loss": -0.09904132891566522, "alpha_value": 0.11963816403434907, "duration": 115.50040674209595, "step": 8750}
{"episode_reward": 209.94412853308165, "episode": 71.0, "Q1 loss": 3.79206805229187, "Q2 loss": 3.7974881896972654, "Mean Target Q": 65.6727362060547, "Mean Q1": 65.67146813964844, "Mean Q2": 65.67128784179687, "critic_loss": 7.589556232452392, "batch_reward": 1.2223130702972411, "actor_loss": -66.77569567967974, "actor_target_entropy": -1.0, "actor_entropy": 0.6644784590554615, "alpha_loss": -0.0965134444690886, "alpha_value": 0.120397420919247, "duration": 111.79155421257019, "step": 8875}
{"episode_reward": 129.2421720368423, "episode": 72.0, "Q1 loss": 3.894607452392578, "Q2 loss": 3.902617036819458, "Mean Target Q": 66.656857421875, "Mean Q1": 66.64984442138672, "Mean Q2": 66.65077056884766, "critic_loss": 7.797224475860595, "batch_reward": 1.2216852645874023, "actor_loss": -67.7534408569336, "actor_target_entropy": -1.0, "actor_entropy": 0.6430417289656978, "alpha_loss": -0.10179632048933737, "alpha_value": 0.12116172643636755, "duration": 127.54505944252014, "step": 9000}
{"episode_reward": 226.93474920791866, "episode": 73.0, "Q1 loss": 3.7946536140441895, "Q2 loss": 3.8050723400115967, "Mean Target Q": 67.7781015625, "Mean Q1": 67.77521606445312, "Mean Q2": 67.7739321899414, "critic_loss": 7.599725959777832, "batch_reward": 1.2389156274795532, "actor_loss": -68.89047095889137, "actor_target_entropy": -1.0, "actor_entropy": 0.6690782336961656, "alpha_loss": -0.09798962575575662, "alpha_value": 0.1219517160703661, "duration": 133.92109155654907, "step": 9125}
{"episode_reward": 292.17808276454065, "episode": 74.0, "Q1 loss": 3.7338267669677734, "Q2 loss": 3.7280303440093996, "Mean Target Q": 68.87714337158204, "Mean Q1": 68.87715289306641, "Mean Q2": 68.87788116455079, "critic_loss": 7.4618571090698245, "batch_reward": 1.2503773469924926, "actor_loss": -70.00200948407573, "actor_target_entropy": -1.0, "actor_entropy": 0.6695196282479071, "alpha_loss": -0.09891145135606488, "alpha_value": 0.1227226436799613, "duration": 126.53370833396912, "step": 9250}
{"episode_reward": 185.96845083301196, "episode": 75.0, "Q1 loss": 3.998192876815796, "Q2 loss": 3.9941236610412596, "Mean Target Q": 69.92798931884765, "Mean Q1": 69.92370092773437, "Mean Q2": 69.92372344970703, "critic_loss": 7.992316570281982, "batch_reward": 1.2467220582962035, "actor_loss": -71.0329109070793, "actor_target_entropy": -1.0, "actor_entropy": 0.660545563887036, "alpha_loss": -0.10006643571550884, "alpha_value": 0.12352699476604942, "duration": 170.57129955291748, "step": 9375}
{"episode_reward": 191.24218264886784, "episode": 76.0, "Q1 loss": 4.391075983047485, "Q2 loss": 4.407905681610107, "Mean Target Q": 70.9735189819336, "Mean Q1": 70.96835125732422, "Mean Q2": 70.96815692138672, "critic_loss": 8.798981647491456, "batch_reward": 1.2542956666946412, "actor_loss": -72.00435884537235, "actor_target_entropy": -1.0, "actor_entropy": 0.6848923419752428, "alpha_loss": -0.0954413206106232, "alpha_value": 0.12430000788378302, "duration": 138.03384160995483, "step": 9500}
{"episode_reward": 207.88122669638702, "episode": 77.0, "Q1 loss": 3.7402679691314695, "Q2 loss": 3.7475906620025636, "Mean Target Q": 71.91513018798828, "Mean Q1": 71.91199877929688, "Mean Q2": 71.91171209716796, "critic_loss": 7.487858631134033, "batch_reward": 1.2501918849945068, "actor_loss": -72.93955497136191, "actor_target_entropy": -1.0, "actor_entropy": 0.6777093997077336, "alpha_loss": -0.09222241798563609, "alpha_value": 0.12504832905630137, "duration": 131.64742350578308, "step": 9625}
{"episode_reward": 193.4929327061344, "episode": 78.0, "Q1 loss": 3.6722813243865966, "Q2 loss": 3.6834326648712157, "Mean Target Q": 73.01446264648438, "Mean Q1": 73.0107367553711, "Mean Q2": 73.01094970703124, "critic_loss": 7.355714008331299, "batch_reward": 1.2527826023101807, "actor_loss": -74.06320621121314, "actor_target_entropy": -1.0, "actor_entropy": 0.6477589145783456, "alpha_loss": -0.09506862334186031, "alpha_value": 0.12581333560142452, "duration": 131.69875073432922, "step": 9750}
{"episode_reward": 91.57903429859297, "episode": 79.0, "Q1 loss": 3.663242399215698, "Q2 loss": 3.6696328678131103, "Mean Target Q": 73.98596197509765, "Mean Q1": 73.97962310791016, "Mean Q2": 73.97952734375, "critic_loss": 7.332875267028808, "batch_reward": 1.2533558292388916, "actor_loss": -75.07481844463045, "actor_target_entropy": -1.0, "actor_entropy": 0.6775635745790269, "alpha_loss": -0.09299751785066393, "alpha_value": 0.12657008520489835, "duration": 143.14259505271912, "step": 9875}
{"episode_reward": 161.6043169769548, "episode": 80.0, "Q1 loss": 3.575613145828247, "Q2 loss": 3.58105397605896, "Mean Target Q": 74.95338061523438, "Mean Q1": 74.95027575683594, "Mean Q2": 74.95026977539062, "critic_loss": 7.156667114257813, "batch_reward": 1.2537938556671142, "actor_loss": -75.96397621400895, "actor_target_entropy": -1.0, "actor_entropy": 0.6675054575166395, "alpha_loss": -0.09058811834021922, "alpha_value": 0.1273263483299216, "step": 10000}
{"duration": 188.03514671325684, "step": 10000}
{"episode_reward": 175.73444713036358, "episode": 81.0, "Q1 loss": 3.529075572967529, "Q2 loss": 3.5303360786437987, "Mean Target Q": 75.9474223022461, "Mean Q1": 75.9456957397461, "Mean Q2": 75.94581378173828, "critic_loss": 7.059411682128906, "batch_reward": 1.2639784421920777, "actor_loss": -76.88632262699188, "actor_target_entropy": -1.0, "actor_entropy": 0.6951275657093714, "alpha_loss": -0.08640181687143114, "alpha_value": 0.1280401526569821, "duration": 125.70082521438599, "step": 10125}
{"episode_reward": 196.408709980298, "episode": 82.0, "Q1 loss": 3.7884773273468015, "Q2 loss": 3.8039226093292235, "Mean Target Q": 76.84686889648438, "Mean Q1": 76.8406997680664, "Mean Q2": 76.84083972167969, "critic_loss": 7.592399951934815, "batch_reward": 1.26383238697052, "actor_loss": -77.84654555782195, "actor_target_entropy": -1.0, "actor_entropy": 0.6433034202744884, "alpha_loss": -0.08386268358557455, "alpha_value": 0.12875575695792943, "duration": 168.84685802459717, "step": 10250}
{"episode_reward": 203.5086342179992, "episode": 83.0, "Q1 loss": 3.606843734741211, "Q2 loss": 3.623893642425537, "Mean Target Q": 77.74261767578125, "Mean Q1": 77.74182727050781, "Mean Q2": 77.74135650634766, "critic_loss": 7.230737392425537, "batch_reward": 1.2638712320327758, "actor_loss": -78.7437511625744, "actor_target_entropy": -1.0, "actor_entropy": 0.6626911172791133, "alpha_loss": -0.08360405603335017, "alpha_value": 0.12946847819659849, "duration": 136.43426966667175, "step": 10375}
{"episode_reward": 163.94296738859575, "episode": 84.0, "Q1 loss": 3.5795610694885256, "Q2 loss": 3.578797103881836, "Mean Target Q": 78.685798828125, "Mean Q1": 78.68118182373047, "Mean Q2": 78.68028936767578, "critic_loss": 7.158358207702637, "batch_reward": 1.2608468208312988, "actor_loss": -79.73088738226122, "actor_target_entropy": -1.0, "actor_entropy": 0.6576565206050873, "alpha_loss": -0.08527573913095458, "alpha_value": 0.13018918437095964, "duration": 127.51215076446533, "step": 10500}
{"episode_reward": 202.59730851896347, "episode": 85.0, "Q1 loss": 3.6390097618103026, "Q2 loss": 3.640722379684448, "Mean Target Q": 79.64448388671875, "Mean Q1": 79.6409105834961, "Mean Q2": 79.64149377441406, "critic_loss": 7.279732170104981, "batch_reward": 1.2753816843032837, "actor_loss": -80.66564263237848, "actor_target_entropy": -1.0, "actor_entropy": 0.6413482039693802, "alpha_loss": -0.08511492272927648, "alpha_value": 0.13093053416073372, "duration": 119.2739098072052, "step": 10625}
{"episode_reward": 158.85533504763748, "episode": 86.0, "Q1 loss": 3.680390968322754, "Q2 loss": 3.684856483459473, "Mean Target Q": 80.6053627319336, "Mean Q1": 80.60691009521484, "Mean Q2": 80.60642895507813, "critic_loss": 7.365247459411621, "batch_reward": 1.271673749923706, "actor_loss": -81.6431884765625, "actor_target_entropy": -1.0, "actor_entropy": 0.6291218678797444, "alpha_loss": -0.08573597705652637, "alpha_value": 0.1316723159522661, "duration": 112.86460995674133, "step": 10750}
{"episode_reward": 199.34869929300532, "episode": 87.0, "Q1 loss": 3.759267818450928, "Q2 loss": 3.7560648765563966, "Mean Target Q": 81.51229986572265, "Mean Q1": 81.50394232177734, "Mean Q2": 81.50496807861329, "critic_loss": 7.5153326950073245, "batch_reward": 1.2688779630661011, "actor_loss": -82.5846704150003, "actor_target_entropy": -1.0, "actor_entropy": 0.6246833309294686, "alpha_loss": -0.08984449085971666, "alpha_value": 0.13244112708586003, "duration": 127.69383072853088, "step": 10875}
{"episode_reward": 142.30192277508812, "episode": 88.0, "Q1 loss": 3.6209641056060793, "Q2 loss": 3.6161357803344725, "Mean Target Q": 82.4249677734375, "Mean Q1": 82.42363287353515, "Mean Q2": 82.42345794677735, "critic_loss": 7.2370999183654785, "batch_reward": 1.2710246725082397, "actor_loss": -83.43371545114825, "actor_target_entropy": -1.0, "actor_entropy": 0.6395686201510891, "alpha_loss": -0.08733226845581685, "alpha_value": 0.13323389000426805, "duration": 130.4561939239502, "step": 11000}
{"episode_reward": 170.4828605215037, "episode": 89.0, "Q1 loss": 3.669042079925537, "Q2 loss": 3.684636043548584, "Mean Target Q": 83.25077880859375, "Mean Q1": 83.24621118164063, "Mean Q2": 83.24555303955079, "critic_loss": 7.353678127288818, "batch_reward": 1.2648911409378052, "actor_loss": -84.25285303025018, "actor_target_entropy": -1.0, "actor_entropy": 0.6525225317667401, "alpha_loss": -0.08385763252301821, "alpha_value": 0.13399654030225708, "duration": 113.82468795776367, "step": 11125}
{"episode_reward": 186.53048123576067, "episode": 90.0, "Q1 loss": 3.793884880065918, "Q2 loss": 3.8014794921875, "Mean Target Q": 84.23253076171875, "Mean Q1": 84.22986614990235, "Mean Q2": 84.23100970458984, "critic_loss": 7.595364398956299, "batch_reward": 1.2797214097976684, "actor_loss": -85.2791287822108, "actor_target_entropy": -1.0, "actor_entropy": 0.6119316306806379, "alpha_loss": -0.08405605319046205, "alpha_value": 0.13475544479377172, "duration": 175.02287077903748, "step": 11250}
{"episode_reward": 176.14720843674718, "episode": 91.0, "Q1 loss": 3.651471799850464, "Q2 loss": 3.680633680343628, "Mean Target Q": 85.04334088134766, "Mean Q1": 85.04015814208984, "Mean Q2": 85.03938507080078, "critic_loss": 7.332105484008789, "batch_reward": 1.274720371246338, "actor_loss": -86.01017410036117, "actor_target_entropy": -1.0, "actor_entropy": 0.648551016572922, "alpha_loss": -0.08564271210204988, "alpha_value": 0.1355465172491623, "duration": 163.05477452278137, "step": 11375}
{"episode_reward": 180.3198456633317, "episode": 92.0, "Q1 loss": 3.8161481590270996, "Q2 loss": 3.835919237136841, "Mean Target Q": 85.97672399902343, "Mean Q1": 85.97322802734375, "Mean Q2": 85.97345928955077, "critic_loss": 7.6520673904418945, "batch_reward": 1.2861590356826782, "actor_loss": -86.98869742116621, "actor_target_entropy": -1.0, "actor_entropy": 0.6369402014440105, "alpha_loss": -0.08433108242048372, "alpha_value": 0.13634089391614182, "duration": 162.3634111881256, "step": 11500}
{"episode_reward": 170.61416570138806, "episode": 93.0, "Q1 loss": 3.6814154357910156, "Q2 loss": 3.670434398651123, "Mean Target Q": 86.84912109375, "Mean Q1": 86.8487529296875, "Mean Q2": 86.8486499633789, "critic_loss": 7.35184980392456, "batch_reward": 1.2802954053878783, "actor_loss": -87.86529250372024, "actor_target_entropy": -1.0, "actor_entropy": 0.6644186566746424, "alpha_loss": -0.08333390093748531, "alpha_value": 0.13711512648132412, "duration": 187.2272436618805, "step": 11625}
{"episode_reward": 209.98037315557505, "episode": 94.0, "Q1 loss": 3.6221566371917726, "Q2 loss": 3.6110152950286865, "Mean Target Q": 87.67299957275391, "Mean Q1": 87.67180712890625, "Mean Q2": 87.67211804199219, "critic_loss": 7.233171970367431, "batch_reward": 1.2814573411941528, "actor_loss": -88.62901712233021, "actor_target_entropy": -1.0, "actor_entropy": 0.6559513682319272, "alpha_loss": -0.08104496677556346, "alpha_value": 0.13788170402045058, "duration": 126.9314022064209, "step": 11750}
{"episode_reward": 221.43618833303364, "episode": 95.0, "Q1 loss": 3.7382611198425293, "Q2 loss": 3.740966457366943, "Mean Target Q": 88.5881704711914, "Mean Q1": 88.5808594970703, "Mean Q2": 88.58056115722657, "critic_loss": 7.479227588653565, "batch_reward": 1.2912019596099853, "actor_loss": -89.4940682063027, "actor_target_entropy": -1.0, "actor_entropy": 0.6572412867394705, "alpha_loss": -0.08303011173293703, "alpha_value": 0.13866590628975975, "duration": 178.7323191165924, "step": 11875}
{"episode_reward": 205.8895197251613, "episode": 96.0, "Q1 loss": 3.836303075790405, "Q2 loss": 3.8510274066925048, "Mean Target Q": 89.46454742431641, "Mean Q1": 89.4636771850586, "Mean Q2": 89.46390893554687, "critic_loss": 7.687330486297608, "batch_reward": 1.2971645727157592, "actor_loss": -90.48863737044796, "actor_target_entropy": -1.0, "actor_entropy": 0.673601778284196, "alpha_loss": -0.08332251444939644, "alpha_value": 0.13947031590700182, "duration": 151.6388816833496, "step": 12000}
{"episode_reward": 191.51182868420605, "episode": 97.0, "Q1 loss": 3.74952006149292, "Q2 loss": 3.7653080883026124, "Mean Target Q": 90.27816418457031, "Mean Q1": 90.27497528076172, "Mean Q2": 90.27441296386719, "critic_loss": 7.514828147888184, "batch_reward": 1.2930137338638306, "actor_loss": -91.2841054522802, "actor_target_entropy": -1.0, "actor_entropy": 0.6729896021267724, "alpha_loss": -0.07833432914718749, "alpha_value": 0.1402604095881307, "duration": 128.2951991558075, "step": 12125}
{"episode_reward": 215.76821899263385, "episode": 98.0, "Q1 loss": 3.7745229778289793, "Q2 loss": 3.798091480255127, "Mean Target Q": 91.12711199951171, "Mean Q1": 91.12465911865235, "Mean Q2": 91.1248897705078, "critic_loss": 7.572614463806152, "batch_reward": 1.2959907913208009, "actor_loss": -92.05828020649571, "actor_target_entropy": -1.0, "actor_entropy": 0.6585293277617423, "alpha_loss": -0.08013390148839643, "alpha_value": 0.14102284701992535, "duration": 121.32341146469116, "step": 12250}
{"episode_reward": 197.0969181676376, "episode": 99.0, "Q1 loss": 3.9472505416870116, "Q2 loss": 3.95438226890564, "Mean Target Q": 91.96592083740235, "Mean Q1": 91.96384790039062, "Mean Q2": 91.96378637695312, "critic_loss": 7.901632843017578, "batch_reward": 1.2993525609970094, "actor_loss": -92.95193941631014, "actor_target_entropy": -1.0, "actor_entropy": 0.6430564191606309, "alpha_loss": -0.07528512664730587, "alpha_value": 0.14180975163576742, "duration": 119.67090106010437, "step": 12375}
{"episode_reward": 171.91572790098638, "episode": 100.0, "Q1 loss": 3.72021174621582, "Q2 loss": 3.7331161251068115, "Mean Target Q": 92.83787573242188, "Mean Q1": 92.83460668945312, "Mean Q2": 92.83459771728516, "critic_loss": 7.453327831268311, "batch_reward": 1.3012385606765746, "actor_loss": -93.7992420811807, "actor_target_entropy": -1.0, "actor_entropy": 0.6987653624626898, "alpha_loss": -0.07359145449534539, "alpha_value": 0.14257066088044976, "duration": 129.08890175819397, "step": 12500}
{"episode_reward": 61.06101795893104, "episode": 101.0, "Q1 loss": 3.782559181213379, "Q2 loss": 3.79023064994812, "Mean Target Q": 93.67762628173828, "Mean Q1": 93.67355780029297, "Mean Q2": 93.67345288085937, "critic_loss": 7.572789821624756, "batch_reward": 1.2863758955001832, "actor_loss": -94.64146205357143, "actor_target_entropy": -1.0, "actor_entropy": 0.6838229837871733, "alpha_loss": -0.07811514164010684, "alpha_value": 0.14333786193633055, "duration": 177.00009155273438, "step": 12625}
{"episode_reward": 115.54060592939494, "episode": 102.0, "Q1 loss": 3.768943962097168, "Q2 loss": 3.771400630950928, "Mean Target Q": 94.41356365966797, "Mean Q1": 94.41074633789063, "Mean Q2": 94.41076293945312, "critic_loss": 7.54034460067749, "batch_reward": 1.2788351573944092, "actor_loss": -95.36656201270318, "actor_target_entropy": -1.0, "actor_entropy": 0.665955848270847, "alpha_loss": -0.07895221212698568, "alpha_value": 0.14414320266470512, "duration": 138.2775046825409, "step": 12750}
{"episode_reward": 180.7186008913881, "episode": 103.0, "Q1 loss": 3.923934724807739, "Q2 loss": 3.9270917587280274, "Mean Target Q": 95.28276312255859, "Mean Q1": 95.28068548583984, "Mean Q2": 95.28076623535156, "critic_loss": 7.851026519775391, "batch_reward": 1.2996001386642455, "actor_loss": -96.26737976074219, "actor_target_entropy": -1.0, "actor_entropy": 0.6576816609927586, "alpha_loss": -0.07902801367971632, "alpha_value": 0.14496886617969706, "duration": 118.06469631195068, "step": 12875}
{"episode_reward": 167.61084062287074, "episode": 104.0, "Q1 loss": 4.112241802215576, "Q2 loss": 4.124257915496826, "Mean Target Q": 96.04771429443359, "Mean Q1": 96.04760302734375, "Mean Q2": 96.04761138916015, "critic_loss": 8.2364997215271, "batch_reward": 1.2946012029647826, "actor_loss": -97.03194341351909, "actor_target_entropy": -1.0, "actor_entropy": 0.6408813845726752, "alpha_loss": -0.07309242962829528, "alpha_value": 0.14575202774159132, "duration": 176.95292162895203, "step": 13000}
{"episode_reward": 174.232098588269, "episode": 105.0, "Q1 loss": 4.03727657699585, "Q2 loss": 4.0475630264282225, "Mean Target Q": 96.80301361083984, "Mean Q1": 96.7991967163086, "Mean Q2": 96.80001776123046, "critic_loss": 8.084839603424072, "batch_reward": 1.2988227519989013, "actor_loss": -97.78279137989831, "actor_target_entropy": -1.0, "actor_entropy": 0.6405645239920843, "alpha_loss": -0.07806988362045515, "alpha_value": 0.1465705232913516, "duration": 181.20213723182678, "step": 13125}
{"episode_reward": 190.2978139140169, "episode": 106.0, "Q1 loss": 3.6578944759368897, "Q2 loss": 3.67518172454834, "Mean Target Q": 97.58465246582031, "Mean Q1": 97.57831707763673, "Mean Q2": 97.5778558959961, "critic_loss": 7.333076210021972, "batch_reward": 1.2915755577087402, "actor_loss": -98.58019047398722, "actor_target_entropy": -1.0, "actor_entropy": 0.6698472557529327, "alpha_loss": -0.07624595486108333, "alpha_value": 0.1474043491052928, "duration": 149.4155912399292, "step": 13250}
{"episode_reward": 28.824796914816496, "episode": 107.0, "Q1 loss": 3.8018913135528565, "Q2 loss": 3.8163161163330077, "Mean Target Q": 98.37257165527343, "Mean Q1": 98.37107720947266, "Mean Q2": 98.36999072265625, "critic_loss": 7.618207431793213, "batch_reward": 1.2834281644821166, "actor_loss": -99.27518499465216, "actor_target_entropy": -1.0, "actor_entropy": 0.6664757321751307, "alpha_loss": -0.07768054424770295, "alpha_value": 0.14823614924908649, "duration": 145.7804400920868, "step": 13375}
{"episode_reward": 161.66054695621236, "episode": 108.0, "Q1 loss": 3.76799866104126, "Q2 loss": 3.7788122673034668, "Mean Target Q": 99.13171691894532, "Mean Q1": 99.13111700439453, "Mean Q2": 99.13184509277343, "critic_loss": 7.5468108787536625, "batch_reward": 1.278559090614319, "actor_loss": -100.1036016402706, "actor_target_entropy": -1.0, "actor_entropy": 0.6595448832358083, "alpha_loss": -0.082312916135115, "alpha_value": 0.14912345906572352, "duration": 168.04384922981262, "step": 13500}
{"episode_reward": 175.29008320144683, "episode": 109.0, "Q1 loss": 3.8619723491668703, "Q2 loss": 3.8780200157165527, "Mean Target Q": 100.00963372802734, "Mean Q1": 100.01084368896484, "Mean Q2": 100.01085485839843, "critic_loss": 7.739992328643799, "batch_reward": 1.2865183191299439, "actor_loss": -100.99774908641028, "actor_target_entropy": -1.0, "actor_entropy": 0.6296182700565883, "alpha_loss": -0.07161589185633356, "alpha_value": 0.1499749178841437, "duration": 116.80593180656433, "step": 13625}
{"episode_reward": 183.34847605355637, "episode": 110.0, "Q1 loss": 3.7888427066802977, "Q2 loss": 3.7986101875305174, "Mean Target Q": 100.77387127685547, "Mean Q1": 100.7673353881836, "Mean Q2": 100.7667041015625, "critic_loss": 7.587452930450439, "batch_reward": 1.2870484066009522, "actor_loss": -101.76555682766822, "actor_target_entropy": -1.0, "actor_entropy": 0.6443618526381831, "alpha_loss": -0.07338835064682268, "alpha_value": 0.1507966062997819, "duration": 109.22986721992493, "step": 13750}
{"episode_reward": 171.24634888723887, "episode": 111.0, "Q1 loss": 3.76755401802063, "Q2 loss": 3.784117042541504, "Mean Target Q": 101.52707849121094, "Mean Q1": 101.52557202148438, "Mean Q2": 101.52579077148438, "critic_loss": 7.551671070098877, "batch_reward": 1.2871015539169313, "actor_loss": -102.49271780347067, "actor_target_entropy": -1.0, "actor_entropy": 0.6384680602285597, "alpha_loss": -0.07250220872580058, "alpha_value": 0.15160651071635142, "duration": 106.83901739120483, "step": 13875}
{"episode_reward": 86.3908514851963, "episode": 112.0, "Q1 loss": 3.535287721633911, "Q2 loss": 3.5466914329528807, "Mean Target Q": 102.35662652587891, "Mean Q1": 102.35396899414063, "Mean Q2": 102.35414050292968, "critic_loss": 7.081979160308838, "batch_reward": 1.286544273376465, "actor_loss": -103.3020757859753, "actor_target_entropy": -1.0, "actor_entropy": 0.6650427224174622, "alpha_loss": -0.07360126180273871, "alpha_value": 0.15244813789390593, "duration": 126.82543158531189, "step": 14000}
{"episode_reward": 121.53050472791888, "episode": 113.0, "Q1 loss": 3.696259065628052, "Q2 loss": 3.698361352920532, "Mean Target Q": 103.04068572998047, "Mean Q1": 103.03681243896484, "Mean Q2": 103.03712860107422, "critic_loss": 7.394620388031006, "batch_reward": 1.2722065343856812, "actor_loss": -104.01193600609189, "actor_target_entropy": -1.0, "actor_entropy": 0.6434523387560769, "alpha_loss": -0.06918023452754059, "alpha_value": 0.15328452734229284, "duration": 123.83072066307068, "step": 14125}
{"episode_reward": 136.00827157001953, "episode": 114.0, "Q1 loss": 3.7966881103515626, "Q2 loss": 3.7851473960876465, "Mean Target Q": 103.79729260253906, "Mean Q1": 103.79613928222656, "Mean Q2": 103.79541094970703, "critic_loss": 7.581835506439209, "batch_reward": 1.2791639556884766, "actor_loss": -104.71300851145098, "actor_target_entropy": -1.0, "actor_entropy": 0.6639791448270121, "alpha_loss": -0.07365341412444268, "alpha_value": 0.15412074639067253, "duration": 106.77822160720825, "step": 14250}
{"episode_reward": 128.7038685970978, "episode": 115.0, "Q1 loss": 3.9631144542694092, "Q2 loss": 3.987099178314209, "Mean Target Q": 104.58027954101563, "Mean Q1": 104.5773062133789, "Mean Q2": 104.57746771240234, "critic_loss": 7.950213668823242, "batch_reward": 1.2774659242630004, "actor_loss": -105.53873625255767, "actor_target_entropy": -1.0, "actor_entropy": 0.66743522787851, "alpha_loss": -0.07221742618888144, "alpha_value": 0.1549940046060374, "duration": 121.27706527709961, "step": 14375}
{"episode_reward": 225.1088890751141, "episode": 116.0, "Q1 loss": 3.855580358505249, "Q2 loss": 3.8702642192840577, "Mean Target Q": 105.34827795410156, "Mean Q1": 105.34601251220703, "Mean Q2": 105.34593658447265, "critic_loss": 7.725844562530518, "batch_reward": 1.287168828010559, "actor_loss": -106.3297725800545, "actor_target_entropy": -1.0, "actor_entropy": 0.6735531235894849, "alpha_loss": -0.07042862150457598, "alpha_value": 0.1558308119143573, "duration": 118.49683785438538, "step": 14500}
{"episode_reward": 157.72625782825554, "episode": 117.0, "Q1 loss": 3.875955234527588, "Q2 loss": 3.9064067459106444, "Mean Target Q": 106.0639476928711, "Mean Q1": 106.06129211425781, "Mean Q2": 106.06094818115234, "critic_loss": 7.782362003326416, "batch_reward": 1.2887994432449341, "actor_loss": -107.04427168104384, "actor_target_entropy": -1.0, "actor_entropy": 0.6704506542947557, "alpha_loss": -0.07538703456521034, "alpha_value": 0.15672285474235848, "duration": 101.03273367881775, "step": 14625}
{"episode_reward": 196.2588178320311, "episode": 118.0, "Q1 loss": 3.9273957233428956, "Q2 loss": 3.9274685764312744, "Mean Target Q": 106.73611535644531, "Mean Q1": 106.7354428100586, "Mean Q2": 106.73566137695312, "critic_loss": 7.854864311218262, "batch_reward": 1.2828620615005493, "actor_loss": -107.63677523213047, "actor_target_entropy": -1.0, "actor_entropy": 0.6540069551237168, "alpha_loss": -0.06508111827556164, "alpha_value": 0.15760002909724005, "duration": 122.87416958808899, "step": 14750}
{"episode_reward": 172.8183011825729, "episode": 119.0, "Q1 loss": 3.6976520214080812, "Q2 loss": 3.698829948425293, "Mean Target Q": 107.521927734375, "Mean Q1": 107.52189605712891, "Mean Q2": 107.52158624267578, "critic_loss": 7.396481983184814, "batch_reward": 1.2852672519683839, "actor_loss": -108.45995718335348, "actor_target_entropy": -1.0, "actor_entropy": 0.6575673856432476, "alpha_loss": -0.06703461990469978, "alpha_value": 0.1584063445850534, "duration": 118.04411363601685, "step": 14875}
{"episode_reward": 137.6838543237576, "episode": 120.0, "Q1 loss": 3.775656442642212, "Q2 loss": 3.775135236740112, "Mean Target Q": 108.25288348388672, "Mean Q1": 108.2485750732422, "Mean Q2": 108.24829449462891, "critic_loss": 7.550791679382324, "batch_reward": 1.2870760984420777, "actor_loss": -109.23319884269468, "actor_target_entropy": -1.0, "actor_entropy": 0.6491849633955187, "alpha_loss": -0.06251405368769361, "alpha_value": 0.15922288656162806, "step": 15000}
{"duration": 136.26600003242493, "step": 15000}
{"episode_reward": 210.53959371371664, "episode": 121.0, "Q1 loss": 3.7974865283966066, "Q2 loss": 3.7994520206451416, "Mean Target Q": 108.90585748291015, "Mean Q1": 108.90012219238281, "Mean Q2": 108.90014263916015, "critic_loss": 7.596938556671143, "batch_reward": 1.2864868421554565, "actor_loss": -109.91686624193949, "actor_target_entropy": -1.0, "actor_entropy": 0.6500228662339468, "alpha_loss": -0.06321927952387976, "alpha_value": 0.1600254609305075, "duration": 105.1580274105072, "step": 15125}
{"episode_reward": 103.21693025924695, "episode": 122.0, "Q1 loss": 3.6338514156341555, "Q2 loss": 3.6274135398864744, "Mean Target Q": 109.64599578857423, "Mean Q1": 109.64136999511719, "Mean Q2": 109.6419428100586, "critic_loss": 7.261264965057373, "batch_reward": 1.2745557985305787, "actor_loss": -110.54693418933499, "actor_target_entropy": -1.0, "actor_entropy": 0.6311203289416528, "alpha_loss": -0.0665065809002807, "alpha_value": 0.16085233454263534, "duration": 146.91992378234863, "step": 15250}
{"episode_reward": 154.28277338600915, "episode": 123.0, "Q1 loss": 3.692770706176758, "Q2 loss": 3.6964012088775635, "Mean Target Q": 110.36439007568359, "Mean Q1": 110.36376788330078, "Mean Q2": 110.36300134277344, "critic_loss": 7.389171936035156, "batch_reward": 1.2885000305175782, "actor_loss": -111.28026641361298, "actor_target_entropy": -1.0, "actor_entropy": 0.6427560600023421, "alpha_loss": -0.05740676246701725, "alpha_value": 0.16165924837983134, "duration": 158.62665677070618, "step": 15375}
{"episode_reward": 178.2803161920383, "episode": 124.0, "Q1 loss": 3.7106984062194823, "Q2 loss": 3.730036766052246, "Mean Target Q": 110.97335125732423, "Mean Q1": 110.97558551025391, "Mean Q2": 110.97583331298829, "critic_loss": 7.4407351722717285, "batch_reward": 1.275320806503296, "actor_loss": -111.97422532112368, "actor_target_entropy": -1.0, "actor_entropy": 0.6396366482780825, "alpha_loss": -0.06260070523187038, "alpha_value": 0.16244478890165054, "duration": 160.35641980171204, "step": 15500}
{"episode_reward": 95.15079689560221, "episode": 125.0, "Q1 loss": 3.63690950012207, "Q2 loss": 3.656468832015991, "Mean Target Q": 111.64149890136719, "Mean Q1": 111.63828405761718, "Mean Q2": 111.63826104736329, "critic_loss": 7.293378314971924, "batch_reward": 1.2679036569595337, "actor_loss": -112.59041268484933, "actor_target_entropy": -1.0, "actor_entropy": 0.6533958760518876, "alpha_loss": -0.06211459837735645, "alpha_value": 0.16329078503327543, "duration": 166.89756155014038, "step": 15625}
{"episode_reward": 99.43451452953221, "episode": 126.0, "Q1 loss": 3.599146831512451, "Q2 loss": 3.603527051925659, "Mean Target Q": 112.30712243652344, "Mean Q1": 112.30324102783203, "Mean Q2": 112.3033276977539, "critic_loss": 7.202673892974854, "batch_reward": 1.2680666303634645, "actor_loss": -113.25166542299333, "actor_target_entropy": -1.0, "actor_entropy": 0.6892777373713832, "alpha_loss": -0.06258904792728924, "alpha_value": 0.16415853166849373, "duration": 154.1938021183014, "step": 15750}
{"episode_reward": 167.38446727895524, "episode": 127.0, "Q1 loss": 3.628948076248169, "Q2 loss": 3.6398222427368165, "Mean Target Q": 113.06983996582031, "Mean Q1": 113.06757147216797, "Mean Q2": 113.06725079345703, "critic_loss": 7.268770301818848, "batch_reward": 1.2768592071533202, "actor_loss": -114.066648453001, "actor_target_entropy": -1.0, "actor_entropy": 0.6329673443521772, "alpha_loss": -0.059339556074331674, "alpha_value": 0.16501084505029692, "duration": 178.17577171325684, "step": 15875}
{"episode_reward": 136.73094258918147, "episode": 128.0, "Q1 loss": 3.785458549499512, "Q2 loss": 3.8005369987487794, "Mean Target Q": 113.73795404052734, "Mean Q1": 113.738146484375, "Mean Q2": 113.73776531982422, "critic_loss": 7.585995540618897, "batch_reward": 1.2651058778762818, "actor_loss": -114.68302523705268, "actor_target_entropy": -1.0, "actor_entropy": 0.6601314390859296, "alpha_loss": -0.06163735170998881, "alpha_value": 0.16586480030896295, "duration": 173.1808376312256, "step": 16000}
{"episode_reward": 168.1497738261767, "episode": 129.0, "Q1 loss": 3.9426494884490966, "Q2 loss": 3.9521165676116943, "Mean Target Q": 114.42524298095704, "Mean Q1": 114.42016314697265, "Mean Q2": 114.42115100097656, "critic_loss": 7.89476607131958, "batch_reward": 1.2726331367492676, "actor_loss": -115.4426775735522, "actor_target_entropy": -1.0, "actor_entropy": 0.6656680059811425, "alpha_loss": -0.05606632342650777, "alpha_value": 0.16669498268044144, "duration": 86.01184964179993, "step": 16125}
{"episode_reward": 7.008575858352152, "episode": 130.0, "Q1 loss": 3.718971830368042, "Q2 loss": 3.7322922477722167, "Mean Target Q": 115.09138598632812, "Mean Q1": 115.09375579833984, "Mean Q2": 115.09230590820313, "critic_loss": 7.451264080047608, "batch_reward": 1.26039430809021, "actor_loss": -116.0740345370385, "actor_target_entropy": -1.0, "actor_entropy": 0.6674782383826471, "alpha_loss": -0.06193301637446688, "alpha_value": 0.16755715863289475, "duration": 160.64910078048706, "step": 16250}
{"episode_reward": 125.06786703660126, "episode": 131.0, "Q1 loss": 3.802751890182495, "Q2 loss": 3.8134154777526854, "Mean Target Q": 115.73774822998047, "Mean Q1": 115.73164056396485, "Mean Q2": 115.73247149658204, "critic_loss": 7.616167381286621, "batch_reward": 1.2659350452423095, "actor_loss": -116.68438006204272, "actor_target_entropy": -1.0, "actor_entropy": 0.6499785459230817, "alpha_loss": -0.057613612817866464, "alpha_value": 0.16844646203085617, "duration": 126.92105507850647, "step": 16375}
{"episode_reward": 161.21448860218078, "episode": 132.0, "Q1 loss": 4.005780788421631, "Q2 loss": 4.02482773399353, "Mean Target Q": 116.37873559570312, "Mean Q1": 116.3753978881836, "Mean Q2": 116.37518768310547, "critic_loss": 8.030608516693116, "batch_reward": 1.260215588569641, "actor_loss": -117.42925557782573, "actor_target_entropy": -1.0, "actor_entropy": 0.6551534850751201, "alpha_loss": -0.06325862070004787, "alpha_value": 0.1693414395669802, "duration": 113.87630486488342, "step": 16500}
{"episode_reward": 167.2629206919438, "episode": 133.0, "Q1 loss": 3.8831427726745606, "Q2 loss": 3.8787702655792238, "Mean Target Q": 117.04094641113281, "Mean Q1": 117.03904754638671, "Mean Q2": 117.03907189941407, "critic_loss": 7.761913021087646, "batch_reward": 1.2581859998703002, "actor_loss": -118.06200203062996, "actor_target_entropy": -1.0, "actor_entropy": 0.650825784319923, "alpha_loss": -0.058037532286511526, "alpha_value": 0.1702344442800573, "duration": 129.5545494556427, "step": 16625}
{"episode_reward": 177.19827853619762, "episode": 134.0, "Q1 loss": 3.9553576507568358, "Q2 loss": 3.9724980182647704, "Mean Target Q": 117.73743920898437, "Mean Q1": 117.73445251464844, "Mean Q2": 117.73506640625, "critic_loss": 7.927855674743652, "batch_reward": 1.2628675107955933, "actor_loss": -118.70657250189012, "actor_target_entropy": -1.0, "actor_entropy": 0.6306555501876339, "alpha_loss": -0.05674284131776902, "alpha_value": 0.17111203207356415, "duration": 111.57743048667908, "step": 16750}
{"episode_reward": 162.12315580484503, "episode": 135.0, "Q1 loss": 4.0312622509002685, "Q2 loss": 4.029724834442138, "Mean Target Q": 118.36685327148437, "Mean Q1": 118.36956451416016, "Mean Q2": 118.36850988769531, "critic_loss": 8.060987113952637, "batch_reward": 1.2685018243789672, "actor_loss": -119.36454215882317, "actor_target_entropy": -1.0, "actor_entropy": 0.6523761720884413, "alpha_loss": -0.05439637134236003, "alpha_value": 0.17197465031530643, "duration": 103.74860882759094, "step": 16875}
{"episode_reward": 171.02465765800181, "episode": 136.0, "Q1 loss": 3.903182067871094, "Q2 loss": 3.8950706596374514, "Mean Target Q": 118.96349493408204, "Mean Q1": 118.9596488647461, "Mean Q2": 118.95969946289063, "critic_loss": 7.798252719879151, "batch_reward": 1.26916326713562, "actor_loss": -119.9714464987478, "actor_target_entropy": -1.0, "actor_entropy": 0.6670490907084557, "alpha_loss": -0.0600776654563003, "alpha_value": 0.1729209908131242, "duration": 113.95221662521362, "step": 17000}
{"episode_reward": 85.4794283753759, "episode": 137.0, "Q1 loss": 3.823425048828125, "Q2 loss": 3.841415678024292, "Mean Target Q": 119.64998937988281, "Mean Q1": 119.64951696777344, "Mean Q2": 119.64892321777344, "critic_loss": 7.664840705871582, "batch_reward": 1.2697208557128907, "actor_loss": -120.62956080361018, "actor_target_entropy": -1.0, "actor_entropy": 0.628101648792388, "alpha_loss": -0.05620872143596884, "alpha_value": 0.17382351655067377, "duration": 132.7244656085968, "step": 17125}
{"episode_reward": 151.50994927032414, "episode": 138.0, "Q1 loss": 3.833054922103882, "Q2 loss": 3.8421469326019286, "Mean Target Q": 120.32911932373047, "Mean Q1": 120.32610931396485, "Mean Q2": 120.32702026367187, "critic_loss": 7.675201873779297, "batch_reward": 1.2570983638763429, "actor_loss": -121.35246227633569, "actor_target_entropy": -1.0, "actor_entropy": 0.6539984797277758, "alpha_loss": -0.056182686081756986, "alpha_value": 0.17472661444411133, "duration": 121.5807728767395, "step": 17250}
{"episode_reward": 172.94173627141566, "episode": 139.0, "Q1 loss": 3.8288377075195315, "Q2 loss": 3.8307057781219482, "Mean Target Q": 120.92972064208985, "Mean Q1": 120.92732482910156, "Mean Q2": 120.92703503417968, "critic_loss": 7.659543495178223, "batch_reward": 1.2673582887649537, "actor_loss": -121.89221627371651, "actor_target_entropy": -1.0, "actor_entropy": 0.6492569683090089, "alpha_loss": -0.05485567975316256, "alpha_value": 0.17559238033951044, "duration": 129.1363308429718, "step": 17375}
{"episode_reward": 142.41151632860263, "episode": 140.0, "Q1 loss": 3.903852153778076, "Q2 loss": 3.903125680923462, "Mean Target Q": 121.56907696533203, "Mean Q1": 121.57004284667968, "Mean Q2": 121.57058337402344, "critic_loss": 7.8069778175354, "batch_reward": 1.2728623189926147, "actor_loss": -122.50351998113817, "actor_target_entropy": -1.0, "actor_entropy": 0.6593795111102443, "alpha_loss": -0.05250820677517162, "alpha_value": 0.17647601776865598, "duration": 113.42688345909119, "step": 17500}
{"episode_reward": 217.48897068653736, "episode": 141.0, "Q1 loss": 3.8050529537200926, "Q2 loss": 3.8200053443908693, "Mean Target Q": 122.13707495117187, "Mean Q1": 122.12949383544922, "Mean Q2": 122.12881640625, "critic_loss": 7.625058296203613, "batch_reward": 1.2696782312393189, "actor_loss": -123.1068129766555, "actor_target_entropy": -1.0, "actor_entropy": 0.6749017314305381, "alpha_loss": -0.05533192546239921, "alpha_value": 0.17737806999334782, "duration": 125.10775995254517, "step": 17625}
{"episode_reward": 144.47899252205238, "episode": 142.0, "Q1 loss": 3.734953666687012, "Q2 loss": 3.7318770122528075, "Mean Target Q": 122.76740692138672, "Mean Q1": 122.76685107421875, "Mean Q2": 122.76669500732422, "critic_loss": 7.466830688476563, "batch_reward": 1.255078122138977, "actor_loss": -123.74950568906722, "actor_target_entropy": -1.0, "actor_entropy": 0.6597201939552061, "alpha_loss": -0.05345375524953969, "alpha_value": 0.17831547855770022, "duration": 127.66600179672241, "step": 17750}
{"episode_reward": 48.69032669003879, "episode": 143.0, "Q1 loss": 3.7611007900238036, "Q2 loss": 3.804321685791016, "Mean Target Q": 123.35615435791016, "Mean Q1": 123.35661975097656, "Mean Q2": 123.35678826904297, "critic_loss": 7.565422512054443, "batch_reward": 1.263835961341858, "actor_loss": -124.3500004117451, "actor_target_entropy": -1.0, "actor_entropy": 0.6509734354321919, "alpha_loss": -0.0486655564653495, "alpha_value": 0.1791952751273992, "duration": 123.50335311889648, "step": 17875}
{"episode_reward": 65.40613604138301, "episode": 144.0, "Q1 loss": 3.675270589828491, "Q2 loss": 3.6815862922668456, "Mean Target Q": 123.90652819824219, "Mean Q1": 123.90072302246094, "Mean Q2": 123.90041174316406, "critic_loss": 7.356856872558594, "batch_reward": 1.253960371017456, "actor_loss": -124.92424429616621, "actor_target_entropy": -1.0, "actor_entropy": 0.6707535011153067, "alpha_loss": -0.05529440215398227, "alpha_value": 0.18008598010391028, "duration": 103.67513537406921, "step": 18000}
{"episode_reward": 188.7840341972948, "episode": 145.0, "Q1 loss": 3.7920069694519043, "Q2 loss": 3.8040282669067382, "Mean Target Q": 124.5142533569336, "Mean Q1": 124.51358215332031, "Mean Q2": 124.51302606201172, "critic_loss": 7.59603519821167, "batch_reward": 1.2500205516815186, "actor_loss": -125.54954771011595, "actor_target_entropy": -1.0, "actor_entropy": 0.6828432636601585, "alpha_loss": -0.05090674052074078, "alpha_value": 0.18101863844811875, "duration": 55.74409890174866, "step": 18125}
{"episode_reward": 110.1460717879826, "episode": 146.0, "Q1 loss": 3.939861898422241, "Q2 loss": 3.951852424621582, "Mean Target Q": 125.16311065673828, "Mean Q1": 125.16561608886718, "Mean Q2": 125.1662905883789, "critic_loss": 7.89171435546875, "batch_reward": 1.255553780555725, "actor_loss": -126.14177002445344, "actor_target_entropy": -1.0, "actor_entropy": 0.6729803806351077, "alpha_loss": -0.05215824215162185, "alpha_value": 0.18190536558978296, "duration": 56.28721618652344, "step": 18250}
{"episode_reward": 89.32002451711531, "episode": 147.0, "Q1 loss": 4.026796894073486, "Q2 loss": 4.029733757019043, "Mean Target Q": 125.69195355224609, "Mean Q1": 125.68522436523438, "Mean Q2": 125.68520367431641, "critic_loss": 8.056530658721924, "batch_reward": 1.2557936525344848, "actor_loss": -126.75483957926433, "actor_target_entropy": -1.0, "actor_entropy": 0.6898905076677837, "alpha_loss": -0.05382089600676582, "alpha_value": 0.18286597940105245, "duration": 64.35232901573181, "step": 18375}
{"episode_reward": 74.50687417507723, "episode": 148.0, "Q1 loss": 4.084064292907715, "Q2 loss": 4.055889642715454, "Mean Target Q": 126.27663372802735, "Mean Q1": 126.27690747070312, "Mean Q2": 126.27754760742188, "critic_loss": 8.139953960418701, "batch_reward": 1.2432643737792968, "actor_loss": -127.32334198490265, "actor_target_entropy": -1.0, "actor_entropy": 0.7127321045244893, "alpha_loss": -0.050308605761177114, "alpha_value": 0.18385017820082977, "duration": 57.65115523338318, "step": 18500}
{"episode_reward": 50.833966803977205, "episode": 149.0, "Q1 loss": 3.9897425899505614, "Q2 loss": 4.015667671203613, "Mean Target Q": 126.89745440673828, "Mean Q1": 126.89605474853515, "Mean Q2": 126.8958115234375, "critic_loss": 8.005410247802734, "batch_reward": 1.241779619216919, "actor_loss": -127.93776957194011, "actor_target_entropy": -1.0, "actor_entropy": 0.6789250506295098, "alpha_loss": -0.050822867538839106, "alpha_value": 0.184731608622257, "duration": 49.95051383972168, "step": 18625}
{"episode_reward": 188.92375528740158, "episode": 150.0, "Q1 loss": 3.925479986190796, "Q2 loss": 3.9377797012329103, "Mean Target Q": 127.43395965576173, "Mean Q1": 127.42703436279297, "Mean Q2": 127.42704412841798, "critic_loss": 7.863259620666504, "batch_reward": 1.2377344799041747, "actor_loss": -128.4863559353736, "actor_target_entropy": -1.0, "actor_entropy": 0.6835364430181442, "alpha_loss": -0.05343026910427837, "alpha_value": 0.18572632255066115, "duration": 51.5512535572052, "step": 18750}
{"episode_reward": 120.55461766759691, "episode": 151.0, "Q1 loss": 4.011778804779053, "Q2 loss": 4.017141126632691, "Mean Target Q": 128.0270220336914, "Mean Q1": 128.0271604003906, "Mean Q2": 128.02706433105467, "critic_loss": 8.028919956207275, "batch_reward": 1.2457117385864258, "actor_loss": -129.0909939720517, "actor_target_entropy": -1.0, "actor_entropy": 0.6468748507045564, "alpha_loss": -0.049299213739614635, "alpha_value": 0.1867135039146485, "duration": 68.47246766090393, "step": 18875}
{"episode_reward": 191.9455134510836, "episode": 152.0, "Q1 loss": 4.12778357887268, "Q2 loss": 4.127197431564331, "Mean Target Q": 128.57604125976562, "Mean Q1": 128.57612731933594, "Mean Q2": 128.5758321533203, "critic_loss": 8.25498099899292, "batch_reward": 1.2330583095550538, "actor_loss": -129.56966498590285, "actor_target_entropy": -1.0, "actor_entropy": 0.6569645347133759, "alpha_loss": -0.05352398413684099, "alpha_value": 0.1877023599363409, "duration": 52.83322238922119, "step": 19000}
{"episode_reward": 185.6157793731183, "episode": 153.0, "Q1 loss": 4.282928607940674, "Q2 loss": 4.288826919555664, "Mean Target Q": 129.19521630859376, "Mean Q1": 129.19237213134767, "Mean Q2": 129.19270416259766, "critic_loss": 8.57175555419922, "batch_reward": 1.2431506090164184, "actor_loss": -130.3048095703125, "actor_target_entropy": -1.0, "actor_entropy": 0.6685724788241916, "alpha_loss": -0.0528982330024952, "alpha_value": 0.1887094086360027, "duration": 56.72643733024597, "step": 19125}
{"episode_reward": 176.81819410453937, "episode": 154.0, "Q1 loss": 4.366372850418091, "Q2 loss": 4.368407535552978, "Mean Target Q": 129.85332458496094, "Mean Q1": 129.85250622558593, "Mean Q2": 129.8514610595703, "critic_loss": 8.734780433654786, "batch_reward": 1.2458578834533691, "actor_loss": -130.9259727231918, "actor_target_entropy": -1.0, "actor_entropy": 0.656496266203542, "alpha_loss": -0.054706627533080115, "alpha_value": 0.1897565594823224, "duration": 59.61875057220459, "step": 19250}
{"episode_reward": 159.01380493515265, "episode": 155.0, "Q1 loss": 4.0943584156036374, "Q2 loss": 4.116715393066406, "Mean Target Q": 130.3823426513672, "Mean Q1": 130.38126538085936, "Mean Q2": 130.3823562011719, "critic_loss": 8.211073833465576, "batch_reward": 1.2533068113327026, "actor_loss": -131.38224162752667, "actor_target_entropy": -1.0, "actor_entropy": 0.6559293951307025, "alpha_loss": -0.054599677493411394, "alpha_value": 0.19082617213303643, "duration": 68.01638197898865, "step": 19375}
{"episode_reward": 169.5659837052143, "episode": 156.0, "Q1 loss": 4.3248119564056395, "Q2 loss": 4.337421897888183, "Mean Target Q": 130.91060998535156, "Mean Q1": 130.9073243408203, "Mean Q2": 130.90725671386718, "critic_loss": 8.66223388671875, "batch_reward": 1.2463981218338012, "actor_loss": -131.92898805679815, "actor_target_entropy": -1.0, "actor_entropy": 0.6695528703351175, "alpha_loss": -0.056850345061731436, "alpha_value": 0.19197667059487014, "duration": 70.35077404975891, "step": 19500}
{"episode_reward": 159.45755972243572, "episode": 157.0, "Q1 loss": 4.2624332695007325, "Q2 loss": 4.2694727916717525, "Mean Target Q": 131.4763605957031, "Mean Q1": 131.47533520507812, "Mean Q2": 131.47568395996095, "critic_loss": 8.531906028747558, "batch_reward": 1.2433444147109984, "actor_loss": -132.4174049014137, "actor_target_entropy": -1.0, "actor_entropy": 0.671708071042621, "alpha_loss": -0.0546009251071761, "alpha_value": 0.19309128552814955, "duration": 69.1391019821167, "step": 19625}
{"episode_reward": 225.19080594592882, "episode": 158.0, "Q1 loss": 4.191993124008179, "Q2 loss": 4.209830589294434, "Mean Target Q": 132.1304217529297, "Mean Q1": 132.1298212890625, "Mean Q2": 132.12973486328124, "critic_loss": 8.401823699951171, "batch_reward": 1.2538676719665527, "actor_loss": -133.18224014774447, "actor_target_entropy": -1.0, "actor_entropy": 0.6770886182785034, "alpha_loss": -0.054373754548930356, "alpha_value": 0.1941864377059215, "duration": 55.34803891181946, "step": 19750}
{"episode_reward": 110.3108163623853, "episode": 159.0, "Q1 loss": 4.101278192520142, "Q2 loss": 4.113524412155152, "Mean Target Q": 132.64131384277343, "Mean Q1": 132.6406629638672, "Mean Q2": 132.64031713867186, "critic_loss": 8.214802577972412, "batch_reward": 1.2430189056396483, "actor_loss": -133.70211452907986, "actor_target_entropy": -1.0, "actor_entropy": 0.6992934469192748, "alpha_loss": -0.04969364013670692, "alpha_value": 0.19521592215062974, "duration": 74.66212964057922, "step": 19875}
{"episode_reward": 100.13830900976966, "episode": 160.0, "Q1 loss": 4.211379177093506, "Q2 loss": 4.2518870105743405, "Mean Target Q": 133.16594555664062, "Mean Q1": 133.16117663574218, "Mean Q2": 133.16114331054686, "critic_loss": 8.463266193389893, "batch_reward": 1.2473240280151368, "actor_loss": -134.19727719214654, "actor_target_entropy": -1.0, "actor_entropy": 0.6800345345850913, "alpha_loss": -0.05571324659150935, "alpha_value": 0.1963046045469251, "step": 20000}
{"duration": 72.34059262275696, "step": 20000}
{"episode_reward": 217.81325476044913, "episode": 161.0, "Q1 loss": 4.30157444190979, "Q2 loss": 4.32175737953186, "Mean Target Q": 133.80261096191407, "Mean Q1": 133.79999694824218, "Mean Q2": 133.7996326904297, "critic_loss": 8.623331817626953, "batch_reward": 1.2569624729156494, "actor_loss": -134.8626207624163, "actor_target_entropy": -1.0, "actor_entropy": 0.6888206080784873, "alpha_loss": -0.049960088827425524, "alpha_value": 0.19738630583483419, "duration": 96.06907486915588, "step": 20125}
{"episode_reward": 178.3370630285084, "episode": 162.0, "Q1 loss": 4.173341585159302, "Q2 loss": 4.173213411331177, "Mean Target Q": 134.30702319335938, "Mean Q1": 134.30717297363282, "Mean Q2": 134.30744470214844, "critic_loss": 8.346555004119873, "batch_reward": 1.2484370841979981, "actor_loss": -135.27385391727572, "actor_target_entropy": -1.0, "actor_entropy": 0.7165828174160372, "alpha_loss": -0.04769374226265016, "alpha_value": 0.19843705043410034, "duration": 116.61746168136597, "step": 20250}
{"episode_reward": 177.2703205602261, "episode": 163.0, "Q1 loss": 4.353495073318482, "Q2 loss": 4.352932247161865, "Mean Target Q": 134.9122186279297, "Mean Q1": 134.9114932861328, "Mean Q2": 134.91170458984374, "critic_loss": 8.706427307128907, "batch_reward": 1.2563289279937744, "actor_loss": -135.92277357313367, "actor_target_entropy": -1.0, "actor_entropy": 0.7001443240377638, "alpha_loss": -0.05455838922884256, "alpha_value": 0.1994759202099537, "duration": 122.7185583114624, "step": 20375}
{"episode_reward": 242.8460974941471, "episode": 164.0, "Q1 loss": 4.269782922744751, "Q2 loss": 4.266618787765503, "Mean Target Q": 135.47162634277345, "Mean Q1": 135.46393811035156, "Mean Q2": 135.46400451660156, "critic_loss": 8.536401748657227, "batch_reward": 1.2495563678741455, "actor_loss": -136.442135718561, "actor_target_entropy": -1.0, "actor_entropy": 0.7128238178068592, "alpha_loss": -0.05590117975108085, "alpha_value": 0.20068215244589196, "duration": 98.00832986831665, "step": 20500}
{"episode_reward": 120.65403039235228, "episode": 165.0, "Q1 loss": 4.153028203964233, "Q2 loss": 4.1655918312072755, "Mean Target Q": 135.9689510498047, "Mean Q1": 135.96953356933594, "Mean Q2": 135.96955529785157, "critic_loss": 8.318620044708252, "batch_reward": 1.2486086349487304, "actor_loss": -136.95294068351623, "actor_target_entropy": -1.0, "actor_entropy": 0.7234609865006947, "alpha_loss": -0.04143785499036312, "alpha_value": 0.2017318905402691, "duration": 51.98570370674133, "step": 20625}
{"episode_reward": 156.62636731242586, "episode": 166.0, "Q1 loss": 4.09598533821106, "Q2 loss": 4.085477123260498, "Mean Target Q": 136.4668181152344, "Mean Q1": 136.46492700195313, "Mean Q2": 136.4652371826172, "critic_loss": 8.18146244430542, "batch_reward": 1.2525169773101807, "actor_loss": -137.43742099885017, "actor_target_entropy": -1.0, "actor_entropy": 0.7120866842808262, "alpha_loss": -0.04315039094146942, "alpha_value": 0.20261645669367773, "duration": 59.76401877403259, "step": 20750}
{"episode_reward": 75.50192440906288, "episode": 167.0, "Q1 loss": 4.2205912952423095, "Q2 loss": 4.221997089385987, "Mean Target Q": 137.00488830566405, "Mean Q1": 137.0055341796875, "Mean Q2": 137.00553698730468, "critic_loss": 8.442588371276855, "batch_reward": 1.2436977920532226, "actor_loss": -138.03467886788505, "actor_target_entropy": -1.0, "actor_entropy": 0.7253307170338101, "alpha_loss": -0.04354366637204611, "alpha_value": 0.2035820949246066, "duration": 56.896950244903564, "step": 20875}
{"episode_reward": 30.836784370525137, "episode": 168.0, "Q1 loss": 4.100565950393677, "Q2 loss": 4.102501773834229, "Mean Target Q": 137.5426602783203, "Mean Q1": 137.53789965820312, "Mean Q2": 137.53724816894533, "critic_loss": 8.203067749023438, "batch_reward": 1.2493506345748902, "actor_loss": -138.5384782360446, "actor_target_entropy": -1.0, "actor_entropy": 0.6998352408409119, "alpha_loss": -0.042637931340704524, "alpha_value": 0.20456360805399026, "duration": 63.66388988494873, "step": 21000}
{"episode_reward": 162.1950688501252, "episode": 169.0, "Q1 loss": 4.217089910507202, "Q2 loss": 4.249998878479004, "Mean Target Q": 138.01147778320313, "Mean Q1": 138.01176416015625, "Mean Q2": 138.01209594726564, "critic_loss": 8.467088809967041, "batch_reward": 1.2387574243545532, "actor_loss": -139.05394199916296, "actor_target_entropy": -1.0, "actor_entropy": 0.7127278191702706, "alpha_loss": -0.04535876918170187, "alpha_value": 0.20555208878356193, "duration": 59.42720603942871, "step": 21125}
{"episode_reward": 135.8479961826575, "episode": 170.0, "Q1 loss": 4.078913970947266, "Q2 loss": 4.088292098999023, "Mean Target Q": 138.5078974609375, "Mean Q1": 138.50703625488282, "Mean Q2": 138.50760375976563, "critic_loss": 8.167206089019775, "batch_reward": 1.2497716026306152, "actor_loss": -139.48287102483934, "actor_target_entropy": -1.0, "actor_entropy": 0.7553376622738377, "alpha_loss": -0.04006452910271623, "alpha_value": 0.2064998385795394, "duration": 56.619749784469604, "step": 21250}
{"episode_reward": 61.18516142422518, "episode": 171.0, "Q1 loss": 4.197511726379394, "Q2 loss": 4.203401304244995, "Mean Target Q": 138.96616552734375, "Mean Q1": 138.96384167480468, "Mean Q2": 138.96321899414062, "critic_loss": 8.40091302871704, "batch_reward": 1.2420823059082031, "actor_loss": -140.00698876759364, "actor_target_entropy": -1.0, "actor_entropy": 0.733188649964711, "alpha_loss": -0.045363138163728375, "alpha_value": 0.2075481586029376, "duration": 52.311097383499146, "step": 21375}
{"episode_reward": 257.2663794234226, "episode": 172.0, "Q1 loss": 4.289768762588501, "Q2 loss": 4.278428583145142, "Mean Target Q": 139.54216760253905, "Mean Q1": 139.5399052734375, "Mean Q2": 139.53995556640626, "critic_loss": 8.568197357177734, "batch_reward": 1.2398700113296508, "actor_loss": -140.5432608819777, "actor_target_entropy": -1.0, "actor_entropy": 0.7453083011411852, "alpha_loss": -0.0349477069384809, "alpha_value": 0.2084927470050444, "duration": 98.28844571113586, "step": 21500}
{"episode_reward": 156.71183784722615, "episode": 173.0, "Q1 loss": 4.403386108398437, "Q2 loss": 4.424206268310547, "Mean Target Q": 140.0204180908203, "Mean Q1": 140.01980200195314, "Mean Q2": 140.01991552734376, "critic_loss": 8.827592384338379, "batch_reward": 1.2407243375778199, "actor_loss": -141.00871107313367, "actor_target_entropy": -1.0, "actor_entropy": 0.6917531102422684, "alpha_loss": -0.03650816467161926, "alpha_value": 0.2093664269247231, "duration": 136.3634102344513, "step": 21625}
{"episode_reward": 252.6793928410767, "episode": 174.0, "Q1 loss": 4.317285060882568, "Q2 loss": 4.3270416278839114, "Mean Target Q": 140.54786767578125, "Mean Q1": 140.5448524169922, "Mean Q2": 140.54450244140625, "critic_loss": 8.644326667785645, "batch_reward": 1.2468642234802245, "actor_loss": -141.52499586536038, "actor_target_entropy": -1.0, "actor_entropy": 0.7601962445243713, "alpha_loss": -0.03269867647829796, "alpha_value": 0.2101629921094041, "duration": 170.63655400276184, "step": 21750}
{"episode_reward": 141.75283451778307, "episode": 175.0, "Q1 loss": 4.155192768096923, "Q2 loss": 4.175595306396485, "Mean Target Q": 140.97432153320312, "Mean Q1": 140.97538806152343, "Mean Q2": 140.9754287109375, "critic_loss": 8.33078804397583, "batch_reward": 1.2463929023742675, "actor_loss": -141.92445107111854, "actor_target_entropy": -1.0, "actor_entropy": 0.7282480086599078, "alpha_loss": -0.03203266226346531, "alpha_value": 0.2109649154370634, "duration": 143.91651701927185, "step": 21875}
{"episode_reward": 98.08954437470196, "episode": 176.0, "Q1 loss": 4.1743856716156005, "Q2 loss": 4.187699460983277, "Mean Target Q": 141.43167932128907, "Mean Q1": 141.42993078613281, "Mean Q2": 141.42989123535156, "critic_loss": 8.362085117340088, "batch_reward": 1.2392932405471802, "actor_loss": -142.41730253158076, "actor_target_entropy": -1.0, "actor_entropy": 0.7091196794663707, "alpha_loss": -0.030731824895126686, "alpha_value": 0.21173423373596736, "duration": 93.26735353469849, "step": 22000}
{"episode_reward": 126.59541680860086, "episode": 177.0, "Q1 loss": 3.9386893615722656, "Q2 loss": 3.9432475757598877, "Mean Target Q": 141.9078132324219, "Mean Q1": 141.90789184570312, "Mean Q2": 141.90814892578126, "critic_loss": 7.881936946868897, "batch_reward": 1.2454346828460694, "actor_loss": -142.8572005014571, "actor_target_entropy": -1.0, "actor_entropy": 0.7059073873928615, "alpha_loss": -0.033665327281351125, "alpha_value": 0.21261158138441524, "duration": 115.13167095184326, "step": 22125}
{"episode_reward": 141.2861062203362, "episode": 178.0, "Q1 loss": 4.0647502002716065, "Q2 loss": 4.068203445434571, "Mean Target Q": 142.35782666015626, "Mean Q1": 142.3498428955078, "Mean Q2": 142.35022863769532, "critic_loss": 8.13295365524292, "batch_reward": 1.2359025688171388, "actor_loss": -143.32311371834047, "actor_target_entropy": -1.0, "actor_entropy": 0.7234761051593288, "alpha_loss": -0.032105161079896555, "alpha_value": 0.21349167448418643, "duration": 156.19760370254517, "step": 22250}
{"episode_reward": 161.47315775186433, "episode": 179.0, "Q1 loss": 4.207726125717163, "Q2 loss": 4.21876410484314, "Mean Target Q": 142.91024865722656, "Mean Q1": 142.9098935546875, "Mean Q2": 142.90975903320313, "critic_loss": 8.426490264892578, "batch_reward": 1.2435271968841553, "actor_loss": -143.91944037543402, "actor_target_entropy": -1.0, "actor_entropy": 0.7443114027144417, "alpha_loss": -0.03533839633954423, "alpha_value": 0.21439468670604026, "duration": 128.87749600410461, "step": 22375}
{"episode_reward": 170.97788494098828, "episode": 180.0, "Q1 loss": 4.314643438339234, "Q2 loss": 4.334244077682495, "Mean Target Q": 143.41011279296876, "Mean Q1": 143.4117297363281, "Mean Q2": 143.41152807617186, "critic_loss": 8.648887474060059, "batch_reward": 1.245230152130127, "actor_loss": -144.41729564051474, "actor_target_entropy": -1.0, "actor_entropy": 0.7286057308796914, "alpha_loss": -0.03609579014817193, "alpha_value": 0.215327482796982, "duration": 171.28689122200012, "step": 22500}
{"episode_reward": 185.89288964277395, "episode": 181.0, "Q1 loss": 4.388488479614258, "Q2 loss": 4.402173406600952, "Mean Target Q": 143.95765686035156, "Mean Q1": 143.95325659179687, "Mean Q2": 143.9528709716797, "critic_loss": 8.790661922454834, "batch_reward": 1.242879346847534, "actor_loss": -144.93119279165117, "actor_target_entropy": -1.0, "actor_entropy": 0.7441520397625272, "alpha_loss": -0.03315161541104317, "alpha_value": 0.21629789863450716, "duration": 160.15026116371155, "step": 22625}
{"episode_reward": 144.9402224608857, "episode": 182.0, "Q1 loss": 4.220810884475708, "Q2 loss": 4.22540613937378, "Mean Target Q": 144.40921569824218, "Mean Q1": 144.4045887451172, "Mean Q2": 144.40510534667968, "critic_loss": 8.446217037200928, "batch_reward": 1.235965612411499, "actor_loss": -145.49695316437752, "actor_target_entropy": -1.0, "actor_entropy": 0.7113886312130959, "alpha_loss": -0.03454684249065336, "alpha_value": 0.21726623053568625, "duration": 149.74080753326416, "step": 22750}
{"episode_reward": 146.8713775544959, "episode": 183.0, "Q1 loss": 4.391087575912476, "Q2 loss": 4.407118583679199, "Mean Target Q": 144.96751110839844, "Mean Q1": 144.96305798339844, "Mean Q2": 144.9627236328125, "critic_loss": 8.79820616531372, "batch_reward": 1.2430426473617553, "actor_loss": -145.99286130874876, "actor_target_entropy": -1.0, "actor_entropy": 0.7265643893726288, "alpha_loss": -0.0319028541904002, "alpha_value": 0.21820798657335597, "duration": 180.22969269752502, "step": 22875}
{"episode_reward": 124.42078539218308, "episode": 184.0, "Q1 loss": 4.330042446136475, "Q2 loss": 4.341077375411987, "Mean Target Q": 145.47684399414064, "Mean Q1": 145.47818103027345, "Mean Q2": 145.47804907226563, "critic_loss": 8.671119815826415, "batch_reward": 1.2486882772445678, "actor_loss": -146.42679743612968, "actor_target_entropy": -1.0, "actor_entropy": 0.7166798316663311, "alpha_loss": -0.031381276315979416, "alpha_value": 0.21909853113286878, "duration": 142.08010411262512, "step": 23000}
{"episode_reward": 175.41617245543966, "episode": 185.0, "Q1 loss": 4.42386068725586, "Q2 loss": 4.443287399291992, "Mean Target Q": 145.88775231933593, "Mean Q1": 145.8869678955078, "Mean Q2": 145.8872811279297, "critic_loss": 8.86714811706543, "batch_reward": 1.2416281032562255, "actor_loss": -146.88460286458334, "actor_target_entropy": -1.0, "actor_entropy": 0.7584782223852854, "alpha_loss": -0.034988009659129946, "alpha_value": 0.22017773602110505, "duration": 176.45175743103027, "step": 23125}
{"episode_reward": 231.76964675285367, "episode": 186.0, "Q1 loss": 4.133200702667236, "Q2 loss": 4.126338357925415, "Mean Target Q": 146.41601513671876, "Mean Q1": 146.41508251953124, "Mean Q2": 146.41456909179686, "critic_loss": 8.259539089202882, "batch_reward": 1.231763339996338, "actor_loss": -147.47067211520286, "actor_target_entropy": -1.0, "actor_entropy": 0.7497226528583034, "alpha_loss": -0.033471706972998234, "alpha_value": 0.2210996929326969, "duration": 153.17592072486877, "step": 23250}
{"episode_reward": 152.98590285175646, "episode": 187.0, "Q1 loss": 4.337184452056885, "Q2 loss": 4.342674247741699, "Mean Target Q": 146.83583630371095, "Mean Q1": 146.8374893798828, "Mean Q2": 146.8381746826172, "critic_loss": 8.679858726501465, "batch_reward": 1.2452313289642334, "actor_loss": -147.8360094342913, "actor_target_entropy": -1.0, "actor_entropy": 0.7257791975187877, "alpha_loss": -0.023240198628858677, "alpha_value": 0.22200936043790181, "duration": 172.42515015602112, "step": 23375}
{"episode_reward": 195.77697635440651, "episode": 188.0, "Q1 loss": 4.461724138259887, "Q2 loss": 4.492576026916504, "Mean Target Q": 147.32381079101563, "Mean Q1": 147.3195712890625, "Mean Q2": 147.31915502929687, "critic_loss": 8.954300178527832, "batch_reward": 1.2412052707672119, "actor_loss": -148.32020076628655, "actor_target_entropy": -1.0, "actor_entropy": 0.7365698593278085, "alpha_loss": -0.02192260141694738, "alpha_value": 0.22262655298032724, "duration": 139.51212859153748, "step": 23500}
{"episode_reward": 111.25966117023434, "episode": 189.0, "Q1 loss": 4.801591918945313, "Q2 loss": 4.80436669921875, "Mean Target Q": 147.78686181640626, "Mean Q1": 147.78567810058593, "Mean Q2": 147.7850772705078, "critic_loss": 9.605958602905273, "batch_reward": 1.2376249113082887, "actor_loss": -148.7758600144159, "actor_target_entropy": -1.0, "actor_entropy": 0.7461327371143159, "alpha_loss": -0.01867313374809566, "alpha_value": 0.22325344608560135, "duration": 158.18412375450134, "step": 23625}
{"episode_reward": 202.36249274924592, "episode": 190.0, "Q1 loss": 4.735866010665894, "Q2 loss": 4.695073108673096, "Mean Target Q": 148.212146484375, "Mean Q1": 148.21033264160155, "Mean Q2": 148.21143762207032, "critic_loss": 9.430939159393311, "batch_reward": 1.2495179433822632, "actor_loss": -149.2315454790669, "actor_target_entropy": -1.0, "actor_entropy": 0.7610438552594954, "alpha_loss": -0.021391158454090117, "alpha_value": 0.2239617190246436, "duration": 164.97045803070068, "step": 23750}
{"episode_reward": 98.74178855067478, "episode": 191.0, "Q1 loss": 4.643876848220825, "Q2 loss": 4.669929111480713, "Mean Target Q": 148.61199169921875, "Mean Q1": 148.60910131835936, "Mean Q2": 148.6100655517578, "critic_loss": 9.313805908203125, "batch_reward": 1.2429290857315063, "actor_loss": -149.6619388640873, "actor_target_entropy": -1.0, "actor_entropy": 0.7440813495999291, "alpha_loss": -0.01962293872964524, "alpha_value": 0.22460967522721328, "duration": 192.36285185813904, "step": 23875}
{"episode_reward": 107.74008192048399, "episode": 192.0, "Q1 loss": 4.663928638458252, "Q2 loss": 4.6903948440551755, "Mean Target Q": 149.08982458496095, "Mean Q1": 149.08852001953124, "Mean Q2": 149.08739489746094, "critic_loss": 9.35432343673706, "batch_reward": 1.2428378887176514, "actor_loss": -150.1467263006395, "actor_target_entropy": -1.0, "actor_entropy": 0.7675667885811098, "alpha_loss": -0.0282343536833181, "alpha_value": 0.22539201185196248, "duration": 155.31929469108582, "step": 24000}
{"episode_reward": 176.52295494725257, "episode": 193.0, "Q1 loss": 4.739692186355591, "Q2 loss": 4.740512954711914, "Mean Target Q": 149.52788745117186, "Mean Q1": 149.52543298339845, "Mean Q2": 149.52512536621094, "critic_loss": 9.480205169677735, "batch_reward": 1.2424735708236694, "actor_loss": -150.50908358134922, "actor_target_entropy": -1.0, "actor_entropy": 0.7359854947952997, "alpha_loss": -0.025686535843840196, "alpha_value": 0.22627876815105427, "duration": 169.74499773979187, "step": 24125}
{"episode_reward": 133.74683657119067, "episode": 194.0, "Q1 loss": 4.723630712509156, "Q2 loss": 4.7221213111877445, "Mean Target Q": 149.96067370605468, "Mean Q1": 149.9631534423828, "Mean Q2": 149.9632784423828, "critic_loss": 9.445752010345458, "batch_reward": 1.2393821907043456, "actor_loss": -150.96990868353075, "actor_target_entropy": -1.0, "actor_entropy": 0.743095003789471, "alpha_loss": -0.02481235909245668, "alpha_value": 0.22716237108970821, "duration": 146.44788670539856, "step": 24250}
{"episode_reward": 79.1800490565808, "episode": 195.0, "Q1 loss": 4.610675941467285, "Q2 loss": 4.626164867401123, "Mean Target Q": 150.3598533935547, "Mean Q1": 150.35580822753906, "Mean Q2": 150.35587109375, "critic_loss": 9.236840797424316, "batch_reward": 1.2369892101287843, "actor_loss": -151.33966040232824, "actor_target_entropy": -1.0, "actor_entropy": 0.7538486104162913, "alpha_loss": -0.018965483497133447, "alpha_value": 0.2279276381797384, "duration": 153.0520040988922, "step": 24375}
{"episode_reward": 111.85995624650883, "episode": 196.0, "Q1 loss": 4.593378652572632, "Q2 loss": 4.614144775390625, "Mean Target Q": 150.87032080078126, "Mean Q1": 150.86814672851563, "Mean Q2": 150.8672645263672, "critic_loss": 9.207523387908935, "batch_reward": 1.2330783386230468, "actor_loss": -151.9249011624244, "actor_target_entropy": -1.0, "actor_entropy": 0.7505107877715942, "alpha_loss": -0.021753980733093717, "alpha_value": 0.22865182885401494, "duration": 152.25555872917175, "step": 24500}
{"episode_reward": 127.49567868557656, "episode": 197.0, "Q1 loss": 4.2855789108276365, "Q2 loss": 4.29009327507019, "Mean Target Q": 151.32790881347657, "Mean Q1": 151.32606701660157, "Mean Q2": 151.32723364257814, "critic_loss": 8.575672164916993, "batch_reward": 1.231128984451294, "actor_loss": -152.45728047688803, "actor_target_entropy": -1.0, "actor_entropy": 0.7415912700077844, "alpha_loss": -0.025686884361747948, "alpha_value": 0.22951702111509106, "duration": 137.02774834632874, "step": 24625}
{"episode_reward": 118.22497580681618, "episode": 198.0, "Q1 loss": 4.558421043395996, "Q2 loss": 4.594819032669068, "Mean Target Q": 151.77611499023436, "Mean Q1": 151.77496447753907, "Mean Q2": 151.77424243164063, "critic_loss": 9.15324003982544, "batch_reward": 1.2406065073013306, "actor_loss": -152.75498371739542, "actor_target_entropy": -1.0, "actor_entropy": 0.742091626890244, "alpha_loss": -0.02368644750752156, "alpha_value": 0.2304385870675578, "duration": 87.7338285446167, "step": 24750}
{"episode_reward": 151.330858722172, "episode": 199.0, "Q1 loss": 4.30589151763916, "Q2 loss": 4.306598508834839, "Mean Target Q": 152.1754284667969, "Mean Q1": 152.1751463623047, "Mean Q2": 152.17518090820312, "critic_loss": 8.612490043640136, "batch_reward": 1.2326127824783326, "actor_loss": -153.17393953838047, "actor_target_entropy": -1.0, "actor_entropy": 0.7445107849817427, "alpha_loss": -0.022055960570772488, "alpha_value": 0.2312772834790279, "duration": 59.38491344451904, "step": 24875}
{"episode_reward": 48.84475465588987, "episode": 200.0, "Q1 loss": 4.238262634277344, "Q2 loss": 4.246271764755249, "Mean Target Q": 152.70336950683594, "Mean Q1": 152.70018139648437, "Mean Q2": 152.70082885742187, "critic_loss": 8.484534412384033, "batch_reward": 1.241236988067627, "actor_loss": -153.7165308306294, "actor_target_entropy": -1.0, "actor_entropy": 0.7400445813132871, "alpha_loss": -0.014195944436059723, "alpha_value": 0.23184420090778404, "step": 25000}
{"duration": 81.02219271659851, "step": 25000}
{"episode_reward": 121.81268817859645, "episode": 201.0, "Q1 loss": 4.533350973129273, "Q2 loss": 4.538653028488159, "Mean Target Q": 153.08296032714844, "Mean Q1": 153.08533251953125, "Mean Q2": 153.0844765625, "critic_loss": 9.072004020690917, "batch_reward": 1.2347191305160523, "actor_loss": -154.12189035567027, "actor_target_entropy": -1.0, "actor_entropy": 0.7515028998965309, "alpha_loss": -0.022212975946742864, "alpha_value": 0.23263316470812367, "duration": 129.62086462974548, "step": 25125}
{"episode_reward": 182.67380071287732, "episode": 202.0, "Q1 loss": 4.468857223510742, "Q2 loss": 4.507336278915405, "Mean Target Q": 153.44694201660155, "Mean Q1": 153.43998767089843, "Mean Q2": 153.43988818359375, "critic_loss": 8.976193508148194, "batch_reward": 1.2311150379180908, "actor_loss": -154.5802289901241, "actor_target_entropy": -1.0, "actor_entropy": 0.7555768932065656, "alpha_loss": -0.02230247345212246, "alpha_value": 0.23343874568131578, "duration": 115.49984741210938, "step": 25250}
{"episode_reward": 138.20407967295407, "episode": 203.0, "Q1 loss": 4.571825967788696, "Q2 loss": 4.573407169342041, "Mean Target Q": 153.90011791992188, "Mean Q1": 153.8962294921875, "Mean Q2": 153.89631616210937, "critic_loss": 9.145233142852783, "batch_reward": 1.2235363874435425, "actor_loss": -155.0319535997179, "actor_target_entropy": -1.0, "actor_entropy": 0.7472666587148394, "alpha_loss": -0.017102028745862228, "alpha_value": 0.23422381812142876, "duration": 115.77689218521118, "step": 25375}
{"episode_reward": 117.52188828380277, "episode": 204.0, "Q1 loss": 4.787243644714356, "Q2 loss": 4.781405565261841, "Mean Target Q": 154.39281127929686, "Mean Q1": 154.38706469726563, "Mean Q2": 154.3878251953125, "critic_loss": 9.568649253845216, "batch_reward": 1.2375404691696168, "actor_loss": -155.4774927939138, "actor_target_entropy": -1.0, "actor_entropy": 0.7660894663103165, "alpha_loss": -0.025635115990054705, "alpha_value": 0.2350634210300097, "duration": 55.50469970703125, "step": 25500}
{"episode_reward": 157.25748461075318, "episode": 205.0, "Q1 loss": 4.492332906723022, "Q2 loss": 4.476942344665527, "Mean Target Q": 154.8274453125, "Mean Q1": 154.83049462890625, "Mean Q2": 154.82965515136718, "critic_loss": 8.969275287628173, "batch_reward": 1.2346477184295654, "actor_loss": -155.84857056632873, "actor_target_entropy": -1.0, "actor_entropy": 0.7578237104037452, "alpha_loss": -0.020037451411582648, "alpha_value": 0.23603900903417163, "duration": 68.47546148300171, "step": 25625}
{"episode_reward": 219.55574158009333, "episode": 206.0, "Q1 loss": 4.737242027282715, "Q2 loss": 4.74801944732666, "Mean Target Q": 155.26946228027344, "Mean Q1": 155.2697702636719, "Mean Q2": 155.26954602050782, "critic_loss": 9.485261493682861, "batch_reward": 1.2253489456176758, "actor_loss": -156.25237889443673, "actor_target_entropy": -1.0, "actor_entropy": 0.7673436201387837, "alpha_loss": -0.01572473041127406, "alpha_value": 0.23669572752158044, "duration": 56.75957894325256, "step": 25750}
{"episode_reward": 29.11435126571481, "episode": 207.0, "Q1 loss": 4.631656694412231, "Q2 loss": 4.629001670837402, "Mean Target Q": 155.75325244140626, "Mean Q1": 155.75207641601563, "Mean Q2": 155.75198120117187, "critic_loss": 9.260658317565918, "batch_reward": 1.2234216794967652, "actor_loss": -156.85668388245597, "actor_target_entropy": -1.0, "actor_entropy": 0.7276116865021842, "alpha_loss": -0.02237421434394838, "alpha_value": 0.23743693500806265, "duration": 57.161718130111694, "step": 25875}
{"episode_reward": 194.51850681741567, "episode": 208.0, "Q1 loss": 4.546876163482666, "Q2 loss": 4.56124529838562, "Mean Target Q": 156.15466662597657, "Mean Q1": 156.14884814453126, "Mean Q2": 156.1482833251953, "critic_loss": 9.108121463775635, "batch_reward": 1.2275288047790527, "actor_loss": -157.22403224822014, "actor_target_entropy": -1.0, "actor_entropy": 0.7564399742311047, "alpha_loss": -0.023246518347502475, "alpha_value": 0.23844986313956268, "duration": 64.2105598449707, "step": 26000}
{"episode_reward": 235.26297256948365, "episode": 209.0, "Q1 loss": 4.711259853363037, "Q2 loss": 4.722328693389892, "Mean Target Q": 156.6396435546875, "Mean Q1": 156.64264294433593, "Mean Q2": 156.6431455078125, "critic_loss": 9.433588550567627, "batch_reward": 1.2301477022171021, "actor_loss": -157.7328401595827, "actor_target_entropy": -1.0, "actor_entropy": 0.7579195584569659, "alpha_loss": -0.018139808641983165, "alpha_value": 0.2393362902464881, "duration": 86.67204165458679, "step": 26125}
{"episode_reward": 109.19562920093487, "episode": 210.0, "Q1 loss": 4.992493682861328, "Q2 loss": 4.994727167129517, "Mean Target Q": 157.07560620117187, "Mean Q1": 157.07086901855467, "Mean Q2": 157.07170532226561, "critic_loss": 9.987220859527588, "batch_reward": 1.2290059690475463, "actor_loss": -158.18468376897997, "actor_target_entropy": -1.0, "actor_entropy": 0.7443900425587932, "alpha_loss": -0.020037997979670763, "alpha_value": 0.24008934998599235, "duration": 127.90584063529968, "step": 26250}
{"episode_reward": 141.94265367486685, "episode": 211.0, "Q1 loss": 4.731138872146606, "Q2 loss": 4.7538892383575435, "Mean Target Q": 157.51511206054687, "Mean Q1": 157.51402514648439, "Mean Q2": 157.51366943359375, "critic_loss": 9.485028106689454, "batch_reward": 1.2248564138412477, "actor_loss": -158.59504723927333, "actor_target_entropy": -1.0, "actor_entropy": 0.7463859376453218, "alpha_loss": -0.014450723663829858, "alpha_value": 0.24087616802962136, "duration": 159.03174901008606, "step": 26375}
{"episode_reward": 77.6854531818796, "episode": 212.0, "Q1 loss": 4.760007164001465, "Q2 loss": 4.777537431716919, "Mean Target Q": 157.92191064453124, "Mean Q1": 157.91613793945314, "Mean Q2": 157.9159725341797, "critic_loss": 9.537544578552247, "batch_reward": 1.227208293914795, "actor_loss": -158.98613862068422, "actor_target_entropy": -1.0, "actor_entropy": 0.7647559162109129, "alpha_loss": -0.020553259073846763, "alpha_value": 0.24159350678104155, "duration": 138.44812393188477, "step": 26500}
{"episode_reward": 222.66300903982383, "episode": 213.0, "Q1 loss": 4.882718532562256, "Q2 loss": 4.8924725646972655, "Mean Target Q": 158.4296318359375, "Mean Q1": 158.43463269042968, "Mean Q2": 158.43496337890625, "critic_loss": 9.775191055297851, "batch_reward": 1.229791247367859, "actor_loss": -159.56888204907614, "actor_target_entropy": -1.0, "actor_entropy": 0.7747903797361586, "alpha_loss": -0.015647942695530163, "alpha_value": 0.24237609634582416, "duration": 116.52451992034912, "step": 26625}
{"episode_reward": 143.03555864651136, "episode": 214.0, "Q1 loss": 4.861683874130249, "Q2 loss": 4.876806085586548, "Mean Target Q": 158.8590372314453, "Mean Q1": 158.85328295898438, "Mean Q2": 158.85206018066407, "critic_loss": 9.7384899559021, "batch_reward": 1.2371509790420532, "actor_loss": -159.9303197553081, "actor_target_entropy": -1.0, "actor_entropy": 0.7658330855831024, "alpha_loss": -0.015043129967976241, "alpha_value": 0.2430890399675896, "duration": 122.68991327285767, "step": 26750}
{"episode_reward": 143.11402812187617, "episode": 215.0, "Q1 loss": 4.929227430343628, "Q2 loss": 4.921956745147705, "Mean Target Q": 159.25790869140624, "Mean Q1": 159.25872229003906, "Mean Q2": 159.25937158203126, "critic_loss": 9.851184154510499, "batch_reward": 1.2320814142227172, "actor_loss": -160.34945678710938, "actor_target_entropy": -1.0, "actor_entropy": 0.7654856102807182, "alpha_loss": -0.018439540347557456, "alpha_value": 0.24380840801200748, "duration": 125.96599221229553, "step": 26875}
{"episode_reward": 157.51888545872598, "episode": 216.0, "Q1 loss": 4.9169952659606935, "Q2 loss": 4.951797630310058, "Mean Target Q": 159.69482568359376, "Mean Q1": 159.6936062011719, "Mean Q2": 159.69305224609374, "critic_loss": 9.868792881011963, "batch_reward": 1.2345002269744874, "actor_loss": -160.73875402635144, "actor_target_entropy": -1.0, "actor_entropy": 0.7648122666343566, "alpha_loss": -0.014146630017597589, "alpha_value": 0.2445960297939706, "duration": 115.85926651954651, "step": 27000}
{"episode_reward": 111.36552473021774, "episode": 217.0, "Q1 loss": 4.816386556625366, "Q2 loss": 4.804545705795288, "Mean Target Q": 160.19260925292969, "Mean Q1": 160.19256286621095, "Mean Q2": 160.19232360839842, "critic_loss": 9.620932289123536, "batch_reward": 1.2270945281982422, "actor_loss": -161.2684573218936, "actor_target_entropy": -1.0, "actor_entropy": 0.7560244164769612, "alpha_loss": -0.013744286457372327, "alpha_value": 0.24528386030469088, "duration": 174.20728182792664, "step": 27125}
{"episode_reward": 48.688223485890425, "episode": 218.0, "Q1 loss": 4.615607767105103, "Q2 loss": 4.621282859802246, "Mean Target Q": 160.48227111816405, "Mean Q1": 160.47676843261718, "Mean Q2": 160.47708032226564, "critic_loss": 9.236890632629395, "batch_reward": 1.2187430334091187, "actor_loss": -161.56856512254285, "actor_target_entropy": -1.0, "actor_entropy": 0.7817272380475075, "alpha_loss": -0.009390107145713221, "alpha_value": 0.24580767388724006, "duration": 145.21008968353271, "step": 27250}
{"episode_reward": 235.54655032850332, "episode": 219.0, "Q1 loss": 4.668448032379151, "Q2 loss": 4.6675738334655765, "Mean Target Q": 160.97869213867187, "Mean Q1": 160.9820606689453, "Mean Q2": 160.98227575683595, "critic_loss": 9.336021877288818, "batch_reward": 1.2265993900299073, "actor_loss": -162.0188247438461, "actor_target_entropy": -1.0, "actor_entropy": 0.7737243506643507, "alpha_loss": -0.01180509551768265, "alpha_value": 0.2463157448136982, "duration": 155.62910962104797, "step": 27375}
{"episode_reward": 133.07794075892605, "episode": 220.0, "Q1 loss": 4.568652994155884, "Q2 loss": 4.592584032058716, "Mean Target Q": 161.37904846191407, "Mean Q1": 161.37514221191407, "Mean Q2": 161.37515686035155, "critic_loss": 9.16123701095581, "batch_reward": 1.2228141222000122, "actor_loss": -162.44313049316406, "actor_target_entropy": -1.0, "actor_entropy": 0.7616074171758467, "alpha_loss": -0.004958150273699674, "alpha_value": 0.2467105135357829, "duration": 163.7208013534546, "step": 27500}
{"episode_reward": 249.97403515328747, "episode": 221.0, "Q1 loss": 4.495844879150391, "Q2 loss": 4.492037206649781, "Mean Target Q": 161.81461499023436, "Mean Q1": 161.81097546386718, "Mean Q2": 161.8114677734375, "critic_loss": 8.987882076263428, "batch_reward": 1.227784701347351, "actor_loss": -162.9170876154824, "actor_target_entropy": -1.0, "actor_entropy": 0.7706754472520616, "alpha_loss": -0.009081831212998145, "alpha_value": 0.2470453983056576, "duration": 163.54933142662048, "step": 27625}
{"episode_reward": 98.13952775191112, "episode": 222.0, "Q1 loss": 4.61196727180481, "Q2 loss": 4.610373302459717, "Mean Target Q": 162.2595831298828, "Mean Q1": 162.2579025878906, "Mean Q2": 162.25773474121092, "critic_loss": 9.222340560913086, "batch_reward": 1.227891728401184, "actor_loss": -163.34955276981478, "actor_target_entropy": -1.0, "actor_entropy": 0.7743775354277703, "alpha_loss": -0.0069801134485450965, "alpha_value": 0.24748444170304398, "duration": 123.99770021438599, "step": 27750}
{"episode_reward": 159.7406477842862, "episode": 223.0, "Q1 loss": 4.612850793838501, "Q2 loss": 4.634358875274658, "Mean Target Q": 162.62308459472655, "Mean Q1": 162.6230495605469, "Mean Q2": 162.62275915527343, "critic_loss": 9.24720965194702, "batch_reward": 1.2276929531097411, "actor_loss": -163.76993597121466, "actor_target_entropy": -1.0, "actor_entropy": 0.7603212027322679, "alpha_loss": -0.011470145830470655, "alpha_value": 0.2478988480335455, "duration": 133.00564050674438, "step": 27875}
{"episode_reward": 281.5308994512623, "episode": 224.0, "Q1 loss": 4.891345766067505, "Q2 loss": 4.91481588935852, "Mean Target Q": 163.0983565673828, "Mean Q1": 163.09214709472656, "Mean Q2": 163.0921376953125, "critic_loss": 9.80616164779663, "batch_reward": 1.2302342824935912, "actor_loss": -164.18921341434603, "actor_target_entropy": -1.0, "actor_entropy": 0.7860228294326413, "alpha_loss": -0.007478404703790382, "alpha_value": 0.24848175246710694, "duration": 111.3179144859314, "step": 28000}
{"episode_reward": 170.4144823657944, "episode": 225.0, "Q1 loss": 4.596797332763672, "Q2 loss": 4.587055591583252, "Mean Target Q": 163.43197937011718, "Mean Q1": 163.43189978027343, "Mean Q2": 163.43190356445314, "critic_loss": 9.183852935791016, "batch_reward": 1.2200658073425292, "actor_loss": -164.51661197722905, "actor_target_entropy": -1.0, "actor_entropy": 0.7773473499313234, "alpha_loss": -0.008153496955018786, "alpha_value": 0.24902607803754775, "duration": 124.95901441574097, "step": 28125}
{"episode_reward": 93.35097342189898, "episode": 226.0, "Q1 loss": 4.750261552810669, "Q2 loss": 4.769828617095947, "Mean Target Q": 163.8750740966797, "Mean Q1": 163.87535766601562, "Mean Q2": 163.87499548339844, "critic_loss": 9.52009013748169, "batch_reward": 1.223789179801941, "actor_loss": -164.94784472065587, "actor_target_entropy": -1.0, "actor_entropy": 0.7713783892893022, "alpha_loss": -0.009028220678784794, "alpha_value": 0.24935318333999384, "duration": 130.3997528553009, "step": 28250}
{"episode_reward": 153.1523131675565, "episode": 227.0, "Q1 loss": 4.835948921203613, "Q2 loss": 4.841555723190307, "Mean Target Q": 164.26679406738282, "Mean Q1": 164.26615441894532, "Mean Q2": 164.26556530761718, "critic_loss": 9.677504653930663, "batch_reward": 1.2273371467590333, "actor_loss": -165.3196050250341, "actor_target_entropy": -1.0, "actor_entropy": 0.7560036286475167, "alpha_loss": 0.00025908151892797344, "alpha_value": 0.24956897334081007, "duration": 124.45063495635986, "step": 28375}
{"episode_reward": 218.3116401909278, "episode": 228.0, "Q1 loss": 4.830348232269287, "Q2 loss": 4.825492860794068, "Mean Target Q": 164.66281359863282, "Mean Q1": 164.66446044921875, "Mean Q2": 164.66519885253905, "critic_loss": 9.655841094970704, "batch_reward": 1.228869665145874, "actor_loss": -165.70306937925278, "actor_target_entropy": -1.0, "actor_entropy": 0.7782711905817832, "alpha_loss": -0.0027949943717929626, "alpha_value": 0.24969142261060695, "duration": 77.12470626831055, "step": 28500}
{"episode_reward": 166.17635116813946, "episode": 229.0, "Q1 loss": 4.865452060699463, "Q2 loss": 4.893174087524414, "Mean Target Q": 165.048626953125, "Mean Q1": 165.04390661621093, "Mean Q2": 165.04379577636718, "critic_loss": 9.758626098632812, "batch_reward": 1.2252158250808716, "actor_loss": -166.10919601198228, "actor_target_entropy": -1.0, "actor_entropy": 0.7739401573226565, "alpha_loss": -0.009292820919423348, "alpha_value": 0.2499992254187871, "duration": 62.1094856262207, "step": 28625}
{"episode_reward": 168.31790128878538, "episode": 230.0, "Q1 loss": 4.793729764938354, "Q2 loss": 4.822889389038086, "Mean Target Q": 165.44950329589844, "Mean Q1": 165.44870483398438, "Mean Q2": 165.44948229980469, "critic_loss": 9.616619132995606, "batch_reward": 1.2374075727462768, "actor_loss": -166.5768257879442, "actor_target_entropy": -1.0, "actor_entropy": 0.7802305336921446, "alpha_loss": -0.0008828694136032174, "alpha_value": 0.2503273606349492, "duration": 51.79599332809448, "step": 28750}
{"episode_reward": 69.17823844601288, "episode": 231.0, "Q1 loss": 5.095419799804687, "Q2 loss": 5.134001718521118, "Mean Target Q": 165.7499763183594, "Mean Q1": 165.74527978515624, "Mean Q2": 165.74469470214845, "critic_loss": 10.22942151260376, "batch_reward": 1.2277068710327148, "actor_loss": -166.80527024042038, "actor_target_entropy": -1.0, "actor_entropy": 0.7827497597724672, "alpha_loss": 0.004803473229653069, "alpha_value": 0.25022357794475564, "duration": 77.53897023200989, "step": 28875}
{"episode_reward": 35.24463119446681, "episode": 232.0, "Q1 loss": 4.712194002151489, "Q2 loss": 4.695235925674439, "Mean Target Q": 166.07725085449218, "Mean Q1": 166.07624841308595, "Mean Q2": 166.07670568847655, "critic_loss": 9.407429931640625, "batch_reward": 1.2301562824249268, "actor_loss": -167.11993088260775, "actor_target_entropy": -1.0, "actor_entropy": 0.7796679667888149, "alpha_loss": -0.0070107950596138835, "alpha_value": 0.2503397715632741, "duration": 129.74163031578064, "step": 29000}
{"episode_reward": 125.80666497646077, "episode": 233.0, "Q1 loss": 4.8285927467346195, "Q2 loss": 4.839330974578857, "Mean Target Q": 166.53978186035155, "Mean Q1": 166.53856689453124, "Mean Q2": 166.53776574707032, "critic_loss": 9.667923713684083, "batch_reward": 1.2177360229492187, "actor_loss": -167.49831959557912, "actor_target_entropy": -1.0, "actor_entropy": 0.7872959772745768, "alpha_loss": -0.003205367526601231, "alpha_value": 0.2506950940221316, "duration": 123.18610119819641, "step": 29125}
{"episode_reward": 140.4885457130172, "episode": 234.0, "Q1 loss": 4.909676721572876, "Q2 loss": 4.928311870574952, "Mean Target Q": 166.94478747558594, "Mean Q1": 166.94695935058593, "Mean Q2": 166.94795275878906, "critic_loss": 9.837988594055176, "batch_reward": 1.238065972328186, "actor_loss": -168.02086860902847, "actor_target_entropy": -1.0, "actor_entropy": 0.7656547427177429, "alpha_loss": 0.00019200015137152326, "alpha_value": 0.2505783662489502, "duration": 157.83788752555847, "step": 29250}
{"episode_reward": 241.9826657257737, "episode": 235.0, "Q1 loss": 4.902555770874024, "Q2 loss": 4.919897798538208, "Mean Target Q": 167.20671447753907, "Mean Q1": 167.2047149658203, "Mean Q2": 167.20390356445313, "critic_loss": 9.822453601837157, "batch_reward": 1.228353238105774, "actor_loss": -168.27329895988342, "actor_target_entropy": -1.0, "actor_entropy": 0.8031366543164329, "alpha_loss": -0.008153635247181806, "alpha_value": 0.2509998733595764, "duration": 147.35150575637817, "step": 29375}
{"episode_reward": 137.738265360317, "episode": 236.0, "Q1 loss": 4.799593147277832, "Q2 loss": 4.8068034458160405, "Mean Target Q": 167.611703125, "Mean Q1": 167.60708312988282, "Mean Q2": 167.60677819824218, "critic_loss": 9.606396583557128, "batch_reward": 1.2266751251220702, "actor_loss": -168.6829582952684, "actor_target_entropy": -1.0, "actor_entropy": 0.7734061143090648, "alpha_loss": -0.008601137673512341, "alpha_value": 0.2513295203722486, "duration": 127.60110282897949, "step": 29500}
{"episode_reward": 177.89390950472256, "episode": 237.0, "Q1 loss": 4.843553909301757, "Q2 loss": 4.8547181797027585, "Mean Target Q": 167.98385717773436, "Mean Q1": 167.98130249023438, "Mean Q2": 167.98173083496093, "critic_loss": 9.698272106170654, "batch_reward": 1.2244374160766602, "actor_loss": -169.08392140221974, "actor_target_entropy": -1.0, "actor_entropy": 0.8028494554852682, "alpha_loss": -0.00026756322513970117, "alpha_value": 0.2517269086363438, "duration": 125.49844765663147, "step": 29625}
{"episode_reward": 237.20606278172212, "episode": 238.0, "Q1 loss": 4.869558654785156, "Q2 loss": 4.846636457443237, "Mean Target Q": 168.48067041015625, "Mean Q1": 168.47929565429686, "Mean Q2": 168.47937915039063, "critic_loss": 9.716195095062256, "batch_reward": 1.2314701309204101, "actor_loss": -169.5632550639491, "actor_target_entropy": -1.0, "actor_entropy": 0.8156328979999788, "alpha_loss": -0.001777117099282482, "alpha_value": 0.25182361967369815, "duration": 145.63354682922363, "step": 29750}
{"episode_reward": 67.64390482354152, "episode": 239.0, "Q1 loss": 4.961629531860352, "Q2 loss": 4.976366157531738, "Mean Target Q": 168.81459155273438, "Mean Q1": 168.8110887451172, "Mean Q2": 168.8107626953125, "critic_loss": 9.937995674133301, "batch_reward": 1.2243439331054689, "actor_loss": -169.85531277126736, "actor_target_entropy": -1.0, "actor_entropy": 0.7723560399479337, "alpha_loss": -0.005663661515369775, "alpha_value": 0.2519423993726297, "duration": 155.70567917823792, "step": 29875}
{"episode_reward": 178.76696590739544, "episode": 240.0, "Q1 loss": 4.93358380317688, "Q2 loss": 4.9363228054046635, "Mean Target Q": 169.19432067871094, "Mean Q1": 169.19920141601563, "Mean Q2": 169.19937438964843, "critic_loss": 9.869906608581543, "batch_reward": 1.229637942314148, "actor_loss": -170.19889142436367, "actor_target_entropy": -1.0, "actor_entropy": 0.7888006077658746, "alpha_loss": -0.003086235614553575, "alpha_value": 0.2521546927225603, "step": 30000}
{"duration": 119.35010957717896, "step": 30000}
{"episode_reward": 162.32177947832193, "episode": 241.0, "Q1 loss": 5.290137676239014, "Q2 loss": 5.295938364028931, "Mean Target Q": 169.67258337402345, "Mean Q1": 169.66595166015625, "Mean Q2": 169.6663739013672, "critic_loss": 10.586076015472413, "batch_reward": 1.2347358407974243, "actor_loss": -170.76895480685764, "actor_target_entropy": -1.0, "actor_entropy": 0.7735976292973473, "alpha_loss": -0.004185664511862255, "alpha_value": 0.2526007067583138, "duration": 114.1772530078888, "step": 30125}
{"episode_reward": 144.2914016715513, "episode": 242.0, "Q1 loss": 5.215790525436401, "Q2 loss": 5.249704544067383, "Mean Target Q": 170.02273022460938, "Mean Q1": 170.02484448242188, "Mean Q2": 170.02477868652343, "critic_loss": 10.465495071411134, "batch_reward": 1.230085422515869, "actor_loss": -171.17117998676915, "actor_target_entropy": -1.0, "actor_entropy": 0.7905550676007425, "alpha_loss": -0.008225183599748678, "alpha_value": 0.25284997167413825, "duration": 138.2856080532074, "step": 30250}
{"episode_reward": 165.58454743079312, "episode": 243.0, "Q1 loss": 5.079653316497803, "Q2 loss": 5.077500726699829, "Mean Target Q": 170.40491088867188, "Mean Q1": 170.4009725341797, "Mean Q2": 170.40018420410155, "critic_loss": 10.157154117584229, "batch_reward": 1.230291290283203, "actor_loss": -171.46253119574652, "actor_target_entropy": -1.0, "actor_entropy": 0.784856463235522, "alpha_loss": -0.008233053169937598, "alpha_value": 0.2533728032909679, "duration": 165.28117895126343, "step": 30375}
{"episode_reward": 203.70494260008329, "episode": 244.0, "Q1 loss": 5.082712434768677, "Q2 loss": 5.096310220718384, "Mean Target Q": 170.71860192871094, "Mean Q1": 170.71847338867187, "Mean Q2": 170.71926818847658, "critic_loss": 10.179022701263428, "batch_reward": 1.2304942007064819, "actor_loss": -171.83343678136026, "actor_target_entropy": -1.0, "actor_entropy": 0.8050727978829415, "alpha_loss": -0.008813417941001394, "alpha_value": 0.25404856610482657, "duration": 123.7741641998291, "step": 30500}
{"episode_reward": 112.77214199708382, "episode": 245.0, "Q1 loss": 5.3678433723449706, "Q2 loss": 5.379082355499268, "Mean Target Q": 171.1408612060547, "Mean Q1": 171.138591796875, "Mean Q2": 171.1373820800781, "critic_loss": 10.74692572784424, "batch_reward": 1.228852102279663, "actor_loss": -172.2469945029607, "actor_target_entropy": -1.0, "actor_entropy": 0.7944839464293586, "alpha_loss": -0.002503777403266184, "alpha_value": 0.2542351986836112, "duration": 149.50904250144958, "step": 30625}
{"episode_reward": 123.56887534136004, "episode": 246.0, "Q1 loss": 5.474609710693359, "Q2 loss": 5.492763690948486, "Mean Target Q": 171.4662020263672, "Mean Q1": 171.46307739257813, "Mean Q2": 171.4639387207031, "critic_loss": 10.96737339782715, "batch_reward": 1.2361700706481933, "actor_loss": -172.50196247716104, "actor_target_entropy": -1.0, "actor_entropy": 0.7953214626158437, "alpha_loss": -0.0027409375742858937, "alpha_value": 0.2548535048565522, "duration": 167.32548451423645, "step": 30750}
{"episode_reward": 241.652206991107, "episode": 247.0, "Q1 loss": 5.113494613647461, "Q2 loss": 5.11532555770874, "Mean Target Q": 171.81207580566405, "Mean Q1": 171.80980126953125, "Mean Q2": 171.80940356445313, "critic_loss": 10.228820209503175, "batch_reward": 1.2268295421600341, "actor_loss": -172.8664267403739, "actor_target_entropy": -1.0, "actor_entropy": 0.8059253560172187, "alpha_loss": -0.0025639383913209986, "alpha_value": 0.25455859970629835, "duration": 132.84545016288757, "step": 30875}
{"episode_reward": 138.20745635381945, "episode": 248.0, "Q1 loss": 4.946685924530029, "Q2 loss": 4.955182332992553, "Mean Target Q": 172.26804248046875, "Mean Q1": 172.27006762695314, "Mean Q2": 172.26935241699218, "critic_loss": 9.901868236541748, "batch_reward": 1.2297347421646119, "actor_loss": -173.35554947391634, "actor_target_entropy": -1.0, "actor_entropy": 0.783368653828098, "alpha_loss": 0.0004435811330744576, "alpha_value": 0.25468267687183915, "duration": 174.96263909339905, "step": 31000}
{"episode_reward": 88.3530186157138, "episode": 249.0, "Q1 loss": 5.085150423049927, "Q2 loss": 5.1041915950775145, "Mean Target Q": 172.585400390625, "Mean Q1": 172.58273779296874, "Mean Q2": 172.58323010253906, "critic_loss": 10.189342037200928, "batch_reward": 1.221374599456787, "actor_loss": -173.72899131169396, "actor_target_entropy": -1.0, "actor_entropy": 0.8036442682856605, "alpha_loss": 0.005351834843630001, "alpha_value": 0.25448694847251896, "duration": 157.7355613708496, "step": 31125}
{"episode_reward": 155.9867935161239, "episode": 250.0, "Q1 loss": 5.136033504486084, "Q2 loss": 5.140872543334961, "Mean Target Q": 172.96855151367188, "Mean Q1": 172.96688842773438, "Mean Q2": 172.96737902832032, "critic_loss": 10.276905975341798, "batch_reward": 1.2311186962127685, "actor_loss": -174.0079830538842, "actor_target_entropy": -1.0, "actor_entropy": 0.7873010500784843, "alpha_loss": 0.0006294624819870919, "alpha_value": 0.25435964036213693, "duration": 150.5331835746765, "step": 31250}
{"episode_reward": 146.73427275555608, "episode": 251.0, "Q1 loss": 5.197048358917236, "Q2 loss": 5.2351621208190915, "Mean Target Q": 173.36809594726563, "Mean Q1": 173.36485339355468, "Mean Q2": 173.36519873046876, "critic_loss": 10.432210464477539, "batch_reward": 1.218670783996582, "actor_loss": -174.5415261889261, "actor_target_entropy": -1.0, "actor_entropy": 0.7784209071643768, "alpha_loss": -0.0068038297846676815, "alpha_value": 0.2544824488011993, "duration": 117.34782147407532, "step": 31375}
{"episode_reward": 139.61679685699892, "episode": 252.0, "Q1 loss": 5.167019662857055, "Q2 loss": 5.17219670677185, "Mean Target Q": 173.68957983398437, "Mean Q1": 173.6892137451172, "Mean Q2": 173.68853393554687, "critic_loss": 10.339216381072998, "batch_reward": 1.2265566778182984, "actor_loss": -174.721806926112, "actor_target_entropy": -1.0, "actor_entropy": 0.7854353823969441, "alpha_loss": -0.0009392538641188894, "alpha_value": 0.2547983545136687, "duration": 177.93598866462708, "step": 31500}
{"episode_reward": 125.63883529104223, "episode": 253.0, "Q1 loss": 5.211919172286987, "Q2 loss": 5.225170318603515, "Mean Target Q": 174.05561303710937, "Mean Q1": 174.0545458984375, "Mean Q2": 174.05533312988283, "critic_loss": 10.437089511871338, "batch_reward": 1.2144367504119873, "actor_loss": -175.2354750860305, "actor_target_entropy": -1.0, "actor_entropy": 0.7786245752894689, "alpha_loss": -0.005353706312321481, "alpha_value": 0.2549652542742151, "duration": 169.06722784042358, "step": 31625}
{"episode_reward": 168.84421784868897, "episode": 254.0, "Q1 loss": 5.2003002395629885, "Q2 loss": 5.233863903045655, "Mean Target Q": 174.43781774902342, "Mean Q1": 174.43336206054687, "Mean Q2": 174.4326827392578, "critic_loss": 10.434164112091064, "batch_reward": 1.2265762243270875, "actor_loss": -175.60198334724672, "actor_target_entropy": -1.0, "actor_entropy": 0.7882127425362987, "alpha_loss": 0.003674674756644714, "alpha_value": 0.2550334158501513, "duration": 149.87135243415833, "step": 31750}
{"episode_reward": 173.80037442525776, "episode": 255.0, "Q1 loss": 5.146893836975098, "Q2 loss": 5.145441093444824, "Mean Target Q": 174.8944305419922, "Mean Q1": 174.89496447753908, "Mean Q2": 174.89489050292968, "critic_loss": 10.292334941864013, "batch_reward": 1.2312997140884399, "actor_loss": -175.96688019283235, "actor_target_entropy": -1.0, "actor_entropy": 0.7936729088662162, "alpha_loss": 0.0016145016406736677, "alpha_value": 0.25497779996101205, "duration": 163.11039972305298, "step": 31875}
{"episode_reward": 88.36137977514639, "episode": 256.0, "Q1 loss": 4.943032297134399, "Q2 loss": 4.94359951210022, "Mean Target Q": 175.08057287597657, "Mean Q1": 175.08169958496094, "Mean Q2": 175.082033203125, "critic_loss": 9.886631786346436, "batch_reward": 1.2254314861297608, "actor_loss": -176.1952883812689, "actor_target_entropy": -1.0, "actor_entropy": 0.7908444452670312, "alpha_loss": 0.0069187787857146995, "alpha_value": 0.25460025542964343, "duration": 168.71135568618774, "step": 32000}
{"episode_reward": 9.024628523545388, "episode": 257.0, "Q1 loss": 5.074623092651367, "Q2 loss": 5.0936900329589845, "Mean Target Q": 175.51957458496094, "Mean Q1": 175.51632470703126, "Mean Q2": 175.51558911132813, "critic_loss": 10.168313137054444, "batch_reward": 1.2170066604614258, "actor_loss": -176.63907901824467, "actor_target_entropy": -1.0, "actor_entropy": 0.7839269117703513, "alpha_loss": 0.002820125492733149, "alpha_value": 0.2543730418555781, "duration": 141.638751745224, "step": 32125}
{"episode_reward": 68.1875524338716, "episode": 258.0, "Q1 loss": 5.0655726642608645, "Q2 loss": 5.054070974349975, "Mean Target Q": 175.93128649902343, "Mean Q1": 175.92242443847655, "Mean Q2": 175.9228303222656, "critic_loss": 10.119643615722657, "batch_reward": 1.2261620225906371, "actor_loss": -177.07636260986328, "actor_target_entropy": -1.0, "actor_entropy": 0.789311602230995, "alpha_loss": 0.005027462172532274, "alpha_value": 0.2540048285223469, "duration": 175.6355950832367, "step": 32250}
{"episode_reward": 167.08335844671458, "episode": 259.0, "Q1 loss": 5.124029623031616, "Q2 loss": 5.127587282180786, "Mean Target Q": 176.2472169189453, "Mean Q1": 176.25061730957032, "Mean Q2": 176.25131286621092, "critic_loss": 10.251616874694824, "batch_reward": 1.215456400871277, "actor_loss": -177.34223962208583, "actor_target_entropy": -1.0, "actor_entropy": 0.80332017417938, "alpha_loss": -0.0010165369862483607, "alpha_value": 0.2539681938926486, "duration": 84.74997854232788, "step": 32375}
{"episode_reward": 166.5520419502052, "episode": 260.0, "Q1 loss": 5.003101457595825, "Q2 loss": 5.008439451217652, "Mean Target Q": 176.64866650390624, "Mean Q1": 176.64594714355468, "Mean Q2": 176.64513269042968, "critic_loss": 10.011540939331054, "batch_reward": 1.2210328369140624, "actor_loss": -177.78904404178743, "actor_target_entropy": -1.0, "actor_entropy": 0.798467690906217, "alpha_loss": 0.00706186854175382, "alpha_value": 0.25375659628459873, "duration": 134.2350766658783, "step": 32500}
{"episode_reward": 171.31996679682206, "episode": 261.0, "Q1 loss": 5.07845260810852, "Q2 loss": 5.083855905532837, "Mean Target Q": 176.9540516357422, "Mean Q1": 176.95265380859374, "Mean Q2": 176.9525400390625, "critic_loss": 10.16230850982666, "batch_reward": 1.2240370740890503, "actor_loss": -178.01586938282801, "actor_target_entropy": -1.0, "actor_entropy": 0.8017555938826667, "alpha_loss": 0.0014727424187142226, "alpha_value": 0.25336672587403997, "duration": 170.25984454154968, "step": 32625}
{"episode_reward": 151.9351403889126, "episode": 262.0, "Q1 loss": 5.232760324478149, "Q2 loss": 5.225033946990967, "Mean Target Q": 177.39008520507812, "Mean Q1": 177.39115063476564, "Mean Q2": 177.39232568359375, "critic_loss": 10.457794273376464, "batch_reward": 1.2250810050964356, "actor_loss": -178.5641366281817, "actor_target_entropy": -1.0, "actor_entropy": 0.7824153323327342, "alpha_loss": -0.0026670106303607745, "alpha_value": 0.2533732242985669, "duration": 126.0707597732544, "step": 32750}
{"episode_reward": 187.15465494137575, "episode": 263.0, "Q1 loss": 5.456744194030762, "Q2 loss": 5.473142469406128, "Mean Target Q": 177.74229663085939, "Mean Q1": 177.74461694335938, "Mean Q2": 177.74315100097655, "critic_loss": 10.929886684417724, "batch_reward": 1.2225787382125854, "actor_loss": -178.8688761393229, "actor_target_entropy": -1.0, "actor_entropy": 0.7901103401940966, "alpha_loss": 0.0005420132370163051, "alpha_value": 0.2535199617336355, "duration": 161.2534749507904, "step": 32875}
{"episode_reward": 195.83256370995304, "episode": 264.0, "Q1 loss": 5.351244691848755, "Q2 loss": 5.340974287033081, "Mean Target Q": 178.06258947753906, "Mean Q1": 178.0544501953125, "Mean Q2": 178.054359375, "critic_loss": 10.692218952178955, "batch_reward": 1.221905722618103, "actor_loss": -179.1318088654549, "actor_target_entropy": -1.0, "actor_entropy": 0.7835745013529255, "alpha_loss": 0.0019828253125231112, "alpha_value": 0.25343184491072723, "duration": 151.75096464157104, "step": 33000}
{"episode_reward": 23.909214717608556, "episode": 265.0, "Q1 loss": 5.273465240478516, "Q2 loss": 5.301283609390259, "Mean Target Q": 178.4573857421875, "Mean Q1": 178.45859985351564, "Mean Q2": 178.45961254882812, "critic_loss": 10.574748859405517, "batch_reward": 1.229858437538147, "actor_loss": -179.54229930090526, "actor_target_entropy": -1.0, "actor_entropy": 0.7934874513792614, "alpha_loss": 0.004975730446093376, "alpha_value": 0.25336280684004514, "duration": 168.91942739486694, "step": 33125}
{"episode_reward": 201.48932423099757, "episode": 266.0, "Q1 loss": 5.228509239196777, "Q2 loss": 5.226786334991455, "Mean Target Q": 178.6826413574219, "Mean Q1": 178.68079333496092, "Mean Q2": 178.68128918457032, "critic_loss": 10.455295555114747, "batch_reward": 1.222534836769104, "actor_loss": -179.76202958629978, "actor_target_entropy": -1.0, "actor_entropy": 0.7782560346588012, "alpha_loss": -0.0029819928365008483, "alpha_value": 0.25326251431259955, "duration": 118.18755984306335, "step": 33250}
{"episode_reward": 53.09982770983318, "episode": 267.0, "Q1 loss": 5.306211080551147, "Q2 loss": 5.337294757843018, "Mean Target Q": 179.01437109375, "Mean Q1": 179.01194921875, "Mean Q2": 179.01192199707032, "critic_loss": 10.643505855560303, "batch_reward": 1.2128999576568604, "actor_loss": -180.1304691859654, "actor_target_entropy": -1.0, "actor_entropy": 0.7907634878915454, "alpha_loss": 0.006049698207616096, "alpha_value": 0.25308262230347833, "duration": 148.05419039726257, "step": 33375}
{"episode_reward": 140.13171462362538, "episode": 268.0, "Q1 loss": 4.899222927093506, "Q2 loss": 4.935218681335449, "Mean Target Q": 179.3224541015625, "Mean Q1": 179.32466052246093, "Mean Q2": 179.32432873535157, "critic_loss": 9.834441646575927, "batch_reward": 1.2080184860229493, "actor_loss": -180.37715468868132, "actor_target_entropy": -1.0, "actor_entropy": 0.7804528513262349, "alpha_loss": 0.01162327082091642, "alpha_value": 0.2525053715099893, "duration": 171.93195843696594, "step": 33500}
{"episode_reward": 9.25096934720808, "episode": 269.0, "Q1 loss": 4.816778915405274, "Q2 loss": 4.842576051712036, "Mean Target Q": 179.65192211914064, "Mean Q1": 179.64845788574218, "Mean Q2": 179.64877612304687, "critic_loss": 9.659354976654052, "batch_reward": 1.2054538202285767, "actor_loss": -180.8170161171565, "actor_target_entropy": -1.0, "actor_entropy": 0.7740752091483464, "alpha_loss": 0.00455148252362888, "alpha_value": 0.2518826136922802, "duration": 150.530757188797, "step": 33625}
{"episode_reward": 252.8866455852041, "episode": 270.0, "Q1 loss": 5.189072448730469, "Q2 loss": 5.198305456161499, "Mean Target Q": 180.1292244873047, "Mean Q1": 180.1287039794922, "Mean Q2": 180.12836267089844, "critic_loss": 10.387377933502197, "batch_reward": 1.2241039981842041, "actor_loss": -181.22293829148816, "actor_target_entropy": -1.0, "actor_entropy": 0.7706690046095079, "alpha_loss": 0.003842721415323115, "alpha_value": 0.2517443455131756, "duration": 161.37838983535767, "step": 33750}
{"episode_reward": 30.623057230764317, "episode": 271.0, "Q1 loss": 5.289635711669922, "Q2 loss": 5.291930013656616, "Mean Target Q": 180.46902001953126, "Mean Q1": 180.46464672851562, "Mean Q2": 180.4647059326172, "critic_loss": 10.581565742492677, "batch_reward": 1.2161874885559083, "actor_loss": -181.67100863986545, "actor_target_entropy": -1.0, "actor_entropy": 0.7811381920935616, "alpha_loss": -0.00848714883867947, "alpha_value": 0.2518615586755558, "duration": 81.42342042922974, "step": 33875}
{"episode_reward": 179.24338709246965, "episode": 272.0, "Q1 loss": 5.3541758899688725, "Q2 loss": 5.3649577579498295, "Mean Target Q": 180.8466160888672, "Mean Q1": 180.8452756347656, "Mean Q2": 180.84500903320313, "critic_loss": 10.719133632659911, "batch_reward": 1.2215047273635864, "actor_loss": -182.0312522149855, "actor_target_entropy": -1.0, "actor_entropy": 0.7910627299739469, "alpha_loss": -6.243672537347001e-05, "alpha_value": 0.2520876938884194, "duration": 154.4329674243927, "step": 34000}
{"episode_reward": 176.11274550577085, "episode": 273.0, "Q1 loss": 5.282129568099975, "Q2 loss": 5.283835428237915, "Mean Target Q": 181.13558178710937, "Mean Q1": 181.1341318359375, "Mean Q2": 181.1335047607422, "critic_loss": 10.565964992523194, "batch_reward": 1.2137507915496826, "actor_loss": -182.24107457721044, "actor_target_entropy": -1.0, "actor_entropy": 0.7880577984310332, "alpha_loss": 0.002415118611506408, "alpha_value": 0.25198552653666867, "duration": 181.64226031303406, "step": 34125}
{"episode_reward": 192.93291667182936, "episode": 274.0, "Q1 loss": 5.404335130691528, "Q2 loss": 5.432416395187378, "Mean Target Q": 181.5034815673828, "Mean Q1": 181.50841259765625, "Mean Q2": 181.50880029296874, "critic_loss": 10.836751502990722, "batch_reward": 1.2142086505889893, "actor_loss": -182.5948722593246, "actor_target_entropy": -1.0, "actor_entropy": 0.798960086799437, "alpha_loss": 0.0017744490028088612, "alpha_value": 0.2519009910522382, "duration": 165.14194083213806, "step": 34250}
{"episode_reward": 108.53769364021724, "episode": 275.0, "Q1 loss": 5.425634246826172, "Q2 loss": 5.434787715911865, "Mean Target Q": 181.79032055664064, "Mean Q1": 181.78497973632813, "Mean Q2": 181.78558764648437, "critic_loss": 10.86042195892334, "batch_reward": 1.211387833595276, "actor_loss": -182.88394213479663, "actor_target_entropy": -1.0, "actor_entropy": 0.7860753782211788, "alpha_loss": -0.004292259157250916, "alpha_value": 0.252162371995066, "duration": 136.09643244743347, "step": 34375}
{"episode_reward": 196.29992333002872, "episode": 276.0, "Q1 loss": 5.182587947845459, "Q2 loss": 5.206536895751953, "Mean Target Q": 182.24668237304687, "Mean Q1": 182.24181689453124, "Mean Q2": 182.2409832763672, "critic_loss": 10.389124813079833, "batch_reward": 1.212689938545227, "actor_loss": -183.38419637372417, "actor_target_entropy": -1.0, "actor_entropy": 0.7949255704879761, "alpha_loss": 0.004456745854939425, "alpha_value": 0.2520074702809673, "duration": 171.30619716644287, "step": 34500}
{"episode_reward": 226.63252001311136, "episode": 277.0, "Q1 loss": 5.502326583862304, "Q2 loss": 5.503051296234131, "Mean Target Q": 182.42796923828126, "Mean Q1": 182.43071044921874, "Mean Q2": 182.43190966796874, "critic_loss": 11.005377899169922, "batch_reward": 1.211181926727295, "actor_loss": -183.59429665217323, "actor_target_entropy": -1.0, "actor_entropy": 0.7853992278613742, "alpha_loss": -0.0024920747105386994, "alpha_value": 0.2519394297231391, "duration": 133.8134524822235, "step": 34625}
{"episode_reward": 68.20691191437186, "episode": 278.0, "Q1 loss": 5.544152584075928, "Q2 loss": 5.541199108123779, "Mean Target Q": 182.7058770751953, "Mean Q1": 182.70696398925782, "Mean Q2": 182.70695471191405, "critic_loss": 11.085351737976074, "batch_reward": 1.2001726112365723, "actor_loss": -183.90381597703504, "actor_target_entropy": -1.0, "actor_entropy": 0.7870122703813738, "alpha_loss": -0.0014543737915735091, "alpha_value": 0.25212102489955085, "duration": 112.20049095153809, "step": 34750}
{"episode_reward": 148.69982172421402, "episode": 279.0, "Q1 loss": 5.531028367996216, "Q2 loss": 5.557265729904175, "Mean Target Q": 183.1222374267578, "Mean Q1": 183.1131337890625, "Mean Q2": 183.1127980957031, "critic_loss": 11.088294120788575, "batch_reward": 1.2160731019973754, "actor_loss": -184.23331172882564, "actor_target_entropy": -1.0, "actor_entropy": 0.757281083909292, "alpha_loss": 0.0011469872856867454, "alpha_value": 0.2520016971985112, "duration": 163.9134418964386, "step": 34875}
{"episode_reward": 222.5214016079652, "episode": 280.0, "Q1 loss": 5.212069250106811, "Q2 loss": 5.211175815582275, "Mean Target Q": 183.33509997558593, "Mean Q1": 183.3360018310547, "Mean Q2": 183.33477868652344, "critic_loss": 10.423245136260986, "batch_reward": 1.2107823247909546, "actor_loss": -184.44000367195375, "actor_target_entropy": -1.0, "actor_entropy": 0.7990409328091529, "alpha_loss": 0.0011849138179733868, "alpha_value": 0.2520099853238827, "step": 35000}
{"duration": 158.04183316230774, "step": 35000}
{"episode_reward": 243.37391686570462, "episode": 281.0, "Q1 loss": 5.521826307296753, "Q2 loss": 5.523256128311157, "Mean Target Q": 183.78519409179688, "Mean Q1": 183.7874912109375, "Mean Q2": 183.78793493652344, "critic_loss": 11.045082431793213, "batch_reward": 1.217445972442627, "actor_loss": -184.86316911001055, "actor_target_entropy": -1.0, "actor_entropy": 0.7748010035545106, "alpha_loss": 0.0006686755204721103, "alpha_value": 0.2519240088193916, "duration": 175.85707449913025, "step": 35125}
{"episode_reward": 55.60071427537365, "episode": 282.0, "Q1 loss": 5.481702899932861, "Q2 loss": 5.479528453826904, "Mean Target Q": 184.02817626953126, "Mean Q1": 184.02573364257813, "Mean Q2": 184.0253292236328, "critic_loss": 10.961231342315674, "batch_reward": 1.2198140897750855, "actor_loss": -185.12303604618197, "actor_target_entropy": -1.0, "actor_entropy": 0.7927399479573772, "alpha_loss": 0.001814378632022248, "alpha_value": 0.25178914892483933, "duration": 162.66906023025513, "step": 35250}
{"episode_reward": 179.72039074568212, "episode": 283.0, "Q1 loss": 5.405465885162354, "Q2 loss": 5.418922502517701, "Mean Target Q": 184.33990881347657, "Mean Q1": 184.338267578125, "Mean Q2": 184.33855249023438, "critic_loss": 10.824388404846191, "batch_reward": 1.2108444089889527, "actor_loss": -185.45063321552578, "actor_target_entropy": -1.0, "actor_entropy": 0.7777085219110761, "alpha_loss": 0.0046355898477255355, "alpha_value": 0.25147359106547307, "duration": 119.26524543762207, "step": 35375}
{"episode_reward": 140.25091530458064, "episode": 284.0, "Q1 loss": 5.422422792434692, "Q2 loss": 5.452313053131103, "Mean Target Q": 184.58395056152344, "Mean Q1": 184.58280529785156, "Mean Q2": 184.58261547851563, "critic_loss": 10.874735843658447, "batch_reward": 1.2211564054489137, "actor_loss": -185.63201042913622, "actor_target_entropy": -1.0, "actor_entropy": 0.7813674298024946, "alpha_loss": 0.004549964526367765, "alpha_value": 0.25111163646771134, "duration": 142.50515961647034, "step": 35500}
{"episode_reward": 199.86139149023617, "episode": 285.0, "Q1 loss": 5.450042255401612, "Q2 loss": 5.453522727966309, "Mean Target Q": 184.87547973632812, "Mean Q1": 184.86976257324218, "Mean Q2": 184.87028393554687, "critic_loss": 10.90356504058838, "batch_reward": 1.2166648235321045, "actor_loss": -186.03828963022383, "actor_target_entropy": -1.0, "actor_entropy": 0.8004261274186392, "alpha_loss": 0.002592174127505767, "alpha_value": 0.25105981622941204, "duration": 167.02877068519592, "step": 35625}
{"episode_reward": 93.07242386535603, "episode": 286.0, "Q1 loss": 5.2955906848907475, "Q2 loss": 5.270459150314331, "Mean Target Q": 185.2010496826172, "Mean Q1": 185.19989428710937, "Mean Q2": 185.1998425292969, "critic_loss": 10.566049812316894, "batch_reward": 1.221834373474121, "actor_loss": -186.32181426017516, "actor_target_entropy": -1.0, "actor_entropy": 0.792628082536882, "alpha_loss": 0.009483920534201447, "alpha_value": 0.25055293906734255, "duration": 161.73510670661926, "step": 35750}
{"episode_reward": 8.873979142235436, "episode": 287.0, "Q1 loss": 5.245596652984619, "Q2 loss": 5.233915082931518, "Mean Target Q": 185.48943896484374, "Mean Q1": 185.4890810546875, "Mean Q2": 185.49017248535156, "critic_loss": 10.47951174545288, "batch_reward": 1.2056898908615112, "actor_loss": -186.59929596431672, "actor_target_entropy": -1.0, "actor_entropy": 0.7728827321340167, "alpha_loss": 0.0025350110612750525, "alpha_value": 0.2501480477650412, "duration": 129.02333307266235, "step": 35875}
{"episode_reward": 175.61444769471217, "episode": 288.0, "Q1 loss": 5.144946046829224, "Q2 loss": 5.154441032409668, "Mean Target Q": 185.72954602050783, "Mean Q1": 185.73314135742189, "Mean Q2": 185.7326181640625, "critic_loss": 10.299387088775635, "batch_reward": 1.2083636245727538, "actor_loss": -186.7984090005198, "actor_target_entropy": -1.0, "actor_entropy": 0.7958367841859018, "alpha_loss": 0.00021829667516172895, "alpha_value": 0.2500918127557358, "duration": 159.2823989391327, "step": 36000}
{"episode_reward": 136.36129217282027, "episode": 289.0, "Q1 loss": 5.669989110946656, "Q2 loss": 5.6679311256408695, "Mean Target Q": 186.10771020507812, "Mean Q1": 186.10522375488281, "Mean Q2": 186.1046630859375, "critic_loss": 11.337920234680176, "batch_reward": 1.2169761638641357, "actor_loss": -187.212891109406, "actor_target_entropy": -1.0, "actor_entropy": 0.797693858070979, "alpha_loss": -0.001454987361775859, "alpha_value": 0.2501638604442952, "duration": 175.04160594940186, "step": 36125}
{"episode_reward": 147.40730406327722, "episode": 290.0, "Q1 loss": 5.659602136611938, "Q2 loss": 5.659599311828614, "Mean Target Q": 186.4165245361328, "Mean Q1": 186.41247485351562, "Mean Q2": 186.41283544921876, "critic_loss": 11.31920142364502, "batch_reward": 1.2152778072357178, "actor_loss": -187.6041240076865, "actor_target_entropy": -1.0, "actor_entropy": 0.779182436966127, "alpha_loss": -0.0014134463703920764, "alpha_value": 0.2502948439302728, "duration": 163.33850979804993, "step": 36250}
{"episode_reward": 118.84169603878843, "episode": 291.0, "Q1 loss": 5.552283067703247, "Q2 loss": 5.565367538452149, "Mean Target Q": 186.62738671875, "Mean Q1": 186.62632958984375, "Mean Q2": 186.62587927246093, "critic_loss": 11.117650566101075, "batch_reward": 1.209862919807434, "actor_loss": -187.71299598330543, "actor_target_entropy": -1.0, "actor_entropy": 0.7921458700346569, "alpha_loss": -0.0054514661416529666, "alpha_value": 0.25042325501221024, "duration": 175.2809636592865, "step": 36375}
{"episode_reward": 176.5141264680506, "episode": 292.0, "Q1 loss": 5.164233352661133, "Q2 loss": 5.16371559715271, "Mean Target Q": 186.94677844238282, "Mean Q1": 186.94601110839844, "Mean Q2": 186.94648583984375, "critic_loss": 10.32794898223877, "batch_reward": 1.2117709999084472, "actor_loss": -188.0625482374622, "actor_target_entropy": -1.0, "actor_entropy": 0.7845242696423684, "alpha_loss": 0.006600304007259829, "alpha_value": 0.25043335841142167, "duration": 144.69643115997314, "step": 36500}
{"episode_reward": 133.19234564986232, "episode": 293.0, "Q1 loss": 5.133712228775025, "Q2 loss": 5.158986236572265, "Mean Target Q": 187.2162283935547, "Mean Q1": 187.21346459960938, "Mean Q2": 187.21340063476563, "critic_loss": 10.292698429107666, "batch_reward": 1.2126528692245484, "actor_loss": -188.2886962890625, "actor_target_entropy": -1.0, "actor_entropy": 0.7921524587131682, "alpha_loss": -0.002834770152167905, "alpha_value": 0.25030710950830665, "duration": 129.54104566574097, "step": 36625}
{"episode_reward": 219.90944740137732, "episode": 294.0, "Q1 loss": 5.154420568466186, "Q2 loss": 5.14952321434021, "Mean Target Q": 187.55551586914063, "Mean Q1": 187.55539599609375, "Mean Q2": 187.55497570800782, "critic_loss": 10.303943771362304, "batch_reward": 1.2194984455108642, "actor_loss": -188.6367888912078, "actor_target_entropy": -1.0, "actor_entropy": 0.7709100140679267, "alpha_loss": -0.004917758145189333, "alpha_value": 0.2505147917125418, "duration": 162.50919604301453, "step": 36750}
{"episode_reward": 170.66717673464652, "episode": 295.0, "Q1 loss": 5.2508884716033934, "Q2 loss": 5.252574993133545, "Mean Target Q": 187.85161572265625, "Mean Q1": 187.85030554199218, "Mean Q2": 187.85140490722657, "critic_loss": 10.503463497161865, "batch_reward": 1.2199463081359863, "actor_loss": -188.9714629158141, "actor_target_entropy": -1.0, "actor_entropy": 0.7788070024005951, "alpha_loss": -0.0034714576100841874, "alpha_value": 0.25082278952727977, "duration": 134.31505513191223, "step": 36875}
{"episode_reward": 134.8210760864067, "episode": 296.0, "Q1 loss": 5.42905828666687, "Q2 loss": 5.433841419219971, "Mean Target Q": 188.09366052246094, "Mean Q1": 188.09103674316407, "Mean Q2": 188.0893800048828, "critic_loss": 10.862899681091308, "batch_reward": 1.2134739303588866, "actor_loss": -189.15341998684792, "actor_target_entropy": -1.0, "actor_entropy": 0.7821533651121201, "alpha_loss": -0.0009375450824717841, "alpha_value": 0.2510421413729264, "duration": 167.4387722015381, "step": 37000}
{"episode_reward": 55.845672050215896, "episode": 297.0, "Q1 loss": 5.167693799972534, "Q2 loss": 5.169131317138672, "Mean Target Q": 188.32302062988282, "Mean Q1": 188.3207762451172, "Mean Q2": 188.32165197753906, "critic_loss": 10.33682511138916, "batch_reward": 1.2103781909942628, "actor_loss": -189.41827634781126, "actor_target_entropy": -1.0, "actor_entropy": 0.7918073771491884, "alpha_loss": -2.096589684249863e-05, "alpha_value": 0.25101355223842875, "duration": 163.28792691230774, "step": 37125}
{"episode_reward": 36.294239901252766, "episode": 298.0, "Q1 loss": 5.237404655456543, "Q2 loss": 5.2471790008544925, "Mean Target Q": 188.5540802001953, "Mean Q1": 188.55214587402344, "Mean Q2": 188.55206591796875, "critic_loss": 10.484583667755127, "batch_reward": 1.2006648569107055, "actor_loss": -189.6456771358367, "actor_target_entropy": -1.0, "actor_entropy": 0.7968349466400761, "alpha_loss": 0.007510011940593681, "alpha_value": 0.25078371537978583, "duration": 168.95763969421387, "step": 37250}
{"episode_reward": 3.4694480843855806, "episode": 299.0, "Q1 loss": 5.215575319290161, "Q2 loss": 5.24057666015625, "Mean Target Q": 188.86068298339845, "Mean Q1": 188.86609582519532, "Mean Q2": 188.86622521972657, "critic_loss": 10.456152027130127, "batch_reward": 1.2003617725372315, "actor_loss": -189.9619840591673, "actor_target_entropy": -1.0, "actor_entropy": 0.7949189874860976, "alpha_loss": 0.0017759388068779593, "alpha_value": 0.2503649331636788, "duration": 155.36745595932007, "step": 37375}
{"episode_reward": 108.9343487922557, "episode": 300.0, "Q1 loss": 5.1416656837463375, "Q2 loss": 5.149334926605224, "Mean Target Q": 189.13507250976562, "Mean Q1": 189.1280146484375, "Mean Q2": 189.12800219726563, "critic_loss": 10.291000625610351, "batch_reward": 1.2002678184509277, "actor_loss": -190.26780011576992, "actor_target_entropy": -1.0, "actor_entropy": 0.7795499938149606, "alpha_loss": -0.0066260503747710775, "alpha_value": 0.25052338522946044, "duration": 165.82881665229797, "step": 37500}
{"episode_reward": 207.9858291480196, "episode": 301.0, "Q1 loss": 5.299564958572388, "Q2 loss": 5.308884813308715, "Mean Target Q": 189.38180786132813, "Mean Q1": 189.38127880859375, "Mean Q2": 189.38142102050782, "critic_loss": 10.608449745178223, "batch_reward": 1.2090148735046387, "actor_loss": -190.4774467831566, "actor_target_entropy": -1.0, "actor_entropy": 0.7706716722912259, "alpha_loss": 0.0017644475872022293, "alpha_value": 0.25090299583360814, "duration": 135.7202591896057, "step": 37625}
{"episode_reward": 137.15249364455536, "episode": 302.0, "Q1 loss": 5.447355262756347, "Q2 loss": 5.410956003189087, "Mean Target Q": 189.72103686523437, "Mean Q1": 189.71560192871092, "Mean Q2": 189.7160139160156, "critic_loss": 10.858311237335204, "batch_reward": 1.1985812921524048, "actor_loss": -190.83737699447138, "actor_target_entropy": -1.0, "actor_entropy": 0.787572709783431, "alpha_loss": 0.005736330580416947, "alpha_value": 0.25064479224947384, "duration": 166.51335072517395, "step": 37750}
{"episode_reward": 113.74511141479361, "episode": 303.0, "Q1 loss": 5.609870643615722, "Q2 loss": 5.620244623184204, "Mean Target Q": 190.00676574707032, "Mean Q1": 190.01042822265626, "Mean Q2": 190.01052770996094, "critic_loss": 11.230115238189697, "batch_reward": 1.2102553119659425, "actor_loss": -191.04418921092199, "actor_target_entropy": -1.0, "actor_entropy": 0.7835409745337472, "alpha_loss": 0.008748370716126547, "alpha_value": 0.2501257923439692, "duration": 151.99782061576843, "step": 37875}
{"episode_reward": 191.27999861676324, "episode": 304.0, "Q1 loss": 5.862101333618164, "Q2 loss": 5.873036125183106, "Mean Target Q": 190.1780799560547, "Mean Q1": 190.1741619873047, "Mean Q2": 190.17365417480468, "critic_loss": 11.73513748550415, "batch_reward": 1.2125059633255004, "actor_loss": -191.2358639624811, "actor_target_entropy": -1.0, "actor_entropy": 0.7875695036303613, "alpha_loss": 0.008387926894600594, "alpha_value": 0.24937157613301855, "duration": 153.93342638015747, "step": 38000}
{"episode_reward": 189.33743604885876, "episode": 305.0, "Q1 loss": 5.473033584594726, "Q2 loss": 5.463289728164673, "Mean Target Q": 190.39425854492188, "Mean Q1": 190.39397924804686, "Mean Q2": 190.39429565429688, "critic_loss": 10.936323307037354, "batch_reward": 1.1988462266921998, "actor_loss": -191.42952885703434, "actor_target_entropy": -1.0, "actor_entropy": 0.7795793291122194, "alpha_loss": 0.005653141554267634, "alpha_value": 0.24885603038528836, "duration": 165.4863085746765, "step": 38125}
{"episode_reward": 79.48338813603254, "episode": 306.0, "Q1 loss": 5.577342222213745, "Q2 loss": 5.630317848205566, "Mean Target Q": 190.61828723144532, "Mean Q1": 190.61452685546874, "Mean Q2": 190.61457055664061, "critic_loss": 11.207660102844239, "batch_reward": 1.2139731397628784, "actor_loss": -191.81078289401145, "actor_target_entropy": -1.0, "actor_entropy": 0.803414911031723, "alpha_loss": -0.0020300650127953097, "alpha_value": 0.2486228180727216, "duration": 175.31227850914001, "step": 38250}
{"episode_reward": 171.78504604041632, "episode": 307.0, "Q1 loss": 5.880211803436279, "Q2 loss": 5.905877872467041, "Mean Target Q": 190.8776942138672, "Mean Q1": 190.87559155273436, "Mean Q2": 190.87483837890625, "critic_loss": 11.786089630126954, "batch_reward": 1.1995837774276734, "actor_loss": -192.11037069653707, "actor_target_entropy": -1.0, "actor_entropy": 0.7698120853257557, "alpha_loss": -0.0010974308150628255, "alpha_value": 0.2487170145131252, "duration": 154.25074195861816, "step": 38375}
{"episode_reward": 168.18470589530963, "episode": 308.0, "Q1 loss": 5.6243319320678715, "Q2 loss": 5.614017158508301, "Mean Target Q": 191.133166015625, "Mean Q1": 191.13168530273438, "Mean Q2": 191.1322100830078, "critic_loss": 11.238349113464356, "batch_reward": 1.2118409566879274, "actor_loss": -192.2043201077369, "actor_target_entropy": -1.0, "actor_entropy": 0.7990901316365888, "alpha_loss": -0.00024242664409440852, "alpha_value": 0.24892526094684997, "duration": 125.02182674407959, "step": 38500}
{"episode_reward": 87.09773151614934, "episode": 309.0, "Q1 loss": 5.542813724517822, "Q2 loss": 5.532757303237915, "Mean Target Q": 191.2815478515625, "Mean Q1": 191.2842547607422, "Mean Q2": 191.28328112792968, "critic_loss": 11.075571033477782, "batch_reward": 1.207342785835266, "actor_loss": -192.30196610708086, "actor_target_entropy": -1.0, "actor_entropy": 0.7962157205929832, "alpha_loss": 0.0045814592029071515, "alpha_value": 0.24874567227737093, "duration": 141.48963856697083, "step": 38625}
{"episode_reward": 154.88272082872558, "episode": 310.0, "Q1 loss": 5.574978681564331, "Q2 loss": 5.579585363388062, "Mean Target Q": 191.4995164794922, "Mean Q1": 191.49854357910155, "Mean Q2": 191.49934033203124, "critic_loss": 11.154564094543456, "batch_reward": 1.2035288591384887, "actor_loss": -192.56281305128527, "actor_target_entropy": -1.0, "actor_entropy": 0.7867682854975423, "alpha_loss": -0.0005926526106533504, "alpha_value": 0.24856120098682488, "duration": 166.06350994110107, "step": 38750}
{"episode_reward": 165.92828036833617, "episode": 311.0, "Q1 loss": 5.6646878623962404, "Q2 loss": 5.676079025268555, "Mean Target Q": 191.73356506347656, "Mean Q1": 191.73375170898439, "Mean Q2": 191.7336376953125, "critic_loss": 11.340766921997071, "batch_reward": 1.195594271659851, "actor_loss": -192.86732700892858, "actor_target_entropy": -1.0, "actor_entropy": 0.7882882981073289, "alpha_loss": -0.00012458824656075903, "alpha_value": 0.24861362157766667, "duration": 145.85864210128784, "step": 38875}
{"episode_reward": 40.518542807255, "episode": 312.0, "Q1 loss": 6.327153789520263, "Q2 loss": 6.337078800201416, "Mean Target Q": 192.00601147460938, "Mean Q1": 192.00368896484375, "Mean Q2": 192.0030919189453, "critic_loss": 12.664232601165772, "batch_reward": 1.1984122104644774, "actor_loss": -193.12567606279927, "actor_target_entropy": -1.0, "actor_entropy": 0.7740979877210432, "alpha_loss": 0.0010646471130331197, "alpha_value": 0.24869561609460286, "duration": 119.07401871681213, "step": 39000}
{"episode_reward": 6.9798854175587275, "episode": 313.0, "Q1 loss": 5.663211364746093, "Q2 loss": 5.648750383377076, "Mean Target Q": 192.23161657714843, "Mean Q1": 192.22678051757813, "Mean Q2": 192.22697131347655, "critic_loss": 11.311961738586426, "batch_reward": 1.1894527759552003, "actor_loss": -193.34503149607824, "actor_target_entropy": -1.0, "actor_entropy": 0.7958873548204937, "alpha_loss": -0.0008899649819507012, "alpha_value": 0.2485180226546229, "duration": 143.3457453250885, "step": 39125}
{"episode_reward": 159.65294562343774, "episode": 314.0, "Q1 loss": 5.732193801879883, "Q2 loss": 5.731846452713013, "Mean Target Q": 192.55815954589843, "Mean Q1": 192.56119299316407, "Mean Q2": 192.5610300292969, "critic_loss": 11.464040237426758, "batch_reward": 1.2016392221450807, "actor_loss": -193.67001441217238, "actor_target_entropy": -1.0, "actor_entropy": 0.8059581681605308, "alpha_loss": -0.0020437630704574048, "alpha_value": 0.2486547583328299, "duration": 126.58558535575867, "step": 39250}
{"episode_reward": 132.7660630821127, "episode": 315.0, "Q1 loss": 5.837314170837402, "Q2 loss": 5.855523983001709, "Mean Target Q": 192.7326447753906, "Mean Q1": 192.7306767578125, "Mean Q2": 192.7318984375, "critic_loss": 11.692838104248047, "batch_reward": 1.1887473773956299, "actor_loss": -193.94838678269159, "actor_target_entropy": -1.0, "actor_entropy": 0.7784038961879791, "alpha_loss": -0.005979406189114329, "alpha_value": 0.24882621560132515, "duration": 143.21926856040955, "step": 39375}
{"episode_reward": 68.15615799606053, "episode": 316.0, "Q1 loss": 6.032999559402466, "Q2 loss": 6.0525999374389645, "Mean Target Q": 193.07932885742187, "Mean Q1": 193.0750010986328, "Mean Q2": 193.07439123535156, "critic_loss": 12.085599502563477, "batch_reward": 1.1795519847869873, "actor_loss": -194.27186904415007, "actor_target_entropy": -1.0, "actor_entropy": 0.7655101629995531, "alpha_loss": -0.0009056487357273938, "alpha_value": 0.24919279547067136, "duration": 129.2993621826172, "step": 39500}
{"episode_reward": 119.59674713600427, "episode": 317.0, "Q1 loss": 6.302950851440429, "Q2 loss": 6.285530746459961, "Mean Target Q": 193.33728112792969, "Mean Q1": 193.33992541503906, "Mean Q2": 193.33916638183592, "critic_loss": 12.588481594085694, "batch_reward": 1.1969882383346557, "actor_loss": -194.50040302579364, "actor_target_entropy": -1.0, "actor_entropy": 0.7647474521682376, "alpha_loss": 2.531057208894737e-05, "alpha_value": 0.24901102392684213, "duration": 179.22041845321655, "step": 39625}
{"episode_reward": 193.31286683941255, "episode": 318.0, "Q1 loss": 6.541739765167236, "Q2 loss": 6.54156950378418, "Mean Target Q": 193.6110625, "Mean Q1": 193.60294958496092, "Mean Q2": 193.60339953613283, "critic_loss": 13.083309219360352, "batch_reward": 1.1896668090820313, "actor_loss": -194.79361921741116, "actor_target_entropy": -1.0, "actor_entropy": 0.7742774092382, "alpha_loss": -0.00206313940185693, "alpha_value": 0.24912427078527288, "duration": 162.5751621723175, "step": 39750}
{"episode_reward": 152.21719014324552, "episode": 319.0, "Q1 loss": 6.337898235321045, "Q2 loss": 6.380933345794678, "Mean Target Q": 193.85879028320312, "Mean Q1": 193.8619415283203, "Mean Q2": 193.86129431152344, "critic_loss": 12.718831596374512, "batch_reward": 1.1909336233139038, "actor_loss": -194.97235785590277, "actor_target_entropy": -1.0, "actor_entropy": 0.7917751121142554, "alpha_loss": -0.007992540308762165, "alpha_value": 0.24959408745112902, "duration": 173.83158612251282, "step": 39875}
{"episode_reward": 171.85491089426685, "episode": 320.0, "Q1 loss": 6.3300444145202635, "Q2 loss": 6.3527597808837895, "Mean Target Q": 194.07089880371095, "Mean Q1": 194.07183618164063, "Mean Q2": 194.0720451660156, "critic_loss": 12.682804161071777, "batch_reward": 1.1941920919418334, "actor_loss": -195.23955757387222, "actor_target_entropy": -1.0, "actor_entropy": 0.7888407197690779, "alpha_loss": 0.0013520695389278472, "alpha_value": 0.24986190144743586, "step": 40000}
{"duration": 140.4210593700409, "step": 40000}
{"episode_reward": 89.821887231669, "episode": 321.0, "Q1 loss": 6.194183734893799, "Q2 loss": 6.188898624420166, "Mean Target Q": 194.29552758789063, "Mean Q1": 194.28961450195314, "Mean Q2": 194.2901553955078, "critic_loss": 12.383082328796387, "batch_reward": 1.1897765941619873, "actor_loss": -195.44188968718998, "actor_target_entropy": -1.0, "actor_entropy": 0.7687383549554008, "alpha_loss": -0.0029366563650823777, "alpha_value": 0.25003024801374235, "duration": 177.82244348526, "step": 40125}
{"episode_reward": 142.0121415949803, "episode": 322.0, "Q1 loss": 5.886105710983276, "Q2 loss": 5.878651956558228, "Mean Target Q": 194.52376745605468, "Mean Q1": 194.5213038330078, "Mean Q2": 194.52113049316407, "critic_loss": 11.764757675170898, "batch_reward": 1.1986379537582397, "actor_loss": -195.7010032899918, "actor_target_entropy": -1.0, "actor_entropy": 0.7819793733858293, "alpha_loss": -0.01815107678844323, "alpha_value": 0.25063554450869596, "duration": 168.19550943374634, "step": 40250}
{"episode_reward": 138.26870222598345, "episode": 323.0, "Q1 loss": 6.114853466033936, "Q2 loss": 6.093511360168457, "Mean Target Q": 194.78819763183594, "Mean Q1": 194.78871032714844, "Mean Q2": 194.78865368652345, "critic_loss": 12.208364791870117, "batch_reward": 1.184296540260315, "actor_loss": -195.9473915705605, "actor_target_entropy": -1.0, "actor_entropy": 0.7846700142300318, "alpha_loss": -0.00881301879232365, "alpha_value": 0.25168186960951644, "duration": 141.2890601158142, "step": 40375}
{"episode_reward": 163.2423443713404, "episode": 324.0, "Q1 loss": 5.947176048278808, "Q2 loss": 5.970545139312744, "Mean Target Q": 195.05062609863282, "Mean Q1": 195.04937145996092, "Mean Q2": 195.04961938476563, "critic_loss": 11.917721202850341, "batch_reward": 1.1944598245620728, "actor_loss": -196.20501635151524, "actor_target_entropy": -1.0, "actor_entropy": 0.7921901758640043, "alpha_loss": -0.004311259565574508, "alpha_value": 0.25213534074855554, "duration": 113.18274402618408, "step": 40500}
{"episode_reward": 116.69098083397621, "episode": 325.0, "Q1 loss": 6.1449314270019535, "Q2 loss": 6.158777191162109, "Mean Target Q": 195.25742126464843, "Mean Q1": 195.25495642089842, "Mean Q2": 195.25461987304686, "critic_loss": 12.303708679199218, "batch_reward": 1.1958198194503784, "actor_loss": -196.39219447544642, "actor_target_entropy": -1.0, "actor_entropy": 0.7685506381685772, "alpha_loss": 0.002813674040168287, "alpha_value": 0.2523202257725007, "duration": 161.40390157699585, "step": 40625}
{"episode_reward": 141.30251600533467, "episode": 326.0, "Q1 loss": 5.843988521575928, "Q2 loss": 5.846528783798218, "Mean Target Q": 195.5160118408203, "Mean Q1": 195.51483288574218, "Mean Q2": 195.51518273925782, "critic_loss": 11.690517250061035, "batch_reward": 1.188818039894104, "actor_loss": -196.6564195694462, "actor_target_entropy": -1.0, "actor_entropy": 0.7802692507543871, "alpha_loss": -0.00024214397830468032, "alpha_value": 0.2520901024630502, "duration": 143.57948899269104, "step": 40750}
{"episode_reward": 30.884964398762293, "episode": 327.0, "Q1 loss": 5.473063028335571, "Q2 loss": 5.4516432571411135, "Mean Target Q": 195.79251708984376, "Mean Q1": 195.78973693847655, "Mean Q2": 195.79020568847656, "critic_loss": 10.924706298828125, "batch_reward": 1.1916668558120727, "actor_loss": -196.96624489436073, "actor_target_entropy": -1.0, "actor_entropy": 0.7743741359029498, "alpha_loss": -0.003774200499589954, "alpha_value": 0.2521427524441343, "duration": 140.681813955307, "step": 40875}
{"episode_reward": 150.38476836483125, "episode": 328.0, "Q1 loss": 5.522211397171021, "Q2 loss": 5.567084722518921, "Mean Target Q": 196.0004227294922, "Mean Q1": 196.00223278808593, "Mean Q2": 196.0027756347656, "critic_loss": 11.08929613494873, "batch_reward": 1.2033136444091797, "actor_loss": -197.10020692886846, "actor_target_entropy": -1.0, "actor_entropy": 0.7941644518606125, "alpha_loss": 0.0044538251146854415, "alpha_value": 0.2521138556805898, "duration": 179.4445343017578, "step": 41000}
{"episode_reward": 140.77683949095425, "episode": 329.0, "Q1 loss": 5.587436378479004, "Q2 loss": 5.593361326217652, "Mean Target Q": 196.14442932128907, "Mean Q1": 196.14295446777345, "Mean Q2": 196.1419267578125, "critic_loss": 11.180797729492188, "batch_reward": 1.184429539680481, "actor_loss": -197.20682779947916, "actor_target_entropy": -1.0, "actor_entropy": 0.7908557085763841, "alpha_loss": -0.002823603590802541, "alpha_value": 0.2521906339680696, "duration": 170.21820640563965, "step": 41125}
{"episode_reward": 84.56134288176226, "episode": 330.0, "Q1 loss": 5.924520099639893, "Q2 loss": 5.923405937194824, "Mean Target Q": 196.44041918945314, "Mean Q1": 196.43552673339843, "Mean Q2": 196.43558532714843, "critic_loss": 11.847926055908204, "batch_reward": 1.1999499130249023, "actor_loss": -197.6724587717364, "actor_target_entropy": -1.0, "actor_entropy": 0.7712874220263574, "alpha_loss": -0.004315067030068847, "alpha_value": 0.2524806059173738, "duration": 170.60884857177734, "step": 41250}
{"episode_reward": 192.54464748634393, "episode": 331.0, "Q1 loss": 5.606634496688843, "Q2 loss": 5.579698013305664, "Mean Target Q": 196.63468432617188, "Mean Q1": 196.63857189941407, "Mean Q2": 196.6384364013672, "critic_loss": 11.186332481384277, "batch_reward": 1.1841248607635497, "actor_loss": -197.7700408451141, "actor_target_entropy": -1.0, "actor_entropy": 0.787935787723178, "alpha_loss": 0.00896072573590255, "alpha_value": 0.25240265783019344, "duration": 168.7261357307434, "step": 41375}
{"episode_reward": 221.33226506634148, "episode": 332.0, "Q1 loss": 5.612945636749267, "Q2 loss": 5.626565958023071, "Mean Target Q": 196.76943774414062, "Mean Q1": 196.76512658691405, "Mean Q2": 196.76535009765624, "critic_loss": 11.239511573791503, "batch_reward": 1.1926597623825073, "actor_loss": -197.8801001271894, "actor_target_entropy": -1.0, "actor_entropy": 0.78270863140783, "alpha_loss": 0.007271146959429907, "alpha_value": 0.2515332805041338, "duration": 134.11519026756287, "step": 41500}
{"episode_reward": 147.21360900761073, "episode": 333.0, "Q1 loss": 5.483762266159058, "Q2 loss": 5.511751308441162, "Mean Target Q": 196.95439709472657, "Mean Q1": 196.9528010253906, "Mean Q2": 196.9524647216797, "critic_loss": 10.995513572692872, "batch_reward": 1.1935579786300659, "actor_loss": -198.0581311422681, "actor_target_entropy": -1.0, "actor_entropy": 0.7835766673088074, "alpha_loss": 0.0009130629662808681, "alpha_value": 0.2514205908603293, "duration": 132.8622407913208, "step": 41625}
{"episode_reward": 147.98350969055872, "episode": 334.0, "Q1 loss": 5.581612092971802, "Q2 loss": 5.587914791107178, "Mean Target Q": 197.10045544433595, "Mean Q1": 197.0996220703125, "Mean Q2": 197.10025805664063, "critic_loss": 11.169526893615723, "batch_reward": 1.1829613914489747, "actor_loss": -198.29043456046813, "actor_target_entropy": -1.0, "actor_entropy": 0.8068358234820827, "alpha_loss": 0.0026149805334787215, "alpha_value": 0.25118060087190236, "duration": 148.0055947303772, "step": 41750}
{"episode_reward": 97.57653399892652, "episode": 335.0, "Q1 loss": 5.378541061401367, "Q2 loss": 5.383303314208985, "Mean Target Q": 197.43315979003907, "Mean Q1": 197.43502185058594, "Mean Q2": 197.43474145507813, "critic_loss": 10.761844383239746, "batch_reward": 1.1892256126403808, "actor_loss": -198.58887445359002, "actor_target_entropy": -1.0, "actor_entropy": 0.77600216770929, "alpha_loss": -0.00392462420351212, "alpha_value": 0.25136197071810823, "duration": 160.09953022003174, "step": 41875}
{"episode_reward": 117.83999951225644, "episode": 336.0, "Q1 loss": 5.317646320343018, "Q2 loss": 5.32115057182312, "Mean Target Q": 197.64219470214843, "Mean Q1": 197.63675952148438, "Mean Q2": 197.636365234375, "critic_loss": 10.638796882629395, "batch_reward": 1.189089853286743, "actor_loss": -198.73311098160283, "actor_target_entropy": -1.0, "actor_entropy": 0.801421336589321, "alpha_loss": 0.005715912910208346, "alpha_value": 0.25131317144799803, "duration": 140.58771538734436, "step": 42000}
{"episode_reward": 90.9210646650003, "episode": 337.0, "Q1 loss": 5.896916294097901, "Q2 loss": 5.928370018005371, "Mean Target Q": 197.80774597167968, "Mean Q1": 197.80400695800782, "Mean Q2": 197.80440380859375, "critic_loss": 11.825286346435547, "batch_reward": 1.1841768350601196, "actor_loss": -199.02087232801648, "actor_target_entropy": -1.0, "actor_entropy": 0.7734117129492382, "alpha_loss": -0.003057261533473456, "alpha_value": 0.2510253266152223, "duration": 181.27207970619202, "step": 42125}
{"episode_reward": 162.1008880882824, "episode": 338.0, "Q1 loss": 5.787004886627197, "Q2 loss": 5.79012064743042, "Mean Target Q": 198.13561169433595, "Mean Q1": 198.1377293701172, "Mean Q2": 198.1372229003906, "critic_loss": 11.577125541687012, "batch_reward": 1.1899741382598876, "actor_loss": -199.29510719545425, "actor_target_entropy": -1.0, "actor_entropy": 0.7882350865871676, "alpha_loss": 0.00044148938069420477, "alpha_value": 0.25125148112859735, "duration": 164.9870047569275, "step": 42250}
{"episode_reward": 123.7993726023085, "episode": 339.0, "Q1 loss": 5.940126819610596, "Q2 loss": 5.93710073852539, "Mean Target Q": 198.24276538085937, "Mean Q1": 198.23986096191408, "Mean Q2": 198.23975427246094, "critic_loss": 11.877227546691895, "batch_reward": 1.1880580005645751, "actor_loss": -199.38107130262586, "actor_target_entropy": -1.0, "actor_entropy": 0.7829606930414835, "alpha_loss": -0.003986492579329818, "alpha_value": 0.2514559447034712, "duration": 139.09105801582336, "step": 42375}
{"episode_reward": 120.01718886564018, "episode": 340.0, "Q1 loss": 5.967726753234864, "Q2 loss": 5.9698220844268794, "Mean Target Q": 198.46660461425782, "Mean Q1": 198.46911157226563, "Mean Q2": 198.46906201171876, "critic_loss": 11.937548824310303, "batch_reward": 1.1867045040130615, "actor_loss": -199.78370494227255, "actor_target_entropy": -1.0, "actor_entropy": 0.7914380671516541, "alpha_loss": -0.012726249398603555, "alpha_value": 0.25193381716110175, "duration": 139.4483253955841, "step": 42500}
{"episode_reward": 133.10837602124036, "episode": 341.0, "Q1 loss": 6.665647514343262, "Q2 loss": 6.67519995880127, "Mean Target Q": 198.9163233642578, "Mean Q1": 198.91353454589844, "Mean Q2": 198.91460864257812, "critic_loss": 13.34084741973877, "batch_reward": 1.184301812171936, "actor_loss": -200.10231550913008, "actor_target_entropy": -1.0, "actor_entropy": 0.8021980968732683, "alpha_loss": -0.005768504363322068, "alpha_value": 0.25271534243112953, "duration": 142.0397367477417, "step": 42625}
{"episode_reward": 222.6005963708602, "episode": 342.0, "Q1 loss": 6.1790926532745365, "Q2 loss": 6.1801536178588865, "Mean Target Q": 199.0009708251953, "Mean Q1": 198.99272338867186, "Mean Q2": 198.9921024169922, "critic_loss": 12.359246273040771, "batch_reward": 1.1857163305282592, "actor_loss": -200.06930148216986, "actor_target_entropy": -1.0, "actor_entropy": 0.816760266019452, "alpha_loss": 0.005949158604527193, "alpha_value": 0.2526373325497975, "duration": 145.3416187763214, "step": 42750}
{"episode_reward": 191.11700224709514, "episode": 343.0, "Q1 loss": 6.012267799377441, "Q2 loss": 6.0209231929779055, "Mean Target Q": 199.190103515625, "Mean Q1": 199.19941625976563, "Mean Q2": 199.1998133544922, "critic_loss": 12.033191032409668, "batch_reward": 1.1829136543273926, "actor_loss": -200.32532876635355, "actor_target_entropy": -1.0, "actor_entropy": 0.7726448991942028, "alpha_loss": -0.0016354509141473543, "alpha_value": 0.2523551082096728, "duration": 172.8540608882904, "step": 42875}
{"episode_reward": 175.2475469936319, "episode": 344.0, "Q1 loss": 5.837796726226807, "Q2 loss": 5.8593064937591555, "Mean Target Q": 199.38293383789062, "Mean Q1": 199.37345971679687, "Mean Q2": 199.37324865722655, "critic_loss": 11.697103225708007, "batch_reward": 1.1843714532852172, "actor_loss": -200.56331634521484, "actor_target_entropy": -1.0, "actor_entropy": 0.7925158469907699, "alpha_loss": -0.007969385570651221, "alpha_value": 0.25285964865880145, "duration": 157.26268649101257, "step": 43000}
{"episode_reward": 96.75798458142381, "episode": 345.0, "Q1 loss": 5.921335926055908, "Q2 loss": 5.932741426467896, "Mean Target Q": 199.51821862792968, "Mean Q1": 199.5185419921875, "Mean Q2": 199.51846911621095, "critic_loss": 11.854077346801757, "batch_reward": 1.1863537845611571, "actor_loss": -200.66346619621154, "actor_target_entropy": -1.0, "actor_entropy": 0.8040660941411578, "alpha_loss": 0.0027733621712300984, "alpha_value": 0.25301061849481626, "duration": 168.7478575706482, "step": 43125}
{"episode_reward": 165.7421364916634, "episode": 346.0, "Q1 loss": 5.730666578292847, "Q2 loss": 5.722900342941284, "Mean Target Q": 199.7595791015625, "Mean Q1": 199.76063940429688, "Mean Q2": 199.76030908203126, "critic_loss": 11.453566883087158, "batch_reward": 1.1884440755844117, "actor_loss": -200.95032550442605, "actor_target_entropy": -1.0, "actor_entropy": 0.790896725270056, "alpha_loss": -0.0032287907388602053, "alpha_value": 0.2529582388869767, "duration": 165.8573079109192, "step": 43250}
{"episode_reward": 95.65147091757892, "episode": 347.0, "Q1 loss": 5.591017993927002, "Q2 loss": 5.6147029552459715, "Mean Target Q": 199.97101770019532, "Mean Q1": 199.9706494140625, "Mean Q2": 199.97047912597657, "critic_loss": 11.20572093963623, "batch_reward": 1.1928975162506104, "actor_loss": -201.11950756254652, "actor_target_entropy": -1.0, "actor_entropy": 0.773643504059504, "alpha_loss": 0.009851831964971055, "alpha_value": 0.25267748073973506, "duration": 182.50228023529053, "step": 43375}
{"episode_reward": 153.95533312445593, "episode": 348.0, "Q1 loss": 6.06792960357666, "Q2 loss": 6.076249011993408, "Mean Target Q": 200.24731481933594, "Mean Q1": 200.24330529785155, "Mean Q2": 200.24276733398438, "critic_loss": 12.14417862701416, "batch_reward": 1.188304958343506, "actor_loss": -201.48099173268963, "actor_target_entropy": -1.0, "actor_entropy": 0.78740434492788, "alpha_loss": -0.005535797182200176, "alpha_value": 0.2525348785702369, "duration": 169.02528762817383, "step": 43500}
{"episode_reward": 146.59065956059632, "episode": 349.0, "Q1 loss": 6.085155220031738, "Q2 loss": 6.073084537506103, "Mean Target Q": 200.43645764160155, "Mean Q1": 200.4329434814453, "Mean Q2": 200.4328104248047, "critic_loss": 12.158239761352538, "batch_reward": 1.1916664113998414, "actor_loss": -201.73078167627727, "actor_target_entropy": -1.0, "actor_entropy": 0.7948024216152373, "alpha_loss": -0.009941996348696568, "alpha_value": 0.25311175521172846, "duration": 159.620046377182, "step": 43625}
{"episode_reward": 4.53937293138322, "episode": 350.0, "Q1 loss": 6.073326110839844, "Q2 loss": 6.093191032409668, "Mean Target Q": 200.69839587402345, "Mean Q1": 200.69705676269533, "Mean Q2": 200.69826953125, "critic_loss": 12.166517135620117, "batch_reward": 1.1828626232147217, "actor_loss": -201.8768746160692, "actor_target_entropy": -1.0, "actor_entropy": 0.8023054234443172, "alpha_loss": 0.0027159889484004627, "alpha_value": 0.2535661634823126, "duration": 179.77594780921936, "step": 43750}
{"episode_reward": 181.39027863176636, "episode": 351.0, "Q1 loss": 6.413124092102051, "Q2 loss": 6.394847248077393, "Mean Target Q": 200.9467823486328, "Mean Q1": 200.94533251953126, "Mean Q2": 200.94507800292968, "critic_loss": 12.807971351623536, "batch_reward": 1.1841569271087646, "actor_loss": -202.11526561918714, "actor_target_entropy": -1.0, "actor_entropy": 0.7836371877836803, "alpha_loss": -0.0050088345176643794, "alpha_value": 0.25363944742828964, "duration": 147.93483805656433, "step": 43875}
{"episode_reward": 21.832113270362818, "episode": 352.0, "Q1 loss": 6.317700824737549, "Q2 loss": 6.347397808074951, "Mean Target Q": 201.09803552246095, "Mean Q1": 201.0967489013672, "Mean Q2": 201.09592504882812, "critic_loss": 12.665098663330077, "batch_reward": 1.18780105304718, "actor_loss": -202.34772442233177, "actor_target_entropy": -1.0, "actor_entropy": 0.7844109141057537, "alpha_loss": -0.0029671616390377522, "alpha_value": 0.25380752343487295, "duration": 175.86467599868774, "step": 44000}
{"episode_reward": 160.70687189327947, "episode": 353.0, "Q1 loss": 6.46870945930481, "Q2 loss": 6.450777040481567, "Mean Target Q": 201.33484790039063, "Mean Q1": 201.3340009765625, "Mean Q2": 201.33549365234376, "critic_loss": 12.919486518859863, "batch_reward": 1.1744998054504394, "actor_loss": -202.4499715169271, "actor_target_entropy": -1.0, "actor_entropy": 0.7759982101500981, "alpha_loss": -0.0031381561938259336, "alpha_value": 0.25399660921337835, "duration": 169.31530141830444, "step": 44125}
{"episode_reward": 157.61016988913627, "episode": 354.0, "Q1 loss": 6.106591590881347, "Q2 loss": 6.099031681060791, "Mean Target Q": 201.50689697265625, "Mean Q1": 201.50844201660155, "Mean Q2": 201.50738415527343, "critic_loss": 12.20562327194214, "batch_reward": 1.1786503009796143, "actor_loss": -202.6908214938256, "actor_target_entropy": -1.0, "actor_entropy": 0.7901298394126277, "alpha_loss": 0.0018784573466907586, "alpha_value": 0.25390728846991323, "duration": 150.63101887702942, "step": 44250}
{"episode_reward": 175.65072427631858, "episode": 355.0, "Q1 loss": 5.727619647979736, "Q2 loss": 5.73632564163208, "Mean Target Q": 201.59209423828125, "Mean Q1": 201.5892305908203, "Mean Q2": 201.58826330566407, "critic_loss": 11.463945301055908, "batch_reward": 1.1838654088973999, "actor_loss": -202.71160767570373, "actor_target_entropy": -1.0, "actor_entropy": 0.7684491182130481, "alpha_loss": 0.00033006008108338666, "alpha_value": 0.25398932129945645, "duration": 172.80594563484192, "step": 44375}
{"episode_reward": 164.0262058789102, "episode": 356.0, "Q1 loss": 5.630411153793335, "Q2 loss": 5.653178674697876, "Mean Target Q": 201.77395861816407, "Mean Q1": 201.7717897949219, "Mean Q2": 201.7725771484375, "critic_loss": 11.283589866638184, "batch_reward": 1.1837386569976807, "actor_loss": -203.00395645633822, "actor_target_entropy": -1.0, "actor_entropy": 0.791073537641956, "alpha_loss": 0.004048263331154181, "alpha_value": 0.25368149453387107, "duration": 162.9081003665924, "step": 44500}
{"episode_reward": 89.85103698829055, "episode": 357.0, "Q1 loss": 5.586079580307007, "Q2 loss": 5.586875970840454, "Mean Target Q": 202.05028149414062, "Mean Q1": 202.0495626220703, "Mean Q2": 202.04987438964844, "critic_loss": 11.172955554962158, "batch_reward": 1.1844427738189698, "actor_loss": -203.2003413609096, "actor_target_entropy": -1.0, "actor_entropy": 0.7906596840374054, "alpha_loss": -0.0013802837107389691, "alpha_value": 0.2538011054949404, "duration": 182.4771375656128, "step": 44625}
{"episode_reward": 180.82678963411558, "episode": 358.0, "Q1 loss": 5.7462805709838864, "Q2 loss": 5.73981742477417, "Mean Target Q": 202.17128454589843, "Mean Q1": 202.16669885253907, "Mean Q2": 202.16621594238282, "critic_loss": 11.486098014831542, "batch_reward": 1.180248595237732, "actor_loss": -203.32737608878844, "actor_target_entropy": -1.0, "actor_entropy": 0.7726027917477393, "alpha_loss": 0.0026160523280381195, "alpha_value": 0.25368910977656356, "duration": 169.78614807128906, "step": 44750}
{"episode_reward": 92.13429710394968, "episode": 359.0, "Q1 loss": 5.719352975845337, "Q2 loss": 5.752574926376343, "Mean Target Q": 202.428791015625, "Mean Q1": 202.42728967285157, "Mean Q2": 202.42722814941405, "critic_loss": 11.47192790222168, "batch_reward": 1.1853745412826537, "actor_loss": -203.62801833379837, "actor_target_entropy": -1.0, "actor_entropy": 0.8121543110363068, "alpha_loss": -0.0012219601961237097, "alpha_value": 0.25353525244848607, "duration": 181.5783188343048, "step": 44875}
{"episode_reward": 132.00254938950326, "episode": 360.0, "Q1 loss": 5.6214322624206545, "Q2 loss": 5.588433418273926, "Mean Target Q": 202.6022705078125, "Mean Q1": 202.60220458984375, "Mean Q2": 202.60251196289062, "critic_loss": 11.209865684509277, "batch_reward": 1.1687471923828125, "actor_loss": -203.7882793795678, "actor_target_entropy": -1.0, "actor_entropy": 0.7876513465758292, "alpha_loss": 0.0030518732702119215, "alpha_value": 0.2537329231380524, "step": 45000}
{"duration": 188.7582631111145, "step": 45000}
{"episode_reward": 23.567545100545125, "episode": 361.0, "Q1 loss": 5.66170788192749, "Q2 loss": 5.68102949142456, "Mean Target Q": 202.81217736816407, "Mean Q1": 202.81531103515624, "Mean Q2": 202.81490197753905, "critic_loss": 11.342737407684327, "batch_reward": 1.1782715587615966, "actor_loss": -204.01361423068576, "actor_target_entropy": -1.0, "actor_entropy": 0.788224648861658, "alpha_loss": -0.005076246033053076, "alpha_value": 0.2535444814194134, "duration": 166.24843740463257, "step": 45125}
{"episode_reward": 151.2667122736586, "episode": 362.0, "Q1 loss": 5.499628980636596, "Q2 loss": 5.493553886413574, "Mean Target Q": 203.00681518554688, "Mean Q1": 203.0047275390625, "Mean Q2": 203.0045029296875, "critic_loss": 10.993182888031006, "batch_reward": 1.1764495124816894, "actor_loss": -204.1460920764554, "actor_target_entropy": -1.0, "actor_entropy": 0.786416519072748, "alpha_loss": 0.004392603344674553, "alpha_value": 0.25373880104942836, "duration": 169.53449392318726, "step": 45250}
{"episode_reward": 80.32510605020501, "episode": 363.0, "Q1 loss": 5.617724718093872, "Q2 loss": 5.613585628509521, "Mean Target Q": 203.18972192382813, "Mean Q1": 203.19277990722657, "Mean Q2": 203.19333081054688, "critic_loss": 11.231310359954835, "batch_reward": 1.1819785537719727, "actor_loss": -204.44684419177827, "actor_target_entropy": -1.0, "actor_entropy": 0.7725107840129307, "alpha_loss": -0.006611825683937659, "alpha_value": 0.2538021998861549, "duration": 166.08137321472168, "step": 45375}
{"episode_reward": 250.05061758754613, "episode": 364.0, "Q1 loss": 6.02098034286499, "Q2 loss": 6.072506103515625, "Mean Target Q": 203.36397827148437, "Mean Q1": 203.3516241455078, "Mean Q2": 203.35097790527342, "critic_loss": 12.093486419677735, "batch_reward": 1.1841305074691773, "actor_loss": -204.60530951715285, "actor_target_entropy": -1.0, "actor_entropy": 0.7964091589373927, "alpha_loss": -0.001649178808645135, "alpha_value": 0.2539017205531161, "duration": 188.56783318519592, "step": 45500}
{"episode_reward": 150.99894298313305, "episode": 365.0, "Q1 loss": 6.067497623443604, "Q2 loss": 6.094831378936767, "Mean Target Q": 203.54351940917968, "Mean Q1": 203.5549697265625, "Mean Q2": 203.55548852539061, "critic_loss": 12.162329025268555, "batch_reward": 1.1812258100509643, "actor_loss": -204.77707199823288, "actor_target_entropy": -1.0, "actor_entropy": 0.8024147096134367, "alpha_loss": -0.0030678320742611375, "alpha_value": 0.2541140880369809, "duration": 182.48354840278625, "step": 45625}
{"episode_reward": 130.88581295908028, "episode": 366.0, "Q1 loss": 6.5151119213104245, "Q2 loss": 6.5189173164367675, "Mean Target Q": 203.82249475097657, "Mean Q1": 203.81354943847657, "Mean Q2": 203.8129403076172, "critic_loss": 13.034029281616212, "batch_reward": 1.186943998336792, "actor_loss": -204.96168714954007, "actor_target_entropy": -1.0, "actor_entropy": 0.7972088177357951, "alpha_loss": -0.00906617533145172, "alpha_value": 0.25467552124385434, "duration": 168.12005996704102, "step": 45750}
{"episode_reward": 180.6018587581947, "episode": 367.0, "Q1 loss": 6.065645212173462, "Q2 loss": 6.055281597137451, "Mean Target Q": 203.97740625, "Mean Q1": 203.97334826660156, "Mean Q2": 203.97429833984376, "critic_loss": 12.120926803588867, "batch_reward": 1.1877804336547853, "actor_loss": -205.1503421843998, "actor_target_entropy": -1.0, "actor_entropy": 0.7824221026329767, "alpha_loss": 0.005279284694956409, "alpha_value": 0.25474421166086475, "duration": 168.5710277557373, "step": 45875}
{"episode_reward": 196.8233111354152, "episode": 368.0, "Q1 loss": 6.224677581787109, "Q2 loss": 6.2167621612548825, "Mean Target Q": 204.15922534179688, "Mean Q1": 204.15761572265626, "Mean Q2": 204.1568172607422, "critic_loss": 12.441439750671387, "batch_reward": 1.1816342945098877, "actor_loss": -205.39617353870022, "actor_target_entropy": -1.0, "actor_entropy": 0.8123881711113837, "alpha_loss": -0.0006260502399996885, "alpha_value": 0.25456249192380315, "duration": 178.5898380279541, "step": 46000}
{"episode_reward": 118.25062018585947, "episode": 369.0, "Q1 loss": 6.235934913635254, "Q2 loss": 6.236053293228149, "Mean Target Q": 204.42077307128906, "Mean Q1": 204.42042272949217, "Mean Q2": 204.41968139648438, "critic_loss": 12.47198821258545, "batch_reward": 1.1894543418884278, "actor_loss": -205.622803218781, "actor_target_entropy": -1.0, "actor_entropy": 0.7706443695794969, "alpha_loss": -0.003227867888257144, "alpha_value": 0.2547674139634155, "duration": 167.64527225494385, "step": 46125}
{"episode_reward": 179.072234302055, "episode": 370.0, "Q1 loss": 6.220091365814209, "Q2 loss": 6.210672122955322, "Mean Target Q": 204.54710815429686, "Mean Q1": 204.54978125, "Mean Q2": 204.55005261230468, "critic_loss": 12.43076346206665, "batch_reward": 1.1840423431396485, "actor_loss": -205.77831489809097, "actor_target_entropy": -1.0, "actor_entropy": 0.7954086901680115, "alpha_loss": -0.003073071369961385, "alpha_value": 0.2551574879093424, "duration": 147.93861556053162, "step": 46250}
{"episode_reward": 172.8221646028286, "episode": 371.0, "Q1 loss": 6.691949844360352, "Q2 loss": 6.6995265045166015, "Mean Target Q": 204.7967686767578, "Mean Q1": 204.7977614746094, "Mean Q2": 204.79838659667968, "critic_loss": 13.39147637939453, "batch_reward": 1.1773712882995606, "actor_loss": -206.0630095951141, "actor_target_entropy": -1.0, "actor_entropy": 0.7908956522033328, "alpha_loss": -0.0016688663689863113, "alpha_value": 0.25521361344084276, "duration": 164.20812821388245, "step": 46375}
{"episode_reward": 30.388415421070164, "episode": 372.0, "Q1 loss": 6.512065013885498, "Q2 loss": 6.562718318939209, "Mean Target Q": 204.9895291748047, "Mean Q1": 204.98539978027344, "Mean Q2": 204.98558874511718, "critic_loss": 13.074783332824707, "batch_reward": 1.174230429649353, "actor_loss": -206.33538252307522, "actor_target_entropy": -1.0, "actor_entropy": 0.793405907769357, "alpha_loss": -0.0037634139167024724, "alpha_value": 0.2553537994886884, "duration": 168.5206594467163, "step": 46500}
{"episode_reward": 22.298074145651686, "episode": 373.0, "Q1 loss": 6.6549837837219235, "Q2 loss": 6.639911697387696, "Mean Target Q": 205.20070678710937, "Mean Q1": 205.19925415039063, "Mean Q2": 205.19849548339843, "critic_loss": 13.294895477294922, "batch_reward": 1.1784091215133667, "actor_loss": -206.49663289388022, "actor_target_entropy": -1.0, "actor_entropy": 0.8001948727501763, "alpha_loss": -0.00832169677411753, "alpha_value": 0.25573700241714303, "duration": 163.55588817596436, "step": 46625}
{"episode_reward": 121.13965512637841, "episode": 374.0, "Q1 loss": 6.279707052230835, "Q2 loss": 6.273839866638183, "Mean Target Q": 205.30062231445314, "Mean Q1": 205.3040245361328, "Mean Q2": 205.3042021484375, "critic_loss": 12.55354694366455, "batch_reward": 1.1671521253585815, "actor_loss": -206.49451569587953, "actor_target_entropy": -1.0, "actor_entropy": 0.7658396901622895, "alpha_loss": 0.007013869362943355, "alpha_value": 0.25595615097848934, "duration": 149.75555729866028, "step": 46750}
{"episode_reward": 169.49904532009268, "episode": 375.0, "Q1 loss": 6.008057098388672, "Q2 loss": 5.973068859100342, "Mean Target Q": 205.45397119140625, "Mean Q1": 205.44981005859376, "Mean Q2": 205.45016186523438, "critic_loss": 11.981125915527343, "batch_reward": 1.172147777557373, "actor_loss": -206.6281500922309, "actor_target_entropy": -1.0, "actor_entropy": 0.7549305264911954, "alpha_loss": 0.0028225750115419192, "alpha_value": 0.2555745504458531, "duration": 145.69792556762695, "step": 46875}
{"episode_reward": 54.66145216694229, "episode": 376.0, "Q1 loss": 5.849465539932251, "Q2 loss": 5.842816440582276, "Mean Target Q": 205.64096813964844, "Mean Q1": 205.63524987792968, "Mean Q2": 205.6350751953125, "critic_loss": 11.692281967163085, "batch_reward": 1.173500521659851, "actor_loss": -206.7585193264869, "actor_target_entropy": -1.0, "actor_entropy": 0.7747087074864295, "alpha_loss": 0.015856784809711238, "alpha_value": 0.25483789317601824, "duration": 164.54141783714294, "step": 47000}
{"episode_reward": 145.03914516935413, "episode": 377.0, "Q1 loss": 5.727104898452759, "Q2 loss": 5.7515192832946775, "Mean Target Q": 205.7102772216797, "Mean Q1": 205.71164013671876, "Mean Q2": 205.711169921875, "critic_loss": 11.478624217987061, "batch_reward": 1.171555881500244, "actor_loss": -206.84407673184833, "actor_target_entropy": -1.0, "actor_entropy": 0.7806683665230161, "alpha_loss": 0.003172952260467268, "alpha_value": 0.25411167383778005, "duration": 150.132000207901, "step": 47125}
{"episode_reward": 72.5838619962935, "episode": 378.0, "Q1 loss": 5.646121416091919, "Q2 loss": 5.66388477897644, "Mean Target Q": 205.92821862792968, "Mean Q1": 205.93014965820313, "Mean Q2": 205.93061462402343, "critic_loss": 11.310006233215333, "batch_reward": 1.172699860572815, "actor_loss": -207.04777108469318, "actor_target_entropy": -1.0, "actor_entropy": 0.7795141695007202, "alpha_loss": 0.0038503906727137584, "alpha_value": 0.25387790505085317, "duration": 165.15466356277466, "step": 47250}
{"episode_reward": 68.58126465760499, "episode": 379.0, "Q1 loss": 5.572867654800415, "Q2 loss": 5.579514636993408, "Mean Target Q": 206.03877307128906, "Mean Q1": 206.03205798339843, "Mean Q2": 206.0318846435547, "critic_loss": 11.152382308959961, "batch_reward": 1.1661359558105469, "actor_loss": -207.16185312422496, "actor_target_entropy": -1.0, "actor_entropy": 0.7761552371676006, "alpha_loss": 0.001876161348754688, "alpha_value": 0.2538417195556163, "duration": 173.43428921699524, "step": 47375}
{"episode_reward": 210.28958218605615, "episode": 380.0, "Q1 loss": 5.3842637252807615, "Q2 loss": 5.374090505599976, "Mean Target Q": 206.20969067382813, "Mean Q1": 206.2106375732422, "Mean Q2": 206.21132836914063, "critic_loss": 10.75835422515869, "batch_reward": 1.1726905269622803, "actor_loss": -207.38204980665637, "actor_target_entropy": -1.0, "actor_entropy": 0.7932046872954215, "alpha_loss": 0.014999397872616687, "alpha_value": 0.2531944649576347, "duration": 170.66308307647705, "step": 47500}
{"episode_reward": 161.96571776727015, "episode": 381.0, "Q1 loss": 5.209041656494141, "Q2 loss": 5.235140161514282, "Mean Target Q": 206.30187634277343, "Mean Q1": 206.30138940429688, "Mean Q2": 206.30042431640624, "critic_loss": 10.44418180847168, "batch_reward": 1.1617622566223145, "actor_loss": -207.42446802532862, "actor_target_entropy": -1.0, "actor_entropy": 0.7758280615957956, "alpha_loss": 0.004285810737028008, "alpha_value": 0.25247136259213604, "duration": 168.48114275932312, "step": 47625}
{"episode_reward": 140.06553354068615, "episode": 382.0, "Q1 loss": 5.163202571868896, "Q2 loss": 5.164899309158325, "Mean Target Q": 206.54021850585937, "Mean Q1": 206.53664501953125, "Mean Q2": 206.5363399658203, "critic_loss": 10.32810188293457, "batch_reward": 1.173159740447998, "actor_loss": -207.74751429403983, "actor_target_entropy": -1.0, "actor_entropy": 0.7621247258878523, "alpha_loss": 0.007501162832692986, "alpha_value": 0.2521172537143599, "duration": 180.923969745636, "step": 47750}
{"episode_reward": 4.306941893885287, "episode": 383.0, "Q1 loss": 5.47363881111145, "Q2 loss": 5.491114870071411, "Mean Target Q": 206.75133447265625, "Mean Q1": 206.75292810058593, "Mean Q2": 206.75261279296876, "critic_loss": 10.964753601074218, "batch_reward": 1.17705574798584, "actor_loss": -207.92195420038132, "actor_target_entropy": -1.0, "actor_entropy": 0.7815869535718646, "alpha_loss": 0.0008470727064247642, "alpha_value": 0.25169252429002076, "duration": 174.174222946167, "step": 47875}
{"episode_reward": 61.70506307510079, "episode": 384.0, "Q1 loss": 5.7392238426208495, "Q2 loss": 5.756827640533447, "Mean Target Q": 206.8284034423828, "Mean Q1": 206.82764282226563, "Mean Q2": 206.82907678222657, "critic_loss": 11.496051467895509, "batch_reward": 1.1644834547042846, "actor_loss": -208.00485352546937, "actor_target_entropy": -1.0, "actor_entropy": 0.7913437899081938, "alpha_loss": -0.006526266705364951, "alpha_value": 0.2520062643407066, "duration": 172.34104824066162, "step": 48000}
{"episode_reward": 234.56969907594453, "episode": 385.0, "Q1 loss": 5.216129039764405, "Q2 loss": 5.190194967269897, "Mean Target Q": 206.9624775390625, "Mean Q1": 206.9572198486328, "Mean Q2": 206.9576171875, "critic_loss": 10.406324001312257, "batch_reward": 1.171435477256775, "actor_loss": -208.14525882781498, "actor_target_entropy": -1.0, "actor_entropy": 0.7833247865949359, "alpha_loss": 0.007800517526144783, "alpha_value": 0.2517823704210871, "duration": 173.28620719909668, "step": 48125}
{"episode_reward": 47.34536578624076, "episode": 386.0, "Q1 loss": 5.833065181732178, "Q2 loss": 5.898748344421387, "Mean Target Q": 207.16920959472657, "Mean Q1": 207.16617395019532, "Mean Q2": 207.16601733398437, "critic_loss": 11.731813514709472, "batch_reward": 1.1654450550079345, "actor_loss": -208.35595358571697, "actor_target_entropy": -1.0, "actor_entropy": 0.7864573136452706, "alpha_loss": 0.006683118994377794, "alpha_value": 0.25137987532168876, "duration": 170.45434045791626, "step": 48250}
{"episode_reward": 51.75009791569432, "episode": 387.0, "Q1 loss": 5.622387065887451, "Q2 loss": 5.624456602096558, "Mean Target Q": 207.332537109375, "Mean Q1": 207.33544592285156, "Mean Q2": 207.33425732421875, "critic_loss": 11.246843688964844, "batch_reward": 1.1696023454666138, "actor_loss": -208.54175216432603, "actor_target_entropy": -1.0, "actor_entropy": 0.7739640691923717, "alpha_loss": 0.002633665943340886, "alpha_value": 0.2510800676507893, "duration": 173.16547894477844, "step": 48375}
{"episode_reward": 145.7406133154956, "episode": 388.0, "Q1 loss": 5.3412973556518555, "Q2 loss": 5.340187488555908, "Mean Target Q": 207.3238184814453, "Mean Q1": 207.3216895751953, "Mean Q2": 207.32193725585938, "critic_loss": 10.681484832763672, "batch_reward": 1.1636778745651246, "actor_loss": -208.49495672410535, "actor_target_entropy": -1.0, "actor_entropy": 0.7747678295258553, "alpha_loss": -0.0021123950587465397, "alpha_value": 0.2510642966199531, "duration": 183.48954463005066, "step": 48500}
{"episode_reward": 178.019172432853, "episode": 389.0, "Q1 loss": 5.600292942047119, "Q2 loss": 5.59587865447998, "Mean Target Q": 207.56141540527344, "Mean Q1": 207.56188793945313, "Mean Q2": 207.56203186035157, "critic_loss": 11.196171592712401, "batch_reward": 1.1606043167114257, "actor_loss": -208.74019513811385, "actor_target_entropy": -1.0, "actor_entropy": 0.7777349693434579, "alpha_loss": -0.000515656608585564, "alpha_value": 0.2513659450180218, "duration": 182.88847374916077, "step": 48625}
{"episode_reward": 163.94224569587013, "episode": 390.0, "Q1 loss": 5.712859611511231, "Q2 loss": 5.724497110366821, "Mean Target Q": 207.79762268066406, "Mean Q1": 207.79627380371093, "Mean Q2": 207.79597814941405, "critic_loss": 11.437356693267823, "batch_reward": 1.1715031929016113, "actor_loss": -208.97596445391255, "actor_target_entropy": -1.0, "actor_entropy": 0.7751766866253268, "alpha_loss": 0.003117085980897349, "alpha_value": 0.2511759855046754, "duration": 181.0375988483429, "step": 48750}
{"episode_reward": 243.07530855552903, "episode": 391.0, "Q1 loss": 5.8420283203125, "Q2 loss": 5.834677909851075, "Mean Target Q": 207.9918466796875, "Mean Q1": 207.98781237792969, "Mean Q2": 207.9889385986328, "critic_loss": 11.676706184387207, "batch_reward": 1.1723031568527222, "actor_loss": -209.14795188298302, "actor_target_entropy": -1.0, "actor_entropy": 0.7709214507587372, "alpha_loss": 0.004053487427650936, "alpha_value": 0.2508567556990985, "duration": 181.13747596740723, "step": 48875}
{"episode_reward": 200.23449578811758, "episode": 392.0, "Q1 loss": 5.820063663482666, "Q2 loss": 5.856540119171142, "Mean Target Q": 208.1283525390625, "Mean Q1": 208.1306572265625, "Mean Q2": 208.1303096923828, "critic_loss": 11.676603767395019, "batch_reward": 1.177896324157715, "actor_loss": -209.34723687941027, "actor_target_entropy": -1.0, "actor_entropy": 0.7679884299155204, "alpha_loss": -0.0011303170148523585, "alpha_value": 0.25088753635650163, "duration": 178.94415068626404, "step": 49000}
{"episode_reward": 4.33846689163382, "episode": 393.0, "Q1 loss": 5.6662752838134764, "Q2 loss": 5.668185768127441, "Mean Target Q": 208.20524072265624, "Mean Q1": 208.2022421875, "Mean Q2": 208.20106018066406, "critic_loss": 11.33446104812622, "batch_reward": 1.16525581741333, "actor_loss": -209.37024821932354, "actor_target_entropy": -1.0, "actor_entropy": 0.7882127165794373, "alpha_loss": 0.005515495570199121, "alpha_value": 0.25059281575636283, "duration": 162.13629531860352, "step": 49125}
{"episode_reward": 142.4741990122099, "episode": 394.0, "Q1 loss": 5.947988487243652, "Q2 loss": 5.950509889602661, "Mean Target Q": 208.38330859375, "Mean Q1": 208.38306384277342, "Mean Q2": 208.3838233642578, "critic_loss": 11.898498397827149, "batch_reward": 1.175113163948059, "actor_loss": -209.59981192311932, "actor_target_entropy": -1.0, "actor_entropy": 0.7732093997540013, "alpha_loss": 0.0015708149162932269, "alpha_value": 0.25021231934705157, "duration": 169.5281937122345, "step": 49250}
{"episode_reward": 164.7201069900004, "episode": 395.0, "Q1 loss": 5.937813957214355, "Q2 loss": 5.930986680984497, "Mean Target Q": 208.60012060546876, "Mean Q1": 208.60278942871093, "Mean Q2": 208.60315466308595, "critic_loss": 11.868800666809083, "batch_reward": 1.1690091009140016, "actor_loss": -209.76791672479538, "actor_target_entropy": -1.0, "actor_entropy": 0.7739191897331722, "alpha_loss": 0.0004900353313941094, "alpha_value": 0.25014966789182425, "duration": 170.91715788841248, "step": 49375}
{"episode_reward": 121.39586813717884, "episode": 396.0, "Q1 loss": 6.324544012069702, "Q2 loss": 6.364934368133545, "Mean Target Q": 208.86787390136718, "Mean Q1": 208.8635280761719, "Mean Q2": 208.8627609863281, "critic_loss": 12.689478401184083, "batch_reward": 1.1718162841796875, "actor_loss": -210.06124213434035, "actor_target_entropy": -1.0, "actor_entropy": 0.7864841251604019, "alpha_loss": -0.003153473713375147, "alpha_value": 0.25031036767239034, "duration": 147.10934734344482, "step": 49500}
{"episode_reward": 11.770561078118151, "episode": 397.0, "Q1 loss": 6.198355377197266, "Q2 loss": 6.180338054656983, "Mean Target Q": 209.0257039794922, "Mean Q1": 209.02268566894531, "Mean Q2": 209.02304833984374, "critic_loss": 12.378693458557128, "batch_reward": 1.1688995122909547, "actor_loss": -210.26932731507316, "actor_target_entropy": -1.0, "actor_entropy": 0.7612413650467282, "alpha_loss": 0.0032101417559065987, "alpha_value": 0.2503742548266305, "duration": 149.34846234321594, "step": 49625}
{"episode_reward": 173.31432337501226, "episode": 398.0, "Q1 loss": 5.91923078918457, "Q2 loss": 5.932137176513672, "Mean Target Q": 209.1213991699219, "Mean Q1": 209.12152893066406, "Mean Q2": 209.12100439453124, "critic_loss": 11.851367973327637, "batch_reward": 1.1658836975097657, "actor_loss": -210.3499568816154, "actor_target_entropy": -1.0, "actor_entropy": 0.7685078949697556, "alpha_loss": 0.0026370100902333377, "alpha_value": 0.2501455176672058, "duration": 168.46762037277222, "step": 49750}
{"episode_reward": 179.53350582399545, "episode": 399.0, "Q1 loss": 6.13153829574585, "Q2 loss": 6.1518565368652345, "Mean Target Q": 209.38474267578124, "Mean Q1": 209.3822606201172, "Mean Q2": 209.38284716796875, "critic_loss": 12.28339486694336, "batch_reward": 1.1628779754638672, "actor_loss": -210.64769587441097, "actor_target_entropy": -1.0, "actor_entropy": 0.7708416439238048, "alpha_loss": 0.0022568533581400676, "alpha_value": 0.24985273972344485, "duration": 152.44321870803833, "step": 49875}
{"episode_reward": 34.8098630676882, "episode": 400.0, "Q1 loss": 6.237964504241943, "Q2 loss": 6.247112518310547, "Mean Target Q": 209.49010205078125, "Mean Q1": 209.4901806640625, "Mean Q2": 209.49008959960938, "critic_loss": 12.48507703781128, "batch_reward": 1.1617466192245482, "actor_loss": -210.7347215221774, "actor_target_entropy": -1.0, "actor_entropy": 0.798366759092577, "alpha_loss": -0.001614322138559674, "alpha_value": 0.2499029470503627, "step": 50000}
{"duration": 160.6887526512146, "step": 50000}
{"episode_reward": 176.95639306729515, "episode": 401.0, "Q1 loss": 6.373097633361817, "Q2 loss": 6.391328147888183, "Mean Target Q": 209.72022961425782, "Mean Q1": 209.71516284179688, "Mean Q2": 209.71533276367188, "critic_loss": 12.764425804138183, "batch_reward": 1.1696425800323487, "actor_loss": -210.98945012168278, "actor_target_entropy": -1.0, "actor_entropy": 0.7891305041691613, "alpha_loss": -0.0007656643921065898, "alpha_value": 0.25007143787029396, "duration": 186.31569385528564, "step": 50125}
{"episode_reward": 177.23932463385032, "episode": 402.0, "Q1 loss": 6.1842489967346195, "Q2 loss": 6.197258623123169, "Mean Target Q": 209.76159741210938, "Mean Q1": 209.76359375, "Mean Q2": 209.76402026367188, "critic_loss": 12.381507598876953, "batch_reward": 1.1608670473098754, "actor_loss": -211.00877281927293, "actor_target_entropy": -1.0, "actor_entropy": 0.7691728780346532, "alpha_loss": -0.00506850378587842, "alpha_value": 0.2502701073885651, "duration": 168.82582783699036, "step": 50250}
{"episode_reward": 96.89546128998548, "episode": 403.0, "Q1 loss": 6.172393672943115, "Q2 loss": 6.166703762054444, "Mean Target Q": 210.00196411132814, "Mean Q1": 210.00251611328125, "Mean Q2": 210.00152722167968, "critic_loss": 12.339097419738769, "batch_reward": 1.1683025493621826, "actor_loss": -211.14727153475323, "actor_target_entropy": -1.0, "actor_entropy": 0.7756081005883595, "alpha_loss": 0.003533898764068172, "alpha_value": 0.2503604311298432, "duration": 187.07542753219604, "step": 50375}
{"episode_reward": 82.97794566513042, "episode": 404.0, "Q1 loss": 6.181725597381591, "Q2 loss": 6.214687740325927, "Mean Target Q": 209.98730151367187, "Mean Q1": 209.98951586914063, "Mean Q2": 209.989599609375, "critic_loss": 12.396413345336914, "batch_reward": 1.1555105237960814, "actor_loss": -211.13279305734943, "actor_target_entropy": -1.0, "actor_entropy": 0.8013099710787496, "alpha_loss": 0.0036902702488606017, "alpha_value": 0.25000702412848297, "duration": 142.3648099899292, "step": 50500}
{"episode_reward": 44.325847271231716, "episode": 405.0, "Q1 loss": 6.0603590602874755, "Q2 loss": 6.050147920608521, "Mean Target Q": 210.15398266601562, "Mean Q1": 210.14630590820312, "Mean Q2": 210.14569262695312, "critic_loss": 12.110506973266602, "batch_reward": 1.1695388975143433, "actor_loss": -211.29810345362102, "actor_target_entropy": -1.0, "actor_entropy": 0.800079535870325, "alpha_loss": -0.0008060854216594072, "alpha_value": 0.25000124266996415, "duration": 196.7882571220398, "step": 50625}
{"episode_reward": 84.22581465081403, "episode": 406.0, "Q1 loss": 5.79996706199646, "Q2 loss": 5.811344476699829, "Mean Target Q": 210.26641088867189, "Mean Q1": 210.2674892578125, "Mean Q2": 210.26789965820313, "critic_loss": 11.611311561584472, "batch_reward": 1.1537551012039184, "actor_loss": -211.51499963575793, "actor_target_entropy": -1.0, "actor_entropy": 0.7632232250705842, "alpha_loss": -0.0011677865949158946, "alpha_value": 0.24988632124051785, "duration": 166.20449256896973, "step": 50750}
{"episode_reward": 84.31111214689835, "episode": 407.0, "Q1 loss": 5.831666561126709, "Q2 loss": 5.8262007064819334, "Mean Target Q": 210.49070666503906, "Mean Q1": 210.48706225585937, "Mean Q2": 210.4872763671875, "critic_loss": 11.657867240905762, "batch_reward": 1.1569017763137817, "actor_loss": -211.73165748232887, "actor_target_entropy": -1.0, "actor_entropy": 0.7734350145809235, "alpha_loss": 0.00558885876163249, "alpha_value": 0.24980126496416774, "duration": 154.9254162311554, "step": 50875}
{"episode_reward": 49.772682792902984, "episode": 408.0, "Q1 loss": 5.888648092269897, "Q2 loss": 5.915992391586304, "Mean Target Q": 210.6155661621094, "Mean Q1": 210.61505236816407, "Mean Q2": 210.6151649169922, "critic_loss": 11.80464044189453, "batch_reward": 1.1496935138702393, "actor_loss": -211.74920211299772, "actor_target_entropy": -1.0, "actor_entropy": 0.7725366709693786, "alpha_loss": 0.00043279463387725333, "alpha_value": 0.24956767988037992, "duration": 190.10630059242249, "step": 51000}
{"episode_reward": 60.18877470968819, "episode": 409.0, "Q1 loss": 5.682481870651245, "Q2 loss": 5.694714050292969, "Mean Target Q": 210.6447999267578, "Mean Q1": 210.64280346679686, "Mean Q2": 210.64237060546876, "critic_loss": 11.377195922851563, "batch_reward": 1.153414523601532, "actor_loss": -211.82968042767237, "actor_target_entropy": -1.0, "actor_entropy": 0.7762592595721048, "alpha_loss": 0.004833534544718171, "alpha_value": 0.24958529599025664, "duration": 178.9349880218506, "step": 51125}
{"episode_reward": 173.45586271655012, "episode": 410.0, "Q1 loss": 5.743012243270874, "Q2 loss": 5.728570119857788, "Mean Target Q": 210.8121124267578, "Mean Q1": 210.8111884765625, "Mean Q2": 210.8115518798828, "critic_loss": 11.471582431793212, "batch_reward": 1.1560069580078125, "actor_loss": -212.0092008036952, "actor_target_entropy": -1.0, "actor_entropy": 0.8098925006005072, "alpha_loss": -0.0028007893913215205, "alpha_value": 0.24939709288607564, "duration": 141.1292359828949, "step": 51250}
{"episode_reward": 60.03182818703944, "episode": 411.0, "Q1 loss": 5.664887147903443, "Q2 loss": 5.673576862335205, "Mean Target Q": 211.0052294921875, "Mean Q1": 211.00495056152343, "Mean Q2": 211.00523156738282, "critic_loss": 11.338464042663574, "batch_reward": 1.154404541015625, "actor_loss": -212.14401002914187, "actor_target_entropy": -1.0, "actor_entropy": 0.7677904878343854, "alpha_loss": 0.010260906613742312, "alpha_value": 0.24901602507425064, "duration": 200.71655011177063, "step": 51375}
{"episode_reward": 121.24917438625333, "episode": 412.0, "Q1 loss": 5.903052591323853, "Q2 loss": 5.9316685771942135, "Mean Target Q": 210.970619140625, "Mean Q1": 210.96731225585938, "Mean Q2": 210.96722912597656, "critic_loss": 11.834721214294433, "batch_reward": 1.144265133857727, "actor_loss": -212.149537855579, "actor_target_entropy": -1.0, "actor_entropy": 0.7523851356198711, "alpha_loss": 0.009024628973190462, "alpha_value": 0.24852056573903755, "duration": 164.94516563415527, "step": 51500}
{"episode_reward": 61.024874113530956, "episode": 413.0, "Q1 loss": 5.768329633712769, "Q2 loss": 5.7585835418701175, "Mean Target Q": 211.12222265625, "Mean Q1": 211.12191271972657, "Mean Q2": 211.12161096191406, "critic_loss": 11.526913177490234, "batch_reward": 1.15924174118042, "actor_loss": -212.33484685988654, "actor_target_entropy": -1.0, "actor_entropy": 0.770101199074397, "alpha_loss": 0.0021437781914654705, "alpha_value": 0.24802861664829637, "duration": 182.03569841384888, "step": 51625}
{"episode_reward": 53.44098222272216, "episode": 414.0, "Q1 loss": 5.5817595462799074, "Q2 loss": 5.585278438568115, "Mean Target Q": 211.17314807128906, "Mean Q1": 211.1724161376953, "Mean Q2": 211.1722947998047, "critic_loss": 11.167037982940673, "batch_reward": 1.143085940361023, "actor_loss": -212.28822203605407, "actor_target_entropy": -1.0, "actor_entropy": 0.7625282128011027, "alpha_loss": -0.00548174727197376, "alpha_value": 0.24811624266647314, "duration": 135.03506112098694, "step": 51750}
{"episode_reward": 26.14527632384842, "episode": 415.0, "Q1 loss": 5.443964239120484, "Q2 loss": 5.440858818054199, "Mean Target Q": 211.39726928710937, "Mean Q1": 211.39426196289062, "Mean Q2": 211.39489208984375, "critic_loss": 10.884823089599609, "batch_reward": 1.1496505460739135, "actor_loss": -212.5326177203466, "actor_target_entropy": -1.0, "actor_entropy": 0.7664196557468839, "alpha_loss": 0.00840411513733367, "alpha_value": 0.24798774600491433, "duration": 134.13415718078613, "step": 51875}
{"episode_reward": 66.04471639231608, "episode": 416.0, "Q1 loss": 5.8709871788024905, "Q2 loss": 5.859068040847778, "Mean Target Q": 211.46344104003907, "Mean Q1": 211.46141760253906, "Mean Q2": 211.4611682128906, "critic_loss": 11.730055267333984, "batch_reward": 1.1439358730316163, "actor_loss": -212.7720199092742, "actor_target_entropy": -1.0, "actor_entropy": 0.7861774842585286, "alpha_loss": 0.0031662839577503263, "alpha_value": 0.24765781364338466, "duration": 149.6039845943451, "step": 52000}
{"episode_reward": 137.80746774890656, "episode": 417.0, "Q1 loss": 5.900642814636231, "Q2 loss": 5.913521522521973, "Mean Target Q": 211.69700134277343, "Mean Q1": 211.70181384277345, "Mean Q2": 211.70148645019532, "critic_loss": 11.814164352416991, "batch_reward": 1.146302466392517, "actor_loss": -212.89893377394904, "actor_target_entropy": -1.0, "actor_entropy": 0.7687943379084269, "alpha_loss": 0.004712593205834901, "alpha_value": 0.2473740043829462, "duration": 146.94215416908264, "step": 52125}
{"episode_reward": 145.3954022020876, "episode": 418.0, "Q1 loss": 5.82422057723999, "Q2 loss": 5.811891540527344, "Mean Target Q": 211.76831286621095, "Mean Q1": 211.76437951660157, "Mean Q2": 211.76407263183594, "critic_loss": 11.636112144470214, "batch_reward": 1.140837519645691, "actor_loss": -213.00545526319934, "actor_target_entropy": -1.0, "actor_entropy": 0.7520882477683406, "alpha_loss": 0.003286387741325363, "alpha_value": 0.24701369434774775, "duration": 127.9655556678772, "step": 52250}
{"episode_reward": 132.4720410870773, "episode": 419.0, "Q1 loss": 6.086060031890869, "Q2 loss": 6.117141326904297, "Mean Target Q": 211.87598120117187, "Mean Q1": 211.8769910888672, "Mean Q2": 211.87740649414062, "critic_loss": 12.203201370239258, "batch_reward": 1.1430003623962401, "actor_loss": -213.1619829450335, "actor_target_entropy": -1.0, "actor_entropy": 0.7682498844843062, "alpha_loss": -0.005333464008770765, "alpha_value": 0.24713783397252667, "duration": 113.56790065765381, "step": 52375}
{"episode_reward": 117.04503898328142, "episode": 420.0, "Q1 loss": 6.1663634338378905, "Q2 loss": 6.1591383094787595, "Mean Target Q": 212.09493969726563, "Mean Q1": 212.09434875488282, "Mean Q2": 212.09421435546875, "critic_loss": 12.32550178527832, "batch_reward": 1.1513250217437745, "actor_loss": -213.34879549088018, "actor_target_entropy": -1.0, "actor_entropy": 0.7605270349210308, "alpha_loss": -0.0014385226663322218, "alpha_value": 0.24751550963712904, "duration": 82.22443079948425, "step": 52500}
{"episode_reward": 212.798433756114, "episode": 421.0, "Q1 loss": 6.187156913757324, "Q2 loss": 6.199719745635987, "Mean Target Q": 212.20883154296874, "Mean Q1": 212.20810876464844, "Mean Q2": 212.20798571777343, "critic_loss": 12.386876636505127, "batch_reward": 1.1517142372131348, "actor_loss": -213.43639264787947, "actor_target_entropy": -1.0, "actor_entropy": 0.7886920306417677, "alpha_loss": 0.0036403935528286392, "alpha_value": 0.24737472037349434, "duration": 87.70944380760193, "step": 52625}
{"episode_reward": 122.72389102756522, "episode": 422.0, "Q1 loss": 6.211168655395507, "Q2 loss": 6.20821993637085, "Mean Target Q": 212.15797802734374, "Mean Q1": 212.15463330078126, "Mean Q2": 212.15474951171876, "critic_loss": 12.419388610839844, "batch_reward": 1.128994896888733, "actor_loss": -213.30331174788935, "actor_target_entropy": -1.0, "actor_entropy": 0.7707766015683452, "alpha_loss": 0.0021591247547598134, "alpha_value": 0.24708963426726757, "duration": 132.17933011054993, "step": 52750}
{"episode_reward": 125.38508646606304, "episode": 423.0, "Q1 loss": 6.078210605621338, "Q2 loss": 6.1240914421081545, "Mean Target Q": 212.36602478027345, "Mean Q1": 212.35898852539063, "Mean Q2": 212.35930505371093, "critic_loss": 12.202302024841309, "batch_reward": 1.1397329664230347, "actor_loss": -213.5577886672247, "actor_target_entropy": -1.0, "actor_entropy": 0.7572628004210336, "alpha_loss": 0.0011146018458973793, "alpha_value": 0.2469333536200222, "duration": 143.92090964317322, "step": 52875}
{"episode_reward": 125.19455949436454, "episode": 424.0, "Q1 loss": 5.8579485206604005, "Q2 loss": 5.864311445236206, "Mean Target Q": 212.47093200683594, "Mean Q1": 212.47580114746094, "Mean Q2": 212.47551892089842, "critic_loss": 11.72225994873047, "batch_reward": 1.1369062480926513, "actor_loss": -213.6016326412078, "actor_target_entropy": -1.0, "actor_entropy": 0.7516940188023352, "alpha_loss": 0.0023524967724487425, "alpha_value": 0.2469601262486871, "duration": 138.33903694152832, "step": 53000}
{"episode_reward": 190.90007659879504, "episode": 425.0, "Q1 loss": 5.983509460449219, "Q2 loss": 5.995720397949219, "Mean Target Q": 212.5369775390625, "Mean Q1": 212.53170007324218, "Mean Q2": 212.5313035888672, "critic_loss": 11.979229827880859, "batch_reward": 1.1354384860992432, "actor_loss": -213.7817169673859, "actor_target_entropy": -1.0, "actor_entropy": 0.7654798835042923, "alpha_loss": 0.004105471980033649, "alpha_value": 0.2467036928263197, "duration": 188.04212999343872, "step": 53125}
{"episode_reward": 149.24827622689637, "episode": 426.0, "Q1 loss": 5.618932779312134, "Q2 loss": 5.624951614379883, "Mean Target Q": 212.67403686523437, "Mean Q1": 212.6809030761719, "Mean Q2": 212.68195556640626, "critic_loss": 11.243884441375732, "batch_reward": 1.1465187673568726, "actor_loss": -213.81185937696887, "actor_target_entropy": -1.0, "actor_entropy": 0.7459937084105707, "alpha_loss": 0.004630217508923623, "alpha_value": 0.2464711247512518, "duration": 158.63646173477173, "step": 53250}
{"episode_reward": 107.3533318544371, "episode": 427.0, "Q1 loss": 5.514708768844605, "Q2 loss": 5.537196519851684, "Mean Target Q": 212.71758557128905, "Mean Q1": 212.71521154785157, "Mean Q2": 212.71471997070313, "critic_loss": 11.051905269622802, "batch_reward": 1.1343898153305054, "actor_loss": -213.84915233793714, "actor_target_entropy": -1.0, "actor_entropy": 0.7529331899824596, "alpha_loss": 0.003979499252246959, "alpha_value": 0.24595190686466434, "duration": 128.92229771614075, "step": 53375}
{"episode_reward": 128.09103256235448, "episode": 428.0, "Q1 loss": 5.406468276977539, "Q2 loss": 5.428140188217163, "Mean Target Q": 212.88018518066406, "Mean Q1": 212.87886560058593, "Mean Q2": 212.87869091796875, "critic_loss": 10.834608459472657, "batch_reward": 1.1418326911926269, "actor_loss": -214.07893470025832, "actor_target_entropy": -1.0, "actor_entropy": 0.7376793046151439, "alpha_loss": 0.001582681210786705, "alpha_value": 0.2457309766011154, "duration": 162.2515094280243, "step": 53500}
{"episode_reward": 121.11393679760677, "episode": 429.0, "Q1 loss": 5.522253866195679, "Q2 loss": 5.498696083068848, "Mean Target Q": 212.9183321533203, "Mean Q1": 212.9174670410156, "Mean Q2": 212.91727233886718, "critic_loss": 11.020949939727783, "batch_reward": 1.1388239116668701, "actor_loss": -214.14790368458583, "actor_target_entropy": -1.0, "actor_entropy": 0.7351669300170172, "alpha_loss": -0.001549272487560908, "alpha_value": 0.24583575996507256, "duration": 177.3902759552002, "step": 53625}
{"episode_reward": 232.36537097654175, "episode": 430.0, "Q1 loss": 5.926643451690674, "Q2 loss": 5.947876306533813, "Mean Target Q": 213.08316674804686, "Mean Q1": 213.0771433105469, "Mean Q2": 213.07696166992187, "critic_loss": 11.874519752502442, "batch_reward": 1.1542004289627075, "actor_loss": -214.28939819335938, "actor_target_entropy": -1.0, "actor_entropy": 0.754014394937023, "alpha_loss": -0.005595892664015053, "alpha_value": 0.24575978115276495, "duration": 146.41651558876038, "step": 53750}
{"episode_reward": 92.58793312840676, "episode": 431.0, "Q1 loss": 5.850432741165161, "Q2 loss": 5.83731629371643, "Mean Target Q": 213.1576025390625, "Mean Q1": 213.15453784179687, "Mean Q2": 213.15564367675782, "critic_loss": 11.687749015808105, "batch_reward": 1.1465609998703004, "actor_loss": -214.38892812577504, "actor_target_entropy": -1.0, "actor_entropy": 0.7622579156406342, "alpha_loss": 0.004529873737030559, "alpha_value": 0.24623179275163212, "duration": 175.42984628677368, "step": 53875}
{"episode_reward": 48.64606082234118, "episode": 432.0, "Q1 loss": 5.8367831420898435, "Q2 loss": 5.880426181793213, "Mean Target Q": 213.24786499023438, "Mean Q1": 213.2486826171875, "Mean Q2": 213.2481524658203, "critic_loss": 11.71720930480957, "batch_reward": 1.1345649261474609, "actor_loss": -214.48221366636216, "actor_target_entropy": -1.0, "actor_entropy": 0.7361433486784658, "alpha_loss": -0.00338495556911033, "alpha_value": 0.2460639210374701, "duration": 183.8372495174408, "step": 54000}
{"episode_reward": 38.7315342524934, "episode": 433.0, "Q1 loss": 5.789865158081055, "Q2 loss": 5.786738670349121, "Mean Target Q": 213.52280773925781, "Mean Q1": 213.5232391357422, "Mean Q2": 213.52323083496094, "critic_loss": 11.57660383605957, "batch_reward": 1.1421847348213197, "actor_loss": -214.69194951133122, "actor_target_entropy": -1.0, "actor_entropy": 0.7602456249887981, "alpha_loss": 0.004777905242961077, "alpha_value": 0.24599977810168158, "duration": 176.59052991867065, "step": 54125}
{"episode_reward": 94.03481843797977, "episode": 434.0, "Q1 loss": 5.801544095993042, "Q2 loss": 5.788639217376709, "Mean Target Q": 213.56154052734374, "Mean Q1": 213.56034155273437, "Mean Q2": 213.55976123046875, "critic_loss": 11.590183288574218, "batch_reward": 1.143228871822357, "actor_loss": -214.84278820407005, "actor_target_entropy": -1.0, "actor_entropy": 0.7374540769284771, "alpha_loss": 0.00400316990881918, "alpha_value": 0.24554420594521706, "duration": 157.2176616191864, "step": 54250}
{"episode_reward": 175.64855375665294, "episode": 435.0, "Q1 loss": 5.968846134185791, "Q2 loss": 5.967038482666015, "Mean Target Q": 213.6147840576172, "Mean Q1": 213.6145762939453, "Mean Q2": 213.61442138671876, "critic_loss": 11.935884613037109, "batch_reward": 1.1426551094055175, "actor_loss": -214.84886968703498, "actor_target_entropy": -1.0, "actor_entropy": 0.7612587932556395, "alpha_loss": -0.0011522870488642227, "alpha_value": 0.24540619303774622, "duration": 177.0465383529663, "step": 54375}
{"episode_reward": 60.24445406144929, "episode": 436.0, "Q1 loss": 6.340647518157959, "Q2 loss": 6.350358348846435, "Mean Target Q": 213.80464685058593, "Mean Q1": 213.80269006347658, "Mean Q2": 213.80271875, "critic_loss": 12.691005859375, "batch_reward": 1.1436050891876222, "actor_loss": -215.03330796764743, "actor_target_entropy": -1.0, "actor_entropy": 0.7468576854275119, "alpha_loss": 0.0004725041686587276, "alpha_value": 0.2456718358063717, "duration": 149.5354540348053, "step": 54500}
{"episode_reward": 109.24143458867785, "episode": 437.0, "Q1 loss": 6.009948369979859, "Q2 loss": 6.0281490688323975, "Mean Target Q": 213.76718872070313, "Mean Q1": 213.76426452636719, "Mean Q2": 213.76332751464844, "critic_loss": 12.03809746170044, "batch_reward": 1.1418958597183229, "actor_loss": -215.020506843688, "actor_target_entropy": -1.0, "actor_entropy": 0.7496002798988706, "alpha_loss": -0.005407318990263674, "alpha_value": 0.24585153055354744, "duration": 192.56578421592712, "step": 54625}
{"episode_reward": 144.18491717738542, "episode": 438.0, "Q1 loss": 6.284414569854737, "Q2 loss": 6.308024173736572, "Mean Target Q": 214.01430151367188, "Mean Q1": 214.01227575683595, "Mean Q2": 214.01283959960938, "critic_loss": 12.592438751220703, "batch_reward": 1.1402064704895019, "actor_loss": -215.2317135718561, "actor_target_entropy": -1.0, "actor_entropy": 0.7380945499866239, "alpha_loss": -0.0040639006990879295, "alpha_value": 0.24622106188729664, "duration": 163.72796082496643, "step": 54750}
{"episode_reward": 93.18667349590223, "episode": 439.0, "Q1 loss": 6.009668136596679, "Q2 loss": 6.002050804138183, "Mean Target Q": 214.1354559326172, "Mean Q1": 214.13520678710938, "Mean Q2": 214.13588171386718, "critic_loss": 12.011718933105469, "batch_reward": 1.1428692026138305, "actor_loss": -215.36273508223277, "actor_target_entropy": -1.0, "actor_entropy": 0.7484813294713459, "alpha_loss": 0.0023795295514107222, "alpha_value": 0.24614269421707943, "duration": 151.24437594413757, "step": 54875}
{"episode_reward": 176.02367782052468, "episode": 440.0, "Q1 loss": 5.972587827682495, "Q2 loss": 5.997888479232788, "Mean Target Q": 214.2737890625, "Mean Q1": 214.27383374023438, "Mean Q2": 214.27373352050782, "critic_loss": 11.970476303100586, "batch_reward": 1.1391328201293944, "actor_loss": -215.35805339197958, "actor_target_entropy": -1.0, "actor_entropy": 0.7375042284688642, "alpha_loss": 0.008476080110056265, "alpha_value": 0.2456927637269805, "step": 55000}
{"duration": 178.4913227558136, "step": 55000}
{"episode_reward": 46.82787256201996, "episode": 441.0, "Q1 loss": 6.0139453411102295, "Q2 loss": 6.010803401947022, "Mean Target Q": 214.33018542480468, "Mean Q1": 214.33275341796875, "Mean Q2": 214.33245056152344, "critic_loss": 12.024748748779297, "batch_reward": 1.1265853633880616, "actor_loss": -215.58841160365515, "actor_target_entropy": -1.0, "actor_entropy": 0.7703866400415935, "alpha_loss": 0.0013431772194241012, "alpha_value": 0.24541044587242122, "duration": 179.62118768692017, "step": 55125}
{"episode_reward": 189.09033881092864, "episode": 442.0, "Q1 loss": 6.074061176300049, "Q2 loss": 6.08733618927002, "Mean Target Q": 214.53268957519532, "Mean Q1": 214.52904345703126, "Mean Q2": 214.5294140625, "critic_loss": 12.161397384643555, "batch_reward": 1.1440719718933106, "actor_loss": -215.77008573470576, "actor_target_entropy": -1.0, "actor_entropy": 0.7265243789842052, "alpha_loss": 0.0022509371666538137, "alpha_value": 0.24534157326915046, "duration": 148.79298949241638, "step": 55250}
{"episode_reward": 69.22594004015865, "episode": 443.0, "Q1 loss": 6.348308902740478, "Q2 loss": 6.359186336517334, "Mean Target Q": 214.64318090820314, "Mean Q1": 214.64454650878906, "Mean Q2": 214.6442449951172, "critic_loss": 12.707495254516601, "batch_reward": 1.137685308456421, "actor_loss": -215.86927383665054, "actor_target_entropy": -1.0, "actor_entropy": 0.7395824222337632, "alpha_loss": -0.004835953610757041, "alpha_value": 0.24536138176543934, "duration": 152.6167221069336, "step": 55375}
{"episode_reward": 187.76610583446757, "episode": 444.0, "Q1 loss": 6.213807899475098, "Q2 loss": 6.1991517505645755, "Mean Target Q": 214.82948864746095, "Mean Q1": 214.82416198730468, "Mean Q2": 214.8242734375, "critic_loss": 12.412959632873536, "batch_reward": 1.1450841598510741, "actor_loss": -216.02309983776462, "actor_target_entropy": -1.0, "actor_entropy": 0.7221823459671389, "alpha_loss": 0.0005106206142133282, "alpha_value": 0.24547235861092698, "duration": 177.0316445827484, "step": 55500}
{"episode_reward": 57.974412504173685, "episode": 445.0, "Q1 loss": 6.262595195770263, "Q2 loss": 6.281048007965088, "Mean Target Q": 214.89070556640624, "Mean Q1": 214.89339367675782, "Mean Q2": 214.89367443847655, "critic_loss": 12.543643211364746, "batch_reward": 1.1428474779129028, "actor_loss": -216.077396937779, "actor_target_entropy": -1.0, "actor_entropy": 0.7262655449292016, "alpha_loss": -0.000817755076457702, "alpha_value": 0.24564093260902517, "duration": 155.326167345047, "step": 55625}
{"episode_reward": 169.5455852916416, "episode": 446.0, "Q1 loss": 5.968391468048096, "Q2 loss": 5.962313772201538, "Mean Target Q": 214.9267891845703, "Mean Q1": 214.92721997070313, "Mean Q2": 214.9264757080078, "critic_loss": 11.930705261230468, "batch_reward": 1.1426783514022827, "actor_loss": -216.1546389672064, "actor_target_entropy": -1.0, "actor_entropy": 0.724582847087614, "alpha_loss": 0.0062666938230845955, "alpha_value": 0.2453530229343682, "duration": 171.2869212627411, "step": 55750}
{"episode_reward": 191.4339600503526, "episode": 447.0, "Q1 loss": 5.9047692527771, "Q2 loss": 5.915658378601075, "Mean Target Q": 215.04051586914062, "Mean Q1": 215.03990441894533, "Mean Q2": 215.04071606445314, "critic_loss": 11.820427589416504, "batch_reward": 1.1476383028030395, "actor_loss": -216.2608666798425, "actor_target_entropy": -1.0, "actor_entropy": 0.7291305112460303, "alpha_loss": 0.003931234461358852, "alpha_value": 0.24490851913558598, "duration": 168.72932600975037, "step": 55875}
{"episode_reward": 91.5137958826114, "episode": 448.0, "Q1 loss": 6.026401433944702, "Q2 loss": 6.041989223480225, "Mean Target Q": 215.1284873046875, "Mean Q1": 215.12397424316407, "Mean Q2": 215.12362866210938, "critic_loss": 12.06839067840576, "batch_reward": 1.141762393951416, "actor_loss": -216.36566482051725, "actor_target_entropy": -1.0, "actor_entropy": 0.7230415796079943, "alpha_loss": 0.002021702622333842, "alpha_value": 0.24462026874939702, "duration": 180.385901927948, "step": 56000}
{"episode_reward": 154.65268935231137, "episode": 449.0, "Q1 loss": 6.0752456092834475, "Q2 loss": 6.079400939941406, "Mean Target Q": 215.20941540527343, "Mean Q1": 215.20642834472656, "Mean Q2": 215.20608862304687, "critic_loss": 12.154646522521972, "batch_reward": 1.1347854819297791, "actor_loss": -216.48405238560267, "actor_target_entropy": -1.0, "actor_entropy": 0.7496741783051264, "alpha_loss": -0.001104813294544343, "alpha_value": 0.24479149073025905, "duration": 171.74980115890503, "step": 56125}
{"episode_reward": 213.1579190680527, "episode": 450.0, "Q1 loss": 5.715728603363037, "Q2 loss": 5.73784485244751, "Mean Target Q": 215.3901954345703, "Mean Q1": 215.39216564941407, "Mean Q2": 215.3933155517578, "critic_loss": 11.45357347869873, "batch_reward": 1.1402059116363525, "actor_loss": -216.57071168961065, "actor_target_entropy": -1.0, "actor_entropy": 0.7737458127160226, "alpha_loss": 0.003927381712973358, "alpha_value": 0.24471348606787718, "duration": 176.08990740776062, "step": 56250}
{"episode_reward": 70.90346526155422, "episode": 451.0, "Q1 loss": 5.997949590682984, "Q2 loss": 6.019037437438965, "Mean Target Q": 215.53980224609376, "Mean Q1": 215.53989172363282, "Mean Q2": 215.53888037109374, "critic_loss": 12.016987022399903, "batch_reward": 1.13828556060791, "actor_loss": -216.75139266725571, "actor_target_entropy": -1.0, "actor_entropy": 0.7548342593132503, "alpha_loss": -0.0036468442810314986, "alpha_value": 0.2444667294918743, "duration": 194.24843049049377, "step": 56375}
{"episode_reward": 129.04666739434262, "episode": 452.0, "Q1 loss": 6.233451969146729, "Q2 loss": 6.209542621612549, "Mean Target Q": 215.60061755371095, "Mean Q1": 215.59617749023437, "Mean Q2": 215.59601110839844, "critic_loss": 12.442994564056397, "batch_reward": 1.1435625643730163, "actor_loss": -216.7957278836158, "actor_target_entropy": -1.0, "actor_entropy": 0.7688545277041774, "alpha_loss": 0.0026514101266530495, "alpha_value": 0.24465479288821462, "duration": 169.8557369709015, "step": 56500}
{"episode_reward": 108.94026776404326, "episode": 453.0, "Q1 loss": 5.860918924331665, "Q2 loss": 5.889269092559815, "Mean Target Q": 215.58597619628907, "Mean Q1": 215.58104638671875, "Mean Q2": 215.58106481933595, "critic_loss": 11.750188026428223, "batch_reward": 1.1319197473526001, "actor_loss": -216.82629878937252, "actor_target_entropy": -1.0, "actor_entropy": 0.7345810854245746, "alpha_loss": 0.0022343056616447275, "alpha_value": 0.24427562851970253, "duration": 136.26764059066772, "step": 56625}
{"episode_reward": 129.69012841070438, "episode": 454.0, "Q1 loss": 5.835563411712647, "Q2 loss": 5.845637325286865, "Mean Target Q": 215.8306163330078, "Mean Q1": 215.82826403808593, "Mean Q2": 215.82840173339844, "critic_loss": 11.681200695037841, "batch_reward": 1.13847806930542, "actor_loss": -217.05825608776462, "actor_target_entropy": -1.0, "actor_entropy": 0.7474213136780646, "alpha_loss": -0.006892655859701335, "alpha_value": 0.24441768006222034, "duration": 146.1827735900879, "step": 56750}
{"episode_reward": 74.0531319824763, "episode": 455.0, "Q1 loss": 6.273022270202636, "Q2 loss": 6.270040203094482, "Mean Target Q": 216.06786376953124, "Mean Q1": 216.0759757080078, "Mean Q2": 216.07603271484376, "critic_loss": 12.543062454223632, "batch_reward": 1.1360308408737183, "actor_loss": -217.25470140245227, "actor_target_entropy": -1.0, "actor_entropy": 0.7544582315853664, "alpha_loss": -0.0028313560677426203, "alpha_value": 0.24503510346325344, "duration": 175.1765637397766, "step": 56875}
{"episode_reward": 153.9914174065068, "episode": 456.0, "Q1 loss": 6.5442970314025875, "Q2 loss": 6.550410900115967, "Mean Target Q": 216.1892802734375, "Mean Q1": 216.17950305175782, "Mean Q2": 216.1789608154297, "critic_loss": 13.094707878112793, "batch_reward": 1.1401699810028076, "actor_loss": -217.37569181380732, "actor_target_entropy": -1.0, "actor_entropy": 0.725256742969636, "alpha_loss": 0.0032318543770440645, "alpha_value": 0.24487619585779488, "duration": 152.58071565628052, "step": 57000}
{"episode_reward": 148.22463829893732, "episode": 457.0, "Q1 loss": 6.4458277206420895, "Q2 loss": 6.465005683898926, "Mean Target Q": 216.34516552734374, "Mean Q1": 216.35234008789064, "Mean Q2": 216.35298986816406, "critic_loss": 12.910833438873292, "batch_reward": 1.1423756904602052, "actor_loss": -217.55195932539684, "actor_target_entropy": -1.0, "actor_entropy": 0.7333381374677023, "alpha_loss": -0.004359613978377883, "alpha_value": 0.24498583649610106, "duration": 170.139502286911, "step": 57125}
{"episode_reward": 154.72286728497974, "episode": 458.0, "Q1 loss": 6.529430156707764, "Q2 loss": 6.514874652862549, "Mean Target Q": 216.41965856933595, "Mean Q1": 216.41586645507812, "Mean Q2": 216.41630981445311, "critic_loss": 13.044304832458495, "batch_reward": 1.1383533172607423, "actor_loss": -217.64147407777847, "actor_target_entropy": -1.0, "actor_entropy": 0.7374088052780398, "alpha_loss": -0.0023942664716272584, "alpha_value": 0.24525031016988455, "duration": 158.80398058891296, "step": 57250}
{"episode_reward": 163.13664274049788, "episode": 459.0, "Q1 loss": 6.87288879776001, "Q2 loss": 6.894063350677491, "Mean Target Q": 216.51477160644532, "Mean Q1": 216.50828271484374, "Mean Q2": 216.50710900878906, "critic_loss": 13.766952186584472, "batch_reward": 1.1241950998306274, "actor_loss": -217.74331907242063, "actor_target_entropy": -1.0, "actor_entropy": 0.7457169691721598, "alpha_loss": 0.0008718030682454506, "alpha_value": 0.24542510192078412, "duration": 142.68973064422607, "step": 57375}
{"episode_reward": 204.69110785707193, "episode": 460.0, "Q1 loss": 6.186599433898926, "Q2 loss": 6.180088790893555, "Mean Target Q": 216.54335327148436, "Mean Q1": 216.5418670654297, "Mean Q2": 216.54250622558592, "critic_loss": 12.36668822479248, "batch_reward": 1.1393901128768922, "actor_loss": -217.62649609965663, "actor_target_entropy": -1.0, "actor_entropy": 0.7512358667389039, "alpha_loss": 0.0014634309148776434, "alpha_value": 0.2453580692937504, "duration": 161.30065369606018, "step": 57500}
{"episode_reward": 5.810853953419375, "episode": 461.0, "Q1 loss": 5.966208377838135, "Q2 loss": 5.989831958770752, "Mean Target Q": 216.6371276855469, "Mean Q1": 216.64151733398438, "Mean Q2": 216.64203125, "critic_loss": 11.956040336608886, "batch_reward": 1.134808608531952, "actor_loss": -217.85330999465216, "actor_target_entropy": -1.0, "actor_entropy": 0.7514835671773032, "alpha_loss": -0.0008731572278997018, "alpha_value": 0.24515904738782834, "duration": 172.14352345466614, "step": 57625}
{"episode_reward": 43.43571384290478, "episode": 462.0, "Q1 loss": 6.05524697303772, "Q2 loss": 6.034815015792847, "Mean Target Q": 216.81967687988282, "Mean Q1": 216.81323461914062, "Mean Q2": 216.81324914550783, "critic_loss": 12.090061935424805, "batch_reward": 1.1424444465637207, "actor_loss": -217.97638407061177, "actor_target_entropy": -1.0, "actor_entropy": 0.7667537216217287, "alpha_loss": -0.0021743254262893913, "alpha_value": 0.24534535674394178, "duration": 141.54678392410278, "step": 57750}
{"episode_reward": 118.06953588234833, "episode": 463.0, "Q1 loss": 5.760715646743774, "Q2 loss": 5.783998746871948, "Mean Target Q": 216.86599938964844, "Mean Q1": 216.87099987792968, "Mean Q2": 216.87012731933595, "critic_loss": 11.544714374542236, "batch_reward": 1.1420477876663209, "actor_loss": -218.0903116861979, "actor_target_entropy": -1.0, "actor_entropy": 0.7674142491249811, "alpha_loss": 0.004379671643532458, "alpha_value": 0.24524102561303027, "duration": 138.5386643409729, "step": 57875}
{"episode_reward": 136.57167622960378, "episode": 464.0, "Q1 loss": 5.791458080291748, "Q2 loss": 5.8125904808044435, "Mean Target Q": 216.97652490234375, "Mean Q1": 216.97195544433595, "Mean Q2": 216.972306640625, "critic_loss": 11.6040485496521, "batch_reward": 1.136316596031189, "actor_loss": -218.14876581007434, "actor_target_entropy": -1.0, "actor_entropy": 0.7702528920865828, "alpha_loss": 0.010339336496056808, "alpha_value": 0.24478440829901196, "duration": 140.63762974739075, "step": 58000}
{"episode_reward": 101.24505940122474, "episode": 465.0, "Q1 loss": 5.641638271331787, "Q2 loss": 5.65448291015625, "Mean Target Q": 217.05202111816405, "Mean Q1": 217.05236865234374, "Mean Q2": 217.0521396484375, "critic_loss": 11.29612116241455, "batch_reward": 1.1377282094955445, "actor_loss": -218.26526871938555, "actor_target_entropy": -1.0, "actor_entropy": 0.7524867701152015, "alpha_loss": 0.0011339020242707597, "alpha_value": 0.24411876084100803, "duration": 136.26122403144836, "step": 58125}
{"episode_reward": 73.00577354564456, "episode": 466.0, "Q1 loss": 5.7963173294067385, "Q2 loss": 5.8059753303527835, "Mean Target Q": 217.04185705566405, "Mean Q1": 217.04296337890625, "Mean Q2": 217.04326196289063, "critic_loss": 11.602292667388916, "batch_reward": 1.1304874629974366, "actor_loss": -218.2382047099452, "actor_target_entropy": -1.0, "actor_entropy": 0.751781165599823, "alpha_loss": -0.0030582704048063005, "alpha_value": 0.24433759774620278, "duration": 126.98991394042969, "step": 58250}
{"episode_reward": 93.08597360969638, "episode": 467.0, "Q1 loss": 5.799019916534424, "Q2 loss": 5.800791660308838, "Mean Target Q": 217.2136680908203, "Mean Q1": 217.21181408691407, "Mean Q2": 217.21080224609375, "critic_loss": 11.599811546325684, "batch_reward": 1.1381368284225464, "actor_loss": -218.45804002549914, "actor_target_entropy": -1.0, "actor_entropy": 0.7564455336994595, "alpha_loss": -0.00111460295461473, "alpha_value": 0.244408169855538, "duration": 130.13190507888794, "step": 58375}
{"episode_reward": 197.23476352339875, "episode": 468.0, "Q1 loss": 5.783969284057617, "Q2 loss": 5.782345294952393, "Mean Target Q": 217.3370305175781, "Mean Q1": 217.33329150390625, "Mean Q2": 217.33359912109376, "critic_loss": 11.56631462097168, "batch_reward": 1.1302796378135682, "actor_loss": -218.5860839351531, "actor_target_entropy": -1.0, "actor_entropy": 0.7368069589138031, "alpha_loss": 0.00026588068313656313, "alpha_value": 0.24451934843427836, "duration": 154.34194087982178, "step": 58500}
{"episode_reward": 137.2189549423801, "episode": 469.0, "Q1 loss": 5.835663005828858, "Q2 loss": 5.835063190460205, "Mean Target Q": 217.47370703125, "Mean Q1": 217.4693798828125, "Mean Q2": 217.47013598632813, "critic_loss": 11.670726165771484, "batch_reward": 1.1340123190879823, "actor_loss": -218.71804858010913, "actor_target_entropy": -1.0, "actor_entropy": 0.7442211669588846, "alpha_loss": 0.001395361921158693, "alpha_value": 0.2445661775073574, "duration": 169.20737504959106, "step": 58625}
{"episode_reward": 84.14696787065037, "episode": 470.0, "Q1 loss": 6.079493667602539, "Q2 loss": 6.097798475265503, "Mean Target Q": 217.61731579589843, "Mean Q1": 217.61751000976562, "Mean Q2": 217.61720581054686, "critic_loss": 12.177292167663575, "batch_reward": 1.1375940427780151, "actor_loss": -218.83625055128527, "actor_target_entropy": -1.0, "actor_entropy": 0.741904180857443, "alpha_loss": 0.0050994401962886895, "alpha_value": 0.24415411627977282, "duration": 147.02527856826782, "step": 58750}
{"episode_reward": 219.98287389354664, "episode": 471.0, "Q1 loss": 6.432192558288574, "Q2 loss": 6.422748058319092, "Mean Target Q": 217.75239965820313, "Mean Q1": 217.75446752929687, "Mean Q2": 217.7554034423828, "critic_loss": 12.854940673828125, "batch_reward": 1.1335146265029907, "actor_loss": -219.0253174796937, "actor_target_entropy": -1.0, "actor_entropy": 0.7476487027274238, "alpha_loss": 0.0004819461942783424, "alpha_value": 0.2441277597587259, "duration": 114.11358404159546, "step": 58875}
{"episode_reward": 182.18854522285605, "episode": 472.0, "Q1 loss": 6.441573665618897, "Q2 loss": 6.458579311370849, "Mean Target Q": 217.80992895507814, "Mean Q1": 217.80767663574218, "Mean Q2": 217.8069521484375, "critic_loss": 12.900152946472168, "batch_reward": 1.1373975381851196, "actor_loss": -219.04483426001764, "actor_target_entropy": -1.0, "actor_entropy": 0.7341687073630672, "alpha_loss": 0.0010577060578901682, "alpha_value": 0.24392940199042953, "duration": 170.31073212623596, "step": 59000}
{"episode_reward": 137.72834685378535, "episode": 473.0, "Q1 loss": 6.037783309936524, "Q2 loss": 6.062405986785889, "Mean Target Q": 217.80134692382813, "Mean Q1": 217.80009606933595, "Mean Q2": 217.79928601074218, "critic_loss": 12.10018928527832, "batch_reward": 1.1353690667152405, "actor_loss": -219.02622598315043, "actor_target_entropy": -1.0, "actor_entropy": 0.7283278136026292, "alpha_loss": 0.002238553872938076, "alpha_value": 0.24381809113171748, "duration": 154.5450930595398, "step": 59125}
{"episode_reward": 138.23227891939317, "episode": 474.0, "Q1 loss": 5.971026853561401, "Q2 loss": 5.986363258361816, "Mean Target Q": 217.93261657714845, "Mean Q1": 217.9301611328125, "Mean Q2": 217.92999621582032, "critic_loss": 11.957390155792236, "batch_reward": 1.1363259997367858, "actor_loss": -219.1098413775044, "actor_target_entropy": -1.0, "actor_entropy": 0.7557976495835089, "alpha_loss": 0.0011856521089230814, "alpha_value": 0.24365465639275807, "duration": 170.1173963546753, "step": 59250}
{"episode_reward": 166.6816797714495, "episode": 475.0, "Q1 loss": 6.316678134918213, "Q2 loss": 6.339104789733887, "Mean Target Q": 218.04460119628905, "Mean Q1": 218.0422733154297, "Mean Q2": 218.04220288085938, "critic_loss": 12.655782913208007, "batch_reward": 1.1281245193481446, "actor_loss": -219.26122514028398, "actor_target_entropy": -1.0, "actor_entropy": 0.7399387142014882, "alpha_loss": -0.0016585224019807008, "alpha_value": 0.2437830497531764, "duration": 181.2501037120819, "step": 59375}
{"episode_reward": 176.50438972986828, "episode": 476.0, "Q1 loss": 5.973139415740967, "Q2 loss": 5.988666498184204, "Mean Target Q": 218.1779090576172, "Mean Q1": 218.1826759033203, "Mean Q2": 218.183419921875, "critic_loss": 11.961805900573731, "batch_reward": 1.1285839395523072, "actor_loss": -219.41899970269972, "actor_target_entropy": -1.0, "actor_entropy": 0.74489376141179, "alpha_loss": -0.002430510380485606, "alpha_value": 0.243771529895025, "duration": 147.55295062065125, "step": 59500}
{"episode_reward": 156.10226713580053, "episode": 477.0, "Q1 loss": 6.406977561950684, "Q2 loss": 6.408068008422852, "Mean Target Q": 218.2745603027344, "Mean Q1": 218.26735205078126, "Mean Q2": 218.26688330078125, "critic_loss": 12.815045516967773, "batch_reward": 1.1365659093856813, "actor_loss": -219.51637146964904, "actor_target_entropy": -1.0, "actor_entropy": 0.7464991713327075, "alpha_loss": 0.002730751556107804, "alpha_value": 0.24388475173408627, "duration": 147.74892687797546, "step": 59625}
{"episode_reward": 153.71092869740477, "episode": 478.0, "Q1 loss": 6.141532434463501, "Q2 loss": 6.151537021636963, "Mean Target Q": 218.37617932128907, "Mean Q1": 218.37962438964843, "Mean Q2": 218.3796678466797, "critic_loss": 12.293069465637206, "batch_reward": 1.1342569379806517, "actor_loss": -219.55981174592048, "actor_target_entropy": -1.0, "actor_entropy": 0.7512664083511599, "alpha_loss": -0.00023101142141968012, "alpha_value": 0.24361502319263303, "duration": 162.41311955451965, "step": 59750}
{"episode_reward": 192.23948991148058, "episode": 479.0, "Q1 loss": 5.934825214385986, "Q2 loss": 5.966776531219482, "Mean Target Q": 218.3524385986328, "Mean Q1": 218.35075512695312, "Mean Q2": 218.35104711914062, "critic_loss": 11.901601779937744, "batch_reward": 1.1337468891143798, "actor_loss": -219.5964607359871, "actor_target_entropy": -1.0, "actor_entropy": 0.7450746742505876, "alpha_loss": 0.0032595303685714803, "alpha_value": 0.24353072300800335, "duration": 159.90602564811707, "step": 59875}
{"episode_reward": 236.71233467682353, "episode": 480.0, "Q1 loss": 5.902058088302613, "Q2 loss": 5.897079061508179, "Mean Target Q": 218.57825622558593, "Mean Q1": 218.57984497070314, "Mean Q2": 218.5800965576172, "critic_loss": 11.799137176513671, "batch_reward": 1.1417112264633178, "actor_loss": -219.78545945690524, "actor_target_entropy": -1.0, "actor_entropy": 0.7478808904847791, "alpha_loss": 0.0024774434315341133, "alpha_value": 0.24349702332563716, "step": 60000}
{"duration": 149.64091849327087, "step": 60000}
{"episode_reward": 189.25912408277182, "episode": 481.0, "Q1 loss": 5.992199924468994, "Q2 loss": 6.001441184997558, "Mean Target Q": 218.67577124023438, "Mean Q1": 218.67436022949218, "Mean Q2": 218.67417333984375, "critic_loss": 11.99364112854004, "batch_reward": 1.1338611097335816, "actor_loss": -219.9438023642888, "actor_target_entropy": -1.0, "actor_entropy": 0.7421000930998061, "alpha_loss": -0.00098459694778458, "alpha_value": 0.24327961058117054, "duration": 130.92213463783264, "step": 60125}
{"episode_reward": 193.3809285623937, "episode": 482.0, "Q1 loss": 6.28862190246582, "Q2 loss": 6.292721374511719, "Mean Target Q": 218.8536433105469, "Mean Q1": 218.84963122558594, "Mean Q2": 218.8482373046875, "critic_loss": 12.581343269348144, "batch_reward": 1.138800880432129, "actor_loss": -219.9886984056042, "actor_target_entropy": -1.0, "actor_entropy": 0.7750916884791467, "alpha_loss": -0.0020982138249242017, "alpha_value": 0.2435297262810806, "duration": 85.12850737571716, "step": 60250}
{"episode_reward": 125.42959277613916, "episode": 483.0, "Q1 loss": 6.556071907043457, "Q2 loss": 6.5664648399353025, "Mean Target Q": 218.89089147949218, "Mean Q1": 218.89243676757812, "Mean Q2": 218.89344274902345, "critic_loss": 13.122536781311036, "batch_reward": 1.1333927512168884, "actor_loss": -220.13966200086804, "actor_target_entropy": -1.0, "actor_entropy": 0.7349232151394799, "alpha_loss": -0.0019021213926847965, "alpha_value": 0.24355276928131267, "duration": 102.3856189250946, "step": 60375}
{"episode_reward": 133.3190307839726, "episode": 484.0, "Q1 loss": 6.245689769744873, "Q2 loss": 6.265319557189941, "Mean Target Q": 219.05032409667967, "Mean Q1": 219.0495546875, "Mean Q2": 219.04977465820312, "critic_loss": 12.511009265899657, "batch_reward": 1.1463923826217652, "actor_loss": -220.2670140420237, "actor_target_entropy": -1.0, "actor_entropy": 0.7728495799726055, "alpha_loss": 0.004255135971752386, "alpha_value": 0.24342002512717537, "duration": 138.55184030532837, "step": 60500}
{"episode_reward": 176.46538949280304, "episode": 485.0, "Q1 loss": 6.097078804016113, "Q2 loss": 6.100631816864014, "Mean Target Q": 219.1505047607422, "Mean Q1": 219.1497509765625, "Mean Q2": 219.14986938476562, "critic_loss": 12.197710594177247, "batch_reward": 1.1375918216705323, "actor_loss": -220.39338950505334, "actor_target_entropy": -1.0, "actor_entropy": 0.7408251601552206, "alpha_loss": 0.002735066645231748, "alpha_value": 0.24332094778905175, "duration": 147.00837898254395, "step": 60625}
{"episode_reward": 141.83897284303086, "episode": 486.0, "Q1 loss": 6.068746662139892, "Q2 loss": 6.081170799255371, "Mean Target Q": 219.26037622070314, "Mean Q1": 219.25716870117188, "Mean Q2": 219.25652600097655, "critic_loss": 12.149917488098145, "batch_reward": 1.1432326965332031, "actor_loss": -220.44608774492818, "actor_target_entropy": -1.0, "actor_entropy": 0.7361892596367867, "alpha_loss": 0.008572749369176886, "alpha_value": 0.24299838374536095, "duration": 160.12548303604126, "step": 60750}
{"episode_reward": 198.15587633820607, "episode": 487.0, "Q1 loss": 5.953670755386352, "Q2 loss": 5.962102426528931, "Mean Target Q": 219.29308715820312, "Mean Q1": 219.2911943359375, "Mean Q2": 219.29189697265625, "critic_loss": 11.915773178100586, "batch_reward": 1.137564274787903, "actor_loss": -220.52847532242063, "actor_target_entropy": -1.0, "actor_entropy": 0.7413912226283361, "alpha_loss": -0.005512270876871688, "alpha_value": 0.24277089712734368, "duration": 151.83904123306274, "step": 60875}
{"episode_reward": 166.21777380702085, "episode": 488.0, "Q1 loss": 5.911151620864868, "Q2 loss": 5.909321481704712, "Mean Target Q": 219.3935888671875, "Mean Q1": 219.39539892578125, "Mean Q2": 219.39379541015626, "critic_loss": 11.820473136901855, "batch_reward": 1.141692102432251, "actor_loss": -220.5745605960969, "actor_target_entropy": -1.0, "actor_entropy": 0.7727576571126138, "alpha_loss": -0.003610403967961188, "alpha_value": 0.24297279625235663, "duration": 142.90069437026978, "step": 61000}
{"episode_reward": 200.06568694832558, "episode": 489.0, "Q1 loss": 6.146297992706299, "Q2 loss": 6.166678611755371, "Mean Target Q": 219.5119171142578, "Mean Q1": 219.50789526367188, "Mean Q2": 219.5090205078125, "critic_loss": 12.312976585388183, "batch_reward": 1.1372528820037842, "actor_loss": -220.78139265756758, "actor_target_entropy": -1.0, "actor_entropy": 0.7509106861220466, "alpha_loss": 0.002119439380568644, "alpha_value": 0.24302577492848537, "duration": 153.70588207244873, "step": 61125}
{"episode_reward": 126.5654293200756, "episode": 490.0, "Q1 loss": 5.894180858612061, "Q2 loss": 5.895904857635498, "Mean Target Q": 219.55349841308595, "Mean Q1": 219.5528095703125, "Mean Q2": 219.5515792236328, "critic_loss": 11.79008578491211, "batch_reward": 1.1306674823760987, "actor_loss": -220.73436441729146, "actor_target_entropy": -1.0, "actor_entropy": 0.7467996872240498, "alpha_loss": 0.009155848219374856, "alpha_value": 0.24275807675741645, "duration": 157.87429213523865, "step": 61250}
{"episode_reward": 171.75395969230786, "episode": 491.0, "Q1 loss": 5.652672128677368, "Q2 loss": 5.673309715270996, "Mean Target Q": 219.62725402832032, "Mean Q1": 219.6326795654297, "Mean Q2": 219.63346826171875, "critic_loss": 11.325981864929199, "batch_reward": 1.1414065752029419, "actor_loss": -220.85823446606832, "actor_target_entropy": -1.0, "actor_entropy": 0.7399762708043295, "alpha_loss": 0.003790218135460265, "alpha_value": 0.24227629536847556, "duration": 147.59275722503662, "step": 61375}
{"episode_reward": 207.27084925106612, "episode": 492.0, "Q1 loss": 5.939008625030517, "Q2 loss": 5.984928768157959, "Mean Target Q": 219.80501818847657, "Mean Q1": 219.79882727050781, "Mean Q2": 219.79872839355468, "critic_loss": 11.923937446594238, "batch_reward": 1.1403206338882446, "actor_loss": -221.0791027930475, "actor_target_entropy": -1.0, "actor_entropy": 0.7525279339282743, "alpha_loss": 0.0027052917697977636, "alpha_value": 0.24197656226742167, "duration": 142.97092127799988, "step": 61500}
{"episode_reward": 27.959678616517795, "episode": 493.0, "Q1 loss": 5.722276174545288, "Q2 loss": 5.687104377746582, "Mean Target Q": 219.93843481445313, "Mean Q1": 219.93685290527344, "Mean Q2": 219.93749963378906, "critic_loss": 11.409380577087402, "batch_reward": 1.145522861480713, "actor_loss": -221.11471315414187, "actor_target_entropy": -1.0, "actor_entropy": 0.7558194436724224, "alpha_loss": 0.002774273522109503, "alpha_value": 0.24171050716998219, "duration": 160.8267023563385, "step": 61625}
{"episode_reward": 64.72228921943665, "episode": 494.0, "Q1 loss": 5.824269123077393, "Q2 loss": 5.817002361297607, "Mean Target Q": 220.03032836914062, "Mean Q1": 220.03361694335936, "Mean Q2": 220.0326241455078, "critic_loss": 11.641271495819092, "batch_reward": 1.1384405550956727, "actor_loss": -221.23995454849737, "actor_target_entropy": -1.0, "actor_entropy": 0.7552494339404567, "alpha_loss": 0.0044878450552782705, "alpha_value": 0.24141779327227275, "duration": 182.67372298240662, "step": 61750}
{"episode_reward": 221.80138040078666, "episode": 495.0, "Q1 loss": 5.920146898269653, "Q2 loss": 5.93727799987793, "Mean Target Q": 220.05879919433593, "Mean Q1": 220.04933435058595, "Mean Q2": 220.04959924316407, "critic_loss": 11.85742487335205, "batch_reward": 1.1227903604507445, "actor_loss": -221.2539522685702, "actor_target_entropy": -1.0, "actor_entropy": 0.7531564330297803, "alpha_loss": 0.0004688614410244756, "alpha_value": 0.2413912918027139, "duration": 173.12068963050842, "step": 61875}
{"episode_reward": 216.7832583731036, "episode": 496.0, "Q1 loss": 5.996063619613648, "Q2 loss": 5.984516956329346, "Mean Target Q": 220.18666857910156, "Mean Q1": 220.18827331542968, "Mean Q2": 220.1885264892578, "critic_loss": 11.980580562591554, "batch_reward": 1.1393288421630858, "actor_loss": -221.35406715639175, "actor_target_entropy": -1.0, "actor_entropy": 0.7433302633223995, "alpha_loss": 0.0013360168236578184, "alpha_value": 0.24140869323184563, "duration": 156.64313793182373, "step": 62000}
{"episode_reward": 82.5506561988148, "episode": 497.0, "Q1 loss": 5.824740581512451, "Q2 loss": 5.81578723526001, "Mean Target Q": 220.2295001220703, "Mean Q1": 220.23238293457032, "Mean Q2": 220.2312283935547, "critic_loss": 11.640527770996094, "batch_reward": 1.1439434957504273, "actor_loss": -221.47162373860678, "actor_target_entropy": -1.0, "actor_entropy": 0.746678682546767, "alpha_loss": 0.0062063985563341586, "alpha_value": 0.24097325067170897, "duration": 167.38704133033752, "step": 62125}
{"episode_reward": 65.3977596216566, "episode": 498.0, "Q1 loss": 5.76732608795166, "Q2 loss": 5.7652927665710445, "Mean Target Q": 220.35794494628905, "Mean Q1": 220.3524814453125, "Mean Q2": 220.35308276367186, "critic_loss": 11.5326188621521, "batch_reward": 1.1403700017929077, "actor_loss": -221.63009766609437, "actor_target_entropy": -1.0, "actor_entropy": 0.748655867192053, "alpha_loss": 0.0003466587626345215, "alpha_value": 0.24074934652580882, "duration": 150.01880741119385, "step": 62250}
{"episode_reward": 55.84173583569661, "episode": 499.0, "Q1 loss": 6.014427770614624, "Q2 loss": 6.026137857437134, "Mean Target Q": 220.48170471191406, "Mean Q1": 220.47882580566406, "Mean Q2": 220.4779852294922, "critic_loss": 12.040565574645996, "batch_reward": 1.1312751293182373, "actor_loss": -221.7641119578528, "actor_target_entropy": -1.0, "actor_entropy": 0.7420149360384259, "alpha_loss": 0.010262979477244829, "alpha_value": 0.2404893847721055, "duration": 174.50244975090027, "step": 62375}
{"episode_reward": 44.54960849106396, "episode": 500.0, "Q1 loss": 6.285588642120361, "Q2 loss": 6.301850231170654, "Mean Target Q": 220.49557543945312, "Mean Q1": 220.49283276367188, "Mean Q2": 220.49368908691406, "critic_loss": 12.587438774108886, "batch_reward": 1.1326086626052856, "actor_loss": -221.66569248322517, "actor_target_entropy": -1.0, "actor_entropy": 0.7239047250440044, "alpha_loss": 0.0035171168199139495, "alpha_value": 0.2397663960446291, "duration": 159.2792193889618, "step": 62500}
{"episode_reward": 196.15943432914864, "episode": 501.0, "Q1 loss": 6.0166390495300295, "Q2 loss": 6.040009185791016, "Mean Target Q": 220.65634338378905, "Mean Q1": 220.6601278076172, "Mean Q2": 220.65981799316407, "critic_loss": 12.056648246765137, "batch_reward": 1.1327462930679322, "actor_loss": -221.94668385339162, "actor_target_entropy": -1.0, "actor_entropy": 0.7246165701321193, "alpha_loss": -0.00316797923444519, "alpha_value": 0.23977421434990112, "duration": 184.191792011261, "step": 62625}
{"episode_reward": 120.83987634486547, "episode": 502.0, "Q1 loss": 6.301774925231934, "Q2 loss": 6.3183433685302735, "Mean Target Q": 220.71148413085936, "Mean Q1": 220.71351098632812, "Mean Q2": 220.71371752929687, "critic_loss": 12.620118293762207, "batch_reward": 1.1374130582809447, "actor_loss": -222.00526526666457, "actor_target_entropy": -1.0, "actor_entropy": 0.7358017861843109, "alpha_loss": -0.007982225037149845, "alpha_value": 0.2402568227352428, "duration": 162.52053880691528, "step": 62750}
{"episode_reward": 170.74118588628002, "episode": 503.0, "Q1 loss": 6.4193735046386715, "Q2 loss": 6.436361377716064, "Mean Target Q": 220.8384952392578, "Mean Q1": 220.83403259277344, "Mean Q2": 220.83388317871095, "critic_loss": 12.855734870910645, "batch_reward": 1.1375489501953124, "actor_loss": -222.02544390966023, "actor_target_entropy": -1.0, "actor_entropy": 0.7341594837960743, "alpha_loss": 0.0026848293981322695, "alpha_value": 0.24050963533316175, "duration": 162.59521579742432, "step": 62875}
{"episode_reward": 193.13586068856242, "episode": 504.0, "Q1 loss": 6.318909736633301, "Q2 loss": 6.325848316192627, "Mean Target Q": 220.97489807128906, "Mean Q1": 220.97718176269532, "Mean Q2": 220.97719580078126, "critic_loss": 12.644758079528808, "batch_reward": 1.1404929418563843, "actor_loss": -222.22051878898375, "actor_target_entropy": -1.0, "actor_entropy": 0.7312896799656653, "alpha_loss": 0.0016723793251590142, "alpha_value": 0.24020013155038444, "duration": 152.6071195602417, "step": 63000}
{"episode_reward": 133.18047524664215, "episode": 505.0, "Q1 loss": 6.260580339431763, "Q2 loss": 6.254400703430176, "Mean Target Q": 221.12815710449217, "Mean Q1": 221.12089916992187, "Mean Q2": 221.12026513671876, "critic_loss": 12.514981048583984, "batch_reward": 1.133437424659729, "actor_loss": -222.32325768849208, "actor_target_entropy": -1.0, "actor_entropy": 0.7211661669943068, "alpha_loss": -0.001189131243523979, "alpha_value": 0.24017202044788288, "duration": 152.5620903968811, "step": 63125}
{"episode_reward": 156.95481233010997, "episode": 506.0, "Q1 loss": 6.183560897827149, "Q2 loss": 6.19275634765625, "Mean Target Q": 221.24589685058595, "Mean Q1": 221.24741015625, "Mean Q2": 221.24747729492188, "critic_loss": 12.376317207336426, "batch_reward": 1.132654615879059, "actor_loss": -222.46812217466294, "actor_target_entropy": -1.0, "actor_entropy": 0.7354987898180562, "alpha_loss": -0.0027816315865023962, "alpha_value": 0.24057181797117672, "duration": 181.67773056030273, "step": 63250}
{"episode_reward": 147.3068340268333, "episode": 507.0, "Q1 loss": 6.287753910064697, "Q2 loss": 6.276665885925293, "Mean Target Q": 221.2993585205078, "Mean Q1": 221.29982446289063, "Mean Q2": 221.30010607910157, "critic_loss": 12.564419784545898, "batch_reward": 1.1425636863708497, "actor_loss": -222.51551528204055, "actor_target_entropy": -1.0, "actor_entropy": 0.7339361007251437, "alpha_loss": -0.004519573701102109, "alpha_value": 0.24064015849312034, "duration": 172.67094254493713, "step": 63375}
{"episode_reward": 188.63992686597294, "episode": 508.0, "Q1 loss": 6.2212511253356935, "Q2 loss": 6.249104347229004, "Mean Target Q": 221.39320361328126, "Mean Q1": 221.39217114257812, "Mean Q2": 221.3918643798828, "critic_loss": 12.470355484008788, "batch_reward": 1.1372635359764098, "actor_loss": -222.59970092773438, "actor_target_entropy": -1.0, "actor_entropy": 0.7492554120479091, "alpha_loss": -0.0015349569279820689, "alpha_value": 0.24098847699672124, "duration": 159.62447714805603, "step": 63500}
{"episode_reward": 46.98980503086506, "episode": 509.0, "Q1 loss": 6.194332509994507, "Q2 loss": 6.176842840194702, "Mean Target Q": 221.48678283691407, "Mean Q1": 221.4822977294922, "Mean Q2": 221.4825975341797, "critic_loss": 12.371175357818604, "batch_reward": 1.1379244232177734, "actor_loss": -222.68741038488963, "actor_target_entropy": -1.0, "actor_entropy": 0.76539189947976, "alpha_loss": -0.01043163233303598, "alpha_value": 0.2412167322992936, "duration": 174.4573357105255, "step": 63625}
{"episode_reward": 72.30518021612203, "episode": 510.0, "Q1 loss": 6.336881008148193, "Q2 loss": 6.3078813591003415, "Mean Target Q": 221.50449194335937, "Mean Q1": 221.506189453125, "Mean Q2": 221.50652770996095, "critic_loss": 12.644762351989746, "batch_reward": 1.140395170211792, "actor_loss": -222.7262479720577, "actor_target_entropy": -1.0, "actor_entropy": 0.7352843784516857, "alpha_loss": 0.002647784793929708, "alpha_value": 0.24183059827067122, "duration": 173.8368263244629, "step": 63750}
{"episode_reward": 214.72082330129652, "episode": 511.0, "Q1 loss": 6.395257026672363, "Q2 loss": 6.42280990600586, "Mean Target Q": 221.5957159423828, "Mean Q1": 221.5893934326172, "Mean Q2": 221.58905505371095, "critic_loss": 12.818066940307617, "batch_reward": 1.1377117557525636, "actor_loss": -222.84388393825955, "actor_target_entropy": -1.0, "actor_entropy": 0.7593260218226721, "alpha_loss": 0.0031504167487756128, "alpha_value": 0.24137333807355843, "duration": 165.78618574142456, "step": 63875}
{"episode_reward": 115.99248797446883, "episode": 512.0, "Q1 loss": 6.1969936752319335, "Q2 loss": 6.217792903900146, "Mean Target Q": 221.78146142578126, "Mean Q1": 221.78271020507813, "Mean Q2": 221.78292810058593, "critic_loss": 12.414786590576172, "batch_reward": 1.137172691345215, "actor_loss": -222.95187599428237, "actor_target_entropy": -1.0, "actor_entropy": 0.753991311596286, "alpha_loss": 0.003178672632202506, "alpha_value": 0.24115102110497755, "duration": 159.37262630462646, "step": 64000}
{"episode_reward": 133.2503058904234, "episode": 513.0, "Q1 loss": 6.035987405776978, "Q2 loss": 6.019156866073608, "Mean Target Q": 221.88254235839844, "Mean Q1": 221.88266638183595, "Mean Q2": 221.88329223632812, "critic_loss": 12.055144237518311, "batch_reward": 1.1405893468856811, "actor_loss": -223.13736858065167, "actor_target_entropy": -1.0, "actor_entropy": 0.7487784491644965, "alpha_loss": -0.007971586016494604, "alpha_value": 0.24122717511121133, "duration": 168.0729956626892, "step": 64125}
{"episode_reward": 134.30324195801737, "episode": 514.0, "Q1 loss": 6.017487823486328, "Q2 loss": 6.005506080627441, "Mean Target Q": 221.958361328125, "Mean Q1": 221.95599536132812, "Mean Q2": 221.9552393798828, "critic_loss": 12.022993919372558, "batch_reward": 1.1405824975967407, "actor_loss": -223.18071869880922, "actor_target_entropy": -1.0, "actor_entropy": 0.745299369096756, "alpha_loss": -1.3383375781197702e-05, "alpha_value": 0.24165375095858846, "duration": 158.51321029663086, "step": 64250}
{"episode_reward": 227.19504286346586, "episode": 515.0, "Q1 loss": 6.316057500839233, "Q2 loss": 6.339574827194214, "Mean Target Q": 221.98229052734376, "Mean Q1": 221.98015441894532, "Mean Q2": 221.9795447998047, "critic_loss": 12.65563232421875, "batch_reward": 1.141621985912323, "actor_loss": -223.32408892919148, "actor_target_entropy": -1.0, "actor_entropy": 0.7236864415426103, "alpha_loss": 0.0020127175412776453, "alpha_value": 0.2415849701863961, "duration": 158.09859228134155, "step": 64375}
{"episode_reward": 146.1899749188891, "episode": 516.0, "Q1 loss": 6.533912532806396, "Q2 loss": 6.535770709991455, "Mean Target Q": 222.07723266601562, "Mean Q1": 222.0786368408203, "Mean Q2": 222.07872900390626, "critic_loss": 13.069683197021485, "batch_reward": 1.1382363657951355, "actor_loss": -223.31367984894783, "actor_target_entropy": -1.0, "actor_entropy": 0.7444765894643722, "alpha_loss": 0.0038612955963359245, "alpha_value": 0.24130689028704924, "duration": 160.68175864219666, "step": 64500}
{"episode_reward": 5.855676613363777, "episode": 517.0, "Q1 loss": 6.413943794250488, "Q2 loss": 6.417808170318604, "Mean Target Q": 222.32955895996093, "Mean Q1": 222.32540380859376, "Mean Q2": 222.3255322265625, "critic_loss": 12.831752006530762, "batch_reward": 1.1405615954399109, "actor_loss": -223.61549135238405, "actor_target_entropy": -1.0, "actor_entropy": 0.7784989722191341, "alpha_loss": -0.007295691833225271, "alpha_value": 0.24147905492488603, "duration": 175.82319474220276, "step": 64625}
{"episode_reward": 178.36071179170412, "episode": 518.0, "Q1 loss": 6.042654088973999, "Q2 loss": 6.050073097229004, "Mean Target Q": 222.38908056640625, "Mean Q1": 222.38920056152344, "Mean Q2": 222.38912390136718, "critic_loss": 12.092727214813232, "batch_reward": 1.1388205165863037, "actor_loss": -223.61954079904865, "actor_target_entropy": -1.0, "actor_entropy": 0.7742098291074077, "alpha_loss": -0.002137303055684653, "alpha_value": 0.24183912942285354, "duration": 155.04553151130676, "step": 64750}
{"episode_reward": 163.30115104946003, "episode": 519.0, "Q1 loss": 6.283928733825683, "Q2 loss": 6.314459575653077, "Mean Target Q": 222.46978283691405, "Mean Q1": 222.47318981933594, "Mean Q2": 222.4731551513672, "critic_loss": 12.598388313293457, "batch_reward": 1.142301646232605, "actor_loss": -223.68003796774244, "actor_target_entropy": -1.0, "actor_entropy": 0.7640060545906188, "alpha_loss": -0.010420910021778019, "alpha_value": 0.24232943416143285, "duration": 158.88771748542786, "step": 64875}
{"episode_reward": 105.10830173424779, "episode": 520.0, "Q1 loss": 6.27371870803833, "Q2 loss": 6.271274242401123, "Mean Target Q": 222.4824881591797, "Mean Q1": 222.47805981445313, "Mean Q2": 222.4777059326172, "critic_loss": 12.54499292755127, "batch_reward": 1.1335799565315248, "actor_loss": -223.6569122806672, "actor_target_entropy": -1.0, "actor_entropy": 0.734981611851723, "alpha_loss": -0.0010304696549991927, "alpha_value": 0.24284138118570567, "step": 65000}
{"duration": 168.47024607658386, "step": 65000}
{"episode_reward": 183.31929377011318, "episode": 521.0, "Q1 loss": 6.356599843978882, "Q2 loss": 6.36055286026001, "Mean Target Q": 222.63692358398438, "Mean Q1": 222.63724462890625, "Mean Q2": 222.63726171875, "critic_loss": 12.717152709960937, "batch_reward": 1.1420721035003663, "actor_loss": -223.94638037303136, "actor_target_entropy": -1.0, "actor_entropy": 0.7464684683179098, "alpha_loss": -0.0012614494337448998, "alpha_value": 0.24295915985237004, "duration": 170.2666094303131, "step": 65125}
{"episode_reward": 183.05104913813153, "episode": 522.0, "Q1 loss": 6.222807861328125, "Q2 loss": 6.215305130004883, "Mean Target Q": 222.74473559570313, "Mean Q1": 222.74832446289062, "Mean Q2": 222.74864978027344, "critic_loss": 12.438112976074219, "batch_reward": 1.1388520765304566, "actor_loss": -224.01687966623615, "actor_target_entropy": -1.0, "actor_entropy": 0.7453521797733922, "alpha_loss": -0.0016121593409127767, "alpha_value": 0.24303450924229983, "duration": 173.43958353996277, "step": 65250}
{"episode_reward": 18.562705854679844, "episode": 523.0, "Q1 loss": 6.28100887298584, "Q2 loss": 6.2858560829162595, "Mean Target Q": 222.8273341064453, "Mean Q1": 222.82453051757813, "Mean Q2": 222.82489477539062, "critic_loss": 12.566864944458008, "batch_reward": 1.1338239421844483, "actor_loss": -224.05435955713665, "actor_target_entropy": -1.0, "actor_entropy": 0.7445643686112904, "alpha_loss": 0.004956844783875914, "alpha_value": 0.24301647614397334, "duration": 173.4614520072937, "step": 65375}
{"episode_reward": 155.11124230374793, "episode": 524.0, "Q1 loss": 6.257922191619873, "Q2 loss": 6.269696800231934, "Mean Target Q": 222.90782543945312, "Mean Q1": 222.90714624023437, "Mean Q2": 222.907171875, "critic_loss": 12.527618911743165, "batch_reward": 1.1350321006774902, "actor_loss": -224.09561649445564, "actor_target_entropy": -1.0, "actor_entropy": 0.7466990688154774, "alpha_loss": 0.009707031061782712, "alpha_value": 0.24230492403028495, "duration": 167.72486329078674, "step": 65500}
{"episode_reward": 113.03788974389653, "episode": 525.0, "Q1 loss": 6.124182960510254, "Q2 loss": 6.131654376983643, "Mean Target Q": 222.9964012451172, "Mean Q1": 222.99462744140624, "Mean Q2": 222.99416955566406, "critic_loss": 12.255837348937987, "batch_reward": 1.1393622007369995, "actor_loss": -224.25557163783483, "actor_target_entropy": -1.0, "actor_entropy": 0.7473426678824047, "alpha_loss": 0.00022543551740310494, "alpha_value": 0.24188814986446452, "duration": 153.83702325820923, "step": 65625}
{"episode_reward": 217.57707707538023, "episode": 526.0, "Q1 loss": 6.393181755065918, "Q2 loss": 6.395127536773682, "Mean Target Q": 223.05256262207033, "Mean Q1": 223.050330078125, "Mean Q2": 223.050455078125, "critic_loss": 12.788309272766114, "batch_reward": 1.1346164569854735, "actor_loss": -224.3414547827936, "actor_target_entropy": -1.0, "actor_entropy": 0.7753543978737246, "alpha_loss": -0.001868588061282231, "alpha_value": 0.2419029121361911, "duration": 163.4068787097931, "step": 65750}
{"episode_reward": 162.0724240786991, "episode": 527.0, "Q1 loss": 6.4962919921875, "Q2 loss": 6.499330898284912, "Mean Target Q": 223.2348056640625, "Mean Q1": 223.2342745361328, "Mean Q2": 223.2343447265625, "critic_loss": 12.995622917175293, "batch_reward": 1.1410346240997316, "actor_loss": -224.51766023181733, "actor_target_entropy": -1.0, "actor_entropy": 0.752169740578485, "alpha_loss": 0.00282036519927224, "alpha_value": 0.24199667485785503, "duration": 162.02020978927612, "step": 65875}
{"episode_reward": 169.1902708905595, "episode": 528.0, "Q1 loss": 6.3954581489562985, "Q2 loss": 6.397648956298828, "Mean Target Q": 223.27013439941408, "Mean Q1": 223.2674659423828, "Mean Q2": 223.2674970703125, "critic_loss": 12.793107093811035, "batch_reward": 1.1371930780410766, "actor_loss": -224.45372181553995, "actor_target_entropy": -1.0, "actor_entropy": 0.7517468323630672, "alpha_loss": 0.0001533848699182272, "alpha_value": 0.24185537126134743, "duration": 184.61925601959229, "step": 66000}
{"episode_reward": 69.02567407973025, "episode": 529.0, "Q1 loss": 6.296177696228027, "Q2 loss": 6.299703802108764, "Mean Target Q": 223.37698669433593, "Mean Q1": 223.374955078125, "Mean Q2": 223.37415197753907, "critic_loss": 12.595881492614746, "batch_reward": 1.1348611345291137, "actor_loss": -224.58647058880518, "actor_target_entropy": -1.0, "actor_entropy": 0.747580761947329, "alpha_loss": -0.005102381686724368, "alpha_value": 0.24196669638821702, "duration": 164.31072664260864, "step": 66125}
{"episode_reward": 199.16265948056463, "episode": 530.0, "Q1 loss": 6.517787399291993, "Q2 loss": 6.536893501281738, "Mean Target Q": 223.45248681640626, "Mean Q1": 223.45220324707032, "Mean Q2": 223.45267834472656, "critic_loss": 13.054680908203125, "batch_reward": 1.1281876010894776, "actor_loss": -224.7105673513105, "actor_target_entropy": -1.0, "actor_entropy": 0.7333632053867463, "alpha_loss": 0.004665674273705771, "alpha_value": 0.24203408685340286, "duration": 152.6400957107544, "step": 66250}
{"episode_reward": 170.5328872340774, "episode": 531.0, "Q1 loss": 6.491440433502198, "Q2 loss": 6.502451595306397, "Mean Target Q": 223.6019822998047, "Mean Q1": 223.60144592285155, "Mean Q2": 223.60115759277343, "critic_loss": 12.993891975402832, "batch_reward": 1.1381492018699646, "actor_loss": -224.77762155684215, "actor_target_entropy": -1.0, "actor_entropy": 0.7469006786270748, "alpha_loss": 0.0029844163236991753, "alpha_value": 0.2418350495991458, "duration": 175.29310822486877, "step": 66375}
{"episode_reward": 215.75283280779928, "episode": 532.0, "Q1 loss": 6.461343948364258, "Q2 loss": 6.453434097290039, "Mean Target Q": 223.64188903808594, "Mean Q1": 223.64367224121094, "Mean Q2": 223.64431799316407, "critic_loss": 12.91477806854248, "batch_reward": 1.1355017690658569, "actor_loss": -224.80221311507685, "actor_target_entropy": -1.0, "actor_entropy": 0.7471629611907467, "alpha_loss": 0.007117362961458463, "alpha_value": 0.24155094948949793, "duration": 161.34939908981323, "step": 66500}
{"episode_reward": 201.19181450434374, "episode": 533.0, "Q1 loss": 5.98026541519165, "Q2 loss": 6.000647123336792, "Mean Target Q": 223.60949645996095, "Mean Q1": 223.60941528320313, "Mean Q2": 223.6090908203125, "critic_loss": 11.980912582397462, "batch_reward": 1.1354365320205688, "actor_loss": -224.78706941150483, "actor_target_entropy": -1.0, "actor_entropy": 0.7222227160892789, "alpha_loss": 0.013642186897673778, "alpha_value": 0.2406918151436972, "duration": 166.98569655418396, "step": 66625}
{"episode_reward": 170.0555628344039, "episode": 534.0, "Q1 loss": 5.831719305038452, "Q2 loss": 5.842012279510498, "Mean Target Q": 223.58985375976562, "Mean Q1": 223.5859276123047, "Mean Q2": 223.585107421875, "critic_loss": 11.673731590270997, "batch_reward": 1.1362062406539917, "actor_loss": -224.6812982866841, "actor_target_entropy": -1.0, "actor_entropy": 0.7451733562254137, "alpha_loss": 0.012141575937294551, "alpha_value": 0.23969370953773586, "duration": 166.26338386535645, "step": 66750}
{"episode_reward": 128.353247815697, "episode": 535.0, "Q1 loss": 6.018875276565551, "Q2 loss": 6.015686779022217, "Mean Target Q": 223.7194611816406, "Mean Q1": 223.71643200683593, "Mean Q2": 223.716951171875, "critic_loss": 12.03456206893921, "batch_reward": 1.139715973854065, "actor_loss": -224.94474065871466, "actor_target_entropy": -1.0, "actor_entropy": 0.7473715231532142, "alpha_loss": 0.003420481214388495, "alpha_value": 0.23898896268110834, "duration": 174.98056530952454, "step": 66875}
{"episode_reward": 104.72861454817362, "episode": 536.0, "Q1 loss": 5.992451221466064, "Q2 loss": 6.013562997817993, "Mean Target Q": 223.7426892089844, "Mean Q1": 223.75133581542968, "Mean Q2": 223.75150866699218, "critic_loss": 12.006014228820801, "batch_reward": 1.1279503965377808, "actor_loss": -224.99888143231792, "actor_target_entropy": -1.0, "actor_entropy": 0.7725291800114417, "alpha_loss": 0.004905102744458183, "alpha_value": 0.2386252206310802, "duration": 200.2864351272583, "step": 67000}
{"episode_reward": 135.8257307076105, "episode": 537.0, "Q1 loss": 6.183401149749756, "Q2 loss": 6.2123701248168945, "Mean Target Q": 223.891609375, "Mean Q1": 223.8815732421875, "Mean Q2": 223.88089758300782, "critic_loss": 12.395771270751952, "batch_reward": 1.1278761548995972, "actor_loss": -225.05356174045139, "actor_target_entropy": -1.0, "actor_entropy": 0.7511913530410282, "alpha_loss": -0.004661294506005351, "alpha_value": 0.23868895169868382, "duration": 186.44204902648926, "step": 67125}
{"episode_reward": 206.38804574484533, "episode": 538.0, "Q1 loss": 6.187366415023804, "Q2 loss": 6.184474603652954, "Mean Target Q": 223.9960302734375, "Mean Q1": 223.99315881347655, "Mean Q2": 223.99387463378906, "critic_loss": 12.371841007232666, "batch_reward": 1.1304173707962035, "actor_loss": -225.29346761395854, "actor_target_entropy": -1.0, "actor_entropy": 0.7659134557170253, "alpha_loss": -0.00043971206046520704, "alpha_value": 0.23897022018649247, "duration": 155.2661097049713, "step": 67250}
{"episode_reward": 167.47413451204392, "episode": 539.0, "Q1 loss": 6.3073080520629885, "Q2 loss": 6.311725770950317, "Mean Target Q": 224.17296667480468, "Mean Q1": 224.17318286132812, "Mean Q2": 224.171703125, "critic_loss": 12.619033821105957, "batch_reward": 1.152831148147583, "actor_loss": -225.44144669790117, "actor_target_entropy": -1.0, "actor_entropy": 0.734354901881445, "alpha_loss": 0.013233342727217528, "alpha_value": 0.23856507680723077, "duration": 147.73795890808105, "step": 67375}
{"episode_reward": 187.9087628235308, "episode": 540.0, "Q1 loss": 6.57674729347229, "Q2 loss": 6.581456859588623, "Mean Target Q": 224.2443719482422, "Mean Q1": 224.24540258789062, "Mean Q2": 224.2465104980469, "critic_loss": 13.158204132080078, "batch_reward": 1.1352097492218018, "actor_loss": -225.40772567256803, "actor_target_entropy": -1.0, "actor_entropy": 0.7250427497971442, "alpha_loss": 0.0025921945888248664, "alpha_value": 0.23800792670435972, "duration": 159.00071740150452, "step": 67500}
{"episode_reward": 132.2076461889979, "episode": 541.0, "Q1 loss": 6.3004958152771, "Q2 loss": 6.288390022277832, "Mean Target Q": 224.23937805175783, "Mean Q1": 224.24053491210938, "Mean Q2": 224.24063745117186, "critic_loss": 12.588885879516601, "batch_reward": 1.1439043073654174, "actor_loss": -225.39404127332898, "actor_target_entropy": -1.0, "actor_entropy": 0.7311698340234303, "alpha_loss": 0.009866733425518586, "alpha_value": 0.23745334882364919, "duration": 158.4741015434265, "step": 67625}
{"episode_reward": 181.35422658406944, "episode": 542.0, "Q1 loss": 6.0247269515991215, "Q2 loss": 6.049906923294067, "Mean Target Q": 224.27527783203124, "Mean Q1": 224.27032373046876, "Mean Q2": 224.27014477539063, "critic_loss": 12.07463385772705, "batch_reward": 1.1391723976135253, "actor_loss": -225.4668721845073, "actor_target_entropy": -1.0, "actor_entropy": 0.7283142324416868, "alpha_loss": 0.011288639634937769, "alpha_value": 0.23678504317884141, "duration": 142.45300936698914, "step": 67750}
{"episode_reward": 79.11153996117656, "episode": 543.0, "Q1 loss": 5.911773639678955, "Q2 loss": 5.9247693405151365, "Mean Target Q": 224.26656799316407, "Mean Q1": 224.27085314941405, "Mean Q2": 224.2705216064453, "critic_loss": 11.83654303741455, "batch_reward": 1.1382964329719543, "actor_loss": -225.39599972679503, "actor_target_entropy": -1.0, "actor_entropy": 0.71493780518335, "alpha_loss": 0.0031337276034589323, "alpha_value": 0.23629119423925654, "duration": 133.87962746620178, "step": 67875}
{"episode_reward": 139.90245180702894, "episode": 544.0, "Q1 loss": 6.1864437561035155, "Q2 loss": 6.182170816421509, "Mean Target Q": 224.44240515136718, "Mean Q1": 224.43900085449218, "Mean Q2": 224.43958068847655, "critic_loss": 12.368614585876465, "batch_reward": 1.1475911331176758, "actor_loss": -225.68345248314643, "actor_target_entropy": -1.0, "actor_entropy": 0.7421564728982987, "alpha_loss": 0.005164289584143027, "alpha_value": 0.23582282001371027, "duration": 138.42849898338318, "step": 68000}
{"episode_reward": 269.93184930554844, "episode": 545.0, "Q1 loss": 5.853627059936524, "Q2 loss": 5.8854385833740235, "Mean Target Q": 224.34398889160155, "Mean Q1": 224.3422471923828, "Mean Q2": 224.34202917480468, "critic_loss": 11.73906559753418, "batch_reward": 1.1387319054603577, "actor_loss": -225.5890839591859, "actor_target_entropy": -1.0, "actor_entropy": 0.7232864934300619, "alpha_loss": 0.003840862825098965, "alpha_value": 0.23567413541695406, "duration": 152.448317527771, "step": 68125}
{"episode_reward": 205.57964153220104, "episode": 546.0, "Q1 loss": 6.193745971679688, "Q2 loss": 6.184060214996338, "Mean Target Q": 224.51217919921876, "Mean Q1": 224.5101662597656, "Mean Q2": 224.51010424804687, "critic_loss": 12.377806144714356, "batch_reward": 1.143536862373352, "actor_loss": -225.79325374480217, "actor_target_entropy": -1.0, "actor_entropy": 0.7361628768905517, "alpha_loss": 0.0002734789722448876, "alpha_value": 0.2355762814361381, "duration": 132.28282570838928, "step": 68250}
{"episode_reward": 116.92776219045514, "episode": 547.0, "Q1 loss": 6.188305980682373, "Q2 loss": 6.213787910461426, "Mean Target Q": 224.56267895507813, "Mean Q1": 224.5616824951172, "Mean Q2": 224.5615390625, "critic_loss": 12.402093879699708, "batch_reward": 1.1442663679122924, "actor_loss": -225.79027399941097, "actor_target_entropy": -1.0, "actor_entropy": 0.7304910591670445, "alpha_loss": 0.001039502639619131, "alpha_value": 0.2353938320594221, "duration": 138.19989800453186, "step": 68375}
{"episode_reward": 101.93365188938425, "episode": 548.0, "Q1 loss": 6.122199800491333, "Q2 loss": 6.128556596755981, "Mean Target Q": 224.74002392578126, "Mean Q1": 224.73899426269531, "Mean Q2": 224.73949096679686, "critic_loss": 12.250756370544433, "batch_reward": 1.132838110923767, "actor_loss": -225.95723822809035, "actor_target_entropy": -1.0, "actor_entropy": 0.7420796059793041, "alpha_loss": -0.004055727678801744, "alpha_value": 0.23554660373137892, "duration": 139.68375754356384, "step": 68500}
{"episode_reward": 147.88500850614417, "episode": 549.0, "Q1 loss": 6.0880663833618165, "Q2 loss": 6.097445999145508, "Mean Target Q": 224.76460473632812, "Mean Q1": 224.76635876464843, "Mean Q2": 224.7660947265625, "critic_loss": 12.185512363433839, "batch_reward": 1.152550630569458, "actor_loss": -225.92261710999503, "actor_target_entropy": -1.0, "actor_entropy": 0.7520946415643843, "alpha_loss": -0.0004580293685966541, "alpha_value": 0.23566809775678824, "duration": 152.42457342147827, "step": 68625}
{"episode_reward": 92.19572064891291, "episode": 550.0, "Q1 loss": 5.930122573852539, "Q2 loss": 5.953015022277832, "Mean Target Q": 224.79360607910155, "Mean Q1": 224.7913533935547, "Mean Q2": 224.7914677734375, "critic_loss": 11.883137573242188, "batch_reward": 1.1395682830810547, "actor_loss": -226.0596963205645, "actor_target_entropy": -1.0, "actor_entropy": 0.7439835696451126, "alpha_loss": 0.006192161296043665, "alpha_value": 0.23546133791474816, "duration": 145.30259442329407, "step": 68750}
{"episode_reward": 142.59352758407198, "episode": 551.0, "Q1 loss": 6.2161710243225095, "Q2 loss": 6.2039648647308345, "Mean Target Q": 224.84934020996093, "Mean Q1": 224.8461444091797, "Mean Q2": 224.8461982421875, "critic_loss": 12.42013585281372, "batch_reward": 1.1343102979660034, "actor_loss": -226.02970547146268, "actor_target_entropy": -1.0, "actor_entropy": 0.7464457693554106, "alpha_loss": 0.00466281138471372, "alpha_value": 0.23525859208666822, "duration": 163.9620761871338, "step": 68875}
{"episode_reward": 41.00026465172797, "episode": 552.0, "Q1 loss": 6.110228321075439, "Q2 loss": 6.140971908569336, "Mean Target Q": 224.96018298339843, "Mean Q1": 224.96284814453125, "Mean Q2": 224.96233935546874, "critic_loss": 12.251200233459473, "batch_reward": 1.1430837383270265, "actor_loss": -226.10143181585497, "actor_target_entropy": -1.0, "actor_entropy": 0.7418910178446001, "alpha_loss": 0.00741981971077621, "alpha_value": 0.23452361480355885, "duration": 155.8564429283142, "step": 69000}
{"episode_reward": 57.53023167906025, "episode": 553.0, "Q1 loss": 5.996881378173828, "Q2 loss": 6.00058634185791, "Mean Target Q": 224.87384228515626, "Mean Q1": 224.862865234375, "Mean Q2": 224.86339636230468, "critic_loss": 11.99746768951416, "batch_reward": 1.1402669305801392, "actor_loss": -226.12817964099702, "actor_target_entropy": -1.0, "actor_entropy": 0.7397552652964516, "alpha_loss": 0.0037238491876494316, "alpha_value": 0.2342079101718642, "duration": 136.2981722354889, "step": 69125}
{"episode_reward": 191.85508432981032, "episode": 554.0, "Q1 loss": 5.681282457351685, "Q2 loss": 5.683057466506958, "Mean Target Q": 225.0366922607422, "Mean Q1": 225.04443542480467, "Mean Q2": 225.04349633789062, "critic_loss": 11.364339935302734, "batch_reward": 1.1435405950546265, "actor_loss": -226.26391257009197, "actor_target_entropy": -1.0, "actor_entropy": 0.7444063059745296, "alpha_loss": 0.0019816501111152673, "alpha_value": 0.23400627789772474, "duration": 118.36849808692932, "step": 69250}
{"episode_reward": 130.61352425317804, "episode": 555.0, "Q1 loss": 6.009928295135498, "Q2 loss": 6.010403770446778, "Mean Target Q": 225.09083239746093, "Mean Q1": 225.09128747558594, "Mean Q2": 225.0912841796875, "critic_loss": 12.02033207321167, "batch_reward": 1.1372471809387208, "actor_loss": -226.29876830085877, "actor_target_entropy": -1.0, "actor_entropy": 0.7188377758813282, "alpha_loss": 0.0016314464931686719, "alpha_value": 0.23406807308675195, "duration": 126.13258385658264, "step": 69375}
{"episode_reward": 85.16242008266754, "episode": 556.0, "Q1 loss": 6.279125610351563, "Q2 loss": 6.292664497375489, "Mean Target Q": 225.29619165039063, "Mean Q1": 225.29398059082033, "Mean Q2": 225.29432653808593, "critic_loss": 12.571790130615234, "batch_reward": 1.1443386702537537, "actor_loss": -226.70183760120022, "actor_target_entropy": -1.0, "actor_entropy": 0.7182085812091827, "alpha_loss": -0.010733229262123426, "alpha_value": 0.2342198955961605, "duration": 150.7120921611786, "step": 69500}
{"episode_reward": 137.4115693456302, "episode": 557.0, "Q1 loss": 6.764643123626709, "Q2 loss": 6.766891151428223, "Mean Target Q": 225.41871862792968, "Mean Q1": 225.4126512451172, "Mean Q2": 225.412693359375, "critic_loss": 13.531534255981445, "batch_reward": 1.1400976905822753, "actor_loss": -226.7324487595331, "actor_target_entropy": -1.0, "actor_entropy": 0.7386417303766523, "alpha_loss": -0.0009256863101784672, "alpha_value": 0.2347669434074085, "duration": 147.65808296203613, "step": 69625}
{"episode_reward": 127.18203440190685, "episode": 558.0, "Q1 loss": 6.608513568878174, "Q2 loss": 6.597096673965454, "Mean Target Q": 225.53194909667968, "Mean Q1": 225.53403479003907, "Mean Q2": 225.53358471679687, "critic_loss": 13.205610237121583, "batch_reward": 1.1428004293441771, "actor_loss": -226.7873298891129, "actor_target_entropy": -1.0, "actor_entropy": 0.7365509733077018, "alpha_loss": -0.0037352337441857782, "alpha_value": 0.23474972854597173, "duration": 126.44669151306152, "step": 69750}
{"episode_reward": 135.5640525818776, "episode": 559.0, "Q1 loss": 6.839771198272705, "Q2 loss": 6.849851913452149, "Mean Target Q": 225.60204724121093, "Mean Q1": 225.60125903320312, "Mean Q2": 225.60175939941405, "critic_loss": 13.689623046875, "batch_reward": 1.1387027883529663, "actor_loss": -226.85218253968253, "actor_target_entropy": -1.0, "actor_entropy": 0.7077081998189291, "alpha_loss": -0.0015277390124364978, "alpha_value": 0.23506304978700582, "duration": 132.7290322780609, "step": 69875}
{"episode_reward": 104.01341003338706, "episode": 560.0, "Q1 loss": 6.56591194152832, "Q2 loss": 6.548095722198486, "Mean Target Q": 225.65667321777343, "Mean Q1": 225.65793237304686, "Mean Q2": 225.657048828125, "critic_loss": 13.114007671356202, "batch_reward": 1.1438555393218994, "actor_loss": -226.8645250874181, "actor_target_entropy": -1.0, "actor_entropy": 0.7441561087485282, "alpha_loss": 0.004405984104866342, "alpha_value": 0.2349442272508118, "step": 70000}
{"duration": 177.54550576210022, "step": 70000}
{"episode_reward": 166.43169025143615, "episode": 561.0, "Q1 loss": 6.56446070098877, "Q2 loss": 6.564229305267334, "Mean Target Q": 225.65204040527342, "Mean Q1": 225.65288610839843, "Mean Q2": 225.65323303222655, "critic_loss": 13.128689971923828, "batch_reward": 1.144047929763794, "actor_loss": -226.87477281358508, "actor_target_entropy": -1.0, "actor_entropy": 0.7225478215823098, "alpha_loss": -0.0016415876572922108, "alpha_value": 0.234818308013814, "duration": 160.52687096595764, "step": 70125}
{"episode_reward": 108.69696029227785, "episode": 562.0, "Q1 loss": 6.408208404541016, "Q2 loss": 6.425561893463135, "Mean Target Q": 225.75900854492187, "Mean Q1": 225.75209545898437, "Mean Q2": 225.75198498535156, "critic_loss": 12.833770317077636, "batch_reward": 1.1366780347824097, "actor_loss": -227.04864083566974, "actor_target_entropy": -1.0, "actor_entropy": 0.734181692523341, "alpha_loss": -0.0025345172898303117, "alpha_value": 0.2350283703189504, "duration": 146.20548129081726, "step": 70250}
{"episode_reward": 153.12962357186262, "episode": 563.0, "Q1 loss": 6.452991512298584, "Q2 loss": 6.467140956878662, "Mean Target Q": 225.91496350097657, "Mean Q1": 225.91711450195314, "Mean Q2": 225.9171572265625, "critic_loss": 12.920132453918457, "batch_reward": 1.1396033821105958, "actor_loss": -227.2044442797464, "actor_target_entropy": -1.0, "actor_entropy": 0.7430054214265611, "alpha_loss": -0.005542142811926111, "alpha_value": 0.23548802723534226, "duration": 161.41003561019897, "step": 70375}
{"episode_reward": 181.4138202748145, "episode": 564.0, "Q1 loss": 6.353640319824219, "Q2 loss": 6.377130123138428, "Mean Target Q": 225.90471508789062, "Mean Q1": 225.90781921386719, "Mean Q2": 225.90737817382814, "critic_loss": 12.730770500183105, "batch_reward": 1.138070966720581, "actor_loss": -227.1383819580078, "actor_target_entropy": -1.0, "actor_entropy": 0.724620541257243, "alpha_loss": -0.007767323787594514, "alpha_value": 0.23565370415917164, "duration": 125.82200694084167, "step": 70500}
{"episode_reward": 165.0801702749521, "episode": 565.0, "Q1 loss": 6.473539279937744, "Q2 loss": 6.492097082138062, "Mean Target Q": 226.05243054199218, "Mean Q1": 226.0483662109375, "Mean Q2": 226.04867614746092, "critic_loss": 12.965636360168457, "batch_reward": 1.1322898602485656, "actor_loss": -227.25892857142858, "actor_target_entropy": -1.0, "actor_entropy": 0.7256804761432466, "alpha_loss": -0.0008498741838607997, "alpha_value": 0.23621550277501335, "duration": 134.9437346458435, "step": 70625}
{"episode_reward": 165.38934870213095, "episode": 566.0, "Q1 loss": 6.149389938354492, "Q2 loss": 6.157006637573242, "Mean Target Q": 226.19062731933593, "Mean Q1": 226.1914835205078, "Mean Q2": 226.1911387939453, "critic_loss": 12.306396560668945, "batch_reward": 1.143025864124298, "actor_loss": -227.41690875637917, "actor_target_entropy": -1.0, "actor_entropy": 0.7237504855279, "alpha_loss": -0.001298715901230612, "alpha_value": 0.2362044207688895, "duration": 148.08406281471252, "step": 70750}
{"episode_reward": 125.3346759494553, "episode": 567.0, "Q1 loss": 6.734038852691651, "Q2 loss": 6.72374471282959, "Mean Target Q": 226.32050952148438, "Mean Q1": 226.31633178710936, "Mean Q2": 226.31674768066407, "critic_loss": 13.457783599853515, "batch_reward": 1.13618936252594, "actor_loss": -227.5586959596664, "actor_target_entropy": -1.0, "actor_entropy": 0.7120208740234375, "alpha_loss": -0.006807725178077817, "alpha_value": 0.23647064461041548, "duration": 150.4503879547119, "step": 70875}
{"episode_reward": 89.46088883413762, "episode": 568.0, "Q1 loss": 6.692446384429932, "Q2 loss": 6.693810235977173, "Mean Target Q": 226.30033422851562, "Mean Q1": 226.2950703125, "Mean Q2": 226.29515893554688, "critic_loss": 13.386256637573242, "batch_reward": 1.1351026458740234, "actor_loss": -227.4325440929782, "actor_target_entropy": -1.0, "actor_entropy": 0.744721511679311, "alpha_loss": 0.004810369258085566, "alpha_value": 0.23651033277160305, "duration": 138.19515919685364, "step": 71000}
{"episode_reward": 138.43848828379205, "episode": 569.0, "Q1 loss": 6.763701917648316, "Q2 loss": 6.777021953582763, "Mean Target Q": 226.36852600097657, "Mean Q1": 226.37399938964845, "Mean Q2": 226.37296923828126, "critic_loss": 13.540723869323731, "batch_reward": 1.1362515964508058, "actor_loss": -227.56985740056115, "actor_target_entropy": -1.0, "actor_entropy": 0.7447719413136679, "alpha_loss": -0.007007769482683331, "alpha_value": 0.23663095733699094, "duration": 125.97139620780945, "step": 71125}
{"episode_reward": 45.53877270098522, "episode": 570.0, "Q1 loss": 6.228260187149048, "Q2 loss": 6.225672035217285, "Mean Target Q": 226.45872314453126, "Mean Q1": 226.45532116699218, "Mean Q2": 226.45640856933593, "critic_loss": 12.453932189941407, "batch_reward": 1.1352302942276, "actor_loss": -227.6186041062878, "actor_target_entropy": -1.0, "actor_entropy": 0.7519125409664646, "alpha_loss": 0.0061280358650331055, "alpha_value": 0.23670001778497837, "duration": 133.02412033081055, "step": 71250}
{"episode_reward": 163.90106378916508, "episode": 571.0, "Q1 loss": 6.382544834136963, "Q2 loss": 6.392178787231446, "Mean Target Q": 226.53836108398437, "Mean Q1": 226.53925134277344, "Mean Q2": 226.53922985839844, "critic_loss": 12.774723556518556, "batch_reward": 1.1438133716583252, "actor_loss": -227.7623559860956, "actor_target_entropy": -1.0, "actor_entropy": 0.7555101021887765, "alpha_loss": -0.003823979336413599, "alpha_value": 0.23651263869611563, "duration": 146.49201130867004, "step": 71375}
{"episode_reward": 134.60863618926115, "episode": 572.0, "Q1 loss": 6.2741695022583, "Q2 loss": 6.307331649780274, "Mean Target Q": 226.63218322753906, "Mean Q1": 226.63282507324217, "Mean Q2": 226.6321407470703, "critic_loss": 12.581501106262207, "batch_reward": 1.1344524660110473, "actor_loss": -227.94492093978388, "actor_target_entropy": -1.0, "actor_entropy": 0.7186243284133172, "alpha_loss": 0.002104375302986873, "alpha_value": 0.23664760593186396, "duration": 156.7529501914978, "step": 71500}
{"episode_reward": 116.20982496471542, "episode": 573.0, "Q1 loss": 6.237259231567383, "Q2 loss": 6.240908842086792, "Mean Target Q": 226.71206433105468, "Mean Q1": 226.707771484375, "Mean Q2": 226.70817333984374, "critic_loss": 12.478168029785156, "batch_reward": 1.144112147331238, "actor_loss": -227.91399129231772, "actor_target_entropy": -1.0, "actor_entropy": 0.7362032542153011, "alpha_loss": -0.002749519186123969, "alpha_value": 0.23677236228605378, "duration": 146.02989292144775, "step": 71625}
{"episode_reward": 155.07638882763845, "episode": 574.0, "Q1 loss": 5.984264307022094, "Q2 loss": 5.991955146789551, "Mean Target Q": 226.72374035644532, "Mean Q1": 226.72150817871093, "Mean Q2": 226.72096496582031, "critic_loss": 11.97621939086914, "batch_reward": 1.1401627535820007, "actor_loss": -227.9610829507151, "actor_target_entropy": -1.0, "actor_entropy": 0.7545331812674, "alpha_loss": 8.647831817788463e-05, "alpha_value": 0.23698067277246104, "duration": 150.29839730262756, "step": 71750}
{"episode_reward": 156.06498641441428, "episode": 575.0, "Q1 loss": 6.213469552993774, "Q2 loss": 6.221631381988526, "Mean Target Q": 226.86511633300782, "Mean Q1": 226.8677216796875, "Mean Q2": 226.8675576171875, "critic_loss": 12.435100914001465, "batch_reward": 1.1360748748779297, "actor_loss": -228.0997779482887, "actor_target_entropy": -1.0, "actor_entropy": 0.7135172656604222, "alpha_loss": -0.002079884299919719, "alpha_value": 0.23698854133746375, "duration": 153.55577397346497, "step": 71875}
{"episode_reward": 200.02390464935294, "episode": 576.0, "Q1 loss": 6.287164108276367, "Q2 loss": 6.287415008544922, "Mean Target Q": 226.99340222167967, "Mean Q1": 226.9937216796875, "Mean Q2": 226.9938193359375, "critic_loss": 12.574579067230225, "batch_reward": 1.1257962245941162, "actor_loss": -228.33027821202433, "actor_target_entropy": -1.0, "actor_entropy": 0.7176713126320993, "alpha_loss": 0.0009527035834898631, "alpha_value": 0.2367703270527605, "duration": 121.7225489616394, "step": 72000}
{"episode_reward": 147.7912882013835, "episode": 577.0, "Q1 loss": 6.7063054237365725, "Q2 loss": 6.7432632217407225, "Mean Target Q": 227.08960913085937, "Mean Q1": 227.08307055664062, "Mean Q2": 227.08348303222655, "critic_loss": 13.44956869506836, "batch_reward": 1.1366628351211547, "actor_loss": -228.36522105383494, "actor_target_entropy": -1.0, "actor_entropy": 0.7200058745959449, "alpha_loss": -0.008686698862307128, "alpha_value": 0.2371099301383153, "duration": 142.2358536720276, "step": 72125}
{"episode_reward": 215.36919677067883, "episode": 578.0, "Q1 loss": 6.668864822387695, "Q2 loss": 6.6713958244323734, "Mean Target Q": 227.27368566894532, "Mean Q1": 227.2749462890625, "Mean Q2": 227.27471228027343, "critic_loss": 13.340260635375977, "batch_reward": 1.1351966314315796, "actor_loss": -228.5249478740077, "actor_target_entropy": -1.0, "actor_entropy": 0.7426228802050313, "alpha_loss": 0.003380606649443507, "alpha_value": 0.2373813650153262, "duration": 145.77719473838806, "step": 72250}
{"episode_reward": 44.565612842530605, "episode": 579.0, "Q1 loss": 6.593586685180664, "Q2 loss": 6.60304275894165, "Mean Target Q": 227.26724719238283, "Mean Q1": 227.26817590332033, "Mean Q2": 227.26780895996095, "critic_loss": 13.196629470825195, "batch_reward": 1.1308690075874328, "actor_loss": -228.48841325063555, "actor_target_entropy": -1.0, "actor_entropy": 0.7402747207217746, "alpha_loss": 0.004180967983316689, "alpha_value": 0.2370945182419177, "duration": 143.87740421295166, "step": 72375}
{"episode_reward": 145.32000736737882, "episode": 580.0, "Q1 loss": 6.448965000152588, "Q2 loss": 6.450098598480225, "Mean Target Q": 227.29734289550782, "Mean Q1": 227.29422045898437, "Mean Q2": 227.29443969726563, "critic_loss": 12.899063613891602, "batch_reward": 1.1324055843353271, "actor_loss": -228.56896529659147, "actor_target_entropy": -1.0, "actor_entropy": 0.7502969849494195, "alpha_loss": 0.0020028878108508162, "alpha_value": 0.23684516295010863, "duration": 152.37114548683167, "step": 72500}
{"episode_reward": 136.9078278816368, "episode": 581.0, "Q1 loss": 6.236308776855469, "Q2 loss": 6.246467710494995, "Mean Target Q": 227.36717651367186, "Mean Q1": 227.36910986328124, "Mean Q2": 227.36896875, "critic_loss": 12.482776504516602, "batch_reward": 1.1265099229812623, "actor_loss": -228.596920437283, "actor_target_entropy": -1.0, "actor_entropy": 0.7502471728930398, "alpha_loss": 0.004414073995403236, "alpha_value": 0.23654294036550105, "duration": 150.20129585266113, "step": 72625}
{"episode_reward": 144.73901772845892, "episode": 582.0, "Q1 loss": 6.514292949676514, "Q2 loss": 6.52759264755249, "Mean Target Q": 227.48930639648438, "Mean Q1": 227.48400988769532, "Mean Q2": 227.48394055175783, "critic_loss": 13.041885631561279, "batch_reward": 1.1327452850341797, "actor_loss": -228.7883571501701, "actor_target_entropy": -1.0, "actor_entropy": 0.7072676958576325, "alpha_loss": 0.0021708881212097984, "alpha_value": 0.23644252873017088, "duration": 147.3556067943573, "step": 72750}
{"episode_reward": 150.91618976416484, "episode": 583.0, "Q1 loss": 6.259350700378418, "Q2 loss": 6.253649250030517, "Mean Target Q": 227.5633074951172, "Mean Q1": 227.56358532714845, "Mean Q2": 227.56345153808593, "critic_loss": 12.512999969482422, "batch_reward": 1.1377261986732483, "actor_loss": -228.77584402901786, "actor_target_entropy": -1.0, "actor_entropy": 0.7358301281929016, "alpha_loss": 0.005239642465427991, "alpha_value": 0.23603018219928706, "duration": 153.7432451248169, "step": 72875}
{"episode_reward": 104.8513883477654, "episode": 584.0, "Q1 loss": 6.433700077056884, "Q2 loss": 6.433990089416504, "Mean Target Q": 227.6247502441406, "Mean Q1": 227.6205075683594, "Mean Q2": 227.62024096679687, "critic_loss": 12.867690158843994, "batch_reward": 1.1392816505432128, "actor_loss": -228.87943981539817, "actor_target_entropy": -1.0, "actor_entropy": 0.722353765080052, "alpha_loss": -0.0008187773487260265, "alpha_value": 0.23599582331292426, "duration": 144.19183993339539, "step": 73000}
{"episode_reward": 193.9723145485131, "episode": 585.0, "Q1 loss": 6.585967937469483, "Q2 loss": 6.604301887512207, "Mean Target Q": 227.6703427734375, "Mean Q1": 227.67380505371094, "Mean Q2": 227.6740321044922, "critic_loss": 13.190269813537597, "batch_reward": 1.1334059619903565, "actor_loss": -228.88562883649553, "actor_target_entropy": -1.0, "actor_entropy": 0.716049001330421, "alpha_loss": 0.007445092579083783, "alpha_value": 0.2358267394211736, "duration": 150.9677255153656, "step": 73125}
{"episode_reward": 157.06407100780055, "episode": 586.0, "Q1 loss": 6.560250762939453, "Q2 loss": 6.547597423553467, "Mean Target Q": 227.82498388671874, "Mean Q1": 227.82133251953124, "Mean Q2": 227.821583984375, "critic_loss": 13.107848178863525, "batch_reward": 1.1377018003463746, "actor_loss": -229.09143755512852, "actor_target_entropy": -1.0, "actor_entropy": 0.7015264822590735, "alpha_loss": 0.002568595693446696, "alpha_value": 0.23532675438150938, "duration": 152.36188054084778, "step": 73250}
{"episode_reward": 18.382737418618593, "episode": 587.0, "Q1 loss": 6.455180688858032, "Q2 loss": 6.465562015533448, "Mean Target Q": 227.82413122558594, "Mean Q1": 227.82700256347655, "Mean Q2": 227.82642028808593, "critic_loss": 12.920742698669434, "batch_reward": 1.1335607166290282, "actor_loss": -229.02136714874752, "actor_target_entropy": -1.0, "actor_entropy": 0.730783150309608, "alpha_loss": 0.002835963462804636, "alpha_value": 0.23519428519037017, "duration": 150.9681658744812, "step": 73375}
{"episode_reward": 88.38199210707242, "episode": 588.0, "Q1 loss": 6.2633436508178715, "Q2 loss": 6.2910070343017575, "Mean Target Q": 227.87551147460937, "Mean Q1": 227.87704064941406, "Mean Q2": 227.87744030761718, "critic_loss": 12.554350708007812, "batch_reward": 1.1267827725410462, "actor_loss": -229.06343127835183, "actor_target_entropy": -1.0, "actor_entropy": 0.72362436113819, "alpha_loss": 0.005016118363146821, "alpha_value": 0.234871938017709, "duration": 145.84879779815674, "step": 73500}
{"episode_reward": 73.78873078223315, "episode": 589.0, "Q1 loss": 6.598539962768554, "Q2 loss": 6.598584770202637, "Mean Target Q": 227.9491875, "Mean Q1": 227.9486135253906, "Mean Q2": 227.94866735839844, "critic_loss": 13.19712467956543, "batch_reward": 1.1320123109817506, "actor_loss": -229.2251717703683, "actor_target_entropy": -1.0, "actor_entropy": 0.7353586545066227, "alpha_loss": -0.001340040075962269, "alpha_value": 0.2346552051134161, "duration": 149.30104994773865, "step": 73625}
{"episode_reward": 114.60857794677787, "episode": 590.0, "Q1 loss": 6.970960430145263, "Q2 loss": 6.971623287200928, "Mean Target Q": 228.11881787109374, "Mean Q1": 228.1168156738281, "Mean Q2": 228.1170047607422, "critic_loss": 13.942583724975586, "batch_reward": 1.1359833421707153, "actor_loss": -229.41050424883443, "actor_target_entropy": -1.0, "actor_entropy": 0.7337552818559832, "alpha_loss": -0.005336427877116348, "alpha_value": 0.2349917782094569, "duration": 153.5423424243927, "step": 73750}
{"episode_reward": 213.38504091787766, "episode": 591.0, "Q1 loss": 6.620609836578369, "Q2 loss": 6.637682861328125, "Mean Target Q": 228.16870922851564, "Mean Q1": 228.16309558105468, "Mean Q2": 228.16311169433592, "critic_loss": 13.258292701721192, "batch_reward": 1.136671654701233, "actor_loss": -229.43624102880085, "actor_target_entropy": -1.0, "actor_entropy": 0.7163949476348029, "alpha_loss": 0.0027568802156204743, "alpha_value": 0.23484017762284082, "duration": 145.2943398952484, "step": 73875}
{"episode_reward": 180.64568301766644, "episode": 592.0, "Q1 loss": 6.6581550941467285, "Q2 loss": 6.6535650177001955, "Mean Target Q": 228.21594372558593, "Mean Q1": 228.21904028320313, "Mean Q2": 228.21856860351562, "critic_loss": 13.311720085144042, "batch_reward": 1.1350018768310546, "actor_loss": -229.43872513309603, "actor_target_entropy": -1.0, "actor_entropy": 0.7223236089752566, "alpha_loss": -0.0062556623222096075, "alpha_value": 0.2350954194355578, "duration": 147.34373807907104, "step": 74000}
{"episode_reward": 153.05343032197501, "episode": 593.0, "Q1 loss": 6.501419803619385, "Q2 loss": 6.513128372192383, "Mean Target Q": 228.26900708007813, "Mean Q1": 228.26615283203125, "Mean Q2": 228.26693725585938, "critic_loss": 13.014548118591309, "batch_reward": 1.135291181564331, "actor_loss": -229.53287590874567, "actor_target_entropy": -1.0, "actor_entropy": 0.7204609409211173, "alpha_loss": 0.003139561931011341, "alpha_value": 0.23517004466978733, "duration": 146.89976453781128, "step": 74125}
{"episode_reward": 163.09493478767578, "episode": 594.0, "Q1 loss": 6.324375993728638, "Q2 loss": 6.338457824707032, "Mean Target Q": 228.4186688232422, "Mean Q1": 228.40980529785156, "Mean Q2": 228.408880859375, "critic_loss": 12.66283383178711, "batch_reward": 1.1382846336364747, "actor_loss": -229.6522453061996, "actor_target_entropy": -1.0, "actor_entropy": 0.7421423677475222, "alpha_loss": 0.005487906766281794, "alpha_value": 0.23503759668631113, "duration": 149.44813919067383, "step": 74250}
{"episode_reward": 190.74356603943755, "episode": 595.0, "Q1 loss": 6.7604703559875485, "Q2 loss": 6.773577045440674, "Mean Target Q": 228.41811950683595, "Mean Q1": 228.4236611328125, "Mean Q2": 228.42347827148438, "critic_loss": 13.534047401428223, "batch_reward": 1.1271338205337524, "actor_loss": -229.65088302370103, "actor_target_entropy": -1.0, "actor_entropy": 0.7353354228867425, "alpha_loss": 0.005513502257166519, "alpha_value": 0.23456561057072733, "duration": 145.36086177825928, "step": 74375}
{"episode_reward": 70.93241928059837, "episode": 596.0, "Q1 loss": 6.402709232330322, "Q2 loss": 6.410179340362549, "Mean Target Q": 228.43602062988282, "Mean Q1": 228.43406274414062, "Mean Q2": 228.43427600097655, "critic_loss": 12.81288856124878, "batch_reward": 1.1307281646728515, "actor_loss": -229.71705258277154, "actor_target_entropy": -1.0, "actor_entropy": 0.7268524948627718, "alpha_loss": 0.013190286545713822, "alpha_value": 0.23395016520562995, "duration": 142.77144384384155, "step": 74500}
{"episode_reward": 107.3144629760414, "episode": 597.0, "Q1 loss": 6.354138710021973, "Q2 loss": 6.359398750305176, "Mean Target Q": 228.53766857910156, "Mean Q1": 228.5367811279297, "Mean Q2": 228.536646484375, "critic_loss": 12.713537399291992, "batch_reward": 1.1342127294540405, "actor_loss": -229.8071536109561, "actor_target_entropy": -1.0, "actor_entropy": 0.7114426578794207, "alpha_loss": 0.006158807891465369, "alpha_value": 0.2329995405719972, "duration": 137.78750228881836, "step": 74625}
{"episode_reward": 136.76636266051023, "episode": 598.0, "Q1 loss": 6.3319452857971195, "Q2 loss": 6.3480218887329105, "Mean Target Q": 228.49929553222657, "Mean Q1": 228.49879553222655, "Mean Q2": 228.49878173828125, "critic_loss": 12.679967185974121, "batch_reward": 1.1205134658813476, "actor_loss": -229.7323214623236, "actor_target_entropy": -1.0, "actor_entropy": 0.7160417812485849, "alpha_loss": 0.0021949780413941028, "alpha_value": 0.23266717737247794, "duration": 138.26719045639038, "step": 74750}
{"episode_reward": 102.93797651135093, "episode": 599.0, "Q1 loss": 6.165632438659668, "Q2 loss": 6.185544395446778, "Mean Target Q": 228.6314119873047, "Mean Q1": 228.6300919189453, "Mean Q2": 228.62999462890625, "critic_loss": 12.351176864624023, "batch_reward": 1.1264544768333435, "actor_loss": -229.79544164264013, "actor_target_entropy": -1.0, "actor_entropy": 0.7169095703533718, "alpha_loss": -0.003318234280283962, "alpha_value": 0.2329078723646041, "duration": 134.27227544784546, "step": 74875}
{"episode_reward": 42.08285050066169, "episode": 600.0, "Q1 loss": 6.142509067535401, "Q2 loss": 6.1527000999450685, "Mean Target Q": 228.7631953125, "Mean Q1": 228.76402563476563, "Mean Q2": 228.76350378417968, "critic_loss": 12.295209144592285, "batch_reward": 1.1327841591835022, "actor_loss": -230.02207528391193, "actor_target_entropy": -1.0, "actor_entropy": 0.7201623397488748, "alpha_loss": 0.002048010915337551, "alpha_value": 0.23290640766540255, "step": 75000}
{"duration": 155.81948399543762, "step": 75000}
{"episode_reward": 170.89769398499257, "episode": 601.0, "Q1 loss": 6.269512001037597, "Q2 loss": 6.284707565307617, "Mean Target Q": 228.8906622314453, "Mean Q1": 228.88916552734375, "Mean Q2": 228.8897360839844, "critic_loss": 12.554219554901122, "batch_reward": 1.1356665945053102, "actor_loss": -230.22002568320622, "actor_target_entropy": -1.0, "actor_entropy": 0.7015383688230363, "alpha_loss": -0.002581834942767663, "alpha_value": 0.2329296653080559, "duration": 143.9342405796051, "step": 75125}
{"episode_reward": 65.07688143687686, "episode": 602.0, "Q1 loss": 6.424758476257324, "Q2 loss": 6.429968391418457, "Mean Target Q": 228.84871337890624, "Mean Q1": 228.84623803710937, "Mean Q2": 228.84600537109375, "critic_loss": 12.854726844787598, "batch_reward": 1.1300977101325989, "actor_loss": -230.11517235540575, "actor_target_entropy": -1.0, "actor_entropy": 0.7415307644874819, "alpha_loss": -0.002845267284541361, "alpha_value": 0.23312459024034046, "duration": 146.32686066627502, "step": 75250}
{"episode_reward": 130.2015317006172, "episode": 603.0, "Q1 loss": 5.865867860794068, "Q2 loss": 5.860470523834229, "Mean Target Q": 228.9450233154297, "Mean Q1": 228.94649755859376, "Mean Q2": 228.946501953125, "critic_loss": 11.72633840560913, "batch_reward": 1.1294268712997437, "actor_loss": -230.16861204117063, "actor_target_entropy": -1.0, "actor_entropy": 0.7275994344363137, "alpha_loss": -0.00039259533930037705, "alpha_value": 0.2332547017915242, "duration": 150.31079864501953, "step": 75375}
{"episode_reward": 86.81780532946078, "episode": 604.0, "Q1 loss": 6.107060653686523, "Q2 loss": 6.097927333831787, "Mean Target Q": 229.02344189453126, "Mean Q1": 229.01974011230467, "Mean Q2": 229.0196925048828, "critic_loss": 12.204987998962402, "batch_reward": 1.1314536628723144, "actor_loss": -230.37494511758126, "actor_target_entropy": -1.0, "actor_entropy": 0.6998735118296838, "alpha_loss": 0.006359546253788134, "alpha_value": 0.2330812257419568, "duration": 126.64349603652954, "step": 75500}
{"episode_reward": 126.20890942299299, "episode": 605.0, "Q1 loss": 5.711132110595703, "Q2 loss": 5.71695133972168, "Mean Target Q": 228.98372229003905, "Mean Q1": 228.98284899902345, "Mean Q2": 228.98287036132814, "critic_loss": 11.428083465576172, "batch_reward": 1.137769872188568, "actor_loss": -230.16065639919705, "actor_target_entropy": -1.0, "actor_entropy": 0.7092891780156938, "alpha_loss": 0.008658218386006496, "alpha_value": 0.23229909061253712, "duration": 150.62544584274292, "step": 75625}
{"episode_reward": 176.19671794336242, "episode": 606.0, "Q1 loss": 5.737208644866944, "Q2 loss": 5.724243263244629, "Mean Target Q": 229.14244079589844, "Mean Q1": 229.1430372314453, "Mean Q2": 229.14335522460937, "critic_loss": 11.461451950073242, "batch_reward": 1.1365331115722657, "actor_loss": -230.39176128756614, "actor_target_entropy": -1.0, "actor_entropy": 0.6707389123978154, "alpha_loss": 0.007328933579922323, "alpha_value": 0.23179368426056818, "duration": 149.344135761261, "step": 75750}
{"episode_reward": 145.90805419632838, "episode": 607.0, "Q1 loss": 5.982356941223144, "Q2 loss": 6.008081901550293, "Mean Target Q": 229.1960859375, "Mean Q1": 229.19600891113282, "Mean Q2": 229.19637548828126, "critic_loss": 11.990438884735108, "batch_reward": 1.1319954824447631, "actor_loss": -230.49066307431175, "actor_target_entropy": -1.0, "actor_entropy": 0.707491051583063, "alpha_loss": 0.0021874481878642526, "alpha_value": 0.2314356624565294, "duration": 164.0069923400879, "step": 75875}
{"episode_reward": 102.2437952806999, "episode": 608.0, "Q1 loss": 5.891786293029785, "Q2 loss": 5.8863129081726075, "Mean Target Q": 229.23578662109375, "Mean Q1": 229.23323608398437, "Mean Q2": 229.23293359375, "critic_loss": 11.7780991897583, "batch_reward": 1.129805736064911, "actor_loss": -230.4920413109564, "actor_target_entropy": -1.0, "actor_entropy": 0.7181667349030895, "alpha_loss": -0.0014889008466965488, "alpha_value": 0.2314706737231741, "duration": 145.64463901519775, "step": 76000}
{"episode_reward": 187.51333443349498, "episode": 609.0, "Q1 loss": 5.8270258064270015, "Q2 loss": 5.824404491424561, "Mean Target Q": 229.27239428710936, "Mean Q1": 229.27419689941405, "Mean Q2": 229.27346069335937, "critic_loss": 11.651430335998535, "batch_reward": 1.136654947757721, "actor_loss": -230.5060836549789, "actor_target_entropy": -1.0, "actor_entropy": 0.7131865639535208, "alpha_loss": 0.004026392583794418, "alpha_value": 0.23130940319487253, "duration": 131.7522177696228, "step": 76125}
{"episode_reward": 173.56874945731983, "episode": 610.0, "Q1 loss": 5.898741167068481, "Q2 loss": 5.883735191345215, "Mean Target Q": 229.25482043457032, "Mean Q1": 229.24957629394532, "Mean Q2": 229.2497960205078, "critic_loss": 11.782476356506347, "batch_reward": 1.1292743988037108, "actor_loss": -230.55365679340977, "actor_target_entropy": -1.0, "actor_entropy": 0.707119511019799, "alpha_loss": 0.006685131980526832, "alpha_value": 0.2308698362510371, "duration": 137.19732475280762, "step": 76250}
{"episode_reward": 162.8954719268958, "episode": 611.0, "Q1 loss": 6.002730087280273, "Q2 loss": 6.014235290527344, "Mean Target Q": 229.41415075683594, "Mean Q1": 229.41452807617188, "Mean Q2": 229.41466821289063, "critic_loss": 12.016965362548827, "batch_reward": 1.1308774042129517, "actor_loss": -230.6829596625434, "actor_target_entropy": -1.0, "actor_entropy": 0.6938151083295307, "alpha_loss": -0.003396703590018054, "alpha_value": 0.23096982936512436, "duration": 158.15056800842285, "step": 76375}
{"episode_reward": 38.13737499262969, "episode": 612.0, "Q1 loss": 5.932597482681275, "Q2 loss": 5.925959852218628, "Mean Target Q": 229.45428637695312, "Mean Q1": 229.45295361328124, "Mean Q2": 229.4528087158203, "critic_loss": 11.85855732345581, "batch_reward": 1.1289639358520507, "actor_loss": -230.7310325868668, "actor_target_entropy": -1.0, "actor_entropy": 0.7231562849014036, "alpha_loss": -0.0015054419073426435, "alpha_value": 0.23113044206816508, "duration": 135.02488255500793, "step": 76500}
{"episode_reward": 180.55986613487198, "episode": 613.0, "Q1 loss": 6.270545719146728, "Q2 loss": 6.293094583511353, "Mean Target Q": 229.44652172851562, "Mean Q1": 229.45311840820312, "Mean Q2": 229.4525255126953, "critic_loss": 12.56364028930664, "batch_reward": 1.1306077728271484, "actor_loss": -230.73068527948288, "actor_target_entropy": -1.0, "actor_entropy": 0.6969632175233629, "alpha_loss": -0.0007163316514047365, "alpha_value": 0.23100320595630086, "duration": 130.57840013504028, "step": 76625}
{"episode_reward": 48.65548812578962, "episode": 614.0, "Q1 loss": 5.777364685058593, "Q2 loss": 5.780036731719971, "Mean Target Q": 229.53482592773437, "Mean Q1": 229.5270704345703, "Mean Q2": 229.52767041015625, "critic_loss": 11.557401473999024, "batch_reward": 1.1247521257400512, "actor_loss": -230.77637826242756, "actor_target_entropy": -1.0, "actor_entropy": 0.7196875685645688, "alpha_loss": 0.003660591991407977, "alpha_value": 0.23093393882360325, "duration": 148.70270347595215, "step": 76750}
{"episode_reward": 116.73231023118655, "episode": 615.0, "Q1 loss": 6.053445964813233, "Q2 loss": 6.057883407592773, "Mean Target Q": 229.58618798828124, "Mean Q1": 229.5880517578125, "Mean Q2": 229.5876970214844, "critic_loss": 12.111329391479492, "batch_reward": 1.131361988067627, "actor_loss": -230.85681321885852, "actor_target_entropy": -1.0, "actor_entropy": 0.723842908465673, "alpha_loss": -0.0009180093405856972, "alpha_value": 0.2307177280559183, "duration": 156.4679458141327, "step": 76875}
{"episode_reward": 78.08607009531605, "episode": 616.0, "Q1 loss": 6.478243759155274, "Q2 loss": 6.493211917877197, "Mean Target Q": 229.67408935546874, "Mean Q1": 229.67018701171875, "Mean Q2": 229.66987841796876, "critic_loss": 12.971455688476562, "batch_reward": 1.136786376953125, "actor_loss": -230.97364954794608, "actor_target_entropy": -1.0, "actor_entropy": 0.7166900750129453, "alpha_loss": -0.0022613326230296687, "alpha_value": 0.231079745800432, "duration": 146.88974404335022, "step": 77000}
{"episode_reward": 196.54427445988736, "episode": 617.0, "Q1 loss": 6.303109432220459, "Q2 loss": 6.307394908905029, "Mean Target Q": 229.7673310546875, "Mean Q1": 229.7675194091797, "Mean Q2": 229.76736865234375, "critic_loss": 12.610504302978516, "batch_reward": 1.1217024607658386, "actor_loss": -231.02629888625373, "actor_target_entropy": -1.0, "actor_entropy": 0.7185674972004361, "alpha_loss": 0.0005133261567809515, "alpha_value": 0.23098347273759856, "duration": 141.4708104133606, "step": 77125}
{"episode_reward": 169.75493881140676, "episode": 618.0, "Q1 loss": 6.465875274658203, "Q2 loss": 6.46660002708435, "Mean Target Q": 229.78406311035155, "Mean Q1": 229.7856043701172, "Mean Q2": 229.78607019042968, "critic_loss": 12.932475288391114, "batch_reward": 1.125369257926941, "actor_loss": -231.02027277792655, "actor_target_entropy": -1.0, "actor_entropy": 0.744791986480836, "alpha_loss": 0.01066125557577658, "alpha_value": 0.23057816521433067, "duration": 152.3299379348755, "step": 77250}
{"episode_reward": 167.6359610842719, "episode": 619.0, "Q1 loss": 6.406709442138672, "Q2 loss": 6.4303800430297855, "Mean Target Q": 229.83110620117188, "Mean Q1": 229.82827612304686, "Mean Q2": 229.8279610595703, "critic_loss": 12.837089500427247, "batch_reward": 1.1365979385375977, "actor_loss": -231.12443518260167, "actor_target_entropy": -1.0, "actor_entropy": 0.7304612606290787, "alpha_loss": -0.00033788815776388795, "alpha_value": 0.23027999540999597, "duration": 161.0276083946228, "step": 77375}
{"episode_reward": 224.12120450331844, "episode": 620.0, "Q1 loss": 6.81669331741333, "Q2 loss": 6.828601936340332, "Mean Target Q": 229.91577954101564, "Mean Q1": 229.91366320800782, "Mean Q2": 229.91303771972656, "critic_loss": 13.64529524230957, "batch_reward": 1.1306666402816772, "actor_loss": -231.0749728295111, "actor_target_entropy": -1.0, "actor_entropy": 0.7344641906599845, "alpha_loss": 0.009212538844064599, "alpha_value": 0.230077352009852, "duration": 153.89671301841736, "step": 77500}
{"episode_reward": 65.14310679568612, "episode": 621.0, "Q1 loss": 6.733291519165039, "Q2 loss": 6.7375254135131835, "Mean Target Q": 229.9634479980469, "Mean Q1": 229.96357592773438, "Mean Q2": 229.96400903320313, "critic_loss": 13.470816864013672, "batch_reward": 1.120564399242401, "actor_loss": -231.24175008138022, "actor_target_entropy": -1.0, "actor_entropy": 0.7040113314749703, "alpha_loss": 0.0024908387567847967, "alpha_value": 0.22949707430695318, "duration": 159.1352367401123, "step": 77625}
{"episode_reward": 182.30436662064452, "episode": 622.0, "Q1 loss": 6.5824439849853515, "Q2 loss": 6.572435764312744, "Mean Target Q": 229.96361401367187, "Mean Q1": 229.95600622558592, "Mean Q2": 229.9572138671875, "critic_loss": 13.154879760742187, "batch_reward": 1.125722288608551, "actor_loss": -231.2528568390877, "actor_target_entropy": -1.0, "actor_entropy": 0.7136779792847172, "alpha_loss": -0.00447114264487379, "alpha_value": 0.2295306481711881, "duration": 153.7242226600647, "step": 77750}
{"episode_reward": 161.72478306804902, "episode": 623.0, "Q1 loss": 6.326645748138428, "Q2 loss": 6.345985927581787, "Mean Target Q": 230.0092724609375, "Mean Q1": 230.0168884277344, "Mean Q2": 230.0164747314453, "critic_loss": 12.67263161468506, "batch_reward": 1.1311876974105834, "actor_loss": -231.2970680357918, "actor_target_entropy": -1.0, "actor_entropy": 0.7217641690420726, "alpha_loss": 0.00862488336306775, "alpha_value": 0.2294747481839551, "duration": 141.85899186134338, "step": 77875}
{"episode_reward": 175.54601435685348, "episode": 624.0, "Q1 loss": 6.27559744644165, "Q2 loss": 6.2751407775878905, "Mean Target Q": 230.1413984375, "Mean Q1": 230.1377752685547, "Mean Q2": 230.13690014648438, "critic_loss": 12.55073823928833, "batch_reward": 1.13037105178833, "actor_loss": -231.3212405789283, "actor_target_entropy": -1.0, "actor_entropy": 0.7246694737865079, "alpha_loss": -0.005010362049835103, "alpha_value": 0.2293652952283051, "duration": 144.47241282463074, "step": 78000}
{"episode_reward": 163.3398831383337, "episode": 625.0, "Q1 loss": 6.03481060218811, "Q2 loss": 6.040535623550415, "Mean Target Q": 230.20626794433593, "Mean Q1": 230.20966247558593, "Mean Q2": 230.20980932617186, "critic_loss": 12.075346214294434, "batch_reward": 1.1317907691001892, "actor_loss": -231.4159911624969, "actor_target_entropy": -1.0, "actor_entropy": 0.721075417503478, "alpha_loss": 0.0025619347025418564, "alpha_value": 0.22958470752783225, "duration": 139.9184272289276, "step": 78125}
{"episode_reward": 124.77825726295485, "episode": 626.0, "Q1 loss": 6.390697673797607, "Q2 loss": 6.401027194976806, "Mean Target Q": 230.34798754882812, "Mean Q1": 230.34519580078126, "Mean Q2": 230.34510009765626, "critic_loss": 12.791724822998047, "batch_reward": 1.1292374029159546, "actor_loss": -231.60197153399068, "actor_target_entropy": -1.0, "actor_entropy": 0.732410131923614, "alpha_loss": -0.0033326681793457076, "alpha_value": 0.22942950740518744, "duration": 151.75438594818115, "step": 78250}
{"episode_reward": 207.55461790925372, "episode": 627.0, "Q1 loss": 6.776909984588623, "Q2 loss": 6.794209167480469, "Mean Target Q": 230.33215673828124, "Mean Q1": 230.32852416992188, "Mean Q2": 230.32823803710937, "critic_loss": 13.571119178771973, "batch_reward": 1.1326312618255616, "actor_loss": -231.5898929172092, "actor_target_entropy": -1.0, "actor_entropy": 0.7375684153465998, "alpha_loss": 0.0068832938596310594, "alpha_value": 0.2293578127309888, "duration": 139.4125542640686, "step": 78375}
{"episode_reward": 59.793160204708045, "episode": 628.0, "Q1 loss": 6.796611030578613, "Q2 loss": 6.783592819213867, "Mean Target Q": 230.41833825683594, "Mean Q1": 230.41742126464842, "Mean Q2": 230.4174696044922, "critic_loss": 13.580203926086426, "batch_reward": 1.1342551345825196, "actor_loss": -231.66067726381362, "actor_target_entropy": -1.0, "actor_entropy": 0.7321938680064294, "alpha_loss": -0.0020783823734569933, "alpha_value": 0.2291514548108454, "duration": 153.62213706970215, "step": 78500}
{"episode_reward": 125.5886434994866, "episode": 629.0, "Q1 loss": 6.4204384765625, "Q2 loss": 6.43298288154602, "Mean Target Q": 230.4059091796875, "Mean Q1": 230.40830017089843, "Mean Q2": 230.40848620605468, "critic_loss": 12.853421363830567, "batch_reward": 1.1234406790733338, "actor_loss": -231.68313840835813, "actor_target_entropy": -1.0, "actor_entropy": 0.7484743301830594, "alpha_loss": 0.005842478350839681, "alpha_value": 0.229125510072437, "duration": 159.506502866745, "step": 78625}
{"episode_reward": 142.90020020150624, "episode": 630.0, "Q1 loss": 6.368447437286377, "Q2 loss": 6.369108123779297, "Mean Target Q": 230.58092883300782, "Mean Q1": 230.57749353027344, "Mean Q2": 230.57737341308595, "critic_loss": 12.737555541992187, "batch_reward": 1.133990460395813, "actor_loss": -231.81610673473728, "actor_target_entropy": -1.0, "actor_entropy": 0.7206049186568106, "alpha_loss": 8.974864613264799e-05, "alpha_value": 0.22884894489790428, "duration": 151.43926000595093, "step": 78750}
{"episode_reward": 78.69865984916214, "episode": 631.0, "Q1 loss": 6.4524799289703365, "Q2 loss": 6.46055863571167, "Mean Target Q": 230.66017260742188, "Mean Q1": 230.65836413574218, "Mean Q2": 230.65832409667968, "critic_loss": 12.913038543701171, "batch_reward": 1.137801944732666, "actor_loss": -231.958004421658, "actor_target_entropy": -1.0, "actor_entropy": 0.719984977964371, "alpha_loss": 0.0004576518355558316, "alpha_value": 0.2286025586014442, "duration": 142.29951000213623, "step": 78875}
{"episode_reward": 86.8299556240483, "episode": 632.0, "Q1 loss": 6.481381336212158, "Q2 loss": 6.482267143249512, "Mean Target Q": 230.70903784179689, "Mean Q1": 230.70787622070313, "Mean Q2": 230.70843103027343, "critic_loss": 12.963648475646973, "batch_reward": 1.125088574409485, "actor_loss": -231.90691744896674, "actor_target_entropy": -1.0, "actor_entropy": 0.7124364424136377, "alpha_loss": 0.006275584061269558, "alpha_value": 0.22849058791350466, "duration": 146.0587351322174, "step": 79000}
{"episode_reward": 195.5049952869019, "episode": 633.0, "Q1 loss": 6.281518836975097, "Q2 loss": 6.293098218917847, "Mean Target Q": 230.72689587402343, "Mean Q1": 230.7298486328125, "Mean Q2": 230.72933923339843, "critic_loss": 12.574617095947266, "batch_reward": 1.1341389398574828, "actor_loss": -231.8766820998419, "actor_target_entropy": -1.0, "actor_entropy": 0.7157340693095374, "alpha_loss": 0.004708839665418343, "alpha_value": 0.22813529851200112, "duration": 241.14778757095337, "step": 79125}
{"episode_reward": 130.62937750039833, "episode": 634.0, "Q1 loss": 6.405292015075684, "Q2 loss": 6.415323856353759, "Mean Target Q": 230.7401787109375, "Mean Q1": 230.73238732910156, "Mean Q2": 230.73303552246094, "critic_loss": 12.82061587524414, "batch_reward": 1.131619460105896, "actor_loss": -231.96617914015246, "actor_target_entropy": -1.0, "actor_entropy": 0.7045282654223903, "alpha_loss": 0.006443794794200409, "alpha_value": 0.2276442247871983, "duration": 316.8338203430176, "step": 79250}
{"episode_reward": 99.92109853176356, "episode": 635.0, "Q1 loss": 6.589261028289795, "Q2 loss": 6.583233753204346, "Mean Target Q": 230.744943359375, "Mean Q1": 230.74772583007814, "Mean Q2": 230.74695544433592, "critic_loss": 13.172494804382325, "batch_reward": 1.1297119216918945, "actor_loss": -232.02779666961186, "actor_target_entropy": -1.0, "actor_entropy": 0.7251876441259233, "alpha_loss": 0.008118135799165992, "alpha_value": 0.22729347424460547, "duration": 306.2682411670685, "step": 79375}
{"episode_reward": 215.7218990905252, "episode": 636.0, "Q1 loss": 6.000853578567505, "Q2 loss": 6.00134094619751, "Mean Target Q": 230.85377270507811, "Mean Q1": 230.8549227294922, "Mean Q2": 230.85526708984375, "critic_loss": 12.002194526672364, "batch_reward": 1.1277053890228272, "actor_loss": -232.0860605547505, "actor_target_entropy": -1.0, "actor_entropy": 0.7118213724705481, "alpha_loss": 0.004622141672899166, "alpha_value": 0.22676030332830058, "duration": 261.0798239707947, "step": 79500}
{"episode_reward": 121.37926431815194, "episode": 637.0, "Q1 loss": 6.1029403762817385, "Q2 loss": 6.105730934143066, "Mean Target Q": 230.81140893554686, "Mean Q1": 230.81144372558595, "Mean Q2": 230.81121606445313, "critic_loss": 12.208671348571777, "batch_reward": 1.1223699560165405, "actor_loss": -232.04406907823352, "actor_target_entropy": -1.0, "actor_entropy": 0.7102762280948578, "alpha_loss": 0.0017164540181439075, "alpha_value": 0.2264753676639088, "duration": 255.52413249015808, "step": 79625}
{"episode_reward": 169.61788273078943, "episode": 638.0, "Q1 loss": 5.954244464874267, "Q2 loss": 5.965781251907349, "Mean Target Q": 230.9260330810547, "Mean Q1": 230.92265258789064, "Mean Q2": 230.922470703125, "critic_loss": 11.920025741577149, "batch_reward": 1.1316278057098388, "actor_loss": -232.1625501571163, "actor_target_entropy": -1.0, "actor_entropy": 0.7082437584477086, "alpha_loss": -0.0006104093345422898, "alpha_value": 0.22625979380812267, "duration": 231.53333473205566, "step": 79750}
{"episode_reward": 154.30076993942376, "episode": 639.0, "Q1 loss": 6.415446266174317, "Q2 loss": 6.413156879425049, "Mean Target Q": 230.99512829589844, "Mean Q1": 230.991375, "Mean Q2": 230.99124755859376, "critic_loss": 12.828603149414063, "batch_reward": 1.1372457070350648, "actor_loss": -232.2539297436911, "actor_target_entropy": -1.0, "actor_entropy": 0.6997851587477184, "alpha_loss": 0.003308510999121363, "alpha_value": 0.22643254738171248, "duration": 237.54257893562317, "step": 79875}
{"episode_reward": 128.84213172145698, "episode": 640.0, "Q1 loss": 6.172120895385742, "Q2 loss": 6.1761802940368655, "Mean Target Q": 231.00302429199218, "Mean Q1": 231.004568359375, "Mean Q2": 231.00495861816407, "critic_loss": 12.348301189422607, "batch_reward": 1.1283670530319214, "actor_loss": -232.25934157832975, "actor_target_entropy": -1.0, "actor_entropy": 0.7105416415199157, "alpha_loss": 0.012837110977289417, "alpha_value": 0.22583711632097017, "step": 80000}
{"duration": 176.73967814445496, "step": 80000}
{"episode_reward": 228.37112438310257, "episode": 641.0, "Q1 loss": 6.204663101196289, "Q2 loss": 6.229724849700927, "Mean Target Q": 231.11751818847657, "Mean Q1": 231.1131876220703, "Mean Q2": 231.1127459716797, "critic_loss": 12.434387966156006, "batch_reward": 1.1344703273773193, "actor_loss": -232.39518592471168, "actor_target_entropy": -1.0, "actor_entropy": 0.6936758520111205, "alpha_loss": 0.004240906350166788, "alpha_value": 0.22514877336157435, "duration": 188.35662937164307, "step": 80125}
{"episode_reward": 116.84642589285045, "episode": 642.0, "Q1 loss": 6.346475103378296, "Q2 loss": 6.346488639831543, "Mean Target Q": 231.25623571777345, "Mean Q1": 231.25786120605468, "Mean Q2": 231.25773376464844, "critic_loss": 12.692963768005372, "batch_reward": 1.142805341720581, "actor_loss": -232.49401092529297, "actor_target_entropy": -1.0, "actor_entropy": 0.6798802393098031, "alpha_loss": 0.0025018090006685063, "alpha_value": 0.22494941389279152, "duration": 183.79083824157715, "step": 80250}
{"episode_reward": 5.194308465003168, "episode": 643.0, "Q1 loss": 6.398302129745483, "Q2 loss": 6.39658253288269, "Mean Target Q": 231.24852319335938, "Mean Q1": 231.24402319335937, "Mean Q2": 231.24390966796875, "critic_loss": 12.794884662628174, "batch_reward": 1.1344040269851685, "actor_loss": -232.4469960530599, "actor_target_entropy": -1.0, "actor_entropy": 0.715686233270736, "alpha_loss": 0.010433171491419512, "alpha_value": 0.22448467297665003, "duration": 165.55913162231445, "step": 80375}
{"episode_reward": 212.75413411106592, "episode": 644.0, "Q1 loss": 6.44321251296997, "Q2 loss": 6.454193752288818, "Mean Target Q": 231.33096887207032, "Mean Q1": 231.3359904785156, "Mean Q2": 231.336693359375, "critic_loss": 12.897406311035157, "batch_reward": 1.1393176403045655, "actor_loss": -232.59412999306954, "actor_target_entropy": -1.0, "actor_entropy": 0.6884373387982768, "alpha_loss": 0.00041872533338685187, "alpha_value": 0.22393328797810036, "duration": 198.98647212982178, "step": 80500}
{"episode_reward": 195.3864699041985, "episode": 645.0, "Q1 loss": 6.062494609832764, "Q2 loss": 6.071459945678711, "Mean Target Q": 231.32593603515625, "Mean Q1": 231.32386474609376, "Mean Q2": 231.32324108886718, "critic_loss": 12.133954582214356, "batch_reward": 1.1281821975708008, "actor_loss": -232.55315193297372, "actor_target_entropy": -1.0, "actor_entropy": 0.6968531731575255, "alpha_loss": 0.007822368049158878, "alpha_value": 0.22365059807663326, "duration": 212.99047780036926, "step": 80625}
{"episode_reward": 175.83536283987402, "episode": 646.0, "Q1 loss": 6.009002031326294, "Q2 loss": 6.030357488632202, "Mean Target Q": 231.29440087890626, "Mean Q1": 231.2894229736328, "Mean Q2": 231.28950463867187, "critic_loss": 12.03935947418213, "batch_reward": 1.1272777853012086, "actor_loss": -232.49920605074973, "actor_target_entropy": -1.0, "actor_entropy": 0.6995842053044227, "alpha_loss": 0.005313943688487334, "alpha_value": 0.22305734425284668, "duration": 208.32405185699463, "step": 80750}
{"episode_reward": 148.10213204465387, "episode": 647.0, "Q1 loss": 5.925900930404663, "Q2 loss": 5.927978509902954, "Mean Target Q": 231.3315192871094, "Mean Q1": 231.33482788085936, "Mean Q2": 231.3346590576172, "critic_loss": 11.853879405975341, "batch_reward": 1.1394782204627991, "actor_loss": -232.55961536225817, "actor_target_entropy": -1.0, "actor_entropy": 0.7129441263183715, "alpha_loss": 0.0054579563734550324, "alpha_value": 0.22260944814177205, "duration": 225.5438814163208, "step": 80875}
{"episode_reward": 231.28294906083724, "episode": 648.0, "Q1 loss": 5.748278617858887, "Q2 loss": 5.751520030975342, "Mean Target Q": 231.4337244873047, "Mean Q1": 231.4320078125, "Mean Q2": 231.43228588867188, "critic_loss": 11.499798679351807, "batch_reward": 1.1406620597839356, "actor_loss": -232.6876469273721, "actor_target_entropy": -1.0, "actor_entropy": 0.692754658960527, "alpha_loss": 0.003970002734868396, "alpha_value": 0.22235828977857092, "duration": 191.0859396457672, "step": 81000}
{"episode_reward": 88.94254728197971, "episode": 649.0, "Q1 loss": 5.766026113510132, "Q2 loss": 5.760915901184082, "Mean Target Q": 231.53537023925782, "Mean Q1": 231.5355947265625, "Mean Q2": 231.53550439453124, "critic_loss": 11.526941993713379, "batch_reward": 1.1362567682266236, "actor_loss": -232.72254750085256, "actor_target_entropy": -1.0, "actor_entropy": 0.7070601629832435, "alpha_loss": -0.0005457892345028028, "alpha_value": 0.22221519345773513, "duration": 190.1044647693634, "step": 81125}
{"episode_reward": 182.85733737162838, "episode": 650.0, "Q1 loss": 5.679375429153442, "Q2 loss": 5.681988122940063, "Mean Target Q": 231.57536376953124, "Mean Q1": 231.57297106933595, "Mean Q2": 231.57287707519532, "critic_loss": 11.361363586425782, "batch_reward": 1.1275624537467956, "actor_loss": -232.755370109312, "actor_target_entropy": -1.0, "actor_entropy": 0.694782700269453, "alpha_loss": -0.0005986936683315903, "alpha_value": 0.22235030184768048, "duration": 152.03465008735657, "step": 81250}
{"episode_reward": 107.13889284917731, "episode": 651.0, "Q1 loss": 5.583809410095215, "Q2 loss": 5.589680229187012, "Mean Target Q": 231.58830102539062, "Mean Q1": 231.58772985839843, "Mean Q2": 231.58756591796876, "critic_loss": 11.173489685058593, "batch_reward": 1.1431370248794557, "actor_loss": -232.84426589239212, "actor_target_entropy": -1.0, "actor_entropy": 0.6782644353215657, "alpha_loss": -0.001512104408845069, "alpha_value": 0.22230918284723056, "duration": 163.79507565498352, "step": 81375}
{"episode_reward": 56.890193838398545, "episode": 652.0, "Q1 loss": 6.034078052520752, "Q2 loss": 6.045065685272217, "Mean Target Q": 231.71496557617186, "Mean Q1": 231.71487768554687, "Mean Q2": 231.71507458496095, "critic_loss": 12.07914370727539, "batch_reward": 1.1286463680267333, "actor_loss": -232.99971918905936, "actor_target_entropy": -1.0, "actor_entropy": 0.7019978473263402, "alpha_loss": -0.0006005491896141921, "alpha_value": 0.2226414476664605, "duration": 163.07538414001465, "step": 81500}
{"episode_reward": 103.2596479938341, "episode": 653.0, "Q1 loss": 5.996040851593017, "Q2 loss": 5.993970790863037, "Mean Target Q": 231.78365612792967, "Mean Q1": 231.78225476074218, "Mean Q2": 231.7824415283203, "critic_loss": 11.990011688232421, "batch_reward": 1.132826922416687, "actor_loss": -233.10822259812127, "actor_target_entropy": -1.0, "actor_entropy": 0.6903826026689439, "alpha_loss": 0.0036077947034278794, "alpha_value": 0.22241654781661074, "duration": 150.03871870040894, "step": 81625}
{"episode_reward": 244.5889267001215, "episode": 654.0, "Q1 loss": 5.980344612121582, "Q2 loss": 5.980112846374512, "Mean Target Q": 231.7938175048828, "Mean Q1": 231.79742822265624, "Mean Q2": 231.79709411621093, "critic_loss": 11.960457481384278, "batch_reward": 1.1303113331794739, "actor_loss": -233.00753242738784, "actor_target_entropy": -1.0, "actor_entropy": 0.6712877183191238, "alpha_loss": -0.006736619135124549, "alpha_value": 0.22247720662789394, "duration": 159.21553754806519, "step": 81750}
{"episode_reward": 168.1810575227144, "episode": 655.0, "Q1 loss": 6.450193099975586, "Q2 loss": 6.459448574066162, "Mean Target Q": 231.86456774902345, "Mean Q1": 231.85724841308593, "Mean Q2": 231.8571564941406, "critic_loss": 12.909641708374023, "batch_reward": 1.1240358924865723, "actor_loss": -233.05639478895398, "actor_target_entropy": -1.0, "actor_entropy": 0.6965929657693893, "alpha_loss": -0.004719700823197999, "alpha_value": 0.2229047769447091, "duration": 122.69072914123535, "step": 81875}
{"episode_reward": 139.90617922111775, "episode": 656.0, "Q1 loss": 6.259242881774902, "Q2 loss": 6.269387577056885, "Mean Target Q": 231.83832983398437, "Mean Q1": 231.83745068359374, "Mean Q2": 231.83773291015626, "critic_loss": 12.528630416870117, "batch_reward": 1.127827000617981, "actor_loss": -233.09420382591986, "actor_target_entropy": -1.0, "actor_entropy": 0.7184471939840624, "alpha_loss": -0.00048229151645735386, "alpha_value": 0.222989641118231, "duration": 176.45604801177979, "step": 82000}
{"episode_reward": 134.73322505062484, "episode": 657.0, "Q1 loss": 6.567149448394775, "Q2 loss": 6.585069679260254, "Mean Target Q": 231.92380053710937, "Mean Q1": 231.922876953125, "Mean Q2": 231.92259008789063, "critic_loss": 13.152219135284424, "batch_reward": 1.128756887435913, "actor_loss": -233.27297876751612, "actor_target_entropy": -1.0, "actor_entropy": 0.7084296534931849, "alpha_loss": -0.0014759045951659717, "alpha_value": 0.22309356236162578, "duration": 188.20327186584473, "step": 82125}
{"episode_reward": 70.83620164128499, "episode": 658.0, "Q1 loss": 6.353525924682617, "Q2 loss": 6.346853858947754, "Mean Target Q": 232.0122596435547, "Mean Q1": 232.01348461914063, "Mean Q2": 232.01314428710938, "critic_loss": 12.700379753112793, "batch_reward": 1.1313275294303895, "actor_loss": -233.3294468541299, "actor_target_entropy": -1.0, "actor_entropy": 0.6996797198249448, "alpha_loss": 0.004771047966524718, "alpha_value": 0.22313963586153354, "duration": 185.74799346923828, "step": 82250}
{"episode_reward": 216.86257329194322, "episode": 659.0, "Q1 loss": 6.361004344940185, "Q2 loss": 6.372764419555664, "Mean Target Q": 232.13848583984375, "Mean Q1": 232.12987939453126, "Mean Q2": 232.13085815429687, "critic_loss": 12.733768753051757, "batch_reward": 1.1279455800056457, "actor_loss": -233.38675411163814, "actor_target_entropy": -1.0, "actor_entropy": 0.7111108927499681, "alpha_loss": 0.00583869419134562, "alpha_value": 0.22262500369171034, "duration": 202.97022604942322, "step": 82375}
{"episode_reward": 174.62784902084292, "episode": 660.0, "Q1 loss": 6.531009586334228, "Q2 loss": 6.549678375244141, "Mean Target Q": 232.05699169921874, "Mean Q1": 232.06215844726563, "Mean Q2": 232.06227185058594, "critic_loss": 13.080687965393066, "batch_reward": 1.12398766374588, "actor_loss": -233.33449111446257, "actor_target_entropy": -1.0, "actor_entropy": 0.6676536654272387, "alpha_loss": -0.002482618960071235, "alpha_value": 0.22248224195429064, "duration": 205.1936058998108, "step": 82500}
{"episode_reward": 70.34726175952297, "episode": 661.0, "Q1 loss": 6.47046548461914, "Q2 loss": 6.4682915458679195, "Mean Target Q": 232.20038403320314, "Mean Q1": 232.197341796875, "Mean Q2": 232.19652099609374, "critic_loss": 12.938757049560547, "batch_reward": 1.1330372653007508, "actor_loss": -233.37674289279514, "actor_target_entropy": -1.0, "actor_entropy": 0.670458163533892, "alpha_loss": 0.003382162061623401, "alpha_value": 0.22261731452490602, "duration": 201.3793601989746, "step": 82625}
{"episode_reward": 173.5007548299278, "episode": 662.0, "Q1 loss": 6.634794151306152, "Q2 loss": 6.639950630187989, "Mean Target Q": 232.19025744628905, "Mean Q1": 232.19330749511718, "Mean Q2": 232.19259814453125, "critic_loss": 13.274744819641112, "batch_reward": 1.135821991443634, "actor_loss": -233.51571409163935, "actor_target_entropy": -1.0, "actor_entropy": 0.6973499088518081, "alpha_loss": 0.0010526610628491448, "alpha_value": 0.22231808250779375, "duration": 187.6431052684784, "step": 82750}
{"episode_reward": 135.85382050539337, "episode": 663.0, "Q1 loss": 6.4197531490325925, "Q2 loss": 6.431937412261963, "Mean Target Q": 232.1786319580078, "Mean Q1": 232.17622912597656, "Mean Q2": 232.17722924804687, "critic_loss": 12.851690567016602, "batch_reward": 1.1292584733963014, "actor_loss": -233.44966513013082, "actor_target_entropy": -1.0, "actor_entropy": 0.6769012780416579, "alpha_loss": 0.000305628219235038, "alpha_value": 0.22227107630497725, "duration": 196.59830045700073, "step": 82875}
{"episode_reward": 226.13178968066825, "episode": 664.0, "Q1 loss": 6.459598861694336, "Q2 loss": 6.471580013275147, "Mean Target Q": 232.26341552734374, "Mean Q1": 232.25995251464843, "Mean Q2": 232.25952673339845, "critic_loss": 12.931178855895997, "batch_reward": 1.133469481945038, "actor_loss": -233.5486792287519, "actor_target_entropy": -1.0, "actor_entropy": 0.6667846931565192, "alpha_loss": -0.003607109327980828, "alpha_value": 0.22240360674213733, "duration": 150.5401051044464, "step": 83000}
{"episode_reward": 122.36424831649775, "episode": 665.0, "Q1 loss": 6.277891807556152, "Q2 loss": 6.274407903671265, "Mean Target Q": 232.4641943359375, "Mean Q1": 232.46548950195313, "Mean Q2": 232.46586450195312, "critic_loss": 12.552299690246581, "batch_reward": 1.1380425391197204, "actor_loss": -233.72071063329304, "actor_target_entropy": -1.0, "actor_entropy": 0.702983610213749, "alpha_loss": 0.0026256557265740064, "alpha_value": 0.22235402247491992, "duration": 146.62744903564453, "step": 83125}
{"episode_reward": 201.15832438036657, "episode": 666.0, "Q1 loss": 6.49160279083252, "Q2 loss": 6.512221115112305, "Mean Target Q": 232.46021264648436, "Mean Q1": 232.46044519042968, "Mean Q2": 232.46019055175782, "critic_loss": 13.003823928833008, "batch_reward": 1.137948907852173, "actor_loss": -233.72087835496473, "actor_target_entropy": -1.0, "actor_entropy": 0.685821952358369, "alpha_loss": -0.0024163693550132937, "alpha_value": 0.22255528830600743, "duration": 156.28267788887024, "step": 83250}
{"episode_reward": 246.64304145617305, "episode": 667.0, "Q1 loss": 6.223197467803955, "Q2 loss": 6.222985076904297, "Mean Target Q": 232.5849471435547, "Mean Q1": 232.5840451660156, "Mean Q2": 232.58401806640626, "critic_loss": 12.446182563781738, "batch_reward": 1.1375976915359498, "actor_loss": -233.8847358340309, "actor_target_entropy": -1.0, "actor_entropy": 0.6728293451051863, "alpha_loss": -0.005722686729674775, "alpha_value": 0.22260773834760422, "duration": 143.55263543128967, "step": 83375}
{"episode_reward": 79.25570651272326, "episode": 668.0, "Q1 loss": 6.524460227966308, "Q2 loss": 6.533787384033203, "Mean Target Q": 232.56106823730468, "Mean Q1": 232.55939074707032, "Mean Q2": 232.55953930664063, "critic_loss": 13.058247581481934, "batch_reward": 1.1386347379684447, "actor_loss": -233.80630591607863, "actor_target_entropy": -1.0, "actor_entropy": 0.7059726397837361, "alpha_loss": -0.0041927395786549295, "alpha_value": 0.22305670017982596, "duration": 167.80138397216797, "step": 83500}
{"episode_reward": 250.5442684482805, "episode": 669.0, "Q1 loss": 6.242895225524903, "Q2 loss": 6.242547912597656, "Mean Target Q": 232.60352880859375, "Mean Q1": 232.60383776855468, "Mean Q2": 232.6043468017578, "critic_loss": 12.485443107604981, "batch_reward": 1.1286050510406493, "actor_loss": -233.89038788326204, "actor_target_entropy": -1.0, "actor_entropy": 0.6969523931306506, "alpha_loss": -0.0016342164460747014, "alpha_value": 0.22332411576852226, "duration": 197.7189793586731, "step": 83625}
{"episode_reward": 174.53633000754687, "episode": 670.0, "Q1 loss": 6.4418820304870605, "Q2 loss": 6.4366764678955075, "Mean Target Q": 232.71641430664062, "Mean Q1": 232.71868615722656, "Mean Q2": 232.7176008300781, "critic_loss": 12.878558517456055, "batch_reward": 1.1350320425033569, "actor_loss": -233.8980959000126, "actor_target_entropy": -1.0, "actor_entropy": 0.7191536340021318, "alpha_loss": -0.0020285462697727545, "alpha_value": 0.2232765885597119, "duration": 196.03681325912476, "step": 83750}
{"episode_reward": 192.98380002555447, "episode": 671.0, "Q1 loss": 6.574468545913696, "Q2 loss": 6.573633769989014, "Mean Target Q": 232.71076599121093, "Mean Q1": 232.70595751953124, "Mean Q2": 232.70620141601563, "critic_loss": 13.148102363586426, "batch_reward": 1.1356128420829772, "actor_loss": -233.95049394880022, "actor_target_entropy": -1.0, "actor_entropy": 0.7142410079638163, "alpha_loss": 0.004342550452473381, "alpha_value": 0.22337961575885157, "duration": 190.71324849128723, "step": 83875}
{"episode_reward": 154.07060997345508, "episode": 672.0, "Q1 loss": 6.298850002288819, "Q2 loss": 6.296193222045899, "Mean Target Q": 232.77592333984376, "Mean Q1": 232.77370166015626, "Mean Q2": 232.77418395996094, "critic_loss": 12.595043266296386, "batch_reward": 1.1353483505249022, "actor_loss": -234.08249713528542, "actor_target_entropy": -1.0, "actor_entropy": 0.6826004683971405, "alpha_loss": 0.005116678413844878, "alpha_value": 0.22298950572065315, "duration": 187.9904294013977, "step": 84000}
{"episode_reward": 187.41737130101276, "episode": 673.0, "Q1 loss": 6.394005020141601, "Q2 loss": 6.400834018707275, "Mean Target Q": 232.8327899169922, "Mean Q1": 232.83164831542967, "Mean Q2": 232.83214221191406, "critic_loss": 12.794839057922363, "batch_reward": 1.137822699546814, "actor_loss": -234.11874220106336, "actor_target_entropy": -1.0, "actor_entropy": 0.6766059710865929, "alpha_loss": -0.0005882751965333545, "alpha_value": 0.22291167973651832, "duration": 203.0212869644165, "step": 84125}
{"episode_reward": 71.21698579254334, "episode": 674.0, "Q1 loss": 6.342406730651856, "Q2 loss": 6.339658786773682, "Mean Target Q": 232.96536450195313, "Mean Q1": 232.96359289550782, "Mean Q2": 232.963154296875, "critic_loss": 12.68206551361084, "batch_reward": 1.138708888053894, "actor_loss": -234.20258085189326, "actor_target_entropy": -1.0, "actor_entropy": 0.7042920493310497, "alpha_loss": 0.002557637981109081, "alpha_value": 0.22287721401777708, "duration": 174.90139317512512, "step": 84250}
{"episode_reward": 205.2263136932674, "episode": 675.0, "Q1 loss": 6.585563873291016, "Q2 loss": 6.602788505554199, "Mean Target Q": 233.05181970214844, "Mean Q1": 233.05141564941405, "Mean Q2": 233.05208203125, "critic_loss": 13.188352424621582, "batch_reward": 1.1400973844528197, "actor_loss": -234.31334068661644, "actor_target_entropy": -1.0, "actor_entropy": 0.6824644832384019, "alpha_loss": 0.0013466354696050522, "alpha_value": 0.2226956476060769, "duration": 150.49560165405273, "step": 84375}
{"episode_reward": 93.71740170005894, "episode": 676.0, "Q1 loss": 6.4229527130126955, "Q2 loss": 6.433696937561035, "Mean Target Q": 232.95471166992186, "Mean Q1": 232.95408325195314, "Mean Q2": 232.9529775390625, "critic_loss": 12.85664965057373, "batch_reward": 1.1308792028427124, "actor_loss": -234.1787554833197, "actor_target_entropy": -1.0, "actor_entropy": 0.6934525783984892, "alpha_loss": -0.0026603739881407348, "alpha_value": 0.22271030503260508, "duration": 164.65046644210815, "step": 84500}
{"episode_reward": 226.53265852673326, "episode": 677.0, "Q1 loss": 6.576190296173095, "Q2 loss": 6.565362770080567, "Mean Target Q": 233.06533361816406, "Mean Q1": 233.0626378173828, "Mean Q2": 233.06309985351564, "critic_loss": 13.141553077697754, "batch_reward": 1.1347381114959716, "actor_loss": -234.37559533497645, "actor_target_entropy": -1.0, "actor_entropy": 0.6664019482476371, "alpha_loss": 0.001818981853180698, "alpha_value": 0.222575868231844, "duration": 169.6471598148346, "step": 84625}
{"episode_reward": 123.46797765443809, "episode": 678.0, "Q1 loss": 6.66476879119873, "Q2 loss": 6.653219844818115, "Mean Target Q": 233.16856518554687, "Mean Q1": 233.17056237792968, "Mean Q2": 233.17075170898437, "critic_loss": 13.317988609313964, "batch_reward": 1.1378907470703126, "actor_loss": -234.42775037211757, "actor_target_entropy": -1.0, "actor_entropy": 0.6702113536096388, "alpha_loss": 0.0006427257885074903, "alpha_value": 0.222435291503465, "duration": 147.10540533065796, "step": 84750}
{"episode_reward": 188.4780498032705, "episode": 679.0, "Q1 loss": 6.86366397857666, "Q2 loss": 6.901776931762695, "Mean Target Q": 233.22654809570312, "Mean Q1": 233.22521118164062, "Mean Q2": 233.22545556640625, "critic_loss": 13.765440910339356, "batch_reward": 1.1443834552764893, "actor_loss": -234.44221932547433, "actor_target_entropy": -1.0, "actor_entropy": 0.6835658048826551, "alpha_loss": 0.005939367042470073, "alpha_value": 0.22247005086196142, "duration": 154.77066135406494, "step": 84875}
{"episode_reward": 169.03073096976345, "episode": 680.0, "Q1 loss": 6.583488410949707, "Q2 loss": 6.596087421417236, "Mean Target Q": 233.22337963867187, "Mean Q1": 233.2256474609375, "Mean Q2": 233.22503186035155, "critic_loss": 13.17957582473755, "batch_reward": 1.1365790920257568, "actor_loss": -234.4182419315461, "actor_target_entropy": -1.0, "actor_entropy": 0.6718752364958486, "alpha_loss": 0.0017075169786450364, "alpha_value": 0.2221493303834016, "step": 85000}
{"duration": 169.63726210594177, "step": 85000}
{"episode_reward": 188.93162316129735, "episode": 681.0, "Q1 loss": 5.915558238983154, "Q2 loss": 5.914022108078003, "Mean Target Q": 233.16292626953125, "Mean Q1": 233.15641455078125, "Mean Q2": 233.15680798339844, "critic_loss": 11.829580375671387, "batch_reward": 1.1316663269996643, "actor_loss": -234.25867643810454, "actor_target_entropy": -1.0, "actor_entropy": 0.6621112388277811, "alpha_loss": 0.012536148030665658, "alpha_value": 0.22167789028083712, "duration": 170.5290048122406, "step": 85125}
{"episode_reward": 202.31451940741414, "episode": 682.0, "Q1 loss": 5.690063579559326, "Q2 loss": 5.703613828659058, "Mean Target Q": 233.10665783691405, "Mean Q1": 233.10653918457032, "Mean Q2": 233.10567468261718, "critic_loss": 11.39367737197876, "batch_reward": 1.140379753112793, "actor_loss": -234.2275388163905, "actor_target_entropy": -1.0, "actor_entropy": 0.6593288760031423, "alpha_loss": 0.008738978146274964, "alpha_value": 0.22076441681493897, "duration": 146.09232831001282, "step": 85250}
{"episode_reward": 131.93282862875844, "episode": 683.0, "Q1 loss": 5.863523632049561, "Q2 loss": 5.886357807159424, "Mean Target Q": 233.04273474121095, "Mean Q1": 233.0489833984375, "Mean Q2": 233.0488193359375, "critic_loss": 11.749881423950196, "batch_reward": 1.13916943359375, "actor_loss": -234.2166510687934, "actor_target_entropy": -1.0, "actor_entropy": 0.6669060199979752, "alpha_loss": 0.007352309164753746, "alpha_value": 0.2201612039237931, "duration": 164.37930989265442, "step": 85375}
{"episode_reward": 111.35654337489662, "episode": 684.0, "Q1 loss": 5.987248649597168, "Q2 loss": 5.975815732955932, "Mean Target Q": 233.19919323730468, "Mean Q1": 233.1942774658203, "Mean Q2": 233.19482666015625, "critic_loss": 11.96306439590454, "batch_reward": 1.1384461040496827, "actor_loss": -234.43722411124938, "actor_target_entropy": -1.0, "actor_entropy": 0.6995671814487826, "alpha_loss": 0.010382644069801656, "alpha_value": 0.2196094009353189, "duration": 158.12790751457214, "step": 85500}
{"episode_reward": 224.68316326501895, "episode": 685.0, "Q1 loss": 6.170319812774658, "Q2 loss": 6.163267208099366, "Mean Target Q": 233.31255224609376, "Mean Q1": 233.31285729980468, "Mean Q2": 233.31270861816407, "critic_loss": 12.333587032318116, "batch_reward": 1.133998064994812, "actor_loss": -234.60718984452504, "actor_target_entropy": -1.0, "actor_entropy": 0.6838521957397461, "alpha_loss": 0.006070433273201897, "alpha_value": 0.21904884441433203, "duration": 141.3400354385376, "step": 85625}
{"episode_reward": 131.60568033096393, "episode": 686.0, "Q1 loss": 6.338111259460449, "Q2 loss": 6.357056209564209, "Mean Target Q": 233.41517138671875, "Mean Q1": 233.4089405517578, "Mean Q2": 233.4089716796875, "critic_loss": 12.695167457580567, "batch_reward": 1.138906322479248, "actor_loss": -234.66864062893777, "actor_target_entropy": -1.0, "actor_entropy": 0.6876921230746854, "alpha_loss": 0.0044326904406320426, "alpha_value": 0.21849653289793552, "duration": 147.14206099510193, "step": 85750}
{"episode_reward": 123.01810990451243, "episode": 687.0, "Q1 loss": 6.509459980010987, "Q2 loss": 6.50409260559082, "Mean Target Q": 233.50420629882814, "Mean Q1": 233.5058740234375, "Mean Q2": 233.5065361328125, "critic_loss": 13.013552619934082, "batch_reward": 1.1418892078399658, "actor_loss": -234.7544485425192, "actor_target_entropy": -1.0, "actor_entropy": 0.6916885858490354, "alpha_loss": 0.003396566328962171, "alpha_value": 0.21831867510142108, "duration": 148.0592839717865, "step": 85875}
{"episode_reward": 165.92669680852293, "episode": 688.0, "Q1 loss": 6.374322792053222, "Q2 loss": 6.368918201446533, "Mean Target Q": 233.52818359375, "Mean Q1": 233.52670532226563, "Mean Q2": 233.5262850341797, "critic_loss": 12.743241035461425, "batch_reward": 1.1400728025436402, "actor_loss": -234.76517831125568, "actor_target_entropy": -1.0, "actor_entropy": 0.6947714359529557, "alpha_loss": 0.010494036412227058, "alpha_value": 0.21797873197786297, "duration": 164.6273729801178, "step": 86000}
{"episode_reward": 97.89351228243677, "episode": 689.0, "Q1 loss": 6.567084114074707, "Q2 loss": 6.5874379501342775, "Mean Target Q": 233.53113012695312, "Mean Q1": 233.52702661132813, "Mean Q2": 233.5264805908203, "critic_loss": 13.154522056579589, "batch_reward": 1.1334414205551147, "actor_loss": -234.78041003999255, "actor_target_entropy": -1.0, "actor_entropy": 0.6842007069360643, "alpha_loss": 0.0008023869216678634, "alpha_value": 0.21732443545685626, "duration": 140.2019762992859, "step": 86125}
{"episode_reward": 188.21410456701872, "episode": 690.0, "Q1 loss": 6.780860809326172, "Q2 loss": 6.805916717529297, "Mean Target Q": 233.53533361816406, "Mean Q1": 233.53929162597657, "Mean Q2": 233.53991796875, "critic_loss": 13.586777496337891, "batch_reward": 1.138619610786438, "actor_loss": -234.73726924773186, "actor_target_entropy": -1.0, "actor_entropy": 0.684633211743447, "alpha_loss": -0.0012014235760415754, "alpha_value": 0.2174102427160857, "duration": 199.40088319778442, "step": 86250}
{"episode_reward": 237.18078206958342, "episode": 691.0, "Q1 loss": 7.0185612869262695, "Q2 loss": 7.012438507080078, "Mean Target Q": 233.71222595214843, "Mean Q1": 233.71018872070312, "Mean Q2": 233.70953173828124, "critic_loss": 14.030999809265136, "batch_reward": 1.1486043033599853, "actor_loss": -234.90076289101253, "actor_target_entropy": -1.0, "actor_entropy": 0.7059224446614584, "alpha_loss": 0.0044669244467975605, "alpha_value": 0.21741000287690884, "duration": 181.2702989578247, "step": 86375}
{"episode_reward": 258.9373752237453, "episode": 692.0, "Q1 loss": 6.503288148880005, "Q2 loss": 6.504065752029419, "Mean Target Q": 233.75579675292968, "Mean Q1": 233.75458142089843, "Mean Q2": 233.75494372558595, "critic_loss": 13.007353916168213, "batch_reward": 1.1384774932861328, "actor_loss": -234.97670672016758, "actor_target_entropy": -1.0, "actor_entropy": 0.6763821888354516, "alpha_loss": -0.0023606832274385998, "alpha_value": 0.21718818243867033, "duration": 200.79140973091125, "step": 86500}
{"episode_reward": 150.4429537058091, "episode": 693.0, "Q1 loss": 6.216819938659668, "Q2 loss": 6.236360424041748, "Mean Target Q": 233.7140234375, "Mean Q1": 233.7154041748047, "Mean Q2": 233.71520068359376, "critic_loss": 12.453180320739746, "batch_reward": 1.1406107320785523, "actor_loss": -234.8877437531002, "actor_target_entropy": -1.0, "actor_entropy": 0.7090939226604643, "alpha_loss": 0.003880738624415937, "alpha_value": 0.21710977290444666, "duration": 217.78983306884766, "step": 86625}
{"episode_reward": 166.3743915337761, "episode": 694.0, "Q1 loss": 5.956281993865967, "Q2 loss": 5.948870231628418, "Mean Target Q": 233.68546118164062, "Mean Q1": 233.68339709472656, "Mean Q2": 233.6843896484375, "critic_loss": 11.90515225982666, "batch_reward": 1.1416989164352418, "actor_loss": -234.81546832669167, "actor_target_entropy": -1.0, "actor_entropy": 0.677879705544441, "alpha_loss": 0.005628094972757202, "alpha_value": 0.21680769986001389, "duration": 208.03239130973816, "step": 86750}
{"episode_reward": 199.88482854309902, "episode": 695.0, "Q1 loss": 5.995546649932861, "Q2 loss": 5.9873178024291995, "Mean Target Q": 233.67985034179688, "Mean Q1": 233.68127697753906, "Mean Q2": 233.6799033203125, "critic_loss": 11.982864471435548, "batch_reward": 1.1436549434661865, "actor_loss": -234.89029197087365, "actor_target_entropy": -1.0, "actor_entropy": 0.6747706021581378, "alpha_loss": 0.003893584112769791, "alpha_value": 0.21650055457994516, "duration": 212.59523177146912, "step": 86875}
{"episode_reward": 64.51572286778595, "episode": 696.0, "Q1 loss": 6.034979377746582, "Q2 loss": 6.031658367156982, "Mean Target Q": 233.7791798095703, "Mean Q1": 233.7777419433594, "Mean Q2": 233.77845202636718, "critic_loss": 12.06663773727417, "batch_reward": 1.1359604063034057, "actor_loss": -234.90609052104335, "actor_target_entropy": -1.0, "actor_entropy": 0.6812529958063557, "alpha_loss": 0.0015584181490985135, "alpha_value": 0.21625879173237675, "duration": 196.04307460784912, "step": 87000}
{"episode_reward": 151.82408545095328, "episode": 697.0, "Q1 loss": 6.352264535903931, "Q2 loss": 6.366359985351562, "Mean Target Q": 233.8018876953125, "Mean Q1": 233.800171875, "Mean Q2": 233.80042443847657, "critic_loss": 12.7186244430542, "batch_reward": 1.1441692914962769, "actor_loss": -235.0552036345951, "actor_target_entropy": -1.0, "actor_entropy": 0.6831490766434443, "alpha_loss": -0.0008880112667582811, "alpha_value": 0.21615633983951438, "duration": 209.07680821418762, "step": 87125}
{"episode_reward": 182.00016384620676, "episode": 698.0, "Q1 loss": 6.188510215759277, "Q2 loss": 6.220392066955567, "Mean Target Q": 233.87626000976562, "Mean Q1": 233.87596740722657, "Mean Q2": 233.87542919921876, "critic_loss": 12.408902290344239, "batch_reward": 1.1484903059005738, "actor_loss": -235.11995647799583, "actor_target_entropy": -1.0, "actor_entropy": 0.6807135891529822, "alpha_loss": -0.003036108271654455, "alpha_value": 0.2163328347257871, "duration": 214.02818083763123, "step": 87250}
{"episode_reward": 121.05092432882483, "episode": 699.0, "Q1 loss": 6.554354942321777, "Q2 loss": 6.5755786628723145, "Mean Target Q": 233.94043359375, "Mean Q1": 233.93741125488282, "Mean Q2": 233.937310546875, "critic_loss": 13.129933570861816, "batch_reward": 1.1403212814331054, "actor_loss": -235.22078983367436, "actor_target_entropy": -1.0, "actor_entropy": 0.6728217790997217, "alpha_loss": -0.0009977102948589222, "alpha_value": 0.2167016933700468, "duration": 212.5844190120697, "step": 87375}
{"episode_reward": 156.2563026315418, "episode": 700.0, "Q1 loss": 6.638056137084961, "Q2 loss": 6.622781173706055, "Mean Target Q": 234.0965369873047, "Mean Q1": 234.0898565673828, "Mean Q2": 234.09026977539062, "critic_loss": 13.260837326049804, "batch_reward": 1.1495445942878724, "actor_loss": -235.32851139191658, "actor_target_entropy": -1.0, "actor_entropy": 0.69719605772726, "alpha_loss": -0.0015594096809265115, "alpha_value": 0.21663164008843422, "duration": 202.2558617591858, "step": 87500}
{"episode_reward": 184.9682003912458, "episode": 701.0, "Q1 loss": 7.205598224639893, "Q2 loss": 7.2275548248291015, "Mean Target Q": 234.233142578125, "Mean Q1": 234.2342501220703, "Mean Q2": 234.23381079101563, "critic_loss": 14.433153076171875, "batch_reward": 1.1454996337890626, "actor_loss": -235.57889108809215, "actor_target_entropy": -1.0, "actor_entropy": 0.6786764670932104, "alpha_loss": -0.007689435809244594, "alpha_value": 0.2169575675184487, "duration": 243.0416338443756, "step": 87625}
{"episode_reward": 57.92267387347491, "episode": 702.0, "Q1 loss": 6.79454141998291, "Q2 loss": 6.804753433227539, "Mean Target Q": 234.2035753173828, "Mean Q1": 234.20517846679687, "Mean Q2": 234.205322265625, "critic_loss": 13.59929483795166, "batch_reward": 1.1417152891159057, "actor_loss": -235.38865563177293, "actor_target_entropy": -1.0, "actor_entropy": 0.6863092799340526, "alpha_loss": -0.003055840858348435, "alpha_value": 0.21741137032535382, "duration": 206.28853726387024, "step": 87750}
{"episode_reward": 78.9748788067233, "episode": 703.0, "Q1 loss": 6.22664852142334, "Q2 loss": 6.239884357452393, "Mean Target Q": 234.15489611816406, "Mean Q1": 234.15510278320312, "Mean Q2": 234.15470727539062, "critic_loss": 12.46653288269043, "batch_reward": 1.1287463297843934, "actor_loss": -235.42919340587798, "actor_target_entropy": -1.0, "actor_entropy": 0.6986093956326681, "alpha_loss": -0.003804418932838691, "alpha_value": 0.21762057869136145, "duration": 199.02065062522888, "step": 87875}
{"episode_reward": 108.39440656105056, "episode": 704.0, "Q1 loss": 6.503061597824097, "Q2 loss": 6.48723885345459, "Mean Target Q": 234.3209835205078, "Mean Q1": 234.31848962402344, "Mean Q2": 234.31849743652344, "critic_loss": 12.990300437927246, "batch_reward": 1.1407540616989136, "actor_loss": -235.59864118022304, "actor_target_entropy": -1.0, "actor_entropy": 0.6945105070067991, "alpha_loss": 0.0014084394149962932, "alpha_value": 0.21784878190638488, "duration": 213.4920778274536, "step": 88000}
{"episode_reward": 218.79205036685315, "episode": 705.0, "Q1 loss": 6.9765516357421875, "Q2 loss": 6.996406314849853, "Mean Target Q": 234.44431652832031, "Mean Q1": 234.4461240234375, "Mean Q2": 234.44616943359375, "critic_loss": 13.972957946777344, "batch_reward": 1.1439560813903809, "actor_loss": -235.76070198180184, "actor_target_entropy": -1.0, "actor_entropy": 0.6656798843353514, "alpha_loss": 0.0034939060283322183, "alpha_value": 0.21754078961951803, "duration": 199.2611439228058, "step": 88125}
{"episode_reward": 212.5636795718516, "episode": 706.0, "Q1 loss": 6.823461322784424, "Q2 loss": 6.818974517822266, "Mean Target Q": 234.4585975341797, "Mean Q1": 234.45593688964843, "Mean Q2": 234.45610717773437, "critic_loss": 13.642435844421387, "batch_reward": 1.1366527585983277, "actor_loss": -235.70271719655682, "actor_target_entropy": -1.0, "actor_entropy": 0.6901912727663594, "alpha_loss": -0.0032770465984339673, "alpha_value": 0.21756339305045927, "duration": 200.74845027923584, "step": 88250}
{"episode_reward": 7.7732587883562605, "episode": 707.0, "Q1 loss": 6.554278560638428, "Q2 loss": 6.556256618499756, "Mean Target Q": 234.47659741210938, "Mean Q1": 234.4761845703125, "Mean Q2": 234.4768621826172, "critic_loss": 13.110535163879394, "batch_reward": 1.135356530189514, "actor_loss": -235.72237747434585, "actor_target_entropy": -1.0, "actor_entropy": 0.6917403671476576, "alpha_loss": -0.005526201149064397, "alpha_value": 0.21787871392177652, "duration": 230.22365045547485, "step": 88375}
{"episode_reward": 47.38754605825696, "episode": 708.0, "Q1 loss": 6.65666007232666, "Q2 loss": 6.671397644042969, "Mean Target Q": 234.62758740234375, "Mean Q1": 234.62565405273438, "Mean Q2": 234.62462377929688, "critic_loss": 13.32805771636963, "batch_reward": 1.1373299446105958, "actor_loss": -235.9299560054656, "actor_target_entropy": -1.0, "actor_entropy": 0.6837752144182881, "alpha_loss": 0.0024180578503517373, "alpha_value": 0.21804057414404537, "duration": 204.51494526863098, "step": 88500}
{"episode_reward": 98.48588010188303, "episode": 709.0, "Q1 loss": 6.652079097747802, "Q2 loss": 6.6553607940673825, "Mean Target Q": 234.65510424804688, "Mean Q1": 234.65432482910157, "Mean Q2": 234.65474658203124, "critic_loss": 13.307439926147461, "batch_reward": 1.1369643907546998, "actor_loss": -235.9427977062407, "actor_target_entropy": -1.0, "actor_entropy": 0.6864139201149108, "alpha_loss": 0.00044191437256005075, "alpha_value": 0.2179288190021626, "duration": 222.8405783176422, "step": 88625}
{"episode_reward": 70.50831927765212, "episode": 710.0, "Q1 loss": 6.664520664215088, "Q2 loss": 6.676054107666015, "Mean Target Q": 234.68349475097656, "Mean Q1": 234.682244140625, "Mean Q2": 234.68195092773436, "critic_loss": 13.340574760437011, "batch_reward": 1.1357755775451661, "actor_loss": -235.8644099081716, "actor_target_entropy": -1.0, "actor_entropy": 0.6811292296455752, "alpha_loss": 0.003853203296931761, "alpha_value": 0.2178102464268743, "duration": 222.82744884490967, "step": 88750}
{"episode_reward": 210.9831994307572, "episode": 711.0, "Q1 loss": 6.433957649230957, "Q2 loss": 6.438808479309082, "Mean Target Q": 234.79916821289063, "Mean Q1": 234.79618225097656, "Mean Q2": 234.79706982421874, "critic_loss": 12.872766120910644, "batch_reward": 1.142781617164612, "actor_loss": -236.0632096547929, "actor_target_entropy": -1.0, "actor_entropy": 0.6716310854942079, "alpha_loss": 0.000727000180631876, "alpha_value": 0.2175578246649856, "duration": 222.2299530506134, "step": 88875}
{"episode_reward": 94.72743024443167, "episode": 712.0, "Q1 loss": 6.159509098052978, "Q2 loss": 6.174382762908936, "Mean Target Q": 234.7404151611328, "Mean Q1": 234.744025390625, "Mean Q2": 234.7434024658203, "critic_loss": 12.333891853332519, "batch_reward": 1.1375357127189636, "actor_loss": -235.9689707602224, "actor_target_entropy": -1.0, "actor_entropy": 0.7154981868882333, "alpha_loss": 0.0015448458725586534, "alpha_value": 0.21755300237362754, "duration": 219.34084367752075, "step": 89000}
{"episode_reward": 185.7136914826969, "episode": 713.0, "Q1 loss": 6.265400840759277, "Q2 loss": 6.26083097076416, "Mean Target Q": 234.8282939453125, "Mean Q1": 234.82315173339845, "Mean Q2": 234.82369702148438, "critic_loss": 12.52623178100586, "batch_reward": 1.1381788387298584, "actor_loss": -236.04036119249133, "actor_target_entropy": -1.0, "actor_entropy": 0.6886837387841845, "alpha_loss": -0.00011094112230080461, "alpha_value": 0.217278257748409, "duration": 229.01524877548218, "step": 89125}
{"episode_reward": 75.83368441821716, "episode": 714.0, "Q1 loss": 6.482096252441406, "Q2 loss": 6.4771881008148195, "Mean Target Q": 234.8875760498047, "Mean Q1": 234.89235705566406, "Mean Q2": 234.89178186035156, "critic_loss": 12.959284355163573, "batch_reward": 1.1326522626876832, "actor_loss": -236.27966997700352, "actor_target_entropy": -1.0, "actor_entropy": 0.7085550994642319, "alpha_loss": -0.0009518060983429032, "alpha_value": 0.2174574153739044, "duration": 210.6145303249359, "step": 89250}
{"episode_reward": 243.5439143867701, "episode": 715.0, "Q1 loss": 6.637901657104492, "Q2 loss": 6.651105331420898, "Mean Target Q": 235.05118920898437, "Mean Q1": 235.04464221191407, "Mean Q2": 235.04518334960937, "critic_loss": 13.289007041931152, "batch_reward": 1.1419118795394898, "actor_loss": -236.36745416550409, "actor_target_entropy": -1.0, "actor_entropy": 0.7050045728683472, "alpha_loss": -0.0020278035736982785, "alpha_value": 0.21755298718894667, "duration": 212.9937686920166, "step": 89375}
{"episode_reward": 65.19075533418021, "episode": 716.0, "Q1 loss": 6.84190714263916, "Q2 loss": 6.866770393371582, "Mean Target Q": 235.0684979248047, "Mean Q1": 235.07257690429688, "Mean Q2": 235.07275512695313, "critic_loss": 13.708677520751953, "batch_reward": 1.1331660108566284, "actor_loss": -236.38055936751826, "actor_target_entropy": -1.0, "actor_entropy": 0.6931523786437127, "alpha_loss": 0.004148672387424496, "alpha_value": 0.21753084190567917, "duration": 187.77685141563416, "step": 89500}
{"episode_reward": 138.77279676480939, "episode": 717.0, "Q1 loss": 6.541553211212158, "Q2 loss": 6.542440826416016, "Mean Target Q": 235.11514013671874, "Mean Q1": 235.11603686523438, "Mean Q2": 235.1157578125, "critic_loss": 13.083994033813477, "batch_reward": 1.144109001159668, "actor_loss": -236.3408883715433, "actor_target_entropy": -1.0, "actor_entropy": 0.6881029605865479, "alpha_loss": -0.0002669507401093604, "alpha_value": 0.21729558611402328, "duration": 184.9309685230255, "step": 89625}
{"episode_reward": 128.01781412410702, "episode": 718.0, "Q1 loss": 6.509600528717041, "Q2 loss": 6.512864482879639, "Mean Target Q": 235.16146325683593, "Mean Q1": 235.15587670898438, "Mean Q2": 235.15511987304689, "critic_loss": 13.022465003967286, "batch_reward": 1.1356567907333375, "actor_loss": -236.39910962504726, "actor_target_entropy": -1.0, "actor_entropy": 0.6846345653457027, "alpha_loss": 0.005785654682005125, "alpha_value": 0.21714798215664285, "duration": 165.5969808101654, "step": 89750}
{"episode_reward": 85.12612909027106, "episode": 719.0, "Q1 loss": 6.6786318359375, "Q2 loss": 6.699848857879639, "Mean Target Q": 235.25867614746093, "Mean Q1": 235.26156494140625, "Mean Q2": 235.26170764160156, "critic_loss": 13.378480712890624, "batch_reward": 1.1332335891723633, "actor_loss": -236.45930747380334, "actor_target_entropy": -1.0, "actor_entropy": 0.7049577917371478, "alpha_loss": 0.005358388490368804, "alpha_value": 0.2166457379922056, "duration": 156.6560356616974, "step": 89875}
{"episode_reward": 235.15167019431036, "episode": 720.0, "Q1 loss": 6.83785933303833, "Q2 loss": 6.834682331085205, "Mean Target Q": 235.24895471191405, "Mean Q1": 235.24727917480467, "Mean Q2": 235.24727465820314, "critic_loss": 13.672541618347168, "batch_reward": 1.1413850564956665, "actor_loss": -236.63766602546937, "actor_target_entropy": -1.0, "actor_entropy": 0.6922795657188662, "alpha_loss": 0.001976031205436635, "alpha_value": 0.2165851664221661, "step": 90000}
{"duration": 169.7217562198639, "step": 90000}
{"episode_reward": 207.50089848008162, "episode": 721.0, "Q1 loss": 6.797524314880371, "Q2 loss": 6.811878810882568, "Mean Target Q": 235.32687817382813, "Mean Q1": 235.32914770507813, "Mean Q2": 235.3292635498047, "critic_loss": 13.609403106689452, "batch_reward": 1.1417072410583495, "actor_loss": -236.56274341401598, "actor_target_entropy": -1.0, "actor_entropy": 0.675718921517569, "alpha_loss": -0.0004988963316593852, "alpha_value": 0.2165029280646076, "duration": 170.56740260124207, "step": 90125}
{"episode_reward": 171.09482594295173, "episode": 722.0, "Q1 loss": 6.830520816802979, "Q2 loss": 6.826113582611084, "Mean Target Q": 235.38685498046874, "Mean Q1": 235.38025573730468, "Mean Q2": 235.37962463378906, "critic_loss": 13.656634414672851, "batch_reward": 1.1419815711975099, "actor_loss": -236.583374269547, "actor_target_entropy": -1.0, "actor_entropy": 0.6856125237480286, "alpha_loss": 0.011446101038957076, "alpha_value": 0.21596991397410004, "duration": 158.00846028327942, "step": 90250}
{"episode_reward": 220.7130744777366, "episode": 723.0, "Q1 loss": 6.82575358581543, "Q2 loss": 6.830980464935303, "Mean Target Q": 235.30298278808593, "Mean Q1": 235.3078669433594, "Mean Q2": 235.30828356933594, "critic_loss": 13.656734123229981, "batch_reward": 1.1351881256103515, "actor_loss": -236.56153239901104, "actor_target_entropy": -1.0, "actor_entropy": 0.6627539377363901, "alpha_loss": 0.0009957054548615973, "alpha_value": 0.2155554918630776, "duration": 159.07015442848206, "step": 90375}
{"episode_reward": 106.8361910960729, "episode": 724.0, "Q1 loss": 6.355945323944092, "Q2 loss": 6.343242561340332, "Mean Target Q": 235.44626599121094, "Mean Q1": 235.43958227539062, "Mean Q2": 235.43962939453124, "critic_loss": 12.699187866210938, "batch_reward": 1.1422743349075317, "actor_loss": -236.70103602255546, "actor_target_entropy": -1.0, "actor_entropy": 0.6737972690213111, "alpha_loss": -0.002551393846290246, "alpha_value": 0.2155633655036346, "duration": 174.66453552246094, "step": 90500}
{"episode_reward": 95.23924907048857, "episode": 725.0, "Q1 loss": 6.6377986106872555, "Q2 loss": 6.64417032623291, "Mean Target Q": 235.52763110351563, "Mean Q1": 235.52450732421875, "Mean Q2": 235.52418151855468, "critic_loss": 13.281968948364257, "batch_reward": 1.1368181009292602, "actor_loss": -236.7500745985243, "actor_target_entropy": -1.0, "actor_entropy": 0.6871630700807723, "alpha_loss": 0.0002536062476417375, "alpha_value": 0.2156187293624021, "duration": 168.88144278526306, "step": 90625}
{"episode_reward": 212.82480694038304, "episode": 726.0, "Q1 loss": 6.795387962341309, "Q2 loss": 6.8041216735839845, "Mean Target Q": 235.63954919433593, "Mean Q1": 235.6404091796875, "Mean Q2": 235.6405167236328, "critic_loss": 13.599509674072266, "batch_reward": 1.137179370880127, "actor_loss": -236.93743551931072, "actor_target_entropy": -1.0, "actor_entropy": 0.6487572260441319, "alpha_loss": 0.004508019766710218, "alpha_value": 0.21549116970546478, "duration": 185.45002341270447, "step": 90750}
{"episode_reward": 132.41942884242047, "episode": 727.0, "Q1 loss": 6.787756345748901, "Q2 loss": 6.819043251037598, "Mean Target Q": 235.58504162597657, "Mean Q1": 235.58534924316407, "Mean Q2": 235.58559716796876, "critic_loss": 13.606799583435059, "batch_reward": 1.1375847473144531, "actor_loss": -236.7671612936353, "actor_target_entropy": -1.0, "actor_entropy": 0.6811617139786009, "alpha_loss": 0.0006475490739657765, "alpha_value": 0.2152580447932134, "duration": 161.57024002075195, "step": 90875}
{"episode_reward": 87.72462982117322, "episode": 728.0, "Q1 loss": 6.663493167877197, "Q2 loss": 6.6749243125915525, "Mean Target Q": 235.6574969482422, "Mean Q1": 235.65405725097656, "Mean Q2": 235.65358764648437, "critic_loss": 13.338417434692383, "batch_reward": 1.1389828543663025, "actor_loss": -236.93766095561367, "actor_target_entropy": -1.0, "actor_entropy": 0.6603091522570579, "alpha_loss": 0.003412812234713666, "alpha_value": 0.21509033592646115, "duration": 155.37888312339783, "step": 91000}
{"episode_reward": 194.53528667065848, "episode": 729.0, "Q1 loss": 6.467717769622802, "Q2 loss": 6.463018054962158, "Mean Target Q": 235.70896984863282, "Mean Q1": 235.711990234375, "Mean Q2": 235.71278186035155, "critic_loss": 12.930735801696777, "batch_reward": 1.1421229667663575, "actor_loss": -236.985348171658, "actor_target_entropy": -1.0, "actor_entropy": 0.657241061566368, "alpha_loss": 0.0015923630128363295, "alpha_value": 0.21497266710470023, "duration": 164.41086959838867, "step": 91125}
{"episode_reward": 192.10422869581132, "episode": 730.0, "Q1 loss": 6.382581241607666, "Q2 loss": 6.382258722305298, "Mean Target Q": 235.75528955078124, "Mean Q1": 235.75497436523438, "Mean Q2": 235.7547658691406, "critic_loss": 12.764839942932129, "batch_reward": 1.1376404757499694, "actor_loss": -236.9385956794985, "actor_target_entropy": -1.0, "actor_entropy": 0.6634820219009153, "alpha_loss": 0.0021498974735638305, "alpha_value": 0.21468598834831615, "duration": 169.42298865318298, "step": 91250}
{"episode_reward": 154.973928382988, "episode": 731.0, "Q1 loss": 6.511947822570801, "Q2 loss": 6.535973941802978, "Mean Target Q": 235.72878454589843, "Mean Q1": 235.72651379394532, "Mean Q2": 235.72601831054686, "critic_loss": 13.047921760559081, "batch_reward": 1.1458002519607544, "actor_loss": -236.9780009436229, "actor_target_entropy": -1.0, "actor_entropy": 0.6390381909552074, "alpha_loss": 0.003660252783447504, "alpha_value": 0.21455307486093683, "duration": 160.68764805793762, "step": 91375}
{"episode_reward": 183.84838448732566, "episode": 732.0, "Q1 loss": 6.571119632720947, "Q2 loss": 6.567663589477539, "Mean Target Q": 235.69982299804687, "Mean Q1": 235.69997497558595, "Mean Q2": 235.70062414550782, "critic_loss": 13.138783203125, "batch_reward": 1.1321623058319092, "actor_loss": -236.92253974176222, "actor_target_entropy": -1.0, "actor_entropy": 0.6470642195593926, "alpha_loss": 0.0027061329578094546, "alpha_value": 0.21445928195332678, "duration": 164.60905075073242, "step": 91500}
{"episode_reward": 102.21024463545939, "episode": 733.0, "Q1 loss": 6.105163970947266, "Q2 loss": 6.112642345428466, "Mean Target Q": 235.78178173828124, "Mean Q1": 235.78157019042968, "Mean Q2": 235.7808994140625, "critic_loss": 12.217806354522706, "batch_reward": 1.142216435432434, "actor_loss": -237.01618352012028, "actor_target_entropy": -1.0, "actor_entropy": 0.6659032210471139, "alpha_loss": 0.00661201022254924, "alpha_value": 0.2139384149959191, "duration": 166.91648888587952, "step": 91625}
{"episode_reward": 196.57283083167982, "episode": 734.0, "Q1 loss": 6.1231403465271, "Q2 loss": 6.111719493865967, "Mean Target Q": 235.7556682128906, "Mean Q1": 235.75231237792968, "Mean Q2": 235.75258654785156, "critic_loss": 12.234859867095947, "batch_reward": 1.1380701632499695, "actor_loss": -236.98680606965095, "actor_target_entropy": -1.0, "actor_entropy": 0.6891475704408461, "alpha_loss": 0.00602129086731903, "alpha_value": 0.21331387090932413, "duration": 166.72270345687866, "step": 91750}
{"episode_reward": 164.3894993673303, "episode": 735.0, "Q1 loss": 5.927018518447876, "Q2 loss": 5.943707622528076, "Mean Target Q": 235.8041379394531, "Mean Q1": 235.80291247558594, "Mean Q2": 235.80259729003907, "critic_loss": 11.870726173400879, "batch_reward": 1.1479176597595215, "actor_loss": -236.90183924114893, "actor_target_entropy": -1.0, "actor_entropy": 0.6631424162122939, "alpha_loss": 0.011513672211015272, "alpha_value": 0.2126601276937168, "duration": 135.3171112537384, "step": 91875}
{"episode_reward": 125.70364296586845, "episode": 736.0, "Q1 loss": 6.052834419250488, "Q2 loss": 6.058130931854248, "Mean Target Q": 235.75971655273437, "Mean Q1": 235.75828295898438, "Mean Q2": 235.7583514404297, "critic_loss": 12.110965396881104, "batch_reward": 1.1413467750549315, "actor_loss": -237.04222476097846, "actor_target_entropy": -1.0, "actor_entropy": 0.6634282335158317, "alpha_loss": 0.00162067738241486, "alpha_value": 0.21219694427631985, "duration": 158.3082411289215, "step": 92000}
{"episode_reward": 136.98019375144366, "episode": 737.0, "Q1 loss": 6.606757991790771, "Q2 loss": 6.62280453491211, "Mean Target Q": 235.96097790527344, "Mean Q1": 235.96476257324218, "Mean Q2": 235.96499267578125, "critic_loss": 13.229562545776368, "batch_reward": 1.140146125793457, "actor_loss": -237.34640139625185, "actor_target_entropy": -1.0, "actor_entropy": 0.6817995745038229, "alpha_loss": -0.006069334669201266, "alpha_value": 0.21232860771306003, "duration": 168.35863208770752, "step": 92125}
{"episode_reward": 177.48859314093926, "episode": 738.0, "Q1 loss": 6.983826240539551, "Q2 loss": 6.995186031341553, "Mean Target Q": 236.01943505859376, "Mean Q1": 236.01633728027343, "Mean Q2": 236.016060546875, "critic_loss": 13.979012275695801, "batch_reward": 1.1419557399749756, "actor_loss": -237.32522386120212, "actor_target_entropy": -1.0, "actor_entropy": 0.6942221483876628, "alpha_loss": -0.001705463325995351, "alpha_value": 0.2127505543332087, "duration": 159.54705905914307, "step": 92250}
{"episode_reward": 96.19239989310667, "episode": 739.0, "Q1 loss": 6.641385635375976, "Q2 loss": 6.634266166687012, "Mean Target Q": 236.1004951171875, "Mean Q1": 236.0903135986328, "Mean Q2": 236.09037158203125, "critic_loss": 13.275651725769043, "batch_reward": 1.140483925819397, "actor_loss": -237.42538185725135, "actor_target_entropy": -1.0, "actor_entropy": 0.6613061342920575, "alpha_loss": -0.0012778356682420487, "alpha_value": 0.21275088486631005, "duration": 175.42120146751404, "step": 92375}
{"episode_reward": 126.97319595764299, "episode": 740.0, "Q1 loss": 6.934278617858887, "Q2 loss": 6.9547088356018065, "Mean Target Q": 236.27665771484374, "Mean Q1": 236.28290161132813, "Mean Q2": 236.2832166748047, "critic_loss": 13.888987487792969, "batch_reward": 1.1491337399482726, "actor_loss": -237.54766574982673, "actor_target_entropy": -1.0, "actor_entropy": 0.6698895202529046, "alpha_loss": -0.005625260259670716, "alpha_value": 0.21299293964183047, "duration": 176.90507411956787, "step": 92500}
{"episode_reward": 205.6292258218473, "episode": 741.0, "Q1 loss": 6.771389392852783, "Q2 loss": 6.785586505889893, "Mean Target Q": 236.23411083984374, "Mean Q1": 236.232927734375, "Mean Q2": 236.23180114746094, "critic_loss": 13.556975883483886, "batch_reward": 1.1371831750869752, "actor_loss": -237.5341322157118, "actor_target_entropy": -1.0, "actor_entropy": 0.6701961604375688, "alpha_loss": 0.003555331966795382, "alpha_value": 0.21294398549461357, "duration": 167.19010376930237, "step": 92625}
{"episode_reward": 78.4160830179177, "episode": 742.0, "Q1 loss": 6.542963836669922, "Q2 loss": 6.5527851829528805, "Mean Target Q": 236.2422219238281, "Mean Q1": 236.238103515625, "Mean Q2": 236.23910192871094, "critic_loss": 13.0957490234375, "batch_reward": 1.146568593978882, "actor_loss": -237.46300555813698, "actor_target_entropy": -1.0, "actor_entropy": 0.6864833043467614, "alpha_loss": -0.00015908001824432324, "alpha_value": 0.21308376388802708, "duration": 158.8338053226471, "step": 92750}
{"episode_reward": 119.64409279117898, "episode": 743.0, "Q1 loss": 6.350861808776855, "Q2 loss": 6.349573089599609, "Mean Target Q": 236.19688195800782, "Mean Q1": 236.20486950683593, "Mean Q2": 236.20439208984374, "critic_loss": 12.700434898376464, "batch_reward": 1.1440843200683595, "actor_loss": -237.44021993970114, "actor_target_entropy": -1.0, "actor_entropy": 0.7001473184615846, "alpha_loss": 0.004489747500638404, "alpha_value": 0.21295302394217946, "duration": 160.76324439048767, "step": 92875}
{"episode_reward": 176.38859853297876, "episode": 744.0, "Q1 loss": 6.333088268280029, "Q2 loss": 6.349517272949218, "Mean Target Q": 236.24090307617186, "Mean Q1": 236.23963842773438, "Mean Q2": 236.23925964355467, "critic_loss": 12.682605522155761, "batch_reward": 1.1461755676269532, "actor_loss": -237.48689516129033, "actor_target_entropy": -1.0, "actor_entropy": 0.6619180585107496, "alpha_loss": -0.0031777866749889065, "alpha_value": 0.21264801138989964, "duration": 159.7328701019287, "step": 93000}
{"episode_reward": 226.67482015486064, "episode": 745.0, "Q1 loss": 6.412366176605224, "Q2 loss": 6.424816268920899, "Mean Target Q": 236.41966540527343, "Mean Q1": 236.41572143554689, "Mean Q2": 236.41628210449218, "critic_loss": 12.837182418823243, "batch_reward": 1.146173583984375, "actor_loss": -237.71857755146328, "actor_target_entropy": -1.0, "actor_entropy": 0.6517491321715098, "alpha_loss": -0.006518602020121993, "alpha_value": 0.2130760623468475, "duration": 163.06087350845337, "step": 93125}
{"episode_reward": 196.02465562616916, "episode": 746.0, "Q1 loss": 6.5832581596374515, "Q2 loss": 6.586903179168702, "Mean Target Q": 236.52717419433594, "Mean Q1": 236.5229276123047, "Mean Q2": 236.52268298339843, "critic_loss": 13.170161376953125, "batch_reward": 1.143120819091797, "actor_loss": -237.77169233752835, "actor_target_entropy": -1.0, "actor_entropy": 0.6962346434593201, "alpha_loss": -0.0026744136252560683, "alpha_value": 0.21351451499937088, "duration": 153.15713167190552, "step": 93250}
{"episode_reward": 158.4757645227718, "episode": 747.0, "Q1 loss": 6.771663726806641, "Q2 loss": 6.799516139984131, "Mean Target Q": 236.58084204101561, "Mean Q1": 236.58223962402343, "Mean Q2": 236.58172680664063, "critic_loss": 13.571179847717286, "batch_reward": 1.140012605190277, "actor_loss": -237.8424326578776, "actor_target_entropy": -1.0, "actor_entropy": 0.6841940151320564, "alpha_loss": -0.000510416706905715, "alpha_value": 0.2136102747153026, "duration": 172.73409748077393, "step": 93375}
{"episode_reward": 188.3140220965771, "episode": 748.0, "Q1 loss": 6.96298422241211, "Q2 loss": 6.955077613830566, "Mean Target Q": 236.7927938232422, "Mean Q1": 236.79223510742187, "Mean Q2": 236.79246618652343, "critic_loss": 13.918061889648438, "batch_reward": 1.1468948078155519, "actor_loss": -238.19283442343436, "actor_target_entropy": -1.0, "actor_entropy": 0.6468752372649408, "alpha_loss": -0.0022214864974000282, "alpha_value": 0.21370728653626608, "duration": 161.43466806411743, "step": 93500}
{"episode_reward": 61.31508264474591, "episode": 749.0, "Q1 loss": 6.756387172698974, "Q2 loss": 6.747181814193725, "Mean Target Q": 236.72329821777345, "Mean Q1": 236.72406286621094, "Mean Q2": 236.72421484375, "critic_loss": 13.503568992614746, "batch_reward": 1.1369147510528566, "actor_loss": -238.05695016043526, "actor_target_entropy": -1.0, "actor_entropy": 0.6761453795054603, "alpha_loss": -0.009309259125046314, "alpha_value": 0.21422637686026907, "duration": 148.2663152217865, "step": 93625}
{"episode_reward": 182.41449681630672, "episode": 750.0, "Q1 loss": 7.181702045440674, "Q2 loss": 7.20053190612793, "Mean Target Q": 236.69419934082032, "Mean Q1": 236.69370776367188, "Mean Q2": 236.6933896484375, "critic_loss": 14.38223397064209, "batch_reward": 1.1378602871894836, "actor_loss": -237.9786896244172, "actor_target_entropy": -1.0, "actor_entropy": 0.6885261160712088, "alpha_loss": 0.0002917172237028999, "alpha_value": 0.21465949288693167, "duration": 158.9579107761383, "step": 93750}
{"episode_reward": 94.1185434054914, "episode": 751.0, "Q1 loss": 6.65051919555664, "Q2 loss": 6.665641521453858, "Mean Target Q": 236.77562548828126, "Mean Q1": 236.77365942382812, "Mean Q2": 236.77381555175782, "critic_loss": 13.316160705566407, "batch_reward": 1.1474928064346313, "actor_loss": -237.96026514446925, "actor_target_entropy": -1.0, "actor_entropy": 0.6522809654947311, "alpha_loss": 0.005245760526685487, "alpha_value": 0.2143241804339169, "duration": 156.6092267036438, "step": 93875}
{"episode_reward": 152.00804737011305, "episode": 752.0, "Q1 loss": 6.414569404602051, "Q2 loss": 6.443479804992676, "Mean Target Q": 236.78268310546875, "Mean Q1": 236.77851635742186, "Mean Q2": 236.7787099609375, "critic_loss": 12.858049201965333, "batch_reward": 1.1522998743057251, "actor_loss": -237.94835982784147, "actor_target_entropy": -1.0, "actor_entropy": 0.6455263158967418, "alpha_loss": 0.008491057264167936, "alpha_value": 0.2136749133904121, "duration": 174.95412850379944, "step": 94000}
{"episode_reward": 169.3628003899485, "episode": 753.0, "Q1 loss": 6.248897941589355, "Q2 loss": 6.263355056762696, "Mean Target Q": 236.76146350097656, "Mean Q1": 236.76378649902344, "Mean Q2": 236.76387561035156, "critic_loss": 12.512253036499024, "batch_reward": 1.1474972410202027, "actor_loss": -238.01718284970238, "actor_target_entropy": -1.0, "actor_entropy": 0.6628158111420889, "alpha_loss": 0.0002617793054216438, "alpha_value": 0.2135270185172722, "duration": 176.4976634979248, "step": 94125}
{"episode_reward": 90.87337527229866, "episode": 754.0, "Q1 loss": 6.476218441009522, "Q2 loss": 6.477720657348633, "Mean Target Q": 236.88279443359374, "Mean Q1": 236.88381909179688, "Mean Q2": 236.8839462890625, "critic_loss": 12.953939140319823, "batch_reward": 1.1488652572631837, "actor_loss": -238.05773458173198, "actor_target_entropy": -1.0, "actor_entropy": 0.6768735551065014, "alpha_loss": 0.0017268548779670269, "alpha_value": 0.21343535959756588, "duration": 164.45120358467102, "step": 94250}
{"episode_reward": 61.23383512397158, "episode": 755.0, "Q1 loss": 6.343023872375488, "Q2 loss": 6.354527833938598, "Mean Target Q": 236.84219091796874, "Mean Q1": 236.83612329101564, "Mean Q2": 236.83539770507812, "critic_loss": 12.697551651000976, "batch_reward": 1.1459333972930907, "actor_loss": -238.08030942886595, "actor_target_entropy": -1.0, "actor_entropy": 0.6790565649668375, "alpha_loss": 0.00637000502781972, "alpha_value": 0.21310472639000091, "duration": 164.8318109512329, "step": 94375}
{"episode_reward": 202.74639457117271, "episode": 756.0, "Q1 loss": 6.309182277679444, "Q2 loss": 6.306413784027099, "Mean Target Q": 236.82888061523437, "Mean Q1": 236.82802282714843, "Mean Q2": 236.82788977050782, "critic_loss": 12.61559603881836, "batch_reward": 1.1453433389663696, "actor_loss": -238.07641453896798, "actor_target_entropy": -1.0, "actor_entropy": 0.679848765173266, "alpha_loss": -0.004432265676798359, "alpha_value": 0.21287780183446398, "duration": 183.91008758544922, "step": 94500}
{"episode_reward": 229.1431421442773, "episode": 757.0, "Q1 loss": 6.495783878326416, "Q2 loss": 6.517264369964599, "Mean Target Q": 236.93461584472655, "Mean Q1": 236.93118908691406, "Mean Q2": 236.9313406982422, "critic_loss": 13.013048225402832, "batch_reward": 1.148319489479065, "actor_loss": -238.16425044952877, "actor_target_entropy": -1.0, "actor_entropy": 0.7087367498685443, "alpha_loss": 0.003470370165323691, "alpha_value": 0.2129643881999039, "duration": 168.238347530365, "step": 94625}
{"episode_reward": 131.68518627429933, "episode": 758.0, "Q1 loss": 6.393239887237549, "Q2 loss": 6.403387573242187, "Mean Target Q": 237.0154715576172, "Mean Q1": 237.01618811035155, "Mean Q2": 237.0163673095703, "critic_loss": 12.796627471923829, "batch_reward": 1.1422721405029297, "actor_loss": -238.282595972861, "actor_target_entropy": -1.0, "actor_entropy": 0.6906812806283275, "alpha_loss": 0.005385951553997133, "alpha_value": 0.2125984931439312, "duration": 160.44137597084045, "step": 94750}
{"episode_reward": 202.09783407736842, "episode": 759.0, "Q1 loss": 6.118221027374267, "Q2 loss": 6.111278497695923, "Mean Target Q": 236.93454357910156, "Mean Q1": 236.93688061523437, "Mean Q2": 236.93649743652344, "critic_loss": 12.229499496459962, "batch_reward": 1.1389136447906494, "actor_loss": -238.09879629952567, "actor_target_entropy": -1.0, "actor_entropy": 0.6726602060454232, "alpha_loss": 0.008398097464888697, "alpha_value": 0.2121952456749974, "duration": 150.04583883285522, "step": 94875}
{"episode_reward": 103.47935728824311, "episode": 760.0, "Q1 loss": 6.042908502578736, "Q2 loss": 6.0432516307830815, "Mean Target Q": 236.9844521484375, "Mean Q1": 236.98004138183595, "Mean Q2": 236.98051708984374, "critic_loss": 12.086160118103027, "batch_reward": 1.1379078764915467, "actor_loss": -238.30037935318487, "actor_target_entropy": -1.0, "actor_entropy": 0.6570842487196769, "alpha_loss": -0.0031940220750027127, "alpha_value": 0.21173999130968102, "step": 95000}
{"duration": 167.83614134788513, "step": 95000}
{"episode_reward": 178.65394713679586, "episode": 761.0, "Q1 loss": 6.54186332321167, "Q2 loss": 6.547932445526123, "Mean Target Q": 237.26678979492186, "Mean Q1": 237.2712723388672, "Mean Q2": 237.2709344482422, "critic_loss": 13.089795791625976, "batch_reward": 1.1483076810836792, "actor_loss": -238.44681972927518, "actor_target_entropy": -1.0, "actor_entropy": 0.6664852755410331, "alpha_loss": 0.004132703172102097, "alpha_value": 0.21191070499427525, "duration": 162.60659408569336, "step": 95125}
{"episode_reward": 148.2554085155532, "episode": 762.0, "Q1 loss": 6.394959774017334, "Q2 loss": 6.399064788818359, "Mean Target Q": 237.26310595703126, "Mean Q1": 237.25924438476562, "Mean Q2": 237.25958447265626, "critic_loss": 12.794024566650391, "batch_reward": 1.1429606161117554, "actor_loss": -238.51658261206842, "actor_target_entropy": -1.0, "actor_entropy": 0.6640921927267506, "alpha_loss": 0.006085687970382071, "alpha_value": 0.21168559474395174, "duration": 161.0816295146942, "step": 95250}
{"episode_reward": 62.942336627999985, "episode": 763.0, "Q1 loss": 6.901684558868408, "Q2 loss": 6.902915702819824, "Mean Target Q": 237.2553311767578, "Mean Q1": 237.24879296875, "Mean Q2": 237.2482247314453, "critic_loss": 13.804600227355957, "batch_reward": 1.141130488395691, "actor_loss": -238.44298274933345, "actor_target_entropy": -1.0, "actor_entropy": 0.6563413540522257, "alpha_loss": -0.0002841621208640318, "alpha_value": 0.21128844364122956, "duration": 169.61000609397888, "step": 95375}
{"episode_reward": 187.23708345815137, "episode": 764.0, "Q1 loss": 6.346758453369141, "Q2 loss": 6.3555764389038085, "Mean Target Q": 237.1738302001953, "Mean Q1": 237.17638354492186, "Mean Q2": 237.176103515625, "critic_loss": 12.702334930419921, "batch_reward": 1.1490566301345826, "actor_loss": -238.33307401595576, "actor_target_entropy": -1.0, "actor_entropy": 0.6620340097335077, "alpha_loss": 0.00016740500746715453, "alpha_value": 0.2112311761443192, "duration": 165.44664025306702, "step": 95500}
{"episode_reward": 191.83896694492677, "episode": 765.0, "Q1 loss": 6.2675431537628175, "Q2 loss": 6.273824981689453, "Mean Target Q": 237.1589592285156, "Mean Q1": 237.159404296875, "Mean Q2": 237.16028759765624, "critic_loss": 12.541368125915527, "batch_reward": 1.14930841255188, "actor_loss": -238.33541022406683, "actor_target_entropy": -1.0, "actor_entropy": 0.6989084425426665, "alpha_loss": 0.008753451090010385, "alpha_value": 0.21098110941154397, "duration": 167.427649974823, "step": 95625}
{"episode_reward": 104.59868245287306, "episode": 766.0, "Q1 loss": 6.261260158538819, "Q2 loss": 6.26005863571167, "Mean Target Q": 237.15415600585936, "Mean Q1": 237.15415979003907, "Mean Q2": 237.1540859375, "critic_loss": 12.521318817138672, "batch_reward": 1.1346863651275634, "actor_loss": -238.35323678293537, "actor_target_entropy": -1.0, "actor_entropy": 0.6538370751565502, "alpha_loss": 0.0009207387469829091, "alpha_value": 0.210640435731828, "duration": 153.88342189788818, "step": 95750}
{"episode_reward": 59.7999385583592, "episode": 767.0, "Q1 loss": 6.537264274597168, "Q2 loss": 6.548888282775879, "Mean Target Q": 237.2240654296875, "Mean Q1": 237.21852307128907, "Mean Q2": 237.21750659179688, "critic_loss": 13.086152549743652, "batch_reward": 1.1476540393829346, "actor_loss": -238.4262482173859, "actor_target_entropy": -1.0, "actor_entropy": 0.6232897147299752, "alpha_loss": 0.0024712584591248914, "alpha_value": 0.21042199885229534, "duration": 150.81933212280273, "step": 95875}
{"episode_reward": 215.29469570212382, "episode": 768.0, "Q1 loss": 6.49725804901123, "Q2 loss": 6.504155456542969, "Mean Target Q": 237.13797033691407, "Mean Q1": 237.13992297363282, "Mean Q2": 237.14006103515624, "critic_loss": 13.00141349029541, "batch_reward": 1.1325146656036378, "actor_loss": -238.34427765877015, "actor_target_entropy": -1.0, "actor_entropy": 0.668937171659162, "alpha_loss": 0.011276450578964526, "alpha_value": 0.20975075035628107, "duration": 166.9840226173401, "step": 96000}
{"episode_reward": 153.56680035970973, "episode": 769.0, "Q1 loss": 6.275427850723267, "Q2 loss": 6.284106388092041, "Mean Target Q": 237.2669200439453, "Mean Q1": 237.27001147460936, "Mean Q2": 237.27033435058593, "critic_loss": 12.559534217834473, "batch_reward": 1.142755208015442, "actor_loss": -238.52904643709698, "actor_target_entropy": -1.0, "actor_entropy": 0.6763849882852464, "alpha_loss": 0.0052999139778197755, "alpha_value": 0.20933516192140428, "duration": 188.85442113876343, "step": 96125}
{"episode_reward": 157.64866568505073, "episode": 770.0, "Q1 loss": 6.3407934875488285, "Q2 loss": 6.340990791320801, "Mean Target Q": 237.31828747558595, "Mean Q1": 237.31518811035156, "Mean Q2": 237.3156368408203, "critic_loss": 12.681784255981444, "batch_reward": 1.1438983383178711, "actor_loss": -238.57391357421875, "actor_target_entropy": -1.0, "actor_entropy": 0.6583646209009232, "alpha_loss": -0.003372887335342145, "alpha_value": 0.2093121623820297, "duration": 166.33221125602722, "step": 96250}
{"episode_reward": 229.46341195340818, "episode": 771.0, "Q1 loss": 6.260964487075806, "Q2 loss": 6.274322490692139, "Mean Target Q": 237.3453564453125, "Mean Q1": 237.34310583496094, "Mean Q2": 237.34321228027343, "critic_loss": 12.53528695678711, "batch_reward": 1.1391868615150451, "actor_loss": -238.6161385188027, "actor_target_entropy": -1.0, "actor_entropy": 0.6596331028711229, "alpha_loss": 0.0068800761345921765, "alpha_value": 0.20904415794204673, "duration": 168.67986035346985, "step": 96375}
{"episode_reward": 190.72181117533094, "episode": 772.0, "Q1 loss": 6.636852172851563, "Q2 loss": 6.63628271484375, "Mean Target Q": 237.40225524902343, "Mean Q1": 237.40160327148436, "Mean Q2": 237.40092272949218, "critic_loss": 13.273134868621826, "batch_reward": 1.1447529439926147, "actor_loss": -238.60160040086316, "actor_target_entropy": -1.0, "actor_entropy": 0.6482102371031239, "alpha_loss": 0.003927674309741105, "alpha_value": 0.2085592204421058, "duration": 178.93554377555847, "step": 96500}
{"episode_reward": 209.77983360704545, "episode": 773.0, "Q1 loss": 6.511865524291992, "Q2 loss": 6.499320442199707, "Mean Target Q": 237.5159063720703, "Mean Q1": 237.51655053710937, "Mean Q2": 237.51708044433593, "critic_loss": 13.011185974121094, "batch_reward": 1.1482764644622803, "actor_loss": -238.7756090921069, "actor_target_entropy": -1.0, "actor_entropy": 0.6586872793379284, "alpha_loss": 0.0027058921321960433, "alpha_value": 0.20850133132678164, "duration": 162.3484709262848, "step": 96625}
{"episode_reward": 149.31169383787935, "episode": 774.0, "Q1 loss": 6.320301860809326, "Q2 loss": 6.314384395599365, "Mean Target Q": 237.50666845703125, "Mean Q1": 237.50428430175782, "Mean Q2": 237.5039892578125, "critic_loss": 12.63468622970581, "batch_reward": 1.1493974676132201, "actor_loss": -238.64485759119833, "actor_target_entropy": -1.0, "actor_entropy": 0.6424341115259355, "alpha_loss": 0.003867579624056816, "alpha_value": 0.20815632452203045, "duration": 154.4808864593506, "step": 96750}
{"episode_reward": 46.1545375523269, "episode": 775.0, "Q1 loss": 6.2142755241394045, "Q2 loss": 6.217280387878418, "Mean Target Q": 237.4168963623047, "Mean Q1": 237.41637585449217, "Mean Q2": 237.41594970703125, "critic_loss": 12.431555870056153, "batch_reward": 1.147542579650879, "actor_loss": -238.47401621985057, "actor_target_entropy": -1.0, "actor_entropy": 0.6619242827097574, "alpha_loss": 0.00929718762857928, "alpha_value": 0.20771232264206882, "duration": 152.80721426010132, "step": 96875}
{"episode_reward": 70.30143704065975, "episode": 776.0, "Q1 loss": 6.2146407279968265, "Q2 loss": 6.248045907974243, "Mean Target Q": 237.3266298828125, "Mean Q1": 237.3231339111328, "Mean Q2": 237.3232724609375, "critic_loss": 12.462686645507812, "batch_reward": 1.1592238302230835, "actor_loss": -238.4951917586788, "actor_target_entropy": -1.0, "actor_entropy": 0.6494930184656574, "alpha_loss": 0.008181152970439965, "alpha_value": 0.2070427213654049, "duration": 172.94112372398376, "step": 97000}
{"episode_reward": 108.86329151677987, "episode": 777.0, "Q1 loss": 6.2507553424835205, "Q2 loss": 6.244985143661499, "Mean Target Q": 237.39098205566407, "Mean Q1": 237.39514990234375, "Mean Q2": 237.39565100097656, "critic_loss": 12.49574055480957, "batch_reward": 1.1382666902542113, "actor_loss": -238.74261353507873, "actor_target_entropy": -1.0, "actor_entropy": 0.6332876937729972, "alpha_loss": -0.0055427836025104165, "alpha_value": 0.2067243298520372, "duration": 190.45679354667664, "step": 97125}
{"episode_reward": 139.46161742722498, "episode": 778.0, "Q1 loss": 6.395148544311524, "Q2 loss": 6.397609661102295, "Mean Target Q": 237.43614587402342, "Mean Q1": 237.43383850097655, "Mean Q2": 237.43362353515624, "critic_loss": 12.792758171081543, "batch_reward": 1.1420908899307252, "actor_loss": -238.69272761191093, "actor_target_entropy": -1.0, "actor_entropy": 0.6367152813942202, "alpha_loss": -0.001037162386872355, "alpha_value": 0.20705969966488397, "duration": 166.93615674972534, "step": 97250}
{"episode_reward": 166.29359734626536, "episode": 779.0, "Q1 loss": 6.6924640045166015, "Q2 loss": 6.700367519378662, "Mean Target Q": 237.54213110351563, "Mean Q1": 237.53872180175782, "Mean Q2": 237.5384201660156, "critic_loss": 13.392831573486328, "batch_reward": 1.1502840404510497, "actor_loss": -238.7817595951141, "actor_target_entropy": -1.0, "actor_entropy": 0.6404453979598151, "alpha_loss": 0.0033913822881581767, "alpha_value": 0.2069601170115843, "duration": 120.48731088638306, "step": 97375}
{"episode_reward": 157.70403470719737, "episode": 780.0, "Q1 loss": 6.574243614196777, "Q2 loss": 6.573878391265869, "Mean Target Q": 237.5559482421875, "Mean Q1": 237.5606954345703, "Mean Q2": 237.56026989746093, "critic_loss": 13.148122024536132, "batch_reward": 1.1473025178909302, "actor_loss": -238.83710233626826, "actor_target_entropy": -1.0, "actor_entropy": 0.6520914829546406, "alpha_loss": -0.0022827695844875226, "alpha_value": 0.20700398636846024, "duration": 166.77456736564636, "step": 97500}
{"episode_reward": 177.0445709133265, "episode": 781.0, "Q1 loss": 7.024204746246338, "Q2 loss": 7.02369047164917, "Mean Target Q": 237.64601501464844, "Mean Q1": 237.6383641357422, "Mean Q2": 237.63832482910155, "critic_loss": 14.047895210266113, "batch_reward": 1.1366568183898926, "actor_loss": -238.97044638981896, "actor_target_entropy": -1.0, "actor_entropy": 0.6525208003937252, "alpha_loss": -0.009027763835287519, "alpha_value": 0.20741254461863115, "duration": 157.4143795967102, "step": 97625}
{"episode_reward": 149.17564469276303, "episode": 782.0, "Q1 loss": 6.927280849456787, "Q2 loss": 6.933920677185059, "Mean Target Q": 237.70024658203124, "Mean Q1": 237.70440600585937, "Mean Q2": 237.70520935058593, "critic_loss": 13.86120150756836, "batch_reward": 1.1400785970687866, "actor_loss": -238.9075199250252, "actor_target_entropy": -1.0, "actor_entropy": 0.6766511288381392, "alpha_loss": -0.003024442324174508, "alpha_value": 0.20799192485380202, "duration": 175.84887385368347, "step": 97750}
{"episode_reward": 203.22426062464072, "episode": 783.0, "Q1 loss": 6.8300184059143065, "Q2 loss": 6.825752521514892, "Mean Target Q": 237.6389979248047, "Mean Q1": 237.63495544433593, "Mean Q2": 237.63483142089845, "critic_loss": 13.655770896911621, "batch_reward": 1.139555290222168, "actor_loss": -238.93753754146516, "actor_target_entropy": -1.0, "actor_entropy": 0.6648520779988122, "alpha_loss": -0.0012987548252567649, "alpha_value": 0.20816148987604677, "duration": 167.7599537372589, "step": 97875}
{"episode_reward": 139.2795500121456, "episode": 784.0, "Q1 loss": 6.427387504577637, "Q2 loss": 6.427829780578613, "Mean Target Q": 237.72484997558593, "Mean Q1": 237.72748413085938, "Mean Q2": 237.7267880859375, "critic_loss": 12.855217239379883, "batch_reward": 1.1424737768173219, "actor_loss": -238.89973941926033, "actor_target_entropy": -1.0, "actor_entropy": 0.6763049998591023, "alpha_loss": 0.005150594170235338, "alpha_value": 0.2079234760721783, "duration": 173.40799975395203, "step": 98000}
{"episode_reward": 126.71191197655602, "episode": 785.0, "Q1 loss": 6.312172840118408, "Q2 loss": 6.324339817047119, "Mean Target Q": 237.72493811035156, "Mean Q1": 237.72091479492187, "Mean Q2": 237.7214561767578, "critic_loss": 12.636512687683105, "batch_reward": 1.1495469799041749, "actor_loss": -238.94937182229663, "actor_target_entropy": -1.0, "actor_entropy": 0.6819767289691501, "alpha_loss": -0.007392183788830326, "alpha_value": 0.20789388256527877, "duration": 159.3922336101532, "step": 98125}
{"episode_reward": 135.02833844840737, "episode": 786.0, "Q1 loss": 6.4690263557434085, "Q2 loss": 6.474988254547119, "Mean Target Q": 237.81038610839843, "Mean Q1": 237.8119346923828, "Mean Q2": 237.81198156738282, "critic_loss": 12.94401456451416, "batch_reward": 1.145942286491394, "actor_loss": -238.97286568918537, "actor_target_entropy": -1.0, "actor_entropy": 0.6631535647376892, "alpha_loss": -0.004692334298705382, "alpha_value": 0.20852620322507592, "duration": 165.37612509727478, "step": 98250}
{"episode_reward": 194.73214192394738, "episode": 787.0, "Q1 loss": 6.032016283035278, "Q2 loss": 6.036720087051392, "Mean Target Q": 237.78411389160155, "Mean Q1": 237.78473046875, "Mean Q2": 237.7842646484375, "critic_loss": 12.068736381530762, "batch_reward": 1.1461594223976135, "actor_loss": -238.96800740559897, "actor_target_entropy": -1.0, "actor_entropy": 0.652793856840285, "alpha_loss": -0.0007440847536874195, "alpha_value": 0.20876391289459717, "duration": 174.21830105781555, "step": 98375}
{"episode_reward": 187.0736758098511, "episode": 788.0, "Q1 loss": 6.050609714508057, "Q2 loss": 6.048887912750244, "Mean Target Q": 237.75240454101564, "Mean Q1": 237.74528820800782, "Mean Q2": 237.74577587890624, "critic_loss": 12.0994976272583, "batch_reward": 1.1357700691223145, "actor_loss": -239.0204561295048, "actor_target_entropy": -1.0, "actor_entropy": 0.6470605980965399, "alpha_loss": -0.003343525346398594, "alpha_value": 0.20872243532530782, "duration": 160.186190366745, "step": 98500}
{"episode_reward": 176.04433819409624, "episode": 789.0, "Q1 loss": 6.218032047271729, "Q2 loss": 6.210896457672119, "Mean Target Q": 237.84914123535157, "Mean Q1": 237.85190063476563, "Mean Q2": 237.8523221435547, "critic_loss": 12.428928466796876, "batch_reward": 1.150970995426178, "actor_loss": -239.09535386827258, "actor_target_entropy": -1.0, "actor_entropy": 0.6531307299931844, "alpha_loss": -0.003241507879768809, "alpha_value": 0.20906542881894044, "duration": 162.47088241577148, "step": 98625}
{"episode_reward": 180.09015480364016, "episode": 790.0, "Q1 loss": 6.3580487365722655, "Q2 loss": 6.3511967086792, "Mean Target Q": 237.93568811035155, "Mean Q1": 237.93524780273438, "Mean Q2": 237.93479296875, "critic_loss": 12.709245460510253, "batch_reward": 1.1515964555740357, "actor_loss": -239.16758826471144, "actor_target_entropy": -1.0, "actor_entropy": 0.6589761770540669, "alpha_loss": -0.00264599371228307, "alpha_value": 0.20930197427429512, "duration": 175.3715591430664, "step": 98750}
{"episode_reward": 98.41577207335176, "episode": 791.0, "Q1 loss": 6.025736377716065, "Q2 loss": 6.028310791015625, "Mean Target Q": 237.93030932617188, "Mean Q1": 237.92777038574218, "Mean Q2": 237.92786401367186, "critic_loss": 12.054047225952148, "batch_reward": 1.1415125370025634, "actor_loss": -239.12618679470486, "actor_target_entropy": -1.0, "actor_entropy": 0.6598169718469892, "alpha_loss": -0.0030116204408899188, "alpha_value": 0.20959271633062454, "duration": 171.02894806861877, "step": 98875}
{"episode_reward": 81.72446041515076, "episode": 792.0, "Q1 loss": 6.37613245010376, "Q2 loss": 6.399678176879883, "Mean Target Q": 238.0238310546875, "Mean Q1": 238.0256279296875, "Mean Q2": 238.0255400390625, "critic_loss": 12.775810607910156, "batch_reward": 1.148831470489502, "actor_loss": -239.28983405328566, "actor_target_entropy": -1.0, "actor_entropy": 0.6678221427625225, "alpha_loss": -0.009834142544517113, "alpha_value": 0.20998499541705212, "duration": 153.83292984962463, "step": 99000}
{"episode_reward": 199.60638086872538, "episode": 793.0, "Q1 loss": 6.4400705718994145, "Q2 loss": 6.444022727966309, "Mean Target Q": 238.11908044433594, "Mean Q1": 238.1184931640625, "Mean Q2": 238.11894555664063, "critic_loss": 12.884093254089356, "batch_reward": 1.1490170736312866, "actor_loss": -239.30425613645522, "actor_target_entropy": -1.0, "actor_entropy": 0.6662542450995672, "alpha_loss": -0.0017533096455274121, "alpha_value": 0.21036556788015148, "duration": 165.54813504219055, "step": 99125}
{"episode_reward": 134.8389110869258, "episode": 794.0, "Q1 loss": 6.410609733581543, "Q2 loss": 6.429789226531982, "Mean Target Q": 238.1086951904297, "Mean Q1": 238.10786047363283, "Mean Q2": 238.1070505371094, "critic_loss": 12.840398948669433, "batch_reward": 1.1513144092559815, "actor_loss": -239.36395189839024, "actor_target_entropy": -1.0, "actor_entropy": 0.6442392314634016, "alpha_loss": -0.0038528543138395873, "alpha_value": 0.21057254139632098, "duration": 171.39470791816711, "step": 99250}
{"episode_reward": 164.45650467041995, "episode": 795.0, "Q1 loss": 6.493802021026611, "Q2 loss": 6.493024242401123, "Mean Target Q": 238.06407177734374, "Mean Q1": 238.0608486328125, "Mean Q2": 238.0615400390625, "critic_loss": 12.986826263427734, "batch_reward": 1.146871506690979, "actor_loss": -239.19244069901723, "actor_target_entropy": -1.0, "actor_entropy": 0.6525034280050368, "alpha_loss": -0.003588106549744095, "alpha_value": 0.21086329319225058, "duration": 164.1017701625824, "step": 99375}
{"episode_reward": 54.344208821254234, "episode": 796.0, "Q1 loss": 6.352424140930176, "Q2 loss": 6.363039709091186, "Mean Target Q": 238.16010754394532, "Mean Q1": 238.1635686035156, "Mean Q2": 238.16285681152343, "critic_loss": 12.715463829040527, "batch_reward": 1.1519231967926025, "actor_loss": -239.44784029068487, "actor_target_entropy": -1.0, "actor_entropy": 0.6758336030667828, "alpha_loss": -0.00030371126899075124, "alpha_value": 0.21122064759210527, "duration": 153.91556239128113, "step": 99500}
{"episode_reward": 106.35077136967337, "episode": 797.0, "Q1 loss": 6.30695160484314, "Q2 loss": 6.301924783706665, "Mean Target Q": 238.08606652832032, "Mean Q1": 238.08565405273438, "Mean Q2": 238.08626538085937, "critic_loss": 12.608876399993896, "batch_reward": 1.142427580356598, "actor_loss": -239.33430747380334, "actor_target_entropy": -1.0, "actor_entropy": 0.6656206013664366, "alpha_loss": 0.00414217579259818, "alpha_value": 0.21083879536097028, "duration": 179.90506052970886, "step": 99625}
{"episode_reward": 109.12346013000682, "episode": 798.0, "Q1 loss": 6.142011283874512, "Q2 loss": 6.14341898727417, "Mean Target Q": 238.18640185546874, "Mean Q1": 238.18518444824218, "Mean Q2": 238.18447351074218, "critic_loss": 12.285430274963378, "batch_reward": 1.1508672218322753, "actor_loss": -239.35147906887917, "actor_target_entropy": -1.0, "actor_entropy": 0.660719113003823, "alpha_loss": 0.0006912286306971744, "alpha_value": 0.21087491408651216, "duration": 164.21870827674866, "step": 99750}
{"episode_reward": 43.72822148091209, "episode": 799.0, "Q1 loss": 6.3226116752624515, "Q2 loss": 6.326842458724975, "Mean Target Q": 238.08509606933595, "Mean Q1": 238.0800808105469, "Mean Q2": 238.08060766601562, "critic_loss": 12.649454177856445, "batch_reward": 1.1458304891586304, "actor_loss": -239.30829535590277, "actor_target_entropy": -1.0, "actor_entropy": 0.670084399836404, "alpha_loss": 0.0007999097107953968, "alpha_value": 0.21073547284165228, "duration": 166.73301887512207, "step": 99875}
{"episode_reward": 189.8887601309995, "episode": 800.0, "Q1 loss": 6.455812008150162, "Q2 loss": 6.4778997475101106, "Mean Target Q": 238.12165229551255, "Mean Q1": 238.11504204042495, "Mean Q2": 238.1145847689721, "critic_loss": 12.93371166721467, "batch_reward": 1.1378058387387184, "actor_loss": -239.33742030974358, "actor_target_entropy": -1.0, "actor_entropy": 0.6583372844803718, "alpha_loss": 0.001576387556269765, "alpha_value": 0.2104748709658291, "step": 99999}
