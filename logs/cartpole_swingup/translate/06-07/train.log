{"episode_reward": 0.0, "episode": 1.0, "duration": 24.979334592819214, "step": 125}
{"episode_reward": 98.93334754503977, "episode": 2.0, "duration": 0.8177995681762695, "step": 250}
{"episode_reward": 83.7891973826063, "episode": 3.0, "duration": 0.8142983913421631, "step": 375}
{"episode_reward": 81.91120157057873, "episode": 4.0, "duration": 0.8138422966003418, "step": 500}
{"episode_reward": 154.56731419304836, "episode": 5.0, "duration": 0.8142879009246826, "step": 625}
{"episode_reward": 47.754455934765794, "episode": 6.0, "duration": 0.814298152923584, "step": 750}
{"episode_reward": 125.90222387858113, "episode": 7.0, "duration": 0.8143446445465088, "step": 875}
{"episode_reward": 143.25102190574748, "episode": 8.0, "duration": 0.8152568340301514, "step": 1000}
{"episode_reward": 186.90792292430567, "episode": 9.0, "Q1 loss": 1.0267885935306549, "Q2 loss": 1.0246617736816406, "Mean Target Q": 1.5795528841018678, "Mean Q1": 1.5683368347883224, "Mean Q2": 1.569872291892767, "critic_loss": 2.0514503507614137, "batch_reward": 0.8880871191024781, "actor_loss": -1.612448640759029, "actor_target_entropy": -1.0, "actor_entropy": 1.1491449986185347, "alpha_loss": 0.1409870602545284, "alpha_value": 0.09974836310251944, "duration": 165.36030411720276, "step": 1125}
{"episode_reward": 98.98876854247303, "episode": 10.0, "Q1 loss": 0.5337947425842285, "Q2 loss": 0.5346139450073242, "Mean Target Q": 2.1266735305786133, "Mean Q1": 2.121817080497742, "Mean Q2": 2.121898889541626, "critic_loss": 1.068408679008484, "batch_reward": 0.8882734031677246, "actor_loss": -2.186788753155739, "actor_target_entropy": -1.0, "actor_entropy": 1.2278566023995798, "alpha_loss": 0.15976849703058119, "alpha_value": 0.09910025572711807, "duration": 159.8539695739746, "step": 1250}
{"episode_reward": 107.79114854516263, "episode": 11.0, "Q1 loss": 0.5194577841758728, "Q2 loss": 0.5203675498962402, "Mean Target Q": 2.614540307998657, "Mean Q1": 2.615228893280029, "Mean Q2": 2.6152425708770752, "critic_loss": 1.03982533454895, "batch_reward": 0.8844478411674499, "actor_loss": -2.681825868667118, "actor_target_entropy": -1.0, "actor_entropy": 1.0693277328733415, "alpha_loss": 0.14906755562812563, "alpha_value": 0.09849979445083859, "duration": 155.4620339870453, "step": 1375}
{"episode_reward": 123.9833077059191, "episode": 12.0, "Q1 loss": 0.5962135772705078, "Q2 loss": 0.5963854577541351, "Mean Target Q": 3.1969616775512697, "Mean Q1": 3.1933467903137207, "Mean Q2": 3.193451930999756, "critic_loss": 1.1925990381240845, "batch_reward": 0.8964397640228271, "actor_loss": -3.250413317834177, "actor_target_entropy": -1.0, "actor_entropy": 0.9252353877790512, "alpha_loss": 0.14714659510120268, "alpha_value": 0.09791205327967167, "duration": 165.55692410469055, "step": 1500}
{"episode_reward": 87.72231450727995, "episode": 13.0, "Q1 loss": 0.5693695538043976, "Q2 loss": 0.5710910456180572, "Mean Target Q": 3.6968585662841797, "Mean Q1": 3.694543869018555, "Mean Q2": 3.6950306243896485, "critic_loss": 1.140460594177246, "batch_reward": 0.8996872735023499, "actor_loss": -3.8016747444395036, "actor_target_entropy": -1.0, "actor_entropy": 0.8050913432287792, "alpha_loss": 0.1338841938783252, "alpha_value": 0.09734684599741239, "duration": 158.63333582878113, "step": 1625}
{"episode_reward": 144.17315754908122, "episode": 14.0, "Q1 loss": 0.7232794618606567, "Q2 loss": 0.7221518006324769, "Mean Target Q": 4.197088470458985, "Mean Q1": 4.192639558792115, "Mean Q2": 4.192305992126465, "critic_loss": 1.445431261062622, "batch_reward": 0.9104408712387085, "actor_loss": -4.281925609034877, "actor_target_entropy": -1.0, "actor_entropy": 0.7443211943872513, "alpha_loss": 0.1260779168336622, "alpha_value": 0.09681843281079107, "duration": 138.23610949516296, "step": 1750}
{"episode_reward": 141.9055320365943, "episode": 15.0, "Q1 loss": 0.9177994213104248, "Q2 loss": 0.9171424717903137, "Mean Target Q": 4.7348885917663575, "Mean Q1": 4.732061241149903, "Mean Q2": 4.732628887176514, "critic_loss": 1.83494189453125, "batch_reward": 0.9231069297790527, "actor_loss": -4.854972975594657, "actor_target_entropy": -1.0, "actor_entropy": 0.7359509326162792, "alpha_loss": 0.11631135547917987, "alpha_value": 0.09631049348823044, "duration": 99.70340085029602, "step": 1875}
{"episode_reward": 177.65008817772593, "episode": 16.0, "Q1 loss": 1.1992240962982177, "Q2 loss": 1.2008868727684021, "Mean Target Q": 5.438314804077148, "Mean Q1": 5.430197257995605, "Mean Q2": 5.430189712524414, "critic_loss": 2.4001109704971313, "batch_reward": 0.9568733506202698, "actor_loss": -5.576121468697825, "actor_target_entropy": -1.0, "actor_entropy": 0.6984273820154129, "alpha_loss": 0.11159229026206079, "alpha_value": 0.09582433925593901, "duration": 105.56760740280151, "step": 2000}
{"episode_reward": 165.1753185759898, "episode": 17.0, "Q1 loss": 1.5909695949554443, "Q2 loss": 1.592557463645935, "Mean Target Q": 6.087648998260498, "Mean Q1": 6.081956176757813, "Mean Q2": 6.081793960571289, "critic_loss": 3.1835270614624025, "batch_reward": 0.9717614302635192, "actor_loss": -6.233553167373415, "actor_target_entropy": -1.0, "actor_entropy": 0.6167589619992271, "alpha_loss": 0.10403247946311557, "alpha_value": 0.09534808317334709, "duration": 114.81926584243774, "step": 2125}
{"episode_reward": 148.30178261784403, "episode": 18.0, "Q1 loss": 1.68345556974411, "Q2 loss": 1.6772957363128662, "Mean Target Q": 6.8237619323730465, "Mean Q1": 6.819347888946533, "Mean Q2": 6.819495464324951, "critic_loss": 3.3607513160705564, "batch_reward": 0.9988262872695923, "actor_loss": -6.9937172935855, "actor_target_entropy": -1.0, "actor_entropy": 0.5210546250304868, "alpha_loss": 0.0947367112723089, "alpha_value": 0.09489835282437308, "duration": 119.56034326553345, "step": 2250}
{"episode_reward": 211.77190473442099, "episode": 19.0, "Q1 loss": 1.927128737449646, "Q2 loss": 1.9289652500152588, "Mean Target Q": 7.676144145965576, "Mean Q1": 7.672204261779785, "Mean Q2": 7.672568088531494, "critic_loss": 3.8560939865112305, "batch_reward": 1.0531376481056214, "actor_loss": -7.920399113306924, "actor_target_entropy": -1.0, "actor_entropy": 0.4261624049099665, "alpha_loss": 0.0830079275700781, "alpha_value": 0.09448795867319869, "duration": 107.93145084381104, "step": 2375}
{"episode_reward": 188.4719059149115, "episode": 20.0, "Q1 loss": 2.8196385383605955, "Q2 loss": 2.805347509384155, "Mean Target Q": 8.466243705749513, "Mean Q1": 8.45401261138916, "Mean Q2": 8.454243278503418, "critic_loss": 5.624986045837402, "batch_reward": 1.071022304534912, "actor_loss": -8.644708279640444, "actor_target_entropy": -1.0, "actor_entropy": 0.40336538637958225, "alpha_loss": 0.07681112225738264, "alpha_value": 0.09410566248343083, "duration": 108.80421042442322, "step": 2500}
{"episode_reward": 178.04333235388805, "episode": 21.0, "Q1 loss": 2.5553046054840087, "Q2 loss": 2.548222972869873, "Mean Target Q": 9.226363700866699, "Mean Q1": 9.223689315795898, "Mean Q2": 9.22451064300537, "critic_loss": 5.10352756690979, "batch_reward": 1.088040445804596, "actor_loss": -9.483961953057182, "actor_target_entropy": -1.0, "actor_entropy": 0.3872038428745573, "alpha_loss": 0.06860308242695672, "alpha_value": 0.09374806701340785, "duration": 163.55377221107483, "step": 2625}
{"episode_reward": 144.4049005911768, "episode": 22.0, "Q1 loss": 2.857934534072876, "Q2 loss": 2.8549606199264526, "Mean Target Q": 9.999155067443848, "Mean Q1": 9.990434150695801, "Mean Q2": 9.989622100830077, "critic_loss": 5.712895153045654, "batch_reward": 1.0902098498344421, "actor_loss": -10.274833940690563, "actor_target_entropy": -1.0, "actor_entropy": 0.3875904221448206, "alpha_loss": 0.061179235217071345, "alpha_value": 0.09341777092999407, "duration": 174.58621621131897, "step": 2750}
{"episode_reward": 230.30597653820104, "episode": 23.0, "Q1 loss": 5.0678947639465335, "Q2 loss": 5.0187396650314335, "Mean Target Q": 10.928465148925781, "Mean Q1": 10.91996063232422, "Mean Q2": 10.921158065795899, "critic_loss": 10.08663447189331, "batch_reward": 1.131238091468811, "actor_loss": -11.141076950799851, "actor_target_entropy": -1.0, "actor_entropy": 0.34599524381614866, "alpha_loss": 0.053333643265807675, "alpha_value": 0.09310967694526971, "duration": 155.6569972038269, "step": 2875}
{"episode_reward": 194.33979776407284, "episode": 24.0, "Q1 loss": 4.225944063186645, "Q2 loss": 4.208229341506958, "Mean Target Q": 11.837216644287109, "Mean Q1": 11.816730255126954, "Mean Q2": 11.815998504638673, "critic_loss": 8.434173397064209, "batch_reward": 1.1585629954338075, "actor_loss": -12.01560018908593, "actor_target_entropy": -1.0, "actor_entropy": 0.44070364991503375, "alpha_loss": 0.055814187943695054, "alpha_value": 0.0928144216445673, "duration": 158.29088377952576, "step": 3000}
{"episode_reward": 298.5794961798488, "episode": 25.0, "Q1 loss": 3.304780666351318, "Q2 loss": 3.2855808029174804, "Mean Target Q": 12.78611826324463, "Mean Q1": 12.784196182250977, "Mean Q2": 12.78414533996582, "critic_loss": 6.590361469268799, "batch_reward": 1.192483669281006, "actor_loss": -13.094110776507666, "actor_target_entropy": -1.0, "actor_entropy": 0.3247568653452964, "alpha_loss": 0.04876070032044062, "alpha_value": 0.09251482948426219, "duration": 141.19580674171448, "step": 3125}
{"episode_reward": 184.8366277668086, "episode": 26.0, "Q1 loss": 3.323459762573242, "Q2 loss": 3.3071748371124268, "Mean Target Q": 13.765000602722168, "Mean Q1": 13.758016159057616, "Mean Q2": 13.757149002075195, "critic_loss": 6.63063461303711, "batch_reward": 1.2087395553588867, "actor_loss": -14.065574999778502, "actor_target_entropy": -1.0, "actor_entropy": 0.3487155612918638, "alpha_loss": 0.04442579049857393, "alpha_value": 0.0922459726668221, "duration": 149.25183153152466, "step": 3250}
{"episode_reward": 199.0866850600038, "episode": 27.0, "Q1 loss": 3.1118423204421997, "Q2 loss": 3.096645583152771, "Mean Target Q": 14.7018392868042, "Mean Q1": 14.694629592895508, "Mean Q2": 14.695862815856934, "critic_loss": 6.208487911224365, "batch_reward": 1.218846357345581, "actor_loss": -15.06650131467789, "actor_target_entropy": -1.0, "actor_entropy": 0.35195867457087077, "alpha_loss": 0.03649009291141752, "alpha_value": 0.09199729080395963, "duration": 159.05731344223022, "step": 3375}
{"episode_reward": 219.6507843423089, "episode": 28.0, "Q1 loss": 3.1233232421875, "Q2 loss": 3.1301275243759155, "Mean Target Q": 15.783352699279785, "Mean Q1": 15.778262359619141, "Mean Q2": 15.778526641845703, "critic_loss": 6.253450786590576, "batch_reward": 1.2495363683700562, "actor_loss": -16.16088996394988, "actor_target_entropy": -1.0, "actor_entropy": 0.37157790266698404, "alpha_loss": 0.034619619469008135, "alpha_value": 0.09177507846930835, "duration": 154.3314938545227, "step": 3500}
{"episode_reward": 236.50740223318692, "episode": 29.0, "Q1 loss": 3.5495415477752688, "Q2 loss": 3.548055763244629, "Mean Target Q": 16.92573011779785, "Mean Q1": 16.917077934265137, "Mean Q2": 16.917403312683106, "critic_loss": 7.097597343444824, "batch_reward": 1.2683278875350952, "actor_loss": -17.2247801281157, "actor_target_entropy": -1.0, "actor_entropy": 0.35916466561574784, "alpha_loss": 0.03296510573653948, "alpha_value": 0.0915566782413818, "duration": 111.96259617805481, "step": 3625}
{"episode_reward": 304.1392204944041, "episode": 30.0, "Q1 loss": 3.804747079849243, "Q2 loss": 3.7978569316864013, "Mean Target Q": 18.097061538696288, "Mean Q1": 18.092033798217773, "Mean Q2": 18.091620864868165, "critic_loss": 7.602604007720947, "batch_reward": 1.30749960231781, "actor_loss": -18.47553708476405, "actor_target_entropy": -1.0, "actor_entropy": 0.31785965566673585, "alpha_loss": 0.028826901388745153, "alpha_value": 0.09135487386527401, "duration": 78.48060703277588, "step": 3750}
{"episode_reward": 213.90746844018307, "episode": 31.0, "Q1 loss": 3.6085640201568605, "Q2 loss": 3.6091798629760743, "Mean Target Q": 19.202481491088868, "Mean Q1": 19.193959381103515, "Mean Q2": 19.194371002197265, "critic_loss": 7.217743892669677, "batch_reward": 1.318332679748535, "actor_loss": -19.577149103558252, "actor_target_entropy": -1.0, "actor_entropy": 0.2953066307873953, "alpha_loss": 0.02087827587855004, "alpha_value": 0.09117889296833617, "duration": 126.50955843925476, "step": 3875}
{"episode_reward": 221.8606733762702, "episode": 32.0, "Q1 loss": 3.810311595916748, "Q2 loss": 3.805665096282959, "Mean Target Q": 20.349326431274413, "Mean Q1": 20.34517478942871, "Mean Q2": 20.344974639892577, "critic_loss": 7.615976696014404, "batch_reward": 1.330935606956482, "actor_loss": -20.779255990059145, "actor_target_entropy": -1.0, "actor_entropy": 0.2786350223806597, "alpha_loss": 0.017458379503354552, "alpha_value": 0.09103842573993226, "duration": 161.73891353607178, "step": 4000}
{"episode_reward": 212.58665794746514, "episode": 33.0, "Q1 loss": 4.192647703170777, "Q2 loss": 4.194692558288574, "Mean Target Q": 21.53380581665039, "Mean Q1": 21.521492950439452, "Mean Q2": 21.52177215576172, "critic_loss": 8.387340270996093, "batch_reward": 1.3600009088516236, "actor_loss": -21.97083346048991, "actor_target_entropy": -1.0, "actor_entropy": 0.2621542000108295, "alpha_loss": 0.017765431313790263, "alpha_value": 0.09090117982896834, "duration": 119.73804807662964, "step": 4125}
{"episode_reward": 273.8328503499659, "episode": 34.0, "Q1 loss": 4.211232141494751, "Q2 loss": 4.206648200988769, "Mean Target Q": 22.698615951538088, "Mean Q1": 22.69300616455078, "Mean Q2": 22.693353729248045, "critic_loss": 8.417880352020264, "batch_reward": 1.376076979637146, "actor_loss": -23.158560722104966, "actor_target_entropy": -1.0, "actor_entropy": 0.2536420835362327, "alpha_loss": 0.015857851846263774, "alpha_value": 0.09078069591870126, "duration": 122.15116500854492, "step": 4250}
{"episode_reward": 307.6126418294712, "episode": 35.0, "Q1 loss": 4.260692361831665, "Q2 loss": 4.275746997833252, "Mean Target Q": 23.939656616210936, "Mean Q1": 23.93657635498047, "Mean Q2": 23.936249099731445, "critic_loss": 8.536439346313477, "batch_reward": 1.4110455856323243, "actor_loss": -24.441619025336372, "actor_target_entropy": -1.0, "actor_entropy": 0.20750030934337585, "alpha_loss": 0.010039858530194217, "alpha_value": 0.09066449392087417, "duration": 147.60224890708923, "step": 4375}
{"episode_reward": 357.7895266421266, "episode": 36.0, "Q1 loss": 4.211877689361573, "Q2 loss": 4.231365774154663, "Mean Target Q": 25.460002670288088, "Mean Q1": 25.45113919067383, "Mean Q2": 25.451187240600586, "critic_loss": 8.443243473052979, "batch_reward": 1.4400653743743896, "actor_loss": -25.994392118146344, "actor_target_entropy": -1.0, "actor_entropy": 0.2094800847492391, "alpha_loss": 0.006941249973380998, "alpha_value": 0.09058951452331086, "duration": 157.00526905059814, "step": 4500}
{"episode_reward": 292.08419291617673, "episode": 37.0, "Q1 loss": 3.99548362159729, "Q2 loss": 4.028723447799683, "Mean Target Q": 26.856232147216797, "Mean Q1": 26.850913284301757, "Mean Q2": 26.850278442382812, "critic_loss": 8.024207069396972, "batch_reward": 1.4670470161437987, "actor_loss": -27.381115474398175, "actor_target_entropy": -1.0, "actor_entropy": 0.18553520047238894, "alpha_loss": 0.0009070845202557625, "alpha_value": 0.09056148640228495, "duration": 168.2218725681305, "step": 4625}
{"episode_reward": 234.46035060185415, "episode": 38.0, "Q1 loss": 4.249567251205445, "Q2 loss": 4.243513967514038, "Mean Target Q": 28.112409576416017, "Mean Q1": 28.104416244506837, "Mean Q2": 28.105310745239258, "critic_loss": 8.493081195831298, "batch_reward": 1.4895563106536864, "actor_loss": -28.579577445983887, "actor_target_entropy": -1.0, "actor_entropy": 0.17928117943266708, "alpha_loss": -0.0014314478800271549, "alpha_value": 0.09056285849977994, "duration": 161.44973945617676, "step": 4750}
{"episode_reward": 333.2637464199127, "episode": 39.0, "Q1 loss": 4.513752393722534, "Q2 loss": 4.506201700210571, "Mean Target Q": 29.527322494506837, "Mean Q1": 29.514654830932617, "Mean Q2": 29.516091857910155, "critic_loss": 9.019954082489013, "batch_reward": 1.5094354677200317, "actor_loss": -30.073126596117778, "actor_target_entropy": -1.0, "actor_entropy": 0.15386437769565317, "alpha_loss": -0.0023051800524135904, "alpha_value": 0.09058835046573345, "duration": 153.6587610244751, "step": 4875}
{"episode_reward": 305.8559157772043, "episode": 40.0, "Q1 loss": 4.281704490661621, "Q2 loss": 4.313042182922363, "Mean Target Q": 31.178511093139647, "Mean Q1": 31.179285873413086, "Mean Q2": 31.177823272705076, "critic_loss": 8.594746704101562, "batch_reward": 1.5439412031173707, "actor_loss": -31.628679644676946, "actor_target_entropy": -1.0, "actor_entropy": 0.1462909616680155, "alpha_loss": -0.002709578649486385, "alpha_value": 0.0906113361856512, "step": 5000}
{"duration": 166.83372902870178, "step": 5000}
{"episode_reward": 283.7390574160502, "episode": 41.0, "Q1 loss": 4.1443611354827885, "Q2 loss": 4.144242055892945, "Mean Target Q": 32.34479209899902, "Mean Q1": 32.33347453308105, "Mean Q2": 32.334299026489255, "critic_loss": 8.288603187561035, "batch_reward": 1.5496220331192017, "actor_loss": -32.87876274472191, "actor_target_entropy": -1.0, "actor_entropy": 0.14372740039927145, "alpha_loss": -0.006292669322445161, "alpha_value": 0.09065265030956997, "duration": 155.04966187477112, "step": 5125}
{"episode_reward": 215.8748801497003, "episode": 42.0, "Q1 loss": 4.478475936889648, "Q2 loss": 4.493998125076294, "Mean Target Q": 33.534796875, "Mean Q1": 33.53158650207519, "Mean Q2": 33.53131881713867, "critic_loss": 8.972474025726319, "batch_reward": 1.5472859048843384, "actor_loss": -34.048424259308845, "actor_target_entropy": -1.0, "actor_entropy": 0.12225989042030226, "alpha_loss": -0.010620875483108383, "alpha_value": 0.09074153730100179, "duration": 167.55043244361877, "step": 5250}
{"episode_reward": 260.2415674617957, "episode": 43.0, "Q1 loss": 4.839191160202026, "Q2 loss": 4.852623922348022, "Mean Target Q": 35.04293927001953, "Mean Q1": 35.0354384765625, "Mean Q2": 35.03599893188476, "critic_loss": 9.691815055847169, "batch_reward": 1.5799044179916382, "actor_loss": -35.5914062015594, "actor_target_entropy": -1.0, "actor_entropy": 0.08093588466623, "alpha_loss": -0.010498850334746143, "alpha_value": 0.09084711042267077, "duration": 157.83806490898132, "step": 5375}
{"episode_reward": 301.63667391366147, "episode": 44.0, "Q1 loss": 4.722937139511108, "Q2 loss": 4.731164089202881, "Mean Target Q": 36.39862307739258, "Mean Q1": 36.39338647460937, "Mean Q2": 36.3933403930664, "critic_loss": 9.454101238250733, "batch_reward": 1.5968766450881957, "actor_loss": -36.87494247190414, "actor_target_entropy": -1.0, "actor_entropy": 0.10224324304069723, "alpha_loss": -0.01497272803305438, "alpha_value": 0.09099936913118131, "duration": 152.45026803016663, "step": 5500}
{"episode_reward": 305.73321155506665, "episode": 45.0, "Q1 loss": 5.143465311050415, "Q2 loss": 5.133421243667603, "Mean Target Q": 38.073161804199216, "Mean Q1": 38.068419372558594, "Mean Q2": 38.06871542358398, "critic_loss": 10.27688653564453, "batch_reward": 1.6294095315933228, "actor_loss": -38.73704147338867, "actor_target_entropy": -1.0, "actor_entropy": 0.056634234279275886, "alpha_loss": -0.017199765683876142, "alpha_value": 0.09116917185840646, "duration": 162.88458800315857, "step": 5625}
{"episode_reward": 451.6688489638133, "episode": 46.0, "Q1 loss": 5.238641139984131, "Q2 loss": 5.243350891113281, "Mean Target Q": 39.70991970825195, "Mean Q1": 39.70469784545899, "Mean Q2": 39.70479440307617, "critic_loss": 10.481992034912109, "batch_reward": 1.6549831228256227, "actor_loss": -40.33574541153446, "actor_target_entropy": -1.0, "actor_entropy": 0.05949845711790746, "alpha_loss": -0.017576126961953816, "alpha_value": 0.09138382434274617, "duration": 172.093496799469, "step": 5750}
{"episode_reward": 295.2151384819891, "episode": 47.0, "Q1 loss": 5.888696840286255, "Q2 loss": 5.909550729751587, "Mean Target Q": 41.15834393310547, "Mean Q1": 41.1479538269043, "Mean Q2": 41.147842834472655, "critic_loss": 11.798247550964355, "batch_reward": 1.6692464570999146, "actor_loss": -41.809169103228854, "actor_target_entropy": -1.0, "actor_entropy": 0.03186850361378184, "alpha_loss": -0.018723836928118198, "alpha_value": 0.09161226384036442, "duration": 174.27866387367249, "step": 5875}
{"episode_reward": 313.62434252627827, "episode": 48.0, "Q1 loss": 6.084589660644531, "Q2 loss": 6.081309963226318, "Mean Target Q": 42.75897915649414, "Mean Q1": 42.749819213867184, "Mean Q2": 42.751079345703126, "critic_loss": 12.165899673461913, "batch_reward": 1.6829259862899781, "actor_loss": -43.40087786028462, "actor_target_entropy": -1.0, "actor_entropy": -0.004041605328600253, "alpha_loss": -0.022867666795894866, "alpha_value": 0.09187411895089034, "duration": 158.70533275604248, "step": 6000}
{"episode_reward": 297.24349206495555, "episode": 49.0, "Q1 loss": 6.185833171844482, "Q2 loss": 6.203540023803711, "Mean Target Q": 43.90117260742188, "Mean Q1": 43.89522891235352, "Mean Q2": 43.894608032226564, "critic_loss": 12.389373207092286, "batch_reward": 1.6972889890670777, "actor_loss": -44.64391538831923, "actor_target_entropy": -1.0, "actor_entropy": 0.032777851137022175, "alpha_loss": -0.02452599996375659, "alpha_value": 0.09215650064708998, "duration": 112.87784171104431, "step": 6125}
{"episode_reward": 261.8592732845794, "episode": 50.0, "Q1 loss": 6.610875003814697, "Q2 loss": 6.628225143432617, "Mean Target Q": 45.578869140625, "Mean Q1": 45.574591491699216, "Mean Q2": 45.574557098388674, "critic_loss": 13.239100151062011, "batch_reward": 1.728111499786377, "actor_loss": -46.132706426805065, "actor_target_entropy": -1.0, "actor_entropy": -0.004809730746332676, "alpha_loss": -0.02460366904720544, "alpha_value": 0.09249055108272043, "duration": 115.72441816329956, "step": 6250}
{"episode_reward": 373.27743766798363, "episode": 51.0, "Q1 loss": 6.907051403045655, "Q2 loss": 6.876207817077637, "Mean Target Q": 47.13288989257813, "Mean Q1": 47.12113311767578, "Mean Q2": 47.12168060302734, "critic_loss": 13.783259239196777, "batch_reward": 1.7502991075515748, "actor_loss": -47.92417526245117, "actor_target_entropy": -1.0, "actor_entropy": -0.026133291319840483, "alpha_loss": -0.023727748816507677, "alpha_value": 0.09281257171205862, "duration": 163.1989448070526, "step": 6375}
{"episode_reward": 413.25903759140925, "episode": 52.0, "Q1 loss": 7.06703462600708, "Q2 loss": 7.065681526184082, "Mean Target Q": 48.7727112121582, "Mean Q1": 48.77230044555664, "Mean Q2": 48.771513244628906, "critic_loss": 14.132716270446778, "batch_reward": 1.762432451248169, "actor_loss": -49.52233056099184, "actor_target_entropy": -1.0, "actor_entropy": -0.05101172980897489, "alpha_loss": -0.025007597572590794, "alpha_value": 0.09317306122947781, "duration": 170.18869161605835, "step": 6500}
{"episode_reward": 339.63732406757174, "episode": 53.0, "Q1 loss": 7.5025636634826665, "Q2 loss": 7.512247547149658, "Mean Target Q": 50.14881423950195, "Mean Q1": 50.1382387084961, "Mean Q2": 50.13900198364258, "critic_loss": 15.014811218261718, "batch_reward": 1.7790555429458619, "actor_loss": -50.8418814643981, "actor_target_entropy": -1.0, "actor_entropy": -0.06333571985837012, "alpha_loss": -0.022970124591319335, "alpha_value": 0.09352276519335985, "duration": 147.51115369796753, "step": 6625}
{"episode_reward": 414.3566845082263, "episode": 54.0, "Q1 loss": 11.377998344421387, "Q2 loss": 11.402616382598877, "Mean Target Q": 51.76849227905274, "Mean Q1": 51.757635986328125, "Mean Q2": 51.75650653076172, "critic_loss": 22.780614646911623, "batch_reward": 1.801447772026062, "actor_loss": -52.3871038498417, "actor_target_entropy": -1.0, "actor_entropy": -0.05038001576078034, "alpha_loss": -0.02708967399573134, "alpha_value": 0.09387963055813804, "duration": 132.37336087226868, "step": 6750}
{"episode_reward": 301.38359651015344, "episode": 55.0, "Q1 loss": 8.671917800903321, "Q2 loss": 8.659443706512452, "Mean Target Q": 53.177270751953124, "Mean Q1": 53.16231420898438, "Mean Q2": 53.16585415649414, "critic_loss": 17.331361557006836, "batch_reward": 1.8334649505615235, "actor_loss": -53.99163479275174, "actor_target_entropy": -1.0, "actor_entropy": -0.06694722258382374, "alpha_loss": -0.02657724686321758, "alpha_value": 0.09426213724801952, "duration": 135.86098909378052, "step": 6875}
{"episode_reward": 411.87260450479937, "episode": 56.0, "Q1 loss": 8.08991138458252, "Q2 loss": 8.148385105133057, "Mean Target Q": 54.90455804443359, "Mean Q1": 54.89726470947266, "Mean Q2": 54.89597821044922, "critic_loss": 16.238296478271483, "batch_reward": 1.8601519775390625, "actor_loss": -55.62631465542701, "actor_target_entropy": -1.0, "actor_entropy": -0.08653368300668174, "alpha_loss": -0.023152247371692813, "alpha_value": 0.09464151670453254, "duration": 141.56040453910828, "step": 7000}
{"episode_reward": 406.8674804060067, "episode": 57.0, "Q1 loss": 7.758335441589355, "Q2 loss": 7.778697624206543, "Mean Target Q": 56.564257995605466, "Mean Q1": 56.559914276123045, "Mean Q2": 56.5615500793457, "critic_loss": 15.537033058166504, "batch_reward": 1.87727969455719, "actor_loss": -57.489607795836434, "actor_target_entropy": -1.0, "actor_entropy": -0.08486653524377043, "alpha_loss": -0.027909917949092766, "alpha_value": 0.0950336805557557, "duration": 173.24275255203247, "step": 7125}
{"episode_reward": 413.33174469359307, "episode": 58.0, "Q1 loss": 7.401069240570068, "Q2 loss": 7.452571800231934, "Mean Target Q": 58.41758624267578, "Mean Q1": 58.410998596191405, "Mean Q2": 58.410640899658205, "critic_loss": 14.853641075134277, "batch_reward": 1.9121213855743409, "actor_loss": -59.297362912085745, "actor_target_entropy": -1.0, "actor_entropy": -0.0865353107332222, "alpha_loss": -0.031170585192739964, "alpha_value": 0.09548980724101405, "duration": 154.5378303527832, "step": 7250}
{"episode_reward": 411.7473187919851, "episode": 59.0, "Q1 loss": 7.71244376373291, "Q2 loss": 7.685349349975586, "Mean Target Q": 60.148825897216796, "Mean Q1": 60.13803802490234, "Mean Q2": 60.1372594909668, "critic_loss": 15.39779305267334, "batch_reward": 1.9407091217041015, "actor_loss": -61.10269419352213, "actor_target_entropy": -1.0, "actor_entropy": -0.11186801313999153, "alpha_loss": -0.028934799474737948, "alpha_value": 0.09597954857095488, "duration": 129.39313626289368, "step": 7375}
{"episode_reward": 441.7307598202612, "episode": 60.0, "Q1 loss": 7.684486488342285, "Q2 loss": 7.751363037109375, "Mean Target Q": 61.8912919921875, "Mean Q1": 61.88857550048828, "Mean Q2": 61.888033142089846, "critic_loss": 15.435849517822266, "batch_reward": 1.9593555603027344, "actor_loss": -62.6397337144421, "actor_target_entropy": -1.0, "actor_entropy": -0.11195081709733894, "alpha_loss": -0.030518875247047793, "alpha_value": 0.09644668078507515, "duration": 137.5712571144104, "step": 7500}
{"episode_reward": 477.97708681835076, "episode": 61.0, "Q1 loss": 7.951309814453125, "Q2 loss": 7.982922805786133, "Mean Target Q": 63.76125280761719, "Mean Q1": 63.75207135009766, "Mean Q2": 63.752551452636716, "critic_loss": 15.93423264312744, "batch_reward": 1.9813785438537597, "actor_loss": -64.72854232788086, "actor_target_entropy": -1.0, "actor_entropy": -0.08526151315383022, "alpha_loss": -0.035076602613405575, "alpha_value": 0.09701240061180078, "duration": 176.956392288208, "step": 7625}
{"episode_reward": 391.61354023826885, "episode": 62.0, "Q1 loss": 7.841669986724853, "Q2 loss": 7.848535530090332, "Mean Target Q": 65.67623907470703, "Mean Q1": 65.67651452636719, "Mean Q2": 65.6782273864746, "critic_loss": 15.69020555114746, "batch_reward": 1.9976618003845215, "actor_loss": -66.5843851643224, "actor_target_entropy": -1.0, "actor_entropy": -0.13747987640841353, "alpha_loss": -0.0358160495187246, "alpha_value": 0.09758611227969297, "duration": 149.74003386497498, "step": 7750}
{"episode_reward": 448.6039959417438, "episode": 63.0, "Q1 loss": 8.045038639068604, "Q2 loss": 8.056858779907227, "Mean Target Q": 67.48632421875, "Mean Q1": 67.47592736816407, "Mean Q2": 67.47547039794922, "critic_loss": 16.101897293090822, "batch_reward": 2.037688717842102, "actor_loss": -68.47302718389602, "actor_target_entropy": -1.0, "actor_entropy": -0.11516153209266208, "alpha_loss": -0.03389610169780633, "alpha_value": 0.09816293068695824, "duration": 152.95072865486145, "step": 7875}
{"episode_reward": 483.2876879707116, "episode": 64.0, "Q1 loss": 8.192740951538086, "Q2 loss": 8.22441315460205, "Mean Target Q": 69.38016540527343, "Mean Q1": 69.370287109375, "Mean Q2": 69.37000164794922, "critic_loss": 16.417154136657715, "batch_reward": 2.05034925365448, "actor_loss": -70.29613827120873, "actor_target_entropy": -1.0, "actor_entropy": -0.15452656819815597, "alpha_loss": -0.03658139059740689, "alpha_value": 0.09875130004714183, "duration": 178.65120720863342, "step": 8000}
{"episode_reward": 466.0227738116273, "episode": 65.0, "Q1 loss": 7.973612106323242, "Q2 loss": 7.994612419128418, "Mean Target Q": 71.48541033935547, "Mean Q1": 71.47850524902344, "Mean Q2": 71.47929357910157, "critic_loss": 15.968224487304688, "batch_reward": 2.091830367088318, "actor_loss": -72.5014883374411, "actor_target_entropy": -1.0, "actor_entropy": -0.13454801674991373, "alpha_loss": -0.03570080365216921, "alpha_value": 0.09936469016607438, "duration": 150.61744689941406, "step": 8125}
{"episode_reward": 458.7577043767638, "episode": 66.0, "Q1 loss": 8.014926517486572, "Q2 loss": 8.039970371246337, "Mean Target Q": 73.27234747314454, "Mean Q1": 73.26505633544922, "Mean Q2": 73.26539562988282, "critic_loss": 16.054896858215333, "batch_reward": 2.117805260658264, "actor_loss": -74.15997843588552, "actor_target_entropy": -1.0, "actor_entropy": -0.15349810370694725, "alpha_loss": -0.03691037470895436, "alpha_value": 0.09998709982369033, "duration": 158.08159255981445, "step": 8250}
{"episode_reward": 435.1327712419445, "episode": 67.0, "Q1 loss": 8.477575817108153, "Q2 loss": 8.576033615112305, "Mean Target Q": 75.21523266601562, "Mean Q1": 75.20853631591797, "Mean Q2": 75.20790881347656, "critic_loss": 17.053609420776368, "batch_reward": 2.1386606912612915, "actor_loss": -76.21815854027157, "actor_target_entropy": -1.0, "actor_entropy": -0.14292490473460584, "alpha_loss": -0.03934963210116303, "alpha_value": 0.1006300876659502, "duration": 128.81464767456055, "step": 8375}
{"episode_reward": 464.78619846528545, "episode": 68.0, "Q1 loss": 8.446691886901856, "Q2 loss": 8.431775661468507, "Mean Target Q": 77.17980725097657, "Mean Q1": 77.17665808105468, "Mean Q2": 77.17470166015624, "critic_loss": 16.87846750640869, "batch_reward": 2.159391671180725, "actor_loss": -77.99194618963426, "actor_target_entropy": -1.0, "actor_entropy": -0.16906063814437197, "alpha_loss": -0.03710063724147697, "alpha_value": 0.10126124137231621, "duration": 115.7749297618866, "step": 8500}
{"episode_reward": 479.093312909539, "episode": 69.0, "Q1 loss": 8.898620498657227, "Q2 loss": 8.793889003753662, "Mean Target Q": 79.1392651977539, "Mean Q1": 79.12801556396484, "Mean Q2": 79.12948193359375, "critic_loss": 17.69250951385498, "batch_reward": 2.189088589668274, "actor_loss": -80.00081162225632, "actor_target_entropy": -1.0, "actor_entropy": -0.1992314224323583, "alpha_loss": -0.0381874144668617, "alpha_value": 0.10191759216827742, "duration": 121.05958652496338, "step": 8625}
{"episode_reward": 502.1026587921147, "episode": 70.0, "Q1 loss": 8.645723472595215, "Q2 loss": 8.659154609680176, "Mean Target Q": 81.0101000366211, "Mean Q1": 80.99751977539063, "Mean Q2": 80.99835028076171, "critic_loss": 17.304878150939942, "batch_reward": 2.2074148178100588, "actor_loss": -82.01809729299238, "actor_target_entropy": -1.0, "actor_entropy": -0.19088865828610235, "alpha_loss": -0.039855748895675905, "alpha_value": 0.10260403509966157, "duration": 130.25647282600403, "step": 8750}
{"episode_reward": 535.7319162694561, "episode": 71.0, "Q1 loss": 8.793510795593262, "Q2 loss": 8.808603790283204, "Mean Target Q": 83.08081494140625, "Mean Q1": 83.08122277832031, "Mean Q2": 83.08159057617188, "critic_loss": 17.602114517211913, "batch_reward": 2.2480302591323853, "actor_loss": -83.8665019444057, "actor_target_entropy": -1.0, "actor_entropy": -0.19139299559451284, "alpha_loss": -0.04096763761388877, "alpha_value": 0.10328571430123851, "duration": 130.60404586791992, "step": 8875}
{"episode_reward": 483.11028266439934, "episode": 72.0, "Q1 loss": 8.951143451690674, "Q2 loss": 8.924590335845947, "Mean Target Q": 84.9715323486328, "Mean Q1": 84.95742980957031, "Mean Q2": 84.95868634033204, "critic_loss": 17.875733741760254, "batch_reward": 2.2560959587097167, "actor_loss": -86.09314186342301, "actor_target_entropy": -1.0, "actor_entropy": -0.2212373486930324, "alpha_loss": -0.048047849487873814, "alpha_value": 0.10404487595064862, "duration": 130.83177185058594, "step": 9000}
{"episode_reward": 526.8247257944847, "episode": 73.0, "Q1 loss": 9.180506980895997, "Q2 loss": 9.230230747222901, "Mean Target Q": 87.10724694824219, "Mean Q1": 87.10574670410156, "Mean Q2": 87.10283819580079, "critic_loss": 18.410737747192382, "batch_reward": 2.2787398147583007, "actor_loss": -88.05950479658823, "actor_target_entropy": -1.0, "actor_entropy": -0.212844613170813, "alpha_loss": -0.04602795100164792, "alpha_value": 0.10485067264113761, "duration": 170.6316065788269, "step": 9125}
{"episode_reward": 422.64064612259045, "episode": 74.0, "Q1 loss": 9.531839668273927, "Q2 loss": 9.537169063568115, "Mean Target Q": 88.97331231689454, "Mean Q1": 88.96681115722656, "Mean Q2": 88.96633654785157, "critic_loss": 19.0690087890625, "batch_reward": 2.2857822141647337, "actor_loss": -89.99279711323399, "actor_target_entropy": -1.0, "actor_entropy": -0.2448644950505226, "alpha_loss": -0.0511875263144893, "alpha_value": 0.10563510159910415, "duration": 140.069500207901, "step": 9250}
{"episode_reward": 515.3370454615532, "episode": 75.0, "Q1 loss": 9.203456089019776, "Q2 loss": 9.220454441070556, "Mean Target Q": 91.17845239257812, "Mean Q1": 91.16675451660156, "Mean Q2": 91.16925653076171, "critic_loss": 18.423910537719728, "batch_reward": 2.3317612895965576, "actor_loss": -92.24914792984251, "actor_target_entropy": -1.0, "actor_entropy": -0.21509452471657406, "alpha_loss": -0.050183137435288655, "alpha_value": 0.10649299463948936, "duration": 134.4069426059723, "step": 9375}
{"episode_reward": 528.6416345145386, "episode": 76.0, "Q1 loss": 9.771133514404298, "Q2 loss": 9.828274131774903, "Mean Target Q": 93.16232165527343, "Mean Q1": 93.16055126953125, "Mean Q2": 93.16170617675782, "critic_loss": 19.59940768432617, "batch_reward": 2.34190851020813, "actor_loss": -94.22266055691627, "actor_target_entropy": -1.0, "actor_entropy": -0.23072975585537572, "alpha_loss": -0.05048095924599517, "alpha_value": 0.1073299435937753, "duration": 132.2095124721527, "step": 9500}
{"episode_reward": 533.9961404948614, "episode": 77.0, "Q1 loss": 9.476013389587402, "Q2 loss": 9.573932201385498, "Mean Target Q": 95.36551348876954, "Mean Q1": 95.35531719970703, "Mean Q2": 95.35339019775391, "critic_loss": 19.049945625305178, "batch_reward": 2.391623624801636, "actor_loss": -96.49251338413784, "actor_target_entropy": -1.0, "actor_entropy": -0.2363568107996668, "alpha_loss": -0.04876305990748935, "alpha_value": 0.1081174255050683, "duration": 148.7699797153473, "step": 9625}
{"episode_reward": 550.8685569321631, "episode": 78.0, "Q1 loss": 10.608338279724121, "Q2 loss": 10.669479137420653, "Mean Target Q": 97.44035388183593, "Mean Q1": 97.43654541015626, "Mean Q2": 97.43715631103515, "critic_loss": 21.277817375183105, "batch_reward": 2.4046669387817383, "actor_loss": -98.77669845088836, "actor_target_entropy": -1.0, "actor_entropy": -0.2993466914180786, "alpha_loss": -0.05436719893928497, "alpha_value": 0.10893969283206964, "duration": 178.83611726760864, "step": 9750}
{"episode_reward": 407.31583298544587, "episode": 79.0, "Q1 loss": 10.282551559448242, "Q2 loss": 10.285620029449463, "Mean Target Q": 99.34849114990234, "Mean Q1": 99.3401382446289, "Mean Q2": 99.34149505615234, "critic_loss": 20.56817156982422, "batch_reward": 2.416298641204834, "actor_loss": -100.49281165713356, "actor_target_entropy": -1.0, "actor_entropy": -0.25066287791918196, "alpha_loss": -0.05379698295441885, "alpha_value": 0.10980274483757833, "duration": 126.74794554710388, "step": 9875}
{"episode_reward": 522.4578612478, "episode": 80.0, "Q1 loss": 11.099861995697022, "Q2 loss": 11.079602321624757, "Mean Target Q": 101.11155041503906, "Mean Q1": 101.09976916503906, "Mean Q2": 101.09919885253906, "critic_loss": 22.17946430969238, "batch_reward": 2.4132900047302246, "actor_loss": -102.40068977109847, "actor_target_entropy": -1.0, "actor_entropy": -0.266055480727265, "alpha_loss": -0.05568720484452863, "alpha_value": 0.11065394450719236, "step": 10000}
{"duration": 181.1026155948639, "step": 10000}
{"episode_reward": 359.2262598385412, "episode": 81.0, "Q1 loss": 11.55974815750122, "Q2 loss": 11.615159530639648, "Mean Target Q": 103.38785845947265, "Mean Q1": 103.38381536865235, "Mean Q2": 103.38359533691406, "critic_loss": 23.174907653808592, "batch_reward": 2.45274979019165, "actor_loss": -104.70723615373883, "actor_target_entropy": -1.0, "actor_entropy": -0.22595121791320188, "alpha_loss": -0.05359511846114719, "alpha_value": 0.11149974696911397, "duration": 129.45770049095154, "step": 10125}
{"episode_reward": 681.8982265291419, "episode": 82.0, "Q1 loss": 11.524781635284423, "Q2 loss": 11.51858563232422, "Mean Target Q": 105.95126550292969, "Mean Q1": 105.94565618896485, "Mean Q2": 105.94539154052734, "critic_loss": 23.04336735534668, "batch_reward": 2.4889418964385985, "actor_loss": -107.11215714485415, "actor_target_entropy": -1.0, "actor_entropy": -0.2666601106043785, "alpha_loss": -0.05482075988285003, "alpha_value": 0.11233522136475672, "duration": 127.02724123001099, "step": 10250}
{"episode_reward": 611.2149562675061, "episode": 83.0, "Q1 loss": 11.13716134262085, "Q2 loss": 11.079372024536132, "Mean Target Q": 108.16957189941407, "Mean Q1": 108.15416125488281, "Mean Q2": 108.15488421630859, "critic_loss": 22.21653335571289, "batch_reward": 2.5154755725860594, "actor_loss": -109.39617605057974, "actor_target_entropy": -1.0, "actor_entropy": -0.31261087268117876, "alpha_loss": -0.055268594285561926, "alpha_value": 0.11316655774422668, "duration": 124.85383224487305, "step": 10375}
{"episode_reward": 698.7292094980155, "episode": 84.0, "Q1 loss": 11.080674365997314, "Q2 loss": 11.170557582855224, "Mean Target Q": 110.45625415039062, "Mean Q1": 110.45128521728516, "Mean Q2": 110.45133630371093, "critic_loss": 22.251231887817383, "batch_reward": 2.5514262504577636, "actor_loss": -111.7655277867471, "actor_target_entropy": -1.0, "actor_entropy": -0.2964674361771153, "alpha_loss": -0.05765532095345759, "alpha_value": 0.11402723540638164, "duration": 115.46588897705078, "step": 10500}
{"episode_reward": 693.1997271643652, "episode": 85.0, "Q1 loss": 13.051131492614745, "Q2 loss": 13.176661262512207, "Mean Target Q": 112.98122143554687, "Mean Q1": 112.97144805908204, "Mean Q2": 112.96982806396484, "critic_loss": 26.227792755126952, "batch_reward": 2.589885986328125, "actor_loss": -114.36981019519624, "actor_target_entropy": -1.0, "actor_entropy": -0.3057306619390609, "alpha_loss": -0.06289878186015856, "alpha_value": 0.11493917155661346, "duration": 132.7833411693573, "step": 10625}
{"episode_reward": 680.3676460070961, "episode": 86.0, "Q1 loss": 12.72670433807373, "Q2 loss": 12.736514595031739, "Mean Target Q": 115.49518084716797, "Mean Q1": 115.49697491455078, "Mean Q2": 115.49842706298828, "critic_loss": 25.46321884918213, "batch_reward": 2.627711399078369, "actor_loss": -116.88229124007687, "actor_target_entropy": -1.0, "actor_entropy": -0.31691353239359393, "alpha_loss": -0.06173996368963872, "alpha_value": 0.11584677250836549, "duration": 134.43641662597656, "step": 10750}
{"episode_reward": 758.9730876973161, "episode": 87.0, "Q1 loss": 12.16562110900879, "Q2 loss": 12.218525917053222, "Mean Target Q": 118.08319207763672, "Mean Q1": 118.06880883789063, "Mean Q2": 118.06952935791016, "critic_loss": 24.38414712524414, "batch_reward": 2.6597389564514162, "actor_loss": -119.29346320742653, "actor_target_entropy": -1.0, "actor_entropy": -0.29967584520105334, "alpha_loss": -0.06233177203980703, "alpha_value": 0.11677431574892184, "duration": 129.82379293441772, "step": 10875}
{"episode_reward": 755.51243552474, "episode": 88.0, "Q1 loss": 11.865526596069335, "Q2 loss": 11.9297183303833, "Mean Target Q": 120.446134765625, "Mean Q1": 120.43646264648437, "Mean Q2": 120.4347603149414, "critic_loss": 23.79524489593506, "batch_reward": 2.6925517520904543, "actor_loss": -121.78791809082031, "actor_target_entropy": -1.0, "actor_entropy": -0.3173688712619966, "alpha_loss": -0.06648368784977544, "alpha_value": 0.11769673173896157, "duration": 167.666442155838, "step": 11000}
{"episode_reward": 532.6537357322945, "episode": 89.0, "Q1 loss": 12.798233360290528, "Q2 loss": 12.846075653076172, "Mean Target Q": 122.80877264404297, "Mean Q1": 122.80700238037109, "Mean Q2": 122.80859381103515, "critic_loss": 25.644308959960938, "batch_reward": 2.709090419769287, "actor_loss": -124.2671392531622, "actor_target_entropy": -1.0, "actor_entropy": -0.3411431818727463, "alpha_loss": -0.06571210849852789, "alpha_value": 0.11863865634899856, "duration": 160.94265627861023, "step": 11125}
{"episode_reward": 765.8858244128573, "episode": 90.0, "Q1 loss": 12.900174758911133, "Q2 loss": 12.932713020324707, "Mean Target Q": 125.13888897705078, "Mean Q1": 125.13145666503907, "Mean Q2": 125.13162335205078, "critic_loss": 25.8328876953125, "batch_reward": 2.7403549041748048, "actor_loss": -126.57463824364447, "actor_target_entropy": -1.0, "actor_entropy": -0.35141284331198663, "alpha_loss": -0.06532660306942079, "alpha_value": 0.11956596783208226, "duration": 160.20128846168518, "step": 11250}
{"episode_reward": 565.7171583662084, "episode": 91.0, "Q1 loss": 13.079750869750976, "Q2 loss": 13.123205619812012, "Mean Target Q": 128.07435241699218, "Mean Q1": 128.0669708251953, "Mean Q2": 128.06637237548827, "critic_loss": 26.202956466674806, "batch_reward": 2.7823525619506837, "actor_loss": -129.56504942878846, "actor_target_entropy": -1.0, "actor_entropy": -0.35125229472205755, "alpha_loss": -0.06730474058597807, "alpha_value": 0.12049390581312615, "duration": 176.50225925445557, "step": 11375}
{"episode_reward": 722.6760767410365, "episode": 92.0, "Q1 loss": 13.553613426208496, "Q2 loss": 13.50351954650879, "Mean Target Q": 130.91749420166016, "Mean Q1": 130.90362896728516, "Mean Q2": 130.9038052368164, "critic_loss": 27.05713298034668, "batch_reward": 2.8122506237030027, "actor_loss": -132.3856457125756, "actor_target_entropy": -1.0, "actor_entropy": -0.3787636415612313, "alpha_loss": -0.07093066565932767, "alpha_value": 0.12145110329982065, "duration": 129.5171868801117, "step": 11500}
{"episode_reward": 740.9940366713853, "episode": 93.0, "Q1 loss": 14.361958541870116, "Q2 loss": 14.283043701171875, "Mean Target Q": 133.69979125976562, "Mean Q1": 133.69463842773436, "Mean Q2": 133.6966866455078, "critic_loss": 28.645002212524414, "batch_reward": 2.847351182937622, "actor_loss": -135.26693677145337, "actor_target_entropy": -1.0, "actor_entropy": -0.3488399206645905, "alpha_loss": -0.06899051356410223, "alpha_value": 0.12241355061012507, "duration": 177.59240126609802, "step": 11625}
{"episode_reward": 731.8686351446979, "episode": 94.0, "Q1 loss": 16.267128051757812, "Q2 loss": 16.29105242919922, "Mean Target Q": 136.38255041503905, "Mean Q1": 136.3786728515625, "Mean Q2": 136.37763317871094, "critic_loss": 32.558180419921875, "batch_reward": 2.873877452850342, "actor_loss": -137.802854722546, "actor_target_entropy": -1.0, "actor_entropy": -0.35188404254374966, "alpha_loss": -0.07103394146167463, "alpha_value": 0.12335476719428376, "duration": 145.87268686294556, "step": 11750}
{"episode_reward": 726.0060078689809, "episode": 95.0, "Q1 loss": 14.891895790100097, "Q2 loss": 14.862632698059082, "Mean Target Q": 139.17794274902343, "Mean Q1": 139.15960986328125, "Mean Q2": 139.16036376953124, "critic_loss": 29.754528411865234, "batch_reward": 2.8831319675445557, "actor_loss": -140.71459476531498, "actor_target_entropy": -1.0, "actor_entropy": -0.3253935913717936, "alpha_loss": -0.07518507835883943, "alpha_value": 0.12432959667839223, "duration": 134.51609683036804, "step": 11875}
{"episode_reward": 736.2827847334349, "episode": 96.0, "Q1 loss": 14.775468383789063, "Q2 loss": 14.685915901184082, "Mean Target Q": 142.439658203125, "Mean Q1": 142.43231823730468, "Mean Q2": 142.43004638671874, "critic_loss": 29.461384201049803, "batch_reward": 2.934768594741821, "actor_loss": -143.98069664739793, "actor_target_entropy": -1.0, "actor_entropy": -0.3697985103053431, "alpha_loss": -0.07174980562300451, "alpha_value": 0.12529558002838476, "duration": 119.08795499801636, "step": 12000}
{"episode_reward": 724.1190433852496, "episode": 97.0, "Q1 loss": 15.147690208435058, "Q2 loss": 15.09111644744873, "Mean Target Q": 144.95556567382812, "Mean Q1": 144.95152966308595, "Mean Q2": 144.95207275390624, "critic_loss": 30.23880665588379, "batch_reward": 2.960884874343872, "actor_loss": -146.52520437089223, "actor_target_entropy": -1.0, "actor_entropy": -0.3248306266845219, "alpha_loss": -0.06544064777711081, "alpha_value": 0.12618554703876436, "duration": 127.31319117546082, "step": 12125}
{"episode_reward": 725.3156893034048, "episode": 98.0, "Q1 loss": 17.016016593933106, "Q2 loss": 17.110579849243162, "Mean Target Q": 148.48058142089843, "Mean Q1": 148.4764853515625, "Mean Q2": 148.47465759277344, "critic_loss": 34.12659652709961, "batch_reward": 3.012330312728882, "actor_loss": -150.3501468781502, "actor_target_entropy": -1.0, "actor_entropy": -0.3863686003511952, "alpha_loss": -0.07340458257784767, "alpha_value": 0.1270955625915495, "duration": 138.32411980628967, "step": 12250}
{"episode_reward": 655.2457871029881, "episode": 99.0, "Q1 loss": 16.31949334716797, "Q2 loss": 16.337688903808594, "Mean Target Q": 151.01929125976562, "Mean Q1": 151.00517456054686, "Mean Q2": 151.0067111816406, "critic_loss": 32.657182281494144, "batch_reward": 3.0160796070098876, "actor_loss": -152.8800034295945, "actor_target_entropy": -1.0, "actor_entropy": -0.35532827367858283, "alpha_loss": -0.07338045306858562, "alpha_value": 0.12805597373201538, "duration": 177.25499510765076, "step": 12375}
{"episode_reward": 700.4789388779504, "episode": 100.0, "Q1 loss": 16.861559005737305, "Q2 loss": 16.692316040039064, "Mean Target Q": 154.27541174316406, "Mean Q1": 154.2677774658203, "Mean Q2": 154.2662462158203, "critic_loss": 33.553874923706054, "batch_reward": 3.0346640415191652, "actor_loss": -156.06513238722277, "actor_target_entropy": -1.0, "actor_entropy": -0.339919934109334, "alpha_loss": -0.07540171869820164, "alpha_value": 0.1290231185016377, "duration": 121.91785836219788, "step": 12500}
{"episode_reward": 692.6385129015778, "episode": 101.0, "Q1 loss": 17.094375755310057, "Q2 loss": 16.98359120941162, "Mean Target Q": 157.24029321289063, "Mean Q1": 157.23711462402343, "Mean Q2": 157.2409880371094, "critic_loss": 34.07796708679199, "batch_reward": 3.0741496181488035, "actor_loss": -158.90480114164808, "actor_target_entropy": -1.0, "actor_entropy": -0.35440284676022, "alpha_loss": -0.0755893298912616, "alpha_value": 0.12997136832939007, "duration": 147.11029887199402, "step": 12625}
{"episode_reward": 694.5165074984585, "episode": 102.0, "Q1 loss": 16.932280418395997, "Q2 loss": 16.96717933654785, "Mean Target Q": 159.66100744628906, "Mean Q1": 159.65485583496093, "Mean Q2": 159.65506701660155, "critic_loss": 33.89945989990235, "batch_reward": 3.0726675987243652, "actor_loss": -161.59066255630987, "actor_target_entropy": -1.0, "actor_entropy": -0.3077717622922313, "alpha_loss": -0.07291760157433248, "alpha_value": 0.1309298340465744, "duration": 165.4634563922882, "step": 12750}
{"episode_reward": 609.7380881799929, "episode": 103.0, "Q1 loss": 18.819025016784668, "Q2 loss": 18.797846611022948, "Mean Target Q": 163.13433447265626, "Mean Q1": 163.12187182617188, "Mean Q2": 163.11919311523437, "critic_loss": 37.616871536254884, "batch_reward": 3.110848846435547, "actor_loss": -165.06419953845796, "actor_target_entropy": -1.0, "actor_entropy": -0.3280230883568052, "alpha_loss": -0.07651806185169825, "alpha_value": 0.13187987974187684, "duration": 168.57237029075623, "step": 12875}
{"episode_reward": 683.825277998947, "episode": 104.0, "Q1 loss": 18.127584259033203, "Q2 loss": 18.25872483062744, "Mean Target Q": 165.92043835449218, "Mean Q1": 165.90934777832032, "Mean Q2": 165.91214868164062, "critic_loss": 36.38630908203125, "batch_reward": 3.137917463302612, "actor_loss": -168.04305759552986, "actor_target_entropy": -1.0, "actor_entropy": -0.3164437160857262, "alpha_loss": -0.07434196535858416, "alpha_value": 0.132834431932305, "duration": 144.1307156085968, "step": 13000}
{"episode_reward": 723.7944470138227, "episode": 105.0, "Q1 loss": 17.898208183288574, "Q2 loss": 17.896846504211425, "Mean Target Q": 168.89595642089844, "Mean Q1": 168.89116540527343, "Mean Q2": 168.88927563476562, "critic_loss": 35.79505464172363, "batch_reward": 3.1563599891662597, "actor_loss": -170.98751419309585, "actor_target_entropy": -1.0, "actor_entropy": -0.30918400628226145, "alpha_loss": -0.06971465269961054, "alpha_value": 0.13374926930163097, "duration": 152.40404272079468, "step": 13125}
{"episode_reward": 685.729252208423, "episode": 106.0, "Q1 loss": 17.789880256652832, "Q2 loss": 17.766468688964842, "Mean Target Q": 172.3707548828125, "Mean Q1": 172.3628134765625, "Mean Q2": 172.36285388183595, "critic_loss": 35.556348831176756, "batch_reward": 3.1876442070007323, "actor_loss": -174.4466304163779, "actor_target_entropy": -1.0, "actor_entropy": -0.35104861206585364, "alpha_loss": -0.07611944213990242, "alpha_value": 0.13466249307056782, "duration": 154.9879412651062, "step": 13250}
{"episode_reward": 722.0211989641637, "episode": 107.0, "Q1 loss": 19.380627464294435, "Q2 loss": 19.374113410949708, "Mean Target Q": 175.31594055175782, "Mean Q1": 175.30452758789062, "Mean Q2": 175.3057626953125, "critic_loss": 38.75474104309082, "batch_reward": 3.1952662754058836, "actor_loss": -176.9202900235615, "actor_target_entropy": -1.0, "actor_entropy": -0.31474466290738845, "alpha_loss": -0.08079383545924747, "alpha_value": 0.13565140866934047, "duration": 118.86617636680603, "step": 13375}
{"episode_reward": 703.2148068204422, "episode": 108.0, "Q1 loss": 19.31642973327637, "Q2 loss": 19.212412155151366, "Mean Target Q": 178.49539404296874, "Mean Q1": 178.49452453613281, "Mean Q2": 178.4935061035156, "critic_loss": 38.52884191894531, "batch_reward": 3.2456493492126466, "actor_loss": -180.56085180467176, "actor_target_entropy": -1.0, "actor_entropy": -0.3289681725925015, "alpha_loss": -0.07727405657210658, "alpha_value": 0.13663613698658258, "duration": 113.69755601882935, "step": 13500}
{"episode_reward": 695.7764264242726, "episode": 109.0, "Q1 loss": 18.005461837768554, "Q2 loss": 18.007589057922363, "Mean Target Q": 181.26696032714844, "Mean Q1": 181.26441857910157, "Mean Q2": 181.26501489257814, "critic_loss": 36.013050857543945, "batch_reward": 3.2385696659088135, "actor_loss": -183.15062556191097, "actor_target_entropy": -1.0, "actor_entropy": -0.3510126840500605, "alpha_loss": -0.0795250330415983, "alpha_value": 0.13762110436015215, "duration": 108.80203700065613, "step": 13625}
{"episode_reward": 699.312040824495, "episode": 110.0, "Q1 loss": 19.306323753356935, "Q2 loss": 19.320100036621092, "Mean Target Q": 185.0229287109375, "Mean Q1": 185.0068651123047, "Mean Q2": 185.00686499023436, "critic_loss": 38.62642376708985, "batch_reward": 3.263425392150879, "actor_loss": -187.36273316414125, "actor_target_entropy": -1.0, "actor_entropy": -0.3904819740883766, "alpha_loss": -0.08659917344489405, "alpha_value": 0.1386510692884066, "duration": 127.68270468711853, "step": 13750}
{"episode_reward": 704.1480997685929, "episode": 111.0, "Q1 loss": 18.76745337677002, "Q2 loss": 18.841740646362304, "Mean Target Q": 188.22604345703124, "Mean Q1": 188.2220860595703, "Mean Q2": 188.21992529296875, "critic_loss": 37.60919416809082, "batch_reward": 3.3066948318481444, "actor_loss": -190.0308355906653, "actor_target_entropy": -1.0, "actor_entropy": -0.3262202690045039, "alpha_loss": -0.08099430290952561, "alpha_value": 0.13968514345735797, "duration": 115.92486572265625, "step": 13875}
{"episode_reward": 771.3603181705026, "episode": 112.0, "Q1 loss": 19.056792312622072, "Q2 loss": 18.97572484588623, "Mean Target Q": 191.24294750976563, "Mean Q1": 191.22220751953125, "Mean Q2": 191.22375085449218, "critic_loss": 38.0325173034668, "batch_reward": 3.329179224014282, "actor_loss": -192.89059743573588, "actor_target_entropy": -1.0, "actor_entropy": -0.33732082141983893, "alpha_loss": -0.08085542009963144, "alpha_value": 0.1406712843527692, "duration": 114.4078574180603, "step": 14000}
{"episode_reward": 779.191144218575, "episode": 113.0, "Q1 loss": 19.660317321777345, "Q2 loss": 19.73820545196533, "Mean Target Q": 194.2963341064453, "Mean Q1": 194.29825634765626, "Mean Q2": 194.29769274902344, "critic_loss": 39.39852278137207, "batch_reward": 3.3405759525299072, "actor_loss": -196.07579718695746, "actor_target_entropy": -1.0, "actor_entropy": -0.2948582304848565, "alpha_loss": -0.07904628445468252, "alpha_value": 0.1416613907967839, "duration": 126.10345911979675, "step": 14125}
{"episode_reward": 734.1141523568957, "episode": 114.0, "Q1 loss": 18.465737182617186, "Q2 loss": 18.603026496887207, "Mean Target Q": 197.63666638183594, "Mean Q1": 197.63050744628907, "Mean Q2": 197.63201745605468, "critic_loss": 37.06876370239258, "batch_reward": 3.3774742259979247, "actor_loss": -199.940311801049, "actor_target_entropy": -1.0, "actor_entropy": -0.3353590116866173, "alpha_loss": -0.07895005458304959, "alpha_value": 0.14261322910294966, "duration": 117.73238444328308, "step": 14250}
{"episode_reward": 788.2275557388015, "episode": 115.0, "Q1 loss": 18.94702207183838, "Q2 loss": 18.941575119018555, "Mean Target Q": 200.60570288085938, "Mean Q1": 200.59412658691406, "Mean Q2": 200.5935146484375, "critic_loss": 37.88859716796875, "batch_reward": 3.374941898345947, "actor_loss": -202.74057249038938, "actor_target_entropy": -1.0, "actor_entropy": -0.3335735152165095, "alpha_loss": -0.0835552489946759, "alpha_value": 0.14361512664963977, "duration": 114.57189154624939, "step": 14375}
{"episode_reward": 729.4218402640522, "episode": 116.0, "Q1 loss": 19.045963996887206, "Q2 loss": 19.0027387008667, "Mean Target Q": 204.4245740966797, "Mean Q1": 204.42210705566407, "Mean Q2": 204.4187138671875, "critic_loss": 38.04870266723633, "batch_reward": 3.4093340549468993, "actor_loss": -206.4565638880576, "actor_target_entropy": -1.0, "actor_entropy": -0.35851162167326095, "alpha_loss": -0.08177432033323473, "alpha_value": 0.14461756463472994, "duration": 119.29222679138184, "step": 14500}
{"episode_reward": 763.2886003114818, "episode": 117.0, "Q1 loss": 19.176084365844726, "Q2 loss": 19.044552459716797, "Mean Target Q": 207.66790283203125, "Mean Q1": 207.65463024902343, "Mean Q2": 207.65517883300782, "critic_loss": 38.220636627197266, "batch_reward": 3.4434668464660643, "actor_loss": -209.97507755340092, "actor_target_entropy": -1.0, "actor_entropy": -0.35942194882839446, "alpha_loss": -0.08001939479320769, "alpha_value": 0.1456071182235969, "duration": 114.92998480796814, "step": 14625}
{"episode_reward": 756.218144727528, "episode": 118.0, "Q1 loss": 18.399019401550294, "Q2 loss": 18.43429391479492, "Mean Target Q": 210.31668432617187, "Mean Q1": 210.315921875, "Mean Q2": 210.3152276611328, "critic_loss": 36.83331340026855, "batch_reward": 3.4384743614196775, "actor_loss": -212.109740964828, "actor_target_entropy": -1.0, "actor_entropy": -0.3439502502160688, "alpha_loss": -0.08469299106828627, "alpha_value": 0.14662116462477032, "duration": 125.2042338848114, "step": 14750}
{"episode_reward": 742.0812710581102, "episode": 119.0, "Q1 loss": 19.200918350219727, "Q2 loss": 19.188711570739745, "Mean Target Q": 214.52088928222656, "Mean Q1": 214.5122442626953, "Mean Q2": 214.5132742919922, "critic_loss": 38.38962992858887, "batch_reward": 3.495207036972046, "actor_loss": -216.50125994001115, "actor_target_entropy": -1.0, "actor_entropy": -0.3558534989281306, "alpha_loss": -0.08640007899394112, "alpha_value": 0.1476570857639554, "duration": 115.227215051651, "step": 14875}
{"episode_reward": 787.7930538055869, "episode": 120.0, "Q1 loss": 19.297020301818847, "Q2 loss": 19.387564292907715, "Mean Target Q": 217.51629150390625, "Mean Q1": 217.51033032226562, "Mean Q2": 217.50908850097656, "critic_loss": 38.68458453369141, "batch_reward": 3.5175906028747557, "actor_loss": -219.60877400059854, "actor_target_entropy": -1.0, "actor_entropy": -0.3559636903866645, "alpha_loss": -0.08478493628001982, "alpha_value": 0.14868461194835994, "step": 15000}
{"duration": 157.36832928657532, "step": 15000}
{"episode_reward": 830.2699197637471, "episode": 121.0, "Q1 loss": 19.2969107131958, "Q2 loss": 19.22601220703125, "Mean Target Q": 220.48234606933593, "Mean Q1": 220.475501953125, "Mean Q2": 220.47773913574218, "critic_loss": 38.52292304992676, "batch_reward": 3.5284490165710447, "actor_loss": -222.77698698497954, "actor_target_entropy": -1.0, "actor_entropy": -0.32896904671002947, "alpha_loss": -0.08470786008096877, "alpha_value": 0.14973338570150088, "duration": 147.72049188613892, "step": 15125}
{"episode_reward": 776.3938730878938, "episode": 122.0, "Q1 loss": 19.401784378051758, "Q2 loss": 19.476287338256835, "Mean Target Q": 223.61713879394532, "Mean Q1": 223.6117264404297, "Mean Q2": 223.60893518066408, "critic_loss": 38.8780717163086, "batch_reward": 3.5386477451324465, "actor_loss": -225.87677346506428, "actor_target_entropy": -1.0, "actor_entropy": -0.35183098719966027, "alpha_loss": -0.08997326025799397, "alpha_value": 0.15076465942922668, "duration": 165.55470848083496, "step": 15250}
{"episode_reward": 729.2152257714172, "episode": 123.0, "Q1 loss": 18.545870895385743, "Q2 loss": 18.46044841003418, "Mean Target Q": 226.98356677246093, "Mean Q1": 226.97263354492188, "Mean Q2": 226.97226208496093, "critic_loss": 37.00631922912598, "batch_reward": 3.5634779148101807, "actor_loss": -229.22652956039187, "actor_target_entropy": -1.0, "actor_entropy": -0.37450921890281497, "alpha_loss": -0.08699272277336272, "alpha_value": 0.15185843431118567, "duration": 164.35770201683044, "step": 15375}
{"episode_reward": 772.1045433317064, "episode": 124.0, "Q1 loss": 18.74077303314209, "Q2 loss": 18.576186393737792, "Mean Target Q": 230.63879443359374, "Mean Q1": 230.63835766601562, "Mean Q2": 230.6374676513672, "critic_loss": 37.31695930480957, "batch_reward": 3.6074423160552977, "actor_loss": -232.7794420796056, "actor_target_entropy": -1.0, "actor_entropy": -0.36630128756646185, "alpha_loss": -0.08480895040256362, "alpha_value": 0.15288627172334301, "duration": 168.9270899295807, "step": 15500}
{"episode_reward": 848.2481493533143, "episode": 125.0, "Q1 loss": 17.841004432678222, "Q2 loss": 17.67294832611084, "Mean Target Q": 233.53213244628907, "Mean Q1": 233.51501135253906, "Mean Q2": 233.51643127441406, "critic_loss": 35.51395280456543, "batch_reward": 3.605862064361572, "actor_loss": -235.64354136633494, "actor_target_entropy": -1.0, "actor_entropy": -0.42936803424169145, "alpha_loss": -0.0881327883828254, "alpha_value": 0.15393179909020108, "duration": 170.44117379188538, "step": 15625}
{"episode_reward": 850.3308423415386, "episode": 126.0, "Q1 loss": 17.84071499633789, "Q2 loss": 17.767104553222655, "Mean Target Q": 237.07733874511717, "Mean Q1": 237.07152978515626, "Mean Q2": 237.07096936035157, "critic_loss": 35.60781945800781, "batch_reward": 3.663531234741211, "actor_loss": -239.21802471530052, "actor_target_entropy": -1.0, "actor_entropy": -0.41457590364640756, "alpha_loss": -0.08891871439353112, "alpha_value": 0.15499521413419667, "duration": 163.01079273223877, "step": 15750}
{"episode_reward": 802.9406351748671, "episode": 127.0, "Q1 loss": 17.80203017425537, "Q2 loss": 17.71744132232666, "Mean Target Q": 240.75970385742187, "Mean Q1": 240.75654797363282, "Mean Q2": 240.75926293945312, "critic_loss": 35.51947146606445, "batch_reward": 3.6935453815460204, "actor_loss": -243.12503899468317, "actor_target_entropy": -1.0, "actor_entropy": -0.40628322154756574, "alpha_loss": -0.08614461242206513, "alpha_value": 0.15606036665186715, "duration": 95.83501648902893, "step": 15875}
{"episode_reward": 841.4159110197174, "episode": 128.0, "Q1 loss": 19.03303579711914, "Q2 loss": 19.054651359558104, "Mean Target Q": 243.97025744628905, "Mean Q1": 243.9570020751953, "Mean Q2": 243.95450842285157, "critic_loss": 38.087687103271485, "batch_reward": 3.6940154399871825, "actor_loss": -246.07018698415447, "actor_target_entropy": -1.0, "actor_entropy": -0.3564035628111132, "alpha_loss": -0.08348974825874451, "alpha_value": 0.15709576715050097, "duration": 164.55648159980774, "step": 16000}
{"episode_reward": 843.6710240457186, "episode": 129.0, "Q1 loss": 17.760342292785644, "Q2 loss": 17.81163028717041, "Mean Target Q": 246.7863712158203, "Mean Q1": 246.778548828125, "Mean Q2": 246.7776112060547, "critic_loss": 35.57197265625, "batch_reward": 3.7095368423461914, "actor_loss": -248.75023711673796, "actor_target_entropy": -1.0, "actor_entropy": -0.4064485165807936, "alpha_loss": -0.0905546426536545, "alpha_value": 0.15813113969073106, "duration": 115.33972382545471, "step": 16125}
{"episode_reward": 775.0142364874342, "episode": 130.0, "Q1 loss": 18.67936404418945, "Q2 loss": 18.58274033355713, "Mean Target Q": 250.50654541015626, "Mean Q1": 250.49235400390626, "Mean Q2": 250.49459118652345, "critic_loss": 37.262104553222656, "batch_reward": 3.740744441986084, "actor_loss": -252.15958995203817, "actor_target_entropy": -1.0, "actor_entropy": -0.38135848843282266, "alpha_loss": -0.0875523371561881, "alpha_value": 0.15921358807678687, "duration": 135.05850911140442, "step": 16250}
{"episode_reward": 758.7515660069073, "episode": 131.0, "Q1 loss": 17.824525886535646, "Q2 loss": 17.82175980377197, "Mean Target Q": 253.98761340332032, "Mean Q1": 253.98160070800782, "Mean Q2": 253.98014135742187, "critic_loss": 35.64628567504883, "batch_reward": 3.7787739219665526, "actor_loss": -256.03108845059836, "actor_target_entropy": -1.0, "actor_entropy": -0.40174362441850087, "alpha_loss": -0.09108303723827241, "alpha_value": 0.16030210239263917, "duration": 110.83771681785583, "step": 16375}
{"episode_reward": 773.7550592502868, "episode": 132.0, "Q1 loss": 17.06976766204834, "Q2 loss": 17.107352554321288, "Mean Target Q": 257.0288620605469, "Mean Q1": 257.02713305664065, "Mean Q2": 257.02512719726565, "critic_loss": 34.17712031555176, "batch_reward": 3.792054386138916, "actor_loss": -258.93334197998047, "actor_target_entropy": -1.0, "actor_entropy": -0.4323534369468689, "alpha_loss": -0.08968549606300169, "alpha_value": 0.16139859952154345, "duration": 115.27351593971252, "step": 16500}
{"episode_reward": 846.1866608082665, "episode": 133.0, "Q1 loss": 18.09237361907959, "Q2 loss": 18.192600051879882, "Mean Target Q": 260.1438699951172, "Mean Q1": 260.130103515625, "Mean Q2": 260.1332662353516, "critic_loss": 36.28497367858887, "batch_reward": 3.7989839324951173, "actor_loss": -262.4167054191468, "actor_target_entropy": -1.0, "actor_entropy": -0.4263852129852961, "alpha_loss": -0.08786533465461126, "alpha_value": 0.1624926404823806, "duration": 107.34542536735535, "step": 16625}
{"episode_reward": 846.5634822612581, "episode": 134.0, "Q1 loss": 17.318059356689453, "Q2 loss": 17.35829563140869, "Mean Target Q": 263.2832043457031, "Mean Q1": 263.27636267089844, "Mean Q2": 263.2761169433594, "critic_loss": 34.6763550415039, "batch_reward": 3.8304238357543947, "actor_loss": -265.49083143664944, "actor_target_entropy": -1.0, "actor_entropy": -0.42277687018917454, "alpha_loss": -0.09367302156263782, "alpha_value": 0.16358083341576435, "duration": 130.20410418510437, "step": 16750}
{"episode_reward": 835.6776195597947, "episode": 135.0, "Q1 loss": 17.705750312805176, "Q2 loss": 17.660739143371583, "Mean Target Q": 266.8280693359375, "Mean Q1": 266.8188572998047, "Mean Q2": 266.81544689941404, "critic_loss": 35.36648944091797, "batch_reward": 3.8434510040283203, "actor_loss": -268.2035406203497, "actor_target_entropy": -1.0, "actor_entropy": -0.4206895066632165, "alpha_loss": -0.09038809178367493, "alpha_value": 0.16470159746311905, "duration": 126.00662302970886, "step": 16875}
{"episode_reward": 774.880579207084, "episode": 136.0, "Q1 loss": 16.939727951049804, "Q2 loss": 16.942299285888673, "Mean Target Q": 270.10838061523435, "Mean Q1": 270.1024001464844, "Mean Q2": 270.10479833984374, "critic_loss": 33.882026992797854, "batch_reward": 3.8602902812957764, "actor_loss": -272.5654764483052, "actor_target_entropy": -1.0, "actor_entropy": -0.4401840288792887, "alpha_loss": -0.09288418268965136, "alpha_value": 0.1658147605693895, "duration": 135.98585534095764, "step": 17000}
{"episode_reward": 761.1281190529503, "episode": 137.0, "Q1 loss": 18.444245697021483, "Q2 loss": 18.38578450012207, "Mean Target Q": 272.6702407226563, "Mean Q1": 272.66421411132814, "Mean Q2": 272.6619025878906, "critic_loss": 36.83003022766113, "batch_reward": 3.8636513862609863, "actor_loss": -274.7328496054998, "actor_target_entropy": -1.0, "actor_entropy": -0.39894924088129924, "alpha_loss": -0.09264715471201473, "alpha_value": 0.16693603023502815, "duration": 124.27954721450806, "step": 17125}
{"episode_reward": 776.6561031803708, "episode": 138.0, "Q1 loss": 19.725242889404296, "Q2 loss": 19.621311714172364, "Mean Target Q": 275.90379052734374, "Mean Q1": 275.8979543457031, "Mean Q2": 275.90050048828124, "critic_loss": 39.34655471801758, "batch_reward": 3.8824386768341066, "actor_loss": -277.78050674930694, "actor_target_entropy": -1.0, "actor_entropy": -0.40586638835168654, "alpha_loss": -0.09477389195272999, "alpha_value": 0.1680809218027624, "duration": 113.31525421142578, "step": 17250}
{"episode_reward": 834.97328099533, "episode": 139.0, "Q1 loss": 16.85725531768799, "Q2 loss": 16.944840324401856, "Mean Target Q": 279.5596713867188, "Mean Q1": 279.5462165527344, "Mean Q2": 279.54306298828124, "critic_loss": 33.80209550476074, "batch_reward": 3.920607488632202, "actor_loss": -281.9450174967448, "actor_target_entropy": -1.0, "actor_entropy": -0.4269376155875978, "alpha_loss": -0.08884070866874286, "alpha_value": 0.16919821447014102, "duration": 126.21212792396545, "step": 17375}
{"episode_reward": 826.5841067547624, "episode": 140.0, "Q1 loss": 18.963842887878418, "Q2 loss": 19.01773026275635, "Mean Target Q": 282.46731591796873, "Mean Q1": 282.46453735351565, "Mean Q2": 282.4640319824219, "critic_loss": 37.98157318115234, "batch_reward": 3.9332401924133302, "actor_loss": -284.5066675986013, "actor_target_entropy": -1.0, "actor_entropy": -0.40951177045222253, "alpha_loss": -0.08904827199876308, "alpha_value": 0.17028794883988527, "duration": 130.77428126335144, "step": 17500}
{"episode_reward": 771.0713691411595, "episode": 141.0, "Q1 loss": 18.728163726806642, "Q2 loss": 18.419946792602538, "Mean Target Q": 285.25918310546876, "Mean Q1": 285.25608569335935, "Mean Q2": 285.2614855957031, "critic_loss": 37.14811045837402, "batch_reward": 3.9352968578338623, "actor_loss": -287.4875793457031, "actor_target_entropy": -1.0, "actor_entropy": -0.4038025036690727, "alpha_loss": -0.09053084396180652, "alpha_value": 0.17141333553135102, "duration": 129.12688064575195, "step": 17625}
{"episode_reward": 771.3801885975411, "episode": 142.0, "Q1 loss": 17.815825637817383, "Q2 loss": 17.993935676574708, "Mean Target Q": 288.4789680175781, "Mean Q1": 288.47551928710936, "Mean Q2": 288.4736376953125, "critic_loss": 35.80976121520996, "batch_reward": 3.954874189376831, "actor_loss": -290.1496020901588, "actor_target_entropy": -1.0, "actor_entropy": -0.3750998570073035, "alpha_loss": -0.09216680738233751, "alpha_value": 0.17251112643018454, "duration": 71.75330376625061, "step": 17750}
{"episode_reward": 833.7604198101473, "episode": 143.0, "Q1 loss": 18.203894828796386, "Q2 loss": 17.976177047729493, "Mean Target Q": 291.3262939453125, "Mean Q1": 291.31670043945314, "Mean Q2": 291.31502270507815, "critic_loss": 36.180071884155275, "batch_reward": 3.958911460876465, "actor_loss": -293.5061224074591, "actor_target_entropy": -1.0, "actor_entropy": -0.3898144458967542, "alpha_loss": -0.088925833976458, "alpha_value": 0.17363324191510396, "duration": 61.173893213272095, "step": 17875}
{"episode_reward": 753.9894244289343, "episode": 144.0, "Q1 loss": 17.00620962524414, "Q2 loss": 16.89169030761719, "Mean Target Q": 294.65228076171877, "Mean Q1": 294.6383747558594, "Mean Q2": 294.6370576171875, "critic_loss": 33.89789988708496, "batch_reward": 3.9920654430389404, "actor_loss": -296.7083946966356, "actor_target_entropy": -1.0, "actor_entropy": -0.373986906341968, "alpha_loss": -0.08674719869609802, "alpha_value": 0.17472766282157096, "duration": 60.34756398200989, "step": 18000}
{"episode_reward": 840.39234162629, "episode": 145.0, "Q1 loss": 17.19408032989502, "Q2 loss": 17.073130752563475, "Mean Target Q": 297.6237331542969, "Mean Q1": 297.622568359375, "Mean Q2": 297.6262102050781, "critic_loss": 34.26721113586426, "batch_reward": 4.01745703125, "actor_loss": -299.6167437841022, "actor_target_entropy": -1.0, "actor_entropy": -0.3736092192786081, "alpha_loss": -0.08579517043535671, "alpha_value": 0.1758044027909886, "duration": 69.38787364959717, "step": 18125}
{"episode_reward": 845.1105696321781, "episode": 146.0, "Q1 loss": 17.291404998779296, "Q2 loss": 17.353392578125, "Mean Target Q": 301.20997973632814, "Mean Q1": 301.1906735839844, "Mean Q2": 301.1892023925781, "critic_loss": 34.64479765319824, "batch_reward": 4.034011608123779, "actor_loss": -303.5397181357107, "actor_target_entropy": -1.0, "actor_entropy": -0.35424759671572714, "alpha_loss": -0.08392160193574044, "alpha_value": 0.17688467312603215, "duration": 56.61378312110901, "step": 18250}
{"episode_reward": 800.8024106242326, "episode": 147.0, "Q1 loss": 17.12308242034912, "Q2 loss": 17.163199417114257, "Mean Target Q": 304.0723330078125, "Mean Q1": 304.0710173339844, "Mean Q2": 304.07103198242186, "critic_loss": 34.286281860351565, "batch_reward": 4.049880809783936, "actor_loss": -306.03149462503103, "actor_target_entropy": -1.0, "actor_entropy": -0.3429603614504375, "alpha_loss": -0.07702913294945445, "alpha_value": 0.1778920150669125, "duration": 55.3900408744812, "step": 18375}
{"episode_reward": 836.419075970161, "episode": 148.0, "Q1 loss": 17.471455184936524, "Q2 loss": 17.740900367736817, "Mean Target Q": 307.4785798339844, "Mean Q1": 307.47497998046873, "Mean Q2": 307.47428662109377, "critic_loss": 35.21235546875, "batch_reward": 4.070115844726563, "actor_loss": -309.64055756599674, "actor_target_entropy": -1.0, "actor_entropy": -0.3562026615104368, "alpha_loss": -0.08079907045729699, "alpha_value": 0.17889656770855844, "duration": 68.98872685432434, "step": 18500}
{"episode_reward": 845.946636294876, "episode": 149.0, "Q1 loss": 17.674248825073242, "Q2 loss": 17.6354037399292, "Mean Target Q": 310.46947534179685, "Mean Q1": 310.45672143554685, "Mean Q2": 310.45517749023435, "critic_loss": 35.30965267944336, "batch_reward": 4.097715503692627, "actor_loss": -313.1364111521887, "actor_target_entropy": -1.0, "actor_entropy": -0.3502839273876614, "alpha_loss": -0.07825393903823126, "alpha_value": 0.1799441982420251, "duration": 59.23240947723389, "step": 18625}
{"episode_reward": 830.3439528063375, "episode": 150.0, "Q1 loss": 17.596595474243163, "Q2 loss": 17.331268379211426, "Mean Target Q": 312.77607861328124, "Mean Q1": 312.77904467773436, "Mean Q2": 312.7794880371094, "critic_loss": 34.92786384582519, "batch_reward": 4.0871946907043455, "actor_loss": -314.966795398343, "actor_target_entropy": -1.0, "actor_entropy": -0.3086608722805977, "alpha_loss": -0.07727004948162264, "alpha_value": 0.1809757136183853, "duration": 61.93747067451477, "step": 18750}
{"episode_reward": 734.9629169113468, "episode": 151.0, "Q1 loss": 16.514868118286135, "Q2 loss": 16.51371943664551, "Mean Target Q": 316.0568889160156, "Mean Q1": 316.0373173828125, "Mean Q2": 316.0393752441406, "critic_loss": 33.0285874786377, "batch_reward": 4.130425241470337, "actor_loss": -317.76017494807166, "actor_target_entropy": -1.0, "actor_entropy": -0.31530164939070504, "alpha_loss": -0.07525423056786022, "alpha_value": 0.1819665924873353, "duration": 72.10480260848999, "step": 18875}
{"episode_reward": 837.4800762379332, "episode": 152.0, "Q1 loss": 16.10752980041504, "Q2 loss": 16.0826114654541, "Mean Target Q": 318.35746728515625, "Mean Q1": 318.357890625, "Mean Q2": 318.35940869140626, "critic_loss": 32.19014128112793, "batch_reward": 4.110600574493408, "actor_loss": -320.0385481311429, "actor_target_entropy": -1.0, "actor_entropy": -0.31420389274435656, "alpha_loss": -0.07256478828287893, "alpha_value": 0.18295522366638176, "duration": 71.58210825920105, "step": 19000}
{"episode_reward": 830.0525201540622, "episode": 153.0, "Q1 loss": 17.247937965393067, "Q2 loss": 17.120930282592774, "Mean Target Q": 321.87533764648435, "Mean Q1": 321.85977465820315, "Mean Q2": 321.858287109375, "critic_loss": 34.3688683013916, "batch_reward": 4.154691370010376, "actor_loss": -323.8179447234623, "actor_target_entropy": -1.0, "actor_entropy": -0.32240036839530584, "alpha_loss": -0.07348865731841042, "alpha_value": 0.18395817348797858, "duration": 73.71000003814697, "step": 19125}
{"episode_reward": 842.0740749155809, "episode": 154.0, "Q1 loss": 17.135696014404296, "Q2 loss": 17.151205810546877, "Mean Target Q": 324.68724877929685, "Mean Q1": 324.68238671875, "Mean Q2": 324.6822734375, "critic_loss": 34.28690174865723, "batch_reward": 4.176194215774536, "actor_loss": -326.61301742061494, "actor_target_entropy": -1.0, "actor_entropy": -0.3037650907231915, "alpha_loss": -0.06914859042773323, "alpha_value": 0.18494577239022936, "duration": 69.52411699295044, "step": 19250}
{"episode_reward": 837.903911786218, "episode": 155.0, "Q1 loss": 17.13554973602295, "Q2 loss": 17.044058586120606, "Mean Target Q": 327.29444213867185, "Mean Q1": 327.28884130859376, "Mean Q2": 327.2889938964844, "critic_loss": 34.17960832214356, "batch_reward": 4.189671356201172, "actor_loss": -329.4500713045635, "actor_target_entropy": -1.0, "actor_entropy": -0.2645118662289211, "alpha_loss": -0.06766761732952935, "alpha_value": 0.1858741868131627, "duration": 58.5347535610199, "step": 19375}
{"episode_reward": 768.3055071693483, "episode": 156.0, "Q1 loss": 18.31058910369873, "Q2 loss": 18.386928192138672, "Mean Target Q": 329.6057578125, "Mean Q1": 329.600466796875, "Mean Q2": 329.5998215332031, "critic_loss": 36.69751731872559, "batch_reward": 4.179568933486938, "actor_loss": -331.63592086299775, "actor_target_entropy": -1.0, "actor_entropy": -0.29429908445285213, "alpha_loss": -0.06754874359936483, "alpha_value": 0.18682857710021558, "duration": 81.36203002929688, "step": 19500}
{"episode_reward": 759.0132657602367, "episode": 157.0, "Q1 loss": 16.693223655700685, "Q2 loss": 16.881024131774904, "Mean Target Q": 332.4904309082031, "Mean Q1": 332.47304125976564, "Mean Q2": 332.47593896484375, "critic_loss": 33.57424780273438, "batch_reward": 4.202437240600586, "actor_loss": -334.3961322118366, "actor_target_entropy": -1.0, "actor_entropy": -0.24286395571534597, "alpha_loss": -0.07104224705743412, "alpha_value": 0.18782106386185043, "duration": 69.67515993118286, "step": 19625}
{"episode_reward": 731.0899972957704, "episode": 158.0, "Q1 loss": 16.89766709136963, "Q2 loss": 16.943839691162108, "Mean Target Q": 335.1997854003906, "Mean Q1": 335.2027531738281, "Mean Q2": 335.2020378417969, "critic_loss": 33.84150692749024, "batch_reward": 4.207997598648071, "actor_loss": -337.33602314610636, "actor_target_entropy": -1.0, "actor_entropy": -0.2697462739963685, "alpha_loss": -0.06548652085926264, "alpha_value": 0.18880049664468754, "duration": 116.5257682800293, "step": 19750}
{"episode_reward": 760.1053666595442, "episode": 159.0, "Q1 loss": 17.97440766143799, "Q2 loss": 17.92592391204834, "Mean Target Q": 337.764501953125, "Mean Q1": 337.7603662109375, "Mean Q2": 337.75922680664064, "critic_loss": 35.90033158874512, "batch_reward": 4.219888471603394, "actor_loss": -339.6171279180618, "actor_target_entropy": -1.0, "actor_entropy": -0.2552126298348109, "alpha_loss": -0.07241053151942435, "alpha_value": 0.18983096907908698, "duration": 116.49737858772278, "step": 19875}
{"episode_reward": 756.33256552036, "episode": 160.0, "Q1 loss": 18.038653564453124, "Q2 loss": 18.13246922302246, "Mean Target Q": 340.513552734375, "Mean Q1": 340.5020483398437, "Mean Q2": 340.501142578125, "critic_loss": 36.17112284851074, "batch_reward": 4.238319696426392, "actor_loss": -342.31997877551663, "actor_target_entropy": -1.0, "actor_entropy": -0.2813282363837765, "alpha_loss": -0.06799742140837255, "alpha_value": 0.19083953396019462, "step": 20000}
{"duration": 123.59923362731934, "step": 20000}
{"episode_reward": 760.9632970846066, "episode": 161.0, "Q1 loss": 17.377796318054198, "Q2 loss": 17.390562797546387, "Mean Target Q": 343.1709150390625, "Mean Q1": 343.1656489257812, "Mean Q2": 343.1654521484375, "critic_loss": 34.76835906982422, "batch_reward": 4.254615716934204, "actor_loss": -345.17154996357266, "actor_target_entropy": -1.0, "actor_entropy": -0.2892093701022012, "alpha_loss": -0.061309736517686696, "alpha_value": 0.1918462169945016, "duration": 76.74817156791687, "step": 20125}
{"episode_reward": 756.9958088894147, "episode": 162.0, "Q1 loss": 17.744307929992676, "Q2 loss": 17.55069421386719, "Mean Target Q": 345.1531828613281, "Mean Q1": 345.1458376464844, "Mean Q2": 345.14847094726565, "critic_loss": 35.295002197265624, "batch_reward": 4.228965299606323, "actor_loss": -346.88910305884576, "actor_target_entropy": -1.0, "actor_entropy": -0.2719702703818198, "alpha_loss": -0.06556432321667671, "alpha_value": 0.1928122582712735, "duration": 60.7926664352417, "step": 20250}
{"episode_reward": 753.3454611984547, "episode": 163.0, "Q1 loss": 18.67168579864502, "Q2 loss": 18.575819862365723, "Mean Target Q": 348.2285476074219, "Mean Q1": 348.2221455078125, "Mean Q2": 348.2206293945313, "critic_loss": 37.24750564575195, "batch_reward": 4.27214179611206, "actor_loss": -350.085684640067, "actor_target_entropy": -1.0, "actor_entropy": -0.25772554486516924, "alpha_loss": -0.05886272574582743, "alpha_value": 0.19378007149412804, "duration": 62.32725167274475, "step": 20375}
{"episode_reward": 769.5413021519793, "episode": 164.0, "Q1 loss": 17.54412928009033, "Q2 loss": 17.633931785583496, "Mean Target Q": 351.05465185546876, "Mean Q1": 351.04513330078123, "Mean Q2": 351.0457971191406, "critic_loss": 35.17806103515625, "batch_reward": 4.282290090560913, "actor_loss": -352.653315882529, "actor_target_entropy": -1.0, "actor_entropy": -0.25653828992958994, "alpha_loss": -0.05681228718810504, "alpha_value": 0.19468182777047127, "duration": 63.46613383293152, "step": 20500}
{"episode_reward": 759.8887755138838, "episode": 165.0, "Q1 loss": 16.951230140686036, "Q2 loss": 17.087631729125977, "Mean Target Q": 353.0798181152344, "Mean Q1": 353.07699096679687, "Mean Q2": 353.075984375, "critic_loss": 34.03886184692383, "batch_reward": 4.284348052978515, "actor_loss": -354.6777571420821, "actor_target_entropy": -1.0, "actor_entropy": -0.2539301722768753, "alpha_loss": -0.05760209339242133, "alpha_value": 0.19563594094946066, "duration": 66.15610551834106, "step": 20625}
{"episode_reward": 759.1722875602617, "episode": 166.0, "Q1 loss": 16.46997843170166, "Q2 loss": 16.491710914611815, "Mean Target Q": 356.52782568359373, "Mean Q1": 356.5221584472656, "Mean Q2": 356.5188620605469, "critic_loss": 32.961689392089845, "batch_reward": 4.333241561889649, "actor_loss": -358.2330789873677, "actor_target_entropy": -1.0, "actor_entropy": -0.3036398832355776, "alpha_loss": -0.061904994680756525, "alpha_value": 0.19659691079646455, "duration": 62.13360857963562, "step": 20750}
{"episode_reward": 765.4424569748205, "episode": 167.0, "Q1 loss": 16.7186428527832, "Q2 loss": 16.932087562561033, "Mean Target Q": 358.1266279296875, "Mean Q1": 358.1184440917969, "Mean Q2": 358.12064965820315, "critic_loss": 33.65073048400879, "batch_reward": 4.3136899871826175, "actor_loss": -359.5673353407118, "actor_target_entropy": -1.0, "actor_entropy": -0.29281540404236506, "alpha_loss": -0.056796248056112775, "alpha_value": 0.19759706762259258, "duration": 56.269511699676514, "step": 20875}
{"episode_reward": 765.0353383092695, "episode": 168.0, "Q1 loss": 17.71044623565674, "Q2 loss": 17.875055641174317, "Mean Target Q": 360.8746333007812, "Mean Q1": 360.87023095703125, "Mean Q2": 360.8689658203125, "critic_loss": 35.585501892089844, "batch_reward": 4.325693252563476, "actor_loss": -362.29930705408896, "actor_target_entropy": -1.0, "actor_entropy": -0.28243217184658975, "alpha_loss": -0.06170958286571887, "alpha_value": 0.1985850607347271, "duration": 116.01514148712158, "step": 21000}
{"episode_reward": 835.6241803311018, "episode": 169.0, "Q1 loss": 18.81893635559082, "Q2 loss": 18.82301837158203, "Mean Target Q": 362.82265576171875, "Mean Q1": 362.8135285644531, "Mean Q2": 362.81559252929685, "critic_loss": 37.641954620361325, "batch_reward": 4.325337566375732, "actor_loss": -364.4478987436446, "actor_target_entropy": -1.0, "actor_entropy": -0.2734965483347575, "alpha_loss": -0.05908353094543729, "alpha_value": 0.19960073513788956, "duration": 135.65481162071228, "step": 21125}
{"episode_reward": 768.8412573953518, "episode": 170.0, "Q1 loss": 17.66242625427246, "Q2 loss": 17.5269967956543, "Mean Target Q": 365.3135546875, "Mean Q1": 365.30575073242187, "Mean Q2": 365.30468969726564, "critic_loss": 35.1894229888916, "batch_reward": 4.352372007369995, "actor_loss": -366.99340278871597, "actor_target_entropy": -1.0, "actor_entropy": -0.28382706858458057, "alpha_loss": -0.0548687556668395, "alpha_value": 0.20057323556109502, "duration": 165.44909191131592, "step": 21250}
{"episode_reward": 771.4322411281852, "episode": 171.0, "Q1 loss": 17.09620166015625, "Q2 loss": 16.952906364440917, "Mean Target Q": 367.463916015625, "Mean Q1": 367.4576516113281, "Mean Q2": 367.46150805664064, "critic_loss": 34.04910801696777, "batch_reward": 4.343247695922852, "actor_loss": -369.51915971059645, "actor_target_entropy": -1.0, "actor_entropy": -0.26707758222307476, "alpha_loss": -0.055637147041067245, "alpha_value": 0.20155126003970406, "duration": 145.20289611816406, "step": 21375}
{"episode_reward": 768.1809660516074, "episode": 172.0, "Q1 loss": 15.872275611877441, "Q2 loss": 16.02970802307129, "Mean Target Q": 370.35014208984376, "Mean Q1": 370.346908203125, "Mean Q2": 370.34373168945314, "critic_loss": 31.901983703613283, "batch_reward": 4.38488106918335, "actor_loss": -371.9979228358115, "actor_target_entropy": -1.0, "actor_entropy": -0.2670592603183562, "alpha_loss": -0.05140131162179093, "alpha_value": 0.2025012217404501, "duration": 85.74056673049927, "step": 21500}
{"episode_reward": 828.3882694898548, "episode": 173.0, "Q1 loss": 15.453745880126952, "Q2 loss": 15.59628830718994, "Mean Target Q": 372.594013671875, "Mean Q1": 372.59456372070315, "Mean Q2": 372.5932399902344, "critic_loss": 31.050034255981444, "batch_reward": 4.377651794433594, "actor_loss": -374.3417164636037, "actor_target_entropy": -1.0, "actor_entropy": -0.3009768710249946, "alpha_loss": -0.05395198421227553, "alpha_value": 0.20343676767132435, "duration": 143.51572036743164, "step": 21625}
{"episode_reward": 836.2619507647039, "episode": 174.0, "Q1 loss": 16.49405918121338, "Q2 loss": 16.502333557128907, "Mean Target Q": 374.75874267578126, "Mean Q1": 374.7502880859375, "Mean Q2": 374.7510981445312, "critic_loss": 32.99639279174805, "batch_reward": 4.3981146850585935, "actor_loss": -376.3818147720829, "actor_target_entropy": -1.0, "actor_entropy": -0.30688194954587567, "alpha_loss": -0.051365000766611865, "alpha_value": 0.20443237991200347, "duration": 140.26683568954468, "step": 21750}
{"episode_reward": 771.7812556323665, "episode": 175.0, "Q1 loss": 17.048393600463868, "Q2 loss": 17.059299629211427, "Mean Target Q": 377.2481853027344, "Mean Q1": 377.23732299804686, "Mean Q2": 377.23829931640626, "critic_loss": 34.107693466186525, "batch_reward": 4.409445014953613, "actor_loss": -378.90479242234005, "actor_target_entropy": -1.0, "actor_entropy": -0.317033765571458, "alpha_loss": -0.05678022916000041, "alpha_value": 0.20542232315355416, "duration": 146.5949673652649, "step": 21875}
{"episode_reward": 836.8903958274093, "episode": 176.0, "Q1 loss": 17.272986068725587, "Q2 loss": 17.421795654296876, "Mean Target Q": 378.9509389648438, "Mean Q1": 378.9464812011719, "Mean Q2": 378.94713012695314, "critic_loss": 34.69478184509278, "batch_reward": 4.40195478439331, "actor_loss": -380.71715373377646, "actor_target_entropy": -1.0, "actor_entropy": -0.22692400697738893, "alpha_loss": -0.04880892865419868, "alpha_value": 0.20646410087687517, "duration": 169.58098244667053, "step": 22000}
{"episode_reward": 841.2233226593125, "episode": 177.0, "Q1 loss": 16.629651443481446, "Q2 loss": 16.518896392822267, "Mean Target Q": 381.7525244140625, "Mean Q1": 381.749021484375, "Mean Q2": 381.7476962890625, "critic_loss": 33.14854774475098, "batch_reward": 4.434192531585693, "actor_loss": -383.6095702156188, "actor_target_entropy": -1.0, "actor_entropy": -0.2919476756027767, "alpha_loss": -0.05639798498697697, "alpha_value": 0.2075026391311496, "duration": 156.6784965991974, "step": 22125}
{"episode_reward": 833.276069498373, "episode": 178.0, "Q1 loss": 15.84463291168213, "Q2 loss": 16.023724075317382, "Mean Target Q": 384.15503662109376, "Mean Q1": 384.1481867675781, "Mean Q2": 384.14913525390625, "critic_loss": 31.868356979370116, "batch_reward": 4.453643787384033, "actor_loss": -385.7751169512349, "actor_target_entropy": -1.0, "actor_entropy": -0.29055729316126916, "alpha_loss": -0.052098955673676346, "alpha_value": 0.20852012336560696, "duration": 156.97320556640625, "step": 22250}
{"episode_reward": 834.5158502645914, "episode": 179.0, "Q1 loss": 15.597679161071778, "Q2 loss": 15.664842071533203, "Mean Target Q": 386.364681640625, "Mean Q1": 386.3531325683594, "Mean Q2": 386.35065087890627, "critic_loss": 31.26252117919922, "batch_reward": 4.465934917449951, "actor_loss": -388.1061023530506, "actor_target_entropy": -1.0, "actor_entropy": -0.2629694627627494, "alpha_loss": -0.04909345884585664, "alpha_value": 0.20959821489028604, "duration": 175.4604527950287, "step": 22375}
{"episode_reward": 843.8093233534976, "episode": 180.0, "Q1 loss": 16.403980308532716, "Q2 loss": 16.397364921569825, "Mean Target Q": 388.60540893554685, "Mean Q1": 388.60186743164064, "Mean Q2": 388.60422314453126, "critic_loss": 32.80134538269043, "batch_reward": 4.472915615081787, "actor_loss": -389.76022240423384, "actor_target_entropy": -1.0, "actor_entropy": -0.2789104241997965, "alpha_loss": -0.05268202082163865, "alpha_value": 0.2105515714653226, "duration": 142.52883887290955, "step": 22500}
{"episode_reward": 842.8475118657379, "episode": 181.0, "Q1 loss": 15.47884871673584, "Q2 loss": 15.544207023620606, "Mean Target Q": 390.85658129882813, "Mean Q1": 390.85110546875, "Mean Q2": 390.8525390625, "critic_loss": 31.023055801391603, "batch_reward": 4.4887420997619625, "actor_loss": -392.49051678369915, "actor_target_entropy": -1.0, "actor_entropy": -0.3093754542725427, "alpha_loss": -0.05086255709211978, "alpha_value": 0.2116050678065901, "duration": 177.19599223136902, "step": 22625}
{"episode_reward": 827.8515844717841, "episode": 182.0, "Q1 loss": 14.771843696594239, "Q2 loss": 14.820834899902344, "Mean Target Q": 392.83724584960936, "Mean Q1": 392.828763671875, "Mean Q2": 392.82594165039063, "critic_loss": 29.592678619384767, "batch_reward": 4.479146415710449, "actor_loss": -394.49769395397556, "actor_target_entropy": -1.0, "actor_entropy": -0.2644038875737498, "alpha_loss": -0.048581133025788495, "alpha_value": 0.21264226238115377, "duration": 163.27917957305908, "step": 22750}
{"episode_reward": 842.7461590014503, "episode": 183.0, "Q1 loss": 14.982391334533691, "Q2 loss": 15.03865859222412, "Mean Target Q": 395.5478940429688, "Mean Q1": 395.54591162109375, "Mean Q2": 395.54624658203124, "critic_loss": 30.02104992675781, "batch_reward": 4.519707653045654, "actor_loss": -397.066400437128, "actor_target_entropy": -1.0, "actor_entropy": -0.26628269042287556, "alpha_loss": -0.04988484698835583, "alpha_value": 0.2137423079866813, "duration": 165.52259397506714, "step": 22875}
{"episode_reward": 840.0735945202449, "episode": 184.0, "Q1 loss": 15.370048622131348, "Q2 loss": 15.33175714111328, "Mean Target Q": 397.7832998046875, "Mean Q1": 397.7799074707031, "Mean Q2": 397.78181958007815, "critic_loss": 30.701805740356445, "batch_reward": 4.510298015594483, "actor_loss": -399.2078562090474, "actor_target_entropy": -1.0, "actor_entropy": -0.2873252897012618, "alpha_loss": -0.04758287611747942, "alpha_value": 0.2147479541781421, "duration": 128.51631808280945, "step": 23000}
{"episode_reward": 828.5114960010767, "episode": 185.0, "Q1 loss": 14.7614951171875, "Q2 loss": 14.906392791748047, "Mean Target Q": 400.1620141601563, "Mean Q1": 400.1483425292969, "Mean Q2": 400.1476650390625, "critic_loss": 29.667887908935548, "batch_reward": 4.549022445678711, "actor_loss": -401.8745960053943, "actor_target_entropy": -1.0, "actor_entropy": -0.30869567678088233, "alpha_loss": -0.044231745488350356, "alpha_value": 0.21574527351676825, "duration": 165.8142580986023, "step": 23125}
{"episode_reward": 825.205442434037, "episode": 186.0, "Q1 loss": 15.675987579345703, "Q2 loss": 15.677649932861328, "Mean Target Q": 402.1925986328125, "Mean Q1": 402.19556909179687, "Mean Q2": 402.19437670898435, "critic_loss": 31.35363752746582, "batch_reward": 4.545140674591065, "actor_loss": -403.3747184507308, "actor_target_entropy": -1.0, "actor_entropy": -0.24453512146588294, "alpha_loss": -0.04797483890527679, "alpha_value": 0.21678856714832725, "duration": 161.07813620567322, "step": 23250}
{"episode_reward": 823.6399779002579, "episode": 187.0, "Q1 loss": 16.18198983001709, "Q2 loss": 16.15645009613037, "Mean Target Q": 404.3177175292969, "Mean Q1": 404.3122985839844, "Mean Q2": 404.3121809082031, "critic_loss": 32.338440032958985, "batch_reward": 4.5490970726013185, "actor_loss": -406.10055251348587, "actor_target_entropy": -1.0, "actor_entropy": -0.290527386797799, "alpha_loss": -0.04474635673539033, "alpha_value": 0.21780760018016812, "duration": 184.37623834609985, "step": 23375}
{"episode_reward": 830.0997600520509, "episode": 188.0, "Q1 loss": 15.556139541625976, "Q2 loss": 15.699348754882813, "Mean Target Q": 406.9590161132812, "Mean Q1": 406.94869189453124, "Mean Q2": 406.948421875, "critic_loss": 31.25548831176758, "batch_reward": 4.576163871765137, "actor_loss": -408.6404010403541, "actor_target_entropy": -1.0, "actor_entropy": -0.2399087764563099, "alpha_loss": -0.0380882877450917, "alpha_value": 0.21877835017750447, "duration": 162.90884399414062, "step": 23500}
{"episode_reward": 747.0019483382753, "episode": 189.0, "Q1 loss": 15.302823852539062, "Q2 loss": 15.249155685424805, "Mean Target Q": 408.77945336914064, "Mean Q1": 408.7770139160156, "Mean Q2": 408.77864208984374, "critic_loss": 30.55197947692871, "batch_reward": 4.579923931121826, "actor_loss": -410.39351641942585, "actor_target_entropy": -1.0, "actor_entropy": -0.2537229301200973, "alpha_loss": -0.040082894901316314, "alpha_value": 0.21967877831115698, "duration": 171.68119764328003, "step": 23625}
{"episode_reward": 845.3574545726877, "episode": 190.0, "Q1 loss": 14.789344688415527, "Q2 loss": 14.922089881896973, "Mean Target Q": 411.21765844726565, "Mean Q1": 411.20835083007813, "Mean Q2": 411.20570263671874, "critic_loss": 29.711434478759767, "batch_reward": 4.599340915679932, "actor_loss": -413.02628351026965, "actor_target_entropy": -1.0, "actor_entropy": -0.2884157047637047, "alpha_loss": -0.04300431542158607, "alpha_value": 0.22065173935461188, "duration": 130.67020463943481, "step": 23750}
{"episode_reward": 845.1361326318107, "episode": 191.0, "Q1 loss": 14.893347328186035, "Q2 loss": 14.96084129333496, "Mean Target Q": 413.61408349609377, "Mean Q1": 413.6135810546875, "Mean Q2": 413.61474609375, "critic_loss": 29.85418865966797, "batch_reward": 4.607512302398682, "actor_loss": -415.09794059632316, "actor_target_entropy": -1.0, "actor_entropy": -0.27184819323675974, "alpha_loss": -0.043454692639883545, "alpha_value": 0.22167913103844386, "duration": 166.7468340396881, "step": 23875}
{"episode_reward": 835.3910084614957, "episode": 192.0, "Q1 loss": 15.242233726501464, "Q2 loss": 15.255074035644531, "Mean Target Q": 415.36410034179687, "Mean Q1": 415.35322680664063, "Mean Q2": 415.3553720703125, "critic_loss": 30.497307571411135, "batch_reward": 4.618629383087158, "actor_loss": -416.7584533691406, "actor_target_entropy": -1.0, "actor_entropy": -0.2641779689058181, "alpha_loss": -0.03884952287039449, "alpha_value": 0.2227031121427347, "duration": 145.16552710533142, "step": 24000}
{"episode_reward": 822.5745041493149, "episode": 193.0, "Q1 loss": 14.840511688232422, "Q2 loss": 14.891587348937989, "Mean Target Q": 417.5917492675781, "Mean Q1": 417.5912265625, "Mean Q2": 417.5893244628906, "critic_loss": 29.732099105834962, "batch_reward": 4.630225048065186, "actor_loss": -418.6620468866257, "actor_target_entropy": -1.0, "actor_entropy": -0.26657803332994856, "alpha_loss": -0.04194493735918686, "alpha_value": 0.2237573925234287, "duration": 121.27458953857422, "step": 24125}
{"episode_reward": 836.4127749998916, "episode": 194.0, "Q1 loss": 14.189903480529786, "Q2 loss": 14.289896690368652, "Mean Target Q": 418.955701171875, "Mean Q1": 418.9483002929687, "Mean Q2": 418.94960791015626, "critic_loss": 28.479800216674803, "batch_reward": 4.598669185638427, "actor_loss": -420.5768127441406, "actor_target_entropy": -1.0, "actor_entropy": -0.24759693828321272, "alpha_loss": -0.03694919296239893, "alpha_value": 0.22466580475415712, "duration": 90.90382480621338, "step": 24250}
{"episode_reward": 840.0414531122983, "episode": 195.0, "Q1 loss": 14.868289543151855, "Q2 loss": 14.79427360534668, "Mean Target Q": 421.13318188476563, "Mean Q1": 421.13301586914065, "Mean Q2": 421.13258203125, "critic_loss": 29.66256312561035, "batch_reward": 4.641752639770508, "actor_loss": -422.13133845253594, "actor_target_entropy": -1.0, "actor_entropy": -0.24190735178334372, "alpha_loss": -0.03859840552987797, "alpha_value": 0.22569354504758263, "duration": 57.663591146469116, "step": 24375}
{"episode_reward": 839.7146216674561, "episode": 196.0, "Q1 loss": 14.37103231048584, "Q2 loss": 14.375913696289063, "Mean Target Q": 423.20798388671875, "Mean Q1": 423.19605419921874, "Mean Q2": 423.19570751953125, "critic_loss": 28.74694593811035, "batch_reward": 4.631006454467774, "actor_loss": -424.83213609264743, "actor_target_entropy": -1.0, "actor_entropy": -0.2695641613775684, "alpha_loss": -0.03490516695854885, "alpha_value": 0.22663836006456017, "duration": 97.22699856758118, "step": 24500}
{"episode_reward": 817.6339768861471, "episode": 197.0, "Q1 loss": 13.969727233886719, "Q2 loss": 14.14097974395752, "Mean Target Q": 425.88402099609374, "Mean Q1": 425.8863100585937, "Mean Q2": 425.88752221679687, "critic_loss": 28.1107068939209, "batch_reward": 4.6736231155395505, "actor_loss": -427.6537470741877, "actor_target_entropy": -1.0, "actor_entropy": -0.2583416168178831, "alpha_loss": -0.03173841815441847, "alpha_value": 0.22755612176466883, "duration": 127.99089741706848, "step": 24625}
{"episode_reward": 842.6423860357866, "episode": 198.0, "Q1 loss": 13.742254592895508, "Q2 loss": 13.761584709167481, "Mean Target Q": 428.07997875976565, "Mean Q1": 428.06860180664063, "Mean Q2": 428.0677763671875, "critic_loss": 27.503839279174805, "batch_reward": 4.701753341674805, "actor_loss": -429.67230470718874, "actor_target_entropy": -1.0, "actor_entropy": -0.2608192113618697, "alpha_loss": -0.02612983814681009, "alpha_value": 0.22828465722783856, "duration": 116.68580913543701, "step": 24750}
{"episode_reward": 822.0801567809854, "episode": 199.0, "Q1 loss": 13.909766510009765, "Q2 loss": 13.965179306030274, "Mean Target Q": 429.77876220703126, "Mean Q1": 429.77393920898436, "Mean Q2": 429.77455419921876, "critic_loss": 27.874945861816407, "batch_reward": 4.6974114990234375, "actor_loss": -431.30455477275547, "actor_target_entropy": -1.0, "actor_entropy": -0.265629485012993, "alpha_loss": -0.03239664351863284, "alpha_value": 0.22915645259590037, "duration": 99.29014277458191, "step": 24875}
{"episode_reward": 833.1703530376545, "episode": 200.0, "Q1 loss": 13.48069571685791, "Q2 loss": 13.677354148864746, "Mean Target Q": 431.45998388671876, "Mean Q1": 431.4581015625, "Mean Q2": 431.45766040039064, "critic_loss": 27.158049835205077, "batch_reward": 4.67396399307251, "actor_loss": -432.66497802734375, "actor_target_entropy": -1.0, "actor_entropy": -0.21380621459214919, "alpha_loss": -0.0250622401494653, "alpha_value": 0.22997597746825466, "step": 25000}
{"duration": 73.24881529808044, "step": 25000}
{"episode_reward": 830.5841478852088, "episode": 201.0, "Q1 loss": 14.1313695602417, "Q2 loss": 13.981059890747071, "Mean Target Q": 433.5849814453125, "Mean Q1": 433.58700756835935, "Mean Q2": 433.58637060546874, "critic_loss": 28.11242953491211, "batch_reward": 4.692793846130371, "actor_loss": -435.1759532141307, "actor_target_entropy": -1.0, "actor_entropy": -0.2351637544139983, "alpha_loss": -0.029666048068080157, "alpha_value": 0.2307991584488479, "duration": 70.67324209213257, "step": 25125}
{"episode_reward": 841.5983397151309, "episode": 202.0, "Q1 loss": 14.2399521484375, "Q2 loss": 14.438312477111817, "Mean Target Q": 435.447908203125, "Mean Q1": 435.43774633789064, "Mean Q2": 435.4381279296875, "critic_loss": 28.678264556884766, "batch_reward": 4.696597583770752, "actor_loss": -436.8471472955519, "actor_target_entropy": -1.0, "actor_entropy": -0.26418962137353036, "alpha_loss": -0.03204922152743224, "alpha_value": 0.2316656600121069, "duration": 58.20653700828552, "step": 25250}
{"episode_reward": 848.8591717313305, "episode": 203.0, "Q1 loss": 13.657211219787598, "Q2 loss": 13.762165229797363, "Mean Target Q": 437.395380859375, "Mean Q1": 437.39425927734374, "Mean Q2": 437.39271826171876, "critic_loss": 27.419376495361327, "batch_reward": 4.7162061767578125, "actor_loss": -438.43497043185766, "actor_target_entropy": -1.0, "actor_entropy": -0.2274604229226945, "alpha_loss": -0.028884889565349098, "alpha_value": 0.23258375063573294, "duration": 59.60717988014221, "step": 25375}
{"episode_reward": 835.1661659352582, "episode": 204.0, "Q1 loss": 14.27804630279541, "Q2 loss": 14.184535301208497, "Mean Target Q": 439.45265087890624, "Mean Q1": 439.4415910644531, "Mean Q2": 439.4435390625, "critic_loss": 28.462581451416014, "batch_reward": 4.734377738952637, "actor_loss": -441.2445993731099, "actor_target_entropy": -1.0, "actor_entropy": -0.22604532996493001, "alpha_loss": -0.021540868471586896, "alpha_value": 0.23340708957442452, "duration": 74.68066787719727, "step": 25500}
{"episode_reward": 842.1146465258348, "episode": 205.0, "Q1 loss": 13.543975379943848, "Q2 loss": 13.579608192443848, "Mean Target Q": 441.32834033203125, "Mean Q1": 441.327380859375, "Mean Q2": 441.32794140625, "critic_loss": 27.123583557128907, "batch_reward": 4.744694011688233, "actor_loss": -442.84197998046875, "actor_target_entropy": -1.0, "actor_entropy": -0.22068446685397436, "alpha_loss": -0.019936957374392522, "alpha_value": 0.23406121303004523, "duration": 125.83612823486328, "step": 25625}
{"episode_reward": 829.0263841348187, "episode": 206.0, "Q1 loss": 14.063847038269042, "Q2 loss": 14.048871452331543, "Mean Target Q": 442.97191455078126, "Mean Q1": 442.96547314453124, "Mean Q2": 442.96413500976564, "critic_loss": 28.11271858215332, "batch_reward": 4.727547481536865, "actor_loss": -444.2818062074723, "actor_target_entropy": -1.0, "actor_entropy": -0.23103551638703193, "alpha_loss": -0.02985735516244125, "alpha_value": 0.23485801204448872, "duration": 150.04974675178528, "step": 25750}
{"episode_reward": 838.2972345007518, "episode": 207.0, "Q1 loss": 13.865918956756591, "Q2 loss": 13.903681587219237, "Mean Target Q": 445.2968325195312, "Mean Q1": 445.29141723632813, "Mean Q2": 445.29033447265624, "critic_loss": 27.769600631713868, "batch_reward": 4.774647876739502, "actor_loss": -446.58715384347096, "actor_target_entropy": -1.0, "actor_entropy": -0.20540402675904926, "alpha_loss": -0.024225370027124882, "alpha_value": 0.23576183380956706, "duration": 159.64656686782837, "step": 25875}
{"episode_reward": 834.7019548017674, "episode": 208.0, "Q1 loss": 15.035066436767577, "Q2 loss": 14.900899421691895, "Mean Target Q": 446.65822119140626, "Mean Q1": 446.6544040527344, "Mean Q2": 446.6576516113281, "critic_loss": 29.93596585083008, "batch_reward": 4.748229557037353, "actor_loss": -448.3792990407636, "actor_target_entropy": -1.0, "actor_entropy": -0.25565309221706084, "alpha_loss": -0.019807269297269805, "alpha_value": 0.23652113826758223, "duration": 115.57279586791992, "step": 26000}
{"episode_reward": 831.2333373154413, "episode": 209.0, "Q1 loss": 13.561992736816407, "Q2 loss": 13.538333221435547, "Mean Target Q": 448.78543896484376, "Mean Q1": 448.7790739746094, "Mean Q2": 448.7780791015625, "critic_loss": 27.100325942993162, "batch_reward": 4.789919498443603, "actor_loss": -450.35522218734496, "actor_target_entropy": -1.0, "actor_entropy": -0.23521503309408823, "alpha_loss": -0.018814065101896486, "alpha_value": 0.23714957003937823, "duration": 127.28367066383362, "step": 26125}
{"episode_reward": 831.3002752743788, "episode": 210.0, "Q1 loss": 13.76458798980713, "Q2 loss": 13.77799959564209, "Mean Target Q": 450.2983781738281, "Mean Q1": 450.28871020507813, "Mean Q2": 450.28908618164064, "critic_loss": 27.54258757019043, "batch_reward": 4.778631572723389, "actor_loss": -451.7852522327054, "actor_target_entropy": -1.0, "actor_entropy": -0.24840406088098402, "alpha_loss": -0.020366233435549563, "alpha_value": 0.23788362714889466, "duration": 120.46102857589722, "step": 26250}
{"episode_reward": 838.5077474559441, "episode": 211.0, "Q1 loss": 12.668832328796388, "Q2 loss": 12.719289695739747, "Mean Target Q": 452.1949208984375, "Mean Q1": 452.1957912597656, "Mean Q2": 452.19496484375, "critic_loss": 25.388122039794922, "batch_reward": 4.7916726303100585, "actor_loss": -453.5829453241257, "actor_target_entropy": -1.0, "actor_entropy": -0.2494363004253024, "alpha_loss": -0.02530982235210046, "alpha_value": 0.23875284447430423, "duration": 119.23490858078003, "step": 26375}
{"episode_reward": 764.3680544847986, "episode": 212.0, "Q1 loss": 13.532290046691895, "Q2 loss": 13.543364196777343, "Mean Target Q": 453.8350070800781, "Mean Q1": 453.83644091796873, "Mean Q2": 453.83696899414065, "critic_loss": 27.07565412902832, "batch_reward": 4.795428375244141, "actor_loss": -455.1613070580267, "actor_target_entropy": -1.0, "actor_entropy": -0.23359043908215338, "alpha_loss": -0.02420724353625349, "alpha_value": 0.23963095069906626, "duration": 161.45380210876465, "step": 26500}
{"episode_reward": 828.3590434522332, "episode": 213.0, "Q1 loss": 13.798416717529296, "Q2 loss": 13.726593383789062, "Mean Target Q": 455.8676381835937, "Mean Q1": 455.8674470214844, "Mean Q2": 455.866078125, "critic_loss": 27.525010101318358, "batch_reward": 4.818146884918213, "actor_loss": -457.2772662450397, "actor_target_entropy": -1.0, "actor_entropy": -0.20895483900630285, "alpha_loss": -0.011177425091672275, "alpha_value": 0.24025443464061946, "duration": 158.56833863258362, "step": 26625}
{"episode_reward": 833.3809446178464, "episode": 214.0, "Q1 loss": 13.372649307250976, "Q2 loss": 13.329487190246581, "Mean Target Q": 457.661712890625, "Mean Q1": 457.6403552246094, "Mean Q2": 457.6396335449219, "critic_loss": 26.702136459350587, "batch_reward": 4.811573223114014, "actor_loss": -459.0352507560484, "actor_target_entropy": -1.0, "actor_entropy": -0.2303803690498875, "alpha_loss": -0.021964644652701194, "alpha_value": 0.24095597389671236, "duration": 145.3347465991974, "step": 26750}
{"episode_reward": 822.0901076297145, "episode": 215.0, "Q1 loss": 13.889370162963868, "Q2 loss": 13.828552665710449, "Mean Target Q": 459.23779614257813, "Mean Q1": 459.23984350585937, "Mean Q2": 459.241505859375, "critic_loss": 27.717922821044922, "batch_reward": 4.823920772552491, "actor_loss": -461.1767098563058, "actor_target_entropy": -1.0, "actor_entropy": -0.23560113187820192, "alpha_loss": -0.026043265806658875, "alpha_value": 0.24184817906750833, "duration": 174.6609137058258, "step": 26875}
{"episode_reward": 762.0651379147567, "episode": 216.0, "Q1 loss": 13.459777542114258, "Q2 loss": 13.56739440536499, "Mean Target Q": 461.25204052734375, "Mean Q1": 461.24956103515626, "Mean Q2": 461.2521652832031, "critic_loss": 27.027171951293944, "batch_reward": 4.826394332885743, "actor_loss": -463.0202370920489, "actor_target_entropy": -1.0, "actor_entropy": -0.2395907486638715, "alpha_loss": -0.021848456303198493, "alpha_value": 0.24284996553238847, "duration": 151.05764651298523, "step": 27000}
{"episode_reward": 826.5756380307398, "episode": 217.0, "Q1 loss": 14.416769821166993, "Q2 loss": 14.444175903320312, "Mean Target Q": 462.7702648925781, "Mean Q1": 462.76128198242185, "Mean Q2": 462.75876708984373, "critic_loss": 28.860945739746093, "batch_reward": 4.840416805267334, "actor_loss": -464.13300141834077, "actor_target_entropy": -1.0, "actor_entropy": -0.23179208404488033, "alpha_loss": -0.01812510662120841, "alpha_value": 0.2437153598281392, "duration": 137.92822551727295, "step": 27125}
{"episode_reward": 832.1819071412178, "episode": 218.0, "Q1 loss": 13.529892463684082, "Q2 loss": 13.610168281555175, "Mean Target Q": 464.8992548828125, "Mean Q1": 464.90133984375, "Mean Q2": 464.9002580566406, "critic_loss": 27.140060821533204, "batch_reward": 4.858376571655273, "actor_loss": -466.22781519736014, "actor_target_entropy": -1.0, "actor_entropy": -0.2407750143639503, "alpha_loss": -0.019929153690745514, "alpha_value": 0.24441888953324398, "duration": 131.44924211502075, "step": 27250}
{"episode_reward": 838.4017190909693, "episode": 219.0, "Q1 loss": 13.21422476196289, "Q2 loss": 13.079827514648438, "Mean Target Q": 466.1590751953125, "Mean Q1": 466.15461328125, "Mean Q2": 466.156361328125, "critic_loss": 26.29405241394043, "batch_reward": 4.851301658630371, "actor_loss": -467.36534336635043, "actor_target_entropy": -1.0, "actor_entropy": -0.21208215634974223, "alpha_loss": -0.018513668247217698, "alpha_value": 0.24526559849329427, "duration": 108.556387424469, "step": 27375}
{"episode_reward": 832.9650072519737, "episode": 220.0, "Q1 loss": 12.579315902709961, "Q2 loss": 12.345054901123047, "Mean Target Q": 468.03430541992185, "Mean Q1": 468.024533203125, "Mean Q2": 468.02538623046877, "critic_loss": 24.924370735168456, "batch_reward": 4.877616638183594, "actor_loss": -469.3573391822077, "actor_target_entropy": -1.0, "actor_entropy": -0.19483700274459778, "alpha_loss": -0.00598305385116668, "alpha_value": 0.2457701558676821, "duration": 130.62075114250183, "step": 27500}
{"episode_reward": 823.1964436915497, "episode": 221.0, "Q1 loss": 13.177652389526367, "Q2 loss": 13.341751220703125, "Mean Target Q": 469.44781396484376, "Mean Q1": 469.4490698242187, "Mean Q2": 469.4481662597656, "critic_loss": 26.519403755187987, "batch_reward": 4.867601078033447, "actor_loss": -470.3274105011471, "actor_target_entropy": -1.0, "actor_entropy": -0.16983883177477216, "alpha_loss": -0.009528577904261294, "alpha_value": 0.24611651542962315, "duration": 122.82296514511108, "step": 27625}
{"episode_reward": 841.0832203995354, "episode": 222.0, "Q1 loss": 13.008860893249512, "Q2 loss": 13.216108444213868, "Mean Target Q": 470.89425439453123, "Mean Q1": 470.89066381835937, "Mean Q2": 470.89089453125, "critic_loss": 26.22496939086914, "batch_reward": 4.857505268096924, "actor_loss": -472.54249129756806, "actor_target_entropy": -1.0, "actor_entropy": -0.20280090767529704, "alpha_loss": -0.013314588442294589, "alpha_value": 0.24661652308990703, "duration": 130.211975812912, "step": 27750}
{"episode_reward": 825.91741319825, "episode": 223.0, "Q1 loss": 13.073473052978516, "Q2 loss": 12.985704200744628, "Mean Target Q": 473.0692646484375, "Mean Q1": 473.06541259765623, "Mean Q2": 473.0647763671875, "critic_loss": 26.05917724609375, "batch_reward": 4.8989016075134275, "actor_loss": -473.86066158234127, "actor_target_entropy": -1.0, "actor_entropy": -0.21461944755107637, "alpha_loss": -0.003934283031239396, "alpha_value": 0.24701009173864338, "duration": 86.01679468154907, "step": 27875}
{"episode_reward": 844.4154790030374, "episode": 224.0, "Q1 loss": 13.087578979492188, "Q2 loss": 13.192907516479492, "Mean Target Q": 474.80117529296876, "Mean Q1": 474.79059838867187, "Mean Q2": 474.78962060546877, "critic_loss": 26.28048649597168, "batch_reward": 4.909149421691895, "actor_loss": -475.8687202699723, "actor_target_entropy": -1.0, "actor_entropy": -0.20932025270115945, "alpha_loss": -0.013476470331360976, "alpha_value": 0.24740720299847282, "duration": 67.24175071716309, "step": 28000}
{"episode_reward": 826.0431707882659, "episode": 225.0, "Q1 loss": 13.758493186950684, "Q2 loss": 13.815175323486327, "Mean Target Q": 476.22437377929685, "Mean Q1": 476.22062451171877, "Mean Q2": 476.22016259765627, "critic_loss": 27.57366837310791, "batch_reward": 4.9096013374328615, "actor_loss": -477.2006429036458, "actor_target_entropy": -1.0, "actor_entropy": -0.19092010079868257, "alpha_loss": -0.0033181705549063666, "alpha_value": 0.24786536482071203, "duration": 58.112372398376465, "step": 28125}
{"episode_reward": 818.1843790547273, "episode": 226.0, "Q1 loss": 12.837029739379883, "Q2 loss": 13.01224843597412, "Mean Target Q": 477.793560546875, "Mean Q1": 477.7994892578125, "Mean Q2": 477.7986577148437, "critic_loss": 25.84927808380127, "batch_reward": 4.917131313323974, "actor_loss": -479.08045368809854, "actor_target_entropy": -1.0, "actor_entropy": -0.17539601304358052, "alpha_loss": -0.001118238027688236, "alpha_value": 0.24787671711181317, "duration": 84.75072646141052, "step": 28250}
{"episode_reward": 844.5172452848967, "episode": 227.0, "Q1 loss": 13.176350444793702, "Q2 loss": 13.113765544891358, "Mean Target Q": 479.44240161132814, "Mean Q1": 479.43671655273437, "Mean Q2": 479.44218359375, "critic_loss": 26.29011605834961, "batch_reward": 4.923488418579102, "actor_loss": -480.5059596470424, "actor_target_entropy": -1.0, "actor_entropy": -0.1944977989982045, "alpha_loss": -0.006783884373449144, "alpha_value": 0.24812881063871695, "duration": 128.0825183391571, "step": 28375}
{"episode_reward": 842.1543312552213, "episode": 228.0, "Q1 loss": 12.41357649230957, "Q2 loss": 12.337707828521728, "Mean Target Q": 480.6296396484375, "Mean Q1": 480.61701586914063, "Mean Q2": 480.61464453125, "critic_loss": 24.751284233093262, "batch_reward": 4.911331241607666, "actor_loss": -482.02254313807333, "actor_target_entropy": -1.0, "actor_entropy": -0.16521181142137897, "alpha_loss": -0.006144394256895588, "alpha_value": 0.2484697792627196, "duration": 124.4528329372406, "step": 28500}
{"episode_reward": 828.2626515911585, "episode": 229.0, "Q1 loss": 12.903186038970947, "Q2 loss": 12.844756233215332, "Mean Target Q": 482.73483911132814, "Mean Q1": 482.7338193359375, "Mean Q2": 482.73147973632814, "critic_loss": 25.74794219970703, "batch_reward": 4.934165504455566, "actor_loss": -484.19567047603545, "actor_target_entropy": -1.0, "actor_entropy": -0.18130792973060456, "alpha_loss": -0.004974553276533409, "alpha_value": 0.2487104770590203, "duration": 162.17813849449158, "step": 28625}
{"episode_reward": 834.5433988851194, "episode": 230.0, "Q1 loss": 11.977726234436036, "Q2 loss": 12.09152526473999, "Mean Target Q": 484.3678176269531, "Mean Q1": 484.363974609375, "Mean Q2": 484.3672087402344, "critic_loss": 24.069251525878908, "batch_reward": 4.943302124023438, "actor_loss": -485.3275806057838, "actor_target_entropy": -1.0, "actor_entropy": -0.18700193018922884, "alpha_loss": -0.008310542558319867, "alpha_value": 0.2491671642334601, "duration": 140.47938632965088, "step": 28750}
{"episode_reward": 825.2347886358829, "episode": 231.0, "Q1 loss": 12.527579460144043, "Q2 loss": 12.554122997283935, "Mean Target Q": 485.639986328125, "Mean Q1": 485.6375517578125, "Mean Q2": 485.6380502929687, "critic_loss": 25.081702331542967, "batch_reward": 4.947123119354248, "actor_loss": -486.71302335224453, "actor_target_entropy": -1.0, "actor_entropy": -0.1972570280943598, "alpha_loss": -0.0029845304846290556, "alpha_value": 0.24944037931453744, "duration": 130.9459264278412, "step": 28875}
{"episode_reward": 820.5732162305201, "episode": 232.0, "Q1 loss": 11.809263893127442, "Q2 loss": 11.889716312408448, "Mean Target Q": 487.20556909179686, "Mean Q1": 487.1964069824219, "Mean Q2": 487.19294091796877, "critic_loss": 23.698980171203612, "batch_reward": 4.9467264060974125, "actor_loss": -488.6367379465411, "actor_target_entropy": -1.0, "actor_entropy": -0.20297381089579675, "alpha_loss": -0.00880122588076178, "alpha_value": 0.24986248831151495, "duration": 124.7514157295227, "step": 29000}
{"episode_reward": 846.2732885692436, "episode": 233.0, "Q1 loss": 11.67574851989746, "Q2 loss": 11.76161088180542, "Mean Target Q": 488.8875893554688, "Mean Q1": 488.8887431640625, "Mean Q2": 488.89084594726563, "critic_loss": 23.437359367370604, "batch_reward": 4.9664093704223635, "actor_loss": -490.21129644484745, "actor_target_entropy": -1.0, "actor_entropy": -0.17239693540429313, "alpha_loss": -0.0008321769354451033, "alpha_value": 0.2500931997616764, "duration": 158.198974609375, "step": 29125}
{"episode_reward": 842.6703734241986, "episode": 234.0, "Q1 loss": 12.2800890045166, "Q2 loss": 12.272983024597169, "Mean Target Q": 490.60522094726565, "Mean Q1": 490.60400244140624, "Mean Q2": 490.60443212890624, "critic_loss": 24.55307204437256, "batch_reward": 4.976052001953125, "actor_loss": -491.8692444832094, "actor_target_entropy": -1.0, "actor_entropy": -0.16305416900544398, "alpha_loss": -0.000755577111586688, "alpha_value": 0.25022397316340456, "duration": 146.94296765327454, "step": 29250}
{"episode_reward": 836.2569279186142, "episode": 235.0, "Q1 loss": 12.660475685119629, "Q2 loss": 12.767902843475342, "Mean Target Q": 492.33400756835937, "Mean Q1": 492.330271484375, "Mean Q2": 492.3298176269531, "critic_loss": 25.428378646850586, "batch_reward": 5.000447734832764, "actor_loss": -493.7707698761471, "actor_target_entropy": -1.0, "actor_entropy": -0.17485818834531874, "alpha_loss": -0.003067031495332245, "alpha_value": 0.25022588761192016, "duration": 110.59270238876343, "step": 29375}
{"episode_reward": 842.7366306330503, "episode": 236.0, "Q1 loss": 13.462731750488281, "Q2 loss": 13.38179125213623, "Mean Target Q": 493.58203857421876, "Mean Q1": 493.5768034667969, "Mean Q2": 493.5768410644531, "critic_loss": 26.84452293395996, "batch_reward": 4.978513313293457, "actor_loss": -495.0542651760963, "actor_target_entropy": -1.0, "actor_entropy": -0.17554797496526472, "alpha_loss": 0.0013981534265762856, "alpha_value": 0.2503303392650201, "duration": 115.77770209312439, "step": 29500}
{"episode_reward": 840.182274786591, "episode": 237.0, "Q1 loss": 11.701950790405274, "Q2 loss": 11.67182349395752, "Mean Target Q": 495.2006101074219, "Mean Q1": 495.19602221679685, "Mean Q2": 495.1945791015625, "critic_loss": 23.373774223327636, "batch_reward": 4.987130630493164, "actor_loss": -496.06404380192834, "actor_target_entropy": -1.0, "actor_entropy": -0.17220968658488894, "alpha_loss": 0.00019997804396091, "alpha_value": 0.25020678751435116, "duration": 140.61184978485107, "step": 29625}
{"episode_reward": 831.1073554952716, "episode": 238.0, "Q1 loss": 11.635798294067383, "Q2 loss": 11.674384830474853, "Mean Target Q": 496.7773916015625, "Mean Q1": 496.77315307617187, "Mean Q2": 496.7736606445313, "critic_loss": 23.310183166503908, "batch_reward": 4.994571884155273, "actor_loss": -497.7842082362021, "actor_target_entropy": -1.0, "actor_entropy": -0.1606927474419917, "alpha_loss": 0.002452697695022629, "alpha_value": 0.2502361983844549, "duration": 161.66854071617126, "step": 29750}
{"episode_reward": 771.1998417483949, "episode": 239.0, "Q1 loss": 12.73956719970703, "Q2 loss": 12.805019275665284, "Mean Target Q": 498.23858203125, "Mean Q1": 498.2301066894531, "Mean Q2": 498.23258374023436, "critic_loss": 25.54458644104004, "batch_reward": 5.009442054748535, "actor_loss": -499.61712452721974, "actor_target_entropy": -1.0, "actor_entropy": -0.18775942555022618, "alpha_loss": -0.002865201002726006, "alpha_value": 0.2501629102007044, "duration": 123.97969198226929, "step": 29875}
{"episode_reward": 833.8169633801591, "episode": 240.0, "Q1 loss": 12.374979454040528, "Q2 loss": 12.29278050994873, "Mean Target Q": 499.2738505859375, "Mean Q1": 499.27689013671875, "Mean Q2": 499.273263671875, "critic_loss": 24.66775988006592, "batch_reward": 4.992941818237305, "actor_loss": -500.31529432727444, "actor_target_entropy": -1.0, "actor_entropy": -0.13515308511353308, "alpha_loss": 0.0075809219683099895, "alpha_value": 0.24992724205160569, "step": 30000}
{"duration": 159.66179013252258, "step": 30000}
{"episode_reward": 819.0617238356584, "episode": 241.0, "Q1 loss": 11.942607006072999, "Q2 loss": 11.973820804595947, "Mean Target Q": 500.7459450683594, "Mean Q1": 500.744, "Mean Q2": 500.74513720703123, "critic_loss": 23.916427726745606, "batch_reward": 5.0030631256103515, "actor_loss": -501.6563037690662, "actor_target_entropy": -1.0, "actor_entropy": -0.19522259112388368, "alpha_loss": -0.001661642364019321, "alpha_value": 0.24981067806373752, "duration": 161.17594385147095, "step": 30125}
{"episode_reward": 842.4913059529637, "episode": 242.0, "Q1 loss": 13.27978985595703, "Q2 loss": 13.288277069091796, "Mean Target Q": 501.95494409179685, "Mean Q1": 501.93883422851565, "Mean Q2": 501.9378771972656, "critic_loss": 26.56806690979004, "batch_reward": 5.008153743743897, "actor_loss": -503.3024119715537, "actor_target_entropy": -1.0, "actor_entropy": -0.17237375544444208, "alpha_loss": 0.004635520989165431, "alpha_value": 0.24977714347914567, "duration": 136.69804334640503, "step": 30250}
{"episode_reward": 832.6960268192109, "episode": 243.0, "Q1 loss": 11.997831256866455, "Q2 loss": 12.092698493957519, "Mean Target Q": 504.15629956054687, "Mean Q1": 504.16865185546874, "Mean Q2": 504.17007739257815, "critic_loss": 24.09052976989746, "batch_reward": 5.044805725097656, "actor_loss": -504.942625984313, "actor_target_entropy": -1.0, "actor_entropy": -0.1606159599290954, "alpha_loss": 0.002805060856709523, "alpha_value": 0.24947809516921043, "duration": 172.21585369110107, "step": 30375}
{"episode_reward": 838.8022028829937, "episode": 244.0, "Q1 loss": 11.851239978790284, "Q2 loss": 11.887308700561523, "Mean Target Q": 505.73732666015627, "Mean Q1": 505.7289287109375, "Mean Q2": 505.72811376953126, "critic_loss": 23.738548698425294, "batch_reward": 5.05420703125, "actor_loss": -507.07619993148313, "actor_target_entropy": -1.0, "actor_entropy": -0.18666305981816783, "alpha_loss": 0.006480371829257497, "alpha_value": 0.2492138872663872, "duration": 155.9474651813507, "step": 30500}
{"episode_reward": 838.675917133321, "episode": 245.0, "Q1 loss": 11.200810298919677, "Q2 loss": 11.250118194580079, "Mean Target Q": 506.74322534179686, "Mean Q1": 506.73853369140625, "Mean Q2": 506.73933471679686, "critic_loss": 22.450928581237793, "batch_reward": 5.039883937835693, "actor_loss": -507.6770925370474, "actor_target_entropy": -1.0, "actor_entropy": -0.1915216018992757, "alpha_loss": 0.005611805309955444, "alpha_value": 0.24880411299264624, "duration": 147.22115802764893, "step": 30625}
{"episode_reward": 841.2909584377994, "episode": 246.0, "Q1 loss": 11.939256969451904, "Q2 loss": 11.869881233215333, "Mean Target Q": 508.399455078125, "Mean Q1": 508.39360571289063, "Mean Q2": 508.39391870117186, "critic_loss": 23.809138206481933, "batch_reward": 5.061592720031738, "actor_loss": -509.4042269799017, "actor_target_entropy": -1.0, "actor_entropy": -0.1957059867920414, "alpha_loss": 0.0032482526355212733, "alpha_value": 0.24845287393657525, "duration": 126.31015920639038, "step": 30750}
{"episode_reward": 832.8224074641334, "episode": 247.0, "Q1 loss": 11.051691864013671, "Q2 loss": 11.157426174163819, "Mean Target Q": 509.6835681152344, "Mean Q1": 509.6835419921875, "Mean Q2": 509.68320703125, "critic_loss": 22.209118019104004, "batch_reward": 5.0593165550231936, "actor_loss": -510.5851086813306, "actor_target_entropy": -1.0, "actor_entropy": -0.18132302756347354, "alpha_loss": 0.004445549906305377, "alpha_value": 0.2480219914519129, "duration": 175.39108753204346, "step": 30875}
{"episode_reward": 842.7231227324704, "episode": 248.0, "Q1 loss": 11.53725309753418, "Q2 loss": 11.551922290802002, "Mean Target Q": 511.1314919433594, "Mean Q1": 511.1318371582031, "Mean Q2": 511.1292778320313, "critic_loss": 23.089175315856934, "batch_reward": 5.0631618309021, "actor_loss": -512.2589633080268, "actor_target_entropy": -1.0, "actor_entropy": -0.1755062996620132, "alpha_loss": 0.006355906887385514, "alpha_value": 0.24773962146261772, "duration": 167.62376713752747, "step": 31000}
{"episode_reward": 826.8584888171606, "episode": 249.0, "Q1 loss": 12.990773025512695, "Q2 loss": 12.870788948059083, "Mean Target Q": 512.7924133300781, "Mean Q1": 512.7911020507812, "Mean Q2": 512.7920456542969, "critic_loss": 25.861562034606933, "batch_reward": 5.080365322113037, "actor_loss": -514.0353214324467, "actor_target_entropy": -1.0, "actor_entropy": -0.1641293709713315, "alpha_loss": 0.008023985340038226, "alpha_value": 0.24731201420574142, "duration": 147.4773552417755, "step": 31125}
{"episode_reward": 825.7358340252254, "episode": 250.0, "Q1 loss": 12.281314117431641, "Q2 loss": 12.436104522705078, "Mean Target Q": 514.1966740722656, "Mean Q1": 514.1831687011719, "Mean Q2": 514.1828225097656, "critic_loss": 24.717418647766113, "batch_reward": 5.083008190155029, "actor_loss": -514.8785872920866, "actor_target_entropy": -1.0, "actor_entropy": -0.14915105832680578, "alpha_loss": 0.00930822098011812, "alpha_value": 0.24656834006718553, "duration": 162.21874952316284, "step": 31250}
{"episode_reward": 755.3140940955882, "episode": 251.0, "Q1 loss": 11.723483409881592, "Q2 loss": 11.86423973083496, "Mean Target Q": 515.5806591796875, "Mean Q1": 515.5752473144531, "Mean Q2": 515.5773500976562, "critic_loss": 23.587723289489745, "batch_reward": 5.096062698364258, "actor_loss": -516.7031826443142, "actor_target_entropy": -1.0, "actor_entropy": -0.17770618697007498, "alpha_loss": 0.0074208329306057995, "alpha_value": 0.24601529214076884, "duration": 170.57217812538147, "step": 31375}
{"episode_reward": 559.7689519087311, "episode": 252.0, "Q1 loss": 12.938217460632325, "Q2 loss": 13.089159149169921, "Mean Target Q": 516.6346206054687, "Mean Q1": 516.6321491699218, "Mean Q2": 516.62983203125, "critic_loss": 26.027376625061034, "batch_reward": 5.073339904785156, "actor_loss": -518.2399104948967, "actor_target_entropy": -1.0, "actor_entropy": -0.17530068478757335, "alpha_loss": 0.009342911001670385, "alpha_value": 0.24540593794866497, "duration": 144.10007095336914, "step": 31500}
{"episode_reward": 818.6390712016789, "episode": 253.0, "Q1 loss": 12.775456893920898, "Q2 loss": 12.669765380859374, "Mean Target Q": 518.2252934570313, "Mean Q1": 518.2154516601563, "Mean Q2": 518.2184567871094, "critic_loss": 25.44522238922119, "batch_reward": 5.101965240478515, "actor_loss": -519.3490649026538, "actor_target_entropy": -1.0, "actor_entropy": -0.1637065133878163, "alpha_loss": 0.010199314153324517, "alpha_value": 0.24471773289935456, "duration": 171.7622525691986, "step": 31625}
{"episode_reward": 742.7463796693443, "episode": 254.0, "Q1 loss": 12.745637413024902, "Q2 loss": 12.859840744018555, "Mean Target Q": 518.9439711914063, "Mean Q1": 518.9506840820312, "Mean Q2": 518.9497543945313, "critic_loss": 25.60547805786133, "batch_reward": 5.0743499336242675, "actor_loss": -519.9450319351688, "actor_target_entropy": -1.0, "actor_entropy": -0.18175453632589308, "alpha_loss": 0.006537121878336033, "alpha_value": 0.2440355599001353, "duration": 84.03297591209412, "step": 31750}
{"episode_reward": 799.685157439882, "episode": 255.0, "Q1 loss": 12.230747505187988, "Q2 loss": 12.31366827774048, "Mean Target Q": 520.4398901367188, "Mean Q1": 520.4316733398438, "Mean Q2": 520.4291108398437, "critic_loss": 24.544415802001954, "batch_reward": 5.09853120803833, "actor_loss": -521.7486688523065, "actor_target_entropy": -1.0, "actor_entropy": -0.19269508986719072, "alpha_loss": 0.007563451608081186, "alpha_value": 0.24342547679218102, "duration": 144.47528672218323, "step": 31875}
{"episode_reward": 844.062249909797, "episode": 256.0, "Q1 loss": 12.035150749206544, "Q2 loss": 12.066028839111327, "Mean Target Q": 521.9990131835938, "Mean Q1": 521.993681640625, "Mean Q2": 521.9962143554687, "critic_loss": 24.10117965698242, "batch_reward": 5.1156881866455075, "actor_loss": -522.988500779675, "actor_target_entropy": -1.0, "actor_entropy": -0.1773495338857174, "alpha_loss": 0.005165939497190618, "alpha_value": 0.24302045713132506, "duration": 162.61455702781677, "step": 32000}
{"episode_reward": 830.0256509304529, "episode": 257.0, "Q1 loss": 12.962109375, "Q2 loss": 12.920465320587159, "Mean Target Q": 523.3384072265625, "Mean Q1": 523.3394760742187, "Mean Q2": 523.3374296875, "critic_loss": 25.882574577331543, "batch_reward": 5.117531894683838, "actor_loss": -524.3010467044891, "actor_target_entropy": -1.0, "actor_entropy": -0.17200654898844067, "alpha_loss": 0.011419264924904656, "alpha_value": 0.2423788077926051, "duration": 136.4708776473999, "step": 32125}
{"episode_reward": 816.6906303575925, "episode": 258.0, "Q1 loss": 11.300321441650391, "Q2 loss": 11.172619140625, "Mean Target Q": 524.3587690429688, "Mean Q1": 524.3495732421875, "Mean Q2": 524.3515629882812, "critic_loss": 22.472940521240233, "batch_reward": 5.094652767181397, "actor_loss": -525.6209352554813, "actor_target_entropy": -1.0, "actor_entropy": -0.17397892739503615, "alpha_loss": 0.010084319258889845, "alpha_value": 0.24149323097515646, "duration": 157.82574343681335, "step": 32250}
{"episode_reward": 838.4269128560516, "episode": 259.0, "Q1 loss": 12.00703517150879, "Q2 loss": 12.099808708190919, "Mean Target Q": 525.893072265625, "Mean Q1": 525.9005224609375, "Mean Q2": 525.9005341796875, "critic_loss": 24.106843856811523, "batch_reward": 5.110820636749268, "actor_loss": -526.8646937779018, "actor_target_entropy": -1.0, "actor_entropy": -0.1831621178795421, "alpha_loss": 0.012973690449836709, "alpha_value": 0.24085689886443826, "duration": 156.33980083465576, "step": 32375}
{"episode_reward": 733.8419345595047, "episode": 260.0, "Q1 loss": 12.115959243774414, "Q2 loss": 12.221353103637695, "Mean Target Q": 527.1910859375, "Mean Q1": 527.184, "Mean Q2": 527.1833466796875, "critic_loss": 24.337312286376953, "batch_reward": 5.125045551300049, "actor_loss": -528.5557162377143, "actor_target_entropy": -1.0, "actor_entropy": -0.1942833762976431, "alpha_loss": 0.008508619270287454, "alpha_value": 0.2398901439409983, "duration": 163.88324856758118, "step": 32500}
{"episode_reward": 845.4616414288986, "episode": 261.0, "Q1 loss": 12.694103610992432, "Q2 loss": 12.863414855957032, "Mean Target Q": 528.815447265625, "Mean Q1": 528.8076708984376, "Mean Q2": 528.808728515625, "critic_loss": 25.557518424987794, "batch_reward": 5.14077530670166, "actor_loss": -530.0361047169519, "actor_target_entropy": -1.0, "actor_entropy": -0.17836893633717582, "alpha_loss": 0.01168497269677501, "alpha_value": 0.239031351841901, "duration": 117.87805509567261, "step": 32625}
{"episode_reward": 837.2825966079841, "episode": 262.0, "Q1 loss": 14.307192161560058, "Q2 loss": 14.443508403778075, "Mean Target Q": 529.8907260742187, "Mean Q1": 529.8792250976562, "Mean Q2": 529.8789223632813, "critic_loss": 28.750700653076173, "batch_reward": 5.126354946136475, "actor_loss": -530.8361324187248, "actor_target_entropy": -1.0, "actor_entropy": -0.22971782905440177, "alpha_loss": 0.0015134203657057256, "alpha_value": 0.23872152081912698, "duration": 153.89183950424194, "step": 32750}
{"episode_reward": 762.9280634829346, "episode": 263.0, "Q1 loss": 12.070447399139404, "Q2 loss": 11.931103382110596, "Mean Target Q": 530.9431821289063, "Mean Q1": 530.95524609375, "Mean Q2": 530.9527436523438, "critic_loss": 24.00155081939697, "batch_reward": 5.140785923004151, "actor_loss": -532.0489986359127, "actor_target_entropy": -1.0, "actor_entropy": -0.21361014696340713, "alpha_loss": 0.0035633178509121375, "alpha_value": 0.23844472909763792, "duration": 161.11547017097473, "step": 32875}
{"episode_reward": 826.2957479407759, "episode": 264.0, "Q1 loss": 11.394409030914307, "Q2 loss": 11.422228588104248, "Mean Target Q": 532.025501953125, "Mean Q1": 532.0160239257813, "Mean Q2": 532.019240234375, "critic_loss": 22.816637657165526, "batch_reward": 5.133394672393798, "actor_loss": -532.8744329637096, "actor_target_entropy": -1.0, "actor_entropy": -0.20959906832825753, "alpha_loss": 0.0017136019924955984, "alpha_value": 0.2382231599243173, "duration": 159.82626605033875, "step": 33000}
{"episode_reward": 839.6337144238528, "episode": 265.0, "Q1 loss": 11.358149906158447, "Q2 loss": 11.299534370422363, "Mean Target Q": 533.3458935546874, "Mean Q1": 533.3433637695313, "Mean Q2": 533.3400825195313, "critic_loss": 22.657684280395507, "batch_reward": 5.143795223236084, "actor_loss": -534.3178168402778, "actor_target_entropy": -1.0, "actor_entropy": -0.20511194921675183, "alpha_loss": 0.004937064547520426, "alpha_value": 0.23805216695603676, "duration": 159.88456535339355, "step": 33125}
{"episode_reward": 820.5714410609046, "episode": 266.0, "Q1 loss": 10.954117557525635, "Q2 loss": 10.902475601196288, "Mean Target Q": 534.8648403320312, "Mean Q1": 534.8608139648437, "Mean Q2": 534.863072265625, "critic_loss": 21.856593154907227, "batch_reward": 5.155361595153809, "actor_loss": -535.9070916944935, "actor_target_entropy": -1.0, "actor_entropy": -0.19642473757266998, "alpha_loss": 0.008068761292604669, "alpha_value": 0.23759262715576182, "duration": 85.8292281627655, "step": 33250}
{"episode_reward": 839.5611375518156, "episode": 267.0, "Q1 loss": 11.504322250366211, "Q2 loss": 11.51324306488037, "Mean Target Q": 535.597025390625, "Mean Q1": 535.5910053710937, "Mean Q2": 535.59454296875, "critic_loss": 23.017565437316893, "batch_reward": 5.134367683410645, "actor_loss": -536.5089992947048, "actor_target_entropy": -1.0, "actor_entropy": -0.2216040249618273, "alpha_loss": 0.0028446871539696103, "alpha_value": 0.23697718354897826, "duration": 159.72514843940735, "step": 33375}
{"episode_reward": 836.7410037851917, "episode": 268.0, "Q1 loss": 11.177619144439698, "Q2 loss": 11.16260544204712, "Mean Target Q": 537.07341015625, "Mean Q1": 537.0687407226562, "Mean Q2": 537.0637299804688, "critic_loss": 22.340224571228028, "batch_reward": 5.163891075134277, "actor_loss": -538.1425928915701, "actor_target_entropy": -1.0, "actor_entropy": -0.21155693970860973, "alpha_loss": 0.0035052844773857824, "alpha_value": 0.236834213843824, "duration": 182.70284581184387, "step": 33500}
{"episode_reward": 844.7960218749073, "episode": 269.0, "Q1 loss": 11.005286392211914, "Q2 loss": 11.117989261627198, "Mean Target Q": 538.4343403320313, "Mean Q1": 538.443916015625, "Mean Q2": 538.4426162109374, "critic_loss": 22.123275718688966, "batch_reward": 5.17106689453125, "actor_loss": -539.2923884316097, "actor_target_entropy": -1.0, "actor_entropy": -0.2210319965841278, "alpha_loss": 0.0031440985566448597, "alpha_value": 0.2365403645585456, "duration": 161.24007725715637, "step": 33625}
{"episode_reward": 830.4724723001673, "episode": 270.0, "Q1 loss": 11.078376300811767, "Q2 loss": 11.211750167846679, "Mean Target Q": 539.9292138671875, "Mean Q1": 539.9193481445312, "Mean Q2": 539.9194301757813, "critic_loss": 22.290126472473144, "batch_reward": 5.17779517364502, "actor_loss": -540.9851920835433, "actor_target_entropy": -1.0, "actor_entropy": -0.20996251618189196, "alpha_loss": 0.004815564841978372, "alpha_value": 0.23624122057674027, "duration": 144.08701729774475, "step": 33750}
{"episode_reward": 834.3215709299748, "episode": 271.0, "Q1 loss": 11.122426513671876, "Q2 loss": 11.214932231903076, "Mean Target Q": 541.141767578125, "Mean Q1": 541.1333520507812, "Mean Q2": 541.1346245117187, "critic_loss": 22.337358711242675, "batch_reward": 5.188103973388672, "actor_loss": -542.1310182601686, "actor_target_entropy": -1.0, "actor_entropy": -0.19466804086215914, "alpha_loss": 0.006276259074978057, "alpha_value": 0.23575518027874037, "duration": 162.94738841056824, "step": 33875}
{"episode_reward": 844.0482643639087, "episode": 272.0, "Q1 loss": 10.528540672302245, "Q2 loss": 10.567599098205566, "Mean Target Q": 542.3361533203125, "Mean Q1": 542.3380634765625, "Mean Q2": 542.3401889648437, "critic_loss": 21.096139778137207, "batch_reward": 5.190070655822754, "actor_loss": -543.1093730311239, "actor_target_entropy": -1.0, "actor_entropy": -0.17066553932043813, "alpha_loss": 0.01018822250226813, "alpha_value": 0.23508782986121826, "duration": 128.69998908042908, "step": 34000}
{"episode_reward": 744.9687888586412, "episode": 273.0, "Q1 loss": 11.091823631286621, "Q2 loss": 10.930417129516602, "Mean Target Q": 543.693361328125, "Mean Q1": 543.6940146484375, "Mean Q2": 543.6912734375, "critic_loss": 22.022240730285645, "batch_reward": 5.194260536193847, "actor_loss": -545.0224057152158, "actor_target_entropy": -1.0, "actor_entropy": -0.20532730884022182, "alpha_loss": 0.009532554193385064, "alpha_value": 0.23432560863147842, "duration": 123.54075932502747, "step": 34125}
{"episode_reward": 828.3786315925843, "episode": 274.0, "Q1 loss": 11.026026111602784, "Q2 loss": 10.92932551574707, "Mean Target Q": 544.9118583984375, "Mean Q1": 544.90140234375, "Mean Q2": 544.9052436523438, "critic_loss": 21.9553516998291, "batch_reward": 5.207930953979492, "actor_loss": -545.9296392625378, "actor_target_entropy": -1.0, "actor_entropy": -0.2000309097911081, "alpha_loss": 0.009782072780052982, "alpha_value": 0.23351982874853974, "duration": 166.39429378509521, "step": 34250}
{"episode_reward": 839.0978641810227, "episode": 275.0, "Q1 loss": 11.626506496429444, "Q2 loss": 11.816813789367675, "Mean Target Q": 546.0702280273438, "Mean Q1": 546.0679663085938, "Mean Q2": 546.06621875, "critic_loss": 23.44332025909424, "batch_reward": 5.214971240997315, "actor_loss": -547.1973547557044, "actor_target_entropy": -1.0, "actor_entropy": -0.19407247917519677, "alpha_loss": 0.012345926104379552, "alpha_value": 0.23251119225793948, "duration": 150.84832906723022, "step": 34375}
{"episode_reward": 826.3989605367193, "episode": 276.0, "Q1 loss": 11.929750953674317, "Q2 loss": 11.774857936859132, "Mean Target Q": 547.0268295898437, "Mean Q1": 547.0253383789062, "Mean Q2": 547.0279165039062, "critic_loss": 23.70460880279541, "batch_reward": 5.220406467437744, "actor_loss": -547.9532884167087, "actor_target_entropy": -1.0, "actor_entropy": -0.21181584438008647, "alpha_loss": 0.004707997075221952, "alpha_value": 0.231939519059342, "duration": 173.08603072166443, "step": 34500}
{"episode_reward": 837.6714774244463, "episode": 277.0, "Q1 loss": 11.169627578735351, "Q2 loss": 11.22366881942749, "Mean Target Q": 548.7103813476563, "Mean Q1": 548.7023364257813, "Mean Q2": 548.701470703125, "critic_loss": 22.39329640197754, "batch_reward": 5.244049530029297, "actor_loss": -549.9670642671131, "actor_target_entropy": -1.0, "actor_entropy": -0.22505901966776168, "alpha_loss": 0.007305051922605979, "alpha_value": 0.2314210158901355, "duration": 159.56448554992676, "step": 34625}
{"episode_reward": 828.2138944227432, "episode": 278.0, "Q1 loss": 12.012685424804687, "Q2 loss": 11.915571918487549, "Mean Target Q": 549.6846372070313, "Mean Q1": 549.6885751953125, "Mean Q2": 549.6876796875, "critic_loss": 23.92825745391846, "batch_reward": 5.231530387878418, "actor_loss": -550.818352483934, "actor_target_entropy": -1.0, "actor_entropy": -0.21925937816981347, "alpha_loss": 0.009899597738929573, "alpha_value": 0.23069167816955935, "duration": 125.0381908416748, "step": 34750}
{"episode_reward": 840.567774982686, "episode": 279.0, "Q1 loss": 11.20944979095459, "Q2 loss": 11.249791431427003, "Mean Target Q": 550.6430014648438, "Mean Q1": 550.6411225585938, "Mean Q2": 550.638435546875, "critic_loss": 22.459241119384764, "batch_reward": 5.220878280639648, "actor_loss": -551.4603474934896, "actor_target_entropy": -1.0, "actor_entropy": -0.20600914482086424, "alpha_loss": 0.004098265601824674, "alpha_value": 0.2302189963785824, "duration": 146.5816366672516, "step": 34875}
{"episode_reward": 834.2369231480251, "episode": 280.0, "Q1 loss": 11.645769939422607, "Q2 loss": 11.54927872467041, "Mean Target Q": 551.87014453125, "Mean Q1": 551.86706640625, "Mean Q2": 551.870275390625, "critic_loss": 23.19504862976074, "batch_reward": 5.230370574951172, "actor_loss": -553.0110906785534, "actor_target_entropy": -1.0, "actor_entropy": -0.20733740973857143, "alpha_loss": 0.006828167993995932, "alpha_value": 0.229717828124641, "step": 35000}
{"duration": 175.73914194107056, "step": 35000}
{"episode_reward": 839.5641025181708, "episode": 281.0, "Q1 loss": 11.322560356140137, "Q2 loss": 11.450269695281982, "Mean Target Q": 553.0741171875, "Mean Q1": 553.0657387695312, "Mean Q2": 553.0646938476563, "critic_loss": 22.772830017089845, "batch_reward": 5.246651401519776, "actor_loss": -554.2696930416047, "actor_target_entropy": -1.0, "actor_entropy": -0.20724013920814272, "alpha_loss": 0.012604403616269194, "alpha_value": 0.2288762248624328, "duration": 152.27114081382751, "step": 35125}
{"episode_reward": 770.3304742525694, "episode": 282.0, "Q1 loss": 12.562998958587647, "Q2 loss": 12.567070156097412, "Mean Target Q": 553.9398813476563, "Mean Q1": 553.9381879882812, "Mean Q2": 553.9335971679687, "critic_loss": 25.13006911468506, "batch_reward": 5.226944061279297, "actor_loss": -554.9147023847027, "actor_target_entropy": -1.0, "actor_entropy": -0.22776859361798532, "alpha_loss": -0.0019149048509256494, "alpha_value": 0.22850725941585173, "duration": 137.56391048431396, "step": 35250}
{"episode_reward": 802.7308586802171, "episode": 283.0, "Q1 loss": 11.502877346038819, "Q2 loss": 11.51330029296875, "Mean Target Q": 555.0499272460937, "Mean Q1": 555.046708984375, "Mean Q2": 555.0504985351563, "critic_loss": 23.01617765045166, "batch_reward": 5.23825313949585, "actor_loss": -555.857179671999, "actor_target_entropy": -1.0, "actor_entropy": -0.22556634270955647, "alpha_loss": 0.012518038186022923, "alpha_value": 0.22814655492797611, "duration": 156.88094568252563, "step": 35375}
{"episode_reward": 835.9221140614271, "episode": 284.0, "Q1 loss": 10.435719318389893, "Q2 loss": 10.327227157592773, "Mean Target Q": 556.2801875, "Mean Q1": 556.2785219726562, "Mean Q2": 556.2786806640624, "critic_loss": 20.762946441650392, "batch_reward": 5.257577255249023, "actor_loss": -557.4403489635837, "actor_target_entropy": -1.0, "actor_entropy": -0.18871614605849307, "alpha_loss": 0.01249070257331515, "alpha_value": 0.2270323207862405, "duration": 173.4323000907898, "step": 35500}
{"episode_reward": 836.2798498014106, "episode": 285.0, "Q1 loss": 12.211920566558838, "Q2 loss": 12.384384006500245, "Mean Target Q": 557.1262504882812, "Mean Q1": 557.1226528320312, "Mean Q2": 557.1220288085938, "critic_loss": 24.596304580688475, "batch_reward": 5.23092043685913, "actor_loss": -558.1926686120412, "actor_target_entropy": -1.0, "actor_entropy": -0.16708687929406998, "alpha_loss": 0.013039614184803906, "alpha_value": 0.2259981934832616, "duration": 164.67810940742493, "step": 35625}
{"episode_reward": 822.8674593736631, "episode": 286.0, "Q1 loss": 11.36920594406128, "Q2 loss": 11.352016769409179, "Mean Target Q": 558.9657749023437, "Mean Q1": 558.9594165039063, "Mean Q2": 558.9615795898437, "critic_loss": 22.72122274017334, "batch_reward": 5.264188331604004, "actor_loss": -560.0542533628402, "actor_target_entropy": -1.0, "actor_entropy": -0.20223925647235685, "alpha_loss": 0.010393901929003937, "alpha_value": 0.22503893459614918, "duration": 170.35640144348145, "step": 35750}
{"episode_reward": 829.4401706755908, "episode": 287.0, "Q1 loss": 11.245089626312256, "Q2 loss": 11.381263668060303, "Mean Target Q": 559.4815439453125, "Mean Q1": 559.4812641601562, "Mean Q2": 559.47981640625, "critic_loss": 22.626353317260744, "batch_reward": 5.243374271392822, "actor_loss": -560.6028684585814, "actor_target_entropy": -1.0, "actor_entropy": -0.19945268403916133, "alpha_loss": 0.010999983908342463, "alpha_value": 0.2242644396128201, "duration": 133.74459624290466, "step": 35875}
{"episode_reward": 803.5314420030948, "episode": 288.0, "Q1 loss": 12.34187714767456, "Q2 loss": 12.089480060577392, "Mean Target Q": 560.8092495117188, "Mean Q1": 560.801423828125, "Mean Q2": 560.8005795898438, "critic_loss": 24.43135717010498, "batch_reward": 5.2590271110534665, "actor_loss": -562.0372560562625, "actor_target_entropy": -1.0, "actor_entropy": -0.16124013060283277, "alpha_loss": 0.01568919745078611, "alpha_value": 0.22329003283895413, "duration": 145.84375286102295, "step": 36000}
{"episode_reward": 766.4923853127377, "episode": 289.0, "Q1 loss": 12.343976154327393, "Q2 loss": 12.405580375671386, "Mean Target Q": 562.1158237304687, "Mean Q1": 562.1144477539062, "Mean Q2": 562.1180439453125, "critic_loss": 24.74955651092529, "batch_reward": 5.2735021171569825, "actor_loss": -563.0377759176587, "actor_target_entropy": -1.0, "actor_entropy": -0.1817353716681874, "alpha_loss": 0.011828927918233804, "alpha_value": 0.2222315469082115, "duration": 162.194354057312, "step": 36125}
{"episode_reward": 843.077762873201, "episode": 290.0, "Q1 loss": 10.853340785980224, "Q2 loss": 10.939881496429443, "Mean Target Q": 562.8682158203125, "Mean Q1": 562.870130859375, "Mean Q2": 562.8683334960938, "critic_loss": 21.793222267150878, "batch_reward": 5.264408946990967, "actor_loss": -563.7756032636089, "actor_target_entropy": -1.0, "actor_entropy": -0.21101968711422336, "alpha_loss": 0.008990797150369373, "alpha_value": 0.22135990719893373, "duration": 128.2380108833313, "step": 36250}
{"episode_reward": 805.3777457730691, "episode": 291.0, "Q1 loss": 11.047231090545655, "Q2 loss": 10.93073596572876, "Mean Target Q": 564.6056572265625, "Mean Q1": 564.5992607421875, "Mean Q2": 564.598017578125, "critic_loss": 21.977966972351073, "batch_reward": 5.299426830291748, "actor_loss": -565.557624937996, "actor_target_entropy": -1.0, "actor_entropy": -0.2344662830943153, "alpha_loss": 0.007592876539713452, "alpha_value": 0.22070853906517188, "duration": 166.569007396698, "step": 36375}
{"episode_reward": 835.6504218226082, "episode": 292.0, "Q1 loss": 11.217794212341309, "Q2 loss": 11.093406833648682, "Mean Target Q": 565.5234047851562, "Mean Q1": 565.5333969726563, "Mean Q2": 565.5317661132813, "critic_loss": 22.31120101928711, "batch_reward": 5.29031379699707, "actor_loss": -566.6309164724042, "actor_target_entropy": -1.0, "actor_entropy": -0.21930232848371228, "alpha_loss": 0.013721955523285414, "alpha_value": 0.21996043649117145, "duration": 162.0693211555481, "step": 36500}
{"episode_reward": 758.0486290176735, "episode": 293.0, "Q1 loss": 11.024533264160157, "Q2 loss": 11.059152130126954, "Mean Target Q": 566.338390625, "Mean Q1": 566.3238803710938, "Mean Q2": 566.327673828125, "critic_loss": 22.0836852645874, "batch_reward": 5.286772304534912, "actor_loss": -567.1964130704365, "actor_target_entropy": -1.0, "actor_entropy": -0.21381063759326935, "alpha_loss": 0.01027425982072831, "alpha_value": 0.21895341120267076, "duration": 163.6716115474701, "step": 36625}
{"episode_reward": 836.7144301583533, "episode": 294.0, "Q1 loss": 12.085662994384766, "Q2 loss": 12.103906051635743, "Mean Target Q": 567.7713803710938, "Mean Q1": 567.7676782226563, "Mean Q2": 567.765322265625, "critic_loss": 24.18956909942627, "batch_reward": 5.309690135955811, "actor_loss": -568.7622365643902, "actor_target_entropy": -1.0, "actor_entropy": -0.1913656538292285, "alpha_loss": 0.012807297462131828, "alpha_value": 0.21814986714126838, "duration": 159.23606157302856, "step": 36750}
{"episode_reward": 756.1520584776486, "episode": 295.0, "Q1 loss": 10.650956535339356, "Q2 loss": 10.831669540405274, "Mean Target Q": 568.4080078125, "Mean Q1": 568.4046254882812, "Mean Q2": 568.4038129882813, "critic_loss": 21.482626022338867, "batch_reward": 5.284996723175049, "actor_loss": -569.2774357871403, "actor_target_entropy": -1.0, "actor_entropy": -0.23897611101468405, "alpha_loss": 0.006834788660016206, "alpha_value": 0.21748651161450944, "duration": 158.8450849056244, "step": 36875}
{"episode_reward": 841.6834990168855, "episode": 296.0, "Q1 loss": 11.883645111083984, "Q2 loss": 11.895184257507324, "Mean Target Q": 569.314330078125, "Mean Q1": 569.3119125976563, "Mean Q2": 569.3117495117187, "critic_loss": 23.778829261779784, "batch_reward": 5.295662536621093, "actor_loss": -570.5054774130545, "actor_target_entropy": -1.0, "actor_entropy": -0.21496170807269313, "alpha_loss": 0.007563993370445866, "alpha_value": 0.2168353384324943, "duration": 135.35916590690613, "step": 37000}
{"episode_reward": 836.6588117274607, "episode": 297.0, "Q1 loss": 12.629147094726562, "Q2 loss": 12.63911601638794, "Mean Target Q": 570.2932451171876, "Mean Q1": 570.2879926757812, "Mean Q2": 570.2879877929688, "critic_loss": 25.26826309967041, "batch_reward": 5.296596370697022, "actor_loss": -570.9727976965526, "actor_target_entropy": -1.0, "actor_entropy": -0.212852262315296, "alpha_loss": 0.009547426405968883, "alpha_value": 0.21614313835117088, "duration": 168.2273027896881, "step": 37125}
{"episode_reward": 839.4091433780549, "episode": 298.0, "Q1 loss": 11.928780540466308, "Q2 loss": 12.030956428527832, "Mean Target Q": 571.2048061523437, "Mean Q1": 571.2071538085937, "Mean Q2": 571.208998046875, "critic_loss": 23.959736907958984, "batch_reward": 5.300466564178467, "actor_loss": -571.8987456290953, "actor_target_entropy": -1.0, "actor_entropy": -0.21273902659454652, "alpha_loss": 0.007009412747837843, "alpha_value": 0.21549224179456, "duration": 148.26711773872375, "step": 37250}
{"episode_reward": 827.1921084303387, "episode": 299.0, "Q1 loss": 10.62526655960083, "Q2 loss": 10.732660652160645, "Mean Target Q": 572.5410551757813, "Mean Q1": 572.5272231445313, "Mean Q2": 572.527091796875, "critic_loss": 21.357927223205568, "batch_reward": 5.312195995330811, "actor_loss": -573.4597381107391, "actor_target_entropy": -1.0, "actor_entropy": -0.241728399362829, "alpha_loss": 0.012447784529141491, "alpha_value": 0.21474265269521495, "duration": 159.20527696609497, "step": 37375}
{"episode_reward": 819.8908044302367, "episode": 300.0, "Q1 loss": 11.681595260620117, "Q2 loss": 11.513909713745118, "Mean Target Q": 573.3524350585938, "Mean Q1": 573.356591796875, "Mean Q2": 573.355310546875, "critic_loss": 23.195504974365235, "batch_reward": 5.31354744720459, "actor_loss": -574.0357675860005, "actor_target_entropy": -1.0, "actor_entropy": -0.18422889865694508, "alpha_loss": 0.01166133425431326, "alpha_value": 0.21395069599647437, "duration": 165.43211770057678, "step": 37500}
{"episode_reward": 831.9318763289809, "episode": 301.0, "Q1 loss": 11.583991024017333, "Q2 loss": 11.654977069854736, "Mean Target Q": 574.2501474609375, "Mean Q1": 574.24378125, "Mean Q2": 574.2450170898437, "critic_loss": 23.23896800994873, "batch_reward": 5.316441829681397, "actor_loss": -575.0824362134176, "actor_target_entropy": -1.0, "actor_entropy": -0.2052309394828857, "alpha_loss": 0.01045002168901856, "alpha_value": 0.21305734201375845, "duration": 172.4797613620758, "step": 37625}
{"episode_reward": 813.6673996187137, "episode": 302.0, "Q1 loss": 10.866010875701905, "Q2 loss": 10.846273532867432, "Mean Target Q": 575.4422905273437, "Mean Q1": 575.4375004882812, "Mean Q2": 575.4369106445313, "critic_loss": 21.712284446716307, "batch_reward": 5.329897312164307, "actor_loss": -576.1857614824848, "actor_target_entropy": -1.0, "actor_entropy": -0.18669103386421357, "alpha_loss": 0.009291203726353425, "alpha_value": 0.21238020938142216, "duration": 150.2945101261139, "step": 37750}
{"episode_reward": 831.5376611535761, "episode": 303.0, "Q1 loss": 10.8185802192688, "Q2 loss": 10.722772743225098, "Mean Target Q": 576.2826147460937, "Mean Q1": 576.2851088867187, "Mean Q2": 576.2840893554687, "critic_loss": 21.541352920532226, "batch_reward": 5.323377952575684, "actor_loss": -576.9943343874008, "actor_target_entropy": -1.0, "actor_entropy": -0.21935753240471795, "alpha_loss": 0.005544105346965056, "alpha_value": 0.21181818470836, "duration": 124.30303406715393, "step": 37875}
{"episode_reward": 836.614960293666, "episode": 304.0, "Q1 loss": 10.73413328552246, "Q2 loss": 10.690339920043945, "Mean Target Q": 577.4126416015625, "Mean Q1": 577.4055361328125, "Mean Q2": 577.4065390625, "critic_loss": 21.424473182678224, "batch_reward": 5.336683860778809, "actor_loss": -578.5087004630797, "actor_target_entropy": -1.0, "actor_entropy": -0.20907083249861194, "alpha_loss": 0.012283901113175576, "alpha_value": 0.21116158447778605, "duration": 142.09403491020203, "step": 38000}
{"episode_reward": 843.2952029110805, "episode": 305.0, "Q1 loss": 10.796896766662597, "Q2 loss": 10.675239139556885, "Mean Target Q": 578.7496215820313, "Mean Q1": 578.7552543945312, "Mean Q2": 578.755271484375, "critic_loss": 21.472135871887208, "batch_reward": 5.344392700195312, "actor_loss": -579.4989885602679, "actor_target_entropy": -1.0, "actor_entropy": -0.2242704215976927, "alpha_loss": 0.005937941505440644, "alpha_value": 0.21046001265020353, "duration": 163.34181022644043, "step": 38125}
{"episode_reward": 841.6380391905533, "episode": 306.0, "Q1 loss": 10.770503467559815, "Q2 loss": 10.819712791442871, "Mean Target Q": 579.6364736328125, "Mean Q1": 579.6297602539063, "Mean Q2": 579.6305786132813, "critic_loss": 21.590216163635255, "batch_reward": 5.34378496170044, "actor_loss": -581.0203926332536, "actor_target_entropy": -1.0, "actor_entropy": -0.22216173597881872, "alpha_loss": 0.01247105531905207, "alpha_value": 0.20974225927155238, "duration": 144.29760575294495, "step": 38250}
{"episode_reward": 837.0684726161516, "episode": 307.0, "Q1 loss": 15.239082187652588, "Q2 loss": 14.960274654388428, "Mean Target Q": 580.374107421875, "Mean Q1": 580.3686904296875, "Mean Q2": 580.3699487304688, "critic_loss": 30.199356857299804, "batch_reward": 5.360437309265136, "actor_loss": -581.0252268957713, "actor_target_entropy": -1.0, "actor_entropy": -0.1983466757431863, "alpha_loss": 0.01511459209631005, "alpha_value": 0.20867795075462256, "duration": 121.74294900894165, "step": 38375}
{"episode_reward": 824.5872995954479, "episode": 308.0, "Q1 loss": 11.500493663787841, "Q2 loss": 11.558494621276855, "Mean Target Q": 581.4641723632812, "Mean Q1": 581.4617905273437, "Mean Q2": 581.460833984375, "critic_loss": 23.05898836517334, "batch_reward": 5.356783557891846, "actor_loss": -582.51462382655, "actor_target_entropy": -1.0, "actor_entropy": -0.22361221284635605, "alpha_loss": 0.008911226151300775, "alpha_value": 0.2077401655976154, "duration": 143.22020936012268, "step": 38500}
{"episode_reward": 803.6896407688406, "episode": 309.0, "Q1 loss": 10.446993492126465, "Q2 loss": 10.281968101501464, "Mean Target Q": 582.1847915039062, "Mean Q1": 582.184474609375, "Mean Q2": 582.1858442382812, "critic_loss": 20.728961616516113, "batch_reward": 5.343333122253418, "actor_loss": -582.8996649848091, "actor_target_entropy": -1.0, "actor_entropy": -0.22036324323169768, "alpha_loss": 0.010889173485338688, "alpha_value": 0.2070551975538787, "duration": 134.35074186325073, "step": 38625}
{"episode_reward": 813.7617729651222, "episode": 310.0, "Q1 loss": 11.033710193634032, "Q2 loss": 10.928108310699463, "Mean Target Q": 583.090138671875, "Mean Q1": 583.0831284179687, "Mean Q2": 583.0803891601563, "critic_loss": 21.961818534851073, "batch_reward": 5.334579696655274, "actor_loss": -583.8473304010207, "actor_target_entropy": -1.0, "actor_entropy": -0.19976627346008055, "alpha_loss": 0.012412309319892477, "alpha_value": 0.2062108936480718, "duration": 135.4405300617218, "step": 38750}
{"episode_reward": 828.8657125766305, "episode": 311.0, "Q1 loss": 10.685342761993407, "Q2 loss": 10.707321231842041, "Mean Target Q": 584.2132177734375, "Mean Q1": 584.208482421875, "Mean Q2": 584.208490234375, "critic_loss": 21.39266404724121, "batch_reward": 5.3564524078369145, "actor_loss": -585.093244280134, "actor_target_entropy": -1.0, "actor_entropy": -0.2355600463019477, "alpha_loss": 0.007190146812400411, "alpha_value": 0.2054862379950499, "duration": 135.03402876853943, "step": 38875}
{"episode_reward": 829.5553544700718, "episode": 312.0, "Q1 loss": 11.183099464416504, "Q2 loss": 11.166736961364746, "Mean Target Q": 585.0424013671875, "Mean Q1": 585.04387109375, "Mean Q2": 585.0430380859375, "critic_loss": 22.349836402893068, "batch_reward": 5.349854560852051, "actor_loss": -585.9123850176411, "actor_target_entropy": -1.0, "actor_entropy": -0.22821385269203492, "alpha_loss": 0.010197090191556322, "alpha_value": 0.20475243359297937, "duration": 178.6890411376953, "step": 39000}
{"episode_reward": 830.5189483137617, "episode": 313.0, "Q1 loss": 10.047864994049073, "Q2 loss": 10.067528297424316, "Mean Target Q": 586.3882783203125, "Mean Q1": 586.3805048828125, "Mean Q2": 586.3834555664063, "critic_loss": 20.115393264770507, "batch_reward": 5.379498840332031, "actor_loss": -587.1303090897817, "actor_target_entropy": -1.0, "actor_entropy": -0.21167762471096857, "alpha_loss": 0.008121199562169966, "alpha_value": 0.2040804481710092, "duration": 156.83294081687927, "step": 39125}
{"episode_reward": 840.3197084889895, "episode": 314.0, "Q1 loss": 9.82711005783081, "Q2 loss": 9.722040718078613, "Mean Target Q": 587.3146362304688, "Mean Q1": 587.3179091796875, "Mean Q2": 587.3179775390626, "critic_loss": 19.549150787353515, "batch_reward": 5.378985004425049, "actor_loss": -588.3360733524446, "actor_target_entropy": -1.0, "actor_entropy": -0.24759715507107397, "alpha_loss": 0.004025754982590555, "alpha_value": 0.20380824246975987, "duration": 170.00406312942505, "step": 39250}
{"episode_reward": 827.8603589204731, "episode": 315.0, "Q1 loss": 9.796811450958252, "Q2 loss": 9.735569160461425, "Mean Target Q": 588.2032280273437, "Mean Q1": 588.2053051757813, "Mean Q2": 588.2038208007813, "critic_loss": 19.53238060760498, "batch_reward": 5.374422420501709, "actor_loss": -589.1333715045263, "actor_target_entropy": -1.0, "actor_entropy": -0.24869731967411343, "alpha_loss": 0.003232914010166294, "alpha_value": 0.20344745011670917, "duration": 133.46379399299622, "step": 39375}
{"episode_reward": 840.8295607844301, "episode": 316.0, "Q1 loss": 10.047296630859375, "Q2 loss": 10.044801681518555, "Mean Target Q": 589.489775390625, "Mean Q1": 589.4779765625, "Mean Q2": 589.4775478515625, "critic_loss": 20.092098289489748, "batch_reward": 5.391740169525146, "actor_loss": -590.0450577274446, "actor_target_entropy": -1.0, "actor_entropy": -0.20652220566426555, "alpha_loss": 0.010614367581212954, "alpha_value": 0.20284390602669605, "duration": 177.57858848571777, "step": 39500}
{"episode_reward": 843.0577203226878, "episode": 317.0, "Q1 loss": 10.059492454528808, "Q2 loss": 10.221854057312012, "Mean Target Q": 590.2847407226562, "Mean Q1": 590.2875029296875, "Mean Q2": 590.2890361328125, "critic_loss": 20.28134649658203, "batch_reward": 5.3838863258361815, "actor_loss": -591.2430536179315, "actor_target_entropy": -1.0, "actor_entropy": -0.2412210532597133, "alpha_loss": 0.0033732163645918407, "alpha_value": 0.2024216794126024, "duration": 168.67833614349365, "step": 39625}
{"episode_reward": 822.8521390520264, "episode": 318.0, "Q1 loss": 9.738630374908448, "Q2 loss": 9.71523783493042, "Mean Target Q": 591.04687109375, "Mean Q1": 591.0462680664062, "Mean Q2": 591.0448178710938, "critic_loss": 19.453868240356446, "batch_reward": 5.402608257293701, "actor_loss": -591.6681213378906, "actor_target_entropy": -1.0, "actor_entropy": -0.239038682032016, "alpha_loss": 0.006226869915882426, "alpha_value": 0.201987011229769, "duration": 145.27482175827026, "step": 39750}
{"episode_reward": 829.9521380333009, "episode": 319.0, "Q1 loss": 9.599989887237548, "Q2 loss": 9.57988772201538, "Mean Target Q": 592.1268383789062, "Mean Q1": 592.1283354492188, "Mean Q2": 592.127283203125, "critic_loss": 19.179877563476563, "batch_reward": 5.3961385803222655, "actor_loss": -593.5469360351562, "actor_target_entropy": -1.0, "actor_entropy": -0.2609783616803941, "alpha_loss": 0.004720466484921792, "alpha_value": 0.20160365332356334, "duration": 113.5769715309143, "step": 39875}
{"episode_reward": 843.2391006108635, "episode": 320.0, "Q1 loss": 10.085320701599121, "Q2 loss": 10.075435390472412, "Mean Target Q": 593.1080375976562, "Mean Q1": 593.0959409179687, "Mean Q2": 593.096306640625, "critic_loss": 20.16075609588623, "batch_reward": 5.412166351318359, "actor_loss": -594.2451644405241, "actor_target_entropy": -1.0, "actor_entropy": -0.2438165074394595, "alpha_loss": 0.004476543129121344, "alpha_value": 0.20132349466040925, "step": 40000}
{"duration": 163.49327874183655, "step": 40000}
{"episode_reward": 827.5340774658343, "episode": 321.0, "Q1 loss": 10.23365246963501, "Q2 loss": 10.38439557647705, "Mean Target Q": 593.7062387695313, "Mean Q1": 593.70591015625, "Mean Q2": 593.7054936523438, "critic_loss": 20.618048095703124, "batch_reward": 5.396874774932861, "actor_loss": -594.8311476934524, "actor_target_entropy": -1.0, "actor_entropy": -0.233042745599671, "alpha_loss": 0.00973947513811586, "alpha_value": 0.20081204215818738, "duration": 143.1457278728485, "step": 40125}
{"episode_reward": 843.0015465594427, "episode": 322.0, "Q1 loss": 10.247194446563721, "Q2 loss": 10.046038158416748, "Mean Target Q": 594.8718911132812, "Mean Q1": 594.8615678710937, "Mean Q2": 594.8656108398437, "critic_loss": 20.29323268890381, "batch_reward": 5.411750450134277, "actor_loss": -595.4056632749496, "actor_target_entropy": -1.0, "actor_entropy": -0.2711403968353425, "alpha_loss": 0.0007412600511264416, "alpha_value": 0.20020292193320147, "duration": 141.75022315979004, "step": 40250}
{"episode_reward": 838.2027260968939, "episode": 323.0, "Q1 loss": 9.881703063964844, "Q2 loss": 9.927137981414795, "Mean Target Q": 595.93670703125, "Mean Q1": 595.9404643554687, "Mean Q2": 595.9387563476563, "critic_loss": 19.80884098815918, "batch_reward": 5.424078895568847, "actor_loss": -596.9923957945808, "actor_target_entropy": -1.0, "actor_entropy": -0.2556102242734697, "alpha_loss": 0.0044390173030218905, "alpha_value": 0.20007510248360377, "duration": 177.4894986152649, "step": 40375}
{"episode_reward": 839.2748192859406, "episode": 324.0, "Q1 loss": 10.00399443435669, "Q2 loss": 9.937822723388672, "Mean Target Q": 596.6673491210937, "Mean Q1": 596.6579516601563, "Mean Q2": 596.6571938476562, "critic_loss": 19.941817169189452, "batch_reward": 5.404538375854492, "actor_loss": -597.5555203345514, "actor_target_entropy": -1.0, "actor_entropy": -0.251354253340152, "alpha_loss": 0.0067602195683115675, "alpha_value": 0.19957687271609093, "duration": 165.01546049118042, "step": 40500}
{"episode_reward": 836.2868257482945, "episode": 325.0, "Q1 loss": 10.541527355194091, "Q2 loss": 10.658379890441894, "Mean Target Q": 597.3319936523437, "Mean Q1": 597.3314116210937, "Mean Q2": 597.3310727539063, "critic_loss": 21.199907218933106, "batch_reward": 5.40143616104126, "actor_loss": -598.2175641741071, "actor_target_entropy": -1.0, "actor_entropy": -0.2524983717335595, "alpha_loss": 0.0007891489917205439, "alpha_value": 0.19936491421436844, "duration": 170.29070496559143, "step": 40625}
{"episode_reward": 822.8483180711215, "episode": 326.0, "Q1 loss": 9.920180667877197, "Q2 loss": 9.99017216873169, "Mean Target Q": 598.589767578125, "Mean Q1": 598.5964291992187, "Mean Q2": 598.5956044921875, "critic_loss": 19.910352767944335, "batch_reward": 5.431059097290039, "actor_loss": -599.394778343939, "actor_target_entropy": -1.0, "actor_entropy": -0.24558191097551776, "alpha_loss": 0.0079216762941571, "alpha_value": 0.19900720717461476, "duration": 165.9005627632141, "step": 40750}
{"episode_reward": 843.3740811352562, "episode": 327.0, "Q1 loss": 10.247691688537598, "Q2 loss": 10.19918217086792, "Mean Target Q": 599.1710708007812, "Mean Q1": 599.1634375, "Mean Q2": 599.1648671875, "critic_loss": 20.44687373352051, "batch_reward": 5.4220889320373535, "actor_loss": -599.9705723353794, "actor_target_entropy": -1.0, "actor_entropy": -0.23780539667322523, "alpha_loss": 0.009190487217098947, "alpha_value": 0.1981929094700712, "duration": 132.8162612915039, "step": 40875}
{"episode_reward": 838.480454627848, "episode": 328.0, "Q1 loss": 9.715086727142333, "Q2 loss": 9.787993713378906, "Mean Target Q": 600.4190268554687, "Mean Q1": 600.4176298828125, "Mean Q2": 600.418205078125, "critic_loss": 19.503080444335936, "batch_reward": 5.4410251121521, "actor_loss": -601.3278395129788, "actor_target_entropy": -1.0, "actor_entropy": -0.24915490155258485, "alpha_loss": 0.004638150214187561, "alpha_value": 0.19781916079403747, "duration": 137.4842746257782, "step": 41000}
{"episode_reward": 824.943443272663, "episode": 329.0, "Q1 loss": 10.209311492919921, "Q2 loss": 9.980926456451416, "Mean Target Q": 601.3618408203125, "Mean Q1": 601.356177734375, "Mean Q2": 601.3567333984375, "critic_loss": 20.190237899780275, "batch_reward": 5.445576026916504, "actor_loss": -602.0451892671131, "actor_target_entropy": -1.0, "actor_entropy": -0.2373341896704265, "alpha_loss": 0.011319550282750574, "alpha_value": 0.1970387609408839, "duration": 138.38281083106995, "step": 41125}
{"episode_reward": 829.4802332985233, "episode": 330.0, "Q1 loss": 9.512148292541504, "Q2 loss": 9.589727336883545, "Mean Target Q": 602.1342788085938, "Mean Q1": 602.137943359375, "Mean Q2": 602.1348212890625, "critic_loss": 19.101875679016114, "batch_reward": 5.450191444396973, "actor_loss": -603.1009698683216, "actor_target_entropy": -1.0, "actor_entropy": -0.2470789518087141, "alpha_loss": 0.011204636766530213, "alpha_value": 0.19611751106700054, "duration": 158.12593460083008, "step": 41250}
{"episode_reward": 845.8238422821586, "episode": 331.0, "Q1 loss": 9.755910259246827, "Q2 loss": 9.792123352050782, "Mean Target Q": 603.244423828125, "Mean Q1": 603.2419145507813, "Mean Q2": 603.2434887695313, "critic_loss": 19.54803353881836, "batch_reward": 5.455824710845947, "actor_loss": -604.1888766818577, "actor_target_entropy": -1.0, "actor_entropy": -0.2585254254795256, "alpha_loss": 0.004005590738314722, "alpha_value": 0.19552427367858333, "duration": 144.3318223953247, "step": 41375}
{"episode_reward": 841.7792531464495, "episode": 332.0, "Q1 loss": 9.830513774871827, "Q2 loss": 9.89479098892212, "Mean Target Q": 604.089892578125, "Mean Q1": 604.0789379882813, "Mean Q2": 604.0775610351562, "critic_loss": 19.72530477142334, "batch_reward": 5.461537403106689, "actor_loss": -604.7496268979964, "actor_target_entropy": -1.0, "actor_entropy": -0.2537300906354381, "alpha_loss": 0.0017062244343481238, "alpha_value": 0.1952952664356209, "duration": 177.3585569858551, "step": 41500}
{"episode_reward": 839.648437938614, "episode": 333.0, "Q1 loss": 9.682084728240968, "Q2 loss": 9.642429325103759, "Mean Target Q": 604.5733842773437, "Mean Q1": 604.5790483398438, "Mean Q2": 604.5800029296875, "critic_loss": 19.32451399230957, "batch_reward": 5.452686977386475, "actor_loss": -605.4742034427703, "actor_target_entropy": -1.0, "actor_entropy": -0.28424924470129465, "alpha_loss": 0.002633994447052597, "alpha_value": 0.19516405681948418, "duration": 156.3345000743866, "step": 41625}
{"episode_reward": 834.4346666873655, "episode": 334.0, "Q1 loss": 9.815282398223877, "Q2 loss": 9.83271751022339, "Mean Target Q": 605.4888388671875, "Mean Q1": 605.48487109375, "Mean Q2": 605.4853803710937, "critic_loss": 19.647999938964844, "batch_reward": 5.462825714111328, "actor_loss": -606.2583746141003, "actor_target_entropy": -1.0, "actor_entropy": -0.2625866736615858, "alpha_loss": 0.00696496048476547, "alpha_value": 0.19470476109308818, "duration": 151.72248673439026, "step": 41750}
{"episode_reward": 843.3279929744415, "episode": 335.0, "Q1 loss": 9.20406170654297, "Q2 loss": 9.181998344421388, "Mean Target Q": 606.314341796875, "Mean Q1": 606.3094526367188, "Mean Q2": 606.309060546875, "critic_loss": 18.38606004333496, "batch_reward": 5.456328525543213, "actor_loss": -607.4696432446676, "actor_target_entropy": -1.0, "actor_entropy": -0.2744037333935026, "alpha_loss": 0.0062415086043377714, "alpha_value": 0.19439706784979596, "duration": 133.32770419120789, "step": 41875}
{"episode_reward": 835.8982679297492, "episode": 336.0, "Q1 loss": 10.285033126831054, "Q2 loss": 10.249578159332275, "Mean Target Q": 607.0943466796875, "Mean Q1": 607.0903754882812, "Mean Q2": 607.0897397460938, "critic_loss": 20.534611320495607, "batch_reward": 5.452683387756347, "actor_loss": -607.7708001905872, "actor_target_entropy": -1.0, "actor_entropy": -0.2762804478406906, "alpha_loss": 0.000992048742069352, "alpha_value": 0.19397249057486451, "duration": 142.67704486846924, "step": 42000}
{"episode_reward": 845.275555283669, "episode": 337.0, "Q1 loss": 9.97362384414673, "Q2 loss": 9.993006801605224, "Mean Target Q": 607.8622924804688, "Mean Q1": 607.864107421875, "Mean Q2": 607.8632143554687, "critic_loss": 19.966630622863768, "batch_reward": 5.453911891937256, "actor_loss": -608.6636129712301, "actor_target_entropy": -1.0, "actor_entropy": -0.2739615598841319, "alpha_loss": 0.005197193761844011, "alpha_value": 0.19371047748729817, "duration": 139.0519187450409, "step": 42125}
{"episode_reward": 838.267143427678, "episode": 338.0, "Q1 loss": 10.003331607818604, "Q2 loss": 10.037568084716797, "Mean Target Q": 608.6930048828125, "Mean Q1": 608.687103515625, "Mean Q2": 608.68963671875, "critic_loss": 20.040899673461915, "batch_reward": 5.462888751983643, "actor_loss": -609.6184810515373, "actor_target_entropy": -1.0, "actor_entropy": -0.25452783223121395, "alpha_loss": 0.0028356311471021225, "alpha_value": 0.19347908257595678, "duration": 172.32903695106506, "step": 42250}
{"episode_reward": 834.5568767253137, "episode": 339.0, "Q1 loss": 9.33984958267212, "Q2 loss": 9.315731880187988, "Mean Target Q": 609.3218466796875, "Mean Q1": 609.3198911132813, "Mean Q2": 609.3200083007813, "critic_loss": 18.655581489562987, "batch_reward": 5.473056716918945, "actor_loss": -610.3155352880084, "actor_target_entropy": -1.0, "actor_entropy": -0.2700751508985247, "alpha_loss": 0.004113263014467463, "alpha_value": 0.19304872692284994, "duration": 149.57674312591553, "step": 42375}
{"episode_reward": 842.5279122111712, "episode": 340.0, "Q1 loss": 9.717318405151367, "Q2 loss": 9.757896953582764, "Mean Target Q": 610.5515073242187, "Mean Q1": 610.5530493164063, "Mean Q2": 610.5523291015625, "critic_loss": 19.47521533203125, "batch_reward": 5.478313968658448, "actor_loss": -611.3402414629536, "actor_target_entropy": -1.0, "actor_entropy": -0.2642481211693056, "alpha_loss": 0.00433019365769841, "alpha_value": 0.19277948616299914, "duration": 163.186017036438, "step": 42500}
{"episode_reward": 823.200480402863, "episode": 341.0, "Q1 loss": 9.098716701507568, "Q2 loss": 9.213115535736083, "Mean Target Q": 611.0113256835938, "Mean Q1": 611.0111625976563, "Mean Q2": 611.0089350585938, "critic_loss": 18.311832191467285, "batch_reward": 5.471290977478027, "actor_loss": -611.887949141245, "actor_target_entropy": -1.0, "actor_entropy": -0.2331293002953605, "alpha_loss": 0.008321183227327845, "alpha_value": 0.1921967628636621, "duration": 166.46332025527954, "step": 42625}
{"episode_reward": 842.5213923664209, "episode": 342.0, "Q1 loss": 9.523687141418456, "Q2 loss": 9.583853847503661, "Mean Target Q": 612.0499951171874, "Mean Q1": 612.0438291015626, "Mean Q2": 612.0467900390624, "critic_loss": 19.107541030883787, "batch_reward": 5.466865505218506, "actor_loss": -612.8932258852067, "actor_target_entropy": -1.0, "actor_entropy": -0.29408750154318347, "alpha_loss": 0.004538785035331403, "alpha_value": 0.19160826630404978, "duration": 182.03519940376282, "step": 42750}
{"episode_reward": 833.1793527499605, "episode": 343.0, "Q1 loss": 10.579032318115235, "Q2 loss": 10.730039321899413, "Mean Target Q": 612.7698588867188, "Mean Q1": 612.7638549804688, "Mean Q2": 612.7646235351563, "critic_loss": 21.309071670532227, "batch_reward": 5.484846374511719, "actor_loss": -613.5914151630705, "actor_target_entropy": -1.0, "actor_entropy": -0.32581629592274863, "alpha_loss": -0.0037793077691088595, "alpha_value": 0.19150751545849937, "duration": 174.28631925582886, "step": 42875}
{"episode_reward": 823.1995191492094, "episode": 344.0, "Q1 loss": 9.784473388671875, "Q2 loss": 9.760837985992431, "Mean Target Q": 613.5244086914063, "Mean Q1": 613.5220927734375, "Mean Q2": 613.5193310546875, "critic_loss": 19.545311325073243, "batch_reward": 5.4861884078979495, "actor_loss": -614.3635076707409, "actor_target_entropy": -1.0, "actor_entropy": -0.21884604639584018, "alpha_loss": 0.010383796560833412, "alpha_value": 0.1913967785549459, "duration": 160.02994298934937, "step": 43000}
{"episode_reward": 838.2811127671905, "episode": 345.0, "Q1 loss": 9.55169997024536, "Q2 loss": 9.729138847351074, "Mean Target Q": 614.2787163085937, "Mean Q1": 614.2829116210937, "Mean Q2": 614.2833178710938, "critic_loss": 19.2808387298584, "batch_reward": 5.473831932067871, "actor_loss": -615.0060947963169, "actor_target_entropy": -1.0, "actor_entropy": -0.2590485562880834, "alpha_loss": 0.006953298637185187, "alpha_value": 0.19062606710067032, "duration": 158.61866903305054, "step": 43125}
{"episode_reward": 844.2562683166298, "episode": 346.0, "Q1 loss": 9.605338764190673, "Q2 loss": 9.604180641174317, "Mean Target Q": 615.0423149414063, "Mean Q1": 615.0365014648437, "Mean Q2": 615.0376303710938, "critic_loss": 19.20951933288574, "batch_reward": 5.479668418884278, "actor_loss": -615.862043811429, "actor_target_entropy": -1.0, "actor_entropy": -0.2931318408058536, "alpha_loss": 0.0032299569293466066, "alpha_value": 0.19019271502214138, "duration": 161.33106112480164, "step": 43250}
{"episode_reward": 836.7821365849503, "episode": 347.0, "Q1 loss": 9.282443691253663, "Q2 loss": 9.258757034301757, "Mean Target Q": 616.3629038085937, "Mean Q1": 616.3560009765625, "Mean Q2": 616.3561352539062, "critic_loss": 18.54120069885254, "batch_reward": 5.521994812011719, "actor_loss": -617.4077506897942, "actor_target_entropy": -1.0, "actor_entropy": -0.25451238973746226, "alpha_loss": 0.01143985665920708, "alpha_value": 0.18959586382048932, "duration": 159.12433552742004, "step": 43375}
{"episode_reward": 833.6400550706115, "episode": 348.0, "Q1 loss": 9.169267024993896, "Q2 loss": 9.097678630828858, "Mean Target Q": 616.8557651367188, "Mean Q1": 616.8586875, "Mean Q2": 616.8564086914063, "critic_loss": 18.266945709228516, "batch_reward": 5.516520896911621, "actor_loss": -617.4006150768649, "actor_target_entropy": -1.0, "actor_entropy": -0.2839816563552426, "alpha_loss": 0.004845772366670351, "alpha_value": 0.18887627358278078, "duration": 178.60243773460388, "step": 43500}
{"episode_reward": 835.9438430037135, "episode": 349.0, "Q1 loss": 8.94937498474121, "Q2 loss": 8.96389538192749, "Mean Target Q": 617.3678022460938, "Mean Q1": 617.3675483398438, "Mean Q2": 617.36875, "critic_loss": 17.913270385742187, "batch_reward": 5.494017162322998, "actor_loss": -618.1244884672619, "actor_target_entropy": -1.0, "actor_entropy": -0.3007143437862396, "alpha_loss": -0.0018661050052042045, "alpha_value": 0.18875014679295216, "duration": 159.60339069366455, "step": 43625}
{"episode_reward": 841.2939733243564, "episode": 350.0, "Q1 loss": 9.481788204193116, "Q2 loss": 9.687996810913086, "Mean Target Q": 618.4695986328124, "Mean Q1": 618.4679262695313, "Mean Q2": 618.4667016601562, "critic_loss": 19.16978497314453, "batch_reward": 5.513054222106933, "actor_loss": -619.0901321903352, "actor_target_entropy": -1.0, "actor_entropy": -0.2646829271989484, "alpha_loss": 0.005215722275146794, "alpha_value": 0.18866785645412132, "duration": 160.2140417098999, "step": 43750}
{"episode_reward": 808.7423646268937, "episode": 351.0, "Q1 loss": 9.618661495208741, "Q2 loss": 9.619475574493409, "Mean Target Q": 619.1971000976563, "Mean Q1": 619.1942006835937, "Mean Q2": 619.1967060546875, "critic_loss": 19.23813710784912, "batch_reward": 5.525013965606689, "actor_loss": -619.9186052594866, "actor_target_entropy": -1.0, "actor_entropy": -0.27372669830681784, "alpha_loss": 0.008627495050267686, "alpha_value": 0.1879785413959426, "duration": 164.75978016853333, "step": 43875}
{"episode_reward": 835.0887468680123, "episode": 352.0, "Q1 loss": 9.401540546417236, "Q2 loss": 9.45379993057251, "Mean Target Q": 620.0072075195312, "Mean Q1": 620.0035688476562, "Mean Q2": 620.002884765625, "critic_loss": 18.855340438842774, "batch_reward": 5.526891036987305, "actor_loss": -620.9223967521422, "actor_target_entropy": -1.0, "actor_entropy": -0.28057902138079366, "alpha_loss": 0.00505346110120656, "alpha_value": 0.18741853893462243, "duration": 173.09004616737366, "step": 44000}
{"episode_reward": 844.0334836998115, "episode": 353.0, "Q1 loss": 9.267667861938477, "Q2 loss": 9.26095319366455, "Mean Target Q": 620.4398740234375, "Mean Q1": 620.4293793945312, "Mean Q2": 620.4302373046875, "critic_loss": 18.528621040344238, "batch_reward": 5.508273803710938, "actor_loss": -621.1130622984871, "actor_target_entropy": -1.0, "actor_entropy": -0.3005492069891521, "alpha_loss": 0.002441720632348387, "alpha_value": 0.18717317547400267, "duration": 161.44451212882996, "step": 44125}
{"episode_reward": 842.6334167673755, "episode": 354.0, "Q1 loss": 8.875774150848388, "Q2 loss": 9.031731410980225, "Mean Target Q": 621.5552670898437, "Mean Q1": 621.5571499023438, "Mean Q2": 621.55619921875, "critic_loss": 17.90750555419922, "batch_reward": 5.531336112976074, "actor_loss": -622.2529779249622, "actor_target_entropy": -1.0, "actor_entropy": -0.2710911720510452, "alpha_loss": 0.006946144148617262, "alpha_value": 0.18662387539426134, "duration": 178.31751775741577, "step": 44250}
{"episode_reward": 777.209521930807, "episode": 355.0, "Q1 loss": 8.768157127380372, "Q2 loss": 8.762866874694824, "Mean Target Q": 621.9270502929687, "Mean Q1": 621.9270361328125, "Mean Q2": 621.9267553710938, "critic_loss": 17.531023956298828, "batch_reward": 5.515271282196045, "actor_loss": -622.9483119419643, "actor_target_entropy": -1.0, "actor_entropy": -0.29052607998961494, "alpha_loss": 0.003968466705243502, "alpha_value": 0.18629921773935704, "duration": 179.88167715072632, "step": 44375}
{"episode_reward": 837.0274791014131, "episode": 356.0, "Q1 loss": 8.911357082366944, "Q2 loss": 8.938730148315429, "Mean Target Q": 622.8631860351562, "Mean Q1": 622.86203125, "Mean Q2": 622.8618095703125, "critic_loss": 17.850087257385255, "batch_reward": 5.516676761627197, "actor_loss": -623.7360859532511, "actor_target_entropy": -1.0, "actor_entropy": -0.30791209517948087, "alpha_loss": 0.007309138825568821, "alpha_value": 0.18579336700707494, "duration": 163.09754872322083, "step": 44500}
{"episode_reward": 769.0561983951197, "episode": 357.0, "Q1 loss": 8.611458930969238, "Q2 loss": 8.473553691864014, "Mean Target Q": 623.5167182617188, "Mean Q1": 623.5166557617188, "Mean Q2": 623.5149072265625, "critic_loss": 17.085012550354005, "batch_reward": 5.518947597503662, "actor_loss": -624.1803976391989, "actor_target_entropy": -1.0, "actor_entropy": -0.2714994613613401, "alpha_loss": 0.010566984658085164, "alpha_value": 0.1849477128439377, "duration": 178.96125984191895, "step": 44625}
{"episode_reward": 834.3873519246839, "episode": 358.0, "Q1 loss": 8.902059555053711, "Q2 loss": 8.7717594871521, "Mean Target Q": 624.3752099609375, "Mean Q1": 624.3675625, "Mean Q2": 624.36872265625, "critic_loss": 17.673819076538084, "batch_reward": 5.543522666931152, "actor_loss": -625.4162824076991, "actor_target_entropy": -1.0, "actor_entropy": -0.29338835131737495, "alpha_loss": 0.012227941488456582, "alpha_value": 0.18403383539416318, "duration": 165.3544635772705, "step": 44750}
{"episode_reward": 846.5774579915786, "episode": 359.0, "Q1 loss": 9.355391052246095, "Q2 loss": 9.39485719680786, "Mean Target Q": 625.1951025390625, "Mean Q1": 625.1904262695313, "Mean Q2": 625.1920883789063, "critic_loss": 18.750248191833496, "batch_reward": 5.535568725585938, "actor_loss": -626.2423706054688, "actor_target_entropy": -1.0, "actor_entropy": -0.3107327535038903, "alpha_loss": 0.0026330657114851334, "alpha_value": 0.18339877706869862, "duration": 176.87404656410217, "step": 44875}
{"episode_reward": 849.8665228565327, "episode": 360.0, "Q1 loss": 9.696164867401123, "Q2 loss": 9.71899609375, "Mean Target Q": 626.0146767578125, "Mean Q1": 626.0098784179687, "Mean Q2": 626.010810546875, "critic_loss": 19.41516101837158, "batch_reward": 5.547283641815185, "actor_loss": -626.6243345199093, "actor_target_entropy": -1.0, "actor_entropy": -0.2665215516763349, "alpha_loss": 0.0066948286727100854, "alpha_value": 0.1831237511821886, "step": 45000}
{"duration": 189.24257397651672, "step": 45000}
{"episode_reward": 835.4279867751812, "episode": 361.0, "Q1 loss": 8.562795391082764, "Q2 loss": 8.648698944091796, "Mean Target Q": 626.5620913085937, "Mean Q1": 626.569095703125, "Mean Q2": 626.5688315429687, "critic_loss": 17.211494331359862, "batch_reward": 5.5339585838317875, "actor_loss": -627.4469410729787, "actor_target_entropy": -1.0, "actor_entropy": -0.2828910518733282, "alpha_loss": 0.006645576054570339, "alpha_value": 0.1825228756861029, "duration": 181.3300530910492, "step": 45125}
{"episode_reward": 835.2757589535387, "episode": 362.0, "Q1 loss": 8.578563968658447, "Q2 loss": 8.550240989685058, "Mean Target Q": 627.1333193359375, "Mean Q1": 627.126673828125, "Mean Q2": 627.1254931640625, "critic_loss": 17.12880492401123, "batch_reward": 5.550547622680664, "actor_loss": -628.2737367691532, "actor_target_entropy": -1.0, "actor_entropy": -0.2637225884583689, "alpha_loss": 0.00717374938352394, "alpha_value": 0.1819224890761361, "duration": 170.2022988796234, "step": 45250}
{"episode_reward": 841.3273289853896, "episode": 363.0, "Q1 loss": 9.146840673446656, "Q2 loss": 9.164324644088746, "Mean Target Q": 628.0888676757812, "Mean Q1": 628.0881044921875, "Mean Q2": 628.088125, "critic_loss": 18.311165225982666, "batch_reward": 5.559265106201172, "actor_loss": -628.7572186182416, "actor_target_entropy": -1.0, "actor_entropy": -0.2922648766211101, "alpha_loss": 0.0031317726760688755, "alpha_value": 0.18157555502943462, "duration": 165.3604292869568, "step": 45375}
{"episode_reward": 769.6379297548541, "episode": 364.0, "Q1 loss": 9.446741886138916, "Q2 loss": 9.520359436035156, "Mean Target Q": 628.4656118164063, "Mean Q1": 628.4562329101562, "Mean Q2": 628.4562172851563, "critic_loss": 18.96710125732422, "batch_reward": 5.54414278793335, "actor_loss": -629.1582257670741, "actor_target_entropy": -1.0, "actor_entropy": -0.307921907594127, "alpha_loss": 0.00031083331146698084, "alpha_value": 0.18141357214401155, "duration": 181.03104305267334, "step": 45500}
{"episode_reward": 832.1428512433437, "episode": 365.0, "Q1 loss": 8.78203667831421, "Q2 loss": 8.636079853057861, "Mean Target Q": 629.5765390625, "Mean Q1": 629.5804594726562, "Mean Q2": 629.5798359375, "critic_loss": 17.418116508483887, "batch_reward": 5.5659651260375975, "actor_loss": -630.2412099686879, "actor_target_entropy": -1.0, "actor_entropy": -0.2828154405431142, "alpha_loss": 0.0017696741103593791, "alpha_value": 0.18111725896998668, "duration": 146.07383847236633, "step": 45625}
{"episode_reward": 835.8383532404007, "episode": 366.0, "Q1 loss": 9.253769088745118, "Q2 loss": 9.289188674926757, "Mean Target Q": 630.165873046875, "Mean Q1": 630.1667958984375, "Mean Q2": 630.1689770507812, "critic_loss": 18.542957801818847, "batch_reward": 5.560755722045898, "actor_loss": -631.0130211614793, "actor_target_entropy": -1.0, "actor_entropy": -0.285892239982082, "alpha_loss": 0.004308578468138172, "alpha_value": 0.18102249364164982, "duration": 162.95031332969666, "step": 45750}
{"episode_reward": 840.7319542749606, "episode": 367.0, "Q1 loss": 8.931862617492676, "Q2 loss": 8.978849605560303, "Mean Target Q": 630.865748046875, "Mean Q1": 630.858212890625, "Mean Q2": 630.859337890625, "critic_loss": 17.91071218109131, "batch_reward": 5.567853942871094, "actor_loss": -631.856699141245, "actor_target_entropy": -1.0, "actor_entropy": -0.3012599273333474, "alpha_loss": 0.003729022333457593, "alpha_value": 0.18070268364066566, "duration": 171.40911078453064, "step": 45875}
{"episode_reward": 775.2842357542754, "episode": 368.0, "Q1 loss": 9.093062961578369, "Q2 loss": 9.019468532562255, "Mean Target Q": 631.8489077148438, "Mean Q1": 631.8497397460937, "Mean Q2": 631.8469252929688, "critic_loss": 18.112531509399414, "batch_reward": 5.59330793762207, "actor_loss": -632.6181030273438, "actor_target_entropy": -1.0, "actor_entropy": -0.2829068545852938, "alpha_loss": 0.009647204931224547, "alpha_value": 0.18010557883726214, "duration": 163.11382699012756, "step": 46000}
{"episode_reward": 835.0714679630826, "episode": 369.0, "Q1 loss": 9.087632717132568, "Q2 loss": 9.023131504058838, "Mean Target Q": 631.9203198242187, "Mean Q1": 631.9210122070313, "Mean Q2": 631.9212509765625, "critic_loss": 18.110764144897463, "batch_reward": 5.554049007415771, "actor_loss": -632.6543201264881, "actor_target_entropy": -1.0, "actor_entropy": -0.32143704900665887, "alpha_loss": -0.0015377658179088953, "alpha_value": 0.17989847771006237, "duration": 158.07119917869568, "step": 46125}
{"episode_reward": 837.3628294846109, "episode": 370.0, "Q1 loss": 8.75637825202942, "Q2 loss": 8.940632339477538, "Mean Target Q": 632.6742641601562, "Mean Q1": 632.6655375976562, "Mean Q2": 632.665951171875, "critic_loss": 17.697010551452635, "batch_reward": 5.549064517974854, "actor_loss": -633.6132192304058, "actor_target_entropy": -1.0, "actor_entropy": -0.2973380035931064, "alpha_loss": 0.003979362652546937, "alpha_value": 0.1797396239197857, "duration": 149.1154546737671, "step": 46250}
{"episode_reward": 844.491847528144, "episode": 371.0, "Q1 loss": 9.030742225646973, "Q2 loss": 9.174694286346435, "Mean Target Q": 633.5688486328125, "Mean Q1": 633.5725258789063, "Mean Q2": 633.5728295898438, "critic_loss": 18.205436447143555, "batch_reward": 5.576540721893311, "actor_loss": -634.5776987227183, "actor_target_entropy": -1.0, "actor_entropy": -0.2916588028745046, "alpha_loss": 0.0053841234591331276, "alpha_value": 0.17927647845289577, "duration": 161.22318172454834, "step": 46375}
{"episode_reward": 774.7157061305297, "episode": 372.0, "Q1 loss": 9.517517448425293, "Q2 loss": 9.510893600463866, "Mean Target Q": 634.2685234375, "Mean Q1": 634.263583984375, "Mean Q2": 634.2630771484374, "critic_loss": 19.02841104888916, "batch_reward": 5.572644477844238, "actor_loss": -634.922590686429, "actor_target_entropy": -1.0, "actor_entropy": -0.2969666104162893, "alpha_loss": 0.0025939622428268194, "alpha_value": 0.17904844972033762, "duration": 153.54344725608826, "step": 46500}
{"episode_reward": 846.0433029696221, "episode": 373.0, "Q1 loss": 9.507898681640626, "Q2 loss": 9.274082221984862, "Mean Target Q": 634.6711713867187, "Mean Q1": 634.6731748046875, "Mean Q2": 634.6726337890625, "critic_loss": 18.781980911254884, "batch_reward": 5.5751484375, "actor_loss": -635.8297923254588, "actor_target_entropy": -1.0, "actor_entropy": -0.28806473480330574, "alpha_loss": 0.008226999602768393, "alpha_value": 0.1785959638647797, "duration": 172.37354826927185, "step": 46625}
{"episode_reward": 820.7588443707142, "episode": 374.0, "Q1 loss": 9.034910528182984, "Q2 loss": 9.114367012023926, "Mean Target Q": 635.4838891601562, "Mean Q1": 635.4817954101562, "Mean Q2": 635.4841782226563, "critic_loss": 18.14927758026123, "batch_reward": 5.5848228569030764, "actor_loss": -636.7547617266255, "actor_target_entropy": -1.0, "actor_entropy": -0.31217564450156304, "alpha_loss": 0.005782298139116216, "alpha_value": 0.17788440616001197, "duration": 166.47232389450073, "step": 46750}
{"episode_reward": 837.4414792575524, "episode": 375.0, "Q1 loss": 8.90865329360962, "Q2 loss": 8.921584701538086, "Mean Target Q": 636.1189169921875, "Mean Q1": 636.1105927734375, "Mean Q2": 636.1120815429688, "critic_loss": 17.830237983703615, "batch_reward": 5.580979755401612, "actor_loss": -637.0081021747892, "actor_target_entropy": -1.0, "actor_entropy": -0.31284326858936795, "alpha_loss": -0.0011168338436012466, "alpha_value": 0.17764663769288414, "duration": 170.2628288269043, "step": 46875}
{"episode_reward": 827.9493263470221, "episode": 376.0, "Q1 loss": 9.187803268432617, "Q2 loss": 9.208779571533203, "Mean Target Q": 637.1246728515625, "Mean Q1": 637.1221787109375, "Mean Q2": 637.119615234375, "critic_loss": 18.396582817077636, "batch_reward": 5.602225120544434, "actor_loss": -637.6723947832661, "actor_target_entropy": -1.0, "actor_entropy": -0.3112278222557037, "alpha_loss": 0.004995462668669079, "alpha_value": 0.17762484009084809, "duration": 172.7030267715454, "step": 47000}
{"episode_reward": 841.7892876541081, "episode": 377.0, "Q1 loss": 9.449677394866944, "Q2 loss": 9.593229179382325, "Mean Target Q": 637.4760346679687, "Mean Q1": 637.4834106445312, "Mean Q2": 637.48262109375, "critic_loss": 19.042906547546387, "batch_reward": 5.592103183746338, "actor_loss": -638.2923845563616, "actor_target_entropy": -1.0, "actor_entropy": -0.32615803253083003, "alpha_loss": 0.0034823507820773455, "alpha_value": 0.1772963071642929, "duration": 175.96107959747314, "step": 47125}
{"episode_reward": 835.3216391610388, "episode": 378.0, "Q1 loss": 10.039186809539794, "Q2 loss": 9.94254072189331, "Mean Target Q": 638.1074702148437, "Mean Q1": 638.0933837890625, "Mean Q2": 638.09465625, "critic_loss": 19.981727561950684, "batch_reward": 5.5873927459716795, "actor_loss": -639.139409219065, "actor_target_entropy": -1.0, "actor_entropy": -0.29128321764930604, "alpha_loss": 0.004134718790620325, "alpha_value": 0.17679249182927018, "duration": 177.6736023426056, "step": 47250}
{"episode_reward": 747.597055242158, "episode": 379.0, "Q1 loss": 10.593751834869385, "Q2 loss": 10.59044687652588, "Mean Target Q": 638.9304887695313, "Mean Q1": 638.9313510742187, "Mean Q2": 638.9296918945313, "critic_loss": 21.184198677062987, "batch_reward": 5.602478126525879, "actor_loss": -639.671392531622, "actor_target_entropy": -1.0, "actor_entropy": -0.324052428205808, "alpha_loss": 0.0017262500773612705, "alpha_value": 0.1765763520476926, "duration": 180.8178939819336, "step": 47375}
{"episode_reward": 823.232775270444, "episode": 380.0, "Q1 loss": 8.76240166091919, "Q2 loss": 8.628720977783203, "Mean Target Q": 638.869990234375, "Mean Q1": 638.868240234375, "Mean Q2": 638.8670234375, "critic_loss": 17.39112267303467, "batch_reward": 5.5683839263916015, "actor_loss": -639.5253217143397, "actor_target_entropy": -1.0, "actor_entropy": -0.32813781932477026, "alpha_loss": 0.0007771794372538645, "alpha_value": 0.17667738662487834, "duration": 172.65786623954773, "step": 47500}
{"episode_reward": 817.3828405668255, "episode": 381.0, "Q1 loss": 8.719240905761719, "Q2 loss": 8.672438095092774, "Mean Target Q": 639.7593061523437, "Mean Q1": 639.7546225585937, "Mean Q2": 639.7553193359375, "critic_loss": 17.391678970336915, "batch_reward": 5.594856380462646, "actor_loss": -640.6788039434524, "actor_target_entropy": -1.0, "actor_entropy": -0.3129213024226446, "alpha_loss": 0.0009719638711965037, "alpha_value": 0.17655265522709004, "duration": 170.6882359981537, "step": 47625}
{"episode_reward": 848.1643686227442, "episode": 382.0, "Q1 loss": 8.556009304046631, "Q2 loss": 8.73080647277832, "Mean Target Q": 640.88825390625, "Mean Q1": 640.8908193359375, "Mean Q2": 640.891056640625, "critic_loss": 17.286815803527833, "batch_reward": 5.617250671386719, "actor_loss": -641.6993477113786, "actor_target_entropy": -1.0, "actor_entropy": -0.29769840836524963, "alpha_loss": 0.007173121274043355, "alpha_value": 0.17612122553575202, "duration": 174.18195056915283, "step": 47750}
{"episode_reward": 840.8045443756246, "episode": 383.0, "Q1 loss": 8.680518363952636, "Q2 loss": 8.809853107452392, "Mean Target Q": 641.4683852539063, "Mean Q1": 641.4679750976562, "Mean Q2": 641.4701518554688, "critic_loss": 17.490371459960937, "batch_reward": 5.613948600769043, "actor_loss": -642.451673719618, "actor_target_entropy": -1.0, "actor_entropy": -0.33053284599667504, "alpha_loss": -0.00216778374132922, "alpha_value": 0.17597926708494793, "duration": 186.12235951423645, "step": 47875}
{"episode_reward": 764.2824749559992, "episode": 384.0, "Q1 loss": 8.689422580718993, "Q2 loss": 8.531994552612305, "Mean Target Q": 641.8232978515625, "Mean Q1": 641.816765625, "Mean Q2": 641.81712109375, "critic_loss": 17.221417205810546, "batch_reward": 5.606885314941406, "actor_loss": -642.498767483619, "actor_target_entropy": -1.0, "actor_entropy": -0.32480361144388875, "alpha_loss": 6.451891104300176e-05, "alpha_value": 0.17605684719284456, "duration": 179.8947834968567, "step": 48000}
{"episode_reward": 842.8630420188829, "episode": 385.0, "Q1 loss": 8.303086666107177, "Q2 loss": 8.373371646881104, "Mean Target Q": 642.3700375976563, "Mean Q1": 642.3713310546875, "Mean Q2": 642.3710854492188, "critic_loss": 16.67645834350586, "batch_reward": 5.5996620559692385, "actor_loss": -642.9867563399058, "actor_target_entropy": -1.0, "actor_entropy": -0.33904297105849734, "alpha_loss": 0.0008342488676250454, "alpha_value": 0.17605098370690153, "duration": 180.8084855079651, "step": 48125}
{"episode_reward": 848.1186269136911, "episode": 386.0, "Q1 loss": 8.708622789382934, "Q2 loss": 8.840647068023681, "Mean Target Q": 643.3319282226563, "Mean Q1": 643.3358500976562, "Mean Q2": 643.3355473632812, "critic_loss": 17.54926982116699, "batch_reward": 5.622344650268555, "actor_loss": -644.170190626575, "actor_target_entropy": -1.0, "actor_entropy": -0.33782433550204, "alpha_loss": 0.0011876886184777945, "alpha_value": 0.17587089619577898, "duration": 177.1329264640808, "step": 48250}
{"episode_reward": 843.5578429309122, "episode": 387.0, "Q1 loss": 8.821602527618408, "Q2 loss": 8.789876903533935, "Mean Target Q": 643.9227275390625, "Mean Q1": 643.9126010742187, "Mean Q2": 643.909533203125, "critic_loss": 17.61147944641113, "batch_reward": 5.616364437103272, "actor_loss": -644.3236355251736, "actor_target_entropy": -1.0, "actor_entropy": -0.3242043838614509, "alpha_loss": 0.002430262682508559, "alpha_value": 0.17575339031757392, "duration": 181.1386103630066, "step": 48375}
{"episode_reward": 830.6310124364018, "episode": 388.0, "Q1 loss": 9.611947090148925, "Q2 loss": 9.685759517669677, "Mean Target Q": 644.3854252929688, "Mean Q1": 644.38525390625, "Mean Q2": 644.3884965820313, "critic_loss": 19.29770654296875, "batch_reward": 5.617819728851319, "actor_loss": -645.1696029170866, "actor_target_entropy": -1.0, "actor_entropy": -0.28133009181868646, "alpha_loss": 0.007563483030084641, "alpha_value": 0.17518333671051348, "duration": 161.64273023605347, "step": 48500}
{"episode_reward": 820.3627089650939, "episode": 389.0, "Q1 loss": 8.862826919555664, "Q2 loss": 8.790984233856202, "Mean Target Q": 644.7616606445313, "Mean Q1": 644.76271875, "Mean Q2": 644.7614033203125, "critic_loss": 17.653811119079588, "batch_reward": 5.623359436035156, "actor_loss": -645.8163432772197, "actor_target_entropy": -1.0, "actor_entropy": -0.30890147600855145, "alpha_loss": 0.002761109262734415, "alpha_value": 0.1749448774024202, "duration": 175.91877508163452, "step": 48625}
{"episode_reward": 845.658049190884, "episode": 390.0, "Q1 loss": 9.527469478607177, "Q2 loss": 9.442673141479492, "Mean Target Q": 645.3543354492188, "Mean Q1": 645.3488833007813, "Mean Q2": 645.3494306640625, "critic_loss": 18.970142631530763, "batch_reward": 5.606682094573975, "actor_loss": -646.3265420236895, "actor_target_entropy": -1.0, "actor_entropy": -0.30492628798369437, "alpha_loss": -0.0007386997289535018, "alpha_value": 0.17476599224048436, "duration": 179.13594269752502, "step": 48750}
{"episode_reward": 841.9042218897633, "episode": 391.0, "Q1 loss": 8.714480464935303, "Q2 loss": 8.867996040344238, "Mean Target Q": 646.2171391601562, "Mean Q1": 646.2175288085938, "Mean Q2": 646.2149614257812, "critic_loss": 17.58247647857666, "batch_reward": 5.628176216125488, "actor_loss": -646.9489775158111, "actor_target_entropy": -1.0, "actor_entropy": -0.28459084483366165, "alpha_loss": 0.004465671163791466, "alpha_value": 0.1746420891248263, "duration": 161.50169038772583, "step": 48875}
{"episode_reward": 836.3741234683653, "episode": 392.0, "Q1 loss": 7.940275243759155, "Q2 loss": 7.92488409614563, "Mean Target Q": 646.5171245117187, "Mean Q1": 646.51494140625, "Mean Q2": 646.5183061523437, "critic_loss": 15.86515938949585, "batch_reward": 5.619423645019531, "actor_loss": -647.339347593246, "actor_target_entropy": -1.0, "actor_entropy": -0.2855970684078432, "alpha_loss": 0.005099080345262924, "alpha_value": 0.17408700045351383, "duration": 152.80808210372925, "step": 49000}
{"episode_reward": 820.3785418768222, "episode": 393.0, "Q1 loss": 9.023348825454711, "Q2 loss": 9.00920820236206, "Mean Target Q": 647.5815771484375, "Mean Q1": 647.5768154296875, "Mean Q2": 647.5789897460937, "critic_loss": 18.03255704498291, "batch_reward": 5.645002285003662, "actor_loss": -648.1003030443949, "actor_target_entropy": -1.0, "actor_entropy": -0.2929239757950344, "alpha_loss": 0.007703765383219376, "alpha_value": 0.17367648784304845, "duration": 172.16902565956116, "step": 49125}
{"episode_reward": 823.7272529388268, "episode": 394.0, "Q1 loss": 8.549412204742431, "Q2 loss": 8.576891525268554, "Mean Target Q": 647.8391713867187, "Mean Q1": 647.836375, "Mean Q2": 647.833466796875, "critic_loss": 17.126303718566895, "batch_reward": 5.631706546783447, "actor_loss": -648.5943140829763, "actor_target_entropy": -1.0, "actor_entropy": -0.292486205216377, "alpha_loss": 0.0072978829904910055, "alpha_value": 0.17280971633821002, "duration": 159.07484698295593, "step": 49250}
{"episode_reward": 833.5008389862626, "episode": 395.0, "Q1 loss": 8.49516837310791, "Q2 loss": 8.515604835510254, "Mean Target Q": 648.3766044921875, "Mean Q1": 648.3764838867188, "Mean Q2": 648.3774086914062, "critic_loss": 17.010773216247557, "batch_reward": 5.650759479522705, "actor_loss": -649.2936817956349, "actor_target_entropy": -1.0, "actor_entropy": -0.3240961413534861, "alpha_loss": 0.0007077963553398611, "alpha_value": 0.17260291254084162, "duration": 152.7063913345337, "step": 49375}
{"episode_reward": 814.8873605602527, "episode": 396.0, "Q1 loss": 8.04930152130127, "Q2 loss": 8.07711241531372, "Mean Target Q": 649.1901630859375, "Mean Q1": 649.1905498046875, "Mean Q2": 649.1900122070313, "critic_loss": 16.126413970947265, "batch_reward": 5.647628486633301, "actor_loss": -649.7453800324471, "actor_target_entropy": -1.0, "actor_entropy": -0.33067146472392545, "alpha_loss": 0.0015109861382253229, "alpha_value": 0.17253334065021286, "duration": 192.34101605415344, "step": 49500}
{"episode_reward": 836.9397420788688, "episode": 397.0, "Q1 loss": 9.491285697937013, "Q2 loss": 9.394695987701416, "Mean Target Q": 649.4998442382813, "Mean Q1": 649.4911474609376, "Mean Q2": 649.48931640625, "critic_loss": 18.88598175048828, "batch_reward": 5.629506385803222, "actor_loss": -649.8525080605159, "actor_target_entropy": -1.0, "actor_entropy": -0.3019897975618877, "alpha_loss": 0.00419346463408262, "alpha_value": 0.1722607904599525, "duration": 175.4174768924713, "step": 49625}
{"episode_reward": 809.2574997092123, "episode": 398.0, "Q1 loss": 8.104932220458984, "Q2 loss": 8.114075672149658, "Mean Target Q": 650.1836904296875, "Mean Q1": 650.1849013671875, "Mean Q2": 650.1853857421875, "critic_loss": 16.219007926940918, "batch_reward": 5.645759124755859, "actor_loss": -651.0038274949596, "actor_target_entropy": -1.0, "actor_entropy": -0.32717235987224885, "alpha_loss": 0.0037241637887012575, "alpha_value": 0.17194424081785253, "duration": 185.5208990573883, "step": 49750}
{"episode_reward": 843.0594728466289, "episode": 399.0, "Q1 loss": 8.161634376525878, "Q2 loss": 8.240766395568848, "Mean Target Q": 650.7004482421875, "Mean Q1": 650.6967954101563, "Mean Q2": 650.6991000976562, "critic_loss": 16.40240079498291, "batch_reward": 5.648784984588623, "actor_loss": -651.4489503890749, "actor_target_entropy": -1.0, "actor_entropy": -0.30941473089513327, "alpha_loss": 0.006539054632571245, "alpha_value": 0.17145696892135506, "duration": 154.32319355010986, "step": 49875}
{"episode_reward": 838.913972206175, "episode": 400.0, "Q1 loss": 8.462760272979736, "Q2 loss": 8.411067321777344, "Mean Target Q": 651.2240209960937, "Mean Q1": 651.2223110351563, "Mean Q2": 651.2231201171875, "critic_loss": 16.873827583312988, "batch_reward": 5.651526847839356, "actor_loss": -652.0177376039567, "actor_target_entropy": -1.0, "actor_entropy": -0.3200617749844828, "alpha_loss": -0.0005245111157907354, "alpha_value": 0.17117209126404279, "step": 50000}
{"duration": 211.75463438034058, "step": 50000}
{"episode_reward": 840.7063521455156, "episode": 401.0, "Q1 loss": 7.882264366149903, "Q2 loss": 7.83684701538086, "Mean Target Q": 651.8404184570312, "Mean Q1": 651.8389248046875, "Mean Q2": 651.8374848632812, "critic_loss": 15.719111362457275, "batch_reward": 5.6556777648925785, "actor_loss": -652.7655939980159, "actor_target_entropy": -1.0, "actor_entropy": -0.32916300779297236, "alpha_loss": 0.0009495030852064253, "alpha_value": 0.17131544557304856, "duration": 169.64864325523376, "step": 50125}
{"episode_reward": 846.5512844901573, "episode": 402.0, "Q1 loss": 8.856152599334717, "Q2 loss": 8.83272348022461, "Mean Target Q": 652.1668623046875, "Mean Q1": 652.170875, "Mean Q2": 652.1694965820312, "critic_loss": 17.688876037597655, "batch_reward": 5.648502414703369, "actor_loss": -652.6863393475933, "actor_target_entropy": -1.0, "actor_entropy": -0.33881326163968734, "alpha_loss": -0.0015803327025364965, "alpha_value": 0.17132559242465573, "duration": 177.34869980812073, "step": 50250}
{"episode_reward": 816.090760415095, "episode": 403.0, "Q1 loss": 8.035563972473145, "Q2 loss": 8.162443410873413, "Mean Target Q": 652.799912109375, "Mean Q1": 652.7958540039062, "Mean Q2": 652.7961801757813, "critic_loss": 16.19800736618042, "batch_reward": 5.643513999938965, "actor_loss": -653.5072418697297, "actor_target_entropy": -1.0, "actor_entropy": -0.3074377952587037, "alpha_loss": 0.0014421753880996552, "alpha_value": 0.1711967122844577, "duration": 198.25465488433838, "step": 50375}
{"episode_reward": 827.8164624383652, "episode": 404.0, "Q1 loss": 8.631890922546386, "Q2 loss": 8.598195655822753, "Mean Target Q": 653.2975893554687, "Mean Q1": 653.299296875, "Mean Q2": 653.3017153320312, "critic_loss": 17.230086555480955, "batch_reward": 5.642130012512207, "actor_loss": -654.0653371503277, "actor_target_entropy": -1.0, "actor_entropy": -0.2980178534503906, "alpha_loss": 0.0008736304608323882, "alpha_value": 0.17112298027570602, "duration": 160.48209142684937, "step": 50500}
{"episode_reward": 820.587017618954, "episode": 405.0, "Q1 loss": 8.23522968864441, "Q2 loss": 8.244290719985962, "Mean Target Q": 653.9555546875, "Mean Q1": 653.9449345703125, "Mean Q2": 653.9432026367188, "critic_loss": 16.479520401000975, "batch_reward": 5.654584487915039, "actor_loss": -654.491458953373, "actor_target_entropy": -1.0, "actor_entropy": -0.318273953265614, "alpha_loss": 0.0015972456894814968, "alpha_value": 0.17102591796783292, "duration": 180.48345398902893, "step": 50625}
{"episode_reward": 776.7744463018737, "episode": 406.0, "Q1 loss": 8.234997718811035, "Q2 loss": 8.362605762481689, "Mean Target Q": 654.5479208984375, "Mean Q1": 654.5455087890625, "Mean Q2": 654.5467236328125, "critic_loss": 16.597603507995604, "batch_reward": 5.664250843048095, "actor_loss": -655.1931339386971, "actor_target_entropy": -1.0, "actor_entropy": -0.34043876105739224, "alpha_loss": -0.002335875649981561, "alpha_value": 0.1710515190041791, "duration": 183.04998660087585, "step": 50750}
{"episode_reward": 839.913206641905, "episode": 407.0, "Q1 loss": 8.530630599975586, "Q2 loss": 8.433968349456787, "Mean Target Q": 655.2035966796875, "Mean Q1": 655.213158203125, "Mean Q2": 655.2102626953125, "critic_loss": 16.96459893798828, "batch_reward": 5.67663597869873, "actor_loss": -656.2510957263764, "actor_target_entropy": -1.0, "actor_entropy": -0.30523591453120824, "alpha_loss": 0.005829803710285988, "alpha_value": 0.17100587487590838, "duration": 192.91405487060547, "step": 50875}
{"episode_reward": 825.6622759884217, "episode": 408.0, "Q1 loss": 8.108766695022583, "Q2 loss": 8.230294368743897, "Mean Target Q": 655.3999155273438, "Mean Q1": 655.3959448242188, "Mean Q2": 655.3975551757812, "critic_loss": 16.339061027526856, "batch_reward": 5.6641696853637695, "actor_loss": -656.0358148390247, "actor_target_entropy": -1.0, "actor_entropy": -0.34647054970264435, "alpha_loss": 0.0030534327360651186, "alpha_value": 0.17049828917553458, "duration": 165.8331708908081, "step": 51000}
{"episode_reward": 819.6742694752827, "episode": 409.0, "Q1 loss": 8.048024982452393, "Q2 loss": 7.888109981536865, "Mean Target Q": 656.0290737304688, "Mean Q1": 656.0294443359375, "Mean Q2": 656.0264643554688, "critic_loss": 15.936134994506835, "batch_reward": 5.669354419708252, "actor_loss": -656.6279287186879, "actor_target_entropy": -1.0, "actor_entropy": -0.31224448907943, "alpha_loss": 0.005417724760870139, "alpha_value": 0.17013329065633873, "duration": 147.22004866600037, "step": 51125}
{"episode_reward": 773.1469785343245, "episode": 410.0, "Q1 loss": 7.9792522602081295, "Q2 loss": 8.105105997085571, "Mean Target Q": 656.6084252929687, "Mean Q1": 656.60208203125, "Mean Q2": 656.6043950195312, "critic_loss": 16.084358318328857, "batch_reward": 5.666091819763183, "actor_loss": -657.6154204337828, "actor_target_entropy": -1.0, "actor_entropy": -0.30848406447518256, "alpha_loss": 0.006431678745655283, "alpha_value": 0.16956592568919013, "duration": 151.33397102355957, "step": 51250}
{"episode_reward": 820.578750985858, "episode": 411.0, "Q1 loss": 8.407868949890137, "Q2 loss": 8.401650924682617, "Mean Target Q": 657.019740234375, "Mean Q1": 657.0226484375, "Mean Q2": 657.0248994140625, "critic_loss": 16.809519943237305, "batch_reward": 5.663964393615722, "actor_loss": -657.8826129247271, "actor_target_entropy": -1.0, "actor_entropy": -0.3233763286991725, "alpha_loss": 0.003585807284310697, "alpha_value": 0.16911837606122246, "duration": 162.84607911109924, "step": 51375}
{"episode_reward": 799.9874990386173, "episode": 412.0, "Q1 loss": 8.428552852630615, "Q2 loss": 8.553226722717286, "Mean Target Q": 657.6428940429688, "Mean Q1": 657.6283754882812, "Mean Q2": 657.6256577148438, "critic_loss": 16.981779556274414, "batch_reward": 5.664161785125732, "actor_loss": -658.4387482673891, "actor_target_entropy": -1.0, "actor_entropy": -0.3179194396061282, "alpha_loss": 0.0040447292192238235, "alpha_value": 0.16871769764938996, "duration": 128.843195438385, "step": 51500}
{"episode_reward": 821.3390903992864, "episode": 413.0, "Q1 loss": 8.019549739837647, "Q2 loss": 8.057395156860352, "Mean Target Q": 658.058015625, "Mean Q1": 658.0580234375, "Mean Q2": 658.0599858398438, "critic_loss": 16.076944843292235, "batch_reward": 5.659950286865234, "actor_loss": -659.0062091161334, "actor_target_entropy": -1.0, "actor_entropy": -0.3047946279957181, "alpha_loss": 0.004014741148917921, "alpha_value": 0.1684812519106063, "duration": 132.5823962688446, "step": 51625}
{"episode_reward": 845.605451204971, "episode": 414.0, "Q1 loss": 7.75248335647583, "Q2 loss": 7.797366352081299, "Mean Target Q": 659.1163627929687, "Mean Q1": 659.11658984375, "Mean Q2": 659.1153139648437, "critic_loss": 15.549849647521972, "batch_reward": 5.693048397064209, "actor_loss": -659.8745442052042, "actor_target_entropy": -1.0, "actor_entropy": -0.320009509642278, "alpha_loss": 0.00465794711471385, "alpha_value": 0.16819712477729168, "duration": 90.68142414093018, "step": 51750}
{"episode_reward": 838.9114900762299, "episode": 415.0, "Q1 loss": 8.672867042541505, "Q2 loss": 8.578144702911377, "Mean Target Q": 659.4979516601562, "Mean Q1": 659.4967412109374, "Mean Q2": 659.4976181640625, "critic_loss": 17.251011703491212, "batch_reward": 5.681785015106201, "actor_loss": -660.6068066793774, "actor_target_entropy": -1.0, "actor_entropy": -0.32027515177688903, "alpha_loss": 0.004956172963988687, "alpha_value": 0.16770143587176092, "duration": 105.41277027130127, "step": 51875}
{"episode_reward": 826.2725028876133, "episode": 416.0, "Q1 loss": 8.06028332901001, "Q2 loss": 8.232193614959717, "Mean Target Q": 660.1257138671875, "Mean Q1": 660.1268208007813, "Mean Q2": 660.1271025390625, "critic_loss": 16.292477005004883, "batch_reward": 5.700013698577881, "actor_loss": -660.9788158785913, "actor_target_entropy": -1.0, "actor_entropy": -0.339764739236524, "alpha_loss": 0.0040647572529832685, "alpha_value": 0.16723028046969238, "duration": 136.5596923828125, "step": 52000}
{"episode_reward": 828.5032656417573, "episode": 417.0, "Q1 loss": 8.300864353179932, "Q2 loss": 8.177278182983398, "Mean Target Q": 660.275216796875, "Mean Q1": 660.26838671875, "Mean Q2": 660.2680874023438, "critic_loss": 16.47814256286621, "batch_reward": 5.684872192382812, "actor_loss": -660.8325902545263, "actor_target_entropy": -1.0, "actor_entropy": -0.3015314896428396, "alpha_loss": 0.003650433812586088, "alpha_value": 0.16688666670029045, "duration": 146.0560519695282, "step": 52125}
{"episode_reward": 814.1904447731182, "episode": 418.0, "Q1 loss": 7.677078168869018, "Q2 loss": 7.673497816085815, "Mean Target Q": 661.0179848632813, "Mean Q1": 661.0181469726563, "Mean Q2": 661.0196923828125, "critic_loss": 15.350576034545899, "batch_reward": 5.692690330505371, "actor_loss": -661.4684084000125, "actor_target_entropy": -1.0, "actor_entropy": -0.3369014330448643, "alpha_loss": -0.0002712941157721704, "alpha_value": 0.16670260200450107, "duration": 157.96744871139526, "step": 52250}
{"episode_reward": 812.4543699456182, "episode": 419.0, "Q1 loss": 7.834967092514038, "Q2 loss": 7.987706771850586, "Mean Target Q": 661.6588510742188, "Mean Q1": 661.655333984375, "Mean Q2": 661.6548813476562, "critic_loss": 15.822673866271973, "batch_reward": 5.708386375427246, "actor_loss": -662.5239742218502, "actor_target_entropy": -1.0, "actor_entropy": -0.3083595761231014, "alpha_loss": 0.005985051484054161, "alpha_value": 0.16655165269858485, "duration": 196.02569103240967, "step": 52375}
{"episode_reward": 841.2607180487203, "episode": 420.0, "Q1 loss": 8.37433837890625, "Q2 loss": 8.302743625640868, "Mean Target Q": 661.952025390625, "Mean Q1": 661.95329296875, "Mean Q2": 661.9524565429688, "critic_loss": 16.67708204650879, "batch_reward": 5.697868099212647, "actor_loss": -662.8558014900453, "actor_target_entropy": -1.0, "actor_entropy": -0.33356423195331325, "alpha_loss": 0.002115614911270959, "alpha_value": 0.16613257128745948, "duration": 149.4166603088379, "step": 52500}
{"episode_reward": 811.5103581095307, "episode": 421.0, "Q1 loss": 9.074270614624023, "Q2 loss": 9.35759635925293, "Mean Target Q": 662.4909560546874, "Mean Q1": 662.4873500976563, "Mean Q2": 662.4869311523438, "critic_loss": 18.431866958618166, "batch_reward": 5.6952012977600095, "actor_loss": -663.5907224624876, "actor_target_entropy": -1.0, "actor_entropy": -0.3457713789410061, "alpha_loss": 0.0011612552639451764, "alpha_value": 0.16605208139619304, "duration": 141.02964568138123, "step": 52625}
{"episode_reward": 829.5374373375938, "episode": 422.0, "Q1 loss": 8.09446826171875, "Q2 loss": 7.961197555541992, "Mean Target Q": 663.1374711914062, "Mean Q1": 663.1349311523437, "Mean Q2": 663.13510546875, "critic_loss": 16.055665786743162, "batch_reward": 5.710993930816651, "actor_loss": -663.6867262317288, "actor_target_entropy": -1.0, "actor_entropy": -0.3331346819477697, "alpha_loss": 3.2502140158847454e-05, "alpha_value": 0.16588911582149327, "duration": 184.29156517982483, "step": 52750}
{"episode_reward": 834.5508053935171, "episode": 423.0, "Q1 loss": 8.652050468444823, "Q2 loss": 8.651238912582398, "Mean Target Q": 663.4215791015625, "Mean Q1": 663.4212006835937, "Mean Q2": 663.4192548828125, "critic_loss": 17.303289337158205, "batch_reward": 5.692366771697998, "actor_loss": -664.3528616768973, "actor_target_entropy": -1.0, "actor_entropy": -0.33310955810168436, "alpha_loss": 0.0025978061049023553, "alpha_value": 0.16575455509296627, "duration": 174.09488034248352, "step": 52875}
{"episode_reward": 826.0427815759448, "episode": 424.0, "Q1 loss": 8.399862991333007, "Q2 loss": 8.435746898651123, "Mean Target Q": 664.0569145507812, "Mean Q1": 664.0552153320313, "Mean Q2": 664.0558295898437, "critic_loss": 16.835609870910645, "batch_reward": 5.707804721832275, "actor_loss": -665.079837922127, "actor_target_entropy": -1.0, "actor_entropy": -0.3556005940321953, "alpha_loss": 0.00155690276146596, "alpha_value": 0.1657253461993738, "duration": 173.28822779655457, "step": 53000}
{"episode_reward": 838.0498710680891, "episode": 425.0, "Q1 loss": 8.20184181213379, "Q2 loss": 8.204404319763183, "Mean Target Q": 664.3541176757813, "Mean Q1": 664.3496923828125, "Mean Q2": 664.3532231445313, "critic_loss": 16.406246170043946, "batch_reward": 5.696083927154541, "actor_loss": -665.3086044069321, "actor_target_entropy": -1.0, "actor_entropy": -0.3334519054208483, "alpha_loss": 0.0027596806120570925, "alpha_value": 0.16548234284801044, "duration": 175.93881368637085, "step": 53125}
{"episode_reward": 767.4369772166735, "episode": 426.0, "Q1 loss": 8.208813743591309, "Q2 loss": 8.251513996124267, "Mean Target Q": 665.0819169921875, "Mean Q1": 665.0781606445313, "Mean Q2": 665.0757373046876, "critic_loss": 16.460327743530275, "batch_reward": 5.703272468566895, "actor_loss": -665.5608874905494, "actor_target_entropy": -1.0, "actor_entropy": -0.35536462981854716, "alpha_loss": -0.0007511484436690807, "alpha_value": 0.16536052527265865, "duration": 192.60910272598267, "step": 53250}
{"episode_reward": 847.6209610833229, "episode": 427.0, "Q1 loss": 8.624464408874513, "Q2 loss": 8.506799453735352, "Mean Target Q": 665.1313266601562, "Mean Q1": 665.1404555664062, "Mean Q2": 665.1406528320313, "critic_loss": 17.13126382446289, "batch_reward": 5.6815918350219725, "actor_loss": -666.3454328264509, "actor_target_entropy": -1.0, "actor_entropy": -0.34508931423936573, "alpha_loss": 0.0015670000520046977, "alpha_value": 0.16526604586639929, "duration": 166.24456572532654, "step": 53375}
{"episode_reward": 824.0906112421956, "episode": 428.0, "Q1 loss": 8.271088806152344, "Q2 loss": 8.352018398284912, "Mean Target Q": 665.933298828125, "Mean Q1": 665.9235209960938, "Mean Q2": 665.9251518554687, "critic_loss": 16.623107139587404, "batch_reward": 5.701911323547363, "actor_loss": -666.6248149256552, "actor_target_entropy": -1.0, "actor_entropy": -0.2904201029769836, "alpha_loss": 0.004442090061568324, "alpha_value": 0.16505820301618507, "duration": 180.948894739151, "step": 53500}
{"episode_reward": 811.1864209504948, "episode": 429.0, "Q1 loss": 8.42301258468628, "Q2 loss": 8.372928813934326, "Mean Target Q": 666.2263955078125, "Mean Q1": 666.2236372070313, "Mean Q2": 666.2226391601563, "critic_loss": 16.79594132232666, "batch_reward": 5.691462844848632, "actor_loss": -666.7119557214162, "actor_target_entropy": -1.0, "actor_entropy": -0.3173859781689114, "alpha_loss": 0.004489887088152861, "alpha_value": 0.16449966900080076, "duration": 157.8026237487793, "step": 53625}
{"episode_reward": 843.0718807215421, "episode": 430.0, "Q1 loss": 8.17500174331665, "Q2 loss": 8.227464862823487, "Mean Target Q": 667.316240234375, "Mean Q1": 667.315189453125, "Mean Q2": 667.3133745117187, "critic_loss": 16.402466621398926, "batch_reward": 5.717450176239014, "actor_loss": -668.1782009986139, "actor_target_entropy": -1.0, "actor_entropy": -0.3258893879190568, "alpha_loss": 0.004397485298179691, "alpha_value": 0.16416863535823514, "duration": 198.52257919311523, "step": 53750}
{"episode_reward": 835.0376036499689, "episode": 431.0, "Q1 loss": 7.406494552612305, "Q2 loss": 7.525444221496582, "Mean Target Q": 667.8629208984376, "Mean Q1": 667.8602797851562, "Mean Q2": 667.8605258789063, "critic_loss": 14.931938819885254, "batch_reward": 5.731492435455322, "actor_loss": -668.6531720842634, "actor_target_entropy": -1.0, "actor_entropy": -0.3562108027556586, "alpha_loss": 0.0007462867384126025, "alpha_value": 0.16379823165654722, "duration": 170.95938539505005, "step": 53875}
{"episode_reward": 836.1007487688609, "episode": 432.0, "Q1 loss": 8.191593355178833, "Q2 loss": 8.229120067596435, "Mean Target Q": 667.9646025390625, "Mean Q1": 667.9607602539063, "Mean Q2": 667.9615932617188, "critic_loss": 16.420713485717773, "batch_reward": 5.708672149658203, "actor_loss": -668.6981545725176, "actor_target_entropy": -1.0, "actor_entropy": -0.3171785070050147, "alpha_loss": 0.005338306717138978, "alpha_value": 0.1638450669845886, "duration": 160.61639952659607, "step": 54000}
{"episode_reward": 843.2600004616936, "episode": 433.0, "Q1 loss": 8.223689994812013, "Q2 loss": 8.337550354003906, "Mean Target Q": 668.61876171875, "Mean Q1": 668.6212875976563, "Mean Q2": 668.623220703125, "critic_loss": 16.561240371704102, "batch_reward": 5.72843569946289, "actor_loss": -669.1787119063121, "actor_target_entropy": -1.0, "actor_entropy": -0.3355022640455337, "alpha_loss": 0.0034275440950064903, "alpha_value": 0.1633277518310592, "duration": 166.2133822441101, "step": 54125}
{"episode_reward": 846.1136188449293, "episode": 434.0, "Q1 loss": 7.928946334838868, "Q2 loss": 7.918946598052979, "Mean Target Q": 668.985892578125, "Mean Q1": 668.9865576171875, "Mean Q2": 668.9849658203125, "critic_loss": 15.847892967224121, "batch_reward": 5.7215431175231934, "actor_loss": -669.188000094506, "actor_target_entropy": -1.0, "actor_entropy": -0.33503083836647773, "alpha_loss": 0.0025495416935413114, "alpha_value": 0.16305691546501955, "duration": 185.00266289710999, "step": 54250}
{"episode_reward": 814.5385584326539, "episode": 435.0, "Q1 loss": 8.313438011169433, "Q2 loss": 8.298741500854492, "Mean Target Q": 669.1164321289062, "Mean Q1": 669.1126958007812, "Mean Q2": 669.1115805664062, "critic_loss": 16.612179527282716, "batch_reward": 5.720738391876221, "actor_loss": -669.6100773887028, "actor_target_entropy": -1.0, "actor_entropy": -0.32643157291033914, "alpha_loss": 0.004754956817210075, "alpha_value": 0.16255534509837968, "duration": 164.83433938026428, "step": 54375}
{"episode_reward": 775.5622249011608, "episode": 436.0, "Q1 loss": 7.782367958068848, "Q2 loss": 7.805088035583496, "Mean Target Q": 669.7611665039062, "Mean Q1": 669.7504311523437, "Mean Q2": 669.7522788085937, "critic_loss": 15.587455947875977, "batch_reward": 5.718675254821777, "actor_loss": -670.6565079227571, "actor_target_entropy": -1.0, "actor_entropy": -0.31857850258388826, "alpha_loss": 0.006745949220438037, "alpha_value": 0.16220576784053362, "duration": 160.78328013420105, "step": 54500}
{"episode_reward": 808.2800713128248, "episode": 437.0, "Q1 loss": 9.14857180404663, "Q2 loss": 9.202404605865478, "Mean Target Q": 670.3037705078125, "Mean Q1": 670.3134975585938, "Mean Q2": 670.3136147460938, "critic_loss": 18.350976417541503, "batch_reward": 5.7294068450927735, "actor_loss": -671.0374833364335, "actor_target_entropy": -1.0, "actor_entropy": -0.34886906449756927, "alpha_loss": 0.0014691376644704076, "alpha_value": 0.16176811527823945, "duration": 185.031334400177, "step": 54625}
{"episode_reward": 718.6291231958885, "episode": 438.0, "Q1 loss": 8.79553849029541, "Q2 loss": 8.831302749633789, "Mean Target Q": 670.6818227539062, "Mean Q1": 670.6698803710938, "Mean Q2": 670.6697182617188, "critic_loss": 17.626841171264648, "batch_reward": 5.735603801727295, "actor_loss": -671.2303102554813, "actor_target_entropy": -1.0, "actor_entropy": -0.3305302454579261, "alpha_loss": 0.003714649461119646, "alpha_value": 0.1614679411654323, "duration": 164.15888452529907, "step": 54750}
{"episode_reward": 817.5722843453141, "episode": 439.0, "Q1 loss": 7.989752704620361, "Q2 loss": 8.030891023635863, "Mean Target Q": 670.5796474609375, "Mean Q1": 670.5786416015625, "Mean Q2": 670.5768818359375, "critic_loss": 16.020643730163574, "batch_reward": 5.719957843780517, "actor_loss": -671.2856890966021, "actor_target_entropy": -1.0, "actor_entropy": -0.35027411201643566, "alpha_loss": -0.0009709944918988243, "alpha_value": 0.16130913817465561, "duration": 176.9230613708496, "step": 54875}
{"episode_reward": 829.2930935720472, "episode": 440.0, "Q1 loss": 8.562589754104614, "Q2 loss": 8.727938316345215, "Mean Target Q": 671.6472592773438, "Mean Q1": 671.6468911132813, "Mean Q2": 671.6477124023437, "critic_loss": 17.29052808380127, "batch_reward": 5.755469604492188, "actor_loss": -672.1540310767389, "actor_target_entropy": -1.0, "actor_entropy": -0.34301753846868394, "alpha_loss": 0.0035413498802471066, "alpha_value": 0.16123639422161612, "step": 55000}
{"duration": 194.2854106426239, "step": 55000}
{"episode_reward": 840.8643477552656, "episode": 441.0, "Q1 loss": 8.210045589447022, "Q2 loss": 8.257655200958252, "Mean Target Q": 671.7813364257812, "Mean Q1": 671.7756181640625, "Mean Q2": 671.7776645507812, "critic_loss": 16.467700805664062, "batch_reward": 5.735767627716064, "actor_loss": -672.6019887772817, "actor_target_entropy": -1.0, "actor_entropy": -0.342352784342236, "alpha_loss": -0.0001833078059707842, "alpha_value": 0.16101043645927013, "duration": 187.33609127998352, "step": 55125}
{"episode_reward": 815.3815055278072, "episode": 442.0, "Q1 loss": 7.795655200958252, "Q2 loss": 7.749116355895996, "Mean Target Q": 672.437158203125, "Mean Q1": 672.4399877929687, "Mean Q2": 672.4379790039062, "critic_loss": 15.544771591186523, "batch_reward": 5.73931131362915, "actor_loss": -673.105715843939, "actor_target_entropy": -1.0, "actor_entropy": -0.343726537881359, "alpha_loss": 0.005270218384647442, "alpha_value": 0.16092103778829225, "duration": 182.30373191833496, "step": 55250}
{"episode_reward": 844.7166052465437, "episode": 443.0, "Q1 loss": 8.386102546691895, "Q2 loss": 8.413779006958007, "Mean Target Q": 672.746884765625, "Mean Q1": 672.7495747070312, "Mean Q2": 672.74958984375, "critic_loss": 16.799881561279296, "batch_reward": 5.730382892608643, "actor_loss": -673.2528919038318, "actor_target_entropy": -1.0, "actor_entropy": -0.31193364991082084, "alpha_loss": 0.002282400515728763, "alpha_value": 0.16054790922903667, "duration": 182.07045912742615, "step": 55375}
{"episode_reward": 818.1362612473199, "episode": 444.0, "Q1 loss": 8.026809257507324, "Q2 loss": 8.06528257751465, "Mean Target Q": 673.384205078125, "Mean Q1": 673.380650390625, "Mean Q2": 673.3791245117187, "critic_loss": 16.09209196472168, "batch_reward": 5.7575190658569335, "actor_loss": -674.2049954322076, "actor_target_entropy": -1.0, "actor_entropy": -0.34430588349219293, "alpha_loss": 0.0004791067011894718, "alpha_value": 0.16026004820513146, "duration": 193.25892210006714, "step": 55500}
{"episode_reward": 729.5850199891881, "episode": 445.0, "Q1 loss": 7.572594882965088, "Q2 loss": 7.641423152923584, "Mean Target Q": 673.9350498046875, "Mean Q1": 673.9359975585937, "Mean Q2": 673.938005859375, "critic_loss": 15.214018020629883, "batch_reward": 5.754743438720703, "actor_loss": -674.3969184027778, "actor_target_entropy": -1.0, "actor_entropy": -0.34356546260061716, "alpha_loss": 0.005465646340910878, "alpha_value": 0.16002020937607972, "duration": 161.54151153564453, "step": 55625}
{"episode_reward": 830.9295997437789, "episode": 446.0, "Q1 loss": 8.198496074676514, "Q2 loss": 8.085627666473389, "Mean Target Q": 673.6347465820312, "Mean Q1": 673.6204033203124, "Mean Q2": 673.6192983398438, "critic_loss": 16.28412368774414, "batch_reward": 5.722485282897949, "actor_loss": -674.3841710244455, "actor_target_entropy": -1.0, "actor_entropy": -0.3306126738748243, "alpha_loss": 0.0035839019654949587, "alpha_value": 0.15963110900221203, "duration": 144.0699965953827, "step": 55750}
{"episode_reward": 844.0440247873581, "episode": 447.0, "Q1 loss": 7.416075183868408, "Q2 loss": 7.629041679382325, "Mean Target Q": 674.3485380859375, "Mean Q1": 674.3570161132812, "Mean Q2": 674.3558637695312, "critic_loss": 15.045116851806641, "batch_reward": 5.735702369689942, "actor_loss": -675.2269597129216, "actor_target_entropy": -1.0, "actor_entropy": -0.3630682282031529, "alpha_loss": -0.0013360500387433502, "alpha_value": 0.159500387801061, "duration": 183.586838722229, "step": 55875}
{"episode_reward": 832.2510811186088, "episode": 448.0, "Q1 loss": 7.8445628528594975, "Q2 loss": 7.829844850540161, "Mean Target Q": 675.1248310546875, "Mean Q1": 675.12523828125, "Mean Q2": 675.126265625, "critic_loss": 15.674407768249512, "batch_reward": 5.760444194793701, "actor_loss": -675.7937474404612, "actor_target_entropy": -1.0, "actor_entropy": -0.347487035778261, "alpha_loss": 0.0023099549279938783, "alpha_value": 0.15944394316445104, "duration": 179.6968822479248, "step": 56000}
{"episode_reward": 833.2287953561583, "episode": 449.0, "Q1 loss": 7.779978218078614, "Q2 loss": 7.807792882919312, "Mean Target Q": 674.9762333984374, "Mean Q1": 674.9681435546875, "Mean Q2": 674.9692348632813, "critic_loss": 15.587771049499512, "batch_reward": 5.74665678024292, "actor_loss": -675.5592951698909, "actor_target_entropy": -1.0, "actor_entropy": -0.31247301068570876, "alpha_loss": 0.0002213389952740972, "alpha_value": 0.15949441411318976, "duration": 154.1262867450714, "step": 56125}
{"episode_reward": 837.7906863736808, "episode": 450.0, "Q1 loss": 8.092840143203736, "Q2 loss": 7.94003144454956, "Mean Target Q": 675.8280424804688, "Mean Q1": 675.8287094726562, "Mean Q2": 675.82977734375, "critic_loss": 16.032871631622314, "batch_reward": 5.756921028137207, "actor_loss": -676.3599321919103, "actor_target_entropy": -1.0, "actor_entropy": -0.3362520587059759, "alpha_loss": 0.0012393134323159052, "alpha_value": 0.1593674739854061, "duration": 175.09827971458435, "step": 56250}
{"episode_reward": 836.3878959439032, "episode": 451.0, "Q1 loss": 8.03257098388672, "Q2 loss": 8.091488651275634, "Mean Target Q": 676.301947265625, "Mean Q1": 676.3026967773437, "Mean Q2": 676.3018950195312, "critic_loss": 16.124059707641603, "batch_reward": 5.763423892974854, "actor_loss": -676.7488112676712, "actor_target_entropy": -1.0, "actor_entropy": -0.3189363657009034, "alpha_loss": 0.001680624266598551, "alpha_value": 0.15919120110094623, "duration": 150.6881766319275, "step": 56375}
{"episode_reward": 831.5536427005371, "episode": 452.0, "Q1 loss": 7.138471977233887, "Q2 loss": 7.094107936859131, "Mean Target Q": 676.509490234375, "Mean Q1": 676.5054897460938, "Mean Q2": 676.5081396484375, "critic_loss": 14.232579887390136, "batch_reward": 5.759560768127441, "actor_loss": -676.9252161825857, "actor_target_entropy": -1.0, "actor_entropy": -0.2920722105810719, "alpha_loss": 0.0036268850728388754, "alpha_value": 0.15891492137543733, "duration": 171.61267066001892, "step": 56500}
{"episode_reward": 844.9512846642364, "episode": 453.0, "Q1 loss": 7.509230796813965, "Q2 loss": 7.55892861366272, "Mean Target Q": 677.1457978515625, "Mean Q1": 677.1463862304688, "Mean Q2": 677.14292578125, "critic_loss": 15.068159454345704, "batch_reward": 5.763434764862061, "actor_loss": -677.6491195436508, "actor_target_entropy": -1.0, "actor_entropy": -0.33394253632378956, "alpha_loss": -0.000774405846771385, "alpha_value": 0.15881227431077896, "duration": 179.99190974235535, "step": 56625}
{"episode_reward": 824.478804412304, "episode": 454.0, "Q1 loss": 7.466975193023682, "Q2 loss": 7.381800107955932, "Mean Target Q": 677.6160629882812, "Mean Q1": 677.6140029296874, "Mean Q2": 677.6164868164062, "critic_loss": 14.84877532196045, "batch_reward": 5.767490180969238, "actor_loss": -678.1143523185484, "actor_target_entropy": -1.0, "actor_entropy": -0.35188504837213025, "alpha_loss": -0.001030431945823253, "alpha_value": 0.15872810372382046, "duration": 148.74493217468262, "step": 56750}
{"episode_reward": 827.0795258316735, "episode": 455.0, "Q1 loss": 8.104322132110596, "Q2 loss": 8.173168895721435, "Mean Target Q": 678.0510024414062, "Mean Q1": 678.0487534179688, "Mean Q2": 678.0480283203125, "critic_loss": 16.277490978240966, "batch_reward": 5.753391052246093, "actor_loss": -678.6387164403521, "actor_target_entropy": -1.0, "actor_entropy": -0.31436157037341406, "alpha_loss": 0.003560568309492535, "alpha_value": 0.15878876914084805, "duration": 145.7570662498474, "step": 56875}
{"episode_reward": 837.5309441148953, "episode": 456.0, "Q1 loss": 7.696056505203247, "Q2 loss": 7.6328136920928955, "Mean Target Q": 678.3857939453125, "Mean Q1": 678.3821557617188, "Mean Q2": 678.3839916992188, "critic_loss": 15.328870220184326, "batch_reward": 5.762596168518066, "actor_loss": -679.0386116273942, "actor_target_entropy": -1.0, "actor_entropy": -0.3247960892415816, "alpha_loss": 0.003441522333530649, "alpha_value": 0.15839837883662386, "duration": 154.03135204315186, "step": 57000}
{"episode_reward": 824.3418772934687, "episode": 457.0, "Q1 loss": 7.2436110877990725, "Q2 loss": 7.280372367858886, "Mean Target Q": 678.8313330078125, "Mean Q1": 678.8281650390625, "Mean Q2": 678.8236323242188, "critic_loss": 14.523983470916749, "batch_reward": 5.767997032165527, "actor_loss": -679.5009717184399, "actor_target_entropy": -1.0, "actor_entropy": -0.3473726265014164, "alpha_loss": -0.0018129927061852954, "alpha_value": 0.15841270960362205, "duration": 144.04483032226562, "step": 57125}
{"episode_reward": 831.3670735959407, "episode": 458.0, "Q1 loss": 7.414296867370606, "Q2 loss": 7.465396314620972, "Mean Target Q": 679.2360356445313, "Mean Q1": 679.236458984375, "Mean Q2": 679.2360849609375, "critic_loss": 14.879693187713624, "batch_reward": 5.7752161140441896, "actor_loss": -679.5640819918725, "actor_target_entropy": -1.0, "actor_entropy": -0.3682892721506857, "alpha_loss": -0.0021030150669356508, "alpha_value": 0.15867551498260232, "duration": 129.64209914207458, "step": 57250}
{"episode_reward": 846.0853544681149, "episode": 459.0, "Q1 loss": 7.487783712387085, "Q2 loss": 7.524499057769775, "Mean Target Q": 679.116154296875, "Mean Q1": 679.1208383789062, "Mean Q2": 679.1228701171875, "critic_loss": 15.01228279876709, "batch_reward": 5.753190925598145, "actor_loss": -679.8677871946304, "actor_target_entropy": -1.0, "actor_entropy": -0.34842361438842046, "alpha_loss": -0.0022827269775526865, "alpha_value": 0.15863052701065994, "duration": 136.5932765007019, "step": 57375}
{"episode_reward": 838.1392086074306, "episode": 460.0, "Q1 loss": 7.6141445960998535, "Q2 loss": 7.638173206329346, "Mean Target Q": 679.8529252929687, "Mean Q1": 679.8407739257813, "Mean Q2": 679.8422856445312, "critic_loss": 15.25231777191162, "batch_reward": 5.772560729980468, "actor_loss": -680.3481189358619, "actor_target_entropy": -1.0, "actor_entropy": -0.34563058614730835, "alpha_loss": 0.00024822220439091325, "alpha_value": 0.1588776082822247, "duration": 160.1842052936554, "step": 57500}
{"episode_reward": 827.3912271768914, "episode": 461.0, "Q1 loss": 7.204175479888916, "Q2 loss": 7.272071420669556, "Mean Target Q": 680.2743364257813, "Mean Q1": 680.276896484375, "Mean Q2": 680.2759799804687, "critic_loss": 14.476246864318847, "batch_reward": 5.768608268737793, "actor_loss": -680.9930981832837, "actor_target_entropy": -1.0, "actor_entropy": -0.3597977752723391, "alpha_loss": 0.0007931897583018456, "alpha_value": 0.15880542397207784, "duration": 175.08952140808105, "step": 57625}
{"episode_reward": 829.4598363353706, "episode": 462.0, "Q1 loss": 7.254648050308227, "Q2 loss": 7.220351863861084, "Mean Target Q": 680.6363305664063, "Mean Q1": 680.6345502929687, "Mean Q2": 680.6340297851563, "critic_loss": 14.47499993133545, "batch_reward": 5.776408752441406, "actor_loss": -681.0970449139995, "actor_target_entropy": -1.0, "actor_entropy": -0.3232122020375344, "alpha_loss": 0.0014610330897173094, "alpha_value": 0.15861510988113023, "duration": 133.91237092018127, "step": 57750}
{"episode_reward": 834.8877894653968, "episode": 463.0, "Q1 loss": 8.801323656082154, "Q2 loss": 8.798098335266113, "Mean Target Q": 680.9170327148438, "Mean Q1": 680.9105024414063, "Mean Q2": 680.9132119140625, "critic_loss": 17.59942202758789, "batch_reward": 5.767840557098388, "actor_loss": -681.4737296937004, "actor_target_entropy": -1.0, "actor_entropy": -0.3133326678995102, "alpha_loss": 0.0026232369672802703, "alpha_value": 0.15841256073661875, "duration": 133.93919825553894, "step": 57875}
{"episode_reward": 848.8026238721546, "episode": 464.0, "Q1 loss": 8.3824058303833, "Q2 loss": 8.32769324874878, "Mean Target Q": 681.5933671875, "Mean Q1": 681.6005463867187, "Mean Q2": 681.5981982421876, "critic_loss": 16.710099143981935, "batch_reward": 5.777968757629394, "actor_loss": -682.047835811492, "actor_target_entropy": -1.0, "actor_entropy": -0.3126955027541807, "alpha_loss": 0.00308780396552456, "alpha_value": 0.15829766345618032, "duration": 169.5405833721161, "step": 58000}
{"episode_reward": 818.9873484514276, "episode": 465.0, "Q1 loss": 7.933849708557129, "Q2 loss": 7.7859058208465575, "Mean Target Q": 681.7737236328124, "Mean Q1": 681.7659311523438, "Mean Q2": 681.7670263671876, "critic_loss": 15.719755477905274, "batch_reward": 5.777425308227539, "actor_loss": -682.2633182586186, "actor_target_entropy": -1.0, "actor_entropy": -0.3558489230890123, "alpha_loss": 0.0022240287942131834, "alpha_value": 0.15781226425059935, "duration": 163.66833662986755, "step": 58125}
{"episode_reward": 849.7472149222968, "episode": 466.0, "Q1 loss": 6.81926623916626, "Q2 loss": 6.787300445556641, "Mean Target Q": 682.44180078125, "Mean Q1": 682.4434228515624, "Mean Q2": 682.4406040039063, "critic_loss": 13.606566677093506, "batch_reward": 5.791246437072754, "actor_loss": -682.9024658203125, "actor_target_entropy": -1.0, "actor_entropy": -0.3594205475622608, "alpha_loss": 0.003321498455930381, "alpha_value": 0.15766421891407026, "duration": 172.77247405052185, "step": 58250}
{"episode_reward": 848.0009319696459, "episode": 467.0, "Q1 loss": 7.450320671081543, "Q2 loss": 7.450826663970947, "Mean Target Q": 682.2316650390625, "Mean Q1": 682.2241733398438, "Mean Q2": 682.2252763671875, "critic_loss": 14.9011473197937, "batch_reward": 5.764737510681153, "actor_loss": -682.8596801757812, "actor_target_entropy": -1.0, "actor_entropy": -0.36358259925766595, "alpha_loss": 0.002865818362416966, "alpha_value": 0.157417038581326, "duration": 182.32188248634338, "step": 58375}
{"episode_reward": 831.2314447347585, "episode": 468.0, "Q1 loss": 7.945792533874512, "Q2 loss": 8.13136468887329, "Mean Target Q": 682.9817231445312, "Mean Q1": 682.979384765625, "Mean Q2": 682.9780698242188, "critic_loss": 16.0771572265625, "batch_reward": 5.797533950805664, "actor_loss": -683.928934404927, "actor_target_entropy": -1.0, "actor_entropy": -0.34193800461869084, "alpha_loss": 0.003238527829037799, "alpha_value": 0.1569842908112876, "duration": 144.7566041946411, "step": 58500}
{"episode_reward": 775.8864960254012, "episode": 469.0, "Q1 loss": 8.11359401702881, "Q2 loss": 8.108642406463623, "Mean Target Q": 683.2248466796875, "Mean Q1": 683.2284140625, "Mean Q2": 683.2309223632813, "critic_loss": 16.22223644256592, "batch_reward": 5.775772201538086, "actor_loss": -683.7873961433531, "actor_target_entropy": -1.0, "actor_entropy": -0.32134637591384707, "alpha_loss": 0.0018138354422435874, "alpha_value": 0.1568483544931365, "duration": 153.92194032669067, "step": 58625}
{"episode_reward": 822.4834401599581, "episode": 470.0, "Q1 loss": 7.984614505767822, "Q2 loss": 7.996511688232422, "Mean Target Q": 683.7929921875, "Mean Q1": 683.7849770507812, "Mean Q2": 683.78579296875, "critic_loss": 15.981126182556153, "batch_reward": 5.789919219970703, "actor_loss": -684.4454522901966, "actor_target_entropy": -1.0, "actor_entropy": -0.32853064229411466, "alpha_loss": 0.0035480617511747105, "alpha_value": 0.1565558101088102, "duration": 163.9477024078369, "step": 58750}
{"episode_reward": 819.4752058727954, "episode": 471.0, "Q1 loss": 7.772222974777222, "Q2 loss": 7.781255306243897, "Mean Target Q": 683.8567807617187, "Mean Q1": 683.8595776367188, "Mean Q2": 683.8578359375, "critic_loss": 15.553478286743164, "batch_reward": 5.78665189743042, "actor_loss": -684.3199995737227, "actor_target_entropy": -1.0, "actor_entropy": -0.35124843508478193, "alpha_loss": 0.0008613863379679738, "alpha_value": 0.15630694539195666, "duration": 151.9512233734131, "step": 58875}
{"episode_reward": 841.0408756090571, "episode": 472.0, "Q1 loss": 7.451339248657226, "Q2 loss": 7.501044212341308, "Mean Target Q": 684.5876762695312, "Mean Q1": 684.5868598632812, "Mean Q2": 684.5859130859375, "critic_loss": 14.95238346862793, "batch_reward": 5.807495105743408, "actor_loss": -684.9755160424018, "actor_target_entropy": -1.0, "actor_entropy": -0.3587193272767528, "alpha_loss": -0.0005476764335687603, "alpha_value": 0.15635443974204544, "duration": 144.65274572372437, "step": 59000}
{"episode_reward": 823.3805986079684, "episode": 473.0, "Q1 loss": 7.791408000946045, "Q2 loss": 7.772734107971192, "Mean Target Q": 684.6635893554687, "Mean Q1": 684.665044921875, "Mean Q2": 684.6649760742188, "critic_loss": 15.564142105102539, "batch_reward": 5.7931318321228025, "actor_loss": -685.5267769949777, "actor_target_entropy": -1.0, "actor_entropy": -0.3490169904534779, "alpha_loss": 0.0022165169717655296, "alpha_value": 0.15641883900351178, "duration": 114.4770245552063, "step": 59125}
{"episode_reward": 842.3788386197386, "episode": 474.0, "Q1 loss": 7.32444517326355, "Q2 loss": 7.332918886184692, "Mean Target Q": 684.9662358398438, "Mean Q1": 684.9647490234375, "Mean Q2": 684.9643803710937, "critic_loss": 14.657364040374755, "batch_reward": 5.784084716796875, "actor_loss": -685.7768111690398, "actor_target_entropy": -1.0, "actor_entropy": -0.3248227411700833, "alpha_loss": 0.0045343970939997705, "alpha_value": 0.15597027513215536, "duration": 90.23021960258484, "step": 59250}
{"episode_reward": 836.8836096615287, "episode": 475.0, "Q1 loss": 7.398802677154541, "Q2 loss": 7.38908203125, "Mean Target Q": 685.4910083007812, "Mean Q1": 685.4860205078126, "Mean Q2": 685.4883681640625, "critic_loss": 14.787884777069092, "batch_reward": 5.794675556182861, "actor_loss": -686.1510000077504, "actor_target_entropy": -1.0, "actor_entropy": -0.33505021485071335, "alpha_loss": 0.0019435096607868753, "alpha_value": 0.15560170844571578, "duration": 103.48529601097107, "step": 59375}
{"episode_reward": 824.9773067223019, "episode": 476.0, "Q1 loss": 7.555494199752808, "Q2 loss": 7.504564819335937, "Mean Target Q": 685.9959321289062, "Mean Q1": 685.9971484375, "Mean Q2": 685.995759765625, "critic_loss": 15.060059013366699, "batch_reward": 5.804619705200195, "actor_loss": -686.517797654675, "actor_target_entropy": -1.0, "actor_entropy": -0.34370591611631457, "alpha_loss": 0.0014610965229240396, "alpha_value": 0.15549709391443398, "duration": 155.03094696998596, "step": 59500}
{"episode_reward": 832.6669817478032, "episode": 477.0, "Q1 loss": 7.875623327255249, "Q2 loss": 8.026094160079957, "Mean Target Q": 686.4081455078125, "Mean Q1": 686.4145522460938, "Mean Q2": 686.4141665039062, "critic_loss": 15.901717388153076, "batch_reward": 5.809021091461181, "actor_loss": -687.2168656606523, "actor_target_entropy": -1.0, "actor_entropy": -0.34709292981359696, "alpha_loss": 0.003304178270304369, "alpha_value": 0.15535194943489647, "duration": 155.76330852508545, "step": 59625}
{"episode_reward": 837.6000310469342, "episode": 478.0, "Q1 loss": 7.737234712600708, "Q2 loss": 7.875037645339966, "Mean Target Q": 686.5636376953125, "Mean Q1": 686.5473740234376, "Mean Q2": 686.54835546875, "critic_loss": 15.612272388458251, "batch_reward": 5.816744281768798, "actor_loss": -687.0106654013357, "actor_target_entropy": -1.0, "actor_entropy": -0.3737526386976242, "alpha_loss": -0.00027814680229752296, "alpha_value": 0.15515675161184084, "duration": 161.0079221725464, "step": 59750}
{"episode_reward": 842.5372477950599, "episode": 479.0, "Q1 loss": 7.480206300735474, "Q2 loss": 7.47316823387146, "Mean Target Q": 687.128833984375, "Mean Q1": 687.130712890625, "Mean Q2": 687.1333798828125, "critic_loss": 14.953374610900878, "batch_reward": 5.818000957489014, "actor_loss": -687.5468023390997, "actor_target_entropy": -1.0, "actor_entropy": -0.35445231814233086, "alpha_loss": 0.0006245910005259609, "alpha_value": 0.15525287955585124, "duration": 151.33122873306274, "step": 59875}
{"episode_reward": 829.7925287630449, "episode": 480.0, "Q1 loss": 7.384995674133301, "Q2 loss": 7.220803623199463, "Mean Target Q": 687.2308857421875, "Mean Q1": 687.2323110351563, "Mean Q2": 687.2313920898438, "critic_loss": 14.605799304962158, "batch_reward": 5.803841785430908, "actor_loss": -687.8268304640247, "actor_target_entropy": -1.0, "actor_entropy": -0.37349173282423326, "alpha_loss": 0.000118885146108486, "alpha_value": 0.15508734561672533, "step": 60000}
{"duration": 163.1177031993866, "step": 60000}
{"episode_reward": 837.2895763712767, "episode": 481.0, "Q1 loss": 7.3033145179748535, "Q2 loss": 7.4043017139434815, "Mean Target Q": 687.35372265625, "Mean Q1": 687.3483588867188, "Mean Q2": 687.3447602539062, "critic_loss": 14.707616249084472, "batch_reward": 5.788020648956299, "actor_loss": -688.2165672665551, "actor_target_entropy": -1.0, "actor_entropy": -0.3477048325160193, "alpha_loss": 0.005388669804522087, "alpha_value": 0.1549261195401017, "duration": 147.01452589035034, "step": 60125}
{"episode_reward": 835.9668376496286, "episode": 482.0, "Q1 loss": 7.296500743865967, "Q2 loss": 7.469140237808228, "Mean Target Q": 687.789994140625, "Mean Q1": 687.7961850585938, "Mean Q2": 687.7984174804687, "critic_loss": 14.765640941619873, "batch_reward": 5.807555118560791, "actor_loss": -688.4718431042087, "actor_target_entropy": -1.0, "actor_entropy": -0.32809590428106244, "alpha_loss": 0.005869723044358374, "alpha_value": 0.154348081269011, "duration": 163.08853197097778, "step": 60250}
{"episode_reward": 842.7986527730093, "episode": 483.0, "Q1 loss": 7.422364868164062, "Q2 loss": 7.508337715148926, "Mean Target Q": 688.4901381835938, "Mean Q1": 688.484462890625, "Mean Q2": 688.4826943359375, "critic_loss": 14.930702491760254, "batch_reward": 5.811250514984131, "actor_loss": -689.1702076745412, "actor_target_entropy": -1.0, "actor_entropy": -0.3552260200182597, "alpha_loss": 0.0005795435096684193, "alpha_value": 0.15409251248563482, "duration": 146.03762483596802, "step": 60375}
{"episode_reward": 834.8066975919747, "episode": 484.0, "Q1 loss": 7.034645963668823, "Q2 loss": 7.011184637069702, "Mean Target Q": 688.9138481445312, "Mean Q1": 688.90921484375, "Mean Q2": 688.9120776367188, "critic_loss": 14.045830577850342, "batch_reward": 5.8232702293396, "actor_loss": -689.1811838457661, "actor_target_entropy": -1.0, "actor_entropy": -0.3557936462663835, "alpha_loss": 0.0033260429514602066, "alpha_value": 0.15379939070277274, "duration": 156.23507714271545, "step": 60500}
{"episode_reward": 842.5884350848193, "episode": 485.0, "Q1 loss": 6.906730850219726, "Q2 loss": 6.899477066040039, "Mean Target Q": 688.9511616210938, "Mean Q1": 688.956390625, "Mean Q2": 688.9522075195313, "critic_loss": 13.806207931518555, "batch_reward": 5.8099325637817385, "actor_loss": -689.5169251457094, "actor_target_entropy": -1.0, "actor_entropy": -0.35526266788679456, "alpha_loss": 0.0005750884893276389, "alpha_value": 0.15378482770791133, "duration": 180.35549020767212, "step": 60625}
{"episode_reward": 839.8019113772605, "episode": 486.0, "Q1 loss": 6.706517812728882, "Q2 loss": 6.782839765548706, "Mean Target Q": 689.478224609375, "Mean Q1": 689.47341015625, "Mean Q2": 689.47737109375, "critic_loss": 13.489357521057128, "batch_reward": 5.822998691558838, "actor_loss": -690.2101391207788, "actor_target_entropy": -1.0, "actor_entropy": -0.36790362048533654, "alpha_loss": 0.0016588710958228235, "alpha_value": 0.1536201756386895, "duration": 181.88647603988647, "step": 60750}
{"episode_reward": 842.4077286879403, "episode": 487.0, "Q1 loss": 7.383484680175782, "Q2 loss": 7.373591688156128, "Mean Target Q": 689.6942744140625, "Mean Q1": 689.69009765625, "Mean Q2": 689.688375, "critic_loss": 14.75707635498047, "batch_reward": 5.817507953643799, "actor_loss": -690.2221592494419, "actor_target_entropy": -1.0, "actor_entropy": -0.33644910416905843, "alpha_loss": 0.0038743759579365216, "alpha_value": 0.15330370009276478, "duration": 163.817533493042, "step": 60875}
{"episode_reward": 829.7115674647068, "episode": 488.0, "Q1 loss": 6.756246065139771, "Q2 loss": 6.863344646453857, "Mean Target Q": 690.0813325195312, "Mean Q1": 690.0766953125, "Mean Q2": 690.0783486328125, "critic_loss": 13.61959070968628, "batch_reward": 5.814237159729004, "actor_loss": -690.4726050592238, "actor_target_entropy": -1.0, "actor_entropy": -0.3628280172424932, "alpha_loss": -8.218796292860662e-05, "alpha_value": 0.1531035757158458, "duration": 158.35116600990295, "step": 61000}
{"episode_reward": 840.7727751261576, "episode": 489.0, "Q1 loss": 6.651612323760986, "Q2 loss": 6.650364421844483, "Mean Target Q": 690.340109375, "Mean Q1": 690.3449575195312, "Mean Q2": 690.3440083007813, "critic_loss": 13.301976749420167, "batch_reward": 5.818701477050781, "actor_loss": -690.7832486591642, "actor_target_entropy": -1.0, "actor_entropy": -0.2939415831887533, "alpha_loss": 0.004355976614908922, "alpha_value": 0.15293661634479952, "duration": 162.87109780311584, "step": 61125}
{"episode_reward": 823.300562616585, "episode": 490.0, "Q1 loss": 7.2977079486846925, "Q2 loss": 7.332248723983764, "Mean Target Q": 690.7816450195312, "Mean Q1": 690.7782001953125, "Mean Q2": 690.77780078125, "critic_loss": 14.629956661224366, "batch_reward": 5.835126194000244, "actor_loss": -691.2973967521422, "actor_target_entropy": -1.0, "actor_entropy": -0.33780924567291815, "alpha_loss": 0.0043087508566978, "alpha_value": 0.1525902157034532, "duration": 171.67033004760742, "step": 61250}
{"episode_reward": 825.0412963557279, "episode": 491.0, "Q1 loss": 7.491792724609375, "Q2 loss": 7.423447895050049, "Mean Target Q": 690.8116806640625, "Mean Q1": 690.8049536132812, "Mean Q2": 690.8057631835937, "critic_loss": 14.915240608215331, "batch_reward": 5.804261505126953, "actor_loss": -691.6028917100695, "actor_target_entropy": -1.0, "actor_entropy": -0.3647747825062464, "alpha_loss": -0.0017998448780013456, "alpha_value": 0.15241617083907433, "duration": 166.39654874801636, "step": 61375}
{"episode_reward": 832.211043661597, "episode": 492.0, "Q1 loss": 7.811807132720947, "Q2 loss": 7.925239778518677, "Mean Target Q": 691.4397778320313, "Mean Q1": 691.443115234375, "Mean Q2": 691.4415961914062, "critic_loss": 15.737046932220458, "batch_reward": 5.8263335762023925, "actor_loss": -691.8277361469884, "actor_target_entropy": -1.0, "actor_entropy": -0.3441176496205791, "alpha_loss": 0.001083029366488899, "alpha_value": 0.15243071664759722, "duration": 175.22500228881836, "step": 61500}
{"episode_reward": 841.7421101156342, "episode": 493.0, "Q1 loss": 6.982571290969848, "Q2 loss": 7.06930344581604, "Mean Target Q": 691.6860454101562, "Mean Q1": 691.6893422851563, "Mean Q2": 691.6920688476563, "critic_loss": 14.051874740600585, "batch_reward": 5.8299608840942385, "actor_loss": -691.7097100151909, "actor_target_entropy": -1.0, "actor_entropy": -0.3242856486449166, "alpha_loss": 0.00433807363428752, "alpha_value": 0.15222661419016187, "duration": 170.18397688865662, "step": 61625}
{"episode_reward": 826.6561411348947, "episode": 494.0, "Q1 loss": 6.63583572769165, "Q2 loss": 6.616243034362793, "Mean Target Q": 692.0753588867187, "Mean Q1": 692.0687993164063, "Mean Q2": 692.066298828125, "critic_loss": 13.252078704833984, "batch_reward": 5.8382469711303715, "actor_loss": -692.8055803852696, "actor_target_entropy": -1.0, "actor_entropy": -0.3284374850411569, "alpha_loss": 0.0030488882349022934, "alpha_value": 0.15190815123694237, "duration": 156.60233759880066, "step": 61750}
{"episode_reward": 835.9705613733984, "episode": 495.0, "Q1 loss": 6.866340847015381, "Q2 loss": 6.752506191253662, "Mean Target Q": 692.695525390625, "Mean Q1": 692.689548828125, "Mean Q2": 692.6928623046875, "critic_loss": 13.61884705734253, "batch_reward": 5.839549659729004, "actor_loss": -693.1724310980903, "actor_target_entropy": -1.0, "actor_entropy": -0.3410543752095056, "alpha_loss": 0.001614109321039111, "alpha_value": 0.15161099961905633, "duration": 159.62659239768982, "step": 61875}
{"episode_reward": 818.7765393744006, "episode": 496.0, "Q1 loss": 6.433377489089966, "Q2 loss": 6.47948583984375, "Mean Target Q": 692.9701704101562, "Mean Q1": 692.9751352539063, "Mean Q2": 692.9721518554687, "critic_loss": 12.912863384246826, "batch_reward": 5.829880794525146, "actor_loss": -693.6160061743951, "actor_target_entropy": -1.0, "actor_entropy": -0.3208873834340803, "alpha_loss": 0.0023602455968953547, "alpha_value": 0.1514032293007262, "duration": 158.69272875785828, "step": 62000}
{"episode_reward": 742.5213756643021, "episode": 497.0, "Q1 loss": 6.992185092926025, "Q2 loss": 7.135917016983032, "Mean Target Q": 693.1915288085937, "Mean Q1": 693.1923623046875, "Mean Q2": 693.1919858398437, "critic_loss": 14.128102157592773, "batch_reward": 5.826744785308838, "actor_loss": -693.6402616954986, "actor_target_entropy": -1.0, "actor_entropy": -0.4029313335343013, "alpha_loss": -0.0027339334474019115, "alpha_value": 0.15139526934364533, "duration": 179.37264037132263, "step": 62125}
{"episode_reward": 778.7605713378152, "episode": 498.0, "Q1 loss": 7.152044849395752, "Q2 loss": 7.075638177871704, "Mean Target Q": 693.1605883789063, "Mean Q1": 693.1531669921875, "Mean Q2": 693.1538388671875, "critic_loss": 14.227682998657226, "batch_reward": 5.820426712036133, "actor_loss": -693.8612680742817, "actor_target_entropy": -1.0, "actor_entropy": -0.34103238342269776, "alpha_loss": 0.00029001007562563303, "alpha_value": 0.1516679544794302, "duration": 177.72278761863708, "step": 62250}
{"episode_reward": 830.7832913371411, "episode": 499.0, "Q1 loss": 7.064439928054809, "Q2 loss": 7.140237691879272, "Mean Target Q": 693.6820981445312, "Mean Q1": 693.6844448242188, "Mean Q2": 693.6831147460938, "critic_loss": 14.204677673339845, "batch_reward": 5.826613388061523, "actor_loss": -694.4432964022197, "actor_target_entropy": -1.0, "actor_entropy": -0.3758049394403185, "alpha_loss": -0.002917532326786646, "alpha_value": 0.15179761956152796, "duration": 165.90607857704163, "step": 62375}
{"episode_reward": 845.06195530225, "episode": 500.0, "Q1 loss": 7.9521144599914555, "Q2 loss": 7.78966056060791, "Mean Target Q": 694.2849770507812, "Mean Q1": 694.2847138671875, "Mean Q2": 694.2838745117188, "critic_loss": 15.741774993896485, "batch_reward": 5.856183437347412, "actor_loss": -694.5658303537676, "actor_target_entropy": -1.0, "actor_entropy": -0.3532729600706408, "alpha_loss": 0.0039985560466565435, "alpha_value": 0.15164253371659536, "duration": 176.98186087608337, "step": 62500}
{"episode_reward": 826.7421834377161, "episode": 501.0, "Q1 loss": 7.106627042770386, "Q2 loss": 7.2271817150115965, "Mean Target Q": 694.4436611328125, "Mean Q1": 694.4412583007812, "Mean Q2": 694.44508984375, "critic_loss": 14.333808715820313, "batch_reward": 5.845548843383789, "actor_loss": -695.0649607824901, "actor_target_entropy": -1.0, "actor_entropy": -0.358261634906133, "alpha_loss": 0.002893003988050161, "alpha_value": 0.1513381323507975, "duration": 172.72068309783936, "step": 62625}
{"episode_reward": 840.2692840292378, "episode": 502.0, "Q1 loss": 6.949665643692017, "Q2 loss": 6.972348739624024, "Mean Target Q": 695.0080073242187, "Mean Q1": 695.00808203125, "Mean Q2": 695.0079770507813, "critic_loss": 13.922014377593994, "batch_reward": 5.866172897338867, "actor_loss": -695.2340422599547, "actor_target_entropy": -1.0, "actor_entropy": -0.3309718115675834, "alpha_loss": 0.0031076291699953856, "alpha_value": 0.1510714673025222, "duration": 168.47337007522583, "step": 62750}
{"episode_reward": 834.2828883403942, "episode": 503.0, "Q1 loss": 7.481118200302124, "Q2 loss": 7.399912412643433, "Mean Target Q": 694.9566474609375, "Mean Q1": 694.9539096679688, "Mean Q2": 694.951771484375, "critic_loss": 14.881030673980712, "batch_reward": 5.840269760131836, "actor_loss": -695.5903155614459, "actor_target_entropy": -1.0, "actor_entropy": -0.36635398675525, "alpha_loss": 0.0014484055499206223, "alpha_value": 0.15080559474065577, "duration": 162.13236117362976, "step": 62875}
{"episode_reward": 841.5136013748628, "episode": 504.0, "Q1 loss": 6.662883514404297, "Q2 loss": 6.799871490478516, "Mean Target Q": 695.6307641601562, "Mean Q1": 695.627599609375, "Mean Q2": 695.6281142578125, "critic_loss": 13.462755043029786, "batch_reward": 5.871189010620117, "actor_loss": -695.9077246881301, "actor_target_entropy": -1.0, "actor_entropy": -0.37569626444770443, "alpha_loss": -0.001697882855941932, "alpha_value": 0.15078526171592604, "duration": 171.2739713191986, "step": 63000}
{"episode_reward": 835.2320700005185, "episode": 505.0, "Q1 loss": 7.166560676574707, "Q2 loss": 7.159457841873169, "Mean Target Q": 695.8442333984375, "Mean Q1": 695.84855859375, "Mean Q2": 695.8485341796875, "critic_loss": 14.326018474578857, "batch_reward": 5.862533664703369, "actor_loss": -696.5006055075024, "actor_target_entropy": -1.0, "actor_entropy": -0.39418461209251765, "alpha_loss": -0.0016390151429241375, "alpha_value": 0.15082224783882714, "duration": 158.92553901672363, "step": 63125}
{"episode_reward": 834.0231347127739, "episode": 506.0, "Q1 loss": 6.909412036895752, "Q2 loss": 6.8377928657531735, "Mean Target Q": 695.9029565429687, "Mean Q1": 695.89333203125, "Mean Q2": 695.8945068359375, "critic_loss": 13.747204872131348, "batch_reward": 5.8438075828552245, "actor_loss": -696.5926641648815, "actor_target_entropy": -1.0, "actor_entropy": -0.3619970386066744, "alpha_loss": 0.0014715818707050094, "alpha_value": 0.1509804126712807, "duration": 163.3148012161255, "step": 63250}
{"episode_reward": 839.402204578559, "episode": 507.0, "Q1 loss": 6.149205690383911, "Q2 loss": 6.197405046463013, "Mean Target Q": 695.9194653320312, "Mean Q1": 695.9247333984375, "Mean Q2": 695.9255615234375, "critic_loss": 12.346610736846923, "batch_reward": 5.836505870819092, "actor_loss": -696.5171634734623, "actor_target_entropy": -1.0, "actor_entropy": -0.3781587027368091, "alpha_loss": -0.0010212205917692729, "alpha_value": 0.151091619072482, "duration": 165.3752520084381, "step": 63375}
{"episode_reward": 775.7764394995819, "episode": 508.0, "Q1 loss": 6.9184273223876955, "Q2 loss": 6.937262687683106, "Mean Target Q": 696.412822265625, "Mean Q1": 696.407076171875, "Mean Q2": 696.4075180664063, "critic_loss": 13.855689964294434, "batch_reward": 5.850203247070312, "actor_loss": -697.0047036447833, "actor_target_entropy": -1.0, "actor_entropy": -0.37237470428789815, "alpha_loss": 0.005957540426959073, "alpha_value": 0.15081722391112592, "duration": 178.13917183876038, "step": 63500}
{"episode_reward": 802.1263999827756, "episode": 509.0, "Q1 loss": 6.962189733505249, "Q2 loss": 7.039390790939331, "Mean Target Q": 697.020806640625, "Mean Q1": 697.0205654296875, "Mean Q2": 697.0181791992187, "critic_loss": 14.001580497741699, "batch_reward": 5.866268093109131, "actor_loss": -697.7013520740327, "actor_target_entropy": -1.0, "actor_entropy": -0.34145193298657733, "alpha_loss": 0.006245195536249657, "alpha_value": 0.15020734142854492, "duration": 157.028737783432, "step": 63625}
{"episode_reward": 830.483925883313, "episode": 510.0, "Q1 loss": 7.022300214767456, "Q2 loss": 7.044375949859619, "Mean Target Q": 697.0961567382813, "Mean Q1": 697.0916323242187, "Mean Q2": 697.0909223632813, "critic_loss": 14.066676094055175, "batch_reward": 5.852308792114258, "actor_loss": -697.7627258300781, "actor_target_entropy": -1.0, "actor_entropy": -0.3457267491086837, "alpha_loss": 0.003458017522784611, "alpha_value": 0.1497010194740028, "duration": 157.13484978675842, "step": 63750}
{"episode_reward": 774.9312928720369, "episode": 511.0, "Q1 loss": 7.314511777877808, "Q2 loss": 7.257522638320923, "Mean Target Q": 697.4539584960937, "Mean Q1": 697.4572202148438, "Mean Q2": 697.4590869140625, "critic_loss": 14.572034461975097, "batch_reward": 5.86357793045044, "actor_loss": -697.997808547247, "actor_target_entropy": -1.0, "actor_entropy": -0.36708003992126104, "alpha_loss": 0.0015481629645422337, "alpha_value": 0.14947813868667836, "duration": 166.06385612487793, "step": 63875}
{"episode_reward": 829.482211491367, "episode": 512.0, "Q1 loss": 6.137981945037842, "Q2 loss": 6.31403998374939, "Mean Target Q": 697.7990576171875, "Mean Q1": 697.7965395507813, "Mean Q2": 697.7969956054687, "critic_loss": 12.452021923065185, "batch_reward": 5.859911911010742, "actor_loss": -698.4358815839214, "actor_target_entropy": -1.0, "actor_entropy": -0.35870366663702075, "alpha_loss": 0.0038273250815578767, "alpha_value": 0.1492002291167364, "duration": 171.72077441215515, "step": 64000}
{"episode_reward": 822.6967058832505, "episode": 513.0, "Q1 loss": 7.3573038883209225, "Q2 loss": 7.371406412124633, "Mean Target Q": 697.9031630859375, "Mean Q1": 697.9046337890625, "Mean Q2": 697.9024077148438, "critic_loss": 14.728710311889648, "batch_reward": 5.862256511688233, "actor_loss": -698.6143672882564, "actor_target_entropy": -1.0, "actor_entropy": -0.355833414528105, "alpha_loss": 0.00045906928449218707, "alpha_value": 0.149132398595971, "duration": 180.90858268737793, "step": 64125}
{"episode_reward": 823.5959869927884, "episode": 514.0, "Q1 loss": 7.083607112884521, "Q2 loss": 7.2024655418396, "Mean Target Q": 698.2023989257813, "Mean Q1": 698.1955366210938, "Mean Q2": 698.1963774414063, "critic_loss": 14.28607258605957, "batch_reward": 5.856970199584961, "actor_loss": -698.6913668724799, "actor_target_entropy": -1.0, "actor_entropy": -0.38831029255543986, "alpha_loss": -0.003336924439927022, "alpha_value": 0.1490855430587, "duration": 171.83143997192383, "step": 64250}
{"episode_reward": 833.5908876111412, "episode": 515.0, "Q1 loss": 6.962680280685425, "Q2 loss": 7.027441320419311, "Mean Target Q": 698.8402231445313, "Mean Q1": 698.84321484375, "Mean Q2": 698.8423413085937, "critic_loss": 13.990121650695801, "batch_reward": 5.882001934051513, "actor_loss": -699.0764247349331, "actor_target_entropy": -1.0, "actor_entropy": -0.36659781847681316, "alpha_loss": 0.0023503857350627346, "alpha_value": 0.14921147574417967, "duration": 166.80075407028198, "step": 64375}
{"episode_reward": 828.379024656532, "episode": 516.0, "Q1 loss": 7.266426984786987, "Q2 loss": 7.250009788513184, "Mean Target Q": 698.8055766601562, "Mean Q1": 698.8061977539063, "Mean Q2": 698.806595703125, "critic_loss": 14.516436836242676, "batch_reward": 5.860002506256103, "actor_loss": -699.2033494518649, "actor_target_entropy": -1.0, "actor_entropy": -0.3886343029237563, "alpha_loss": -0.003484655367848914, "alpha_value": 0.14930383332926803, "duration": 164.2235734462738, "step": 64500}
{"episode_reward": 839.7550648842027, "episode": 517.0, "Q1 loss": 7.145754016876221, "Q2 loss": 7.143814403533936, "Mean Target Q": 698.8948989257813, "Mean Q1": 698.8860639648437, "Mean Q2": 698.8862690429687, "critic_loss": 14.289568389892578, "batch_reward": 5.8521960105896, "actor_loss": -699.5077417767237, "actor_target_entropy": -1.0, "actor_entropy": -0.3312248516650427, "alpha_loss": 0.0028488868089865836, "alpha_value": 0.14920232865095906, "duration": 156.24441361427307, "step": 64625}
{"episode_reward": 847.3281908289432, "episode": 518.0, "Q1 loss": 7.319816802978516, "Q2 loss": 7.203917604446411, "Mean Target Q": 699.4224775390625, "Mean Q1": 699.4246284179687, "Mean Q2": 699.4272202148437, "critic_loss": 14.523734409332276, "batch_reward": 5.868867710113525, "actor_loss": -699.7166364116054, "actor_target_entropy": -1.0, "actor_entropy": -0.39365823614981865, "alpha_loss": 5.512817522450801e-05, "alpha_value": 0.1492422807759781, "duration": 173.16239547729492, "step": 64750}
{"episode_reward": 832.8837152167644, "episode": 519.0, "Q1 loss": 6.54773434638977, "Q2 loss": 6.561185459136963, "Mean Target Q": 699.429537109375, "Mean Q1": 699.4237060546875, "Mean Q2": 699.4208310546875, "critic_loss": 13.10891979598999, "batch_reward": 5.868098209381103, "actor_loss": -699.8320118737599, "actor_target_entropy": -1.0, "actor_entropy": -0.3639288620343284, "alpha_loss": 0.0017452701937318558, "alpha_value": 0.14901647760384695, "duration": 186.67868328094482, "step": 64875}
{"episode_reward": 839.1341078338833, "episode": 520.0, "Q1 loss": 6.136492166519165, "Q2 loss": 6.154662317276001, "Mean Target Q": 700.1808247070312, "Mean Q1": 700.18149609375, "Mean Q2": 700.1815805664063, "critic_loss": 12.29115449142456, "batch_reward": 5.880155696868896, "actor_loss": -700.7701258505545, "actor_target_entropy": -1.0, "actor_entropy": -0.36791325336502445, "alpha_loss": 0.004497632593660044, "alpha_value": 0.1486984299079443, "step": 65000}
{"duration": 168.271231174469, "step": 65000}
{"episode_reward": 832.9416679127008, "episode": 521.0, "Q1 loss": 7.028008995056152, "Q2 loss": 6.983151309967041, "Mean Target Q": 700.3212211914063, "Mean Q1": 700.322119140625, "Mean Q2": 700.3219145507812, "critic_loss": 14.01116035079956, "batch_reward": 5.866180164337158, "actor_loss": -700.9241749596974, "actor_target_entropy": -1.0, "actor_entropy": -0.3682705471439967, "alpha_loss": 0.0010221732192717138, "alpha_value": 0.14852015083497372, "duration": 172.59718894958496, "step": 65125}
{"episode_reward": 833.8925087331376, "episode": 522.0, "Q1 loss": 6.532783012390137, "Q2 loss": 6.4838607883453365, "Mean Target Q": 701.0953725585938, "Mean Q1": 701.0895634765625, "Mean Q2": 701.0901342773437, "critic_loss": 13.016643810272218, "batch_reward": 5.905605369567871, "actor_loss": -701.4558518932712, "actor_target_entropy": -1.0, "actor_entropy": -0.3992697577322683, "alpha_loss": -0.0020953303995361974, "alpha_value": 0.14846861254335358, "duration": 168.03761625289917, "step": 65250}
{"episode_reward": 846.3409817585639, "episode": 523.0, "Q1 loss": 6.537346157073975, "Q2 loss": 6.701918209075928, "Mean Target Q": 700.7892036132813, "Mean Q1": 700.7871479492187, "Mean Q2": 700.788388671875, "critic_loss": 13.239264400482178, "batch_reward": 5.86678031539917, "actor_loss": -701.2908964611236, "actor_target_entropy": -1.0, "actor_entropy": -0.35075487929677207, "alpha_loss": 0.004070654910589967, "alpha_value": 0.14843429186618387, "duration": 162.81801295280457, "step": 65375}
{"episode_reward": 781.9575201610505, "episode": 524.0, "Q1 loss": 6.603108222961426, "Q2 loss": 6.59146473312378, "Mean Target Q": 701.2558603515625, "Mean Q1": 701.2550561523437, "Mean Q2": 701.2522299804688, "critic_loss": 13.194573020935058, "batch_reward": 5.875748222351074, "actor_loss": -702.0193343623991, "actor_target_entropy": -1.0, "actor_entropy": -0.38211531456439723, "alpha_loss": 0.0012292693248919903, "alpha_value": 0.14813670404451854, "duration": 168.37393069267273, "step": 65500}
{"episode_reward": 824.4478904546311, "episode": 525.0, "Q1 loss": 6.605936235427857, "Q2 loss": 6.769610984802246, "Mean Target Q": 701.0847104492187, "Mean Q1": 701.0796274414063, "Mean Q2": 701.0827016601562, "critic_loss": 13.375547145843505, "batch_reward": 5.857869510650635, "actor_loss": -701.6671878875248, "actor_target_entropy": -1.0, "actor_entropy": -0.37505949158517143, "alpha_loss": -0.0005743208947399306, "alpha_value": 0.14814783598690356, "duration": 172.95667266845703, "step": 65625}
{"episode_reward": 779.7698622954417, "episode": 526.0, "Q1 loss": 7.096166381835937, "Q2 loss": 7.092893894195557, "Mean Target Q": 701.6249565429688, "Mean Q1": 701.6357934570312, "Mean Q2": 701.6341201171875, "critic_loss": 14.189060287475586, "batch_reward": 5.8748526153564455, "actor_loss": -702.1955123409148, "actor_target_entropy": -1.0, "actor_entropy": -0.38121615542519477, "alpha_loss": 0.0013101814369175344, "alpha_value": 0.14807939952631788, "duration": 182.7328004837036, "step": 65750}
{"episode_reward": 838.412771648322, "episode": 527.0, "Q1 loss": 6.453892305374145, "Q2 loss": 6.475717092514038, "Mean Target Q": 702.0480161132813, "Mean Q1": 702.031224609375, "Mean Q2": 702.0332529296875, "critic_loss": 12.929609413146972, "batch_reward": 5.88562064743042, "actor_loss": -702.508544921875, "actor_target_entropy": -1.0, "actor_entropy": -0.38415418399704826, "alpha_loss": 0.0006762794385265027, "alpha_value": 0.1480213736420175, "duration": 185.7692391872406, "step": 65875}
{"episode_reward": 775.1206678512558, "episode": 528.0, "Q1 loss": 6.991659818649292, "Q2 loss": 7.101468879699707, "Mean Target Q": 702.2684516601563, "Mean Q1": 702.273349609375, "Mean Q2": 702.2742407226563, "critic_loss": 14.09312866973877, "batch_reward": 5.876425365447998, "actor_loss": -702.8064220797631, "actor_target_entropy": -1.0, "actor_entropy": -0.3778523423017994, "alpha_loss": 0.004143268459536616, "alpha_value": 0.14782251630820345, "duration": 187.9199676513672, "step": 66000}
{"episode_reward": 832.1223714013689, "episode": 529.0, "Q1 loss": 6.664472036361694, "Q2 loss": 6.654873844146729, "Mean Target Q": 702.4958642578125, "Mean Q1": 702.4972294921874, "Mean Q2": 702.4933720703125, "critic_loss": 13.319345825195313, "batch_reward": 5.879323848724365, "actor_loss": -702.966814313616, "actor_target_entropy": -1.0, "actor_entropy": -0.3746665635752299, "alpha_loss": 0.00037490009027163663, "alpha_value": 0.14759317080546452, "duration": 139.44648718833923, "step": 66125}
{"episode_reward": 829.8398609280642, "episode": 530.0, "Q1 loss": 6.93301805305481, "Q2 loss": 6.930560115814209, "Mean Target Q": 702.8306625976562, "Mean Q1": 702.8373403320312, "Mean Q2": 702.839220703125, "critic_loss": 13.863578189849854, "batch_reward": 5.887263687133789, "actor_loss": -703.1476410896547, "actor_target_entropy": -1.0, "actor_entropy": -0.3927730538191334, "alpha_loss": -0.001628855034904254, "alpha_value": 0.1475623940924148, "duration": 148.1475796699524, "step": 66250}
{"episode_reward": 821.8783894489536, "episode": 531.0, "Q1 loss": 6.862394676208496, "Q2 loss": 6.909309995651245, "Mean Target Q": 703.0332978515625, "Mean Q1": 703.0223051757813, "Mean Q2": 703.021435546875, "critic_loss": 13.77170468902588, "batch_reward": 5.882170272827149, "actor_loss": -703.6882333906871, "actor_target_entropy": -1.0, "actor_entropy": -0.3751379828604441, "alpha_loss": 0.0002433429527584286, "alpha_value": 0.14777785767939217, "duration": 165.23350477218628, "step": 66375}
{"episode_reward": 843.5643703364159, "episode": 532.0, "Q1 loss": 6.31693994140625, "Q2 loss": 6.447200527191162, "Mean Target Q": 703.363384765625, "Mean Q1": 703.3621704101563, "Mean Q2": 703.3631137695312, "critic_loss": 12.764140518188476, "batch_reward": 5.885640922546386, "actor_loss": -703.8693434192288, "actor_target_entropy": -1.0, "actor_entropy": -0.38914419902909186, "alpha_loss": 0.0018264277905766521, "alpha_value": 0.14760878732574748, "duration": 150.37980842590332, "step": 66500}
{"episode_reward": 831.8763767677542, "episode": 533.0, "Q1 loss": 6.9404029922485355, "Q2 loss": 6.886760465621948, "Mean Target Q": 703.3692236328125, "Mean Q1": 703.365998046875, "Mean Q2": 703.3647451171875, "critic_loss": 13.827163497924804, "batch_reward": 5.872515396118164, "actor_loss": -704.1180768694196, "actor_target_entropy": -1.0, "actor_entropy": -0.37008264377003625, "alpha_loss": -0.0009724093926331353, "alpha_value": 0.14762944659829852, "duration": 143.00199627876282, "step": 66625}
{"episode_reward": 780.1746015324247, "episode": 534.0, "Q1 loss": 7.057190340042114, "Q2 loss": 7.11897785949707, "Mean Target Q": 703.6428315429688, "Mean Q1": 703.6448515625, "Mean Q2": 703.6444731445313, "critic_loss": 14.176168178558349, "batch_reward": 5.877945037841797, "actor_loss": -704.5756009009576, "actor_target_entropy": -1.0, "actor_entropy": -0.37809211015701294, "alpha_loss": 0.0004917165778967883, "alpha_value": 0.14760653503243348, "duration": 130.75577473640442, "step": 66750}
{"episode_reward": 806.9690045179686, "episode": 535.0, "Q1 loss": 7.12130345916748, "Q2 loss": 7.001477180480957, "Mean Target Q": 704.385521484375, "Mean Q1": 704.3898876953125, "Mean Q2": 704.3922895507812, "critic_loss": 14.122780620574952, "batch_reward": 5.912566616058349, "actor_loss": -704.9910481770834, "actor_target_entropy": -1.0, "actor_entropy": -0.3666283048334576, "alpha_loss": 0.0033427562475914045, "alpha_value": 0.14739105217350876, "duration": 143.19982433319092, "step": 66875}
{"episode_reward": 776.0798496781284, "episode": 536.0, "Q1 loss": 6.762425325393677, "Q2 loss": 6.82174658203125, "Mean Target Q": 704.0277392578125, "Mean Q1": 704.018734375, "Mean Q2": 704.016869140625, "critic_loss": 13.584171882629395, "batch_reward": 5.877186336517334, "actor_loss": -704.6622373519406, "actor_target_entropy": -1.0, "actor_entropy": -0.42891414367383524, "alpha_loss": -0.0024350377178991274, "alpha_value": 0.1473784562651354, "duration": 146.69012093544006, "step": 67000}
{"episode_reward": 819.5258932806044, "episode": 537.0, "Q1 loss": 6.873247072219849, "Q2 loss": 6.835377456665039, "Mean Target Q": 704.4218803710937, "Mean Q1": 704.4187578125, "Mean Q2": 704.4195541992187, "critic_loss": 13.708624542236327, "batch_reward": 5.88163705444336, "actor_loss": -704.7499622163318, "actor_target_entropy": -1.0, "actor_entropy": -0.363455862752975, "alpha_loss": 0.0016993162756238783, "alpha_value": 0.14733588735372863, "duration": 124.79425621032715, "step": 67125}
{"episode_reward": 830.9978196527398, "episode": 538.0, "Q1 loss": 7.10222908782959, "Q2 loss": 7.124248151779175, "Mean Target Q": 704.92901953125, "Mean Q1": 704.9308681640625, "Mean Q2": 704.93183984375, "critic_loss": 14.226477233886719, "batch_reward": 5.89421688079834, "actor_loss": -705.3643720073085, "actor_target_entropy": -1.0, "actor_entropy": -0.3386032057385291, "alpha_loss": 0.005351017341919003, "alpha_value": 0.1470521260179577, "duration": 138.9129581451416, "step": 67250}
{"episode_reward": 820.3882708158304, "episode": 539.0, "Q1 loss": 6.982363519668579, "Q2 loss": 7.036294523239135, "Mean Target Q": 705.1532944335937, "Mean Q1": 705.1517690429688, "Mean Q2": 705.1528510742188, "critic_loss": 14.018657989501953, "batch_reward": 5.895291072845459, "actor_loss": -705.3880489288814, "actor_target_entropy": -1.0, "actor_entropy": -0.3815661730274322, "alpha_loss": 0.0029711823038283793, "alpha_value": 0.1466502912784371, "duration": 139.3051950931549, "step": 67375}
{"episode_reward": 822.3753988867574, "episode": 540.0, "Q1 loss": 6.589720851898194, "Q2 loss": 6.606455696105957, "Mean Target Q": 705.3002470703125, "Mean Q1": 705.2965849609375, "Mean Q2": 705.2951176757813, "critic_loss": 13.196176570892334, "batch_reward": 5.892976036071778, "actor_loss": -705.6173834031628, "actor_target_entropy": -1.0, "actor_entropy": -0.36977821059765353, "alpha_loss": -5.5165321100503206e-05, "alpha_value": 0.1465815310038084, "duration": 156.24100875854492, "step": 67500}
{"episode_reward": 837.2900050931673, "episode": 541.0, "Q1 loss": 6.544391241073608, "Q2 loss": 6.544315618515014, "Mean Target Q": 705.6978056640625, "Mean Q1": 705.69792578125, "Mean Q2": 705.697833984375, "critic_loss": 13.088706813812255, "batch_reward": 5.9122857704162595, "actor_loss": -706.2657625713045, "actor_target_entropy": -1.0, "actor_entropy": -0.3735879243366302, "alpha_loss": 0.0061300209324274746, "alpha_value": 0.1461946171156081, "duration": 139.860689163208, "step": 67625}
{"episode_reward": 829.9204578024213, "episode": 542.0, "Q1 loss": 6.956139070510864, "Q2 loss": 6.98066533279419, "Mean Target Q": 705.7923559570313, "Mean Q1": 705.7903134765625, "Mean Q2": 705.7911752929688, "critic_loss": 13.93680445098877, "batch_reward": 5.892706130981446, "actor_loss": -706.4113946730091, "actor_target_entropy": -1.0, "actor_entropy": -0.37834413445764975, "alpha_loss": -0.0005570326541219988, "alpha_value": 0.14583321931255383, "duration": 164.33720517158508, "step": 67750}
{"episode_reward": 834.0941833765114, "episode": 543.0, "Q1 loss": 6.769478994369507, "Q2 loss": 6.744627202987671, "Mean Target Q": 705.7058149414063, "Mean Q1": 705.70189453125, "Mean Q2": 705.7014565429688, "critic_loss": 13.51410610961914, "batch_reward": 5.882834484100342, "actor_loss": -706.2008095393105, "actor_target_entropy": -1.0, "actor_entropy": -0.36366491776610177, "alpha_loss": 0.0022079262897253984, "alpha_value": 0.1458527628614322, "duration": 154.09449362754822, "step": 67875}
{"episode_reward": 842.0800266034109, "episode": 544.0, "Q1 loss": 6.731559940338135, "Q2 loss": 6.7585776309967045, "Mean Target Q": 706.3381728515625, "Mean Q1": 706.3424453125, "Mean Q2": 706.3404575195312, "critic_loss": 13.490137603759766, "batch_reward": 5.8968247718811035, "actor_loss": -706.8965631300404, "actor_target_entropy": -1.0, "actor_entropy": -0.3825272504360445, "alpha_loss": 1.8188813438398704e-05, "alpha_value": 0.14580351756433066, "duration": 125.63906335830688, "step": 68000}
{"episode_reward": 784.6353367861421, "episode": 545.0, "Q1 loss": 6.880173080444336, "Q2 loss": 6.873742349624634, "Mean Target Q": 706.5276762695313, "Mean Q1": 706.5237099609375, "Mean Q2": 706.5266723632812, "critic_loss": 13.753915420532227, "batch_reward": 5.9047138824462895, "actor_loss": -706.9181906079489, "actor_target_entropy": -1.0, "actor_entropy": -0.394426123963462, "alpha_loss": 0.0012231701412164266, "alpha_value": 0.14571046445556302, "duration": 120.45407056808472, "step": 68125}
{"episode_reward": 847.2928940695753, "episode": 546.0, "Q1 loss": 7.465158891677857, "Q2 loss": 7.472179275512695, "Mean Target Q": 707.0091958007813, "Mean Q1": 707.0069453125, "Mean Q2": 707.0037275390625, "critic_loss": 14.937338130950927, "batch_reward": 5.918906982421875, "actor_loss": -707.619379843435, "actor_target_entropy": -1.0, "actor_entropy": -0.35604153140898676, "alpha_loss": 0.007078133698087186, "alpha_value": 0.14524133392077515, "duration": 131.0026979446411, "step": 68250}
{"episode_reward": 831.4627118252757, "episode": 547.0, "Q1 loss": 6.501262317657471, "Q2 loss": 6.362152729034424, "Mean Target Q": 706.907142578125, "Mean Q1": 706.9051010742188, "Mean Q2": 706.9080107421875, "critic_loss": 12.863415046691895, "batch_reward": 5.900131839752198, "actor_loss": -707.3516729445685, "actor_target_entropy": -1.0, "actor_entropy": -0.3601905433904557, "alpha_loss": 0.0022202050867712216, "alpha_value": 0.14481159585876682, "duration": 145.8035798072815, "step": 68375}
{"episode_reward": 836.6194656890603, "episode": 548.0, "Q1 loss": 6.135783296585083, "Q2 loss": 6.038774887084961, "Mean Target Q": 707.2732231445312, "Mean Q1": 707.2752905273437, "Mean Q2": 707.2742138671875, "critic_loss": 12.17455814743042, "batch_reward": 5.90625581741333, "actor_loss": -707.9314240486391, "actor_target_entropy": -1.0, "actor_entropy": -0.39046407563071095, "alpha_loss": 0.00021277685300447047, "alpha_value": 0.14461355705034445, "duration": 142.2897503376007, "step": 68500}
{"episode_reward": 845.6481181982118, "episode": 549.0, "Q1 loss": 6.650423824310303, "Q2 loss": 6.736407075881958, "Mean Target Q": 707.4537836914062, "Mean Q1": 707.4494956054688, "Mean Q2": 707.449173828125, "critic_loss": 13.386830905914307, "batch_reward": 5.913945743560791, "actor_loss": -707.9371473524305, "actor_target_entropy": -1.0, "actor_entropy": -0.36266055703163147, "alpha_loss": 0.003931980605961548, "alpha_value": 0.14443700268663992, "duration": 124.81682395935059, "step": 68625}
{"episode_reward": 840.173930285858, "episode": 550.0, "Q1 loss": 7.173347665786743, "Q2 loss": 7.33206322479248, "Mean Target Q": 708.1259077148437, "Mean Q1": 708.1277509765625, "Mean Q2": 708.1284282226562, "critic_loss": 14.505410881042481, "batch_reward": 5.927271842956543, "actor_loss": -708.4169311523438, "actor_target_entropy": -1.0, "actor_entropy": -0.3723547314443896, "alpha_loss": 0.005933547983013634, "alpha_value": 0.1440735601654104, "duration": 129.46770358085632, "step": 68750}
{"episode_reward": 665.3174312384554, "episode": 551.0, "Q1 loss": 7.175238573074341, "Q2 loss": 7.022734731674194, "Mean Target Q": 707.8777836914062, "Mean Q1": 707.8751865234375, "Mean Q2": 707.8741655273437, "critic_loss": 14.197973274230957, "batch_reward": 5.904314586639404, "actor_loss": -708.4874267578125, "actor_target_entropy": -1.0, "actor_entropy": -0.38216015318083385, "alpha_loss": 0.0007760389347649401, "alpha_value": 0.14361056308428347, "duration": 168.44763779640198, "step": 68875}
{"episode_reward": 838.7959710697374, "episode": 552.0, "Q1 loss": 6.880393220901489, "Q2 loss": 6.846704395294189, "Mean Target Q": 708.4137827148437, "Mean Q1": 708.4118046875, "Mean Q2": 708.41150390625, "critic_loss": 13.727097732543946, "batch_reward": 5.915963455200195, "actor_loss": -708.7807233256679, "actor_target_entropy": -1.0, "actor_entropy": -0.3612504377961159, "alpha_loss": -0.0006780577372879752, "alpha_value": 0.14370028988680147, "duration": 156.4868233203888, "step": 69000}
{"episode_reward": 836.5551223865672, "episode": 553.0, "Q1 loss": 7.559540058135986, "Q2 loss": 7.5860206985473635, "Mean Target Q": 708.5490209960938, "Mean Q1": 708.5520283203125, "Mean Q2": 708.5518774414063, "critic_loss": 15.145560836791992, "batch_reward": 5.906034126281738, "actor_loss": -708.931900266617, "actor_target_entropy": -1.0, "actor_entropy": -0.3982873227861192, "alpha_loss": 0.0017597670666873455, "alpha_value": 0.14364404964526342, "duration": 145.62254285812378, "step": 69125}
{"episode_reward": 779.3914045350173, "episode": 554.0, "Q1 loss": 5.955242658615112, "Q2 loss": 5.994966875076294, "Mean Target Q": 708.8585131835938, "Mean Q1": 708.854064453125, "Mean Q2": 708.8554135742188, "critic_loss": 11.950209575653076, "batch_reward": 5.906565734863281, "actor_loss": -709.5047902753277, "actor_target_entropy": -1.0, "actor_entropy": -0.4116178909617086, "alpha_loss": -0.0008929624990184581, "alpha_value": 0.14367475888967246, "duration": 157.90255880355835, "step": 69250}
{"episode_reward": 803.2876106260255, "episode": 555.0, "Q1 loss": 6.739425437927246, "Q2 loss": 6.709691078186035, "Mean Target Q": 708.6120229492187, "Mean Q1": 708.6132666015625, "Mean Q2": 708.6120317382813, "critic_loss": 13.449116519927978, "batch_reward": 5.898980865478515, "actor_loss": -708.9878762865824, "actor_target_entropy": -1.0, "actor_entropy": -0.3536859168892815, "alpha_loss": 0.0034940689321725613, "alpha_value": 0.14348491863548227, "duration": 130.32733798027039, "step": 69375}
{"episode_reward": 835.829494809366, "episode": 556.0, "Q1 loss": 6.95827649307251, "Q2 loss": 6.997205589294434, "Mean Target Q": 708.8970424804687, "Mean Q1": 708.8941147460938, "Mean Q2": 708.893287109375, "critic_loss": 13.95548205947876, "batch_reward": 5.898808986663818, "actor_loss": -709.4003601074219, "actor_target_entropy": -1.0, "actor_entropy": -0.3669700233205672, "alpha_loss": 0.0029200201426001805, "alpha_value": 0.14314503485963204, "duration": 125.74839782714844, "step": 69500}
{"episode_reward": 844.1535118853855, "episode": 557.0, "Q1 loss": 7.0957779083251955, "Q2 loss": 7.15206833076477, "Mean Target Q": 709.4674306640625, "Mean Q1": 709.46972265625, "Mean Q2": 709.4732275390625, "critic_loss": 14.247846302032471, "batch_reward": 5.917972148895264, "actor_loss": -710.0832102942088, "actor_target_entropy": -1.0, "actor_entropy": -0.3747389926796868, "alpha_loss": 0.0016052063724528703, "alpha_value": 0.14290908957808768, "duration": 153.26020288467407, "step": 69625}
{"episode_reward": 840.0292494465551, "episode": 558.0, "Q1 loss": 6.3782644462585445, "Q2 loss": 6.3496839046478275, "Mean Target Q": 709.2214653320312, "Mean Q1": 709.2120771484375, "Mean Q2": 709.2102465820312, "critic_loss": 12.727948383331299, "batch_reward": 5.892828044891357, "actor_loss": -709.9711244644657, "actor_target_entropy": -1.0, "actor_entropy": -0.39675471282774405, "alpha_loss": -0.00023647474928668912, "alpha_value": 0.142814418375523, "duration": 145.38933753967285, "step": 69750}
{"episode_reward": 844.3513712961211, "episode": 559.0, "Q1 loss": 6.487141042709351, "Q2 loss": 6.498325813293457, "Mean Target Q": 709.6965756835938, "Mean Q1": 709.6961640625, "Mean Q2": 709.6964638671875, "critic_loss": 12.98546688079834, "batch_reward": 5.918702220916748, "actor_loss": -710.336173890129, "actor_target_entropy": -1.0, "actor_entropy": -0.385454983938308, "alpha_loss": -0.0021909086942850124, "alpha_value": 0.14294536760264823, "duration": 137.85148692131042, "step": 69875}
{"episode_reward": 814.2241943114868, "episode": 560.0, "Q1 loss": 6.56270751953125, "Q2 loss": 6.638078895568848, "Mean Target Q": 710.1689130859374, "Mean Q1": 710.1653286132813, "Mean Q2": 710.1641723632813, "critic_loss": 13.200786415100097, "batch_reward": 5.930927993774414, "actor_loss": -710.9357565602949, "actor_target_entropy": -1.0, "actor_entropy": -0.36491791375221744, "alpha_loss": 0.0014811094395906453, "alpha_value": 0.14297944023282505, "step": 70000}
{"duration": 134.68016910552979, "step": 70000}
{"episode_reward": 839.6080509801197, "episode": 561.0, "Q1 loss": 7.108763370513916, "Q2 loss": 7.09173980140686, "Mean Target Q": 710.0253579101562, "Mean Q1": 710.0299379882813, "Mean Q2": 710.0321220703125, "critic_loss": 14.200503139495849, "batch_reward": 5.905066680908203, "actor_loss": -710.4580678788442, "actor_target_entropy": -1.0, "actor_entropy": -0.39772166382698787, "alpha_loss": -0.0024042561232659313, "alpha_value": 0.14296435023790563, "duration": 134.1864447593689, "step": 70125}
{"episode_reward": 842.0804558602916, "episode": 562.0, "Q1 loss": 6.142930925369263, "Q2 loss": 6.119327745437622, "Mean Target Q": 710.6514653320312, "Mean Q1": 710.6507993164063, "Mean Q2": 710.6478154296875, "critic_loss": 12.262258701324463, "batch_reward": 5.922110828399658, "actor_loss": -711.4547444005167, "actor_target_entropy": -1.0, "actor_entropy": -0.37912750244140625, "alpha_loss": 0.0012072498493287112, "alpha_value": 0.14309859111023487, "duration": 144.356627702713, "step": 70250}
{"episode_reward": 832.3911371329676, "episode": 563.0, "Q1 loss": 6.304439418792724, "Q2 loss": 6.3432118015289305, "Mean Target Q": 710.92158984375, "Mean Q1": 710.91286328125, "Mean Q2": 710.9170541992188, "critic_loss": 12.647651191711425, "batch_reward": 5.92569229888916, "actor_loss": -711.7079012431795, "actor_target_entropy": -1.0, "actor_entropy": -0.38950269893994405, "alpha_loss": 0.005691094056052703, "alpha_value": 0.14279751821482856, "duration": 152.96309804916382, "step": 70375}
{"episode_reward": 818.8222548310423, "episode": 564.0, "Q1 loss": 6.6692715225219725, "Q2 loss": 6.533224546432495, "Mean Target Q": 710.6388603515625, "Mean Q1": 710.639015625, "Mean Q2": 710.6368920898437, "critic_loss": 13.202496116638184, "batch_reward": 5.909505561828613, "actor_loss": -711.0961973128781, "actor_target_entropy": -1.0, "actor_entropy": -0.3674730942133934, "alpha_loss": 0.004048602937179948, "alpha_value": 0.14221334691899, "duration": 145.35587644577026, "step": 70500}
{"episode_reward": 830.4681053877636, "episode": 565.0, "Q1 loss": 6.8334280872344975, "Q2 loss": 6.993201456069946, "Mean Target Q": 711.1469619140624, "Mean Q1": 711.1497685546875, "Mean Q2": 711.1524482421875, "critic_loss": 13.826629524230958, "batch_reward": 5.920807857513427, "actor_loss": -711.662349640377, "actor_target_entropy": -1.0, "actor_entropy": -0.3816962182994873, "alpha_loss": 0.00228109814056624, "alpha_value": 0.14204078015199584, "duration": 150.53641176223755, "step": 70625}
{"episode_reward": 832.784879733778, "episode": 566.0, "Q1 loss": 6.447779689788819, "Q2 loss": 6.454335609436035, "Mean Target Q": 711.3564165039063, "Mean Q1": 711.3553359375, "Mean Q2": 711.353271484375, "critic_loss": 12.902115303039551, "batch_reward": 5.921182376861572, "actor_loss": -711.8363361973917, "actor_target_entropy": -1.0, "actor_entropy": -0.38165628285177294, "alpha_loss": 0.004036189971356502, "alpha_value": 0.14159655815487032, "duration": 149.52231168746948, "step": 70750}
{"episode_reward": 837.2486736218497, "episode": 567.0, "Q1 loss": 6.712253789901734, "Q2 loss": 6.780621301651001, "Mean Target Q": 711.706869140625, "Mean Q1": 711.7088081054687, "Mean Q2": 711.707494140625, "critic_loss": 13.492875068664551, "batch_reward": 5.927307025909424, "actor_loss": -712.6276807028149, "actor_target_entropy": -1.0, "actor_entropy": -0.39852687148820787, "alpha_loss": 0.0013123241951689124, "alpha_value": 0.1414456908641863, "duration": 125.69176363945007, "step": 70875}
{"episode_reward": 840.210089475107, "episode": 568.0, "Q1 loss": 7.025061193466186, "Q2 loss": 7.119809083938598, "Mean Target Q": 711.5860590820313, "Mean Q1": 711.5847065429688, "Mean Q2": 711.5854409179688, "critic_loss": 14.144870296478272, "batch_reward": 5.9129287109375, "actor_loss": -711.8719708842616, "actor_target_entropy": -1.0, "actor_entropy": -0.3713988051299126, "alpha_loss": 0.001407544735083056, "alpha_value": 0.14130466867753647, "duration": 135.12450242042542, "step": 71000}
{"episode_reward": 840.6489102713916, "episode": 569.0, "Q1 loss": 6.6259780006408695, "Q2 loss": 6.571945348739624, "Mean Target Q": 711.8684360351563, "Mean Q1": 711.8631396484375, "Mean Q2": 711.8646381835938, "critic_loss": 13.197923301696777, "batch_reward": 5.923333423614502, "actor_loss": -712.4595133463541, "actor_target_entropy": -1.0, "actor_entropy": -0.3880120463787563, "alpha_loss": 0.00037321216973756986, "alpha_value": 0.14122924608929155, "duration": 145.39887881278992, "step": 71125}
{"episode_reward": 778.9488014245842, "episode": 570.0, "Q1 loss": 7.433559417724609, "Q2 loss": 7.301413150787353, "Mean Target Q": 712.1269560546875, "Mean Q1": 712.11594921875, "Mean Q2": 712.1152236328124, "critic_loss": 14.734972583770752, "batch_reward": 5.922464900970459, "actor_loss": -712.3073061050907, "actor_target_entropy": -1.0, "actor_entropy": -0.37991131073044193, "alpha_loss": 0.00143204846667246, "alpha_value": 0.14120772586000885, "duration": 146.83457684516907, "step": 71250}
{"episode_reward": 835.0339394911225, "episode": 571.0, "Q1 loss": 7.399924926757812, "Q2 loss": 7.335883480072021, "Mean Target Q": 712.2189829101562, "Mean Q1": 712.2331279296875, "Mean Q2": 712.2322153320313, "critic_loss": 14.735808391571044, "batch_reward": 5.919510421752929, "actor_loss": -712.8343244280134, "actor_target_entropy": -1.0, "actor_entropy": -0.40214029664085027, "alpha_loss": -0.0015948640749908038, "alpha_value": 0.1410510581109867, "duration": 141.06239318847656, "step": 71375}
{"episode_reward": 847.8174016293015, "episode": 572.0, "Q1 loss": 7.190673599243164, "Q2 loss": 7.222436580657959, "Mean Target Q": 712.3786821289062, "Mean Q1": 712.3735131835938, "Mean Q2": 712.3752114257812, "critic_loss": 14.413110214233399, "batch_reward": 5.918860294342041, "actor_loss": -712.9000962780368, "actor_target_entropy": -1.0, "actor_entropy": -0.3866006616623171, "alpha_loss": 0.0018882423661829484, "alpha_value": 0.1411214053928474, "duration": 149.29222702980042, "step": 71500}
{"episode_reward": 775.2176385002306, "episode": 573.0, "Q1 loss": 7.310204402923584, "Q2 loss": 7.315543474197388, "Mean Target Q": 712.5336176757812, "Mean Q1": 712.5369624023438, "Mean Q2": 712.5365654296875, "critic_loss": 14.62574787902832, "batch_reward": 5.923849388122559, "actor_loss": -712.8275940910219, "actor_target_entropy": -1.0, "actor_entropy": -0.3933714382232182, "alpha_loss": 0.00048058751475302475, "alpha_value": 0.14092324831579303, "duration": 146.69261980056763, "step": 71625}
{"episode_reward": 845.572937414074, "episode": 574.0, "Q1 loss": 6.533145189285278, "Q2 loss": 6.519989175796509, "Mean Target Q": 713.3118759765625, "Mean Q1": 713.3020659179688, "Mean Q2": 713.3009223632813, "critic_loss": 13.053134384155273, "batch_reward": 5.958986679077149, "actor_loss": -713.6468417259955, "actor_target_entropy": -1.0, "actor_entropy": -0.38757944155123925, "alpha_loss": 0.0001484682866101784, "alpha_value": 0.14089201577288032, "duration": 146.13373470306396, "step": 71750}
{"episode_reward": 833.9587938317518, "episode": 575.0, "Q1 loss": 6.59093306350708, "Q2 loss": 6.599851648330689, "Mean Target Q": 713.2070541992188, "Mean Q1": 713.20505078125, "Mean Q2": 713.2064643554687, "critic_loss": 13.190784679412841, "batch_reward": 5.918822784423828, "actor_loss": -713.6404331752232, "actor_target_entropy": -1.0, "actor_entropy": -0.40310137328647433, "alpha_loss": 0.001025345289177956, "alpha_value": 0.14086778263934918, "duration": 152.17676711082458, "step": 71875}
{"episode_reward": 840.7061861282059, "episode": 576.0, "Q1 loss": 6.517361827850342, "Q2 loss": 6.6308733825683595, "Mean Target Q": 713.2129848632812, "Mean Q1": 713.21814453125, "Mean Q2": 713.2175747070313, "critic_loss": 13.148235172271729, "batch_reward": 5.939287975311279, "actor_loss": -713.6935838268649, "actor_target_entropy": -1.0, "actor_entropy": -0.42220644845116523, "alpha_loss": -0.004288890678811098, "alpha_value": 0.14114410412166928, "duration": 146.02933311462402, "step": 72000}
{"episode_reward": 771.4230486320209, "episode": 577.0, "Q1 loss": 6.501257318496704, "Q2 loss": 6.478331996917724, "Mean Target Q": 713.632052734375, "Mean Q1": 713.6295678710937, "Mean Q2": 713.6268168945312, "critic_loss": 12.979589328765869, "batch_reward": 5.938330429077149, "actor_loss": -714.2600630502852, "actor_target_entropy": -1.0, "actor_entropy": -0.37360107472964693, "alpha_loss": 0.005738386880635979, "alpha_value": 0.14098963121113645, "duration": 159.39121961593628, "step": 72125}
{"episode_reward": 831.4997796436566, "episode": 578.0, "Q1 loss": 6.48911569595337, "Q2 loss": 6.5830018463134765, "Mean Target Q": 713.6974287109375, "Mean Q1": 713.6941840820313, "Mean Q2": 713.6943857421875, "critic_loss": 13.072117538452149, "batch_reward": 5.92885457611084, "actor_loss": -714.1625740297379, "actor_target_entropy": -1.0, "actor_entropy": -0.4264313852594745, "alpha_loss": 0.001123375745655428, "alpha_value": 0.14068008528609877, "duration": 142.5251977443695, "step": 72250}
{"episode_reward": 822.8493734369162, "episode": 579.0, "Q1 loss": 7.057354406356811, "Q2 loss": 6.973211017608643, "Mean Target Q": 713.8081552734375, "Mean Q1": 713.8012026367187, "Mean Q2": 713.8037451171875, "critic_loss": 14.030565410614013, "batch_reward": 5.929912460327149, "actor_loss": -714.1644674634176, "actor_target_entropy": -1.0, "actor_entropy": -0.38991597815165446, "alpha_loss": 0.0007617547405913235, "alpha_value": 0.14050239663794237, "duration": 144.0282461643219, "step": 72375}
{"episode_reward": 819.1377287446334, "episode": 580.0, "Q1 loss": 6.97605438041687, "Q2 loss": 6.994523372650146, "Mean Target Q": 713.7497670898438, "Mean Q1": 713.7518603515625, "Mean Q2": 713.7505180664062, "critic_loss": 13.970577732086182, "batch_reward": 5.919950378417969, "actor_loss": -714.5968942949848, "actor_target_entropy": -1.0, "actor_entropy": -0.3562458864142818, "alpha_loss": 0.006345514320738373, "alpha_value": 0.1401754129604271, "duration": 147.68819069862366, "step": 72500}
{"episode_reward": 833.1137459554694, "episode": 581.0, "Q1 loss": 6.607393655776978, "Q2 loss": 6.7014194736480714, "Mean Target Q": 714.0918911132812, "Mean Q1": 714.096255859375, "Mean Q2": 714.0965024414063, "critic_loss": 13.308813179016113, "batch_reward": 5.924981845855713, "actor_loss": -714.3975975399926, "actor_target_entropy": -1.0, "actor_entropy": -0.4062008077190036, "alpha_loss": -0.00226814726123675, "alpha_value": 0.14006251740263945, "duration": 146.03938126564026, "step": 72625}
{"episode_reward": 779.3674386182605, "episode": 582.0, "Q1 loss": 7.094604791641236, "Q2 loss": 7.076559480667115, "Mean Target Q": 715.0024467773437, "Mean Q1": 714.9952407226563, "Mean Q2": 714.9938569335937, "critic_loss": 14.171164276123047, "batch_reward": 5.973162998199463, "actor_loss": -715.4779623708417, "actor_target_entropy": -1.0, "actor_entropy": -0.42116381179901863, "alpha_loss": 0.0021337051312589356, "alpha_value": 0.1400327099516445, "duration": 145.86408257484436, "step": 72750}
{"episode_reward": 837.1377841799741, "episode": 583.0, "Q1 loss": 6.752558238983155, "Q2 loss": 6.717168952941894, "Mean Target Q": 714.7277846679688, "Mean Q1": 714.7287709960938, "Mean Q2": 714.7298442382812, "critic_loss": 13.469727199554443, "batch_reward": 5.940053848266602, "actor_loss": -715.2731236049107, "actor_target_entropy": -1.0, "actor_entropy": -0.41247335312858463, "alpha_loss": 0.0009959770647424554, "alpha_value": 0.13984113194353112, "duration": 149.40962672233582, "step": 72875}
{"episode_reward": 841.1548325247282, "episode": 584.0, "Q1 loss": 6.18480694770813, "Q2 loss": 6.127192903518677, "Mean Target Q": 715.2106538085937, "Mean Q1": 715.2060595703125, "Mean Q2": 715.2061235351563, "critic_loss": 12.311999862670898, "batch_reward": 5.9652675361633305, "actor_loss": -715.9754175986013, "actor_target_entropy": -1.0, "actor_entropy": -0.3996846430724667, "alpha_loss": 0.0018857744064242129, "alpha_value": 0.1396644087057009, "duration": 145.4562029838562, "step": 73000}
{"episode_reward": 831.0592232957345, "episode": 585.0, "Q1 loss": 6.244521339416504, "Q2 loss": 6.120469245910645, "Mean Target Q": 715.21776171875, "Mean Q1": 715.2203129882812, "Mean Q2": 715.2232626953125, "critic_loss": 12.364990612030029, "batch_reward": 5.939540660858154, "actor_loss": -715.4559897770957, "actor_target_entropy": -1.0, "actor_entropy": -0.4189018356421637, "alpha_loss": 0.00024939450575777936, "alpha_value": 0.13966432687796854, "duration": 148.17555856704712, "step": 73125}
{"episode_reward": 820.437945028217, "episode": 586.0, "Q1 loss": 6.3337649059295655, "Q2 loss": 6.427656656265259, "Mean Target Q": 715.5167983398437, "Mean Q1": 715.517537109375, "Mean Q2": 715.5158100585937, "critic_loss": 12.761421535491943, "batch_reward": 5.963669132232666, "actor_loss": -715.9037209787676, "actor_target_entropy": -1.0, "actor_entropy": -0.41149330283364943, "alpha_loss": 2.0412213709806244e-05, "alpha_value": 0.13960440915932334, "duration": 151.3377525806427, "step": 73250}
{"episode_reward": 774.734719805094, "episode": 587.0, "Q1 loss": 6.917442018508911, "Q2 loss": 6.9308296585083005, "Mean Target Q": 715.800345703125, "Mean Q1": 715.7944848632812, "Mean Q2": 715.7958461914062, "critic_loss": 13.848271648406982, "batch_reward": 5.951805507659912, "actor_loss": -716.350082155258, "actor_target_entropy": -1.0, "actor_entropy": -0.43871192988895236, "alpha_loss": -0.0008628638904719125, "alpha_value": 0.13960025428179398, "duration": 141.2181613445282, "step": 73375}
{"episode_reward": 831.5526488599148, "episode": 588.0, "Q1 loss": 7.099443765640259, "Q2 loss": 6.993506174087525, "Mean Target Q": 715.7837485351563, "Mean Q1": 715.7813305664063, "Mean Q2": 715.7800576171875, "critic_loss": 14.09294998550415, "batch_reward": 5.936382873535156, "actor_loss": -716.3522368400328, "actor_target_entropy": -1.0, "actor_entropy": -0.3998753394811384, "alpha_loss": 0.006183750777234954, "alpha_value": 0.13947021698745107, "duration": 140.726478099823, "step": 73500}
{"episode_reward": 707.1674073048471, "episode": 589.0, "Q1 loss": 6.523243482589722, "Q2 loss": 6.628843656539917, "Mean Target Q": 716.2249506835938, "Mean Q1": 716.227791015625, "Mean Q2": 716.225916015625, "critic_loss": 13.152087169647217, "batch_reward": 5.956778369903565, "actor_loss": -716.7608032226562, "actor_target_entropy": -1.0, "actor_entropy": -0.41092528379152693, "alpha_loss": 0.0023453555103125317, "alpha_value": 0.13882577324219952, "duration": 135.26286101341248, "step": 73625}
{"episode_reward": 832.6619462152469, "episode": 590.0, "Q1 loss": 6.770554565429688, "Q2 loss": 6.691211017608643, "Mean Target Q": 716.5205034179687, "Mean Q1": 716.5211689453125, "Mean Q2": 716.5237319335937, "critic_loss": 13.46176560974121, "batch_reward": 5.967791225433349, "actor_loss": -717.1756985572076, "actor_target_entropy": -1.0, "actor_entropy": -0.4296200458080538, "alpha_loss": 0.00023198247635586848, "alpha_value": 0.13879777239132, "duration": 129.126944065094, "step": 73750}
{"episode_reward": 842.0150816723566, "episode": 591.0, "Q1 loss": 6.9207299633026125, "Q2 loss": 6.933443075180054, "Mean Target Q": 716.4456879882813, "Mean Q1": 716.4366088867188, "Mean Q2": 716.4354365234375, "critic_loss": 13.854173049926757, "batch_reward": 5.9616910781860355, "actor_loss": -717.0551370287699, "actor_target_entropy": -1.0, "actor_entropy": -0.4162608872330378, "alpha_loss": -0.0020798476919206598, "alpha_value": 0.1389273626703824, "duration": 148.5763602256775, "step": 73875}
{"episode_reward": 777.5898223641614, "episode": 592.0, "Q1 loss": 6.1427116870880125, "Q2 loss": 6.128249383926391, "Mean Target Q": 716.8102182617188, "Mean Q1": 716.81405078125, "Mean Q2": 716.8156826171875, "critic_loss": 12.270961067199707, "batch_reward": 5.960031814575196, "actor_loss": -717.0933877268145, "actor_target_entropy": -1.0, "actor_entropy": -0.38061492673812375, "alpha_loss": 0.005479638297636542, "alpha_value": 0.1388024613751856, "duration": 142.38815665245056, "step": 74000}
{"episode_reward": 745.3946266894993, "episode": 593.0, "Q1 loss": 6.573318752288818, "Q2 loss": 6.5798725986480715, "Mean Target Q": 716.4128784179687, "Mean Q1": 716.410083984375, "Mean Q2": 716.4084453125, "critic_loss": 13.153191329956055, "batch_reward": 5.936875053405762, "actor_loss": -717.0693126860119, "actor_target_entropy": -1.0, "actor_entropy": -0.4072292943795522, "alpha_loss": 0.000849701942772501, "alpha_value": 0.13831796222809553, "duration": 148.5808527469635, "step": 74125}
{"episode_reward": 831.9102905081389, "episode": 594.0, "Q1 loss": 6.625601636886596, "Q2 loss": 6.655828424453736, "Mean Target Q": 716.785849609375, "Mean Q1": 716.7844897460938, "Mean Q2": 716.7848686523438, "critic_loss": 13.281430027008057, "batch_reward": 5.949538604736328, "actor_loss": -717.2447066768523, "actor_target_entropy": -1.0, "actor_entropy": -0.40088793106617465, "alpha_loss": -0.001172832034963874, "alpha_value": 0.13847529924552188, "duration": 141.05720114707947, "step": 74250}
{"episode_reward": 837.5305927726105, "episode": 595.0, "Q1 loss": 7.322106472015381, "Q2 loss": 7.357816562652588, "Mean Target Q": 716.9968520507813, "Mean Q1": 716.9976333007812, "Mean Q2": 716.9971909179687, "critic_loss": 14.679922977447509, "batch_reward": 5.944428375244141, "actor_loss": -717.0170162140377, "actor_target_entropy": -1.0, "actor_entropy": -0.40026434546425227, "alpha_loss": 0.0006651439443452372, "alpha_value": 0.1384863401286428, "duration": 136.82736730575562, "step": 74375}
{"episode_reward": 841.3951291143065, "episode": 596.0, "Q1 loss": 6.635280796051026, "Q2 loss": 6.660600866317749, "Mean Target Q": 717.046361328125, "Mean Q1": 717.046962890625, "Mean Q2": 717.0483740234375, "critic_loss": 13.295881702423095, "batch_reward": 5.944003280639649, "actor_loss": -717.5338164298765, "actor_target_entropy": -1.0, "actor_entropy": -0.4107072598511173, "alpha_loss": -0.00016654554131110348, "alpha_value": 0.13843492540719216, "duration": 138.3740475177765, "step": 74500}
{"episode_reward": 845.9955594101701, "episode": 597.0, "Q1 loss": 6.561880590438843, "Q2 loss": 6.571797157287597, "Mean Target Q": 717.1869990234375, "Mean Q1": 717.18272265625, "Mean Q2": 717.18147265625, "critic_loss": 13.13367777633667, "batch_reward": 5.95164102935791, "actor_loss": -717.8490426199777, "actor_target_entropy": -1.0, "actor_entropy": -0.3636101124778626, "alpha_loss": 0.004644075353142051, "alpha_value": 0.13819231778729796, "duration": 153.22238039970398, "step": 74625}
{"episode_reward": 779.5252262084229, "episode": 598.0, "Q1 loss": 6.681778642654419, "Q2 loss": 6.691461521148682, "Mean Target Q": 717.5729868164062, "Mean Q1": 717.5753955078125, "Mean Q2": 717.57382421875, "critic_loss": 13.373240142822265, "batch_reward": 5.956708339691162, "actor_loss": -718.2323539487777, "actor_target_entropy": -1.0, "actor_entropy": -0.4239097112609494, "alpha_loss": 1.9622987301479425e-05, "alpha_value": 0.1378728524658704, "duration": 157.77692580223083, "step": 74750}
{"episode_reward": 823.3204396781305, "episode": 599.0, "Q1 loss": 6.88973583984375, "Q2 loss": 6.891877811431884, "Mean Target Q": 717.82343359375, "Mean Q1": 717.8216279296875, "Mean Q2": 717.822041015625, "critic_loss": 13.781613658905028, "batch_reward": 5.9631846961975095, "actor_loss": -718.5243404327877, "actor_target_entropy": -1.0, "actor_entropy": -0.41142816770644414, "alpha_loss": -0.0004704842752303987, "alpha_value": 0.13806468517068476, "duration": 149.61154794692993, "step": 74875}
{"episode_reward": 839.1198146398017, "episode": 600.0, "Q1 loss": 7.398794303894043, "Q2 loss": 7.369773248672486, "Mean Target Q": 717.7971958007812, "Mean Q1": 717.7926596679688, "Mean Q2": 717.7938159179688, "critic_loss": 14.768567619323731, "batch_reward": 5.957923110961914, "actor_loss": -717.9312488186744, "actor_target_entropy": -1.0, "actor_entropy": -0.4030783378308819, "alpha_loss": 0.0007834480099019504, "alpha_value": 0.13800483549200632, "step": 75000}
{"duration": 143.5078899860382, "step": 75000}
{"episode_reward": 824.8455101262072, "episode": 601.0, "Q1 loss": 6.8799785785675045, "Q2 loss": 6.94187459564209, "Mean Target Q": 718.0218217773438, "Mean Q1": 718.0261298828125, "Mean Q2": 718.0258315429687, "critic_loss": 13.821853168487548, "batch_reward": 5.950396392822266, "actor_loss": -718.738535078745, "actor_target_entropy": -1.0, "actor_entropy": -0.384081493767481, "alpha_loss": 0.0027490672544531877, "alpha_value": 0.13774805308554186, "duration": 128.22303986549377, "step": 75125}
{"episode_reward": 827.4122171179844, "episode": 602.0, "Q1 loss": 7.473229030609131, "Q2 loss": 7.382693862915039, "Mean Target Q": 718.2024912109375, "Mean Q1": 718.1942788085937, "Mean Q2": 718.1958139648438, "critic_loss": 14.85592287826538, "batch_reward": 5.960469837188721, "actor_loss": -718.5769485965852, "actor_target_entropy": -1.0, "actor_entropy": -0.4140193029757469, "alpha_loss": 7.166805857371899e-05, "alpha_value": 0.13771751051473893, "duration": 141.2867636680603, "step": 75250}
{"episode_reward": 837.5553591993511, "episode": 603.0, "Q1 loss": 6.375507089614868, "Q2 loss": 6.389382436752319, "Mean Target Q": 718.4299360351563, "Mean Q1": 718.4331000976563, "Mean Q2": 718.432001953125, "critic_loss": 12.764889560699462, "batch_reward": 5.95872220993042, "actor_loss": -718.9879566979787, "actor_target_entropy": -1.0, "actor_entropy": -0.43348596966455855, "alpha_loss": -0.0008399432223837172, "alpha_value": 0.13771745813557038, "duration": 153.2476589679718, "step": 75375}
{"episode_reward": 806.0546840944387, "episode": 604.0, "Q1 loss": 6.662613641738892, "Q2 loss": 6.491607526779175, "Mean Target Q": 718.4028315429688, "Mean Q1": 718.3984008789063, "Mean Q2": 718.3986865234375, "critic_loss": 13.154221160888671, "batch_reward": 5.9363976745605465, "actor_loss": -718.7715129237021, "actor_target_entropy": -1.0, "actor_entropy": -0.40249724590009256, "alpha_loss": 0.0006764230849747096, "alpha_value": 0.13785374489356408, "duration": 119.22592806816101, "step": 75500}
{"episode_reward": 839.8225263071081, "episode": 605.0, "Q1 loss": 6.271304523468017, "Q2 loss": 6.402311117172241, "Mean Target Q": 719.0193037109375, "Mean Q1": 719.0264125976563, "Mean Q2": 719.0268891601562, "critic_loss": 12.673615650177002, "batch_reward": 5.9730068283081055, "actor_loss": -719.713152204241, "actor_target_entropy": -1.0, "actor_entropy": -0.39829784395202755, "alpha_loss": 0.0032163199410581637, "alpha_value": 0.1374196504965704, "duration": 131.52459192276, "step": 75625}
{"episode_reward": 846.4401583346826, "episode": 606.0, "Q1 loss": 6.589206693649292, "Q2 loss": 6.553342191696167, "Mean Target Q": 719.2979233398438, "Mean Q1": 719.2946303710937, "Mean Q2": 719.2929165039062, "critic_loss": 13.142548866271973, "batch_reward": 5.96317378616333, "actor_loss": -719.843998078377, "actor_target_entropy": -1.0, "actor_entropy": -0.38981995851762835, "alpha_loss": -0.0006472864939320472, "alpha_value": 0.13740859435127192, "duration": 155.86855053901672, "step": 75750}
{"episode_reward": 840.0450028040048, "episode": 607.0, "Q1 loss": 6.102031240463257, "Q2 loss": 6.121682159423828, "Mean Target Q": 719.2676137695313, "Mean Q1": 719.2621079101563, "Mean Q2": 719.2633549804688, "critic_loss": 12.22371336364746, "batch_reward": 5.9613731002807615, "actor_loss": -719.8938240172371, "actor_target_entropy": -1.0, "actor_entropy": -0.40518148172469365, "alpha_loss": 0.0019211121354370364, "alpha_value": 0.13753824175577087, "duration": 152.63003134727478, "step": 75875}
{"episode_reward": 846.7013360824526, "episode": 608.0, "Q1 loss": 6.213449878692627, "Q2 loss": 6.152598804473877, "Mean Target Q": 719.56230078125, "Mean Q1": 719.5615258789062, "Mean Q2": 719.5618989257813, "critic_loss": 12.366048698425294, "batch_reward": 5.975085098266602, "actor_loss": -719.9161652595766, "actor_target_entropy": -1.0, "actor_entropy": -0.4062310928298581, "alpha_loss": 0.005488009950626762, "alpha_value": 0.13693117149478834, "duration": 145.4570186138153, "step": 76000}
{"episode_reward": 819.0307139147145, "episode": 609.0, "Q1 loss": 6.4720356674194335, "Q2 loss": 6.478759508132935, "Mean Target Q": 719.5286928710938, "Mean Q1": 719.530369140625, "Mean Q2": 719.5290268554687, "critic_loss": 12.950795219421387, "batch_reward": 5.974206005096436, "actor_loss": -720.0179385230655, "actor_target_entropy": -1.0, "actor_entropy": -0.40178230073716903, "alpha_loss": 0.0014628264960640715, "alpha_value": 0.13657298643866383, "duration": 147.78299474716187, "step": 76125}
{"episode_reward": 820.7779715461305, "episode": 610.0, "Q1 loss": 7.073798328399659, "Q2 loss": 7.1812507362365725, "Mean Target Q": 719.3882529296875, "Mean Q1": 719.3804716796875, "Mean Q2": 719.3814555664062, "critic_loss": 14.255049053192138, "batch_reward": 5.953774806976319, "actor_loss": -719.8341418850806, "actor_target_entropy": -1.0, "actor_entropy": -0.414941692544568, "alpha_loss": 0.002492329670912436, "alpha_value": 0.13643455414403627, "duration": 153.41973161697388, "step": 76250}
{"episode_reward": 832.1570329823539, "episode": 611.0, "Q1 loss": 6.024883369445801, "Q2 loss": 6.121019613265991, "Mean Target Q": 720.2443959960938, "Mean Q1": 720.2488544921875, "Mean Q2": 720.2494057617188, "critic_loss": 12.14590297317505, "batch_reward": 5.990168724060059, "actor_loss": -720.9872581845239, "actor_target_entropy": -1.0, "actor_entropy": -0.38948913509883576, "alpha_loss": 0.0011004494606620735, "alpha_value": 0.13624315338425025, "duration": 150.74433422088623, "step": 76375}
{"episode_reward": 841.5361486331461, "episode": 612.0, "Q1 loss": 6.715722806930542, "Q2 loss": 6.697023057937622, "Mean Target Q": 719.8783842773438, "Mean Q1": 719.8754296875, "Mean Q2": 719.874673828125, "critic_loss": 13.41274585723877, "batch_reward": 5.962064929962159, "actor_loss": -720.4990874259703, "actor_target_entropy": -1.0, "actor_entropy": -0.40162247851971655, "alpha_loss": 0.003743014104510357, "alpha_value": 0.13603157633490212, "duration": 155.13371682167053, "step": 76500}
{"episode_reward": 845.8931837043857, "episode": 613.0, "Q1 loss": 5.7711104507446285, "Q2 loss": 5.713011304855347, "Mean Target Q": 720.3722543945313, "Mean Q1": 720.3736850585938, "Mean Q2": 720.373490234375, "critic_loss": 11.484121753692627, "batch_reward": 5.983286869049072, "actor_loss": -720.7803567553324, "actor_target_entropy": -1.0, "actor_entropy": -0.39022478082823375, "alpha_loss": 0.003985675421380807, "alpha_value": 0.1357043440652936, "duration": 154.48539662361145, "step": 76625}
{"episode_reward": 843.0801790040762, "episode": 614.0, "Q1 loss": 6.9548783817291255, "Q2 loss": 6.8572482604980465, "Mean Target Q": 720.128380859375, "Mean Q1": 720.123302734375, "Mean Q2": 720.1221904296875, "critic_loss": 13.81212652206421, "batch_reward": 5.95713298034668, "actor_loss": -720.2456290952621, "actor_target_entropy": -1.0, "actor_entropy": -0.36413593349918244, "alpha_loss": 0.0021699381834496896, "alpha_value": 0.1353201732005679, "duration": 145.13003540039062, "step": 76750}
{"episode_reward": 834.6804744888971, "episode": 615.0, "Q1 loss": 6.846943918228149, "Q2 loss": 6.902117858886719, "Mean Target Q": 720.7790434570312, "Mean Q1": 720.7768359375, "Mean Q2": 720.7766040039063, "critic_loss": 13.749061744689941, "batch_reward": 5.998840679168701, "actor_loss": -721.2865600585938, "actor_target_entropy": -1.0, "actor_entropy": -0.43860528866449994, "alpha_loss": -0.0009892697442352536, "alpha_value": 0.1352633664737366, "duration": 147.94688749313354, "step": 76875}
{"episode_reward": 823.976678642372, "episode": 616.0, "Q1 loss": 6.075181640625, "Q2 loss": 6.0313373489379885, "Mean Target Q": 720.6118198242187, "Mean Q1": 720.6136171875, "Mean Q2": 720.6139560546875, "critic_loss": 12.106519035339355, "batch_reward": 5.973367893218994, "actor_loss": -720.7610394877772, "actor_target_entropy": -1.0, "actor_entropy": -0.3997251223171911, "alpha_loss": -0.0013083686485075422, "alpha_value": 0.13534804554978713, "duration": 138.51916432380676, "step": 77000}
{"episode_reward": 793.6493008683705, "episode": 617.0, "Q1 loss": 6.653360858917236, "Q2 loss": 6.702111400604248, "Mean Target Q": 720.7243178710937, "Mean Q1": 720.7272807617187, "Mean Q2": 720.7294873046875, "critic_loss": 13.355472282409668, "batch_reward": 5.964743682861328, "actor_loss": -721.2161438957094, "actor_target_entropy": -1.0, "actor_entropy": -0.41647555336119635, "alpha_loss": -0.0037659930752678996, "alpha_value": 0.13565904901941148, "duration": 138.50849628448486, "step": 77125}
{"episode_reward": 832.9028868505976, "episode": 618.0, "Q1 loss": 6.268800325393677, "Q2 loss": 6.279375461578369, "Mean Target Q": 721.39422265625, "Mean Q1": 721.3896044921875, "Mean Q2": 721.3887216796875, "critic_loss": 12.54817582321167, "batch_reward": 5.994532619476319, "actor_loss": -721.8695599955897, "actor_target_entropy": -1.0, "actor_entropy": -0.42275505296645627, "alpha_loss": -0.0019128039937406297, "alpha_value": 0.13591948328294448, "duration": 147.9076018333435, "step": 77250}
{"episode_reward": 830.0132962286805, "episode": 619.0, "Q1 loss": 6.4317049922943115, "Q2 loss": 6.252168601989746, "Mean Target Q": 721.0690708007812, "Mean Q1": 721.06425390625, "Mean Q2": 721.06416015625, "critic_loss": 12.683873546600342, "batch_reward": 5.977986907958984, "actor_loss": -721.771738203745, "actor_target_entropy": -1.0, "actor_entropy": -0.3906827266254122, "alpha_loss": 0.0025938922531961923, "alpha_value": 0.13596898848575137, "duration": 148.35945892333984, "step": 77375}
{"episode_reward": 840.0380083569114, "episode": 620.0, "Q1 loss": 6.199910461425781, "Q2 loss": 6.2232386608123775, "Mean Target Q": 721.2115888671875, "Mean Q1": 721.2080927734376, "Mean Q2": 721.208396484375, "critic_loss": 12.423149181365966, "batch_reward": 5.969581836700439, "actor_loss": -721.6056026335685, "actor_target_entropy": -1.0, "actor_entropy": -0.4469031946312997, "alpha_loss": -0.003737990789475941, "alpha_value": 0.13595757294227367, "duration": 146.27340602874756, "step": 77500}
{"episode_reward": 833.4364821965098, "episode": 621.0, "Q1 loss": 6.541172647476197, "Q2 loss": 6.604690511703491, "Mean Target Q": 721.5104418945313, "Mean Q1": 721.5110732421875, "Mean Q2": 721.511240234375, "critic_loss": 13.145863174438476, "batch_reward": 5.977481273651123, "actor_loss": -722.2134050641741, "actor_target_entropy": -1.0, "actor_entropy": -0.3967647495723906, "alpha_loss": 0.0031844003713645394, "alpha_value": 0.1359995030763786, "duration": 150.67549085617065, "step": 77625}
{"episode_reward": 835.3367907898065, "episode": 622.0, "Q1 loss": 6.496039762496948, "Q2 loss": 6.449393543243408, "Mean Target Q": 721.7304125976563, "Mean Q1": 721.73519140625, "Mean Q2": 721.7351342773437, "critic_loss": 12.945433284759522, "batch_reward": 5.976333599090577, "actor_loss": -722.2014947706654, "actor_target_entropy": -1.0, "actor_entropy": -0.42548060465243553, "alpha_loss": -0.0005487346056578381, "alpha_value": 0.13578329369222622, "duration": 150.7249767780304, "step": 77750}
{"episode_reward": 843.0488529346894, "episode": 623.0, "Q1 loss": 5.8419408588409425, "Q2 loss": 5.843073093414307, "Mean Target Q": 722.089599609375, "Mean Q1": 722.0842348632813, "Mean Q2": 722.0846142578125, "critic_loss": 11.685013954162597, "batch_reward": 5.986389640808105, "actor_loss": -722.5165986560639, "actor_target_entropy": -1.0, "actor_entropy": -0.4066899731045678, "alpha_loss": 0.001972223253225878, "alpha_value": 0.13586159644385284, "duration": 141.52157592773438, "step": 77875}
{"episode_reward": 838.5342913666352, "episode": 624.0, "Q1 loss": 5.8391484375, "Q2 loss": 5.971565826416016, "Mean Target Q": 721.984556640625, "Mean Q1": 721.9856645507813, "Mean Q2": 721.9846586914063, "critic_loss": 11.810714302062989, "batch_reward": 5.986553848266602, "actor_loss": -722.5198462701613, "actor_target_entropy": -1.0, "actor_entropy": -0.41482261496205486, "alpha_loss": -0.000412695107027708, "alpha_value": 0.1357455085574607, "duration": 152.55940175056458, "step": 78000}
{"episode_reward": 834.5530487327168, "episode": 625.0, "Q1 loss": 6.259291793823242, "Q2 loss": 6.196384525299072, "Mean Target Q": 722.1082241210937, "Mean Q1": 722.10276171875, "Mean Q2": 722.104052734375, "critic_loss": 12.455676361083984, "batch_reward": 5.9756281929016115, "actor_loss": -722.4273148794023, "actor_target_entropy": -1.0, "actor_entropy": -0.4200022892346458, "alpha_loss": -0.0014559164170234922, "alpha_value": 0.1358861273147473, "duration": 284.5041241645813, "step": 78125}
{"episode_reward": 845.772737453843, "episode": 626.0, "Q1 loss": 6.735212749481201, "Q2 loss": 6.656621284484864, "Mean Target Q": 722.7757514648438, "Mean Q1": 722.7783852539062, "Mean Q2": 722.7766459960937, "critic_loss": 13.391834075927735, "batch_reward": 6.0210821838378905, "actor_loss": -723.3753662109375, "actor_target_entropy": -1.0, "actor_entropy": -0.4241817656063264, "alpha_loss": 0.002553156800492997, "alpha_value": 0.13574033444281075, "duration": 313.1951684951782, "step": 78250}
{"episode_reward": 780.6635959530159, "episode": 627.0, "Q1 loss": 6.739754606246948, "Q2 loss": 6.7285720729827885, "Mean Target Q": 722.4968486328125, "Mean Q1": 722.4937568359375, "Mean Q2": 722.4942158203125, "critic_loss": 13.46832666015625, "batch_reward": 5.979381038665771, "actor_loss": -723.0526026165675, "actor_target_entropy": -1.0, "actor_entropy": -0.4164028252874102, "alpha_loss": 0.0011712443878105472, "alpha_value": 0.13554163166677619, "duration": 294.4563932418823, "step": 78375}
{"episode_reward": 835.8716200135545, "episode": 628.0, "Q1 loss": 6.13029443359375, "Q2 loss": 6.180546237945556, "Mean Target Q": 722.730638671875, "Mean Q1": 722.7296420898438, "Mean Q2": 722.72944140625, "critic_loss": 12.310840568542481, "batch_reward": 5.978875839233399, "actor_loss": -723.0342367849042, "actor_target_entropy": -1.0, "actor_entropy": -0.42760348368075585, "alpha_loss": 5.910552910438949e-05, "alpha_value": 0.1354736841841179, "duration": 245.58101224899292, "step": 78500}
{"episode_reward": 852.0919157698567, "episode": 629.0, "Q1 loss": 5.968416404724121, "Q2 loss": 5.980250654220581, "Mean Target Q": 722.9454418945312, "Mean Q1": 722.9433129882813, "Mean Q2": 722.944693359375, "critic_loss": 11.948667053222657, "batch_reward": 6.008571441650391, "actor_loss": -723.8078845796131, "actor_target_entropy": -1.0, "actor_entropy": -0.40926950980746557, "alpha_loss": 0.003495927696811065, "alpha_value": 0.13537883560405087, "duration": 249.95623326301575, "step": 78625}
{"episode_reward": 824.7489144405544, "episode": 630.0, "Q1 loss": 6.044060600280762, "Q2 loss": 6.231658657073974, "Mean Target Q": 723.2375825195312, "Mean Q1": 723.23390625, "Mean Q2": 723.2341479492187, "critic_loss": 12.27571928024292, "batch_reward": 6.0043971061706545, "actor_loss": -723.5115553332913, "actor_target_entropy": -1.0, "actor_entropy": -0.3826240887564997, "alpha_loss": 0.0007700025716105536, "alpha_value": 0.13519482504907457, "duration": 231.2778925895691, "step": 78750}
{"episode_reward": 820.4158064941089, "episode": 631.0, "Q1 loss": 5.855099809646607, "Q2 loss": 5.865090692520142, "Mean Target Q": 723.3211596679688, "Mean Q1": 723.322537109375, "Mean Q2": 723.3225087890625, "critic_loss": 11.720190532684326, "batch_reward": 6.012602897644043, "actor_loss": -723.9356505378844, "actor_target_entropy": -1.0, "actor_entropy": -0.4403286666151077, "alpha_loss": -0.0033899365382875123, "alpha_value": 0.13515966084100653, "duration": 227.76520371437073, "step": 78875}
{"episode_reward": 828.5361573565008, "episode": 632.0, "Q1 loss": 6.326893960952758, "Q2 loss": 6.338993320465088, "Mean Target Q": 723.3679057617187, "Mean Q1": 723.3648979492187, "Mean Q2": 723.365611328125, "critic_loss": 12.665887279510498, "batch_reward": 5.998014797210693, "actor_loss": -723.68847164031, "actor_target_entropy": -1.0, "actor_entropy": -0.40913842426192376, "alpha_loss": 0.0020413078863414065, "alpha_value": 0.13531966455566324, "duration": 160.92356657981873, "step": 79000}
{"episode_reward": 828.7188025893746, "episode": 633.0, "Q1 loss": 5.653849334716797, "Q2 loss": 5.639238971710205, "Mean Target Q": 723.2944829101563, "Mean Q1": 723.2997294921875, "Mean Q2": 723.2983041992187, "critic_loss": 11.293088275909424, "batch_reward": 5.993972835540771, "actor_loss": -723.426744249132, "actor_target_entropy": -1.0, "actor_entropy": -0.36947014265590244, "alpha_loss": 0.0016082233660632656, "alpha_value": 0.1351289745180012, "duration": 186.8514289855957, "step": 79125}
{"episode_reward": 838.3459886909679, "episode": 634.0, "Q1 loss": 5.758384798049927, "Q2 loss": 5.765605411529541, "Mean Target Q": 723.6182241210937, "Mean Q1": 723.62249609375, "Mean Q2": 723.6211987304688, "critic_loss": 11.523990224838256, "batch_reward": 5.998644145965576, "actor_loss": -723.5326321509576, "actor_target_entropy": -1.0, "actor_entropy": -0.37978739459668437, "alpha_loss": -0.00038535310323500345, "alpha_value": 0.13503336988993567, "duration": 179.05253982543945, "step": 79250}
{"episode_reward": 824.5488657616166, "episode": 635.0, "Q1 loss": 6.735853935241699, "Q2 loss": 6.83626068687439, "Mean Target Q": 723.44990234375, "Mean Q1": 723.4396381835937, "Mean Q2": 723.44055078125, "critic_loss": 13.572114608764648, "batch_reward": 5.974870704650879, "actor_loss": -723.6507926819817, "actor_target_entropy": -1.0, "actor_entropy": -0.4016565912299686, "alpha_loss": -0.00193013521447216, "alpha_value": 0.13524140029269105, "duration": 172.2365744113922, "step": 79375}
{"episode_reward": 846.9437164132612, "episode": 636.0, "Q1 loss": 6.37519291305542, "Q2 loss": 6.500367343902588, "Mean Target Q": 724.1389448242187, "Mean Q1": 724.1358134765625, "Mean Q2": 724.135107421875, "critic_loss": 12.875560291290283, "batch_reward": 6.014876602172851, "actor_loss": -724.4903741651966, "actor_target_entropy": -1.0, "actor_entropy": -0.3948142797716202, "alpha_loss": 0.0006628717866636091, "alpha_value": 0.13529339071157026, "duration": 197.9450967311859, "step": 79500}
{"episode_reward": 816.5521360060903, "episode": 637.0, "Q1 loss": 6.379095405578613, "Q2 loss": 6.306956436157226, "Mean Target Q": 723.7206147460937, "Mean Q1": 723.7195224609375, "Mean Q2": 723.7175483398438, "critic_loss": 12.686051887512207, "batch_reward": 5.977008632659912, "actor_loss": -723.7647695390004, "actor_target_entropy": -1.0, "actor_entropy": -0.4282399903214167, "alpha_loss": 0.00017670761989725252, "alpha_value": 0.13524747467649004, "duration": 207.22628951072693, "step": 79625}
{"episode_reward": 827.8377595902975, "episode": 638.0, "Q1 loss": 6.523974634170532, "Q2 loss": 6.557485534667968, "Mean Target Q": 724.1874565429688, "Mean Q1": 724.1879633789063, "Mean Q2": 724.1909365234375, "critic_loss": 13.081460140228272, "batch_reward": 5.998302619934082, "actor_loss": -724.6397380213583, "actor_target_entropy": -1.0, "actor_entropy": -0.3816331865326051, "alpha_loss": 0.0033722679401116985, "alpha_value": 0.13504432787732853, "duration": 209.00827717781067, "step": 79750}
{"episode_reward": 843.5290594997235, "episode": 639.0, "Q1 loss": 6.392366979598999, "Q2 loss": 6.326878889083862, "Mean Target Q": 724.297220703125, "Mean Q1": 724.298587890625, "Mean Q2": 724.2990717773438, "critic_loss": 12.719245876312256, "batch_reward": 6.000478076934814, "actor_loss": -724.83788093688, "actor_target_entropy": -1.0, "actor_entropy": -0.4120278348998418, "alpha_loss": 0.00016349759544171985, "alpha_value": 0.13478535689232982, "duration": 220.64367651939392, "step": 79875}
{"episode_reward": 784.8808263310204, "episode": 640.0, "Q1 loss": 6.393368978500366, "Q2 loss": 6.2532782535552975, "Mean Target Q": 724.3007436523437, "Mean Q1": 724.2913974609374, "Mean Q2": 724.2918232421875, "critic_loss": 12.646647270202637, "batch_reward": 5.989853504180908, "actor_loss": -724.9534843198714, "actor_target_entropy": -1.0, "actor_entropy": -0.41604084833975763, "alpha_loss": 0.0011343966912282931, "alpha_value": 0.13474313012286826, "step": 80000}
{"duration": 196.8075475692749, "step": 80000}
{"episode_reward": 824.1953093883345, "episode": 641.0, "Q1 loss": 6.354530363082886, "Q2 loss": 6.295211935043335, "Mean Target Q": 724.497203125, "Mean Q1": 724.5039721679688, "Mean Q2": 724.502640625, "critic_loss": 12.649742305755614, "batch_reward": 6.003359573364258, "actor_loss": -724.9075298006572, "actor_target_entropy": -1.0, "actor_entropy": -0.3942607929782262, "alpha_loss": 0.001064079614090068, "alpha_value": 0.1346785112827157, "duration": 188.31233978271484, "step": 80125}
{"episode_reward": 777.2864940739101, "episode": 642.0, "Q1 loss": 5.7857272300720215, "Q2 loss": 5.858166454315185, "Mean Target Q": 724.866947265625, "Mean Q1": 724.8681953125, "Mean Q2": 724.8702900390625, "critic_loss": 11.643893661499023, "batch_reward": 5.997997188568116, "actor_loss": -725.5653233681955, "actor_target_entropy": -1.0, "actor_entropy": -0.3962791052556807, "alpha_loss": 0.003231897402832645, "alpha_value": 0.1344706873355035, "duration": 148.4945147037506, "step": 80250}
{"episode_reward": 837.9716904642323, "episode": 643.0, "Q1 loss": 5.52938360786438, "Q2 loss": 5.568121042251587, "Mean Target Q": 725.0907065429687, "Mean Q1": 725.08478125, "Mean Q2": 725.0821987304688, "critic_loss": 11.097504665374755, "batch_reward": 6.023069404602051, "actor_loss": -725.6315365745908, "actor_target_entropy": -1.0, "actor_entropy": -0.41998008272004506, "alpha_loss": 0.00011336572083925444, "alpha_value": 0.13434613128995626, "duration": 159.97169470787048, "step": 80375}
{"episode_reward": 839.141591932401, "episode": 644.0, "Q1 loss": 5.595491106033325, "Q2 loss": 5.719958671569824, "Mean Target Q": 725.0208422851563, "Mean Q1": 725.0170502929687, "Mean Q2": 725.0176870117187, "critic_loss": 11.315449714660645, "batch_reward": 5.997782348632812, "actor_loss": -725.4693701959426, "actor_target_entropy": -1.0, "actor_entropy": -0.4206466006655847, "alpha_loss": -0.0017033799311086055, "alpha_value": 0.13437636979104123, "duration": 170.1609399318695, "step": 80500}
{"episode_reward": 743.8833601400487, "episode": 645.0, "Q1 loss": 6.548721755981445, "Q2 loss": 6.500136659622193, "Mean Target Q": 724.9534052734375, "Mean Q1": 724.958603515625, "Mean Q2": 724.959287109375, "critic_loss": 13.048858406066895, "batch_reward": 5.99153536605835, "actor_loss": -725.3604261610243, "actor_target_entropy": -1.0, "actor_entropy": -0.4156892328035264, "alpha_loss": -0.0004988630923132101, "alpha_value": 0.13452522536680364, "duration": 147.92667174339294, "step": 80625}
{"episode_reward": 817.509616172299, "episode": 646.0, "Q1 loss": 5.618408958435059, "Q2 loss": 5.615678226470947, "Mean Target Q": 725.4179194335937, "Mean Q1": 725.4107143554687, "Mean Q2": 725.410212890625, "critic_loss": 11.234087226867675, "batch_reward": 6.011797950744629, "actor_loss": -725.602046843498, "actor_target_entropy": -1.0, "actor_entropy": -0.41692443143936897, "alpha_loss": -0.0001604705842422141, "alpha_value": 0.13455489583304078, "duration": 159.18272805213928, "step": 80750}
{"episode_reward": 779.5291554607476, "episode": 647.0, "Q1 loss": 5.728572919845581, "Q2 loss": 5.827715421676635, "Mean Target Q": 725.5291879882813, "Mean Q1": 725.533162109375, "Mean Q2": 725.5341787109375, "critic_loss": 11.556288352966309, "batch_reward": 6.009555152893066, "actor_loss": -725.9578305199033, "actor_target_entropy": -1.0, "actor_entropy": -0.4691923222844563, "alpha_loss": -0.0033021330517450614, "alpha_value": 0.1347123039789023, "duration": 116.81603288650513, "step": 80875}
{"episode_reward": 830.6262440334543, "episode": 648.0, "Q1 loss": 6.1700649814605715, "Q2 loss": 6.103429607391357, "Mean Target Q": 725.2116801757812, "Mean Q1": 725.210185546875, "Mean Q2": 725.2084516601562, "critic_loss": 12.27349458694458, "batch_reward": 5.987072681427002, "actor_loss": -725.4672713741179, "actor_target_entropy": -1.0, "actor_entropy": -0.43259941714425243, "alpha_loss": -0.0003350969542929482, "alpha_value": 0.13490510499050015, "duration": 177.29281878471375, "step": 81000}
{"episode_reward": 840.0961652166021, "episode": 649.0, "Q1 loss": 6.12690340423584, "Q2 loss": 6.181135805130005, "Mean Target Q": 725.3321694335938, "Mean Q1": 725.3294541015625, "Mean Q2": 725.3305200195313, "critic_loss": 12.308039199829102, "batch_reward": 6.0016383438110354, "actor_loss": -725.9314594571553, "actor_target_entropy": -1.0, "actor_entropy": -0.4359086165352473, "alpha_loss": 0.0009463027670299487, "alpha_value": 0.13484210161562352, "duration": 190.0422239303589, "step": 81125}
{"episode_reward": 836.7628866500208, "episode": 650.0, "Q1 loss": 5.94788501739502, "Q2 loss": 6.01436749458313, "Mean Target Q": 725.7324697265625, "Mean Q1": 725.72694140625, "Mean Q2": 725.727078125, "critic_loss": 11.962252517700195, "batch_reward": 6.015339309692383, "actor_loss": -725.9551834598665, "actor_target_entropy": -1.0, "actor_entropy": -0.414841117878114, "alpha_loss": -0.002243088629667557, "alpha_value": 0.13492825417923096, "duration": 184.6183726787567, "step": 81250}
{"episode_reward": 829.6329894109551, "episode": 651.0, "Q1 loss": 6.464938724517823, "Q2 loss": 6.495967905044556, "Mean Target Q": 725.6896118164062, "Mean Q1": 725.6958618164062, "Mean Q2": 725.69553515625, "critic_loss": 12.960906608581542, "batch_reward": 6.002416687011719, "actor_loss": -725.8400123232886, "actor_target_entropy": -1.0, "actor_entropy": -0.40441113237350707, "alpha_loss": 0.0015558463443691533, "alpha_value": 0.13503732957460998, "duration": 200.87220096588135, "step": 81375}
{"episode_reward": 834.4077526434071, "episode": 652.0, "Q1 loss": 6.51627073097229, "Q2 loss": 6.436945247650146, "Mean Target Q": 725.7229716796875, "Mean Q1": 725.7170883789063, "Mean Q2": 725.7164462890624, "critic_loss": 12.953215942382812, "batch_reward": 5.997396503448487, "actor_loss": -726.2385706747732, "actor_target_entropy": -1.0, "actor_entropy": -0.4005667831628553, "alpha_loss": 0.003151797653821808, "alpha_value": 0.13480889578926086, "duration": 201.34357571601868, "step": 81500}
{"episode_reward": 840.2796843628666, "episode": 653.0, "Q1 loss": 6.152788915634155, "Q2 loss": 6.080979639053345, "Mean Target Q": 726.3875961914063, "Mean Q1": 726.3926884765625, "Mean Q2": 726.39218359375, "critic_loss": 12.233768535614013, "batch_reward": 6.013884548187256, "actor_loss": -726.8206719292534, "actor_target_entropy": -1.0, "actor_entropy": -0.38724285553372095, "alpha_loss": 0.002458424810024481, "alpha_value": 0.13445986141456792, "duration": 197.5766944885254, "step": 81625}
{"episode_reward": 825.1072042261001, "episode": 654.0, "Q1 loss": 6.393819875717163, "Q2 loss": 6.52988996887207, "Mean Target Q": 726.3785346679688, "Mean Q1": 726.3759809570313, "Mean Q2": 726.374953125, "critic_loss": 12.923709827423096, "batch_reward": 6.015314720153809, "actor_loss": -726.9076892483619, "actor_target_entropy": -1.0, "actor_entropy": -0.42075786763621914, "alpha_loss": 0.002272631017295944, "alpha_value": 0.1342096421580225, "duration": 189.40167546272278, "step": 81750}
{"episode_reward": 818.9744468054666, "episode": 655.0, "Q1 loss": 5.669100635528564, "Q2 loss": 5.806311820983887, "Mean Target Q": 726.6322856445313, "Mean Q1": 726.6283950195312, "Mean Q2": 726.6315327148437, "critic_loss": 11.475412456512451, "batch_reward": 6.017498558044434, "actor_loss": -726.9174698118179, "actor_target_entropy": -1.0, "actor_entropy": -0.4289399986229246, "alpha_loss": -0.001707562781308615, "alpha_value": 0.13407429666900764, "duration": 192.4704875946045, "step": 81875}
{"episode_reward": 848.2432012377736, "episode": 656.0, "Q1 loss": 5.9365890522003175, "Q2 loss": 5.905109083175659, "Mean Target Q": 726.5084096679687, "Mean Q1": 726.5101245117188, "Mean Q2": 726.5098403320312, "critic_loss": 11.841698123931884, "batch_reward": 6.0158020133972165, "actor_loss": -727.0077750913558, "actor_target_entropy": -1.0, "actor_entropy": -0.426148695330466, "alpha_loss": -0.00196216978891302, "alpha_value": 0.13441324358722648, "duration": 152.4916386604309, "step": 82000}
{"episode_reward": 813.6277116321039, "episode": 657.0, "Q1 loss": 6.833756662368774, "Q2 loss": 6.735396928787232, "Mean Target Q": 726.7282421875, "Mean Q1": 726.732341796875, "Mean Q2": 726.7298916015625, "critic_loss": 13.569153533935546, "batch_reward": 6.022785724639893, "actor_loss": -727.0900210425967, "actor_target_entropy": -1.0, "actor_entropy": -0.4077253720116994, "alpha_loss": -3.975778005071103e-05, "alpha_value": 0.13451623272222624, "duration": 148.30177283287048, "step": 82125}
{"episode_reward": 783.7838720878336, "episode": 658.0, "Q1 loss": 6.276961429595947, "Q2 loss": 6.30205383682251, "Mean Target Q": 726.7808896484376, "Mean Q1": 726.770849609375, "Mean Q2": 726.7706611328125, "critic_loss": 12.579015285491943, "batch_reward": 6.008388439178467, "actor_loss": -727.4817495038433, "actor_target_entropy": -1.0, "actor_entropy": -0.44003132706688297, "alpha_loss": -3.246437183641378e-05, "alpha_value": 0.13448406277824743, "duration": 154.23852109909058, "step": 82250}
{"episode_reward": 826.4193168413685, "episode": 659.0, "Q1 loss": 6.205889331817627, "Q2 loss": 6.1607259864807125, "Mean Target Q": 726.8278588867188, "Mean Q1": 726.8291245117188, "Mean Q2": 726.8317416992187, "critic_loss": 12.366615272521972, "batch_reward": 6.011513584136963, "actor_loss": -727.2855621822297, "actor_target_entropy": -1.0, "actor_entropy": -0.4229873754675426, "alpha_loss": -0.0002275905193066195, "alpha_value": 0.13446707168136424, "duration": 137.77452564239502, "step": 82375}
{"episode_reward": 838.8967516795636, "episode": 660.0, "Q1 loss": 6.400370992660522, "Q2 loss": 6.61394317817688, "Mean Target Q": 726.9842133789062, "Mean Q1": 726.9809609375, "Mean Q2": 726.9781787109375, "critic_loss": 13.014314182281494, "batch_reward": 6.019564769744873, "actor_loss": -727.4691221175656, "actor_target_entropy": -1.0, "actor_entropy": -0.40899256881206264, "alpha_loss": 0.0021199717772223295, "alpha_value": 0.13438766558596943, "duration": 160.65137553215027, "step": 82500}
{"episode_reward": 844.0124576373257, "episode": 661.0, "Q1 loss": 5.893082199096679, "Q2 loss": 5.87152396774292, "Mean Target Q": 726.9516606445312, "Mean Q1": 726.9536518554687, "Mean Q2": 726.9557358398438, "critic_loss": 11.764606113433837, "batch_reward": 5.998715911865235, "actor_loss": -727.4422956194196, "actor_target_entropy": -1.0, "actor_entropy": -0.4180589360850198, "alpha_loss": 0.0015585455149116497, "alpha_value": 0.13412707530096354, "duration": 196.0151243209839, "step": 82625}
{"episode_reward": 826.6739283969227, "episode": 662.0, "Q1 loss": 6.044456443786621, "Q2 loss": 6.093607166290283, "Mean Target Q": 727.3213872070312, "Mean Q1": 727.3165810546875, "Mean Q2": 727.3149609375, "critic_loss": 12.138063606262207, "batch_reward": 6.026258567810059, "actor_loss": -727.7877935594128, "actor_target_entropy": -1.0, "actor_entropy": -0.37640696908197097, "alpha_loss": 0.006232539278214737, "alpha_value": 0.1337498022817115, "duration": 191.22732734680176, "step": 82750}
{"episode_reward": 810.6478154825905, "episode": 663.0, "Q1 loss": 6.315800960540772, "Q2 loss": 6.346255151748657, "Mean Target Q": 727.412087890625, "Mean Q1": 727.4175810546875, "Mean Q2": 727.4161948242188, "critic_loss": 12.662056098937988, "batch_reward": 6.020752376556397, "actor_loss": -727.9515400235615, "actor_target_entropy": -1.0, "actor_entropy": -0.4306561601540399, "alpha_loss": -0.0002188525090570606, "alpha_value": 0.13336937022964074, "duration": 193.53280520439148, "step": 82875}
{"episode_reward": 821.5200947531081, "episode": 664.0, "Q1 loss": 5.917092519760132, "Q2 loss": 5.853007148742676, "Mean Target Q": 727.6617651367187, "Mean Q1": 727.6590444335937, "Mean Q2": 727.66069921875, "critic_loss": 11.770099643707276, "batch_reward": 6.022796302795411, "actor_loss": -727.9756361438382, "actor_target_entropy": -1.0, "actor_entropy": -0.43255891146198394, "alpha_loss": -0.0010882559919639702, "alpha_value": 0.13351179931510138, "duration": 171.8683521747589, "step": 83000}
{"episode_reward": 848.7414720210697, "episode": 665.0, "Q1 loss": 5.7585336818695065, "Q2 loss": 5.847664026260376, "Mean Target Q": 727.619962890625, "Mean Q1": 727.6202661132812, "Mean Q2": 727.6191220703125, "critic_loss": 11.606197692871094, "batch_reward": 6.025936939239502, "actor_loss": -727.6526731460814, "actor_target_entropy": -1.0, "actor_entropy": -0.4000259032325139, "alpha_loss": -3.109065194924673e-05, "alpha_value": 0.13360978303160023, "duration": 206.79663610458374, "step": 83125}
{"episode_reward": 842.1716573188858, "episode": 666.0, "Q1 loss": 5.897565496444702, "Q2 loss": 5.837532161712646, "Mean Target Q": 728.0643383789062, "Mean Q1": 728.0561547851562, "Mean Q2": 728.057861328125, "critic_loss": 11.735097660064698, "batch_reward": 6.029534320831299, "actor_loss": -728.7594752157888, "actor_target_entropy": -1.0, "actor_entropy": -0.41828440562371283, "alpha_loss": -0.00048523753197983867, "alpha_value": 0.13361778741975033, "duration": 184.40117478370667, "step": 83250}
{"episode_reward": 845.2735378909794, "episode": 667.0, "Q1 loss": 5.315772409439087, "Q2 loss": 5.326907321929932, "Mean Target Q": 727.9139077148437, "Mean Q1": 727.9142099609375, "Mean Q2": 727.9158857421875, "critic_loss": 10.64267975616455, "batch_reward": 6.008442401885986, "actor_loss": -728.8112541077629, "actor_target_entropy": -1.0, "actor_entropy": -0.4085327788950905, "alpha_loss": 0.00015567486462671133, "alpha_value": 0.1336041331960588, "duration": 148.22727847099304, "step": 83375}
{"episode_reward": 832.8166058489887, "episode": 668.0, "Q1 loss": 5.9626053600311275, "Q2 loss": 6.014888031005859, "Mean Target Q": 728.30462890625, "Mean Q1": 728.3098369140625, "Mean Q2": 728.3086157226562, "critic_loss": 11.977493396759034, "batch_reward": 6.0239954071044925, "actor_loss": -728.929679624496, "actor_target_entropy": -1.0, "actor_entropy": -0.41392368414709646, "alpha_loss": -0.0012577962085244157, "alpha_value": 0.1336861155261665, "duration": 161.4692759513855, "step": 83500}
{"episode_reward": 826.842581172796, "episode": 669.0, "Q1 loss": 5.942230096817017, "Q2 loss": 5.911997192382812, "Mean Target Q": 728.4060791015625, "Mean Q1": 728.4060869140625, "Mean Q2": 728.403615234375, "critic_loss": 11.85422727584839, "batch_reward": 6.023840450286865, "actor_loss": -728.5633002387153, "actor_target_entropy": -1.0, "actor_entropy": -0.4236294433238014, "alpha_loss": -0.00016708138384043225, "alpha_value": 0.13371697153746448, "duration": 161.92533993721008, "step": 83625}
{"episode_reward": 815.7135795708318, "episode": 670.0, "Q1 loss": 5.980883197784424, "Q2 loss": 5.945309381484986, "Mean Target Q": 728.4301323242188, "Mean Q1": 728.4274599609375, "Mean Q2": 728.42725390625, "critic_loss": 11.926192546844483, "batch_reward": 6.029285751342774, "actor_loss": -729.1657055270288, "actor_target_entropy": -1.0, "actor_entropy": -0.40471913112748054, "alpha_loss": 0.003162229956585854, "alpha_value": 0.13359694044050935, "duration": 152.6904058456421, "step": 83750}
{"episode_reward": 841.3040983251781, "episode": 671.0, "Q1 loss": 5.87705626487732, "Q2 loss": 5.935667057037353, "Mean Target Q": 728.4943315429688, "Mean Q1": 728.4882724609375, "Mean Q2": 728.4884638671875, "critic_loss": 11.812723323822022, "batch_reward": 6.0138913383483885, "actor_loss": -728.9153616768973, "actor_target_entropy": -1.0, "actor_entropy": -0.4193427524869404, "alpha_loss": -0.002069836081419554, "alpha_value": 0.13356428005428808, "duration": 147.6522023677826, "step": 83875}
{"episode_reward": 837.4181552888682, "episode": 672.0, "Q1 loss": 6.404482904434204, "Q2 loss": 6.483974597930908, "Mean Target Q": 728.7981918945312, "Mean Q1": 728.7962915039062, "Mean Q2": 728.797134765625, "critic_loss": 12.888457511901855, "batch_reward": 6.040715713500976, "actor_loss": -729.1940415905368, "actor_target_entropy": -1.0, "actor_entropy": -0.40508332512071055, "alpha_loss": -0.0015198257207239589, "alpha_value": 0.13384148584205494, "duration": 156.94379711151123, "step": 84000}
{"episode_reward": 777.8220609317565, "episode": 673.0, "Q1 loss": 6.695291553497315, "Q2 loss": 6.712958566665649, "Mean Target Q": 728.63330078125, "Mean Q1": 728.6294975585937, "Mean Q2": 728.629548828125, "critic_loss": 13.408250133514404, "batch_reward": 6.012435565948486, "actor_loss": -729.3740244063121, "actor_target_entropy": -1.0, "actor_entropy": -0.4022180404927995, "alpha_loss": -0.00016408552700239752, "alpha_value": 0.13381558962790416, "duration": 176.1990704536438, "step": 84125}
{"episode_reward": 837.5610399095525, "episode": 674.0, "Q1 loss": 6.478675382614136, "Q2 loss": 6.534583860397339, "Mean Target Q": 728.929541015625, "Mean Q1": 728.935615234375, "Mean Q2": 728.937619140625, "critic_loss": 13.01325925064087, "batch_reward": 6.021910614013672, "actor_loss": -729.3627112603957, "actor_target_entropy": -1.0, "actor_entropy": -0.42303871675845117, "alpha_loss": 0.0005329252453520894, "alpha_value": 0.1338251739256645, "duration": 135.46878242492676, "step": 84250}
{"episode_reward": 839.5149502716921, "episode": 675.0, "Q1 loss": 6.168427406311035, "Q2 loss": 6.169772424697876, "Mean Target Q": 728.949517578125, "Mean Q1": 728.9436381835937, "Mean Q2": 728.9417573242188, "critic_loss": 12.338199840545654, "batch_reward": 6.035514965057373, "actor_loss": -729.2077229817709, "actor_target_entropy": -1.0, "actor_entropy": -0.42347740559350877, "alpha_loss": 0.0006883333895414595, "alpha_value": 0.13376043965223688, "duration": 162.5939965248108, "step": 84375}
{"episode_reward": 840.430713535449, "episode": 676.0, "Q1 loss": 5.734040922164917, "Q2 loss": 5.8644447402954105, "Mean Target Q": 729.2438388671875, "Mean Q1": 729.24613671875, "Mean Q2": 729.24671875, "critic_loss": 11.598485725402831, "batch_reward": 6.035584712982177, "actor_loss": -729.4360765026462, "actor_target_entropy": -1.0, "actor_entropy": -0.4047804003761661, "alpha_loss": -0.00028298899245959136, "alpha_value": 0.13376561430926434, "duration": 155.18418097496033, "step": 84500}
{"episode_reward": 832.3964112491452, "episode": 677.0, "Q1 loss": 6.116784952163696, "Q2 loss": 6.02236088180542, "Mean Target Q": 729.4344521484375, "Mean Q1": 729.4317841796875, "Mean Q2": 729.43360546875, "critic_loss": 12.139145793914794, "batch_reward": 6.043273681640625, "actor_loss": -729.8880314902653, "actor_target_entropy": -1.0, "actor_entropy": -0.4078152132412744, "alpha_loss": 3.373854800999638e-05, "alpha_value": 0.13381238072553592, "duration": 151.2339746952057, "step": 84625}
{"episode_reward": 823.7371291941562, "episode": 678.0, "Q1 loss": 6.040980350494385, "Q2 loss": 6.082764192581177, "Mean Target Q": 729.4705649414062, "Mean Q1": 729.4647475585938, "Mean Q2": 729.4639252929687, "critic_loss": 12.123744525909423, "batch_reward": 6.038441688537597, "actor_loss": -729.9845709031628, "actor_target_entropy": -1.0, "actor_entropy": -0.39668998699034413, "alpha_loss": 0.0030876242850471527, "alpha_value": 0.13351923173120284, "duration": 154.21328258514404, "step": 84750}
{"episode_reward": 843.9084162360215, "episode": 679.0, "Q1 loss": 5.392588050842285, "Q2 loss": 5.419038736343384, "Mean Target Q": 729.6394033203125, "Mean Q1": 729.6414409179688, "Mean Q2": 729.6429208984375, "critic_loss": 10.811626762390137, "batch_reward": 6.033760433197021, "actor_loss": -730.2395348927331, "actor_target_entropy": -1.0, "actor_entropy": -0.402920507249378, "alpha_loss": 0.0026464309979466693, "alpha_value": 0.13326228338424637, "duration": 145.3647322654724, "step": 84875}
{"episode_reward": 841.2246674803018, "episode": 680.0, "Q1 loss": 5.720271398544312, "Q2 loss": 5.735170501708985, "Mean Target Q": 729.65143359375, "Mean Q1": 729.6478491210937, "Mean Q2": 729.6462944335938, "critic_loss": 11.455441898345947, "batch_reward": 6.031208599090577, "actor_loss": -730.2129821777344, "actor_target_entropy": -1.0, "actor_entropy": -0.40695153945876705, "alpha_loss": 0.0037674775418464934, "alpha_value": 0.13298930338876847, "step": 85000}
{"duration": 173.13276624679565, "step": 85000}
{"episode_reward": 739.8113067779043, "episode": 681.0, "Q1 loss": 5.956985458374024, "Q2 loss": 5.90852749633789, "Mean Target Q": 729.8969741210938, "Mean Q1": 729.9023481445313, "Mean Q2": 729.9030732421875, "critic_loss": 11.865512908935546, "batch_reward": 6.052171974182129, "actor_loss": -730.0583224826389, "actor_target_entropy": -1.0, "actor_entropy": -0.3965759433451153, "alpha_loss": 0.0011506779137850991, "alpha_value": 0.13275318657862403, "duration": 139.77039051055908, "step": 85125}
{"episode_reward": 843.8069479189803, "episode": 682.0, "Q1 loss": 5.58151194190979, "Q2 loss": 5.569762403488159, "Mean Target Q": 729.8546352539063, "Mean Q1": 729.8541064453125, "Mean Q2": 729.8527705078125, "critic_loss": 11.15127439880371, "batch_reward": 6.02930813217163, "actor_loss": -730.4327313823085, "actor_target_entropy": -1.0, "actor_entropy": -0.3990840354273396, "alpha_loss": 0.004040206338451695, "alpha_value": 0.13245995011144676, "duration": 176.35267424583435, "step": 85250}
{"episode_reward": 833.8045218156489, "episode": 683.0, "Q1 loss": 5.653192863464356, "Q2 loss": 5.723198068618775, "Mean Target Q": 730.1770322265625, "Mean Q1": 730.1727216796875, "Mean Q2": 730.1736430664063, "critic_loss": 11.376390956878662, "batch_reward": 6.0419896049499515, "actor_loss": -730.9562804206969, "actor_target_entropy": -1.0, "actor_entropy": -0.41219697301349945, "alpha_loss": 0.004328785836511839, "alpha_value": 0.13206338063583425, "duration": 186.75389194488525, "step": 85375}
{"episode_reward": 839.7399997106849, "episode": 684.0, "Q1 loss": 6.406966524124146, "Q2 loss": 6.356969514846802, "Mean Target Q": 730.3435693359374, "Mean Q1": 730.339794921875, "Mean Q2": 730.3413676757813, "critic_loss": 12.763936042785645, "batch_reward": 6.056106208801269, "actor_loss": -730.803963938067, "actor_target_entropy": -1.0, "actor_entropy": -0.4266822429433946, "alpha_loss": 0.002963046828705457, "alpha_value": 0.1316874321687451, "duration": 192.2104001045227, "step": 85500}
{"episode_reward": 835.6753063536162, "episode": 685.0, "Q1 loss": 6.046851135253906, "Q2 loss": 6.057896186828613, "Mean Target Q": 730.4223061523437, "Mean Q1": 730.4260625, "Mean Q2": 730.4247548828125, "critic_loss": 12.104747303009033, "batch_reward": 6.059777759552002, "actor_loss": -730.5841645740327, "actor_target_entropy": -1.0, "actor_entropy": -0.41381780259192935, "alpha_loss": -0.0019712592105543803, "alpha_value": 0.1316565042633082, "duration": 214.11768341064453, "step": 85625}
{"episode_reward": 835.5992457261847, "episode": 686.0, "Q1 loss": 6.076912832260132, "Q2 loss": 6.113169509887696, "Mean Target Q": 730.2322622070312, "Mean Q1": 730.2334189453125, "Mean Q2": 730.2331953125, "critic_loss": 12.190082389831543, "batch_reward": 6.038355480194092, "actor_loss": -730.5598774571573, "actor_target_entropy": -1.0, "actor_entropy": -0.408625181163511, "alpha_loss": -0.001438959255709403, "alpha_value": 0.13182581683679243, "duration": 202.75118589401245, "step": 85750}
{"episode_reward": 819.6786528906565, "episode": 687.0, "Q1 loss": 6.478725553512573, "Q2 loss": 6.5114055995941165, "Mean Target Q": 730.28458984375, "Mean Q1": 730.2783032226563, "Mean Q2": 730.2781958007813, "critic_loss": 12.990131191253662, "batch_reward": 6.03636856842041, "actor_loss": -730.4619528149801, "actor_target_entropy": -1.0, "actor_entropy": -0.3962164000859336, "alpha_loss": 0.0016485108099582176, "alpha_value": 0.1317643685765654, "duration": 220.13994073867798, "step": 85875}
{"episode_reward": 805.7018909913636, "episode": 688.0, "Q1 loss": 7.162485664367676, "Q2 loss": 7.258000045776368, "Mean Target Q": 730.510060546875, "Mean Q1": 730.5100185546875, "Mean Q2": 730.5085239257812, "critic_loss": 14.420485759735108, "batch_reward": 6.047811203002929, "actor_loss": -731.2173255182082, "actor_target_entropy": -1.0, "actor_entropy": -0.4178580848440047, "alpha_loss": 0.0008822082140062364, "alpha_value": 0.1317608613408001, "duration": 192.16472959518433, "step": 86000}
{"episode_reward": 804.0296075233098, "episode": 689.0, "Q1 loss": 5.8659784088134765, "Q2 loss": 5.869738916397095, "Mean Target Q": 730.8057861328125, "Mean Q1": 730.80837890625, "Mean Q2": 730.8096118164062, "critic_loss": 11.735717311859132, "batch_reward": 6.057752689361572, "actor_loss": -731.1750401088169, "actor_target_entropy": -1.0, "actor_entropy": -0.3764093868316166, "alpha_loss": 0.004638201322421313, "alpha_value": 0.13142370616682264, "duration": 211.9359953403473, "step": 86125}
{"episode_reward": 833.6667131122695, "episode": 690.0, "Q1 loss": 5.850714595794678, "Q2 loss": 5.822388265609741, "Mean Target Q": 730.9856552734375, "Mean Q1": 730.978970703125, "Mean Q2": 730.977337890625, "critic_loss": 11.673102867126465, "batch_reward": 6.051336204528808, "actor_loss": -731.334463796308, "actor_target_entropy": -1.0, "actor_entropy": -0.3773505742992124, "alpha_loss": 0.004101722184831517, "alpha_value": 0.1310559262180732, "duration": 215.1070237159729, "step": 86250}
{"episode_reward": 822.8792509342114, "episode": 691.0, "Q1 loss": 5.92210346031189, "Q2 loss": 5.7660412654876705, "Mean Target Q": 730.8736665039063, "Mean Q1": 730.8731489257813, "Mean Q2": 730.8743198242188, "critic_loss": 11.688144737243652, "batch_reward": 6.037194610595703, "actor_loss": -731.2906271313864, "actor_target_entropy": -1.0, "actor_entropy": -0.4228024440152304, "alpha_loss": -0.0026563219578256683, "alpha_value": 0.13086391409904702, "duration": 202.73934268951416, "step": 86375}
{"episode_reward": 843.9971406301967, "episode": 692.0, "Q1 loss": 5.694032804489136, "Q2 loss": 5.6472675876617435, "Mean Target Q": 731.0656557617187, "Mean Q1": 731.0655922851563, "Mean Q2": 731.0658979492188, "critic_loss": 11.341300380706787, "batch_reward": 6.0401212577819825, "actor_loss": -731.1554043677545, "actor_target_entropy": -1.0, "actor_entropy": -0.40105906753770765, "alpha_loss": 0.0003725868262981455, "alpha_value": 0.13094078875210846, "duration": 203.04530549049377, "step": 86500}
{"episode_reward": 813.5068090268243, "episode": 693.0, "Q1 loss": 6.2873705291748045, "Q2 loss": 6.290223974227906, "Mean Target Q": 731.088650390625, "Mean Q1": 731.083607421875, "Mean Q2": 731.0837412109375, "critic_loss": 12.577594512939454, "batch_reward": 6.0458544120788575, "actor_loss": -731.7761647057912, "actor_target_entropy": -1.0, "actor_entropy": -0.41285671790440875, "alpha_loss": 0.0011249883867253268, "alpha_value": 0.13100732933564968, "duration": 230.17679929733276, "step": 86625}
{"episode_reward": 832.4465047980225, "episode": 694.0, "Q1 loss": 5.154966540336609, "Q2 loss": 5.190928050994873, "Mean Target Q": 731.0239877929688, "Mean Q1": 731.0260229492187, "Mean Q2": 731.0246782226562, "critic_loss": 10.345894535064698, "batch_reward": 6.033844470977783, "actor_loss": -731.7514126685357, "actor_target_entropy": -1.0, "actor_entropy": -0.43170374679949974, "alpha_loss": -0.0014250014566876475, "alpha_value": 0.13102860405078584, "duration": 213.9644274711609, "step": 86750}
{"episode_reward": 783.9934962466257, "episode": 695.0, "Q1 loss": 6.2844065608978275, "Q2 loss": 6.221052799224854, "Mean Target Q": 731.4500908203125, "Mean Q1": 731.45518359375, "Mean Q2": 731.4573637695313, "critic_loss": 12.50545934677124, "batch_reward": 6.048695770263672, "actor_loss": -732.1681305416047, "actor_target_entropy": -1.0, "actor_entropy": -0.4299175876473624, "alpha_loss": 0.003370985526421536, "alpha_value": 0.1308058784569319, "duration": 200.73400402069092, "step": 86875}
{"episode_reward": 842.7744063066233, "episode": 696.0, "Q1 loss": 6.038021627426147, "Q2 loss": 5.937134294509888, "Mean Target Q": 731.5168627929687, "Mean Q1": 731.5121611328125, "Mean Q2": 731.511818359375, "critic_loss": 11.975155899047852, "batch_reward": 6.046100128173828, "actor_loss": -731.7311824675529, "actor_target_entropy": -1.0, "actor_entropy": -0.42242232013133263, "alpha_loss": 0.0052160855510362215, "alpha_value": 0.13042188378363762, "duration": 203.0036895275116, "step": 87000}
{"episode_reward": 840.5521980281499, "episode": 697.0, "Q1 loss": 5.383123376846314, "Q2 loss": 5.482348398208618, "Mean Target Q": 731.8737065429688, "Mean Q1": 731.876, "Mean Q2": 731.8753139648437, "critic_loss": 10.865471782684326, "batch_reward": 6.058625522613525, "actor_loss": -732.4508366660466, "actor_target_entropy": -1.0, "actor_entropy": -0.40572919968574767, "alpha_loss": 0.003126489142665551, "alpha_value": 0.13009464204863108, "duration": 202.78040981292725, "step": 87125}
{"episode_reward": 834.0149098096265, "episode": 698.0, "Q1 loss": 5.955388729095459, "Q2 loss": 6.031591073989868, "Mean Target Q": 731.853748046875, "Mean Q1": 731.8482075195312, "Mean Q2": 731.848892578125, "critic_loss": 11.98697975921631, "batch_reward": 6.056297061920166, "actor_loss": -732.3509531328755, "actor_target_entropy": -1.0, "actor_entropy": -0.42388395484416713, "alpha_loss": -0.001105522669311012, "alpha_value": 0.12998015384212516, "duration": 197.8386673927307, "step": 87250}
{"episode_reward": 841.454934276532, "episode": 699.0, "Q1 loss": 5.139764097213745, "Q2 loss": 5.1664676723480225, "Mean Target Q": 731.9524145507812, "Mean Q1": 731.950896484375, "Mean Q2": 731.952005859375, "critic_loss": 10.30623180770874, "batch_reward": 6.058298755645752, "actor_loss": -732.4945891849578, "actor_target_entropy": -1.0, "actor_entropy": -0.4188832948132167, "alpha_loss": 0.0039618057124908, "alpha_value": 0.12992524197815997, "duration": 215.71614837646484, "step": 87375}
{"episode_reward": 835.0846463281746, "episode": 700.0, "Q1 loss": 5.621496297836304, "Q2 loss": 5.641229717254639, "Mean Target Q": 732.133712890625, "Mean Q1": 732.1386752929687, "Mean Q2": 732.1381831054688, "critic_loss": 11.262725959777832, "batch_reward": 6.060064079284668, "actor_loss": -732.437751031691, "actor_target_entropy": -1.0, "actor_entropy": -0.41458838649334445, "alpha_loss": 0.0014870239106277304, "alpha_value": 0.12958513079494355, "duration": 212.1648075580597, "step": 87500}
{"episode_reward": 840.1606851004312, "episode": 701.0, "Q1 loss": 6.060529706954956, "Q2 loss": 6.035796028137207, "Mean Target Q": 732.2599165039062, "Mean Q1": 732.253646484375, "Mean Q2": 732.2526508789063, "critic_loss": 12.096325736999512, "batch_reward": 6.077454917907715, "actor_loss": -732.5909297882564, "actor_target_entropy": -1.0, "actor_entropy": -0.3839498261610667, "alpha_loss": 0.0023019505241545775, "alpha_value": 0.12942597171552891, "duration": 218.9167721271515, "step": 87625}
{"episode_reward": 836.2898907995101, "episode": 702.0, "Q1 loss": 6.266048080444336, "Q2 loss": 6.294763555526734, "Mean Target Q": 732.0463115234375, "Mean Q1": 732.0523369140625, "Mean Q2": 732.05239453125, "critic_loss": 12.560811656951904, "batch_reward": 6.042813358306884, "actor_loss": -732.3584712859123, "actor_target_entropy": -1.0, "actor_entropy": -0.3979458015772604, "alpha_loss": 0.004090110271898729, "alpha_value": 0.12913197113688846, "duration": 219.70908427238464, "step": 87750}
{"episode_reward": 832.608082811526, "episode": 703.0, "Q1 loss": 5.832131118774414, "Q2 loss": 5.844677568435669, "Mean Target Q": 731.8855122070313, "Mean Q1": 731.8843193359374, "Mean Q2": 731.8845673828125, "critic_loss": 11.676808712005615, "batch_reward": 6.034676570892334, "actor_loss": -732.4050738622271, "actor_target_entropy": -1.0, "actor_entropy": -0.4394662474829053, "alpha_loss": -0.00408683661445384, "alpha_value": 0.12914660822444626, "duration": 223.1541042327881, "step": 87875}
{"episode_reward": 835.9024568709607, "episode": 704.0, "Q1 loss": 6.647705457687378, "Q2 loss": 6.705110269546509, "Mean Target Q": 732.4746625976562, "Mean Q1": 732.4670639648438, "Mean Q2": 732.4655278320313, "critic_loss": 13.35281569671631, "batch_reward": 6.072062057495117, "actor_loss": -733.1019966371598, "actor_target_entropy": -1.0, "actor_entropy": -0.44158069981682685, "alpha_loss": 0.00023500559919123208, "alpha_value": 0.12920771158415148, "duration": 214.4667329788208, "step": 88000}
{"episode_reward": 850.1926446973573, "episode": 705.0, "Q1 loss": 6.175842384338379, "Q2 loss": 6.232453283309937, "Mean Target Q": 732.453830078125, "Mean Q1": 732.4486342773438, "Mean Q2": 732.45015234375, "critic_loss": 12.40829573059082, "batch_reward": 6.064644016265869, "actor_loss": -733.1493074931795, "actor_target_entropy": -1.0, "actor_entropy": -0.42713749077585006, "alpha_loss": -2.2698846083903122e-05, "alpha_value": 0.12929454136872776, "duration": 221.93219089508057, "step": 88125}
{"episode_reward": 729.6068456402727, "episode": 706.0, "Q1 loss": 5.489420463562012, "Q2 loss": 5.474158229827881, "Mean Target Q": 732.5640517578125, "Mean Q1": 732.5667768554688, "Mean Q2": 732.5665620117187, "critic_loss": 10.963578723907471, "batch_reward": 6.060889987945557, "actor_loss": -733.2855027721774, "actor_target_entropy": -1.0, "actor_entropy": -0.43073944266765346, "alpha_loss": 0.0006229627254088559, "alpha_value": 0.12929089900463034, "duration": 221.38621473312378, "step": 88250}
{"episode_reward": 826.2452016612644, "episode": 707.0, "Q1 loss": 5.690220882415772, "Q2 loss": 5.653921585083008, "Mean Target Q": 732.5797534179687, "Mean Q1": 732.5776962890625, "Mean Q2": 732.577041015625, "critic_loss": 11.344142456054687, "batch_reward": 6.059265880584717, "actor_loss": -732.8355567568824, "actor_target_entropy": -1.0, "actor_entropy": -0.40567034104513744, "alpha_loss": -0.00017629665163685642, "alpha_value": 0.12914105359673908, "duration": 217.28110575675964, "step": 88375}
{"episode_reward": 841.2460314960616, "episode": 708.0, "Q1 loss": 6.144567419052124, "Q2 loss": 6.137568071365356, "Mean Target Q": 732.796, "Mean Q1": 732.8000249023437, "Mean Q2": 732.8007543945313, "critic_loss": 12.282135509490967, "batch_reward": 6.0619457244873045, "actor_loss": -733.1693636986518, "actor_target_entropy": -1.0, "actor_entropy": -0.4214193316236619, "alpha_loss": 0.0017317823226368355, "alpha_value": 0.12914099155672046, "duration": 193.53103590011597, "step": 88500}
{"episode_reward": 836.3195848927922, "episode": 709.0, "Q1 loss": 6.179255844116211, "Q2 loss": 6.234855838775635, "Mean Target Q": 732.8314174804688, "Mean Q1": 732.8320815429687, "Mean Q2": 732.8325341796875, "critic_loss": 12.414111663818359, "batch_reward": 6.057827434539795, "actor_loss": -733.6639055524554, "actor_target_entropy": -1.0, "actor_entropy": -0.4157771094450875, "alpha_loss": 0.0028869762798653, "alpha_value": 0.12891371063350573, "duration": 187.20214533805847, "step": 88625}
{"episode_reward": 840.9195855099236, "episode": 710.0, "Q1 loss": 6.096235090255737, "Q2 loss": 6.150496671676636, "Mean Target Q": 733.0652451171875, "Mean Q1": 733.0605424804687, "Mean Q2": 733.0604267578125, "critic_loss": 12.246731754302978, "batch_reward": 6.072888553619385, "actor_loss": -733.4934269074471, "actor_target_entropy": -1.0, "actor_entropy": -0.44381160601492853, "alpha_loss": 0.0012762666034001496, "alpha_value": 0.12856455220388147, "duration": 168.61245965957642, "step": 88750}
{"episode_reward": 840.3181404361083, "episode": 711.0, "Q1 loss": 5.988748264312744, "Q2 loss": 5.95185347366333, "Mean Target Q": 732.9283818359374, "Mean Q1": 732.9244462890625, "Mean Q2": 732.9242734375, "critic_loss": 11.940601745605468, "batch_reward": 6.052427223205567, "actor_loss": -733.3711102198041, "actor_target_entropy": -1.0, "actor_entropy": -0.4216510932596903, "alpha_loss": 0.001734981678300611, "alpha_value": 0.12859563396531037, "duration": 173.89344763755798, "step": 88875}
{"episode_reward": 828.3515685150178, "episode": 712.0, "Q1 loss": 5.877752555847168, "Q2 loss": 5.780073266983032, "Mean Target Q": 733.1837954101562, "Mean Q1": 733.1790590820312, "Mean Q2": 733.1792192382812, "critic_loss": 11.657825912475586, "batch_reward": 6.065651737213135, "actor_loss": -733.3829266948085, "actor_target_entropy": -1.0, "actor_entropy": -0.4240613627818323, "alpha_loss": -0.0006231736868710047, "alpha_value": 0.12842681630010616, "duration": 152.5509431362152, "step": 89000}
{"episode_reward": 843.3260632579811, "episode": 713.0, "Q1 loss": 5.9059211597442625, "Q2 loss": 5.903200706481933, "Mean Target Q": 733.2954453125, "Mean Q1": 733.296712890625, "Mean Q2": 733.2956357421875, "critic_loss": 11.809121864318847, "batch_reward": 6.068495544433594, "actor_loss": -733.6050298781622, "actor_target_entropy": -1.0, "actor_entropy": -0.4234603194017259, "alpha_loss": -0.0003828309413548263, "alpha_value": 0.12843389019805584, "duration": 164.21903896331787, "step": 89125}
{"episode_reward": 826.9107201603688, "episode": 714.0, "Q1 loss": 5.306309160232544, "Q2 loss": 5.342489742279053, "Mean Target Q": 733.0690146484375, "Mean Q1": 733.0697592773438, "Mean Q2": 733.0707661132813, "critic_loss": 10.648798862457275, "batch_reward": 6.053001403808594, "actor_loss": -733.6867134340348, "actor_target_entropy": -1.0, "actor_entropy": -0.42329007627502563, "alpha_loss": -0.0031369104709160784, "alpha_value": 0.12868889398411765, "duration": 166.00599551200867, "step": 89250}
{"episode_reward": 846.6934226597405, "episode": 715.0, "Q1 loss": 5.571052179336548, "Q2 loss": 5.522673091888428, "Mean Target Q": 733.4793569335937, "Mean Q1": 733.474599609375, "Mean Q2": 733.4745395507813, "critic_loss": 11.093725204467773, "batch_reward": 6.063278717041015, "actor_loss": -733.9496053059896, "actor_target_entropy": -1.0, "actor_entropy": -0.3793614095165616, "alpha_loss": 0.00511214926299299, "alpha_value": 0.12857287065841144, "duration": 164.98795652389526, "step": 89375}
{"episode_reward": 840.7757295136845, "episode": 716.0, "Q1 loss": 5.450336488723755, "Q2 loss": 5.483013578414917, "Mean Target Q": 733.6575224609375, "Mean Q1": 733.6614135742187, "Mean Q2": 733.6626391601562, "critic_loss": 10.933350074768066, "batch_reward": 6.053379981994629, "actor_loss": -733.8997930711315, "actor_target_entropy": -1.0, "actor_entropy": -0.4048684460501517, "alpha_loss": 0.0006140057652843215, "alpha_value": 0.12835037267433563, "duration": 159.29935312271118, "step": 89500}
{"episode_reward": 848.0651625607187, "episode": 717.0, "Q1 loss": 5.948112131118775, "Q2 loss": 5.916859239578247, "Mean Target Q": 733.6440688476563, "Mean Q1": 733.6460776367187, "Mean Q2": 733.644591796875, "critic_loss": 11.864971397399902, "batch_reward": 6.065367115020752, "actor_loss": -733.9434620690724, "actor_target_entropy": -1.0, "actor_entropy": -0.450453623892769, "alpha_loss": -0.0015716959301027515, "alpha_value": 0.12843105142508038, "duration": 162.56503915786743, "step": 89625}
{"episode_reward": 819.849646816361, "episode": 718.0, "Q1 loss": 5.103408388137817, "Q2 loss": 5.086758945465088, "Mean Target Q": 734.1220922851562, "Mean Q1": 734.1200595703125, "Mean Q2": 734.120884765625, "critic_loss": 10.190167278289795, "batch_reward": 6.077207313537597, "actor_loss": -734.6563248172884, "actor_target_entropy": -1.0, "actor_entropy": -0.43034921250035685, "alpha_loss": 0.0012502895598675335, "alpha_value": 0.1284647642810446, "duration": 187.68383312225342, "step": 89750}
{"episode_reward": 804.8836420715132, "episode": 719.0, "Q1 loss": 5.434038480758667, "Q2 loss": 5.408686046600342, "Mean Target Q": 733.8154501953125, "Mean Q1": 733.81048828125, "Mean Q2": 733.8092436523438, "critic_loss": 10.842724544525147, "batch_reward": 6.063237060546875, "actor_loss": -734.1445545014881, "actor_target_entropy": -1.0, "actor_entropy": -0.411267273955875, "alpha_loss": -0.000280546641627711, "alpha_value": 0.12840545488527125, "duration": 168.25611090660095, "step": 89875}
{"episode_reward": 842.4037204053985, "episode": 720.0, "Q1 loss": 5.738162893295288, "Q2 loss": 5.8050008964538575, "Mean Target Q": 733.7695727539062, "Mean Q1": 733.7659790039063, "Mean Q2": 733.7682231445312, "critic_loss": 11.543163825988769, "batch_reward": 6.0581847801208495, "actor_loss": -734.229711717175, "actor_target_entropy": -1.0, "actor_entropy": -0.43624164115998054, "alpha_loss": -0.001390003931573442, "alpha_value": 0.12842945067095435, "step": 90000}
{"duration": 170.5116307735443, "step": 90000}
{"episode_reward": 843.4783573648308, "episode": 721.0, "Q1 loss": 5.929357835769653, "Q2 loss": 5.938419384002685, "Mean Target Q": 733.5573359375, "Mean Q1": 733.5629829101563, "Mean Q2": 733.56145703125, "critic_loss": 11.8677772026062, "batch_reward": 6.0501405715942385, "actor_loss": -733.9764704628597, "actor_target_entropy": -1.0, "actor_entropy": -0.4129433002736833, "alpha_loss": 0.0019719437696039677, "alpha_value": 0.12849849995860588, "duration": 160.27086853981018, "step": 90125}
{"episode_reward": 843.8763412801871, "episode": 722.0, "Q1 loss": 6.256393201828003, "Q2 loss": 6.166960771560669, "Mean Target Q": 733.914345703125, "Mean Q1": 733.9090478515625, "Mean Q2": 733.9093935546875, "critic_loss": 12.423353958129884, "batch_reward": 6.060529632568359, "actor_loss": -734.3739830755418, "actor_target_entropy": -1.0, "actor_entropy": -0.37795629664774866, "alpha_loss": 0.002822429067530339, "alpha_value": 0.12819932112574167, "duration": 171.31913352012634, "step": 90250}
{"episode_reward": 659.399617653837, "episode": 723.0, "Q1 loss": 5.519740232467651, "Q2 loss": 5.530940052032471, "Mean Target Q": 734.5217866210937, "Mean Q1": 734.519716796875, "Mean Q2": 734.5190732421875, "critic_loss": 11.050680290222168, "batch_reward": 6.094014175415039, "actor_loss": -734.9788082062252, "actor_target_entropy": -1.0, "actor_entropy": -0.4449957325344994, "alpha_loss": -0.0009032749009156038, "alpha_value": 0.1281065830640791, "duration": 160.9078619480133, "step": 90375}
{"episode_reward": 839.3486909734072, "episode": 724.0, "Q1 loss": 5.630568806648254, "Q2 loss": 5.6765417137146, "Mean Target Q": 734.3738916015625, "Mean Q1": 734.3721928710937, "Mean Q2": 734.3708486328125, "critic_loss": 11.307110466003419, "batch_reward": 6.073413406372071, "actor_loss": -734.8434802639869, "actor_target_entropy": -1.0, "actor_entropy": -0.4367429729430906, "alpha_loss": -0.00025368485160382284, "alpha_value": 0.12818904150616564, "duration": 151.0616524219513, "step": 90500}
{"episode_reward": 831.848219414507, "episode": 725.0, "Q1 loss": 6.255444763183593, "Q2 loss": 6.227561420440674, "Mean Target Q": 734.443603515625, "Mean Q1": 734.4482104492188, "Mean Q2": 734.4487143554687, "critic_loss": 12.483006206512451, "batch_reward": 6.074592655181885, "actor_loss": -734.5331052749876, "actor_target_entropy": -1.0, "actor_entropy": -0.3985150016489483, "alpha_loss": 0.002404027001281816, "alpha_value": 0.12810271754185706, "duration": 168.46862602233887, "step": 90625}
{"episode_reward": 845.1038806036282, "episode": 726.0, "Q1 loss": 6.237627838134766, "Q2 loss": 6.2184971389770505, "Mean Target Q": 734.3545083007813, "Mean Q1": 734.3487221679687, "Mean Q2": 734.3477041015625, "critic_loss": 12.45612498474121, "batch_reward": 6.0690700073242185, "actor_loss": -734.934818390877, "actor_target_entropy": -1.0, "actor_entropy": -0.4245700566999374, "alpha_loss": 0.00021978109068567715, "alpha_value": 0.12793666477161705, "duration": 159.96794533729553, "step": 90750}
{"episode_reward": 827.7829261832971, "episode": 727.0, "Q1 loss": 6.10365947341919, "Q2 loss": 6.139661401748657, "Mean Target Q": 734.4470180664063, "Mean Q1": 734.4490771484375, "Mean Q2": 734.4508564453125, "critic_loss": 12.243320919036865, "batch_reward": 6.064809181213379, "actor_loss": -734.7660202752976, "actor_target_entropy": -1.0, "actor_entropy": -0.3869381703081585, "alpha_loss": 0.004901171499301517, "alpha_value": 0.12770535350048123, "duration": 181.82470989227295, "step": 90875}
{"episode_reward": 818.4094827598929, "episode": 728.0, "Q1 loss": 6.166563608169556, "Q2 loss": 6.239574447631836, "Mean Target Q": 734.6985864257813, "Mean Q1": 734.6965590820313, "Mean Q2": 734.6958784179687, "critic_loss": 12.406138027191162, "batch_reward": 6.077977230072022, "actor_loss": -734.9644381615424, "actor_target_entropy": -1.0, "actor_entropy": -0.34419220493685815, "alpha_loss": 0.011552316286871511, "alpha_value": 0.12693497209279941, "duration": 123.95878577232361, "step": 91000}
{"episode_reward": 835.0427576273552, "episode": 729.0, "Q1 loss": 5.752696670532226, "Q2 loss": 5.851979209899902, "Mean Target Q": 734.8062094726563, "Mean Q1": 734.8050356445312, "Mean Q2": 734.8036098632813, "critic_loss": 11.604675930023193, "batch_reward": 6.068265884399414, "actor_loss": -735.1500873868428, "actor_target_entropy": -1.0, "actor_entropy": -0.4213996311974904, "alpha_loss": 0.003573246038747981, "alpha_value": 0.12614053028314853, "duration": 164.02115201950073, "step": 91125}
{"episode_reward": 831.3400089999113, "episode": 730.0, "Q1 loss": 5.9110361328125, "Q2 loss": 5.924356136322022, "Mean Target Q": 735.0260400390625, "Mean Q1": 735.03074609375, "Mean Q2": 735.0347568359375, "critic_loss": 11.835392276763915, "batch_reward": 6.078403247833252, "actor_loss": -735.5099703881049, "actor_target_entropy": -1.0, "actor_entropy": -0.4618139098728857, "alpha_loss": -0.0016371763936589442, "alpha_value": 0.12605773574904477, "duration": 161.15493512153625, "step": 91250}
{"episode_reward": 847.905311988906, "episode": 731.0, "Q1 loss": 6.110191658020019, "Q2 loss": 6.050206228256226, "Mean Target Q": 735.0849516601562, "Mean Q1": 735.0774604492187, "Mean Q2": 735.0754711914062, "critic_loss": 12.160397903442384, "batch_reward": 6.08041989517212, "actor_loss": -735.249038938492, "actor_target_entropy": -1.0, "actor_entropy": -0.4039748921280816, "alpha_loss": 0.0007903294929761499, "alpha_value": 0.12619653164655892, "duration": 168.269615650177, "step": 91375}
{"episode_reward": 848.7331135133436, "episode": 732.0, "Q1 loss": 6.338497468948364, "Q2 loss": 6.378295686721802, "Mean Target Q": 735.8808969726563, "Mean Q1": 735.8808813476562, "Mean Q2": 735.8812749023438, "critic_loss": 12.716793117523194, "batch_reward": 6.119108276367188, "actor_loss": -736.0711226924773, "actor_target_entropy": -1.0, "actor_entropy": -0.3791643328243686, "alpha_loss": 0.0065068587784715476, "alpha_value": 0.12586017847879105, "duration": 169.8866093158722, "step": 91500}
{"episode_reward": 850.551606543071, "episode": 733.0, "Q1 loss": 6.261088933944702, "Q2 loss": 6.242134122848511, "Mean Target Q": 735.2650751953125, "Mean Q1": 735.2628452148438, "Mean Q2": 735.2628393554687, "critic_loss": 12.503223041534424, "batch_reward": 6.082242893218994, "actor_loss": -735.6148778521825, "actor_target_entropy": -1.0, "actor_entropy": -0.3648063327584948, "alpha_loss": 0.006975040175131566, "alpha_value": 0.1252635973013528, "duration": 169.62602543830872, "step": 91625}
{"episode_reward": 828.7845121160982, "episode": 734.0, "Q1 loss": 5.500234439849853, "Q2 loss": 5.6427590675354, "Mean Target Q": 735.3853706054688, "Mean Q1": 735.3863173828125, "Mean Q2": 735.3859086914063, "critic_loss": 11.142993534088134, "batch_reward": 6.071860649108887, "actor_loss": -735.5118841355846, "actor_target_entropy": -1.0, "actor_entropy": -0.39543718772549785, "alpha_loss": 0.0041088273677404126, "alpha_value": 0.12462394881118621, "duration": 171.14676094055176, "step": 91750}
{"episode_reward": 835.7215150011504, "episode": 735.0, "Q1 loss": 5.380685436248779, "Q2 loss": 5.215402496337891, "Mean Target Q": 735.3285893554687, "Mean Q1": 735.3281694335938, "Mean Q2": 735.3292241210937, "critic_loss": 10.596087928771972, "batch_reward": 6.0881471328735355, "actor_loss": -736.0138530428447, "actor_target_entropy": -1.0, "actor_entropy": -0.41927150459516616, "alpha_loss": 0.000791273905806953, "alpha_value": 0.12443959117319607, "duration": 155.98590779304504, "step": 91875}
{"episode_reward": 842.2068384386799, "episode": 736.0, "Q1 loss": 5.3832779302597045, "Q2 loss": 5.351714307785034, "Mean Target Q": 735.5229379882812, "Mean Q1": 735.5213354492188, "Mean Q2": 735.5197797851563, "critic_loss": 10.734992237091065, "batch_reward": 6.088021194458007, "actor_loss": -735.879163188319, "actor_target_entropy": -1.0, "actor_entropy": -0.43865321336254, "alpha_loss": -0.00133758197508512, "alpha_value": 0.12446723417776102, "duration": 165.10465669631958, "step": 92000}
{"episode_reward": 842.5800916828841, "episode": 737.0, "Q1 loss": 5.69876806640625, "Q2 loss": 5.6908639011383055, "Mean Target Q": 735.5817221679688, "Mean Q1": 735.57491015625, "Mean Q2": 735.5762114257813, "critic_loss": 11.389631988525391, "batch_reward": 6.0873231582641605, "actor_loss": -735.7569977291047, "actor_target_entropy": -1.0, "actor_entropy": -0.4494592282507155, "alpha_loss": -0.001986875374328404, "alpha_value": 0.12455574602688496, "duration": 158.75132727622986, "step": 92125}
{"episode_reward": 837.7741516407777, "episode": 738.0, "Q1 loss": 5.318097812652588, "Q2 loss": 5.372482704162597, "Mean Target Q": 735.5278046875, "Mean Q1": 735.5370258789062, "Mean Q2": 735.53549609375, "critic_loss": 10.690580513000489, "batch_reward": 6.086991004943847, "actor_loss": -735.9141520838583, "actor_target_entropy": -1.0, "actor_entropy": -0.44985449698663527, "alpha_loss": -0.004681846601963644, "alpha_value": 0.12491359993751906, "duration": 156.88076543807983, "step": 92250}
{"episode_reward": 845.6607319631354, "episode": 739.0, "Q1 loss": 5.236918474197387, "Q2 loss": 5.1710954208374025, "Mean Target Q": 735.7580068359375, "Mean Q1": 735.7532744140625, "Mean Q2": 735.7541875, "critic_loss": 10.408013885498047, "batch_reward": 6.079520385742187, "actor_loss": -736.2837495349702, "actor_target_entropy": -1.0, "actor_entropy": -0.4455711453680008, "alpha_loss": 0.0009153598830813454, "alpha_value": 0.125128979264436, "duration": 154.238431930542, "step": 92375}
{"episode_reward": 841.2091534374239, "episode": 740.0, "Q1 loss": 6.304125518798828, "Q2 loss": 6.357381158828735, "Mean Target Q": 735.7937109375, "Mean Q1": 735.7906357421875, "Mean Q2": 735.7908828125, "critic_loss": 12.661506706237793, "batch_reward": 6.084408840179443, "actor_loss": -735.9255951912172, "actor_target_entropy": -1.0, "actor_entropy": -0.47099754214286804, "alpha_loss": -0.00447775776715829, "alpha_value": 0.12522249926086285, "duration": 180.00968766212463, "step": 92500}
{"episode_reward": 839.5018062739586, "episode": 741.0, "Q1 loss": 5.675638942718506, "Q2 loss": 5.638879430770874, "Mean Target Q": 735.9329223632812, "Mean Q1": 735.9318369140625, "Mean Q2": 735.9303012695312, "critic_loss": 11.314518398284912, "batch_reward": 6.079446434020996, "actor_loss": -736.1559738885788, "actor_target_entropy": -1.0, "actor_entropy": -0.427165376761603, "alpha_loss": 0.0006886772231184064, "alpha_value": 0.1256400813998203, "duration": 151.22357153892517, "step": 92625}
{"episode_reward": 842.3530270375509, "episode": 742.0, "Q1 loss": 5.440149681091309, "Q2 loss": 5.437584386825561, "Mean Target Q": 735.9826645507812, "Mean Q1": 735.9844560546875, "Mean Q2": 735.9857880859375, "critic_loss": 10.877734088897705, "batch_reward": 6.084594486236572, "actor_loss": -736.1411467521422, "actor_target_entropy": -1.0, "actor_entropy": -0.42878116282724565, "alpha_loss": 0.0005766336163956552, "alpha_value": 0.12535581407231733, "duration": 149.02075481414795, "step": 92750}
{"episode_reward": 843.0047193070423, "episode": 743.0, "Q1 loss": 5.541421602249145, "Q2 loss": 5.43573916053772, "Mean Target Q": 736.25116796875, "Mean Q1": 736.2506059570312, "Mean Q2": 736.2526967773438, "critic_loss": 10.977160751342774, "batch_reward": 6.097926002502441, "actor_loss": -736.6984437003969, "actor_target_entropy": -1.0, "actor_entropy": -0.4069386876764752, "alpha_loss": 0.004941892983864934, "alpha_value": 0.12516369956112172, "duration": 160.28353905677795, "step": 92875}
{"episode_reward": 780.9957931965963, "episode": 744.0, "Q1 loss": 5.84237092590332, "Q2 loss": 5.792144449234009, "Mean Target Q": 736.4960541992187, "Mean Q1": 736.4918208007813, "Mean Q2": 736.4915668945313, "critic_loss": 11.634515361785889, "batch_reward": 6.102720806121826, "actor_loss": -736.9335356681578, "actor_target_entropy": -1.0, "actor_entropy": -0.4192028531143742, "alpha_loss": 0.00462553937423734, "alpha_value": 0.12474966008148176, "duration": 162.80016493797302, "step": 93000}
{"episode_reward": 842.543780845221, "episode": 745.0, "Q1 loss": 5.906558084487915, "Q2 loss": 5.862872692108154, "Mean Target Q": 736.4159682617187, "Mean Q1": 736.412482421875, "Mean Q2": 736.4105004882813, "critic_loss": 11.769430767059326, "batch_reward": 6.098904064178467, "actor_loss": -736.6400340246776, "actor_target_entropy": -1.0, "actor_entropy": -0.43590074824908426, "alpha_loss": 7.914746039739204e-05, "alpha_value": 0.12452778492589725, "duration": 178.56306290626526, "step": 93125}
{"episode_reward": 780.9545895806149, "episode": 746.0, "Q1 loss": 5.851156623840332, "Q2 loss": 5.914521226882934, "Mean Target Q": 736.3649892578125, "Mean Q1": 736.3678618164063, "Mean Q2": 736.3656801757812, "critic_loss": 11.765677856445313, "batch_reward": 6.082894989013672, "actor_loss": -736.3960709110384, "actor_target_entropy": -1.0, "actor_entropy": -0.43159375411848866, "alpha_loss": 0.0019224088990144551, "alpha_value": 0.12441945138559836, "duration": 175.33673906326294, "step": 93250}
{"episode_reward": 840.017469945433, "episode": 747.0, "Q1 loss": 5.814357301712036, "Q2 loss": 5.591902379989624, "Mean Target Q": 736.4409829101562, "Mean Q1": 736.438103515625, "Mean Q2": 736.43990234375, "critic_loss": 11.406259662628173, "batch_reward": 6.097469333648681, "actor_loss": -737.0078522212922, "actor_target_entropy": -1.0, "actor_entropy": -0.41802811953756547, "alpha_loss": 0.005319488269927364, "alpha_value": 0.12400803421425863, "duration": 162.52123951911926, "step": 93375}
{"episode_reward": 743.0283717738814, "episode": 748.0, "Q1 loss": 5.078698289871216, "Q2 loss": 5.218509677886963, "Mean Target Q": 736.7516821289063, "Mean Q1": 736.7484907226562, "Mean Q2": 736.74734765625, "critic_loss": 10.297208015441894, "batch_reward": 6.105440792083741, "actor_loss": -737.1069641113281, "actor_target_entropy": -1.0, "actor_entropy": -0.4051256920060804, "alpha_loss": 0.002916066775909595, "alpha_value": 0.12369049967361749, "duration": 168.0274579524994, "step": 93500}
{"episode_reward": 845.5531670411391, "episode": 749.0, "Q1 loss": 5.351446743011475, "Q2 loss": 5.325419630050659, "Mean Target Q": 736.6307700195313, "Mean Q1": 736.6338154296875, "Mean Q2": 736.635248046875, "critic_loss": 10.676866367340088, "batch_reward": 6.098051986694336, "actor_loss": -737.0743175688244, "actor_target_entropy": -1.0, "actor_entropy": -0.4158397004717872, "alpha_loss": 0.00119872871021341, "alpha_value": 0.12356268653096002, "duration": 181.901917219162, "step": 93625}
{"episode_reward": 849.8027607854982, "episode": 750.0, "Q1 loss": 4.852756851196289, "Q2 loss": 4.934576126098633, "Mean Target Q": 736.7634116210937, "Mean Q1": 736.7672783203125, "Mean Q2": 736.7669140625, "critic_loss": 9.787332956314087, "batch_reward": 6.0927000312805175, "actor_loss": -737.2461587229083, "actor_target_entropy": -1.0, "actor_entropy": -0.404319534378667, "alpha_loss": -0.0004831338188641014, "alpha_value": 0.1234488949066759, "duration": 154.84759330749512, "step": 93750}
{"episode_reward": 850.6093216893901, "episode": 751.0, "Q1 loss": 5.335102090835571, "Q2 loss": 5.320524442672729, "Mean Target Q": 737.0543759765625, "Mean Q1": 737.0463295898437, "Mean Q2": 737.0473564453125, "critic_loss": 10.655626518249512, "batch_reward": 6.1015106964111325, "actor_loss": -737.2553429982019, "actor_target_entropy": -1.0, "actor_entropy": -0.44096706121686907, "alpha_loss": -0.0008084203240402516, "alpha_value": 0.12355445983175288, "duration": 165.55608797073364, "step": 93875}
{"episode_reward": 847.1712744923796, "episode": 752.0, "Q1 loss": 5.2931050777435305, "Q2 loss": 5.283586168289185, "Mean Target Q": 737.0700805664062, "Mean Q1": 737.0726342773437, "Mean Q2": 737.0725209960938, "critic_loss": 10.5766912651062, "batch_reward": 6.114665916442871, "actor_loss": -737.3468263687625, "actor_target_entropy": -1.0, "actor_entropy": -0.4366159391018652, "alpha_loss": -0.00015569584079897932, "alpha_value": 0.12351286539069409, "duration": 149.06610131263733, "step": 94000}
{"episode_reward": 832.7469366030493, "episode": 753.0, "Q1 loss": 5.794209815979004, "Q2 loss": 5.768905193328857, "Mean Target Q": 736.802146484375, "Mean Q1": 736.7998432617187, "Mean Q2": 736.7992094726562, "critic_loss": 11.563115016937257, "batch_reward": 6.08238236618042, "actor_loss": -737.1099427238344, "actor_target_entropy": -1.0, "actor_entropy": -0.4269216216745831, "alpha_loss": 0.0022222003742446384, "alpha_value": 0.12339895202600448, "duration": 167.44776487350464, "step": 94125}
{"episode_reward": 841.4493661629659, "episode": 754.0, "Q1 loss": 5.948496062278748, "Q2 loss": 5.84557967376709, "Mean Target Q": 737.1649809570313, "Mean Q1": 737.1650620117188, "Mean Q2": 737.1646000976563, "critic_loss": 11.794075771331787, "batch_reward": 6.108598636627197, "actor_loss": -737.576391404675, "actor_target_entropy": -1.0, "actor_entropy": -0.4507775739316017, "alpha_loss": -0.00036756950336688706, "alpha_value": 0.12326395622776881, "duration": 152.32331895828247, "step": 94250}
{"episode_reward": 834.5381206496916, "episode": 755.0, "Q1 loss": 5.553385116577148, "Q2 loss": 5.708298013687134, "Mean Target Q": 736.8215200195312, "Mean Q1": 736.8247407226562, "Mean Q2": 736.825923828125, "critic_loss": 11.261683200836181, "batch_reward": 6.090751529693604, "actor_loss": -737.1447569831969, "actor_target_entropy": -1.0, "actor_entropy": -0.40829420893911333, "alpha_loss": -6.995544702346836e-05, "alpha_value": 0.12340521000562465, "duration": 166.63698077201843, "step": 94375}
{"episode_reward": 760.4612022570963, "episode": 756.0, "Q1 loss": 5.854183195114135, "Q2 loss": 5.815776441574097, "Mean Target Q": 737.2212553710938, "Mean Q1": 737.21901171875, "Mean Q2": 737.2167944335938, "critic_loss": 11.669959663391113, "batch_reward": 6.107230556488037, "actor_loss": -737.5646756079889, "actor_target_entropy": -1.0, "actor_entropy": -0.40460665668210677, "alpha_loss": 0.002484320360611403, "alpha_value": 0.12320387836016236, "duration": 168.7665433883667, "step": 94500}
{"episode_reward": 841.1224376434745, "episode": 757.0, "Q1 loss": 5.979863374710083, "Q2 loss": 5.953306810379028, "Mean Target Q": 737.311935546875, "Mean Q1": 737.3060791015625, "Mean Q2": 737.306255859375, "critic_loss": 11.933170204162598, "batch_reward": 6.10219983291626, "actor_loss": -737.8746095687624, "actor_target_entropy": -1.0, "actor_entropy": -0.44219603661506895, "alpha_loss": 0.0004394639889517474, "alpha_value": 0.12309720177379202, "duration": 167.026597738266, "step": 94625}
{"episode_reward": 825.4369794906164, "episode": 758.0, "Q1 loss": 5.603904235839844, "Q2 loss": 5.587021150588989, "Mean Target Q": 737.3474331054688, "Mean Q1": 737.3520434570313, "Mean Q2": 737.3522802734375, "critic_loss": 11.190925399780273, "batch_reward": 6.095114234924316, "actor_loss": -737.5235448037424, "actor_target_entropy": -1.0, "actor_entropy": -0.47762386116289324, "alpha_loss": -0.0029668686310610464, "alpha_value": 0.12323611525215755, "duration": 160.2934432029724, "step": 94750}
{"episode_reward": 843.9115784901502, "episode": 759.0, "Q1 loss": 5.386696125030517, "Q2 loss": 5.434290891647339, "Mean Target Q": 737.4431303710937, "Mean Q1": 737.4363139648437, "Mean Q2": 737.437498046875, "critic_loss": 10.820987010955811, "batch_reward": 6.102431999206543, "actor_loss": -737.7495737227183, "actor_target_entropy": -1.0, "actor_entropy": -0.45956986906036495, "alpha_loss": -0.0008639991172545013, "alpha_value": 0.12340475728049312, "duration": 161.34617710113525, "step": 94875}
{"episode_reward": 827.8563283941467, "episode": 760.0, "Q1 loss": 5.950703401565551, "Q2 loss": 6.010949186325073, "Mean Target Q": 737.6402314453125, "Mean Q1": 737.6355415039062, "Mean Q2": 737.6365014648437, "critic_loss": 11.961652568817138, "batch_reward": 6.100651744842529, "actor_loss": -737.7543079007056, "actor_target_entropy": -1.0, "actor_entropy": -0.43860206200230506, "alpha_loss": -0.0005834088735883274, "alpha_value": 0.12352427994292588, "step": 95000}
{"duration": 161.36105942726135, "step": 95000}
{"episode_reward": 845.8552459603314, "episode": 761.0, "Q1 loss": 5.261904918670655, "Q2 loss": 5.2590675601959225, "Mean Target Q": 737.6181220703126, "Mean Q1": 737.6231787109375, "Mean Q2": 737.6234936523438, "critic_loss": 10.520972492218018, "batch_reward": 6.09763313293457, "actor_loss": -737.9629545665923, "actor_target_entropy": -1.0, "actor_entropy": -0.4315285677947695, "alpha_loss": 0.0007997485494891566, "alpha_value": 0.12347329243144915, "duration": 172.91726183891296, "step": 95125}
{"episode_reward": 832.7284078167236, "episode": 762.0, "Q1 loss": 5.603725606918335, "Q2 loss": 5.564179447174072, "Mean Target Q": 737.5562524414063, "Mean Q1": 737.5437104492188, "Mean Q2": 737.5432036132812, "critic_loss": 11.167905094146729, "batch_reward": 6.104439582824707, "actor_loss": -737.8803376228578, "actor_target_entropy": -1.0, "actor_entropy": -0.44957722338937944, "alpha_loss": 0.000649940457210065, "alpha_value": 0.12350328121498906, "duration": 176.34977412223816, "step": 95250}
{"episode_reward": 833.6564647384723, "episode": 763.0, "Q1 loss": 5.5813125667572026, "Q2 loss": 5.508617282867432, "Mean Target Q": 737.63409375, "Mean Q1": 737.6444833984375, "Mean Q2": 737.6420063476562, "critic_loss": 11.08992984008789, "batch_reward": 6.090473712921143, "actor_loss": -738.374527219742, "actor_target_entropy": -1.0, "actor_entropy": -0.433299122821717, "alpha_loss": 0.004500958262868817, "alpha_value": 0.1232195678342728, "duration": 177.39336133003235, "step": 95375}
{"episode_reward": 829.7343249961796, "episode": 764.0, "Q1 loss": 5.867024885177612, "Q2 loss": 5.888592956542968, "Mean Target Q": 738.1045517578125, "Mean Q1": 738.1049331054687, "Mean Q2": 738.1059794921875, "critic_loss": 11.75561784362793, "batch_reward": 6.129838657379151, "actor_loss": -738.3502266176286, "actor_target_entropy": -1.0, "actor_entropy": -0.437653205087108, "alpha_loss": 0.001326776235439484, "alpha_value": 0.12290771053612365, "duration": 160.9058575630188, "step": 95500}
{"episode_reward": 832.5780719347242, "episode": 765.0, "Q1 loss": 5.685092273712158, "Q2 loss": 5.640191583633423, "Mean Target Q": 738.0141806640625, "Mean Q1": 738.009470703125, "Mean Q2": 738.0104204101563, "critic_loss": 11.325283924102783, "batch_reward": 6.1143131332397465, "actor_loss": -738.4157230437748, "actor_target_entropy": -1.0, "actor_entropy": -0.44923779652232215, "alpha_loss": 0.0023685860122361828, "alpha_value": 0.12267630010123545, "duration": 179.8122489452362, "step": 95625}
{"episode_reward": 846.1100123185331, "episode": 766.0, "Q1 loss": 6.113543697357178, "Q2 loss": 6.128205427169799, "Mean Target Q": 737.8765166015625, "Mean Q1": 737.8785483398437, "Mean Q2": 737.8775537109375, "critic_loss": 12.241749114990235, "batch_reward": 6.102812160491943, "actor_loss": -738.1968364100302, "actor_target_entropy": -1.0, "actor_entropy": -0.4432712826998003, "alpha_loss": -0.0025905331581710807, "alpha_value": 0.12274568562746448, "duration": 156.27742505073547, "step": 95750}
{"episode_reward": 845.6582596139286, "episode": 767.0, "Q1 loss": 6.4867571144104, "Q2 loss": 6.385908988952637, "Mean Target Q": 738.09582421875, "Mean Q1": 738.1004267578126, "Mean Q2": 738.101634765625, "critic_loss": 12.872666130065918, "batch_reward": 6.106785762786865, "actor_loss": -738.2199474516369, "actor_target_entropy": -1.0, "actor_entropy": -0.42180964208784555, "alpha_loss": -0.0009169497763708471, "alpha_value": 0.12301723480906102, "duration": 155.10719108581543, "step": 95875}
{"episode_reward": 843.993671561142, "episode": 768.0, "Q1 loss": 5.68179761505127, "Q2 loss": 5.697572862625122, "Mean Target Q": 737.9368833007812, "Mean Q1": 737.9236840820313, "Mean Q2": 737.9217250976562, "critic_loss": 11.379370487213135, "batch_reward": 6.090838203430176, "actor_loss": -738.6187990250125, "actor_target_entropy": -1.0, "actor_entropy": -0.40946569894590684, "alpha_loss": 0.004792852342248925, "alpha_value": 0.12263791056451132, "duration": 162.79334211349487, "step": 96000}
{"episode_reward": 783.3230106748601, "episode": 769.0, "Q1 loss": 5.581420766830444, "Q2 loss": 5.595484577178955, "Mean Target Q": 738.0624106445313, "Mean Q1": 738.0671508789062, "Mean Q2": 738.0665844726562, "critic_loss": 11.176905311584473, "batch_reward": 6.101672630310059, "actor_loss": -738.5351572188121, "actor_target_entropy": -1.0, "actor_entropy": -0.4288780414868915, "alpha_loss": 0.0011481349116250399, "alpha_value": 0.12239575081152015, "duration": 173.7992980480194, "step": 96125}
{"episode_reward": 832.7010298990482, "episode": 770.0, "Q1 loss": 5.893119945526123, "Q2 loss": 5.9417359790802005, "Mean Target Q": 738.2253056640625, "Mean Q1": 738.220302734375, "Mean Q2": 738.2228911132812, "critic_loss": 11.83485593032837, "batch_reward": 6.105050365447998, "actor_loss": -738.3200900170111, "actor_target_entropy": -1.0, "actor_entropy": -0.4771010471928504, "alpha_loss": -0.003213428865907894, "alpha_value": 0.12236708590996632, "duration": 181.7691526412964, "step": 96250}
{"episode_reward": 835.8518780486511, "episode": 771.0, "Q1 loss": 5.30835200881958, "Q2 loss": 5.304248165130615, "Mean Target Q": 738.4005698242188, "Mean Q1": 738.40179296875, "Mean Q2": 738.4021899414063, "critic_loss": 10.61260018157959, "batch_reward": 6.114863563537598, "actor_loss": -738.6891363234747, "actor_target_entropy": -1.0, "actor_entropy": -0.45511625588886323, "alpha_loss": -0.0012147032105112596, "alpha_value": 0.12266367517566622, "duration": 151.5932948589325, "step": 96375}
{"episode_reward": 838.3111846672821, "episode": 772.0, "Q1 loss": 5.292866428375244, "Q2 loss": 5.255707567214966, "Mean Target Q": 738.5553715820313, "Mean Q1": 738.5594096679688, "Mean Q2": 738.5568955078126, "critic_loss": 10.548573970794678, "batch_reward": 6.120368137359619, "actor_loss": -739.0780925135458, "actor_target_entropy": -1.0, "actor_entropy": -0.4449262239279286, "alpha_loss": -0.002264801983631426, "alpha_value": 0.12299202077025842, "duration": 143.7787811756134, "step": 96500}
{"episode_reward": 848.742176077019, "episode": 773.0, "Q1 loss": 5.596714651107788, "Q2 loss": 5.57846047782898, "Mean Target Q": 738.538041015625, "Mean Q1": 738.538125, "Mean Q2": 738.5394301757813, "critic_loss": 11.175175163269042, "batch_reward": 6.106874099731446, "actor_loss": -739.0358092292906, "actor_target_entropy": -1.0, "actor_entropy": -0.44998039801915485, "alpha_loss": -0.0007916590280180412, "alpha_value": 0.12298246038208051, "duration": 162.55464363098145, "step": 96625}
{"episode_reward": 845.2316602623689, "episode": 774.0, "Q1 loss": 5.33961777305603, "Q2 loss": 5.275564533233642, "Mean Target Q": 739.0081635742188, "Mean Q1": 738.9963647460937, "Mean Q2": 738.9959350585938, "critic_loss": 10.615182359695435, "batch_reward": 6.121748546600342, "actor_loss": -739.3125659573462, "actor_target_entropy": -1.0, "actor_entropy": -0.45521034588736875, "alpha_loss": -0.0020536470514226465, "alpha_value": 0.12323765375247758, "duration": 167.1793258190155, "step": 96750}
{"episode_reward": 826.584614450427, "episode": 775.0, "Q1 loss": 5.5380463066101075, "Q2 loss": 5.5269200859069825, "Mean Target Q": 738.6839379882813, "Mean Q1": 738.6837641601562, "Mean Q2": 738.6844814453125, "critic_loss": 11.064966396331787, "batch_reward": 6.115530502319336, "actor_loss": -739.0279250372024, "actor_target_entropy": -1.0, "actor_entropy": -0.3818012461775825, "alpha_loss": 0.005551919688485445, "alpha_value": 0.12292869751522777, "duration": 163.63579750061035, "step": 96875}
{"episode_reward": 834.0097602731001, "episode": 776.0, "Q1 loss": 5.413371276855469, "Q2 loss": 5.473712677001953, "Mean Target Q": 738.6950869140625, "Mean Q1": 738.7020512695312, "Mean Q2": 738.7012338867188, "critic_loss": 10.887083969116212, "batch_reward": 6.100126041412354, "actor_loss": -738.9547571982107, "actor_target_entropy": -1.0, "actor_entropy": -0.4445931459626844, "alpha_loss": -0.00030070546856750886, "alpha_value": 0.12264455085298087, "duration": 164.34238195419312, "step": 97000}
{"episode_reward": 841.2463649908775, "episode": 777.0, "Q1 loss": 5.831747837066651, "Q2 loss": 5.871513118743897, "Mean Target Q": 738.6371572265625, "Mean Q1": 738.6322392578124, "Mean Q2": 738.6342836914063, "critic_loss": 11.703260955810547, "batch_reward": 6.100554496765136, "actor_loss": -739.0834001813616, "actor_target_entropy": -1.0, "actor_entropy": -0.4219626968815213, "alpha_loss": 0.0032758418995413987, "alpha_value": 0.12265705412289475, "duration": 172.95946049690247, "step": 97125}
{"episode_reward": 816.6679604267604, "episode": 778.0, "Q1 loss": 5.543103000640869, "Q2 loss": 5.645860433578491, "Mean Target Q": 738.7092685546875, "Mean Q1": 738.710470703125, "Mean Q2": 738.7111689453125, "critic_loss": 11.188963478088379, "batch_reward": 6.102006328582764, "actor_loss": -738.9195054577243, "actor_target_entropy": -1.0, "actor_entropy": -0.432508235977542, "alpha_loss": 0.0007629474613725418, "alpha_value": 0.12241742238058972, "duration": 154.20908188819885, "step": 97250}
{"episode_reward": 840.345414814225, "episode": 779.0, "Q1 loss": 5.882780870437622, "Q2 loss": 5.949032899856568, "Mean Target Q": 739.03418359375, "Mean Q1": 739.0258579101562, "Mean Q2": 739.0243515625, "critic_loss": 11.831813785552978, "batch_reward": 6.124132362365723, "actor_loss": -739.6405823722719, "actor_target_entropy": -1.0, "actor_entropy": -0.4627318207233671, "alpha_loss": 0.0017535161201117767, "alpha_value": 0.12234999040659375, "duration": 182.72622895240784, "step": 97375}
{"episode_reward": 832.6810467814552, "episode": 780.0, "Q1 loss": 6.2594484558105465, "Q2 loss": 6.220363897323608, "Mean Target Q": 738.9502944335937, "Mean Q1": 738.9568217773437, "Mean Q2": 738.9549892578125, "critic_loss": 12.479812355041505, "batch_reward": 6.103299705505371, "actor_loss": -739.2045563728578, "actor_target_entropy": -1.0, "actor_entropy": -0.4405083146787459, "alpha_loss": 0.0009055631329125214, "alpha_value": 0.12213225798255149, "duration": 170.32285714149475, "step": 97500}
{"episode_reward": 850.0653569161348, "episode": 781.0, "Q1 loss": 5.018577293395996, "Q2 loss": 5.0371865482330325, "Mean Target Q": 739.0371459960937, "Mean Q1": 739.0373095703125, "Mean Q2": 739.0402397460938, "critic_loss": 10.0557638130188, "batch_reward": 6.11631201171875, "actor_loss": -739.5273863777281, "actor_target_entropy": -1.0, "actor_entropy": -0.40877003518361893, "alpha_loss": 0.005626810698895641, "alpha_value": 0.12185126725135458, "duration": 159.53507685661316, "step": 97625}
{"episode_reward": 818.810161969434, "episode": 782.0, "Q1 loss": 5.495466430664062, "Q2 loss": 5.532674152374268, "Mean Target Q": 738.8706484375, "Mean Q1": 738.8652817382813, "Mean Q2": 738.86383984375, "critic_loss": 11.02814058303833, "batch_reward": 6.101832599639892, "actor_loss": -739.1392733666205, "actor_target_entropy": -1.0, "actor_entropy": -0.45022652610655756, "alpha_loss": 6.274588128191329e-05, "alpha_value": 0.12156888664031978, "duration": 151.56732153892517, "step": 97750}
{"episode_reward": 844.0877748642457, "episode": 783.0, "Q1 loss": 5.499443937301636, "Q2 loss": 5.4822581787109375, "Mean Target Q": 738.9988276367187, "Mean Q1": 739.0013920898438, "Mean Q2": 739.0016552734374, "critic_loss": 10.981702117919921, "batch_reward": 6.091784717559815, "actor_loss": -739.4322800409226, "actor_target_entropy": -1.0, "actor_entropy": -0.46359140390441533, "alpha_loss": -0.003744959515253348, "alpha_value": 0.12174937474610066, "duration": 185.99106407165527, "step": 97875}
{"episode_reward": 838.556931022243, "episode": 784.0, "Q1 loss": 5.726530448913574, "Q2 loss": 5.730297082901001, "Mean Target Q": 739.4100942382812, "Mean Q1": 739.4068315429688, "Mean Q2": 739.4062680664063, "critic_loss": 11.456827564239502, "batch_reward": 6.121663455963135, "actor_loss": -739.447485154675, "actor_target_entropy": -1.0, "actor_entropy": -0.43714783172453603, "alpha_loss": 0.0005031604443736855, "alpha_value": 0.12190855009713265, "duration": 160.1716823577881, "step": 98000}
{"episode_reward": 833.8350937603767, "episode": 785.0, "Q1 loss": 5.585736391067505, "Q2 loss": 5.566897808074951, "Mean Target Q": 739.4214477539062, "Mean Q1": 739.4215083007813, "Mean Q2": 739.4203779296874, "critic_loss": 11.152634132385254, "batch_reward": 6.120337951660156, "actor_loss": -739.7495611281622, "actor_target_entropy": -1.0, "actor_entropy": -0.41491207764262245, "alpha_loss": 0.003354951140603849, "alpha_value": 0.12173589565033087, "duration": 156.57387828826904, "step": 98125}
{"episode_reward": 849.8753141879249, "episode": 786.0, "Q1 loss": 5.207862131118774, "Q2 loss": 5.228949190139771, "Mean Target Q": 739.11239453125, "Mean Q1": 739.110248046875, "Mean Q2": 739.1109780273438, "critic_loss": 10.436811283111572, "batch_reward": 6.099895488739014, "actor_loss": -739.5990974672379, "actor_target_entropy": -1.0, "actor_entropy": -0.47574856156303036, "alpha_loss": -0.004522872050367896, "alpha_value": 0.12173048402020055, "duration": 167.9498610496521, "step": 98250}
{"episode_reward": 839.2430044860954, "episode": 787.0, "Q1 loss": 5.60717608833313, "Q2 loss": 5.646707466125489, "Mean Target Q": 739.4831157226563, "Mean Q1": 739.48578125, "Mean Q2": 739.4854116210937, "critic_loss": 11.253883567810059, "batch_reward": 6.119005447387695, "actor_loss": -740.0020093160962, "actor_target_entropy": -1.0, "actor_entropy": -0.42441965899770223, "alpha_loss": -0.0012415217102638312, "alpha_value": 0.12199433330576068, "duration": 171.91122722625732, "step": 98375}
{"episode_reward": 838.9426449837551, "episode": 788.0, "Q1 loss": 5.254718423843384, "Q2 loss": 5.245239780426026, "Mean Target Q": 739.662580078125, "Mean Q1": 739.6600395507812, "Mean Q2": 739.6621166992187, "critic_loss": 10.499958198547363, "batch_reward": 6.1195392951965335, "actor_loss": -740.0485465757308, "actor_target_entropy": -1.0, "actor_entropy": -0.4368973489730589, "alpha_loss": -0.003897863132278285, "alpha_value": 0.12237979097218735, "duration": 153.59301137924194, "step": 98500}
{"episode_reward": 838.3219252609103, "episode": 789.0, "Q1 loss": 5.13984489440918, "Q2 loss": 5.240847826004028, "Mean Target Q": 739.7874541015625, "Mean Q1": 739.7922045898438, "Mean Q2": 739.7904995117187, "critic_loss": 10.380692752838135, "batch_reward": 6.114120471954346, "actor_loss": -740.1635112459697, "actor_target_entropy": -1.0, "actor_entropy": -0.472217244288278, "alpha_loss": -0.0035715929716677655, "alpha_value": 0.12264439512990832, "duration": 174.01367139816284, "step": 98625}
{"episode_reward": 825.7011737067576, "episode": 790.0, "Q1 loss": 5.266233430862426, "Q2 loss": 5.223758787155151, "Mean Target Q": 739.8360908203125, "Mean Q1": 739.82630078125, "Mean Q2": 739.8266259765625, "critic_loss": 10.48999228668213, "batch_reward": 6.125188331604004, "actor_loss": -740.3014861076109, "actor_target_entropy": -1.0, "actor_entropy": -0.46043191657912347, "alpha_loss": -0.0025286155934971305, "alpha_value": 0.12298319050519843, "duration": 175.84066200256348, "step": 98750}
{"episode_reward": 772.7854370759133, "episode": 791.0, "Q1 loss": 5.293246145248413, "Q2 loss": 5.258008945465088, "Mean Target Q": 739.8483642578125, "Mean Q1": 739.8537998046875, "Mean Q2": 739.8541103515626, "critic_loss": 10.551255172729492, "batch_reward": 6.129174144744873, "actor_loss": -740.463123139881, "actor_target_entropy": -1.0, "actor_entropy": -0.42137405418214346, "alpha_loss": -0.0013646981623467234, "alpha_value": 0.1232090248004953, "duration": 171.93010091781616, "step": 98875}
{"episode_reward": 837.2941312631496, "episode": 792.0, "Q1 loss": 5.500789199829102, "Q2 loss": 5.562423055648804, "Mean Target Q": 740.0905424804688, "Mean Q1": 740.0867060546875, "Mean Q2": 740.0871943359375, "critic_loss": 11.063212268829346, "batch_reward": 6.136324279785156, "actor_loss": -740.5165228074596, "actor_target_entropy": -1.0, "actor_entropy": -0.4243341434386469, "alpha_loss": 0.001654613859793772, "alpha_value": 0.12318845268932394, "duration": 164.12799310684204, "step": 99000}
{"episode_reward": 836.3448645382651, "episode": 793.0, "Q1 loss": 5.046493288993836, "Q2 loss": 5.101664884567261, "Mean Target Q": 740.052298828125, "Mean Q1": 740.0490009765625, "Mean Q2": 740.0476088867188, "critic_loss": 10.14815816116333, "batch_reward": 6.118706703186035, "actor_loss": -740.3262513175844, "actor_target_entropy": -1.0, "actor_entropy": -0.39226565190723967, "alpha_loss": 0.0027218469998814047, "alpha_value": 0.12293190163142109, "duration": 157.88520860671997, "step": 99125}
{"episode_reward": 844.4103375784807, "episode": 794.0, "Q1 loss": 5.525620168685913, "Q2 loss": 5.406039163589478, "Mean Target Q": 740.0006376953125, "Mean Q1": 740.0006928710937, "Mean Q2": 740.0010883789063, "critic_loss": 10.931659351348877, "batch_reward": 6.117281486511231, "actor_loss": -740.3655553017893, "actor_target_entropy": -1.0, "actor_entropy": -0.39646417623566044, "alpha_loss": 0.002051926317489556, "alpha_value": 0.12273463139005598, "duration": 146.30408596992493, "step": 99250}
{"episode_reward": 824.0360955603951, "episode": 795.0, "Q1 loss": 4.949110378265381, "Q2 loss": 4.935722346305847, "Mean Target Q": 740.0886357421875, "Mean Q1": 740.08391015625, "Mean Q2": 740.0849057617188, "critic_loss": 9.884832706451416, "batch_reward": 6.117326156616211, "actor_loss": -740.4210602291047, "actor_target_entropy": -1.0, "actor_entropy": -0.4411327786861904, "alpha_loss": -0.003061822824372304, "alpha_value": 0.12273276102524432, "duration": 154.0095112323761, "step": 99375}
{"episode_reward": 804.0064019376989, "episode": 796.0, "Q1 loss": 4.975270971298218, "Q2 loss": 5.174414630889893, "Mean Target Q": 740.1762456054687, "Mean Q1": 740.1794765625, "Mean Q2": 740.1812358398438, "critic_loss": 10.149685577392578, "batch_reward": 6.124450458526612, "actor_loss": -740.6458838678176, "actor_target_entropy": -1.0, "actor_entropy": -0.4482981495318874, "alpha_loss": 0.00021416181510674857, "alpha_value": 0.12289824112499864, "duration": 158.77956438064575, "step": 99500}
{"episode_reward": 838.8053882792806, "episode": 797.0, "Q1 loss": 5.452249732017517, "Q2 loss": 5.449006407737732, "Mean Target Q": 740.2842509765625, "Mean Q1": 740.2852495117188, "Mean Q2": 740.2834682617188, "critic_loss": 10.901256116867065, "batch_reward": 6.124116577148437, "actor_loss": -740.6079973493304, "actor_target_entropy": -1.0, "actor_entropy": -0.45262742610204787, "alpha_loss": -0.0016426092867429058, "alpha_value": 0.12303369806958928, "duration": 152.40577578544617, "step": 99625}
{"episode_reward": 850.3303592801251, "episode": 798.0, "Q1 loss": 4.751776441574097, "Q2 loss": 4.842574172973633, "Mean Target Q": 739.8376103515625, "Mean Q1": 739.8353178710937, "Mean Q2": 739.8367387695313, "critic_loss": 9.59435055923462, "batch_reward": 6.104688270568848, "actor_loss": -740.4098776540449, "actor_target_entropy": -1.0, "actor_entropy": -0.45095816879503187, "alpha_loss": -0.0023303194884060612, "alpha_value": 0.12316084803551047, "duration": 162.28969550132751, "step": 99750}
{"episode_reward": 832.9717000633711, "episode": 799.0, "Q1 loss": 5.743453052520752, "Q2 loss": 5.67097402381897, "Mean Target Q": 740.397552734375, "Mean Q1": 740.3952919921875, "Mean Q2": 740.3951879882812, "critic_loss": 11.414427043914795, "batch_reward": 6.134289505004883, "actor_loss": -740.9320940290179, "actor_target_entropy": -1.0, "actor_entropy": -0.4333157563020313, "alpha_loss": -0.00039557549208106975, "alpha_value": 0.12325778800473625, "duration": 157.5380036830902, "step": 99875}
{"episode_reward": 827.4973836748544, "episode": 800.0, "Q1 loss": 5.62698406557883, "Q2 loss": 5.547925858728347, "Mean Target Q": 740.3795126638105, "Mean Q1": 740.3767567296183, "Mean Q2": 740.3738506686303, "critic_loss": 11.174909910848063, "batch_reward": 6.132254096769517, "actor_loss": -740.4143282982611, "actor_target_entropy": -1.0, "actor_entropy": -0.4476529566511031, "alpha_loss": -0.0021089006791777548, "alpha_value": 0.12347537023809628, "step": 99999}
