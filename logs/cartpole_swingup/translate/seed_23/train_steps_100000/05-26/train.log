{"episode_reward": 0.0, "episode": 1.0, "duration": 17.167882204055786, "step": 125}
{"episode_reward": 98.93334754503977, "episode": 2.0, "duration": 0.8015868663787842, "step": 250}
{"episode_reward": 83.7891973826063, "episode": 3.0, "duration": 0.802055835723877, "step": 375}
{"episode_reward": 81.91120157057873, "episode": 4.0, "duration": 0.8013746738433838, "step": 500}
{"episode_reward": 154.56731419304836, "episode": 5.0, "duration": 0.8028671741485596, "step": 625}
{"episode_reward": 47.754455934765794, "episode": 6.0, "duration": 0.799569845199585, "step": 750}
{"episode_reward": 125.90222387858113, "episode": 7.0, "duration": 0.8003332614898682, "step": 875}
{"episode_reward": 143.25102190574748, "episode": 8.0, "duration": 0.8011343479156494, "step": 1000}
{"episode_reward": 186.90792292430567, "episode": 9.0, "Q1 loss": 0.9950311372280121, "Q2 loss": 0.9970073616504669, "Mean Target Q": 1.5694679081439973, "Mean Q1": 1.5568420763015747, "Mean Q2": 1.5594909049868584, "critic_loss": 1.9920384922027587, "batch_reward": 0.8834072885513305, "actor_loss": -1.5825900123232888, "actor_target_entropy": -1.0, "actor_entropy": 1.1620875464545355, "alpha_loss": 0.14149190287386615, "alpha_value": 0.09974807492898215, "duration": 40.90326118469238, "step": 1125}
{"episode_reward": 75.3243301830934, "episode": 10.0, "Q1 loss": 0.5131697924137115, "Q2 loss": 0.5118976776599884, "Mean Target Q": 2.1332759370803833, "Mean Q1": 2.131391326904297, "Mean Q2": 2.1313784379959104, "critic_loss": 1.0250674705505372, "batch_reward": 0.8842901663780213, "actor_loss": -2.191915617835137, "actor_target_entropy": -1.0, "actor_entropy": 1.2596227988120048, "alpha_loss": 0.16090733750212577, "alpha_value": 0.099100009829484, "duration": 41.06927037239075, "step": 1250}
{"episode_reward": 133.92552724153836, "episode": 11.0, "Q1 loss": 0.4297285933494568, "Q2 loss": 0.4305440363883972, "Mean Target Q": 2.68140433883667, "Mean Q1": 2.6802111377716065, "Mean Q2": 2.680329902648926, "critic_loss": 0.8602726273536682, "batch_reward": 0.8924513125419616, "actor_loss": -2.7394156720903187, "actor_target_entropy": -1.0, "actor_entropy": 1.1190500155327812, "alpha_loss": 0.15429530139007266, "alpha_value": 0.0984882790252695, "duration": 41.188530683517456, "step": 1375}
{"episode_reward": 127.39637658588559, "episode": 12.0, "Q1 loss": 0.44856692004203796, "Q2 loss": 0.44851613545417784, "Mean Target Q": 3.1747410335540773, "Mean Q1": 3.1712112846374514, "Mean Q2": 3.170991292953491, "critic_loss": 0.8970830559730529, "batch_reward": 0.8915228343009949, "actor_loss": -3.2291770750476467, "actor_target_entropy": -1.0, "actor_entropy": 1.0267591707168087, "alpha_loss": 0.14838274496216927, "alpha_value": 0.09789677809774808, "duration": 42.73557925224304, "step": 1500}
{"episode_reward": 45.961113579369666, "episode": 13.0, "Q1 loss": 0.4827582244873047, "Q2 loss": 0.48399213075637815, "Mean Target Q": 3.5626138858795167, "Mean Q1": 3.561207359313965, "Mean Q2": 3.5611986961364748, "critic_loss": 0.96675035572052, "batch_reward": 0.856222430229187, "actor_loss": -3.6555454390389577, "actor_target_entropy": -1.0, "actor_entropy": 0.9353921403960576, "alpha_loss": 0.14019134475125206, "alpha_value": 0.0973256455356521, "duration": 40.911866188049316, "step": 1625}
{"episode_reward": 58.21321168317807, "episode": 14.0, "Q1 loss": 0.6590694899559021, "Q2 loss": 0.6597773127555847, "Mean Target Q": 4.009480974197388, "Mean Q1": 4.004264728546143, "Mean Q2": 4.0045738048553465, "critic_loss": 1.3188468055725098, "batch_reward": 0.8475268330574036, "actor_loss": -4.089037587565761, "actor_target_entropy": -1.0, "actor_entropy": 0.879638901641292, "alpha_loss": 0.1360085878160692, "alpha_value": 0.0967734066102777, "duration": 40.83323931694031, "step": 1750}
{"episode_reward": 173.44987110127195, "episode": 15.0, "Q1 loss": 0.8630335426330566, "Q2 loss": 0.8623501653671265, "Mean Target Q": 4.556337955474853, "Mean Q1": 4.553789714813233, "Mean Q2": 4.553461864471435, "critic_loss": 1.7253837127685547, "batch_reward": 0.881031991481781, "actor_loss": -4.622425026363796, "actor_target_entropy": -1.0, "actor_entropy": 0.7785716004787929, "alpha_loss": 0.12635061511444667, "alpha_value": 0.09624257049678937, "duration": 39.817301988601685, "step": 1875}
{"episode_reward": 143.37293394844684, "episode": 16.0, "Q1 loss": 1.189441068649292, "Q2 loss": 1.1859140605926515, "Mean Target Q": 5.117934391021729, "Mean Q1": 5.111404411315918, "Mean Q2": 5.1123373947143556, "critic_loss": 2.375355134963989, "batch_reward": 0.8887188572883606, "actor_loss": -5.224859091543382, "actor_target_entropy": -1.0, "actor_entropy": 0.745969993452872, "alpha_loss": 0.11846147633848651, "alpha_value": 0.09574130740449939, "duration": 39.789597511291504, "step": 2000}
{"episode_reward": 95.65193300918374, "episode": 17.0, "Q1 loss": 0.9322931208610534, "Q2 loss": 0.9286528959274292, "Mean Target Q": 5.677306758880615, "Mean Q1": 5.67658576965332, "Mean Q2": 5.676286571502685, "critic_loss": 1.8609460172653198, "batch_reward": 0.9023163151741028, "actor_loss": -5.7957172015356635, "actor_target_entropy": -1.0, "actor_entropy": 0.7132544299912831, "alpha_loss": 0.11019900003595957, "alpha_value": 0.09524484955078298, "duration": 39.80229187011719, "step": 2125}
{"episode_reward": 183.59004021637105, "episode": 18.0, "Q1 loss": 1.1060078916549683, "Q2 loss": 1.102054801940918, "Mean Target Q": 6.197872844696045, "Mean Q1": 6.194404861450195, "Mean Q2": 6.194404483795166, "critic_loss": 2.2080626974105835, "batch_reward": 0.902107204914093, "actor_loss": -6.337462386777324, "actor_target_entropy": -1.0, "actor_entropy": 0.6896867281006228, "alpha_loss": 0.09651469727677683, "alpha_value": 0.09480521936824526, "duration": 39.81990027427673, "step": 2250}
{"episode_reward": 78.43027931126473, "episode": 19.0, "Q1 loss": 1.2484654817581178, "Q2 loss": 1.2429609236717225, "Mean Target Q": 6.80045193862915, "Mean Q1": 6.794385749816895, "Mean Q2": 6.794665702819824, "critic_loss": 2.4914264068603518, "batch_reward": 0.9094399790763855, "actor_loss": -6.95451635784573, "actor_target_entropy": -1.0, "actor_entropy": 0.6997820413301862, "alpha_loss": 0.09013374457283625, "alpha_value": 0.09438836331148535, "duration": 41.569483280181885, "step": 2375}
{"episode_reward": 97.1172490040381, "episode": 20.0, "Q1 loss": 1.2905751414299012, "Q2 loss": 1.280433000087738, "Mean Target Q": 7.493789371490479, "Mean Q1": 7.4908282012939456, "Mean Q2": 7.4904984321594235, "critic_loss": 2.5710081338882445, "batch_reward": 0.9193331394195556, "actor_loss": -7.681814062979914, "actor_target_entropy": -1.0, "actor_entropy": 0.6552255720861496, "alpha_loss": 0.07654773576125022, "alpha_value": 0.09400802854823959, "duration": 50.636261224746704, "step": 2500}
{"episode_reward": 232.8578265745394, "episode": 21.0, "Q1 loss": 1.530726628780365, "Q2 loss": 1.5263035202026367, "Mean Target Q": 8.359362247467041, "Mean Q1": 8.354442741394044, "Mean Q2": 8.355064083099366, "critic_loss": 3.0570301513671874, "batch_reward": 0.9756745767593383, "actor_loss": -8.556418267507402, "actor_target_entropy": -1.0, "actor_entropy": 0.7040690093759506, "alpha_loss": 0.06842204005945296, "alpha_value": 0.09366337538147433, "duration": 59.247008085250854, "step": 2625}
{"episode_reward": 317.36182695464726, "episode": 22.0, "Q1 loss": 1.649250789642334, "Q2 loss": 1.6397025852203369, "Mean Target Q": 9.205970352172852, "Mean Q1": 9.201996528625488, "Mean Q2": 9.201564613342285, "critic_loss": 3.288953374862671, "batch_reward": 1.019359384059906, "actor_loss": -9.454454791161321, "actor_target_entropy": -1.0, "actor_entropy": 0.6701724115879305, "alpha_loss": 0.05959293907207827, "alpha_value": 0.09334979486794401, "duration": 50.38949728012085, "step": 2750}
{"episode_reward": 192.3872839217225, "episode": 23.0, "Q1 loss": 1.8126113576889038, "Q2 loss": 1.798292366027832, "Mean Target Q": 10.33374730682373, "Mean Q1": 10.32753173828125, "Mean Q2": 10.328139701843261, "critic_loss": 3.610903720855713, "batch_reward": 1.075851435661316, "actor_loss": -10.627946899050759, "actor_target_entropy": -1.0, "actor_entropy": 0.5413521514052436, "alpha_loss": 0.05314901364701135, "alpha_value": 0.09306235928603819, "duration": 67.25241684913635, "step": 2875}
{"episode_reward": 262.11852727817825, "episode": 24.0, "Q1 loss": 2.199429051399231, "Q2 loss": 2.195125729560852, "Mean Target Q": 11.262244781494141, "Mean Q1": 11.254834365844726, "Mean Q2": 11.25533715057373, "critic_loss": 4.3945547580719, "batch_reward": 1.1173286395072937, "actor_loss": -11.526858837373796, "actor_target_entropy": -1.0, "actor_entropy": 0.5682000008321577, "alpha_loss": 0.05125403217971325, "alpha_value": 0.09278373939957388, "duration": 55.4481680393219, "step": 3000}
{"episode_reward": 234.30147961937635, "episode": 25.0, "Q1 loss": 3.002893681526184, "Q2 loss": 2.9909035949707032, "Mean Target Q": 12.046588325500489, "Mean Q1": 12.04098110961914, "Mean Q2": 12.040931182861328, "critic_loss": 5.993797273635864, "batch_reward": 1.1379613842964171, "actor_loss": -12.313237871442523, "actor_target_entropy": -1.0, "actor_entropy": 0.5375785832367246, "alpha_loss": 0.053957413290701216, "alpha_value": 0.09249442450742479, "duration": 63.86787247657776, "step": 3125}
{"episode_reward": 200.0680432361912, "episode": 26.0, "Q1 loss": 2.4286070480346678, "Q2 loss": 2.430782455444336, "Mean Target Q": 13.008060653686524, "Mean Q1": 13.004397468566895, "Mean Q2": 13.004658851623535, "critic_loss": 4.8593895015716555, "batch_reward": 1.1506048336029053, "actor_loss": -13.323877949868479, "actor_target_entropy": -1.0, "actor_entropy": 0.49186346896233096, "alpha_loss": 0.048310938982232925, "alpha_value": 0.09220529358058924, "duration": 70.22319865226746, "step": 3250}
{"episode_reward": 195.5246703174973, "episode": 27.0, "Q1 loss": 2.6505803642272947, "Q2 loss": 2.6325191230773926, "Mean Target Q": 13.917138954162597, "Mean Q1": 13.912503280639648, "Mean Q2": 13.91268458557129, "critic_loss": 5.283099494934082, "batch_reward": 1.170087908744812, "actor_loss": -14.312864606342618, "actor_target_entropy": -1.0, "actor_entropy": 0.48453378015094334, "alpha_loss": 0.03726825032324072, "alpha_value": 0.09195287163985638, "duration": 43.541505336761475, "step": 3375}
{"episode_reward": 220.45138465335856, "episode": 28.0, "Q1 loss": 3.0235154666900637, "Q2 loss": 3.0110009174346923, "Mean Target Q": 15.140365180969239, "Mean Q1": 15.134383728027343, "Mean Q2": 15.134826080322267, "critic_loss": 6.034516365051269, "batch_reward": 1.1880690298080445, "actor_loss": -15.569872840758293, "actor_target_entropy": -1.0, "actor_entropy": 0.43325268020552976, "alpha_loss": 0.029631544340161547, "alpha_value": 0.09175108947824687, "duration": 39.60619020462036, "step": 3500}
{"episode_reward": 230.89006381208083, "episode": 29.0, "Q1 loss": 3.0524674434661865, "Q2 loss": 3.0267093238830567, "Mean Target Q": 16.351844581604006, "Mean Q1": 16.34573030090332, "Mean Q2": 16.345826820373535, "critic_loss": 6.079176753997802, "batch_reward": 1.2165398578643798, "actor_loss": -16.776700352865554, "actor_target_entropy": -1.0, "actor_entropy": 0.4651966861316136, "alpha_loss": 0.020927429661184313, "alpha_value": 0.09159090956576521, "duration": 39.62948942184448, "step": 3625}
{"episode_reward": 218.58549035251778, "episode": 30.0, "Q1 loss": 3.1631255016326905, "Q2 loss": 3.163830099105835, "Mean Target Q": 17.45300485229492, "Mean Q1": 17.445424224853515, "Mean Q2": 17.446095916748046, "critic_loss": 6.326955585479737, "batch_reward": 1.2354193115234375, "actor_loss": -17.95283366787818, "actor_target_entropy": -1.0, "actor_entropy": 0.4298770386845835, "alpha_loss": 0.016629686933987205, "alpha_value": 0.09146770418532124, "duration": 39.583410024642944, "step": 3750}
{"episode_reward": 237.57109933617573, "episode": 31.0, "Q1 loss": 4.251682474136352, "Q2 loss": 4.250534839630127, "Mean Target Q": 18.73896566772461, "Mean Q1": 18.73202813720703, "Mean Q2": 18.731317260742188, "critic_loss": 8.50221728515625, "batch_reward": 1.2587861404418945, "actor_loss": -19.230805260794504, "actor_target_entropy": -1.0, "actor_entropy": 0.4528766111249015, "alpha_loss": 0.013746855057968152, "alpha_value": 0.09136987839741066, "duration": 39.734081745147705, "step": 3875}
{"episode_reward": 297.5535065584657, "episode": 32.0, "Q1 loss": 3.8745662727355956, "Q2 loss": 3.8443148746490476, "Mean Target Q": 20.154739349365233, "Mean Q1": 20.143941986083984, "Mean Q2": 20.145139541625976, "critic_loss": 7.718881134033203, "batch_reward": 1.2886565828323364, "actor_loss": -20.642678599203787, "actor_target_entropy": -1.0, "actor_entropy": 0.4302770793437958, "alpha_loss": 0.012294260293035018, "alpha_value": 0.09127812494682111, "duration": 39.79669547080994, "step": 4000}
{"episode_reward": 294.8923575424462, "episode": 33.0, "Q1 loss": 3.5176423110961914, "Q2 loss": 3.505211820602417, "Mean Target Q": 21.63428547668457, "Mean Q1": 21.630902389526366, "Mean Q2": 21.63126089477539, "critic_loss": 7.022854133605957, "batch_reward": 1.343133026123047, "actor_loss": -22.24543026515416, "actor_target_entropy": -1.0, "actor_entropy": 0.4042387916928246, "alpha_loss": 0.007970722519703918, "alpha_value": 0.09118662734568543, "duration": 119.22783613204956, "step": 4125}
{"episode_reward": 357.7219069935001, "episode": 34.0, "Q1 loss": 3.9108136653900147, "Q2 loss": 3.884084747314453, "Mean Target Q": 23.131519317626953, "Mean Q1": 23.129666900634767, "Mean Q2": 23.12976187133789, "critic_loss": 7.794898357391357, "batch_reward": 1.3930738582611084, "actor_loss": -23.857427350936398, "actor_target_entropy": -1.0, "actor_entropy": 0.3842924564115463, "alpha_loss": -0.00101258889152368, "alpha_value": 0.09117079411592337, "duration": 154.58926010131836, "step": 4250}
{"episode_reward": 307.3366740531696, "episode": 35.0, "Q1 loss": 4.267286993026733, "Q2 loss": 4.247436517715454, "Mean Target Q": 24.70154493713379, "Mean Q1": 24.68860336303711, "Mean Q2": 24.689555252075195, "critic_loss": 8.51472346496582, "batch_reward": 1.4261990642547608, "actor_loss": -25.328497447664777, "actor_target_entropy": -1.0, "actor_entropy": 0.367932553329165, "alpha_loss": -0.003435759332090143, "alpha_value": 0.0911881376987489, "duration": 150.95255613327026, "step": 4375}
{"episode_reward": 406.1435297740349, "episode": 36.0, "Q1 loss": 4.380844387054443, "Q2 loss": 4.3736574192047115, "Mean Target Q": 26.250460876464842, "Mean Q1": 26.24695603942871, "Mean Q2": 26.246303253173828, "critic_loss": 8.754501808166504, "batch_reward": 1.4597572593688966, "actor_loss": -27.03551464696084, "actor_target_entropy": -1.0, "actor_entropy": 0.35659035151043245, "alpha_loss": -0.010800226215994167, "alpha_value": 0.09124212194656439, "duration": 146.6691598892212, "step": 4500}
{"episode_reward": 302.50093853769266, "episode": 37.0, "Q1 loss": 5.191534753799439, "Q2 loss": 5.1650761699676515, "Mean Target Q": 27.766899780273437, "Mean Q1": 27.757540130615233, "Mean Q2": 27.75879266357422, "critic_loss": 10.35661089706421, "batch_reward": 1.488809534072876, "actor_loss": -28.520913048396036, "actor_target_entropy": -1.0, "actor_entropy": 0.3219802074489139, "alpha_loss": -0.014099111677043967, "alpha_value": 0.09135145416281662, "duration": 165.05755805969238, "step": 4625}
{"episode_reward": 303.36716232068045, "episode": 38.0, "Q1 loss": 5.117343725204468, "Q2 loss": 5.130836351394653, "Mean Target Q": 29.29800143432617, "Mean Q1": 29.292884216308593, "Mean Q2": 29.29333430480957, "critic_loss": 10.248180072784423, "batch_reward": 1.5090487184524537, "actor_loss": -30.19894753732989, "actor_target_entropy": -1.0, "actor_entropy": 0.30037924022443835, "alpha_loss": -0.019424147626024582, "alpha_value": 0.09150129204746238, "duration": 148.06081175804138, "step": 4750}
{"episode_reward": 250.41940689932778, "episode": 39.0, "Q1 loss": 5.7278409061431885, "Q2 loss": 5.72365353012085, "Mean Target Q": 30.87836506652832, "Mean Q1": 30.867513870239257, "Mean Q2": 30.86720555114746, "critic_loss": 11.451494457244873, "batch_reward": 1.5360825366973876, "actor_loss": -31.872827651008727, "actor_target_entropy": -1.0, "actor_entropy": 0.2857688380375741, "alpha_loss": -0.022427268304108156, "alpha_value": 0.09168611270267776, "duration": 156.1704924106598, "step": 4875}
{"episode_reward": 436.03349638468836, "episode": 40.0, "Q1 loss": 5.631841184616089, "Q2 loss": 5.666054765701294, "Mean Target Q": 32.91664779663086, "Mean Q1": 32.90331057739258, "Mean Q2": 32.9039778137207, "critic_loss": 11.297895950317383, "batch_reward": 1.5826322784423827, "actor_loss": -33.88258706369707, "actor_target_entropy": -1.0, "actor_entropy": 0.23032109042809856, "alpha_loss": -0.021580365659188357, "alpha_value": 0.09190327295330487, "step": 5000}
{"duration": 166.1629979610443, "step": 5000}
{"episode_reward": 409.34154424632993, "episode": 41.0, "Q1 loss": 6.145458209991455, "Q2 loss": 6.123857273101807, "Mean Target Q": 34.79828063964844, "Mean Q1": 34.79686709594726, "Mean Q2": 34.795848602294924, "critic_loss": 12.269315483093262, "batch_reward": 1.6331066427230836, "actor_loss": -35.76484008062454, "actor_target_entropy": -1.0, "actor_entropy": 0.18923636641175973, "alpha_loss": -0.027295743743519462, "alpha_value": 0.09213230507865139, "duration": 153.08167505264282, "step": 5125}
{"episode_reward": 420.8495486480657, "episode": 42.0, "Q1 loss": 6.8168325614929195, "Q2 loss": 6.846114559173584, "Mean Target Q": 36.68653970336914, "Mean Q1": 36.67715875244141, "Mean Q2": 36.677790832519534, "critic_loss": 13.66294711303711, "batch_reward": 1.6782726192474364, "actor_loss": -37.61127010468514, "actor_target_entropy": -1.0, "actor_entropy": 0.1312511248115991, "alpha_loss": -0.027427013497799635, "alpha_value": 0.09242229167454961, "duration": 156.91311383247375, "step": 5250}
{"episode_reward": 455.88491282243086, "episode": 43.0, "Q1 loss": 6.687371646881103, "Q2 loss": 6.63116554069519, "Mean Target Q": 38.81063354492188, "Mean Q1": 38.803490234375, "Mean Q2": 38.803037872314455, "critic_loss": 13.318537162780762, "batch_reward": 1.7206287078857423, "actor_loss": -39.87237112862723, "actor_target_entropy": -1.0, "actor_entropy": 0.09101850693188017, "alpha_loss": -0.026515752786681765, "alpha_value": 0.09270160963433831, "duration": 157.93161749839783, "step": 5375}
{"episode_reward": 408.2983561215321, "episode": 44.0, "Q1 loss": 7.308163398742676, "Q2 loss": 7.278015644073486, "Mean Target Q": 40.97058059692383, "Mean Q1": 40.96278759765625, "Mean Q2": 40.96255535888672, "critic_loss": 14.586179054260255, "batch_reward": 1.7501290082931518, "actor_loss": -41.996449501283706, "actor_target_entropy": -1.0, "actor_entropy": 0.07524862984615949, "alpha_loss": -0.02747080841612431, "alpha_value": 0.09299294758474354, "duration": 157.4183406829834, "step": 5500}
{"episode_reward": 460.1057898041385, "episode": 45.0, "Q1 loss": 7.445932559967041, "Q2 loss": 7.415814727783203, "Mean Target Q": 42.98823788452148, "Mean Q1": 42.982597930908206, "Mean Q2": 42.98467999267578, "critic_loss": 14.861747245788575, "batch_reward": 1.7976149072647094, "actor_loss": -44.09996632167271, "actor_target_entropy": -1.0, "actor_entropy": 0.09185356901042045, "alpha_loss": -0.029055544929135414, "alpha_value": 0.09329454004700927, "duration": 156.49610376358032, "step": 5625}
{"episode_reward": 400.63631786995245, "episode": 46.0, "Q1 loss": 7.353806003570557, "Q2 loss": 7.345030647277832, "Mean Target Q": 45.10316552734375, "Mean Q1": 45.09577154541016, "Mean Q2": 45.09534844970703, "critic_loss": 14.698836601257325, "batch_reward": 1.8171671438217163, "actor_loss": -46.19520495014806, "actor_target_entropy": -1.0, "actor_entropy": 0.08191987965255976, "alpha_loss": -0.0307820349210693, "alpha_value": 0.09363575597234783, "duration": 171.72581887245178, "step": 5750}
{"episode_reward": 395.8391305621251, "episode": 47.0, "Q1 loss": 11.55373775100708, "Q2 loss": 11.58182130432129, "Mean Target Q": 47.00825894165039, "Mean Q1": 46.986723022460936, "Mean Q2": 46.98655053710937, "critic_loss": 23.135558937072755, "batch_reward": 1.852687967300415, "actor_loss": -48.03477532523019, "actor_target_entropy": -1.0, "actor_entropy": 0.10780001171524563, "alpha_loss": -0.03453251536166857, "alpha_value": 0.09401815941200592, "duration": 160.8066327571869, "step": 5875}
{"episode_reward": 464.0644058985287, "episode": 48.0, "Q1 loss": 7.348992835998535, "Q2 loss": 7.326005313873291, "Mean Target Q": 49.55014938354492, "Mean Q1": 49.54472277832031, "Mean Q2": 49.54381430053711, "critic_loss": 14.674998138427734, "batch_reward": 1.8944626941680909, "actor_loss": -50.515419190929784, "actor_target_entropy": -1.0, "actor_entropy": 0.08955990461512439, "alpha_loss": -0.031187304656111425, "alpha_value": 0.09441292893706066, "duration": 157.64331793785095, "step": 6000}
{"episode_reward": 440.8269321753003, "episode": 49.0, "Q1 loss": 7.888439193725586, "Q2 loss": 7.852513763427734, "Mean Target Q": 51.51102188110352, "Mean Q1": 51.504683380126956, "Mean Q2": 51.50602758789063, "critic_loss": 15.74095297241211, "batch_reward": 1.914004963874817, "actor_loss": -52.62511244274321, "actor_target_entropy": -1.0, "actor_entropy": 0.08851279401116902, "alpha_loss": -0.03442969439285142, "alpha_value": 0.09480242558175352, "duration": 153.19521045684814, "step": 6125}
{"episode_reward": 384.9922425197889, "episode": 50.0, "Q1 loss": 7.406807186126709, "Q2 loss": 7.383751640319824, "Mean Target Q": 53.75653341674805, "Mean Q1": 53.74482116699219, "Mean Q2": 53.74523516845703, "critic_loss": 14.790558822631835, "batch_reward": 1.968332350730896, "actor_loss": -54.73542668742518, "actor_target_entropy": -1.0, "actor_entropy": 0.04744094656780362, "alpha_loss": -0.03562984058272935, "alpha_value": 0.09523196761541217, "duration": 151.97213315963745, "step": 6250}
{"episode_reward": 521.7485484356981, "episode": 51.0, "Q1 loss": 7.366546127319336, "Q2 loss": 7.35510338973999, "Mean Target Q": 56.09078112792969, "Mean Q1": 56.08804483032227, "Mean Q2": 56.088162689208986, "critic_loss": 14.72164956665039, "batch_reward": 1.9886326532363892, "actor_loss": -57.466150737944105, "actor_target_entropy": -1.0, "actor_entropy": 0.05763899493548605, "alpha_loss": -0.03697058555507471, "alpha_value": 0.09569463908355222, "duration": 158.7503638267517, "step": 6375}
{"episode_reward": 401.28669844203966, "episode": 52.0, "Q1 loss": 8.02457738494873, "Q2 loss": 8.059256927490235, "Mean Target Q": 58.2976354675293, "Mean Q1": 58.28894473266602, "Mean Q2": 58.288301391601564, "critic_loss": 16.08383432006836, "batch_reward": 2.0147860803604125, "actor_loss": -59.59741192479287, "actor_target_entropy": -1.0, "actor_entropy": 0.05001233470055365, "alpha_loss": -0.03970096795068633, "alpha_value": 0.09617375253890895, "duration": 166.03613805770874, "step": 6500}
{"episode_reward": 380.03495947009304, "episode": 53.0, "Q1 loss": 7.553450023651123, "Q2 loss": 7.567854118347168, "Mean Target Q": 60.462293243408205, "Mean Q1": 60.45968643188476, "Mean Q2": 60.459780883789065, "critic_loss": 15.121304100036621, "batch_reward": 2.0399132719039916, "actor_loss": -61.58456535944863, "actor_target_entropy": -1.0, "actor_entropy": 0.061880779999589165, "alpha_loss": -0.03705128203959219, "alpha_value": 0.09667574538559347, "duration": 146.7404568195343, "step": 6625}
{"episode_reward": 469.16123889999903, "episode": 54.0, "Q1 loss": 7.570441555023193, "Q2 loss": 7.552707153320313, "Mean Target Q": 62.82333590698242, "Mean Q1": 62.81189468383789, "Mean Q2": 62.81129577636719, "critic_loss": 15.123148727416993, "batch_reward": 2.0744762029647825, "actor_loss": -64.00124162243259, "actor_target_entropy": -1.0, "actor_entropy": -0.0027569902970665887, "alpha_loss": -0.041804020683611595, "alpha_value": 0.09719696561421501, "duration": 151.91459584236145, "step": 6750}
{"episode_reward": 462.1685077224528, "episode": 55.0, "Q1 loss": 7.3619401626586916, "Q2 loss": 7.364474094390869, "Mean Target Q": 65.08111618041993, "Mean Q1": 65.07039089965821, "Mean Q2": 65.07096960449219, "critic_loss": 14.726414199829101, "batch_reward": 2.111093388557434, "actor_loss": -66.40831272185795, "actor_target_entropy": -1.0, "actor_entropy": 0.004282635207923632, "alpha_loss": -0.042787315294383066, "alpha_value": 0.09776038182720716, "duration": 156.79502749443054, "step": 6875}
{"episode_reward": 536.5442828915428, "episode": 56.0, "Q1 loss": 7.287938858032226, "Q2 loss": 7.260474479675293, "Mean Target Q": 67.68359088134765, "Mean Q1": 67.67818426513672, "Mean Q2": 67.67757739257813, "critic_loss": 14.548413352966309, "batch_reward": 2.1574427490234376, "actor_loss": -68.9188724640877, "actor_target_entropy": -1.0, "actor_entropy": -0.0235461357139772, "alpha_loss": -0.042241650363129955, "alpha_value": 0.09834574234246066, "duration": 162.0426104068756, "step": 7000}
{"episode_reward": 528.842370397132, "episode": 57.0, "Q1 loss": 6.881298908233642, "Q2 loss": 6.865781955718994, "Mean Target Q": 69.8475283203125, "Mean Q1": 69.84405963134766, "Mean Q2": 69.8450806274414, "critic_loss": 13.747080879211426, "batch_reward": 2.1840443134307863, "actor_loss": -71.15506259978764, "actor_target_entropy": -1.0, "actor_entropy": -0.016659836935263777, "alpha_loss": -0.04474641081123125, "alpha_value": 0.09892149802262062, "duration": 156.80418634414673, "step": 7125}
{"episode_reward": 484.00094546088764, "episode": 58.0, "Q1 loss": 6.812425773620605, "Q2 loss": 6.797024032592773, "Mean Target Q": 72.18994024658203, "Mean Q1": 72.17787884521485, "Mean Q2": 72.17818524169923, "critic_loss": 13.609449806213378, "batch_reward": 2.2286961212158203, "actor_loss": -73.3949949202999, "actor_target_entropy": -1.0, "actor_entropy": -0.05461749366875137, "alpha_loss": -0.04731280404713846, "alpha_value": 0.09953796233146366, "duration": 145.98961925506592, "step": 7250}
{"episode_reward": 468.6408641606848, "episode": 59.0, "Q1 loss": 6.789646911621094, "Q2 loss": 6.764625923156738, "Mean Target Q": 74.22129321289063, "Mean Q1": 74.21252374267578, "Mean Q2": 74.21294323730469, "critic_loss": 13.554272819519044, "batch_reward": 2.227671104431152, "actor_loss": -75.50580027746776, "actor_target_entropy": -1.0, "actor_entropy": -0.0008064574961151395, "alpha_loss": -0.044168572399824385, "alpha_value": 0.10015860211248583, "duration": 157.0177822113037, "step": 7375}
{"episode_reward": 459.68285370864595, "episode": 60.0, "Q1 loss": 7.433585514068604, "Q2 loss": 7.433877429962158, "Mean Target Q": 76.469935546875, "Mean Q1": 76.47012200927735, "Mean Q2": 76.47012213134765, "critic_loss": 14.867462913513183, "batch_reward": 2.2536510753631593, "actor_loss": -77.47447573754096, "actor_target_entropy": -1.0, "actor_entropy": -0.027555161831720222, "alpha_loss": -0.044890020313041824, "alpha_value": 0.10078566088024378, "duration": 155.65715909004211, "step": 7500}
{"episode_reward": 557.0370194664141, "episode": 61.0, "Q1 loss": 7.710803279876709, "Q2 loss": 7.656027858734131, "Mean Target Q": 78.55040924072266, "Mean Q1": 78.53902526855468, "Mean Q2": 78.5383090209961, "critic_loss": 15.36683113861084, "batch_reward": 2.278054946899414, "actor_loss": -79.82867673843626, "actor_target_entropy": -1.0, "actor_entropy": -0.034866593260731965, "alpha_loss": -0.049782380579955994, "alpha_value": 0.10143448974794134, "duration": 150.3194499015808, "step": 7625}
{"episode_reward": 471.87712026249164, "episode": 62.0, "Q1 loss": 7.573917205810547, "Q2 loss": 7.6016390495300294, "Mean Target Q": 81.07765124511718, "Mean Q1": 81.06827667236328, "Mean Q2": 81.06874182128907, "critic_loss": 15.175556312561035, "batch_reward": 2.342260789871216, "actor_loss": -82.28710457586473, "actor_target_entropy": -1.0, "actor_entropy": -0.06925259985690636, "alpha_loss": -0.04693215487584952, "alpha_value": 0.10210099782177981, "duration": 149.54549980163574, "step": 7750}
{"episode_reward": 611.8365575129935, "episode": 63.0, "Q1 loss": 7.440690620422363, "Q2 loss": 7.467196449279785, "Mean Target Q": 83.56819842529296, "Mean Q1": 83.56194665527343, "Mean Q2": 83.56133001708984, "critic_loss": 14.907887115478516, "batch_reward": 2.3767079486846923, "actor_loss": -84.83928692530073, "actor_target_entropy": -1.0, "actor_entropy": -0.05986449286519062, "alpha_loss": -0.04528873836592076, "alpha_value": 0.10274632323824687, "duration": 160.7779188156128, "step": 7875}
{"episode_reward": 631.1355502972261, "episode": 64.0, "Q1 loss": 7.943207286834717, "Q2 loss": 7.884528533935547, "Mean Target Q": 85.67710333251954, "Mean Q1": 85.67547454833985, "Mean Q2": 85.67675323486328, "critic_loss": 15.827735832214355, "batch_reward": 2.3881718196868897, "actor_loss": -87.0159208236202, "actor_target_entropy": -1.0, "actor_entropy": -0.08892863102617764, "alpha_loss": -0.04386765041178273, "alpha_value": 0.10335591571199233, "duration": 144.2719292640686, "step": 8000}
{"episode_reward": 510.96877249356993, "episode": 65.0, "Q1 loss": 8.12313431930542, "Q2 loss": 8.182369235992432, "Mean Target Q": 88.10640673828125, "Mean Q1": 88.09683679199219, "Mean Q2": 88.09498693847657, "critic_loss": 16.305503532409666, "batch_reward": 2.4284445991516113, "actor_loss": -89.37374345083086, "actor_target_entropy": -1.0, "actor_entropy": -0.08835099937601222, "alpha_loss": -0.044087790484939306, "alpha_value": 0.10398154640089599, "duration": 147.97402954101562, "step": 8125}
{"episode_reward": 585.3204554313927, "episode": 66.0, "Q1 loss": 8.146847217559815, "Q2 loss": 8.147896644592285, "Mean Target Q": 90.19972467041016, "Mean Q1": 90.19536224365234, "Mean Q2": 90.19554461669922, "critic_loss": 16.294743873596193, "batch_reward": 2.4682859363555907, "actor_loss": -91.45110702514648, "actor_target_entropy": -1.0, "actor_entropy": -0.07065299579933766, "alpha_loss": -0.04428470152760706, "alpha_value": 0.10459352610148562, "duration": 145.0909218788147, "step": 8250}
{"episode_reward": 674.8373843891719, "episode": 67.0, "Q1 loss": 8.964731754302978, "Q2 loss": 8.987187690734864, "Mean Target Q": 92.74177917480469, "Mean Q1": 92.7262349243164, "Mean Q2": 92.72673278808594, "critic_loss": 17.951919509887695, "batch_reward": 2.5168304595947264, "actor_loss": -93.98958369663784, "actor_target_entropy": -1.0, "actor_entropy": -0.09125084329455618, "alpha_loss": -0.04583573356152527, "alpha_value": 0.1052527557621194, "duration": 151.17049193382263, "step": 8375}
{"episode_reward": 633.2642260394906, "episode": 68.0, "Q1 loss": 8.678135444641113, "Q2 loss": 8.681475177764893, "Mean Target Q": 95.23433575439454, "Mean Q1": 95.2280473022461, "Mean Q2": 95.22900341796876, "critic_loss": 17.35961057281494, "batch_reward": 2.5446337451934813, "actor_loss": -96.38108702628843, "actor_target_entropy": -1.0, "actor_entropy": -0.1342687443830073, "alpha_loss": -0.051149462950566126, "alpha_value": 0.10595426709917811, "duration": 157.82887530326843, "step": 8500}
{"episode_reward": 826.2069370175667, "episode": 69.0, "Q1 loss": 9.473736743927002, "Q2 loss": 9.524929222106934, "Mean Target Q": 97.89254962158203, "Mean Q1": 97.88815344238282, "Mean Q2": 97.88727532958984, "critic_loss": 18.998665969848634, "batch_reward": 2.593609474182129, "actor_loss": -99.18087744334387, "actor_target_entropy": -1.0, "actor_entropy": -0.13295615950806272, "alpha_loss": -0.04816241792979695, "alpha_value": 0.10664249590510101, "duration": 141.98626255989075, "step": 8625}
{"episode_reward": 584.48981044334, "episode": 70.0, "Q1 loss": 10.589276092529296, "Q2 loss": 10.620019836425781, "Mean Target Q": 100.19751165771484, "Mean Q1": 100.18329968261719, "Mean Q2": 100.18338946533203, "critic_loss": 21.209295913696288, "batch_reward": 2.6187558364868164, "actor_loss": -101.42028845510175, "actor_target_entropy": -1.0, "actor_entropy": -0.16965398585964594, "alpha_loss": -0.050725173115009264, "alpha_value": 0.10736231323508455, "duration": 151.84419536590576, "step": 8750}
{"episode_reward": 741.0644118878572, "episode": 71.0, "Q1 loss": 10.021408962249756, "Q2 loss": 10.019881046295167, "Mean Target Q": 103.05235064697266, "Mean Q1": 103.04799450683593, "Mean Q2": 103.0474580078125, "critic_loss": 20.041289962768555, "batch_reward": 2.696589696884155, "actor_loss": -104.189452156188, "actor_target_entropy": -1.0, "actor_entropy": -0.1553375685498828, "alpha_loss": -0.054228297952148646, "alpha_value": 0.1081071740285292, "duration": 152.10789585113525, "step": 8875}
{"episode_reward": 738.1276735785947, "episode": 72.0, "Q1 loss": 10.494803779602051, "Q2 loss": 10.48890673828125, "Mean Target Q": 105.90441729736328, "Mean Q1": 105.89711431884766, "Mean Q2": 105.89769885253907, "critic_loss": 20.983710609436034, "batch_reward": 2.743064250946045, "actor_loss": -107.40388587213332, "actor_target_entropy": -1.0, "actor_entropy": -0.14810247892033188, "alpha_loss": -0.0519282431491921, "alpha_value": 0.10886084015029515, "duration": 160.35082602500916, "step": 9000}
{"episode_reward": 733.3206080904989, "episode": 73.0, "Q1 loss": 10.342411010742188, "Q2 loss": 10.40580029296875, "Mean Target Q": 108.40608135986328, "Mean Q1": 108.40115576171875, "Mean Q2": 108.4022244873047, "critic_loss": 20.748211334228515, "batch_reward": 2.761475112915039, "actor_loss": -109.68161894783141, "actor_target_entropy": -1.0, "actor_entropy": -0.1603998929143898, "alpha_loss": -0.051869391892401, "alpha_value": 0.10960582490701616, "duration": 143.61548924446106, "step": 9125}
{"episode_reward": 759.7882704069884, "episode": 74.0, "Q1 loss": 11.460718181610108, "Q2 loss": 11.380784580230713, "Mean Target Q": 111.33623974609375, "Mean Q1": 111.33341564941406, "Mean Q2": 111.33408703613281, "critic_loss": 22.841502799987794, "batch_reward": 2.8060019779205323, "actor_loss": -112.82522287676412, "actor_target_entropy": -1.0, "actor_entropy": -0.1869107513658462, "alpha_loss": -0.053154954085907626, "alpha_value": 0.1103570294438506, "duration": 171.34045314788818, "step": 9250}
{"episode_reward": 693.7869950060337, "episode": 75.0, "Q1 loss": 12.817645755767822, "Q2 loss": 12.811961238861084, "Mean Target Q": 114.3504942626953, "Mean Q1": 114.32821618652343, "Mean Q2": 114.3294278564453, "critic_loss": 25.629606986999512, "batch_reward": 2.8607348327636717, "actor_loss": -115.62932647220673, "actor_target_entropy": -1.0, "actor_entropy": -0.18929815919153273, "alpha_loss": -0.05130364154539411, "alpha_value": 0.11109518024172597, "duration": 154.932213306427, "step": 9375}
{"episode_reward": 808.3808309808882, "episode": 76.0, "Q1 loss": 12.09269362640381, "Q2 loss": 12.077533115386963, "Mean Target Q": 117.08600482177734, "Mean Q1": 117.08762866210938, "Mean Q2": 117.08486267089843, "critic_loss": 24.17022674560547, "batch_reward": 2.898822885513306, "actor_loss": -118.4181897563319, "actor_target_entropy": -1.0, "actor_entropy": -0.23390965187741863, "alpha_loss": -0.054996614915228656, "alpha_value": 0.11184254728893649, "duration": 161.07583951950073, "step": 9500}
{"episode_reward": 677.7432174059038, "episode": 77.0, "Q1 loss": 12.370945663452149, "Q2 loss": 12.340459804534913, "Mean Target Q": 120.21066882324219, "Mean Q1": 120.20351696777344, "Mean Q2": 120.20340856933593, "critic_loss": 24.711405441284178, "batch_reward": 2.9504200859069822, "actor_loss": -121.83314829024057, "actor_target_entropy": -1.0, "actor_entropy": -0.228965426011691, "alpha_loss": -0.055214699712537584, "alpha_value": 0.11261889732266821, "duration": 159.27338361740112, "step": 9625}
{"episode_reward": 815.2657232157082, "episode": 78.0, "Q1 loss": 13.416342697143556, "Q2 loss": 13.472306247711181, "Mean Target Q": 123.19568988037109, "Mean Q1": 123.18697021484375, "Mean Q2": 123.18631774902343, "critic_loss": 26.88864897918701, "batch_reward": 2.9889960899353025, "actor_loss": -124.72780965989635, "actor_target_entropy": -1.0, "actor_entropy": -0.2712789415832489, "alpha_loss": -0.05381167346551534, "alpha_value": 0.11340459079744378, "duration": 159.4114124774933, "step": 9750}
{"episode_reward": 822.8422860394613, "episode": 79.0, "Q1 loss": 13.049765769958496, "Q2 loss": 12.962258697509766, "Mean Target Q": 126.26885656738281, "Mean Q1": 126.26038623046875, "Mean Q2": 126.261349609375, "critic_loss": 26.012024421691894, "batch_reward": 3.0447311992645263, "actor_loss": -127.88345240032862, "actor_target_entropy": -1.0, "actor_entropy": -0.22955571978338182, "alpha_loss": -0.05740426652251728, "alpha_value": 0.11420303429769661, "duration": 159.19549775123596, "step": 9875}
{"episode_reward": 755.9189383593274, "episode": 80.0, "Q1 loss": 13.83772255706787, "Q2 loss": 13.868843193054198, "Mean Target Q": 128.9429217529297, "Mean Q1": 128.93480737304688, "Mean Q2": 128.93488409423827, "critic_loss": 27.706565673828123, "batch_reward": 3.0611722984313965, "actor_loss": -130.7488044000441, "actor_target_entropy": -1.0, "actor_entropy": -0.27084324076291055, "alpha_loss": -0.05769028340376193, "alpha_value": 0.11501041096657783, "step": 10000}
{"duration": 169.82785606384277, "step": 10000}
{"episode_reward": 753.779688167176, "episode": 81.0, "Q1 loss": 15.0332314453125, "Q2 loss": 15.122425453186036, "Mean Target Q": 132.06406921386719, "Mean Q1": 132.05819744873048, "Mean Q2": 132.0582244873047, "critic_loss": 30.15565689086914, "batch_reward": 3.1011642723083495, "actor_loss": -133.78241160559276, "actor_target_entropy": -1.0, "actor_entropy": -0.24224632682781372, "alpha_loss": -0.05564720928668976, "alpha_value": 0.11579477240978739, "duration": 176.08237051963806, "step": 10125}
{"episode_reward": 748.3019691594232, "episode": 82.0, "Q1 loss": 15.877536827087402, "Q2 loss": 15.761969573974609, "Mean Target Q": 135.44377795410156, "Mean Q1": 135.43324743652343, "Mean Q2": 135.43238134765625, "critic_loss": 31.639506378173827, "batch_reward": 3.159905652999878, "actor_loss": -136.9034950502457, "actor_target_entropy": -1.0, "actor_entropy": -0.30108473834491545, "alpha_loss": -0.05612311878752324, "alpha_value": 0.11658838544965931, "duration": 156.9801013469696, "step": 10250}
{"episode_reward": 759.1400190824754, "episode": 83.0, "Q1 loss": 16.930028450012205, "Q2 loss": 17.00887731170654, "Mean Target Q": 138.59193872070313, "Mean Q1": 138.58871508789062, "Mean Q2": 138.589498046875, "critic_loss": 33.93890580749512, "batch_reward": 3.186144344329834, "actor_loss": -140.26322113521516, "actor_target_entropy": -1.0, "actor_entropy": -0.29195841319031185, "alpha_loss": -0.06110811777531155, "alpha_value": 0.11741231614559763, "duration": 158.85896515846252, "step": 10375}
{"episode_reward": 764.0063348174593, "episode": 84.0, "Q1 loss": 15.227014869689942, "Q2 loss": 15.230087837219239, "Mean Target Q": 141.2493253173828, "Mean Q1": 141.24241772460937, "Mean Q2": 141.24273779296874, "critic_loss": 30.457102844238282, "batch_reward": 3.2029450016021728, "actor_loss": -143.05904437649636, "actor_target_entropy": -1.0, "actor_entropy": -0.29371445505849775, "alpha_loss": -0.06102455713816227, "alpha_value": 0.11827988686118222, "duration": 154.19358110427856, "step": 10500}
{"episode_reward": 750.659611876574, "episode": 85.0, "Q1 loss": 16.558183830261232, "Q2 loss": 16.525462951660156, "Mean Target Q": 145.0147391357422, "Mean Q1": 144.99471240234374, "Mean Q2": 144.99524536132813, "critic_loss": 33.08364663696289, "batch_reward": 3.260634178161621, "actor_loss": -146.5985812232608, "actor_target_entropy": -1.0, "actor_entropy": -0.30834297244510955, "alpha_loss": -0.06396272074845102, "alpha_value": 0.11916379728541704, "duration": 159.83147168159485, "step": 10625}
{"episode_reward": 763.5093606908957, "episode": 86.0, "Q1 loss": 18.810296897888183, "Q2 loss": 18.792450729370117, "Mean Target Q": 147.86415307617187, "Mean Q1": 147.86340197753907, "Mean Q2": 147.862521484375, "critic_loss": 37.60274772644043, "batch_reward": 3.265666893005371, "actor_loss": -149.76314495455833, "actor_target_entropy": -1.0, "actor_entropy": -0.27845796221686947, "alpha_loss": -0.06226957943891325, "alpha_value": 0.12002450605056719, "duration": 157.25798344612122, "step": 10750}
{"episode_reward": 813.3307900884596, "episode": 87.0, "Q1 loss": 19.104880836486817, "Q2 loss": 19.029660095214844, "Mean Target Q": 151.28948779296874, "Mean Q1": 151.27914721679687, "Mean Q2": 151.27993835449217, "critic_loss": 38.134540832519534, "batch_reward": 3.3102468223571777, "actor_loss": -152.7984875875806, "actor_target_entropy": -1.0, "actor_entropy": -0.2739032019698431, "alpha_loss": -0.05980025421059321, "alpha_value": 0.12087404127935954, "duration": 165.67915391921997, "step": 10875}
{"episode_reward": 832.946096981783, "episode": 88.0, "Q1 loss": 18.99840663909912, "Q2 loss": 19.1091256942749, "Mean Target Q": 154.57382141113283, "Mean Q1": 154.56278051757812, "Mean Q2": 154.56358898925782, "critic_loss": 38.107532455444336, "batch_reward": 3.355811450958252, "actor_loss": -156.06995908675654, "actor_target_entropy": -1.0, "actor_entropy": -0.2931434192484425, "alpha_loss": -0.06718205089770979, "alpha_value": 0.12174968611007837, "duration": 168.87262606620789, "step": 11000}
{"episode_reward": 824.2117548394243, "episode": 89.0, "Q1 loss": 18.545791961669924, "Q2 loss": 18.66580995941162, "Mean Target Q": 158.10295910644533, "Mean Q1": 158.10072473144533, "Mean Q2": 158.09959020996095, "critic_loss": 37.21160203552246, "batch_reward": 3.394391538619995, "actor_loss": -159.79151577419705, "actor_target_entropy": -1.0, "actor_entropy": -0.3135892010870434, "alpha_loss": -0.06818910652682894, "alpha_value": 0.12267208149346216, "duration": 158.71550154685974, "step": 11125}
{"episode_reward": 761.8924860233219, "episode": 90.0, "Q1 loss": 19.515901893615723, "Q2 loss": 19.752373527526856, "Mean Target Q": 161.13445874023438, "Mean Q1": 161.11782763671874, "Mean Q2": 161.11847985839844, "critic_loss": 39.268275421142576, "batch_reward": 3.4042804546356202, "actor_loss": -162.90477678852696, "actor_target_entropy": -1.0, "actor_entropy": -0.32346301117251, "alpha_loss": -0.06127947448722778, "alpha_value": 0.12356665924475334, "duration": 153.2881200313568, "step": 11250}
{"episode_reward": 827.0209802454574, "episode": 91.0, "Q1 loss": 18.32538655090332, "Q2 loss": 18.454354774475096, "Mean Target Q": 164.74591430664063, "Mean Q1": 164.74642224121095, "Mean Q2": 164.74414404296874, "critic_loss": 36.779741287231445, "batch_reward": 3.465281211853027, "actor_loss": -166.57814268081907, "actor_target_entropy": -1.0, "actor_entropy": -0.29555181827810073, "alpha_loss": -0.06633659203847249, "alpha_value": 0.12441562591366614, "duration": 156.29903316497803, "step": 11375}
{"episode_reward": 761.7371175467404, "episode": 92.0, "Q1 loss": 20.699962829589843, "Q2 loss": 20.667096893310546, "Mean Target Q": 167.87891320800782, "Mean Q1": 167.86163623046875, "Mean Q2": 167.8616365966797, "critic_loss": 41.36705952453613, "batch_reward": 3.4942068576812746, "actor_loss": -169.57533731768208, "actor_target_entropy": -1.0, "actor_entropy": -0.3267489837542657, "alpha_loss": -0.0644510488115972, "alpha_value": 0.12530321998314134, "duration": 154.22002577781677, "step": 11500}
{"episode_reward": 730.7955305005311, "episode": 93.0, "Q1 loss": 18.802487083435057, "Q2 loss": 18.891355155944826, "Mean Target Q": 171.16825634765624, "Mean Q1": 171.16247387695313, "Mean Q2": 171.1628446044922, "critic_loss": 37.693842010498045, "batch_reward": 3.51180002784729, "actor_loss": -173.17273796929254, "actor_target_entropy": -1.0, "actor_entropy": -0.3325518343656782, "alpha_loss": -0.06631130742884818, "alpha_value": 0.12618073036066388, "duration": 150.20078134536743, "step": 11625}
{"episode_reward": 754.5816013729348, "episode": 94.0, "Q1 loss": 19.888240036010743, "Q2 loss": 19.953526428222656, "Mean Target Q": 174.45595373535156, "Mean Q1": 174.44899169921874, "Mean Q2": 174.4509005126953, "critic_loss": 39.84176657104492, "batch_reward": 3.533542345046997, "actor_loss": -176.08484748102003, "actor_target_entropy": -1.0, "actor_entropy": -0.33170273755827256, "alpha_loss": -0.06771798906547408, "alpha_value": 0.1270845455033906, "duration": 152.07310390472412, "step": 11750}
{"episode_reward": 797.7652584591341, "episode": 95.0, "Q1 loss": 21.836147979736328, "Q2 loss": 21.86225026702881, "Mean Target Q": 177.629623046875, "Mean Q1": 177.62676208496094, "Mean Q2": 177.62616821289063, "critic_loss": 43.69839833068848, "batch_reward": 3.5562669696807863, "actor_loss": -179.62097095307848, "actor_target_entropy": -1.0, "actor_entropy": -0.3268740153501904, "alpha_loss": -0.06614901628049594, "alpha_value": 0.12799639590036674, "duration": 159.4357874393463, "step": 11875}
{"episode_reward": 791.1411025435674, "episode": 96.0, "Q1 loss": 21.211438873291016, "Q2 loss": 21.32257836151123, "Mean Target Q": 181.36852221679686, "Mean Q1": 181.35340246582032, "Mean Q2": 181.35209423828124, "critic_loss": 42.534017166137694, "batch_reward": 3.599040964126587, "actor_loss": -183.3924279982044, "actor_target_entropy": -1.0, "actor_entropy": -0.31753376991518084, "alpha_loss": -0.06837801442992303, "alpha_value": 0.12890228475219337, "duration": 148.24049925804138, "step": 12000}
{"episode_reward": 824.0154095327272, "episode": 97.0, "Q1 loss": 21.98704430389404, "Q2 loss": 22.055698997497558, "Mean Target Q": 184.82685107421875, "Mean Q1": 184.8221007080078, "Mean Q2": 184.8234207763672, "critic_loss": 44.042743545532225, "batch_reward": 3.623888252258301, "actor_loss": -187.05956571064297, "actor_target_entropy": -1.0, "actor_entropy": -0.370580394116659, "alpha_loss": -0.07029495648448429, "alpha_value": 0.12981397039860323, "duration": 146.45927953720093, "step": 12125}
{"episode_reward": 804.8568194436599, "episode": 98.0, "Q1 loss": 23.50296041870117, "Q2 loss": 23.604254859924318, "Mean Target Q": 188.66618395996093, "Mean Q1": 188.6507666015625, "Mean Q2": 188.65214135742187, "critic_loss": 47.10721517944336, "batch_reward": 3.6878124866485598, "actor_loss": -190.77637506300402, "actor_target_entropy": -1.0, "actor_entropy": -0.37005286086951533, "alpha_loss": -0.07043339840827449, "alpha_value": 0.1307628999930453, "duration": 158.80974745750427, "step": 12250}
{"episode_reward": 684.303357521492, "episode": 99.0, "Q1 loss": 22.196848937988282, "Q2 loss": 22.31221788787842, "Mean Target Q": 191.41969604492186, "Mean Q1": 191.4182763671875, "Mean Q2": 191.41647290039063, "critic_loss": 44.50906669616699, "batch_reward": 3.67414133644104, "actor_loss": -193.746334015377, "actor_target_entropy": -1.0, "actor_entropy": -0.345985283927312, "alpha_loss": -0.07226120426304757, "alpha_value": 0.13171079572230243, "duration": 164.02783513069153, "step": 12375}
{"episode_reward": 728.1798931996262, "episode": 100.0, "Q1 loss": 22.630602432250978, "Q2 loss": 22.649140815734864, "Mean Target Q": 195.13533459472657, "Mean Q1": 195.11810925292968, "Mean Q2": 195.12034326171874, "critic_loss": 45.27974319458008, "batch_reward": 3.6935928325653076, "actor_loss": -197.1179260746125, "actor_target_entropy": -1.0, "actor_entropy": -0.34387698961842444, "alpha_loss": -0.06759534842304644, "alpha_value": 0.13262273093105176, "duration": 157.80977296829224, "step": 12500}
{"episode_reward": 744.032780444296, "episode": 101.0, "Q1 loss": 24.491651878356933, "Q2 loss": 24.395879859924317, "Mean Target Q": 198.92688818359375, "Mean Q1": 198.91881066894533, "Mean Q2": 198.9165623779297, "critic_loss": 48.887531677246095, "batch_reward": 3.7218095474243165, "actor_loss": -201.15157766190785, "actor_target_entropy": -1.0, "actor_entropy": -0.3741687387228012, "alpha_loss": -0.07380315750127747, "alpha_value": 0.13354763750506765, "duration": 154.9788589477539, "step": 12625}
{"episode_reward": 818.139285164475, "episode": 102.0, "Q1 loss": 26.90108009338379, "Q2 loss": 26.851421615600586, "Mean Target Q": 201.56930493164063, "Mean Q1": 201.5697606201172, "Mean Q2": 201.5716710205078, "critic_loss": 53.75250183105469, "batch_reward": 3.708333641052246, "actor_loss": -203.82962602184665, "actor_target_entropy": -1.0, "actor_entropy": -0.3583157966213842, "alpha_loss": -0.07203935333076984, "alpha_value": 0.13450456699375687, "duration": 159.75129652023315, "step": 12750}
{"episode_reward": 733.3435984044539, "episode": 103.0, "Q1 loss": 23.7834061126709, "Q2 loss": 23.87716237640381, "Mean Target Q": 205.53389587402344, "Mean Q1": 205.5135656738281, "Mean Q2": 205.51235607910155, "critic_loss": 47.660568450927734, "batch_reward": 3.7769927616119383, "actor_loss": -207.66331360832092, "actor_target_entropy": -1.0, "actor_entropy": -0.3404214736961183, "alpha_loss": -0.07272381773070684, "alpha_value": 0.1354441693031955, "duration": 157.71537232398987, "step": 12875}
{"episode_reward": 718.4538940141107, "episode": 104.0, "Q1 loss": 23.13497918701172, "Q2 loss": 23.108808670043945, "Mean Target Q": 208.9655920410156, "Mean Q1": 208.95783154296876, "Mean Q2": 208.95707800292968, "critic_loss": 46.24378805541992, "batch_reward": 3.7959049491882326, "actor_loss": -211.4815216064453, "actor_target_entropy": -1.0, "actor_entropy": -0.36468180196900524, "alpha_loss": -0.07419144921004772, "alpha_value": 0.136426312472733, "duration": 154.94597148895264, "step": 13000}
{"episode_reward": 815.2193361407056, "episode": 105.0, "Q1 loss": 24.078206260681153, "Q2 loss": 24.146405899047853, "Mean Target Q": 212.54209106445313, "Mean Q1": 212.53404809570313, "Mean Q2": 212.53233544921875, "critic_loss": 48.224612365722656, "batch_reward": 3.803946273803711, "actor_loss": -214.90486895848835, "actor_target_entropy": -1.0, "actor_entropy": -0.34864356664438095, "alpha_loss": -0.07409044083148714, "alpha_value": 0.1373966845280306, "duration": 159.5587501525879, "step": 13125}
{"episode_reward": 753.1502358319673, "episode": 106.0, "Q1 loss": 25.545404724121095, "Q2 loss": 25.38949966430664, "Mean Target Q": 216.03156860351564, "Mean Q1": 216.02726611328126, "Mean Q2": 216.02900109863282, "critic_loss": 50.93490447998047, "batch_reward": 3.8307864990234375, "actor_loss": -218.09131105484502, "actor_target_entropy": -1.0, "actor_entropy": -0.35631870694698825, "alpha_loss": -0.07193534004111443, "alpha_value": 0.13834967279843086, "duration": 156.06616497039795, "step": 13250}
{"episode_reward": 757.6161192466326, "episode": 107.0, "Q1 loss": 24.94831243133545, "Q2 loss": 24.952133506774903, "Mean Target Q": 219.71902368164064, "Mean Q1": 219.69841931152342, "Mean Q2": 219.69968200683593, "critic_loss": 49.90044604492188, "batch_reward": 3.864428493499756, "actor_loss": -221.45155140710256, "actor_target_entropy": -1.0, "actor_entropy": -0.35042058404475923, "alpha_loss": -0.07286993189463539, "alpha_value": 0.13928667075164364, "duration": 158.5922088623047, "step": 13375}
{"episode_reward": 752.6452530983527, "episode": 108.0, "Q1 loss": 23.914093132019044, "Q2 loss": 24.03759973144531, "Mean Target Q": 223.05615209960936, "Mean Q1": 223.06008813476564, "Mean Q2": 223.0592060546875, "critic_loss": 47.9516929473877, "batch_reward": 3.8858571014404295, "actor_loss": -225.31774336291897, "actor_target_entropy": -1.0, "actor_entropy": -0.33725892319794626, "alpha_loss": -0.07192288002660198, "alpha_value": 0.1402262164251689, "duration": 148.09041261672974, "step": 13500}
{"episode_reward": 734.0175582163677, "episode": 109.0, "Q1 loss": 23.07063986968994, "Q2 loss": 23.138492362976073, "Mean Target Q": 226.16341101074218, "Mean Q1": 226.14903173828125, "Mean Q2": 226.14860290527344, "critic_loss": 46.209132293701174, "batch_reward": 3.8765509700775147, "actor_loss": -228.1887718079582, "actor_target_entropy": -1.0, "actor_entropy": -0.34005384383693577, "alpha_loss": -0.07779684302116198, "alpha_value": 0.14121560539857586, "duration": 149.27969670295715, "step": 13625}
{"episode_reward": 760.4523679108241, "episode": 110.0, "Q1 loss": 22.334691902160646, "Q2 loss": 22.498557540893554, "Mean Target Q": 230.11027490234375, "Mean Q1": 230.095978515625, "Mean Q2": 230.09665209960937, "critic_loss": 44.83324928283692, "batch_reward": 3.94248309135437, "actor_loss": -232.47389467300908, "actor_target_entropy": -1.0, "actor_entropy": -0.3325104458678153, "alpha_loss": -0.06905763049519831, "alpha_value": 0.1421505471499202, "duration": 152.29638981819153, "step": 13750}
{"episode_reward": 736.9918497009522, "episode": 111.0, "Q1 loss": 23.497789169311524, "Q2 loss": 23.368220504760743, "Mean Target Q": 233.42765563964844, "Mean Q1": 233.42894665527345, "Mean Q2": 233.43031213378907, "critic_loss": 46.86600970458984, "batch_reward": 3.939627561569214, "actor_loss": -235.17862011137464, "actor_target_entropy": -1.0, "actor_entropy": -0.3503054098950492, "alpha_loss": -0.07130802416848758, "alpha_value": 0.14307808162036087, "duration": 156.748473405838, "step": 13875}
{"episode_reward": 808.0700283232919, "episode": 112.0, "Q1 loss": 23.21426249694824, "Q2 loss": 23.090575881958006, "Mean Target Q": 236.8432882080078, "Mean Q1": 236.8340450439453, "Mean Q2": 236.83328466796874, "critic_loss": 46.30483837890625, "batch_reward": 3.961373037338257, "actor_loss": -238.8598115982548, "actor_target_entropy": -1.0, "actor_entropy": -0.36294535763802066, "alpha_loss": -0.07711621728395263, "alpha_value": 0.1440574055898607, "duration": 150.31744623184204, "step": 14000}
{"episode_reward": 808.797257126535, "episode": 113.0, "Q1 loss": 23.575192695617677, "Q2 loss": 23.602379608154298, "Mean Target Q": 240.015169921875, "Mean Q1": 239.99703552246095, "Mean Q2": 239.99390185546875, "critic_loss": 47.17757217407227, "batch_reward": 3.9791008377075197, "actor_loss": -241.88375854492188, "actor_target_entropy": -1.0, "actor_entropy": -0.3184573797006456, "alpha_loss": -0.07717163683403105, "alpha_value": 0.1450636679535249, "duration": 153.85702514648438, "step": 14125}
{"episode_reward": 753.8442958191021, "episode": 114.0, "Q1 loss": 23.581229835510253, "Q2 loss": 23.608761306762695, "Mean Target Q": 243.6269541015625, "Mean Q1": 243.61575634765626, "Mean Q2": 243.6197490234375, "critic_loss": 47.189991134643556, "batch_reward": 4.013582731246948, "actor_loss": -245.83929024973224, "actor_target_entropy": -1.0, "actor_entropy": -0.3298234302670725, "alpha_loss": -0.07477598949786156, "alpha_value": 0.1460255593016688, "duration": 160.32461714744568, "step": 14250}
{"episode_reward": 822.3841416543945, "episode": 115.0, "Q1 loss": 21.586191513061525, "Q2 loss": 21.781503959655762, "Mean Target Q": 246.5364423828125, "Mean Q1": 246.53122204589843, "Mean Q2": 246.52981274414063, "critic_loss": 43.36769552612305, "batch_reward": 3.9980215015411376, "actor_loss": -248.62224566747273, "actor_target_entropy": -1.0, "actor_entropy": -0.3177377811026952, "alpha_loss": -0.07483494878997879, "alpha_value": 0.14700245325356473, "duration": 159.7082715034485, "step": 14375}
{"episode_reward": 813.4083690247865, "episode": 116.0, "Q1 loss": 23.401253707885743, "Q2 loss": 23.50432657623291, "Mean Target Q": 250.08002807617189, "Mean Q1": 250.07241809082032, "Mean Q2": 250.071634765625, "critic_loss": 46.90558003234863, "batch_reward": 4.040692108154297, "actor_loss": -252.0952933526808, "actor_target_entropy": -1.0, "actor_entropy": -0.3159689622059945, "alpha_loss": -0.06938662512167808, "alpha_value": 0.14795527940863296, "duration": 155.76020622253418, "step": 14500}
{"episode_reward": 735.5032861520117, "episode": 117.0, "Q1 loss": 22.21457024383545, "Q2 loss": 22.16216328430176, "Mean Target Q": 253.5348564453125, "Mean Q1": 253.51942639160157, "Mean Q2": 253.52114416503906, "critic_loss": 44.376733352661134, "batch_reward": 4.055750843048096, "actor_loss": -255.73533436608693, "actor_target_entropy": -1.0, "actor_entropy": -0.3081883840144627, "alpha_loss": -0.07205026744613571, "alpha_value": 0.1488887658432411, "duration": 155.64371132850647, "step": 14625}
{"episode_reward": 742.9723527491873, "episode": 118.0, "Q1 loss": 20.892170707702636, "Q2 loss": 20.78109433746338, "Mean Target Q": 256.0627697753906, "Mean Q1": 256.06454077148436, "Mean Q2": 256.0644434814453, "critic_loss": 41.673265075683595, "batch_reward": 4.057004219055176, "actor_loss": -257.9895949825164, "actor_target_entropy": -1.0, "actor_entropy": -0.3607079550143211, "alpha_loss": -0.07991507553285168, "alpha_value": 0.14990048394196542, "duration": 154.93946313858032, "step": 14750}
{"episode_reward": 674.7992939761679, "episode": 119.0, "Q1 loss": 20.800178329467773, "Q2 loss": 20.70257331085205, "Mean Target Q": 260.0085759277344, "Mean Q1": 259.9923114013672, "Mean Q2": 259.9920621337891, "critic_loss": 41.502751693725585, "batch_reward": 4.098926231384278, "actor_loss": -262.1838926285032, "actor_target_entropy": -1.0, "actor_entropy": -0.29195976351934766, "alpha_loss": -0.07385936929356485, "alpha_value": 0.150926817232888, "duration": 146.31220960617065, "step": 14875}
{"episode_reward": 798.2137346419372, "episode": 120.0, "Q1 loss": 20.19657196044922, "Q2 loss": 20.190663444519043, "Mean Target Q": 263.38461279296877, "Mean Q1": 263.37700622558594, "Mean Q2": 263.37593701171875, "critic_loss": 40.38723533630371, "batch_reward": 4.112761476516724, "actor_loss": -265.38970898043726, "actor_target_entropy": -1.0, "actor_entropy": -0.3294797287352623, "alpha_loss": -0.07324557126529756, "alpha_value": 0.1518712395033906, "step": 15000}
{"duration": 176.56938552856445, "step": 15000}
{"episode_reward": 820.2406602239316, "episode": 121.0, "Q1 loss": 24.03630295562744, "Q2 loss": 24.01226188659668, "Mean Target Q": 266.0795729980469, "Mean Q1": 266.06622241210937, "Mean Q2": 266.06750268554686, "critic_loss": 48.04856494140625, "batch_reward": 4.111916986465454, "actor_loss": -268.10603598942834, "actor_target_entropy": -1.0, "actor_entropy": -0.2766543314570472, "alpha_loss": -0.06737002263229991, "alpha_value": 0.15280745146579028, "duration": 158.4448812007904, "step": 15125}
{"episode_reward": 739.2940234963819, "episode": 122.0, "Q1 loss": 20.20164245605469, "Q2 loss": 20.110351623535156, "Mean Target Q": 269.3310224609375, "Mean Q1": 269.32403125, "Mean Q2": 269.3211730957031, "critic_loss": 40.31199403381348, "batch_reward": 4.1166727848052975, "actor_loss": -271.58938992408014, "actor_target_entropy": -1.0, "actor_entropy": -0.3159568795273381, "alpha_loss": -0.07310878245099899, "alpha_value": 0.15373710616329656, "duration": 147.10071635246277, "step": 15250}
{"episode_reward": 743.2878219114032, "episode": 123.0, "Q1 loss": 21.00821147155762, "Q2 loss": 20.893565170288085, "Mean Target Q": 272.88969946289063, "Mean Q1": 272.8848295898438, "Mean Q2": 272.8875810546875, "critic_loss": 41.901776504516604, "batch_reward": 4.1669466514587405, "actor_loss": -275.0952385796441, "actor_target_entropy": -1.0, "actor_entropy": -0.2820728418845979, "alpha_loss": -0.07239475923161658, "alpha_value": 0.15471568391158128, "duration": 143.34449863433838, "step": 15375}
{"episode_reward": 821.1007563867696, "episode": 124.0, "Q1 loss": 20.809889236450196, "Q2 loss": 20.806620956420897, "Mean Target Q": 276.1952385253906, "Mean Q1": 276.1876604003906, "Mean Q2": 276.1867683105469, "critic_loss": 41.616510238647464, "batch_reward": 4.162324377059937, "actor_loss": -278.18076644405244, "actor_target_entropy": -1.0, "actor_entropy": -0.3007659407392625, "alpha_loss": -0.06870035130170084, "alpha_value": 0.15569119725291647, "duration": 154.9444944858551, "step": 15500}
{"episode_reward": 687.0475401334313, "episode": 125.0, "Q1 loss": 20.344828521728516, "Q2 loss": 20.46913089752197, "Mean Target Q": 279.0117985839844, "Mean Q1": 279.0023767089844, "Mean Q2": 279.00295947265624, "critic_loss": 40.81395939636231, "batch_reward": 4.172780216217041, "actor_loss": -280.8841015043713, "actor_target_entropy": -1.0, "actor_entropy": -0.2895375691236012, "alpha_loss": -0.0701377990226897, "alpha_value": 0.156620537510541, "duration": 153.49620938301086, "step": 15625}
{"episode_reward": 748.6389442711376, "episode": 126.0, "Q1 loss": 20.769211769104004, "Q2 loss": 20.796654556274415, "Mean Target Q": 282.1077248535156, "Mean Q1": 282.10134130859376, "Mean Q2": 282.1008791503906, "critic_loss": 41.565866302490235, "batch_reward": 4.200445579528808, "actor_loss": -284.07569639144407, "actor_target_entropy": -1.0, "actor_entropy": -0.30294476353353067, "alpha_loss": -0.06514889350341212, "alpha_value": 0.15755537845252873, "duration": 144.6658320426941, "step": 15750}
{"episode_reward": 732.704977999408, "episode": 127.0, "Q1 loss": 21.04030802154541, "Q2 loss": 21.028908668518067, "Mean Target Q": 285.7202573242188, "Mean Q1": 285.71917846679685, "Mean Q2": 285.72044091796874, "critic_loss": 42.069216567993166, "batch_reward": 4.23594762802124, "actor_loss": -287.6191164046999, "actor_target_entropy": -1.0, "actor_entropy": -0.31013570725917816, "alpha_loss": -0.0629015839880421, "alpha_value": 0.15843202163005177, "duration": 149.4921932220459, "step": 15875}
{"episode_reward": 839.1306243597043, "episode": 128.0, "Q1 loss": 23.613291831970216, "Q2 loss": 23.580637634277345, "Mean Target Q": 288.7002121582031, "Mean Q1": 288.68198046875, "Mean Q2": 288.68082666015624, "critic_loss": 47.193929519653324, "batch_reward": 4.223756101608276, "actor_loss": -290.5881199990549, "actor_target_entropy": -1.0, "actor_entropy": -0.27220082403190676, "alpha_loss": -0.06486573659123913, "alpha_value": 0.15933591551872722, "duration": 148.1692132949829, "step": 16000}
{"episode_reward": 757.7566221934801, "episode": 129.0, "Q1 loss": 20.05086427307129, "Q2 loss": 20.184116584777833, "Mean Target Q": 291.3597687988281, "Mean Q1": 291.3508249511719, "Mean Q2": 291.34995141601564, "critic_loss": 40.23498080444336, "batch_reward": 4.240918985366822, "actor_loss": -293.195064484127, "actor_target_entropy": -1.0, "actor_entropy": -0.28129476734570097, "alpha_loss": -0.06000400707125664, "alpha_value": 0.16021445088823666, "duration": 159.13327550888062, "step": 16125}
{"episode_reward": 764.8953710368124, "episode": 130.0, "Q1 loss": 18.976279167175292, "Q2 loss": 18.880137062072755, "Mean Target Q": 294.8410146484375, "Mean Q1": 294.83803564453126, "Mean Q2": 294.83944873046875, "critic_loss": 37.85641629028321, "batch_reward": 4.289992860794067, "actor_loss": -296.1453754055885, "actor_target_entropy": -1.0, "actor_entropy": -0.3130878460022711, "alpha_loss": -0.06616873438319852, "alpha_value": 0.16109832445458994, "duration": 147.36291790008545, "step": 16250}
{"episode_reward": 810.3482618864119, "episode": 131.0, "Q1 loss": 19.02533080291748, "Q2 loss": 19.048610054016113, "Mean Target Q": 297.97645703125, "Mean Q1": 297.96578002929687, "Mean Q2": 297.9647160644531, "critic_loss": 38.073940658569335, "batch_reward": 4.297620611190796, "actor_loss": -299.64486016167535, "actor_target_entropy": -1.0, "actor_entropy": -0.27964201191115, "alpha_loss": -0.060472951226291205, "alpha_value": 0.16202302934550739, "duration": 158.22627592086792, "step": 16375}
{"episode_reward": 820.9523012079698, "episode": 132.0, "Q1 loss": 19.67433127593994, "Q2 loss": 19.794930740356445, "Mean Target Q": 300.5624104003906, "Mean Q1": 300.5467954101563, "Mean Q2": 300.5474157714844, "critic_loss": 39.46926196289063, "batch_reward": 4.298384677886963, "actor_loss": -302.01918226672757, "actor_target_entropy": -1.0, "actor_entropy": -0.3042708145033929, "alpha_loss": -0.062219992099750425, "alpha_value": 0.16293942268129283, "duration": 153.16339325904846, "step": 16500}
{"episode_reward": 816.5825241239515, "episode": 133.0, "Q1 loss": 18.101552963256836, "Q2 loss": 17.903555694580078, "Mean Target Q": 303.5359633789063, "Mean Q1": 303.5350075683594, "Mean Q2": 303.5342585449219, "critic_loss": 36.00510871887207, "batch_reward": 4.317521993637085, "actor_loss": -305.3567272367932, "actor_target_entropy": -1.0, "actor_entropy": -0.2852407057606985, "alpha_loss": -0.05959838232587254, "alpha_value": 0.16383496729154273, "duration": 161.46925163269043, "step": 16625}
{"episode_reward": 811.5461720524104, "episode": 134.0, "Q1 loss": 18.12190424346924, "Q2 loss": 17.977139419555662, "Mean Target Q": 306.3926840820312, "Mean Q1": 306.38178955078126, "Mean Q2": 306.3828071289062, "critic_loss": 36.09904377746582, "batch_reward": 4.3378595352172855, "actor_loss": -308.11263398201237, "actor_target_entropy": -1.0, "actor_entropy": -0.2903797424608661, "alpha_loss": -0.060379261150956154, "alpha_value": 0.16474038344363448, "duration": 152.64181447029114, "step": 16750}
{"episode_reward": 737.2178519402198, "episode": 135.0, "Q1 loss": 19.27404582977295, "Q2 loss": 19.207980178833008, "Mean Target Q": 309.0793701171875, "Mean Q1": 309.07456494140627, "Mean Q2": 309.0773137207031, "critic_loss": 38.48202600097656, "batch_reward": 4.333666193008423, "actor_loss": -310.1087099105593, "actor_target_entropy": -1.0, "actor_entropy": -0.32258040895537726, "alpha_loss": -0.06777654588222504, "alpha_value": 0.1656857993694603, "duration": 150.27355360984802, "step": 16875}
{"episode_reward": 766.4801146173967, "episode": 136.0, "Q1 loss": 18.568759475708006, "Q2 loss": 18.724724075317383, "Mean Target Q": 312.1595478515625, "Mean Q1": 312.1459970703125, "Mean Q2": 312.14177465820313, "critic_loss": 37.29348330688477, "batch_reward": 4.353831953048706, "actor_loss": -314.25980451030114, "actor_target_entropy": -1.0, "actor_entropy": -0.2941132067672668, "alpha_loss": -0.05930991068242058, "alpha_value": 0.16664525362915578, "duration": 154.22013020515442, "step": 17000}
{"episode_reward": 748.3736592136246, "episode": 137.0, "Q1 loss": 18.175730575561523, "Q2 loss": 18.074882987976075, "Mean Target Q": 314.8527431640625, "Mean Q1": 314.84660546875, "Mean Q2": 314.8493107910156, "critic_loss": 36.25061364746094, "batch_reward": 4.35848403930664, "actor_loss": -316.5096881200397, "actor_target_entropy": -1.0, "actor_entropy": -0.3047524624400669, "alpha_loss": -0.061866610828373164, "alpha_value": 0.16759168589899773, "duration": 162.56991481781006, "step": 17125}
{"episode_reward": 814.3211807267475, "episode": 138.0, "Q1 loss": 18.33397113800049, "Q2 loss": 18.437313346862794, "Mean Target Q": 317.85973974609374, "Mean Q1": 317.8572092285156, "Mean Q2": 317.85749169921877, "critic_loss": 36.77128459167481, "batch_reward": 4.368569416046142, "actor_loss": -319.29041068784653, "actor_target_entropy": -1.0, "actor_entropy": -0.24494887335646537, "alpha_loss": -0.06110335772316302, "alpha_value": 0.1685278681043037, "duration": 149.9408311843872, "step": 17250}
{"episode_reward": 820.1977839543888, "episode": 139.0, "Q1 loss": 17.498377159118654, "Q2 loss": 17.574829551696777, "Mean Target Q": 321.09276977539065, "Mean Q1": 321.07519213867187, "Mean Q2": 321.0731242675781, "critic_loss": 35.07320666503906, "batch_reward": 4.410932403564453, "actor_loss": -322.7826068212116, "actor_target_entropy": -1.0, "actor_entropy": -0.3073209871848424, "alpha_loss": -0.059877047551766274, "alpha_value": 0.16950172346585396, "duration": 162.63939547538757, "step": 17375}
{"episode_reward": 743.9884822566582, "episode": 140.0, "Q1 loss": 17.637801681518553, "Q2 loss": 17.48062925720215, "Mean Target Q": 323.7400710449219, "Mean Q1": 323.7378046875, "Mean Q2": 323.73944287109373, "critic_loss": 35.11843089294434, "batch_reward": 4.425774898529053, "actor_loss": -325.3594311129662, "actor_target_entropy": -1.0, "actor_entropy": -0.30399936990391824, "alpha_loss": -0.05945371923547599, "alpha_value": 0.1704098786546576, "duration": 155.990492105484, "step": 17500}
{"episode_reward": 719.4154706439358, "episode": 141.0, "Q1 loss": 17.07366993713379, "Q2 loss": 17.02170001220703, "Mean Target Q": 326.16591821289063, "Mean Q1": 326.1623645019531, "Mean Q2": 326.1620715332031, "critic_loss": 34.09536987304688, "batch_reward": 4.402171619415284, "actor_loss": -327.982903374566, "actor_target_entropy": -1.0, "actor_entropy": -0.29329210567095926, "alpha_loss": -0.055420240623846886, "alpha_value": 0.17134891788014103, "duration": 147.33134412765503, "step": 17625}
{"episode_reward": 812.9434612120928, "episode": 142.0, "Q1 loss": 18.078655860900877, "Q2 loss": 18.236981796264647, "Mean Target Q": 328.64154565429686, "Mean Q1": 328.63287329101564, "Mean Q2": 328.63256127929685, "critic_loss": 36.31563752746582, "batch_reward": 4.419636775970459, "actor_loss": -330.02549743652344, "actor_target_entropy": -1.0, "actor_entropy": -0.2638214261781785, "alpha_loss": -0.05912026531633831, "alpha_value": 0.17229237270178285, "duration": 160.01225113868713, "step": 17750}
{"episode_reward": 662.8568376124691, "episode": 143.0, "Q1 loss": 17.350016693115233, "Q2 loss": 17.33702102661133, "Mean Target Q": 331.4121201171875, "Mean Q1": 331.4065578613281, "Mean Q2": 331.4052692871094, "critic_loss": 34.68703782653809, "batch_reward": 4.4232885398864745, "actor_loss": -332.89478604755703, "actor_target_entropy": -1.0, "actor_entropy": -0.24760050503980546, "alpha_loss": -0.054446843467534534, "alpha_value": 0.17321745210750872, "duration": 159.39307165145874, "step": 17875}
{"episode_reward": 829.5775286159646, "episode": 144.0, "Q1 loss": 17.717581565856932, "Q2 loss": 17.67826210784912, "Mean Target Q": 334.2310432128906, "Mean Q1": 334.21984765625, "Mean Q2": 334.221708984375, "critic_loss": 35.395843673706054, "batch_reward": 4.425653034210205, "actor_loss": -335.9874041157384, "actor_target_entropy": -1.0, "actor_entropy": -0.28299937277070936, "alpha_loss": -0.053141266377943176, "alpha_value": 0.1741122291126524, "duration": 156.0459442138672, "step": 18000}
{"episode_reward": 749.6274400037397, "episode": 145.0, "Q1 loss": 16.86722554779053, "Q2 loss": 17.01154941558838, "Mean Target Q": 336.72523168945315, "Mean Q1": 336.7106787109375, "Mean Q2": 336.7093967285156, "critic_loss": 33.878774932861326, "batch_reward": 4.454004875183106, "actor_loss": -338.3347574869792, "actor_target_entropy": -1.0, "actor_entropy": -0.2606758451651013, "alpha_loss": -0.05402142983225603, "alpha_value": 0.1749971120451342, "duration": 150.58033299446106, "step": 18125}
{"episode_reward": 825.0543284692491, "episode": 146.0, "Q1 loss": 17.11686184692383, "Q2 loss": 16.984288856506346, "Mean Target Q": 339.67063916015627, "Mean Q1": 339.66757470703124, "Mean Q2": 339.6690439453125, "critic_loss": 34.10115051269531, "batch_reward": 4.500230815887451, "actor_loss": -341.4045759631741, "actor_target_entropy": -1.0, "actor_entropy": -0.26247278745135955, "alpha_loss": -0.05009965759311472, "alpha_value": 0.17589276601779083, "duration": 152.3816101551056, "step": 18250}
{"episode_reward": 733.6882315070385, "episode": 147.0, "Q1 loss": 17.34736149597168, "Q2 loss": 17.319342277526854, "Mean Target Q": 342.17502465820314, "Mean Q1": 342.17137744140626, "Mean Q2": 342.17010302734377, "critic_loss": 34.66670361328125, "batch_reward": 4.492529640197754, "actor_loss": -343.6702614436074, "actor_target_entropy": -1.0, "actor_entropy": -0.26130499442418414, "alpha_loss": -0.05178822677523371, "alpha_value": 0.17677299889025744, "duration": 161.28366112709045, "step": 18375}
{"episode_reward": 802.3606193972705, "episode": 148.0, "Q1 loss": 16.443150413513184, "Q2 loss": 16.44939375305176, "Mean Target Q": 344.95302221679685, "Mean Q1": 344.9518666992187, "Mean Q2": 344.9529619140625, "critic_loss": 32.89254411315918, "batch_reward": 4.51029532623291, "actor_loss": -346.53776008852066, "actor_target_entropy": -1.0, "actor_entropy": -0.28107969318666765, "alpha_loss": -0.05125769861643353, "alpha_value": 0.17773993453413822, "duration": 147.05619525909424, "step": 18500}
{"episode_reward": 789.6374805225898, "episode": 149.0, "Q1 loss": 18.06712520599365, "Q2 loss": 18.029672966003417, "Mean Target Q": 347.5751213378906, "Mean Q1": 347.55855493164063, "Mean Q2": 347.5589875488281, "critic_loss": 36.09679797363281, "batch_reward": 4.530655769348145, "actor_loss": -349.3915555439298, "actor_target_entropy": -1.0, "actor_entropy": -0.27958675627670593, "alpha_loss": -0.04601060838571617, "alpha_value": 0.17857589328125922, "duration": 159.0083713531494, "step": 18625}
{"episode_reward": 824.241044122226, "episode": 150.0, "Q1 loss": 16.78464119720459, "Q2 loss": 16.672583778381348, "Mean Target Q": 349.67662646484376, "Mean Q1": 349.67700952148436, "Mean Q2": 349.67659619140625, "critic_loss": 33.45722491455078, "batch_reward": 4.525571956634521, "actor_loss": -351.1980310255481, "actor_target_entropy": -1.0, "actor_entropy": -0.23584859481742304, "alpha_loss": -0.04366224808918853, "alpha_value": 0.17939489400637562, "duration": 152.74050450325012, "step": 18750}
{"episode_reward": 757.9404840682798, "episode": 151.0, "Q1 loss": 16.131587532043458, "Q2 loss": 16.291951705932618, "Mean Target Q": 351.9906586914062, "Mean Q1": 351.97370971679686, "Mean Q2": 351.97224462890625, "critic_loss": 32.4235391998291, "batch_reward": 4.536398723602295, "actor_loss": -353.31349787636407, "actor_target_entropy": -1.0, "actor_entropy": -0.2546997990400072, "alpha_loss": -0.04572093959838625, "alpha_value": 0.18020955291706725, "duration": 152.82470536231995, "step": 18875}
{"episode_reward": 739.3868550378778, "episode": 152.0, "Q1 loss": 16.470372123718263, "Q2 loss": 16.50722292327881, "Mean Target Q": 354.1429162597656, "Mean Q1": 354.1455495605469, "Mean Q2": 354.14329663085937, "critic_loss": 32.97759489440918, "batch_reward": 4.515366176605225, "actor_loss": -355.3844195950416, "actor_target_entropy": -1.0, "actor_entropy": -0.2355029436369096, "alpha_loss": -0.04886526001557227, "alpha_value": 0.18109185507498654, "duration": 145.74089312553406, "step": 19000}
{"episode_reward": 660.115544902811, "episode": 153.0, "Q1 loss": 15.535216674804687, "Q2 loss": 15.561144912719726, "Mean Target Q": 357.0373806152344, "Mean Q1": 357.0257287597656, "Mean Q2": 357.02707421875, "critic_loss": 31.096361526489257, "batch_reward": 4.558424091339111, "actor_loss": -358.559819297185, "actor_target_entropy": -1.0, "actor_entropy": -0.2683245135205133, "alpha_loss": -0.045520595053122156, "alpha_value": 0.18200879154522218, "duration": 157.25523138046265, "step": 19125}
{"episode_reward": 819.7835148085427, "episode": 154.0, "Q1 loss": 16.72355384063721, "Q2 loss": 16.649510200500487, "Mean Target Q": 359.7157131347656, "Mean Q1": 359.7049243164063, "Mean Q2": 359.7071271972656, "critic_loss": 33.37306396484375, "batch_reward": 4.575702518463134, "actor_loss": -361.1457106067288, "actor_target_entropy": -1.0, "actor_entropy": -0.2468615972226666, "alpha_loss": -0.04149287335214115, "alpha_value": 0.18286279226773278, "duration": 154.07131457328796, "step": 19250}
{"episode_reward": 835.1730883912824, "episode": 155.0, "Q1 loss": 15.449679870605468, "Q2 loss": 15.331624214172363, "Mean Target Q": 361.6608884277344, "Mean Q1": 361.66297900390623, "Mean Q2": 361.66274291992187, "critic_loss": 30.781303955078126, "batch_reward": 4.589524578094482, "actor_loss": -363.2379697769407, "actor_target_entropy": -1.0, "actor_entropy": -0.25842134228774477, "alpha_loss": -0.042498640908253574, "alpha_value": 0.1836817145528301, "duration": 164.68810391426086, "step": 19375}
{"episode_reward": 805.8158069603081, "episode": 156.0, "Q1 loss": 16.498014366149903, "Q2 loss": 16.613623069763182, "Mean Target Q": 364.0654619140625, "Mean Q1": 364.05826196289064, "Mean Q2": 364.05727465820314, "critic_loss": 33.11163752746582, "batch_reward": 4.599582950592041, "actor_loss": -365.42879658360636, "actor_target_entropy": -1.0, "actor_entropy": -0.2523088097091644, "alpha_loss": -0.04675462769885217, "alpha_value": 0.1845762905239712, "duration": 154.80510592460632, "step": 19500}
{"episode_reward": 818.6272435839389, "episode": 157.0, "Q1 loss": 15.23459001159668, "Q2 loss": 15.25439031982422, "Mean Target Q": 366.52596704101563, "Mean Q1": 366.52094482421876, "Mean Q2": 366.5224348144531, "critic_loss": 30.488980361938477, "batch_reward": 4.612915470123291, "actor_loss": -367.89107501317585, "actor_target_entropy": -1.0, "actor_entropy": -0.259558174108702, "alpha_loss": -0.047588230716803716, "alpha_value": 0.18557559154037123, "duration": 150.62912464141846, "step": 19625}
{"episode_reward": 820.6323292634136, "episode": 158.0, "Q1 loss": 16.387263427734375, "Q2 loss": 16.55616877746582, "Mean Target Q": 368.90688330078126, "Mean Q1": 368.9028115234375, "Mean Q2": 368.8999289550781, "critic_loss": 32.943432250976564, "batch_reward": 4.606722232818604, "actor_loss": -370.5623203400643, "actor_target_entropy": -1.0, "actor_entropy": -0.2335065636904009, "alpha_loss": -0.04067578910279178, "alpha_value": 0.1864731436991853, "duration": 155.15830063819885, "step": 19750}
{"episode_reward": 765.4692533895005, "episode": 159.0, "Q1 loss": 14.9494945602417, "Q2 loss": 14.72978939819336, "Mean Target Q": 371.19238427734376, "Mean Q1": 371.17931884765625, "Mean Q2": 371.18390942382814, "critic_loss": 29.679284042358397, "batch_reward": 4.615818813323974, "actor_loss": -372.65164959619915, "actor_target_entropy": -1.0, "actor_entropy": -0.21209880177463805, "alpha_loss": -0.03725789837716591, "alpha_value": 0.1872785754544294, "duration": 160.37691831588745, "step": 19875}
{"episode_reward": 750.8562244839567, "episode": 160.0, "Q1 loss": 14.53396215057373, "Q2 loss": 14.627660152435302, "Mean Target Q": 373.45700048828127, "Mean Q1": 373.45417211914065, "Mean Q2": 373.4502702636719, "critic_loss": 29.16162222290039, "batch_reward": 4.629190658569336, "actor_loss": -374.57926202589465, "actor_target_entropy": -1.0, "actor_entropy": -0.22971492260694504, "alpha_loss": -0.04207751942017386, "alpha_value": 0.188098142796389, "step": 20000}
{"duration": 184.1436996459961, "step": 20000}
{"episode_reward": 811.5735203897157, "episode": 161.0, "Q1 loss": 14.559444534301758, "Q2 loss": 14.643789489746094, "Mean Target Q": 375.91825854492185, "Mean Q1": 375.9126887207031, "Mean Q2": 375.91505346679685, "critic_loss": 29.203233947753905, "batch_reward": 4.655952442169189, "actor_loss": -377.3986259339348, "actor_target_entropy": -1.0, "actor_entropy": -0.24663646684752571, "alpha_loss": -0.037421756985759926, "alpha_value": 0.1889970001735895, "duration": 198.09816122055054, "step": 20125}
{"episode_reward": 750.9068094677559, "episode": 162.0, "Q1 loss": 15.291148414611817, "Q2 loss": 15.227482711791993, "Mean Target Q": 377.5915202636719, "Mean Q1": 377.5875693359375, "Mean Q2": 377.5868552246094, "critic_loss": 30.51863117980957, "batch_reward": 4.622415904998779, "actor_loss": -379.0051500874181, "actor_target_entropy": -1.0, "actor_entropy": -0.23156221319110162, "alpha_loss": -0.03998714260148605, "alpha_value": 0.18986675463734234, "duration": 161.37029600143433, "step": 20250}
{"episode_reward": 737.4850838602608, "episode": 163.0, "Q1 loss": 14.798950401306152, "Q2 loss": 14.804938323974609, "Mean Target Q": 380.1932687988281, "Mean Q1": 380.1805900878906, "Mean Q2": 380.181287109375, "critic_loss": 29.603888717651365, "batch_reward": 4.6556290473937985, "actor_loss": -381.57551647367933, "actor_target_entropy": -1.0, "actor_entropy": -0.2159738747609986, "alpha_loss": -0.035859054375794674, "alpha_value": 0.19072821052751837, "duration": 158.55166792869568, "step": 20375}
{"episode_reward": 764.6905530511933, "episode": 164.0, "Q1 loss": 14.741179054260254, "Q2 loss": 14.855226013183593, "Mean Target Q": 382.6526708984375, "Mean Q1": 382.6500346679687, "Mean Q2": 382.6504560546875, "critic_loss": 29.59640510559082, "batch_reward": 4.673047084808349, "actor_loss": -384.05554691437754, "actor_target_entropy": -1.0, "actor_entropy": -0.23110095495658536, "alpha_loss": -0.029418345180249984, "alpha_value": 0.19144557592829356, "duration": 163.07651829719543, "step": 20500}
{"episode_reward": 816.8744678689865, "episode": 165.0, "Q1 loss": 15.151475425720214, "Q2 loss": 15.166103805541992, "Mean Target Q": 384.4457954101562, "Mean Q1": 384.4437741699219, "Mean Q2": 384.44352709960935, "critic_loss": 30.317579360961915, "batch_reward": 4.675365177154541, "actor_loss": -385.59042164636037, "actor_target_entropy": -1.0, "actor_entropy": -0.23514183480588216, "alpha_loss": -0.03578377332878373, "alpha_value": 0.19218069946458077, "duration": 154.83769869804382, "step": 20625}
{"episode_reward": 831.3346732035175, "episode": 166.0, "Q1 loss": 14.705759048461914, "Q2 loss": 14.61045278930664, "Mean Target Q": 387.4336799316406, "Mean Q1": 387.42549780273436, "Mean Q2": 387.4244929199219, "critic_loss": 29.31621186065674, "batch_reward": 4.717137981414795, "actor_loss": -388.73279103925154, "actor_target_entropy": -1.0, "actor_entropy": -0.23715211655343732, "alpha_loss": -0.03512106050977543, "alpha_value": 0.19307265494067852, "duration": 164.23316359519958, "step": 20750}
{"episode_reward": 754.9888979827633, "episode": 167.0, "Q1 loss": 13.594347743988036, "Q2 loss": 13.63077431869507, "Mean Target Q": 389.099994140625, "Mean Q1": 389.09716064453124, "Mean Q2": 389.0967712402344, "critic_loss": 27.225122039794922, "batch_reward": 4.7050596084594725, "actor_loss": -390.26648288302954, "actor_target_entropy": -1.0, "actor_entropy": -0.2370795760126341, "alpha_loss": -0.034754101423517106, "alpha_value": 0.19390375834081502, "duration": 166.4437952041626, "step": 20875}
{"episode_reward": 834.4222986270046, "episode": 168.0, "Q1 loss": 13.957224159240722, "Q2 loss": 14.147547985076905, "Mean Target Q": 391.30232177734376, "Mean Q1": 391.30158935546876, "Mean Q2": 391.30157983398436, "critic_loss": 28.10477215576172, "batch_reward": 4.714169021606446, "actor_loss": -392.3183830015121, "actor_target_entropy": -1.0, "actor_entropy": -0.19145829843417292, "alpha_loss": -0.033512203849010894, "alpha_value": 0.19477904039801677, "duration": 167.05612683296204, "step": 21000}
{"episode_reward": 703.8791762302814, "episode": 169.0, "Q1 loss": 16.755581382751465, "Q2 loss": 16.44534410095215, "Mean Target Q": 393.46512768554686, "Mean Q1": 393.44967797851564, "Mean Q2": 393.44939306640623, "critic_loss": 33.200925415039066, "batch_reward": 4.71083012008667, "actor_loss": -394.5809980119978, "actor_target_entropy": -1.0, "actor_entropy": -0.21728491381047263, "alpha_loss": -0.031242335174557944, "alpha_value": 0.19557502229898363, "duration": 156.47157955169678, "step": 21125}
{"episode_reward": 827.3254563137793, "episode": 170.0, "Q1 loss": 15.58813688659668, "Q2 loss": 15.59008568572998, "Mean Target Q": 395.4847419433594, "Mean Q1": 395.4818601074219, "Mean Q2": 395.4797236328125, "critic_loss": 31.178222595214844, "batch_reward": 4.725412574768066, "actor_loss": -396.73956052718626, "actor_target_entropy": -1.0, "actor_entropy": -0.19840624435774742, "alpha_loss": -0.029501607164650435, "alpha_value": 0.19637842802092817, "duration": 162.5333514213562, "step": 21250}
{"episode_reward": 760.8359381545193, "episode": 171.0, "Q1 loss": 15.387225944519043, "Q2 loss": 15.390834480285644, "Mean Target Q": 397.36643676757814, "Mean Q1": 397.3607443847656, "Mean Q2": 397.36314477539065, "critic_loss": 30.77806051635742, "batch_reward": 4.729219860076904, "actor_loss": -398.84947664775547, "actor_target_entropy": -1.0, "actor_entropy": -0.2023913435756214, "alpha_loss": -0.02592184621885064, "alpha_value": 0.19710379142856452, "duration": 165.87957119941711, "step": 21375}
{"episode_reward": 769.151366798182, "episode": 172.0, "Q1 loss": 14.727604866027832, "Q2 loss": 14.694411117553711, "Mean Target Q": 399.99912719726564, "Mean Q1": 399.9998759765625, "Mean Q2": 399.999275390625, "critic_loss": 29.42201597595215, "batch_reward": 4.761873016357422, "actor_loss": -401.3261531706779, "actor_target_entropy": -1.0, "actor_entropy": -0.20833168539308733, "alpha_loss": -0.02266933141847051, "alpha_value": 0.19769589339854565, "duration": 165.42400336265564, "step": 21500}
{"episode_reward": 756.1326850707949, "episode": 173.0, "Q1 loss": 14.775477382659911, "Q2 loss": 14.783928291320802, "Mean Target Q": 401.660451171875, "Mean Q1": 401.64682080078126, "Mean Q2": 401.6466701660156, "critic_loss": 29.559405654907227, "batch_reward": 4.743834266662597, "actor_loss": -402.86413719540553, "actor_target_entropy": -1.0, "actor_entropy": -0.2374132765190942, "alpha_loss": -0.02347811380223859, "alpha_value": 0.1983511894853548, "duration": 158.73765540122986, "step": 21625}
{"episode_reward": 762.4177526980105, "episode": 174.0, "Q1 loss": 14.475466827392578, "Q2 loss": 14.439139919281006, "Mean Target Q": 403.81882470703124, "Mean Q1": 403.8136735839844, "Mean Q2": 403.81356372070314, "critic_loss": 28.91460678100586, "batch_reward": 4.7614022102355955, "actor_loss": -405.1728515625, "actor_target_entropy": -1.0, "actor_entropy": -0.23980083484803477, "alpha_loss": -0.026208290462231925, "alpha_value": 0.19909813122128311, "duration": 169.62919807434082, "step": 21750}
{"episode_reward": 697.3565557903656, "episode": 175.0, "Q1 loss": 15.13332430267334, "Q2 loss": 14.965572402954102, "Mean Target Q": 405.66037524414065, "Mean Q1": 405.6609313964844, "Mean Q2": 405.66091870117185, "critic_loss": 30.098896697998047, "batch_reward": 4.765582317352295, "actor_loss": -406.94495839921257, "actor_target_entropy": -1.0, "actor_entropy": -0.20500331101495595, "alpha_loss": -0.02425063428069864, "alpha_value": 0.19985559439463998, "duration": 164.9512209892273, "step": 21875}
{"episode_reward": 772.7507998303679, "episode": 176.0, "Q1 loss": 14.878089073181153, "Q2 loss": 14.875954986572266, "Mean Target Q": 407.42007470703123, "Mean Q1": 407.41694799804685, "Mean Q2": 407.41819580078123, "critic_loss": 29.75404393005371, "batch_reward": 4.75296741104126, "actor_loss": -408.75876740486393, "actor_target_entropy": -1.0, "actor_entropy": -0.20855163470391305, "alpha_loss": -0.02415266080624274, "alpha_value": 0.20041758698273296, "duration": 160.7259805202484, "step": 22000}
{"episode_reward": 828.4096075946447, "episode": 177.0, "Q1 loss": 14.406910675048827, "Q2 loss": 14.374373023986816, "Mean Target Q": 409.86675830078127, "Mean Q1": 409.86099047851565, "Mean Q2": 409.8587280273438, "critic_loss": 28.781283660888672, "batch_reward": 4.783750217437744, "actor_loss": -411.11661202566967, "actor_target_entropy": -1.0, "actor_entropy": -0.21154178075847171, "alpha_loss": -0.017996194668942027, "alpha_value": 0.2011117857376382, "duration": 167.60874271392822, "step": 22125}
{"episode_reward": 770.2369407407471, "episode": 178.0, "Q1 loss": 15.564113655090331, "Q2 loss": 15.661842887878418, "Mean Target Q": 412.00993115234377, "Mean Q1": 412.0092192382813, "Mean Q2": 412.0113420410156, "critic_loss": 31.225956512451173, "batch_reward": 4.797724864959717, "actor_loss": -413.30231303553427, "actor_target_entropy": -1.0, "actor_entropy": -0.18106769986691013, "alpha_loss": -0.0181566103203823, "alpha_value": 0.20165486253949452, "duration": 166.2764253616333, "step": 22250}
{"episode_reward": 826.7175597522742, "episode": 179.0, "Q1 loss": 14.286466835021972, "Q2 loss": 14.221779586791993, "Mean Target Q": 413.9308056640625, "Mean Q1": 413.911671875, "Mean Q2": 413.912056640625, "critic_loss": 28.50824642944336, "batch_reward": 4.8091815605163575, "actor_loss": -415.2917989095052, "actor_target_entropy": -1.0, "actor_entropy": -0.19800559750625066, "alpha_loss": -0.017384614111737362, "alpha_value": 0.20225516446338093, "duration": 157.96036028862, "step": 22375}
{"episode_reward": 773.186958232919, "episode": 180.0, "Q1 loss": 14.620552352905273, "Q2 loss": 14.634192085266113, "Mean Target Q": 415.88641235351565, "Mean Q1": 415.8915363769531, "Mean Q2": 415.88928955078126, "critic_loss": 29.25474464416504, "batch_reward": 4.809947280883789, "actor_loss": -416.6639571651336, "actor_target_entropy": -1.0, "actor_entropy": -0.18287393546873523, "alpha_loss": -0.019220735370782355, "alpha_value": 0.20279655007062622, "duration": 157.9471435546875, "step": 22500}
{"episode_reward": 759.2617716919714, "episode": 181.0, "Q1 loss": 14.205083137512206, "Q2 loss": 14.036749053955079, "Mean Target Q": 417.94321850585936, "Mean Q1": 417.93735888671876, "Mean Q2": 417.9372888183594, "critic_loss": 28.241832191467285, "batch_reward": 4.817778186798096, "actor_loss": -419.0357486785404, "actor_target_entropy": -1.0, "actor_entropy": -0.20725245691008037, "alpha_loss": -0.01423303317648196, "alpha_value": 0.20332279374229048, "duration": 164.575115442276, "step": 22625}
{"episode_reward": 828.9607493809982, "episode": 182.0, "Q1 loss": 13.372434478759766, "Q2 loss": 13.31257894897461, "Mean Target Q": 419.50364819335937, "Mean Q1": 419.4899287109375, "Mean Q2": 419.4902399902344, "critic_loss": 26.685013465881347, "batch_reward": 4.8108110466003415, "actor_loss": -421.05855289582286, "actor_target_entropy": -1.0, "actor_entropy": -0.19798882888449776, "alpha_loss": -0.010251098729279493, "alpha_value": 0.20386594892388496, "duration": 162.276371717453, "step": 22750}
{"episode_reward": 832.2785598286644, "episode": 183.0, "Q1 loss": 13.760651306152344, "Q2 loss": 13.940207862854004, "Mean Target Q": 421.72170336914064, "Mean Q1": 421.72145068359373, "Mean Q2": 421.72288793945313, "critic_loss": 27.700859237670898, "batch_reward": 4.841640167236328, "actor_loss": -422.91492764911953, "actor_target_entropy": -1.0, "actor_entropy": -0.20527612808204831, "alpha_loss": -0.01307749266122719, "alpha_value": 0.20420680691043752, "duration": 159.98588943481445, "step": 22875}
{"episode_reward": 778.5764295887102, "episode": 184.0, "Q1 loss": 14.393586769104004, "Q2 loss": 14.316477085113526, "Mean Target Q": 423.60435302734373, "Mean Q1": 423.6019494628906, "Mean Q2": 423.6032971191406, "critic_loss": 28.710063919067384, "batch_reward": 4.836715141296387, "actor_loss": -424.5676574707031, "actor_target_entropy": -1.0, "actor_entropy": -0.22047437090546854, "alpha_loss": -0.016793952387337004, "alpha_value": 0.20467725189655586, "duration": 147.64959263801575, "step": 23000}
{"episode_reward": 819.204521683, "episode": 185.0, "Q1 loss": 14.215257823944091, "Q2 loss": 14.156550819396973, "Mean Target Q": 425.87573608398435, "Mean Q1": 425.86403295898435, "Mean Q2": 425.8592473144531, "critic_loss": 28.371808616638184, "batch_reward": 4.8584424438476566, "actor_loss": -427.12263852074034, "actor_target_entropy": -1.0, "actor_entropy": -0.2197297600999711, "alpha_loss": -0.01885854182321401, "alpha_value": 0.2053269018087308, "duration": 158.09112572669983, "step": 23125}
{"episode_reward": 829.5422474388771, "episode": 186.0, "Q1 loss": 14.276011734008788, "Q2 loss": 14.288544219970703, "Mean Target Q": 427.52761181640625, "Mean Q1": 427.53497875976564, "Mean Q2": 427.5344714355469, "critic_loss": 28.564555908203126, "batch_reward": 4.859669826507568, "actor_loss": -428.45059548654865, "actor_target_entropy": -1.0, "actor_entropy": -0.21186770727076837, "alpha_loss": -0.018174420445105963, "alpha_value": 0.20604861837866853, "duration": 153.57204818725586, "step": 23250}
{"episode_reward": 761.8730944039578, "episode": 187.0, "Q1 loss": 15.364281288146973, "Q2 loss": 15.279458847045898, "Mean Target Q": 429.4102412109375, "Mean Q1": 429.3923288574219, "Mean Q2": 429.39492041015626, "critic_loss": 30.6437400970459, "batch_reward": 4.867368495941162, "actor_loss": -430.58780343191967, "actor_target_entropy": -1.0, "actor_entropy": -0.17308143353355782, "alpha_loss": -0.01507551524980319, "alpha_value": 0.20664782521114944, "duration": 153.12007999420166, "step": 23375}
{"episode_reward": 829.4256527024265, "episode": 188.0, "Q1 loss": 15.60516625213623, "Q2 loss": 15.698456024169921, "Mean Target Q": 431.41145263671876, "Mean Q1": 431.4105485839844, "Mean Q2": 431.41190087890624, "critic_loss": 31.303622314453126, "batch_reward": 4.878991512298584, "actor_loss": -432.4787390924269, "actor_target_entropy": -1.0, "actor_entropy": -0.20878589129255665, "alpha_loss": -0.01477475772093561, "alpha_value": 0.20720840033900656, "duration": 153.07204413414001, "step": 23500}
{"episode_reward": 762.7198712771564, "episode": 189.0, "Q1 loss": 14.831612533569336, "Q2 loss": 14.817116096496582, "Mean Target Q": 433.15744140625, "Mean Q1": 433.153580078125, "Mean Q2": 433.1497648925781, "critic_loss": 29.648728744506837, "batch_reward": 4.880355194091797, "actor_loss": -434.14658900669644, "actor_target_entropy": -1.0, "actor_entropy": -0.1983346055660929, "alpha_loss": -0.016727054136849585, "alpha_value": 0.20782813874933856, "duration": 164.06003069877625, "step": 23625}
{"episode_reward": 769.5715227037558, "episode": 190.0, "Q1 loss": 14.970942672729493, "Q2 loss": 14.863702323913575, "Mean Target Q": 435.3776943359375, "Mean Q1": 435.3765173339844, "Mean Q2": 435.37822607421873, "critic_loss": 29.834644927978516, "batch_reward": 4.91213345336914, "actor_loss": -436.8452847388483, "actor_target_entropy": -1.0, "actor_entropy": -0.23230412506288098, "alpha_loss": -0.013640683790248248, "alpha_value": 0.2084681345908287, "duration": 155.32906985282898, "step": 23750}
{"episode_reward": 775.3055382711701, "episode": 191.0, "Q1 loss": 14.89534295272827, "Q2 loss": 14.867384536743163, "Mean Target Q": 437.3668579101562, "Mean Q1": 437.36803442382814, "Mean Q2": 437.36972265625, "critic_loss": 29.76272737121582, "batch_reward": 4.913715721130371, "actor_loss": -438.3025440034412, "actor_target_entropy": -1.0, "actor_entropy": -0.22354941495827266, "alpha_loss": -0.016782733316104564, "alpha_value": 0.20909451430250448, "duration": 167.0364532470703, "step": 23875}
{"episode_reward": 764.0054686289648, "episode": 192.0, "Q1 loss": 15.233233390808106, "Q2 loss": 15.23198764038086, "Mean Target Q": 439.0067421875, "Mean Q1": 438.9919055175781, "Mean Q2": 438.9910583496094, "critic_loss": 30.46522091674805, "batch_reward": 4.914367286682129, "actor_loss": -440.2166314894153, "actor_target_entropy": -1.0, "actor_entropy": -0.20874924693376787, "alpha_loss": -0.015152305574907411, "alpha_value": 0.20973916824581532, "duration": 162.5908317565918, "step": 24000}
{"episode_reward": 831.880710915705, "episode": 193.0, "Q1 loss": 15.511622344970704, "Q2 loss": 15.404589668273927, "Mean Target Q": 441.07481469726565, "Mean Q1": 441.0755344238281, "Mean Q2": 441.075533203125, "critic_loss": 30.91621206665039, "batch_reward": 4.931400672912598, "actor_loss": -441.80020383804566, "actor_target_entropy": -1.0, "actor_entropy": -0.198604763382011, "alpha_loss": -0.007582743105197709, "alpha_value": 0.21028946511784202, "duration": 158.94687151908875, "step": 24125}
{"episode_reward": 833.7436684712209, "episode": 194.0, "Q1 loss": 14.150730491638184, "Q2 loss": 13.91671535873413, "Mean Target Q": 442.25486450195314, "Mean Q1": 442.2457966308594, "Mean Q2": 442.2448903808594, "critic_loss": 28.06744595336914, "batch_reward": 4.897874820709228, "actor_loss": -443.4024397327054, "actor_target_entropy": -1.0, "actor_entropy": -0.21447509226779785, "alpha_loss": -0.005571472942979346, "alpha_value": 0.21058943659886847, "duration": 155.09281587600708, "step": 24250}
{"episode_reward": 742.90388958983, "episode": 195.0, "Q1 loss": 15.637869987487793, "Q2 loss": 15.610472412109376, "Mean Target Q": 444.0395239257812, "Mean Q1": 444.0417197265625, "Mean Q2": 444.0425168457031, "critic_loss": 31.24834245300293, "batch_reward": 4.913289230346679, "actor_loss": -444.97403826032365, "actor_target_entropy": -1.0, "actor_entropy": -0.18247113968171771, "alpha_loss": -0.0022391726776573155, "alpha_value": 0.21067055671015206, "duration": 158.38695907592773, "step": 24375}
{"episode_reward": 770.1233744899342, "episode": 196.0, "Q1 loss": 14.186597763061524, "Q2 loss": 14.275414302825927, "Mean Target Q": 446.0420612792969, "Mean Q1": 446.02624609375, "Mean Q2": 446.02635278320315, "critic_loss": 28.462012115478515, "batch_reward": 4.930295597076416, "actor_loss": -447.3951519381615, "actor_target_entropy": -1.0, "actor_entropy": -0.18104644480251497, "alpha_loss": -0.0053353478114361004, "alpha_value": 0.21081764249321794, "duration": 146.99559044837952, "step": 24500}
{"episode_reward": 834.8809349516966, "episode": 197.0, "Q1 loss": 13.128939540863037, "Q2 loss": 13.041025989532471, "Mean Target Q": 448.48253100585936, "Mean Q1": 448.4858229980469, "Mean Q2": 448.4873991699219, "critic_loss": 26.169965614318848, "batch_reward": 4.95936861038208, "actor_loss": -449.83006165519595, "actor_target_entropy": -1.0, "actor_entropy": -0.15688442817283055, "alpha_loss": 0.004939914100788652, "alpha_value": 0.21077458983514694, "duration": 148.789803981781, "step": 24625}
{"episode_reward": 823.187961394966, "episode": 198.0, "Q1 loss": 13.982237773895264, "Q2 loss": 13.992384159088134, "Mean Target Q": 450.4142626953125, "Mean Q1": 450.4137646484375, "Mean Q2": 450.4106162109375, "critic_loss": 27.974621994018555, "batch_reward": 4.976030002593994, "actor_loss": -451.6567112092049, "actor_target_entropy": -1.0, "actor_entropy": -0.19225986037523515, "alpha_loss": 0.0001266596298063955, "alpha_value": 0.21070366370126214, "duration": 162.2274944782257, "step": 24750}
{"episode_reward": 768.5350930294046, "episode": 199.0, "Q1 loss": 14.48033821105957, "Q2 loss": 14.363376041412353, "Mean Target Q": 451.98095556640624, "Mean Q1": 451.9602155761719, "Mean Q2": 451.9622385253906, "critic_loss": 28.84371421813965, "batch_reward": 4.967683917999268, "actor_loss": -453.00067623077877, "actor_target_entropy": -1.0, "actor_entropy": -0.17523272628230707, "alpha_loss": 0.004347882457151417, "alpha_value": 0.2106831933377681, "duration": 147.01990699768066, "step": 24875}
{"episode_reward": 826.3686216176401, "episode": 200.0, "Q1 loss": 14.632818458557129, "Q2 loss": 14.445639045715332, "Mean Target Q": 453.37249609375, "Mean Q1": 453.38349609375, "Mean Q2": 453.3825988769531, "critic_loss": 29.078457481384277, "batch_reward": 4.95494860458374, "actor_loss": -454.2885348412298, "actor_target_entropy": -1.0, "actor_entropy": -0.14303424059142988, "alpha_loss": -0.001141187137803964, "alpha_value": 0.2105353626726464, "step": 25000}
{"duration": 145.09514808654785, "step": 25000}
{"episode_reward": 769.1314203277104, "episode": 201.0, "Q1 loss": 13.836688537597656, "Q2 loss": 13.800553485870362, "Mean Target Q": 455.51047534179685, "Mean Q1": 455.49869116210937, "Mean Q2": 455.50229077148435, "critic_loss": 27.637242050170897, "batch_reward": 4.977382225036621, "actor_loss": -456.85784330822173, "actor_target_entropy": -1.0, "actor_entropy": -0.15101209696796206, "alpha_loss": 0.004410030604857538, "alpha_value": 0.21042520037959972, "duration": 135.23725700378418, "step": 25125}
{"episode_reward": 762.8432684541121, "episode": 202.0, "Q1 loss": 13.093485877990723, "Q2 loss": 13.052863361358643, "Mean Target Q": 456.9112958984375, "Mean Q1": 456.90728735351564, "Mean Q2": 456.9034694824219, "critic_loss": 26.146349174499512, "batch_reward": 4.969053417205811, "actor_loss": -457.9614026469569, "actor_target_entropy": -1.0, "actor_entropy": -0.18798368988979247, "alpha_loss": -0.005388636194590119, "alpha_value": 0.21046950619909638, "duration": 129.03303790092468, "step": 25250}
{"episode_reward": 765.2738308696901, "episode": 203.0, "Q1 loss": 14.418505779266358, "Q2 loss": 14.435566772460938, "Mean Target Q": 458.78521826171874, "Mean Q1": 458.7822160644531, "Mean Q2": 458.78425708007813, "critic_loss": 28.854072326660155, "batch_reward": 4.986534854888916, "actor_loss": -459.73895651196676, "actor_target_entropy": -1.0, "actor_entropy": -0.18840114086393325, "alpha_loss": -0.0019163016917272692, "alpha_value": 0.21069956844702994, "duration": 144.11939001083374, "step": 25375}
{"episode_reward": 758.4293354209368, "episode": 204.0, "Q1 loss": 14.635839427947998, "Q2 loss": 14.633137573242188, "Mean Target Q": 460.62155859375, "Mean Q1": 460.6197683105469, "Mean Q2": 460.62050341796873, "critic_loss": 29.268977020263673, "batch_reward": 5.003858982086181, "actor_loss": -462.03439577164187, "actor_target_entropy": -1.0, "actor_entropy": -0.19312988528080524, "alpha_loss": -0.00012772994288693992, "alpha_value": 0.21072970614873754, "duration": 140.13724660873413, "step": 25500}
{"episode_reward": 749.6599781154255, "episode": 205.0, "Q1 loss": 14.025379238128663, "Q2 loss": 13.90281028366089, "Mean Target Q": 462.29026611328123, "Mean Q1": 462.28860424804685, "Mean Q2": 462.28567407226564, "critic_loss": 27.928189529418944, "batch_reward": 5.008241920471192, "actor_loss": -463.39927164713544, "actor_target_entropy": -1.0, "actor_entropy": -0.20252647132627546, "alpha_loss": -0.0038192621986603455, "alpha_value": 0.21086972929875963, "duration": 140.02805280685425, "step": 25625}
{"episode_reward": 764.8884402126674, "episode": 206.0, "Q1 loss": 14.24623048400879, "Q2 loss": 14.052386756896972, "Mean Target Q": 463.66940576171874, "Mean Q1": 463.66299243164065, "Mean Q2": 463.6648745117187, "critic_loss": 28.298617294311523, "batch_reward": 4.983796535491943, "actor_loss": -464.76589079826107, "actor_target_entropy": -1.0, "actor_entropy": -0.1831777254419942, "alpha_loss": -0.0011035929877130735, "alpha_value": 0.21089758850128043, "duration": 140.3800392150879, "step": 25750}
{"episode_reward": 763.4629174493349, "episode": 207.0, "Q1 loss": 13.368767456054687, "Q2 loss": 13.327481853485107, "Mean Target Q": 465.66868310546874, "Mean Q1": 465.6628405761719, "Mean Q2": 465.6607770996094, "critic_loss": 26.696249374389648, "batch_reward": 5.015642204284668, "actor_loss": -466.75371926928324, "actor_target_entropy": -1.0, "actor_entropy": -0.19568026042173778, "alpha_loss": 0.003520575586691617, "alpha_value": 0.21091127826947884, "duration": 144.23773884773254, "step": 25875}
{"episode_reward": 815.8520730693739, "episode": 208.0, "Q1 loss": 14.600940509796143, "Q2 loss": 14.543514560699462, "Mean Target Q": 466.729765625, "Mean Q1": 466.724732421875, "Mean Q2": 466.7263244628906, "critic_loss": 29.144455047607423, "batch_reward": 4.990379211425782, "actor_loss": -468.2177035424017, "actor_target_entropy": -1.0, "actor_entropy": -0.17630220889564482, "alpha_loss": -0.0007160553828843178, "alpha_value": 0.21084842563540962, "duration": 137.6724030971527, "step": 26000}
{"episode_reward": 828.7035427349226, "episode": 209.0, "Q1 loss": 13.611045349121094, "Q2 loss": 13.589697849273682, "Mean Target Q": 468.7989987792969, "Mean Q1": 468.8025888671875, "Mean Q2": 468.8008596191406, "critic_loss": 27.20074317932129, "batch_reward": 5.018907997131348, "actor_loss": -470.11332339332216, "actor_target_entropy": -1.0, "actor_entropy": -0.23879677743192704, "alpha_loss": -0.007577208979498772, "alpha_value": 0.21106479895571034, "duration": 141.5052797794342, "step": 26125}
{"episode_reward": 726.7723101686529, "episode": 210.0, "Q1 loss": 13.279912330627441, "Q2 loss": 13.310408016204834, "Mean Target Q": 470.48804077148435, "Mean Q1": 470.4779538574219, "Mean Q2": 470.47650659179686, "critic_loss": 26.59032032775879, "batch_reward": 5.015303272247315, "actor_loss": -471.6399462299962, "actor_target_entropy": -1.0, "actor_entropy": -0.23555573280299863, "alpha_loss": -0.00650949327410349, "alpha_value": 0.21143437534838158, "duration": 139.68496680259705, "step": 26250}
{"episode_reward": 747.1061059968523, "episode": 211.0, "Q1 loss": 13.354060062408447, "Q2 loss": 13.405796264648437, "Mean Target Q": 472.2269299316406, "Mean Q1": 472.22266918945314, "Mean Q2": 472.2247795410156, "critic_loss": 26.75985649108887, "batch_reward": 5.0432035293579105, "actor_loss": -473.31326536148316, "actor_target_entropy": -1.0, "actor_entropy": -0.21554925919525206, "alpha_loss": -0.0019840464635293873, "alpha_value": 0.21182310476669933, "duration": 138.66213655471802, "step": 26375}
{"episode_reward": 825.3424923910535, "episode": 212.0, "Q1 loss": 14.48301750946045, "Q2 loss": 14.280849308013916, "Mean Target Q": 473.87174951171875, "Mean Q1": 473.86883569335936, "Mean Q2": 473.8692150878906, "critic_loss": 28.763866821289064, "batch_reward": 5.030833595275879, "actor_loss": -474.82540696667087, "actor_target_entropy": -1.0, "actor_entropy": -0.20740994594750867, "alpha_loss": -0.0023294663011667227, "alpha_value": 0.21189029816232907, "duration": 150.299880027771, "step": 26500}
{"episode_reward": 816.8213927091089, "episode": 213.0, "Q1 loss": 12.960679885864257, "Q2 loss": 12.868291282653809, "Mean Target Q": 475.54767431640624, "Mean Q1": 475.54171728515627, "Mean Q2": 475.54099072265626, "critic_loss": 25.82897122192383, "batch_reward": 5.041314468383789, "actor_loss": -476.5436740451389, "actor_target_entropy": -1.0, "actor_entropy": -0.18956042175728177, "alpha_loss": -0.006039585574485716, "alpha_value": 0.21236076623276642, "duration": 143.30477786064148, "step": 26625}
{"episode_reward": 764.8138827389938, "episode": 214.0, "Q1 loss": 14.114666481018066, "Q2 loss": 13.940441184997558, "Mean Target Q": 477.33296240234375, "Mean Q1": 477.3213942871094, "Mean Q2": 477.32370068359376, "critic_loss": 28.055107681274414, "batch_reward": 5.0512133331298825, "actor_loss": -478.5191665157195, "actor_target_entropy": -1.0, "actor_entropy": -0.20568020930213313, "alpha_loss": -0.006597110674896788, "alpha_value": 0.21255507666907214, "duration": 146.9244077205658, "step": 26750}
{"episode_reward": 768.5945767051331, "episode": 215.0, "Q1 loss": 13.934786113739014, "Q2 loss": 13.929441230773925, "Mean Target Q": 478.928333984375, "Mean Q1": 478.9339189453125, "Mean Q2": 478.9307377929687, "critic_loss": 27.864227310180663, "batch_reward": 5.057710906982422, "actor_loss": -480.4407978360615, "actor_target_entropy": -1.0, "actor_entropy": -0.23995602603942628, "alpha_loss": -0.006600466074555048, "alpha_value": 0.2129645812124111, "duration": 145.21366429328918, "step": 26875}
{"episode_reward": 822.2628698814498, "episode": 216.0, "Q1 loss": 14.024150909423827, "Q2 loss": 14.085302772521972, "Mean Target Q": 480.3995632324219, "Mean Q1": 480.39360034179685, "Mean Q2": 480.3962131347656, "critic_loss": 28.10945357513428, "batch_reward": 5.057438159942627, "actor_loss": -481.7858148390247, "actor_target_entropy": -1.0, "actor_entropy": -0.2068472841093617, "alpha_loss": -0.0008299332412500535, "alpha_value": 0.21335522788262007, "duration": 140.0265383720398, "step": 27000}
{"episode_reward": 798.4513208340263, "episode": 217.0, "Q1 loss": 13.448451263427735, "Q2 loss": 13.454075458526612, "Mean Target Q": 481.9518127441406, "Mean Q1": 481.9514206542969, "Mean Q2": 481.9500451660156, "critic_loss": 26.90252668762207, "batch_reward": 5.062584197998047, "actor_loss": -483.11817956349205, "actor_target_entropy": -1.0, "actor_entropy": -0.18851538002490997, "alpha_loss": 0.0035444392512242, "alpha_value": 0.21323105262735953, "duration": 139.71462488174438, "step": 27125}
{"episode_reward": 838.4123932604521, "episode": 218.0, "Q1 loss": 13.721858589172363, "Q2 loss": 13.799268913269042, "Mean Target Q": 483.8509465332031, "Mean Q1": 483.8403537597656, "Mean Q2": 483.8379326171875, "critic_loss": 27.52112747192383, "batch_reward": 5.0828894424438475, "actor_loss": -485.00747631442164, "actor_target_entropy": -1.0, "actor_entropy": -0.18238327243635732, "alpha_loss": 0.002883058525772104, "alpha_value": 0.21306408297545232, "duration": 134.17248845100403, "step": 27250}
{"episode_reward": 828.9070554359475, "episode": 219.0, "Q1 loss": 13.659145530700684, "Q2 loss": 13.541788249969482, "Mean Target Q": 484.999580078125, "Mean Q1": 484.99253125, "Mean Q2": 484.99504516601564, "critic_loss": 27.200933860778807, "batch_reward": 5.078420257568359, "actor_loss": -485.97932991148934, "actor_target_entropy": -1.0, "actor_entropy": -0.19439847317952957, "alpha_loss": -0.0011101168088821901, "alpha_value": 0.21290628102390596, "duration": 136.33727264404297, "step": 27375}
{"episode_reward": 771.535644396473, "episode": 220.0, "Q1 loss": 13.720759914398194, "Q2 loss": 13.746965408325195, "Mean Target Q": 487.00576196289063, "Mean Q1": 487.0079130859375, "Mean Q2": 487.00623046875, "critic_loss": 27.467725341796875, "batch_reward": 5.096966526031494, "actor_loss": -488.07618467269407, "actor_target_entropy": -1.0, "actor_entropy": -0.21182687796892657, "alpha_loss": -0.0022648746399359116, "alpha_value": 0.21297728503964017, "duration": 136.4606328010559, "step": 27500}
{"episode_reward": 827.2319909941858, "episode": 221.0, "Q1 loss": 14.611916843414306, "Q2 loss": 14.527763725280762, "Mean Target Q": 488.1617470703125, "Mean Q1": 488.15189477539064, "Mean Q2": 488.15260205078124, "critic_loss": 29.139680557250976, "batch_reward": 5.086541362762452, "actor_loss": -488.9805593339224, "actor_target_entropy": -1.0, "actor_entropy": -0.2083551890793301, "alpha_loss": -0.0040120572601962425, "alpha_value": 0.21320525110648103, "duration": 139.1453356742859, "step": 27625}
{"episode_reward": 844.775983617121, "episode": 222.0, "Q1 loss": 13.320031295776367, "Q2 loss": 13.494246162414552, "Mean Target Q": 489.635865234375, "Mean Q1": 489.63960864257814, "Mean Q2": 489.6372861328125, "critic_loss": 26.814277389526367, "batch_reward": 5.082826976776123, "actor_loss": -490.89969905730214, "actor_target_entropy": -1.0, "actor_entropy": -0.22784059134221846, "alpha_loss": -0.00259965559047076, "alpha_value": 0.21347583625221067, "duration": 147.41347432136536, "step": 27750}
{"episode_reward": 778.7092315959798, "episode": 223.0, "Q1 loss": 13.185994186401366, "Q2 loss": 13.294894222259522, "Mean Target Q": 491.6293837890625, "Mean Q1": 491.624849609375, "Mean Q2": 491.62663842773435, "critic_loss": 26.480888442993162, "batch_reward": 5.115275352478028, "actor_loss": -492.2911299448165, "actor_target_entropy": -1.0, "actor_entropy": -0.21483962639929757, "alpha_loss": 0.004561897382021896, "alpha_value": 0.2134314265751698, "duration": 141.38531637191772, "step": 27875}
{"episode_reward": 768.463376925416, "episode": 224.0, "Q1 loss": 12.472211151123046, "Q2 loss": 12.338007202148438, "Mean Target Q": 493.1832265625, "Mean Q1": 493.174828125, "Mean Q2": 493.1773356933594, "critic_loss": 24.81021839904785, "batch_reward": 5.114758075714112, "actor_loss": -494.04237168835056, "actor_target_entropy": -1.0, "actor_entropy": -0.17435134601809324, "alpha_loss": 0.004846126603473338, "alpha_value": 0.21302765801003273, "duration": 135.03839111328125, "step": 28000}
{"episode_reward": 825.5845873313075, "episode": 225.0, "Q1 loss": 14.016969360351563, "Q2 loss": 14.108092628479003, "Mean Target Q": 494.58185791015626, "Mean Q1": 494.5843798828125, "Mean Q2": 494.58445458984374, "critic_loss": 28.125061996459962, "batch_reward": 5.12368330001831, "actor_loss": -495.2470562647259, "actor_target_entropy": -1.0, "actor_entropy": -0.1868091289486204, "alpha_loss": 0.004077595787026757, "alpha_value": 0.21278073309227571, "duration": 138.19939708709717, "step": 28125}
{"episode_reward": 824.9416388189115, "episode": 226.0, "Q1 loss": 13.538436447143555, "Q2 loss": 13.4710454788208, "Mean Target Q": 496.3749365234375, "Mean Q1": 496.3648017578125, "Mean Q2": 496.3632819824219, "critic_loss": 27.00948194885254, "batch_reward": 5.138430484771728, "actor_loss": -497.3438745314075, "actor_target_entropy": -1.0, "actor_entropy": -0.2032441005351082, "alpha_loss": 0.003378004665606685, "alpha_value": 0.2123982261204188, "duration": 144.81950426101685, "step": 28250}
{"episode_reward": 812.6246107089745, "episode": 227.0, "Q1 loss": 13.73176487350464, "Q2 loss": 13.868053813934326, "Mean Target Q": 497.7612297363281, "Mean Q1": 497.757228515625, "Mean Q2": 497.75470361328127, "critic_loss": 27.59981871032715, "batch_reward": 5.132381450653076, "actor_loss": -498.5086950877356, "actor_target_entropy": -1.0, "actor_entropy": -0.16868078957001367, "alpha_loss": 0.007831544790875226, "alpha_value": 0.21205193244174292, "duration": 131.70428895950317, "step": 28375}
{"episode_reward": 675.8998617525764, "episode": 228.0, "Q1 loss": 13.98489559173584, "Q2 loss": 14.143348110198975, "Mean Target Q": 498.8039987792969, "Mean Q1": 498.802080078125, "Mean Q2": 498.8048544921875, "critic_loss": 28.12824375152588, "batch_reward": 5.11368998336792, "actor_loss": -499.96406062956777, "actor_target_entropy": -1.0, "actor_entropy": -0.22505741446248947, "alpha_loss": -0.0022703509800316344, "alpha_value": 0.21180980484165807, "duration": 137.14224123954773, "step": 28500}
{"episode_reward": 827.7033049249761, "episode": 229.0, "Q1 loss": 15.073187194824218, "Q2 loss": 14.782809898376465, "Mean Target Q": 500.6637233886719, "Mean Q1": 500.66109741210937, "Mean Q2": 500.66078173828123, "critic_loss": 29.85599708557129, "batch_reward": 5.127128425598144, "actor_loss": -501.8038291325645, "actor_target_entropy": -1.0, "actor_entropy": -0.2149722422399218, "alpha_loss": -0.0009127191659654417, "alpha_value": 0.21193541574805574, "duration": 135.81322717666626, "step": 28625}
{"episode_reward": 770.059234027774, "episode": 230.0, "Q1 loss": 13.271380828857422, "Q2 loss": 13.274497356414795, "Mean Target Q": 502.00348999023436, "Mean Q1": 501.9961684570313, "Mean Q2": 501.9958654785156, "critic_loss": 26.545878158569337, "batch_reward": 5.131029968261719, "actor_loss": -502.67576746786796, "actor_target_entropy": -1.0, "actor_entropy": -0.20394969683501027, "alpha_loss": 0.001199833590597395, "alpha_value": 0.2119519400708512, "duration": 44.37441825866699, "step": 28750}
{"episode_reward": 829.8653175266634, "episode": 231.0, "Q1 loss": 13.297452960968018, "Q2 loss": 13.330075382232666, "Mean Target Q": 503.52414599609375, "Mean Q1": 503.5207312011719, "Mean Q2": 503.5189626464844, "critic_loss": 26.62752838897705, "batch_reward": 5.147602523803711, "actor_loss": -504.5599515400236, "actor_target_entropy": -1.0, "actor_entropy": -0.2318610737011546, "alpha_loss": -0.0029948285322577233, "alpha_value": 0.21201366086702536, "duration": 40.86697697639465, "step": 28875}
{"episode_reward": 839.1422707509593, "episode": 232.0, "Q1 loss": 12.441778423309326, "Q2 loss": 12.270118103027343, "Mean Target Q": 505.0507124023438, "Mean Q1": 505.04423583984374, "Mean Q2": 505.0445244140625, "critic_loss": 24.71189651489258, "batch_reward": 5.15553470993042, "actor_loss": -506.0675339237336, "actor_target_entropy": -1.0, "actor_entropy": -0.21462300179466123, "alpha_loss": 0.00362273319924791, "alpha_value": 0.21183064280355865, "duration": 40.257834672927856, "step": 29000}
{"episode_reward": 836.446860524046, "episode": 233.0, "Q1 loss": 13.337313411712646, "Q2 loss": 13.414194091796874, "Mean Target Q": 506.6167109375, "Mean Q1": 506.61557592773437, "Mean Q2": 506.6163173828125, "critic_loss": 26.75150747680664, "batch_reward": 5.177385478973389, "actor_loss": -507.84496634347096, "actor_target_entropy": -1.0, "actor_entropy": -0.19967053901581538, "alpha_loss": 0.0049656043309600105, "alpha_value": 0.2115719191999022, "duration": 40.290401458740234, "step": 29125}
{"episode_reward": 820.0616260027426, "episode": 234.0, "Q1 loss": 13.283564437866211, "Q2 loss": 13.349775074005127, "Mean Target Q": 507.88388256835935, "Mean Q1": 507.878220703125, "Mean Q2": 507.87796484375, "critic_loss": 26.63333949279785, "batch_reward": 5.16788969039917, "actor_loss": -508.87969576927924, "actor_target_entropy": -1.0, "actor_entropy": -0.2080147331280093, "alpha_loss": -0.0005065429291026967, "alpha_value": 0.2113736094682294, "duration": 123.0989933013916, "step": 29250}
{"episode_reward": 805.0540503645376, "episode": 235.0, "Q1 loss": 12.819512622833251, "Q2 loss": 12.78273985671997, "Mean Target Q": 509.5958239746094, "Mean Q1": 509.5946457519531, "Mean Q2": 509.5962236328125, "critic_loss": 25.60225240325928, "batch_reward": 5.184331958770752, "actor_loss": -510.5997750418527, "actor_target_entropy": -1.0, "actor_entropy": -0.25675912970115267, "alpha_loss": -0.0068488572169804855, "alpha_value": 0.2118261353183759, "duration": 163.47420477867126, "step": 29375}
{"episode_reward": 836.0290019397514, "episode": 236.0, "Q1 loss": 13.445343799591065, "Q2 loss": 13.227939613342285, "Mean Target Q": 510.6599487304687, "Mean Q1": 510.66223315429687, "Mean Q2": 510.66140185546874, "critic_loss": 26.673283363342286, "batch_reward": 5.168673435211182, "actor_loss": -512.1140496038621, "actor_target_entropy": -1.0, "actor_entropy": -0.23491522621723912, "alpha_loss": -0.0035425631194225243, "alpha_value": 0.21218071398102187, "duration": 163.08269882202148, "step": 29500}
{"episode_reward": 636.906973156268, "episode": 237.0, "Q1 loss": 14.082426399230958, "Q2 loss": 14.07963854598999, "Mean Target Q": 512.1378078613282, "Mean Q1": 512.1306442871094, "Mean Q2": 512.128677734375, "critic_loss": 28.162065002441405, "batch_reward": 5.1744402885437015, "actor_loss": -513.0087609669519, "actor_target_entropy": -1.0, "actor_entropy": -0.25707841676379006, "alpha_loss": -0.007723345107118052, "alpha_value": 0.2125564394004391, "duration": 166.30478358268738, "step": 29625}
{"episode_reward": 769.7534990514613, "episode": 238.0, "Q1 loss": 13.128437873840332, "Q2 loss": 13.134821174621582, "Mean Target Q": 513.7272280273437, "Mean Q1": 513.7208745117188, "Mean Q2": 513.7215864257812, "critic_loss": 26.26325902557373, "batch_reward": 5.181072170257568, "actor_loss": -514.4861154863911, "actor_target_entropy": -1.0, "actor_entropy": -0.17990818379386778, "alpha_loss": 0.0005256545020177239, "alpha_value": 0.21284526405720347, "duration": 159.89284825325012, "step": 29750}
{"episode_reward": 832.6842498141962, "episode": 239.0, "Q1 loss": 14.355923374176026, "Q2 loss": 14.368966373443604, "Mean Target Q": 515.3132009277343, "Mean Q1": 515.3053195800782, "Mean Q2": 515.3075942382812, "critic_loss": 28.724889694213868, "batch_reward": 5.2109145698547366, "actor_loss": -516.3827722943018, "actor_target_entropy": -1.0, "actor_entropy": -0.18800134578394512, "alpha_loss": 0.00504849048235291, "alpha_value": 0.21280781003517707, "duration": 149.02673888206482, "step": 29875}
{"episode_reward": 769.5127482712518, "episode": 240.0, "Q1 loss": 13.602500839233398, "Q2 loss": 13.618442649841308, "Mean Target Q": 516.2080251464844, "Mean Q1": 516.2044018554687, "Mean Q2": 516.2027194824219, "critic_loss": 27.22094339752197, "batch_reward": 5.173138954162598, "actor_loss": -516.8284055648312, "actor_target_entropy": -1.0, "actor_entropy": -0.1809904890195016, "alpha_loss": 0.004387813120810015, "alpha_value": 0.21222897554179482, "step": 30000}
{"duration": 169.86954998970032, "step": 30000}
{"episode_reward": 828.9984440855737, "episode": 241.0, "Q1 loss": 13.498173069000243, "Q2 loss": 13.433552127838135, "Mean Target Q": 517.5645485839843, "Mean Q1": 517.562015625, "Mean Q2": 517.5639123535157, "critic_loss": 26.93172523498535, "batch_reward": 5.182218727111817, "actor_loss": -518.3081306578621, "actor_target_entropy": -1.0, "actor_entropy": -0.15673518665726222, "alpha_loss": 0.011505583763152125, "alpha_value": 0.21176230786451075, "duration": 182.8534688949585, "step": 30125}
{"episode_reward": 831.8158206941852, "episode": 242.0, "Q1 loss": 13.334712642669677, "Q2 loss": 13.151190563201904, "Mean Target Q": 518.9503872070312, "Mean Q1": 518.9546459960937, "Mean Q2": 518.9507006835937, "critic_loss": 26.48590315246582, "batch_reward": 5.195407718658447, "actor_loss": -520.099137829196, "actor_target_entropy": -1.0, "actor_entropy": -0.19447803557399782, "alpha_loss": 0.002685308653575879, "alpha_value": 0.2112008753494428, "duration": 160.40488123893738, "step": 30250}
{"episode_reward": 771.6990277704803, "episode": 243.0, "Q1 loss": 12.72557092666626, "Q2 loss": 12.821779235839843, "Mean Target Q": 520.6389033203125, "Mean Q1": 520.6281049804687, "Mean Q2": 520.6309936523437, "critic_loss": 25.547350219726564, "batch_reward": 5.215173164367676, "actor_loss": -521.4339454287574, "actor_target_entropy": -1.0, "actor_entropy": -0.16746701737717976, "alpha_loss": 0.0017742444132824266, "alpha_value": 0.21088946101528017, "duration": 160.56612968444824, "step": 30375}
{"episode_reward": 823.317351323537, "episode": 244.0, "Q1 loss": 12.76230341720581, "Q2 loss": 12.562405979156495, "Mean Target Q": 522.109607421875, "Mean Q1": 522.1096967773437, "Mean Q2": 522.1076958007812, "critic_loss": 25.3247094039917, "batch_reward": 5.229229446411133, "actor_loss": -523.1533429545741, "actor_target_entropy": -1.0, "actor_entropy": -0.17810666573143774, "alpha_loss": 0.006688631455143613, "alpha_value": 0.2104889643925717, "duration": 150.88595366477966, "step": 30500}
{"episode_reward": 832.9642656970067, "episode": 245.0, "Q1 loss": 14.552005020141602, "Q2 loss": 14.472334075927735, "Mean Target Q": 523.1552998046875, "Mean Q1": 523.1455805664062, "Mean Q2": 523.1472939453125, "critic_loss": 29.024339065551757, "batch_reward": 5.214825057983399, "actor_loss": -523.9067411876861, "actor_target_entropy": -1.0, "actor_entropy": -0.1745180743081229, "alpha_loss": 0.007227104985051685, "alpha_value": 0.20989076801318465, "duration": 153.574116230011, "step": 30625}
{"episode_reward": 831.727077809179, "episode": 246.0, "Q1 loss": 12.751509159088135, "Q2 loss": 12.703929306030274, "Mean Target Q": 524.6400395507812, "Mean Q1": 524.6438759765625, "Mean Q2": 524.64300390625, "critic_loss": 25.455438606262206, "batch_reward": 5.227359920501709, "actor_loss": -525.4433869392641, "actor_target_entropy": -1.0, "actor_entropy": -0.20293108590187564, "alpha_loss": 0.004143682516916024, "alpha_value": 0.20944776210723318, "duration": 149.44604182243347, "step": 30750}
{"episode_reward": 827.8054400416504, "episode": 247.0, "Q1 loss": 12.666457176208496, "Q2 loss": 12.710427951812743, "Mean Target Q": 526.1843725585937, "Mean Q1": 526.1805629882813, "Mean Q2": 526.1790444335937, "critic_loss": 25.376885055541994, "batch_reward": 5.236510322570801, "actor_loss": -526.9505285838294, "actor_target_entropy": -1.0, "actor_entropy": -0.2108287059125446, "alpha_loss": 0.005266789317367569, "alpha_value": 0.2091902384640195, "duration": 147.7060513496399, "step": 30875}
{"episode_reward": 837.8057194525987, "episode": 248.0, "Q1 loss": 12.950632656097412, "Q2 loss": 12.99123634338379, "Mean Target Q": 527.3410571289063, "Mean Q1": 527.3353349609375, "Mean Q2": 527.33858203125, "critic_loss": 25.941868980407715, "batch_reward": 5.230543804168701, "actor_loss": -528.3942733272429, "actor_target_entropy": -1.0, "actor_entropy": -0.17616952787483892, "alpha_loss": 0.011358153074979782, "alpha_value": 0.2085207845414081, "duration": 162.20902013778687, "step": 31000}
{"episode_reward": 828.1401554402161, "episode": 249.0, "Q1 loss": 12.260220283508302, "Q2 loss": 12.167280220031738, "Mean Target Q": 528.77621875, "Mean Q1": 528.7717919921874, "Mean Q2": 528.772453125, "critic_loss": 24.427500617980957, "batch_reward": 5.239055267333985, "actor_loss": -529.5829932803199, "actor_target_entropy": -1.0, "actor_entropy": -0.2044507326587798, "alpha_loss": 0.003374656010973489, "alpha_value": 0.20784450516635755, "duration": 147.93814826011658, "step": 31125}
{"episode_reward": 823.1565915312757, "episode": 250.0, "Q1 loss": 12.708698711395265, "Q2 loss": 12.698383182525635, "Mean Target Q": 530.212375, "Mean Q1": 530.2099711914062, "Mean Q2": 530.206365234375, "critic_loss": 25.40708194732666, "batch_reward": 5.253760108947754, "actor_loss": -530.6170683830015, "actor_target_entropy": -1.0, "actor_entropy": -0.21332835165723676, "alpha_loss": 0.006307698478321394, "alpha_value": 0.20746446526969514, "duration": 148.56237697601318, "step": 31250}
{"episode_reward": 830.8392563015033, "episode": 251.0, "Q1 loss": 11.575112728118896, "Q2 loss": 11.687068439483642, "Mean Target Q": 531.6680415039062, "Mean Q1": 531.6642583007813, "Mean Q2": 531.6645473632813, "critic_loss": 23.262181159973146, "batch_reward": 5.26432308959961, "actor_loss": -532.5672704303075, "actor_target_entropy": -1.0, "actor_entropy": -0.20725724030108678, "alpha_loss": 0.007209725999495103, "alpha_value": 0.20708246545113632, "duration": 146.5044708251953, "step": 31375}
{"episode_reward": 828.2408405933817, "episode": 252.0, "Q1 loss": 11.294956184387207, "Q2 loss": 11.158996711730957, "Mean Target Q": 532.6771787109375, "Mean Q1": 532.666974609375, "Mean Q2": 532.6686577148438, "critic_loss": 22.453952888488768, "batch_reward": 5.246809490203858, "actor_loss": -534.1081159037929, "actor_target_entropy": -1.0, "actor_entropy": -0.20881982195761897, "alpha_loss": 0.008110613197899394, "alpha_value": 0.20644852801738092, "duration": 157.14922976493835, "step": 31500}
{"episode_reward": 820.8408774008944, "episode": 253.0, "Q1 loss": 12.250373405456543, "Q2 loss": 12.2093857421875, "Mean Target Q": 534.1796079101563, "Mean Q1": 534.1801010742188, "Mean Q2": 534.1797895507813, "critic_loss": 24.459759086608887, "batch_reward": 5.2795111999511715, "actor_loss": -535.1220867823041, "actor_target_entropy": -1.0, "actor_entropy": -0.20216588179270426, "alpha_loss": 0.0023378708274177616, "alpha_value": 0.20589337087799278, "duration": 158.2826828956604, "step": 31625}
{"episode_reward": 769.2517097978111, "episode": 254.0, "Q1 loss": 11.458666893005372, "Q2 loss": 11.327188194274902, "Mean Target Q": 534.9747270507812, "Mean Q1": 534.9714033203124, "Mean Q2": 534.97262890625, "critic_loss": 22.785855102539063, "batch_reward": 5.252853355407715, "actor_loss": -535.8566047914567, "actor_target_entropy": -1.0, "actor_entropy": -0.214082162947424, "alpha_loss": -0.0016960257048448247, "alpha_value": 0.20594656707134004, "duration": 153.61691880226135, "step": 31750}
{"episode_reward": 842.7039874525402, "episode": 255.0, "Q1 loss": 11.682332653045654, "Q2 loss": 11.678582046508788, "Mean Target Q": 536.4771943359375, "Mean Q1": 536.4744487304688, "Mean Q2": 536.471076171875, "critic_loss": 23.360914695739748, "batch_reward": 5.271923095703125, "actor_loss": -537.6342134021577, "actor_target_entropy": -1.0, "actor_entropy": -0.23901285302071346, "alpha_loss": 0.000453821915600981, "alpha_value": 0.20593467655075237, "duration": 157.70206260681152, "step": 31875}
{"episode_reward": 740.8864259327789, "episode": 256.0, "Q1 loss": 11.763734001159667, "Q2 loss": 11.797511745452882, "Mean Target Q": 538.1256923828125, "Mean Q1": 538.1246259765625, "Mean Q2": 538.1275903320312, "critic_loss": 23.561245697021484, "batch_reward": 5.302525314331055, "actor_loss": -538.8394263482863, "actor_target_entropy": -1.0, "actor_entropy": -0.22233488158352913, "alpha_loss": 0.008233096739727884, "alpha_value": 0.20563685851180596, "duration": 137.47144103050232, "step": 32000}
{"episode_reward": 818.593075473267, "episode": 257.0, "Q1 loss": 12.506551635742188, "Q2 loss": 12.386175346374511, "Mean Target Q": 539.1441904296875, "Mean Q1": 539.1420659179687, "Mean Q2": 539.1421674804687, "critic_loss": 24.89272696685791, "batch_reward": 5.282576210021973, "actor_loss": -540.1088072761656, "actor_target_entropy": -1.0, "actor_entropy": -0.20713792717646037, "alpha_loss": 0.001685849568318753, "alpha_value": 0.2052545523422904, "duration": 149.74646186828613, "step": 32125}
{"episode_reward": 835.8530885812049, "episode": 258.0, "Q1 loss": 12.490429656982421, "Q2 loss": 12.594598979949952, "Mean Target Q": 540.1779340820312, "Mean Q1": 540.1741616210937, "Mean Q2": 540.172103515625, "critic_loss": 25.085028549194337, "batch_reward": 5.2846041069030765, "actor_loss": -541.367912046371, "actor_target_entropy": -1.0, "actor_entropy": -0.17289900275007372, "alpha_loss": 0.00582959521336541, "alpha_value": 0.2049394811136978, "duration": 155.43440699577332, "step": 32250}
{"episode_reward": 835.7021568227531, "episode": 259.0, "Q1 loss": 12.261508968353272, "Q2 loss": 12.103051921844482, "Mean Target Q": 541.7860732421875, "Mean Q1": 541.77615625, "Mean Q2": 541.7792016601562, "critic_loss": 24.3645609664917, "batch_reward": 5.3005437049865725, "actor_loss": -542.6093042767237, "actor_target_entropy": -1.0, "actor_entropy": -0.21560338860939418, "alpha_loss": 0.0006846129314027845, "alpha_value": 0.20478593154652655, "duration": 150.3725335597992, "step": 32375}
{"episode_reward": 832.9350657760945, "episode": 260.0, "Q1 loss": 12.403839183807372, "Q2 loss": 12.473541118621826, "Mean Target Q": 542.881826171875, "Mean Q1": 542.88787109375, "Mean Q2": 542.8838828125, "critic_loss": 24.877380271911623, "batch_reward": 5.303901752471924, "actor_loss": -543.9023910030241, "actor_target_entropy": -1.0, "actor_entropy": -0.2198101569327616, "alpha_loss": 0.003687912334440156, "alpha_value": 0.20446887944314643, "duration": 157.81203722953796, "step": 32500}
{"episode_reward": 832.6281367714527, "episode": 261.0, "Q1 loss": 12.739623023986816, "Q2 loss": 12.747561420440674, "Mean Target Q": 544.5322778320312, "Mean Q1": 544.5265727539063, "Mean Q2": 544.5283129882813, "critic_loss": 25.487184425354005, "batch_reward": 5.317093486785889, "actor_loss": -545.6397918216766, "actor_target_entropy": -1.0, "actor_entropy": -0.18323911052374614, "alpha_loss": 0.01014313699736718, "alpha_value": 0.20393613979868777, "duration": 146.2747392654419, "step": 32625}
{"episode_reward": 830.1950743379415, "episode": 262.0, "Q1 loss": 11.934973678588868, "Q2 loss": 11.836485961914063, "Mean Target Q": 545.5107817382813, "Mean Q1": 545.5005751953125, "Mean Q2": 545.5015375976562, "critic_loss": 23.771459663391113, "batch_reward": 5.3098670120239255, "actor_loss": -546.1647053380167, "actor_target_entropy": -1.0, "actor_entropy": -0.2019040077444046, "alpha_loss": 0.005603796323656195, "alpha_value": 0.2033070196636938, "duration": 157.79931807518005, "step": 32750}
{"episode_reward": 833.1413361890931, "episode": 263.0, "Q1 loss": 13.525804569244384, "Q2 loss": 13.537322353363036, "Mean Target Q": 546.6361381835937, "Mean Q1": 546.63944921875, "Mean Q2": 546.6384096679687, "critic_loss": 27.063126876831056, "batch_reward": 5.313421466827393, "actor_loss": -547.5856507316469, "actor_target_entropy": -1.0, "actor_entropy": -0.1676872612701522, "alpha_loss": 0.007015883922576904, "alpha_value": 0.20283206744644852, "duration": 158.00855016708374, "step": 32875}
{"episode_reward": 830.6912481442429, "episode": 264.0, "Q1 loss": 12.305348655700683, "Q2 loss": 12.219843849182128, "Mean Target Q": 547.7635087890625, "Mean Q1": 547.7593940429688, "Mean Q2": 547.7602919921875, "critic_loss": 24.525192489624022, "batch_reward": 5.3132327346801755, "actor_loss": -548.5700289818549, "actor_target_entropy": -1.0, "actor_entropy": -0.22472304778714333, "alpha_loss": -0.0035356492829328825, "alpha_value": 0.20258840233138256, "duration": 146.66102933883667, "step": 33000}
{"episode_reward": 814.4427652162339, "episode": 265.0, "Q1 loss": 12.51349513244629, "Q2 loss": 12.455254875183105, "Mean Target Q": 548.8814970703125, "Mean Q1": 548.8701108398437, "Mean Q2": 548.8701157226562, "critic_loss": 24.96875, "batch_reward": 5.3181838569641116, "actor_loss": -549.7864951481895, "actor_target_entropy": -1.0, "actor_entropy": -0.21711245723186978, "alpha_loss": 0.0023369490693781582, "alpha_value": 0.20264329556135216, "duration": 151.0732946395874, "step": 33125}
{"episode_reward": 761.1297648837959, "episode": 266.0, "Q1 loss": 11.939113250732422, "Q2 loss": 11.994934001922607, "Mean Target Q": 550.2877041015626, "Mean Q1": 550.2931459960937, "Mean Q2": 550.291166015625, "critic_loss": 23.934047126770018, "batch_reward": 5.326322540283203, "actor_loss": -551.0460579164567, "actor_target_entropy": -1.0, "actor_entropy": -0.17162673055164276, "alpha_loss": 0.0034011661097587595, "alpha_value": 0.2025299037514449, "duration": 140.32125759124756, "step": 33250}
{"episode_reward": 770.9823946647489, "episode": 267.0, "Q1 loss": 12.269804347991943, "Q2 loss": 12.057556842803955, "Mean Target Q": 550.9323173828125, "Mean Q1": 550.9301201171875, "Mean Q2": 550.9311259765625, "critic_loss": 24.327361358642577, "batch_reward": 5.3061855697631835, "actor_loss": -551.8823765345982, "actor_target_entropy": -1.0, "actor_entropy": -0.17071729389921067, "alpha_loss": 0.0022216570279043582, "alpha_value": 0.20214945214751942, "duration": 160.54189157485962, "step": 33375}
{"episode_reward": 814.4801100545029, "episode": 268.0, "Q1 loss": 12.612586860656739, "Q2 loss": 12.568080005645752, "Mean Target Q": 552.5013256835938, "Mean Q1": 552.49819140625, "Mean Q2": 552.4982700195312, "critic_loss": 25.180666778564454, "batch_reward": 5.343602771759033, "actor_loss": -553.4141501149824, "actor_target_entropy": -1.0, "actor_entropy": -0.21958550498370202, "alpha_loss": -0.0004967865327583445, "alpha_value": 0.20211752909128664, "duration": 155.9259729385376, "step": 33500}
{"episode_reward": 834.3628703720772, "episode": 269.0, "Q1 loss": 12.131647369384766, "Q2 loss": 12.008459495544434, "Mean Target Q": 553.5893999023438, "Mean Q1": 553.585814453125, "Mean Q2": 553.5863056640625, "critic_loss": 24.140106986999513, "batch_reward": 5.336262775421143, "actor_loss": -554.2886052207341, "actor_target_entropy": -1.0, "actor_entropy": -0.2033048654122958, "alpha_loss": 0.002367965692269897, "alpha_value": 0.20201837889582272, "duration": 151.3446900844574, "step": 33625}
{"episode_reward": 751.842932794473, "episode": 270.0, "Q1 loss": 11.835302772521972, "Q2 loss": 11.717751621246338, "Mean Target Q": 554.8936254882813, "Mean Q1": 554.89883203125, "Mean Q2": 554.8959946289062, "critic_loss": 23.55305445098877, "batch_reward": 5.339652900695801, "actor_loss": -555.7985396846648, "actor_target_entropy": -1.0, "actor_entropy": -0.20798836311986368, "alpha_loss": 0.004173084038249668, "alpha_value": 0.20173387945142787, "duration": 160.26785802841187, "step": 33750}
{"episode_reward": 767.9905504523274, "episode": 271.0, "Q1 loss": 12.86212133026123, "Q2 loss": 12.709766414642335, "Mean Target Q": 556.1751313476562, "Mean Q1": 556.1632607421875, "Mean Q2": 556.1647534179688, "critic_loss": 25.571887702941893, "batch_reward": 5.346289199829101, "actor_loss": -556.8643188476562, "actor_target_entropy": -1.0, "actor_entropy": -0.2066712954214641, "alpha_loss": 0.003489445695387466, "alpha_value": 0.201445857141639, "duration": 155.17831158638, "step": 33875}
{"episode_reward": 813.7049272366698, "episode": 272.0, "Q1 loss": 12.680715545654296, "Q2 loss": 12.713330860137939, "Mean Target Q": 557.3313403320312, "Mean Q1": 557.3268720703124, "Mean Q2": 557.3274541015625, "critic_loss": 25.394046226501466, "batch_reward": 5.355308532714844, "actor_loss": -557.8341034919985, "actor_target_entropy": -1.0, "actor_entropy": -0.19712504143676451, "alpha_loss": 0.0019082661057191511, "alpha_value": 0.20121414897040504, "duration": 156.5232446193695, "step": 34000}
{"episode_reward": 832.0181201719754, "episode": 273.0, "Q1 loss": 12.57653039932251, "Q2 loss": 12.475590728759766, "Mean Target Q": 558.659119140625, "Mean Q1": 558.6562353515625, "Mean Q2": 558.6553515625, "critic_loss": 25.052121147155763, "batch_reward": 5.358032966613769, "actor_loss": -559.8452739412822, "actor_target_entropy": -1.0, "actor_entropy": -0.22212509089519109, "alpha_loss": -0.005754816852184752, "alpha_value": 0.20124017112544354, "duration": 161.2098970413208, "step": 34125}
{"episode_reward": 771.9473166866251, "episode": 274.0, "Q1 loss": 11.812792881011962, "Q2 loss": 12.041955135345459, "Mean Target Q": 559.8367490234375, "Mean Q1": 559.8386005859375, "Mean Q2": 559.8359912109376, "critic_loss": 23.85474799346924, "batch_reward": 5.359639484405518, "actor_loss": -560.5414605909779, "actor_target_entropy": -1.0, "actor_entropy": -0.1922126571016927, "alpha_loss": 0.0030940304803211364, "alpha_value": 0.2015083033742229, "duration": 156.12237095832825, "step": 34250}
{"episode_reward": 826.7418061898503, "episode": 275.0, "Q1 loss": 12.446911640167237, "Q2 loss": 12.323064178466797, "Mean Target Q": 561.00834375, "Mean Q1": 561.0015512695312, "Mean Q2": 561.0066416015625, "critic_loss": 24.769975784301757, "batch_reward": 5.375998386383056, "actor_loss": -561.8741648840526, "actor_target_entropy": -1.0, "actor_entropy": -0.19445344923980654, "alpha_loss": 0.0030078364957478784, "alpha_value": 0.2012551933648537, "duration": 145.67314338684082, "step": 34375}
{"episode_reward": 764.5247994708647, "episode": 276.0, "Q1 loss": 12.490331951141357, "Q2 loss": 12.475414688110352, "Mean Target Q": 561.9256435546876, "Mean Q1": 561.9246044921875, "Mean Q2": 561.9224223632813, "critic_loss": 24.965746543884276, "batch_reward": 5.361426170349121, "actor_loss": -562.506078904675, "actor_target_entropy": -1.0, "actor_entropy": -0.19233178743912327, "alpha_loss": -1.0387063206684205e-06, "alpha_value": 0.20106611762911963, "duration": 143.9757912158966, "step": 34500}
{"episode_reward": 835.9225167486339, "episode": 277.0, "Q1 loss": 12.798149711608886, "Q2 loss": 12.561885284423829, "Mean Target Q": 563.5232250976562, "Mean Q1": 563.518806640625, "Mean Q2": 563.5186181640624, "critic_loss": 25.36003495025635, "batch_reward": 5.399007915496826, "actor_loss": -564.6387309725322, "actor_target_entropy": -1.0, "actor_entropy": -0.20767494113672347, "alpha_loss": 0.008591643626993847, "alpha_value": 0.20082188304612644, "duration": 158.51638197898865, "step": 34625}
{"episode_reward": 833.5989622138399, "episode": 278.0, "Q1 loss": 12.268170402526856, "Q2 loss": 12.398873912811279, "Mean Target Q": 564.4239565429688, "Mean Q1": 564.4230361328125, "Mean Q2": 564.4251918945313, "critic_loss": 24.667044227600098, "batch_reward": 5.38231982421875, "actor_loss": -565.4785835512223, "actor_target_entropy": -1.0, "actor_entropy": -0.21550915630594378, "alpha_loss": 0.0010340945314495794, "alpha_value": 0.20035569503258313, "duration": 159.54128170013428, "step": 34750}
{"episode_reward": 764.8585443160272, "episode": 279.0, "Q1 loss": 12.977467353820801, "Q2 loss": 12.82325182723999, "Mean Target Q": 565.1963413085938, "Mean Q1": 565.1998056640625, "Mean Q2": 565.1936655273438, "critic_loss": 25.800719108581543, "batch_reward": 5.369046581268311, "actor_loss": -565.971685500372, "actor_target_entropy": -1.0, "actor_entropy": -0.1893109797485291, "alpha_loss": -0.00156614200271193, "alpha_value": 0.20035816518705754, "duration": 161.66553902626038, "step": 34875}
{"episode_reward": 821.1515343409255, "episode": 280.0, "Q1 loss": 12.972117477416992, "Q2 loss": 12.926780715942384, "Mean Target Q": 566.2762587890625, "Mean Q1": 566.2631767578125, "Mean Q2": 566.2667084960938, "critic_loss": 25.898898246765135, "batch_reward": 5.373651279449463, "actor_loss": -567.2437074722782, "actor_target_entropy": -1.0, "actor_entropy": -0.19912974692640767, "alpha_loss": -0.0063561104320650616, "alpha_value": 0.20068632179720947, "step": 35000}
{"duration": 168.8441879749298, "step": 35000}
{"episode_reward": 769.7257393384484, "episode": 281.0, "Q1 loss": 11.445266174316407, "Q2 loss": 11.46651248550415, "Mean Target Q": 567.8380961914063, "Mean Q1": 567.8348110351562, "Mean Q2": 567.836126953125, "critic_loss": 22.911778701782225, "batch_reward": 5.405272357940674, "actor_loss": -568.6986839657739, "actor_target_entropy": -1.0, "actor_entropy": -0.19405666040995764, "alpha_loss": 0.004905356493379388, "alpha_value": 0.20072859844651547, "duration": 150.18501996994019, "step": 35125}
{"episode_reward": 835.7048711032838, "episode": 282.0, "Q1 loss": 11.798094886779785, "Q2 loss": 11.738384468078614, "Mean Target Q": 568.5446528320313, "Mean Q1": 568.5397236328125, "Mean Q2": 568.5389165039062, "critic_loss": 23.53647933959961, "batch_reward": 5.378078460693359, "actor_loss": -569.613280265562, "actor_target_entropy": -1.0, "actor_entropy": -0.19950125558722404, "alpha_loss": -0.001175390164022364, "alpha_value": 0.20044529057997298, "duration": 148.3481149673462, "step": 35250}
{"episode_reward": 803.81400519785, "episode": 283.0, "Q1 loss": 11.89623303604126, "Q2 loss": 11.865463459014892, "Mean Target Q": 569.6414575195313, "Mean Q1": 569.639, "Mean Q2": 569.6375141601562, "critic_loss": 23.761696464538574, "batch_reward": 5.391407520294189, "actor_loss": -570.3665287078373, "actor_target_entropy": -1.0, "actor_entropy": -0.19288848624342964, "alpha_loss": 0.003170671222347116, "alpha_value": 0.20047556100107294, "duration": 153.22504258155823, "step": 35375}
{"episode_reward": 808.3020445583853, "episode": 284.0, "Q1 loss": 10.98980145263672, "Q2 loss": 11.093181770324707, "Mean Target Q": 570.7620864257813, "Mean Q1": 570.7646166992188, "Mean Q2": 570.7653120117187, "critic_loss": 22.082983283996583, "batch_reward": 5.392094402313233, "actor_loss": -571.6924911006804, "actor_target_entropy": -1.0, "actor_entropy": -0.2285863682627678, "alpha_loss": 0.005557517509817356, "alpha_value": 0.2001794722994936, "duration": 152.59752368927002, "step": 35500}
{"episode_reward": 814.2898373418398, "episode": 285.0, "Q1 loss": 11.756567337036133, "Q2 loss": 11.685730400085449, "Mean Target Q": 571.637091796875, "Mean Q1": 571.6329853515625, "Mean Q2": 571.6334096679687, "critic_loss": 23.442297775268553, "batch_reward": 5.379888675689697, "actor_loss": -572.4700753348214, "actor_target_entropy": -1.0, "actor_entropy": -0.19294874571145526, "alpha_loss": 0.007350625954420557, "alpha_value": 0.19945915767368602, "duration": 150.01048111915588, "step": 35625}
{"episode_reward": 828.9823058579449, "episode": 286.0, "Q1 loss": 12.203404968261719, "Q2 loss": 12.206148597717284, "Mean Target Q": 573.2236655273438, "Mean Q1": 573.2194536132813, "Mean Q2": 573.2211396484375, "critic_loss": 24.409553588867187, "batch_reward": 5.418279884338379, "actor_loss": -574.0521151634955, "actor_target_entropy": -1.0, "actor_entropy": -0.20076318355577608, "alpha_loss": 0.004225675410951578, "alpha_value": 0.1989839889424629, "duration": 158.3837571144104, "step": 35750}
{"episode_reward": 833.8581952233806, "episode": 287.0, "Q1 loss": 12.622376502990722, "Q2 loss": 12.460731647491455, "Mean Target Q": 573.9589887695313, "Mean Q1": 573.9673139648437, "Mean Q2": 573.9651313476562, "critic_loss": 25.0831081161499, "batch_reward": 5.388810920715332, "actor_loss": -574.7489992171999, "actor_target_entropy": -1.0, "actor_entropy": -0.1993712850269817, "alpha_loss": 0.002470735161166106, "alpha_value": 0.19877476040233388, "duration": 156.27678894996643, "step": 35875}
{"episode_reward": 826.5478801912247, "episode": 288.0, "Q1 loss": 12.108003635406494, "Q2 loss": 12.115419887542725, "Mean Target Q": 575.1411528320313, "Mean Q1": 575.12925, "Mean Q2": 575.12815234375, "critic_loss": 24.22342349243164, "batch_reward": 5.40608321762085, "actor_loss": -576.1756099577873, "actor_target_entropy": -1.0, "actor_entropy": -0.20186762992412813, "alpha_loss": 0.006424362807827551, "alpha_value": 0.19834763398877975, "duration": 149.60441637039185, "step": 36000}
{"episode_reward": 829.7263079276574, "episode": 289.0, "Q1 loss": 12.924090839385986, "Q2 loss": 12.822225776672363, "Mean Target Q": 576.2706025390625, "Mean Q1": 576.265365234375, "Mean Q2": 576.26729296875, "critic_loss": 25.746316574096678, "batch_reward": 5.403570747375488, "actor_loss": -577.1486370752729, "actor_target_entropy": -1.0, "actor_entropy": -0.20448487701397094, "alpha_loss": 0.006584870189221369, "alpha_value": 0.19783946879648914, "duration": 152.31148219108582, "step": 36125}
{"episode_reward": 839.5209551477058, "episode": 290.0, "Q1 loss": 11.72144242477417, "Q2 loss": 11.8421848487854, "Mean Target Q": 576.9794716796875, "Mean Q1": 576.9726240234374, "Mean Q2": 576.9719028320312, "critic_loss": 23.563627250671388, "batch_reward": 5.406165145874024, "actor_loss": -577.6211203298261, "actor_target_entropy": -1.0, "actor_entropy": -0.19754053003364994, "alpha_loss": 0.004370986934631101, "alpha_value": 0.19734385173347452, "duration": 150.8744034767151, "step": 36250}
{"episode_reward": 828.0818947859233, "episode": 291.0, "Q1 loss": 12.57262589263916, "Q2 loss": 12.57884680557251, "Mean Target Q": 578.7245698242187, "Mean Q1": 578.7274086914063, "Mean Q2": 578.7267651367188, "critic_loss": 25.151472747802735, "batch_reward": 5.452434112548828, "actor_loss": -579.58592781188, "actor_target_entropy": -1.0, "actor_entropy": -0.2049328437636769, "alpha_loss": 0.006934845699958267, "alpha_value": 0.19691366639112953, "duration": 154.37499451637268, "step": 36375}
{"episode_reward": 822.8669486075394, "episode": 292.0, "Q1 loss": 11.93147227859497, "Q2 loss": 11.936964385986329, "Mean Target Q": 579.4747299804687, "Mean Q1": 579.4665717773438, "Mean Q2": 579.4690400390625, "critic_loss": 23.868436637878418, "batch_reward": 5.441188358306885, "actor_loss": -580.519800001575, "actor_target_entropy": -1.0, "actor_entropy": -0.24429960044160967, "alpha_loss": 0.001215582638378105, "alpha_value": 0.19646037740263325, "duration": 157.4321551322937, "step": 36500}
{"episode_reward": 833.8932217372485, "episode": 293.0, "Q1 loss": 10.920700050354004, "Q2 loss": 10.922264190673829, "Mean Target Q": 580.5784692382813, "Mean Q1": 580.5767387695313, "Mean Q2": 580.5736791992188, "critic_loss": 21.842964332580568, "batch_reward": 5.43585506439209, "actor_loss": -581.4990147181919, "actor_target_entropy": -1.0, "actor_entropy": -0.20560476479549256, "alpha_loss": 0.004105821643615999, "alpha_value": 0.19634463354101753, "duration": 155.02821707725525, "step": 36625}
{"episode_reward": 838.7474927752962, "episode": 294.0, "Q1 loss": 10.999213233947755, "Q2 loss": 10.978356132507324, "Mean Target Q": 581.6991713867187, "Mean Q1": 581.69832421875, "Mean Q2": 581.7008403320312, "critic_loss": 21.97756932067871, "batch_reward": 5.44299647140503, "actor_loss": -582.6499889742944, "actor_target_entropy": -1.0, "actor_entropy": -0.2050836703950359, "alpha_loss": 0.0007417282097101692, "alpha_value": 0.19623347931297902, "duration": 152.44231510162354, "step": 36750}
{"episode_reward": 830.9086396322224, "episode": 295.0, "Q1 loss": 11.912676837921143, "Q2 loss": 11.734343353271484, "Mean Target Q": 582.470345703125, "Mean Q1": 582.4706655273437, "Mean Q2": 582.4713901367187, "critic_loss": 23.64702015686035, "batch_reward": 5.444491645812988, "actor_loss": -583.0609411814856, "actor_target_entropy": -1.0, "actor_entropy": -0.19244498653071268, "alpha_loss": 0.004459047157849584, "alpha_value": 0.19588408454191325, "duration": 153.66007256507874, "step": 36875}
{"episode_reward": 814.9479855207842, "episode": 296.0, "Q1 loss": 10.954952766418456, "Q2 loss": 10.83367183303833, "Mean Target Q": 583.4858022460937, "Mean Q1": 583.4789370117187, "Mean Q2": 583.4759438476563, "critic_loss": 21.78862449645996, "batch_reward": 5.442138824462891, "actor_loss": -584.2537910707536, "actor_target_entropy": -1.0, "actor_entropy": -0.17142303696563166, "alpha_loss": 0.009896246156835507, "alpha_value": 0.19544106276381595, "duration": 147.26741814613342, "step": 37000}
{"episode_reward": 828.1017217198619, "episode": 297.0, "Q1 loss": 11.585676361083985, "Q2 loss": 11.347246204376221, "Mean Target Q": 584.3210590820313, "Mean Q1": 584.316486328125, "Mean Q2": 584.3174228515625, "critic_loss": 22.932922470092773, "batch_reward": 5.437745800018311, "actor_loss": -584.9442012726314, "actor_target_entropy": -1.0, "actor_entropy": -0.2108311170623416, "alpha_loss": 0.003856001013431639, "alpha_value": 0.19487192195071637, "duration": 158.7823748588562, "step": 37125}
{"episode_reward": 810.5105696175705, "episode": 298.0, "Q1 loss": 11.085096786499024, "Q2 loss": 11.028009685516357, "Mean Target Q": 585.045291015625, "Mean Q1": 585.0484921875, "Mean Q2": 585.0499848632812, "critic_loss": 22.113106300354005, "batch_reward": 5.437202281951905, "actor_loss": -585.8799871629284, "actor_target_entropy": -1.0, "actor_entropy": -0.22274584924021074, "alpha_loss": 0.003964549558605218, "alpha_value": 0.1946816578900679, "duration": 149.5783131122589, "step": 37250}
{"episode_reward": 673.8236051807783, "episode": 299.0, "Q1 loss": 10.932331184387207, "Q2 loss": 10.937667663574219, "Mean Target Q": 586.3511904296874, "Mean Q1": 586.33323046875, "Mean Q2": 586.3329790039063, "critic_loss": 21.86999880218506, "batch_reward": 5.454305526733399, "actor_loss": -587.2713506789435, "actor_target_entropy": -1.0, "actor_entropy": -0.2280020576620859, "alpha_loss": 0.006160167201111714, "alpha_value": 0.19401789274027925, "duration": 159.98332238197327, "step": 37375}
{"episode_reward": 777.7716313735924, "episode": 300.0, "Q1 loss": 11.619732921600342, "Q2 loss": 11.524770656585693, "Mean Target Q": 587.2416049804688, "Mean Q1": 587.247640625, "Mean Q2": 587.2463217773437, "critic_loss": 23.144503410339354, "batch_reward": 5.455738586425781, "actor_loss": -587.5781397665701, "actor_target_entropy": -1.0, "actor_entropy": -0.21797688353446223, "alpha_loss": 0.0016004894559662189, "alpha_value": 0.19384187484978577, "duration": 152.8133237361908, "step": 37500}
{"episode_reward": 832.8241759463361, "episode": 301.0, "Q1 loss": 11.92639807510376, "Q2 loss": 11.93541365814209, "Mean Target Q": 588.184951171875, "Mean Q1": 588.1839799804687, "Mean Q2": 588.183779296875, "critic_loss": 23.86181175994873, "batch_reward": 5.452044334411621, "actor_loss": -588.8399406312004, "actor_target_entropy": -1.0, "actor_entropy": -0.2113991758180043, "alpha_loss": 0.0022072063847666697, "alpha_value": 0.193546349722533, "duration": 143.17402911186218, "step": 37625}
{"episode_reward": 832.1289036947214, "episode": 302.0, "Q1 loss": 11.57592956161499, "Q2 loss": 11.72292481994629, "Mean Target Q": 589.31103515625, "Mean Q1": 589.307525390625, "Mean Q2": 589.3080322265625, "critic_loss": 23.298854377746583, "batch_reward": 5.462691310882568, "actor_loss": -590.0993977208292, "actor_target_entropy": -1.0, "actor_entropy": -0.18774286639546195, "alpha_loss": 0.0030797249862864135, "alpha_value": 0.1934899787857048, "duration": 148.21190524101257, "step": 37750}
{"episode_reward": 828.6428168344939, "episode": 303.0, "Q1 loss": 11.829516235351562, "Q2 loss": 11.821155429840088, "Mean Target Q": 590.20717578125, "Mean Q1": 590.2041274414063, "Mean Q2": 590.2035717773438, "critic_loss": 23.650671684265138, "batch_reward": 5.461052009582519, "actor_loss": -591.0204080248636, "actor_target_entropy": -1.0, "actor_entropy": -0.1757000247755694, "alpha_loss": 0.005263926165681037, "alpha_value": 0.19307894488396724, "duration": 152.27003812789917, "step": 37875}
{"episode_reward": 823.5517415666493, "episode": 304.0, "Q1 loss": 10.929732173919678, "Q2 loss": 10.946833065032958, "Mean Target Q": 591.043466796875, "Mean Q1": 591.0355336914063, "Mean Q2": 591.0381806640625, "critic_loss": 21.876565216064453, "batch_reward": 5.460287872314453, "actor_loss": -591.8766075872605, "actor_target_entropy": -1.0, "actor_entropy": -0.21753160054645232, "alpha_loss": 0.0018479399563324068, "alpha_value": 0.19274674499875777, "duration": 150.31540989875793, "step": 38000}
{"episode_reward": 827.658098658353, "episode": 305.0, "Q1 loss": 10.708045642852783, "Q2 loss": 10.760013019561768, "Mean Target Q": 592.4419360351562, "Mean Q1": 592.4426665039063, "Mean Q2": 592.4392026367187, "critic_loss": 21.468058624267577, "batch_reward": 5.481471931457519, "actor_loss": -593.1614622085814, "actor_target_entropy": -1.0, "actor_entropy": -0.21314748506697398, "alpha_loss": 0.003837663639662048, "alpha_value": 0.19240152840119445, "duration": 146.8612678050995, "step": 38125}
{"episode_reward": 837.96506782032, "episode": 306.0, "Q1 loss": 11.782663627624512, "Q2 loss": 11.651531620025635, "Mean Target Q": 593.3397856445313, "Mean Q1": 593.340673828125, "Mean Q2": 593.3413994140625, "critic_loss": 23.434195205688475, "batch_reward": 5.481536449432373, "actor_loss": -594.3073051206527, "actor_target_entropy": -1.0, "actor_entropy": -0.20451543311918935, "alpha_loss": 0.004429168912822441, "alpha_value": 0.19207828056037657, "duration": 147.35527563095093, "step": 38250}
{"episode_reward": 692.6613511859088, "episode": 307.0, "Q1 loss": 10.579737678527833, "Q2 loss": 10.63564744567871, "Mean Target Q": 594.1771298828126, "Mean Q1": 594.1664267578125, "Mean Q2": 594.1680209960938, "critic_loss": 21.21538511657715, "batch_reward": 5.476699558258057, "actor_loss": -594.9111279684399, "actor_target_entropy": -1.0, "actor_entropy": -0.16387916084319826, "alpha_loss": 0.0064281310317003066, "alpha_value": 0.19161536449060224, "duration": 155.7952105998993, "step": 38375}
{"episode_reward": 817.1142394781987, "episode": 308.0, "Q1 loss": 11.976033592224121, "Q2 loss": 12.0522859916687, "Mean Target Q": 595.149423828125, "Mean Q1": 595.1566787109375, "Mean Q2": 595.1552041015625, "critic_loss": 24.02831950378418, "batch_reward": 5.48256559753418, "actor_loss": -595.7668742518271, "actor_target_entropy": -1.0, "actor_entropy": -0.1690236865993469, "alpha_loss": 0.00877582126357142, "alpha_value": 0.1909474142880098, "duration": 146.96434831619263, "step": 38500}
{"episode_reward": 818.7479675402477, "episode": 309.0, "Q1 loss": 11.680527961730958, "Q2 loss": 11.835373817443848, "Mean Target Q": 595.6108637695313, "Mean Q1": 595.6013041992187, "Mean Q2": 595.6013046875, "critic_loss": 23.515901710510253, "batch_reward": 5.4643709869384764, "actor_loss": -596.2218511672247, "actor_target_entropy": -1.0, "actor_entropy": -0.1918571095854517, "alpha_loss": 0.0049741183396517525, "alpha_value": 0.19031533639864123, "duration": 146.49225497245789, "step": 38625}
{"episode_reward": 680.8201989698033, "episode": 310.0, "Q1 loss": 10.600298641204834, "Q2 loss": 10.47712190246582, "Mean Target Q": 596.627833984375, "Mean Q1": 596.6265146484375, "Mean Q2": 596.62687109375, "critic_loss": 21.07742060852051, "batch_reward": 5.47623934173584, "actor_loss": -597.121590891192, "actor_target_entropy": -1.0, "actor_entropy": -0.2060971859722368, "alpha_loss": 0.004606519264334272, "alpha_value": 0.19007978551782453, "duration": 161.65921473503113, "step": 38750}
{"episode_reward": 823.6564456214041, "episode": 311.0, "Q1 loss": 11.066010456085206, "Q2 loss": 10.96850075149536, "Mean Target Q": 597.73809375, "Mean Q1": 597.73247265625, "Mean Q2": 597.7328178710937, "critic_loss": 22.03451107788086, "batch_reward": 5.483758167266846, "actor_loss": -598.5978316049727, "actor_target_entropy": -1.0, "actor_entropy": -0.19401242465726912, "alpha_loss": 0.010373600917528309, "alpha_value": 0.1895027804189049, "duration": 157.22578024864197, "step": 38875}
{"episode_reward": 772.7659650853205, "episode": 312.0, "Q1 loss": 11.22916068649292, "Q2 loss": 11.08808377456665, "Mean Target Q": 598.3711147460938, "Mean Q1": 598.370830078125, "Mean Q2": 598.3720620117188, "critic_loss": 22.31724449157715, "batch_reward": 5.480997856140137, "actor_loss": -599.1922371156754, "actor_target_entropy": -1.0, "actor_entropy": -0.23156858536024247, "alpha_loss": 6.0555341112757885e-05, "alpha_value": 0.188919949897879, "duration": 150.33480095863342, "step": 39000}
{"episode_reward": 826.6178004951884, "episode": 313.0, "Q1 loss": 11.235557800292968, "Q2 loss": 11.206919075012207, "Mean Target Q": 599.32613671875, "Mean Q1": 599.316759765625, "Mean Q2": 599.31552734375, "critic_loss": 22.442476959228514, "batch_reward": 5.500850170135498, "actor_loss": -599.955568343874, "actor_target_entropy": -1.0, "actor_entropy": -0.19384765873352686, "alpha_loss": 0.008051741871953247, "alpha_value": 0.18859564481218752, "duration": 158.8825740814209, "step": 39125}
{"episode_reward": 836.2162124173323, "episode": 314.0, "Q1 loss": 11.658540821075439, "Q2 loss": 11.554020175933838, "Mean Target Q": 600.2651821289063, "Mean Q1": 600.2677397460938, "Mean Q2": 600.2681318359375, "critic_loss": 23.21256095123291, "batch_reward": 5.500080047607422, "actor_loss": -600.9775705645161, "actor_target_entropy": -1.0, "actor_entropy": -0.22731664632597276, "alpha_loss": 0.0016563984156105548, "alpha_value": 0.18828871832045316, "duration": 141.7305872440338, "step": 39250}
{"episode_reward": 834.9588988630873, "episode": 315.0, "Q1 loss": 10.533559356689453, "Q2 loss": 10.51569488143921, "Mean Target Q": 601.0962231445312, "Mean Q1": 601.098697265625, "Mean Q2": 601.098509765625, "critic_loss": 21.04925428009033, "batch_reward": 5.500750560760498, "actor_loss": -601.5342281281002, "actor_target_entropy": -1.0, "actor_entropy": -0.25918684367622646, "alpha_loss": -0.0031478270696150877, "alpha_value": 0.1883192818328724, "duration": 159.35783553123474, "step": 39375}
{"episode_reward": 825.3385576402931, "episode": 316.0, "Q1 loss": 11.616883800506592, "Q2 loss": 11.650670120239258, "Mean Target Q": 602.1844897460937, "Mean Q1": 602.181658203125, "Mean Q2": 602.1818432617188, "critic_loss": 23.267553955078125, "batch_reward": 5.508456272125244, "actor_loss": -602.6502596947455, "actor_target_entropy": -1.0, "actor_entropy": -0.23242884838292677, "alpha_loss": -0.002777068920794033, "alpha_value": 0.18851761107819887, "duration": 145.9294080734253, "step": 39500}
{"episode_reward": 757.4410629063731, "episode": 317.0, "Q1 loss": 10.724224914550781, "Q2 loss": 10.784608631134033, "Mean Target Q": 603.085658203125, "Mean Q1": 603.0864155273438, "Mean Q2": 603.084095703125, "critic_loss": 21.5088335647583, "batch_reward": 5.5149766578674315, "actor_loss": -603.9418499658979, "actor_target_entropy": -1.0, "actor_entropy": -0.21100408619358427, "alpha_loss": 0.003065863147466665, "alpha_value": 0.18846237254581297, "duration": 150.0047550201416, "step": 39625}
{"episode_reward": 845.3158227021581, "episode": 318.0, "Q1 loss": 10.27417212677002, "Q2 loss": 10.314835746765137, "Mean Target Q": 603.9356040039063, "Mean Q1": 603.9278979492187, "Mean Q2": 603.9279428710937, "critic_loss": 20.589007751464845, "batch_reward": 5.517851573944092, "actor_loss": -604.377189390121, "actor_target_entropy": -1.0, "actor_entropy": -0.21559671408707096, "alpha_loss": 0.003781748406078306, "alpha_value": 0.18826477913803152, "duration": 147.91571354866028, "step": 39750}
{"episode_reward": 768.9757814901782, "episode": 319.0, "Q1 loss": 10.563787532806396, "Q2 loss": 10.602235389709472, "Mean Target Q": 604.5930024414063, "Mean Q1": 604.5886215820312, "Mean Q2": 604.5901206054688, "critic_loss": 21.166022914886476, "batch_reward": 5.5156901206970215, "actor_loss": -605.8110516260541, "actor_target_entropy": -1.0, "actor_entropy": -0.24952309756051927, "alpha_loss": -0.0003278261523634668, "alpha_value": 0.18812451422716917, "duration": 145.39775562286377, "step": 39875}
{"episode_reward": 808.1298689053843, "episode": 320.0, "Q1 loss": 10.91566278076172, "Q2 loss": 10.894841732025146, "Mean Target Q": 605.3972099609375, "Mean Q1": 605.4028090820312, "Mean Q2": 605.3992587890625, "critic_loss": 21.81050454711914, "batch_reward": 5.525164813995361, "actor_loss": -606.0500252016129, "actor_target_entropy": -1.0, "actor_entropy": -0.2251762661241716, "alpha_loss": 0.0036305704477032825, "alpha_value": 0.18790383796301593, "step": 40000}
{"duration": 160.4126272201538, "step": 40000}
{"episode_reward": 826.8195000061711, "episode": 321.0, "Q1 loss": 11.540253875732422, "Q2 loss": 11.48273049545288, "Mean Target Q": 605.8381655273438, "Mean Q1": 605.8327036132813, "Mean Q2": 605.8367626953125, "critic_loss": 23.022984382629396, "batch_reward": 5.510003509521485, "actor_loss": -606.8270379929315, "actor_target_entropy": -1.0, "actor_entropy": -0.21970729742731368, "alpha_loss": 0.003050853936223402, "alpha_value": 0.18770429676631908, "duration": 170.5533435344696, "step": 40125}
{"episode_reward": 840.034079006687, "episode": 322.0, "Q1 loss": 11.245788932800293, "Q2 loss": 11.230492908477784, "Mean Target Q": 606.9708359375, "Mean Q1": 606.9696655273438, "Mean Q2": 606.9676474609375, "critic_loss": 22.47628182220459, "batch_reward": 5.53641227722168, "actor_loss": -607.4349581810736, "actor_target_entropy": -1.0, "actor_entropy": -0.20428477828541108, "alpha_loss": 0.005575862936600442, "alpha_value": 0.18739379980371848, "duration": 150.74961638450623, "step": 40250}
{"episode_reward": 803.2635169762311, "episode": 323.0, "Q1 loss": 10.06033895111084, "Q2 loss": 10.163194004058838, "Mean Target Q": 607.867265625, "Mean Q1": 607.8630893554688, "Mean Q2": 607.864525390625, "critic_loss": 20.22353290557861, "batch_reward": 5.525797740936279, "actor_loss": -608.676996140253, "actor_target_entropy": -1.0, "actor_entropy": -0.18130072939490516, "alpha_loss": 0.005352104127052284, "alpha_value": 0.18679380621209593, "duration": 155.6731767654419, "step": 40375}
{"episode_reward": 767.5286187980515, "episode": 324.0, "Q1 loss": 10.381731018066406, "Q2 loss": 10.220075141906738, "Mean Target Q": 608.6863994140625, "Mean Q1": 608.68293359375, "Mean Q2": 608.681208984375, "critic_loss": 20.601806106567384, "batch_reward": 5.521149864196778, "actor_loss": -609.4352190571446, "actor_target_entropy": -1.0, "actor_entropy": -0.2314482807151733, "alpha_loss": 0.00214229742695968, "alpha_value": 0.1865450819549446, "duration": 152.82147908210754, "step": 40500}
{"episode_reward": 663.1153812524283, "episode": 325.0, "Q1 loss": 10.326453559875489, "Q2 loss": 10.270995792388916, "Mean Target Q": 609.2040727539063, "Mean Q1": 609.19501953125, "Mean Q2": 609.1960922851563, "critic_loss": 20.597449325561524, "batch_reward": 5.508961048126221, "actor_loss": -609.8810628255209, "actor_target_entropy": -1.0, "actor_entropy": -0.21869116879644848, "alpha_loss": 0.004919971620279645, "alpha_value": 0.18627344670795326, "duration": 156.06027007102966, "step": 40625}
{"episode_reward": 807.8427619791005, "episode": 326.0, "Q1 loss": 11.29005567932129, "Q2 loss": 11.258821155548096, "Mean Target Q": 610.486345703125, "Mean Q1": 610.4901630859375, "Mean Q2": 610.4894125976563, "critic_loss": 22.548876876831056, "batch_reward": 5.541535926818848, "actor_loss": -611.067631875315, "actor_target_entropy": -1.0, "actor_entropy": -0.2284295724764947, "alpha_loss": 0.004004698372521107, "alpha_value": 0.18577805209019957, "duration": 163.95387148857117, "step": 40750}
{"episode_reward": 831.4252685169646, "episode": 327.0, "Q1 loss": 10.850807502746582, "Q2 loss": 11.015029663085938, "Mean Target Q": 611.124345703125, "Mean Q1": 611.1225947265625, "Mean Q2": 611.1217368164063, "critic_loss": 21.865837112426757, "batch_reward": 5.528124225616455, "actor_loss": -611.6935308547247, "actor_target_entropy": -1.0, "actor_entropy": -0.21296748306070054, "alpha_loss": 9.643256900802492e-05, "alpha_value": 0.18564810313442423, "duration": 158.93307161331177, "step": 40875}
{"episode_reward": 839.2720604206759, "episode": 328.0, "Q1 loss": 10.200209762573243, "Q2 loss": 10.12294111251831, "Mean Target Q": 611.99283203125, "Mean Q1": 611.9843813476563, "Mean Q2": 611.9876870117188, "critic_loss": 20.323150871276855, "batch_reward": 5.54539920425415, "actor_loss": -612.6159441548009, "actor_target_entropy": -1.0, "actor_entropy": -0.20468055937559373, "alpha_loss": 0.0025153006070233403, "alpha_value": 0.18562103683218298, "duration": 163.36341071128845, "step": 41000}
{"episode_reward": 826.8608405089343, "episode": 329.0, "Q1 loss": 10.714427928924561, "Q2 loss": 10.485406387329101, "Mean Target Q": 612.9428505859375, "Mean Q1": 612.94709765625, "Mean Q2": 612.944744140625, "critic_loss": 21.19983438873291, "batch_reward": 5.549245471954346, "actor_loss": -613.4910249255952, "actor_target_entropy": -1.0, "actor_entropy": -0.21270077226180878, "alpha_loss": 0.005297709365434471, "alpha_value": 0.18508974017763494, "duration": 167.4709644317627, "step": 41125}
{"episode_reward": 833.9268634696864, "episode": 330.0, "Q1 loss": 9.9976763381958, "Q2 loss": 9.918219497680663, "Mean Target Q": 613.6993828125, "Mean Q1": 613.691572265625, "Mean Q2": 613.693177734375, "critic_loss": 19.915895790100098, "batch_reward": 5.547276649475098, "actor_loss": -614.5156102334299, "actor_target_entropy": -1.0, "actor_entropy": -0.2093229153223576, "alpha_loss": 0.0034985477611753006, "alpha_value": 0.18481016792598332, "duration": 154.5152440071106, "step": 41250}
{"episode_reward": 845.6541275282656, "episode": 331.0, "Q1 loss": 11.671101318359375, "Q2 loss": 11.736837322235107, "Mean Target Q": 614.4108193359375, "Mean Q1": 614.4109790039063, "Mean Q2": 614.408646484375, "critic_loss": 23.407938644409178, "batch_reward": 5.5398594055175785, "actor_loss": -615.0890609499008, "actor_target_entropy": -1.0, "actor_entropy": -0.23785553541448382, "alpha_loss": 0.001374296330299879, "alpha_value": 0.18455855448274366, "duration": 158.46666884422302, "step": 41375}
{"episode_reward": 830.8167256141434, "episode": 332.0, "Q1 loss": 11.221344039916993, "Q2 loss": 11.100572444915771, "Mean Target Q": 615.5523642578125, "Mean Q1": 615.5513515625, "Mean Q2": 615.5525571289063, "critic_loss": 22.321916427612305, "batch_reward": 5.562158645629883, "actor_loss": -616.0735503165953, "actor_target_entropy": -1.0, "actor_entropy": -0.22137748426006687, "alpha_loss": 0.0015114304504447406, "alpha_value": 0.18456062092691844, "duration": 159.98926615715027, "step": 41500}
{"episode_reward": 833.4995335356745, "episode": 333.0, "Q1 loss": 10.338002506256103, "Q2 loss": 10.377464363098145, "Mean Target Q": 616.07948046875, "Mean Q1": 616.0836669921875, "Mean Q2": 616.0843779296875, "critic_loss": 20.715466873168946, "batch_reward": 5.5601186866760255, "actor_loss": -616.8882756308903, "actor_target_entropy": -1.0, "actor_entropy": -0.2495954575992766, "alpha_loss": 0.0016961958303692796, "alpha_value": 0.18435559673145946, "duration": 156.9372968673706, "step": 41625}
{"episode_reward": 778.6853138930729, "episode": 334.0, "Q1 loss": 10.619221950531006, "Q2 loss": 10.553762493133545, "Mean Target Q": 617.0382431640625, "Mean Q1": 617.022193359375, "Mean Q2": 617.0240786132813, "critic_loss": 21.172984382629394, "batch_reward": 5.563844005584717, "actor_loss": -617.763435609879, "actor_target_entropy": -1.0, "actor_entropy": -0.20274581639997422, "alpha_loss": 0.0037967465374799023, "alpha_value": 0.18420775784409266, "duration": 161.64973783493042, "step": 41750}
{"episode_reward": 842.7779533562668, "episode": 335.0, "Q1 loss": 10.670689990997314, "Q2 loss": 10.679922523498535, "Mean Target Q": 617.8937607421875, "Mean Q1": 617.8969990234375, "Mean Q2": 617.89506640625, "critic_loss": 21.35061260986328, "batch_reward": 5.566395401000976, "actor_loss": -618.6989203559028, "actor_target_entropy": -1.0, "actor_entropy": -0.22185835147660876, "alpha_loss": 0.006798992702175701, "alpha_value": 0.18368671547723775, "duration": 142.76245760917664, "step": 41875}
{"episode_reward": 806.6120116920033, "episode": 336.0, "Q1 loss": 10.213940292358398, "Q2 loss": 10.15137106704712, "Mean Target Q": 618.3930595703125, "Mean Q1": 618.3937529296875, "Mean Q2": 618.3925673828124, "critic_loss": 20.36531134033203, "batch_reward": 5.555516326904297, "actor_loss": -618.7346004363029, "actor_target_entropy": -1.0, "actor_entropy": -0.2039521889340493, "alpha_loss": 0.0023635549568420938, "alpha_value": 0.18318435251336052, "duration": 154.62317180633545, "step": 42000}
{"episode_reward": 826.0998804291502, "episode": 337.0, "Q1 loss": 11.301787029266357, "Q2 loss": 11.300267036437988, "Mean Target Q": 619.1418349609374, "Mean Q1": 619.1315629882813, "Mean Q2": 619.1346147460938, "critic_loss": 22.602054107666017, "batch_reward": 5.553943996429443, "actor_loss": -619.8900446816097, "actor_target_entropy": -1.0, "actor_entropy": -0.25690451524560415, "alpha_loss": -0.005941695452386897, "alpha_value": 0.18342864183266502, "duration": 152.23498725891113, "step": 42125}
{"episode_reward": 839.833046868487, "episode": 338.0, "Q1 loss": 11.764870754241944, "Q2 loss": 11.695254528045654, "Mean Target Q": 620.1772934570313, "Mean Q1": 620.1765927734375, "Mean Q2": 620.1752529296875, "critic_loss": 23.460125244140624, "batch_reward": 5.566528060913086, "actor_loss": -620.9586880591607, "actor_target_entropy": -1.0, "actor_entropy": -0.2484836986949367, "alpha_loss": -0.006155262736889023, "alpha_value": 0.18392697270127564, "duration": 157.98773097991943, "step": 42250}
{"episode_reward": 777.1896644821408, "episode": 339.0, "Q1 loss": 9.63869927597046, "Q2 loss": 9.679431991577149, "Mean Target Q": 620.945736328125, "Mean Q1": 620.9408154296875, "Mean Q2": 620.9413305664062, "critic_loss": 19.31813133239746, "batch_reward": 5.58235429763794, "actor_loss": -621.6605631510416, "actor_target_entropy": -1.0, "actor_entropy": -0.249042575794553, "alpha_loss": -0.00024918554210296226, "alpha_value": 0.18419141840700667, "duration": 146.19969248771667, "step": 42375}
{"episode_reward": 823.934237466365, "episode": 340.0, "Q1 loss": 10.017673988342285, "Q2 loss": 9.997248722076415, "Mean Target Q": 621.88234375, "Mean Q1": 621.8928364257813, "Mean Q2": 621.8921064453125, "critic_loss": 20.014922706604004, "batch_reward": 5.586660270690918, "actor_loss": -622.5864720498362, "actor_target_entropy": -1.0, "actor_entropy": -0.2053016171820702, "alpha_loss": 0.007984279497196116, "alpha_value": 0.18395900292044562, "duration": 150.8817653656006, "step": 42500}
{"episode_reward": 830.2895356206951, "episode": 341.0, "Q1 loss": 10.142798728942871, "Q2 loss": 9.97719240951538, "Mean Target Q": 622.103080078125, "Mean Q1": 622.0981435546875, "Mean Q2": 622.0996020507813, "critic_loss": 20.119991180419923, "batch_reward": 5.568993980407715, "actor_loss": -622.8333003937252, "actor_target_entropy": -1.0, "actor_entropy": -0.22434960282038127, "alpha_loss": 0.0014195188044732999, "alpha_value": 0.18354637173310848, "duration": 160.04079222679138, "step": 42625}
{"episode_reward": 848.7163878314071, "episode": 342.0, "Q1 loss": 11.143068534851075, "Q2 loss": 11.09098667907715, "Mean Target Q": 623.0243569335937, "Mean Q1": 623.0149272460937, "Mean Q2": 623.0143876953125, "critic_loss": 22.234055168151855, "batch_reward": 5.573146053314209, "actor_loss": -623.6903401036417, "actor_target_entropy": -1.0, "actor_entropy": -0.19570485514498526, "alpha_loss": 0.007469602939372342, "alpha_value": 0.18320977727674156, "duration": 155.51140213012695, "step": 42750}
{"episode_reward": 846.8139622847733, "episode": 343.0, "Q1 loss": 11.745655513763428, "Q2 loss": 11.384488906860351, "Mean Target Q": 623.7680615234375, "Mean Q1": 623.7640537109374, "Mean Q2": 623.7633022460938, "critic_loss": 23.130144371032713, "batch_reward": 5.572420585632324, "actor_loss": -624.7627253456722, "actor_target_entropy": -1.0, "actor_entropy": -0.22815405612900144, "alpha_loss": 0.006592649744734878, "alpha_value": 0.1825180175407491, "duration": 166.95771050453186, "step": 42875}
{"episode_reward": 843.3086179614594, "episode": 344.0, "Q1 loss": 12.289472255706787, "Q2 loss": 12.344559814453126, "Mean Target Q": 624.4413276367187, "Mean Q1": 624.4378227539063, "Mean Q2": 624.438708984375, "critic_loss": 24.634032066345213, "batch_reward": 5.587546352386474, "actor_loss": -625.229715654927, "actor_target_entropy": -1.0, "actor_entropy": -0.22169928264714056, "alpha_loss": 0.0027806476780003115, "alpha_value": 0.18207929028024838, "duration": 166.4962887763977, "step": 43000}
{"episode_reward": 825.8646868804949, "episode": 345.0, "Q1 loss": 11.39723134613037, "Q2 loss": 11.371836791992187, "Mean Target Q": 624.9930654296875, "Mean Q1": 624.9996225585937, "Mean Q2": 624.99925, "critic_loss": 22.769068161010743, "batch_reward": 5.557995548248291, "actor_loss": -625.7210673983135, "actor_target_entropy": -1.0, "actor_entropy": -0.213740112407813, "alpha_loss": 0.0027795347758376647, "alpha_value": 0.18186692749500705, "duration": 160.08720517158508, "step": 43125}
{"episode_reward": 839.2107979590922, "episode": 346.0, "Q1 loss": 10.742078857421875, "Q2 loss": 10.766772087097168, "Mean Target Q": 625.7701704101562, "Mean Q1": 625.7606708984375, "Mean Q2": 625.760603515625, "critic_loss": 21.508850914001464, "batch_reward": 5.5805424880981445, "actor_loss": -626.2838380875125, "actor_target_entropy": -1.0, "actor_entropy": -0.22181711610286467, "alpha_loss": 0.0020543933271490516, "alpha_value": 0.18154872259478289, "duration": 161.89760541915894, "step": 43250}
{"episode_reward": 820.326077313519, "episode": 347.0, "Q1 loss": 10.625425765991212, "Q2 loss": 10.63141191482544, "Mean Target Q": 627.1108364257813, "Mean Q1": 627.1089096679688, "Mean Q2": 627.1059794921875, "critic_loss": 21.256837699890138, "batch_reward": 5.609717937469482, "actor_loss": -627.8921382843502, "actor_target_entropy": -1.0, "actor_entropy": -0.21476242265530995, "alpha_loss": 0.009283278606802461, "alpha_value": 0.1812508178745677, "duration": 151.28739738464355, "step": 43375}
{"episode_reward": 829.8246121880853, "episode": 348.0, "Q1 loss": 11.382038303375245, "Q2 loss": 11.189531982421874, "Mean Target Q": 627.4852836914063, "Mean Q1": 627.4833090820313, "Mean Q2": 627.4838515625, "critic_loss": 22.571570266723633, "batch_reward": 5.6043224639892575, "actor_loss": -628.0122454243321, "actor_target_entropy": -1.0, "actor_entropy": -0.2190821260934876, "alpha_loss": 0.0034350231947046857, "alpha_value": 0.18059667800455761, "duration": 159.47835206985474, "step": 43500}
{"episode_reward": 835.7637628244155, "episode": 349.0, "Q1 loss": 10.577914932250977, "Q2 loss": 10.574736194610596, "Mean Target Q": 628.2383994140625, "Mean Q1": 628.2335395507813, "Mean Q2": 628.2319331054688, "critic_loss": 21.152651245117188, "batch_reward": 5.599922611236572, "actor_loss": -628.8931410047743, "actor_target_entropy": -1.0, "actor_entropy": -0.24654844332308995, "alpha_loss": 0.0014874628515884516, "alpha_value": 0.18042684980781834, "duration": 159.02373147010803, "step": 43625}
{"episode_reward": 822.2659783650548, "episode": 350.0, "Q1 loss": 10.450862773895263, "Q2 loss": 10.435330047607422, "Mean Target Q": 629.1313681640625, "Mean Q1": 629.135515625, "Mean Q2": 629.1391015625, "critic_loss": 20.88619277191162, "batch_reward": 5.612774421691895, "actor_loss": -629.5820863785282, "actor_target_entropy": -1.0, "actor_entropy": -0.22478270963315042, "alpha_loss": 0.0024620436898042117, "alpha_value": 0.18016503104226989, "duration": 152.9660964012146, "step": 43750}
{"episode_reward": 840.5653800356545, "episode": 351.0, "Q1 loss": 10.220704986572265, "Q2 loss": 10.302928478240966, "Mean Target Q": 629.7237607421876, "Mean Q1": 629.7224731445312, "Mean Q2": 629.723623046875, "critic_loss": 20.523633422851564, "batch_reward": 5.6115472068786625, "actor_loss": -630.4849020337301, "actor_target_entropy": -1.0, "actor_entropy": -0.2471806520507449, "alpha_loss": 0.003937309663299294, "alpha_value": 0.17994273748508535, "duration": 148.666827917099, "step": 43875}
{"episode_reward": 838.5970534297874, "episode": 352.0, "Q1 loss": 9.571260353088379, "Q2 loss": 9.52086280822754, "Mean Target Q": 630.4877846679688, "Mean Q1": 630.4806352539063, "Mean Q2": 630.4808408203126, "critic_loss": 19.0921231842041, "batch_reward": 5.618294940948486, "actor_loss": -631.0856461063509, "actor_target_entropy": -1.0, "actor_entropy": -0.21117725607848936, "alpha_loss": 0.009534900681295942, "alpha_value": 0.17941888700726769, "duration": 164.6432158946991, "step": 44000}
{"episode_reward": 819.5276600828561, "episode": 353.0, "Q1 loss": 10.244676162719726, "Q2 loss": 10.202348346710204, "Mean Target Q": 630.8403271484375, "Mean Q1": 630.8458056640625, "Mean Q2": 630.8439731445312, "critic_loss": 20.447024543762208, "batch_reward": 5.613757202148437, "actor_loss": -631.4163915240575, "actor_target_entropy": -1.0, "actor_entropy": -0.22293168318177026, "alpha_loss": 0.004465512639384658, "alpha_value": 0.17877963479249587, "duration": 155.93563747406006, "step": 44125}
{"episode_reward": 814.9604649844994, "episode": 354.0, "Q1 loss": 11.496384185791015, "Q2 loss": 11.33930260848999, "Mean Target Q": 631.9445068359375, "Mean Q1": 631.9396103515625, "Mean Q2": 631.9383959960937, "critic_loss": 22.83568673706055, "batch_reward": 5.626460037231445, "actor_loss": -632.4664119597404, "actor_target_entropy": -1.0, "actor_entropy": -0.1815816798517781, "alpha_loss": 0.011408441358305994, "alpha_value": 0.17813647840860708, "duration": 155.3325309753418, "step": 44250}
{"episode_reward": 815.1498265194072, "episode": 355.0, "Q1 loss": 9.678056522369385, "Q2 loss": 9.710465618133545, "Mean Target Q": 632.443185546875, "Mean Q1": 632.43562890625, "Mean Q2": 632.43801953125, "critic_loss": 19.38852214050293, "batch_reward": 5.6111454582214355, "actor_loss": -633.3968728686136, "actor_target_entropy": -1.0, "actor_entropy": -0.18334166350818815, "alpha_loss": 0.011144547235398065, "alpha_value": 0.1771322423237961, "duration": 169.00529146194458, "step": 44375}
{"episode_reward": 835.0260712512141, "episode": 356.0, "Q1 loss": 9.88072072982788, "Q2 loss": 9.895532424926758, "Mean Target Q": 633.1848642578125, "Mean Q1": 633.1815737304687, "Mean Q2": 633.1806938476562, "critic_loss": 19.776253204345704, "batch_reward": 5.6285864448547365, "actor_loss": -633.8324683404738, "actor_target_entropy": -1.0, "actor_entropy": -0.24216812320293918, "alpha_loss": 0.003246137339081014, "alpha_value": 0.176694896910429, "duration": 149.92790269851685, "step": 44500}
{"episode_reward": 835.8490925732286, "episode": 357.0, "Q1 loss": 10.874779476165772, "Q2 loss": 10.973013069152833, "Mean Target Q": 633.7784077148438, "Mean Q1": 633.7749077148437, "Mean Q2": 633.7757944335938, "critic_loss": 21.847792572021483, "batch_reward": 5.623152141571045, "actor_loss": -634.3574015299479, "actor_target_entropy": -1.0, "actor_entropy": -0.21832001705964407, "alpha_loss": 0.0009701090184823861, "alpha_value": 0.17633542121481788, "duration": 150.67780208587646, "step": 44625}
{"episode_reward": 834.0573391369757, "episode": 358.0, "Q1 loss": 10.527171283721923, "Q2 loss": 10.441089633941651, "Mean Target Q": 634.648458984375, "Mean Q1": 634.6446801757812, "Mean Q2": 634.641408203125, "critic_loss": 20.96826081085205, "batch_reward": 5.641144287109375, "actor_loss": -635.4961646295363, "actor_target_entropy": -1.0, "actor_entropy": -0.2657433116147595, "alpha_loss": -0.0007649822340857598, "alpha_value": 0.176416127629903, "duration": 154.67624807357788, "step": 44750}
{"episode_reward": 848.5055027161476, "episode": 359.0, "Q1 loss": 9.239257450103759, "Q2 loss": 9.321475200653076, "Mean Target Q": 635.1808686523437, "Mean Q1": 635.1847861328125, "Mean Q2": 635.187513671875, "critic_loss": 18.560732681274413, "batch_reward": 5.624902446746826, "actor_loss": -636.0830552842882, "actor_target_entropy": -1.0, "actor_entropy": -0.24063851388673935, "alpha_loss": 0.004451206632121097, "alpha_value": 0.17618231379544216, "duration": 146.85912132263184, "step": 44875}
{"episode_reward": 838.1166506434365, "episode": 360.0, "Q1 loss": 11.104873336791993, "Q2 loss": 10.891786678314208, "Mean Target Q": 636.117861328125, "Mean Q1": 636.1119731445312, "Mean Q2": 636.1102563476562, "critic_loss": 21.996660026550295, "batch_reward": 5.6431566467285155, "actor_loss": -636.7942632859753, "actor_target_entropy": -1.0, "actor_entropy": -0.26195582362913317, "alpha_loss": 0.0019645592115158515, "alpha_value": 0.17605594961929313, "step": 45000}
{"duration": 175.0072319507599, "step": 45000}
{"episode_reward": 838.1398136196018, "episode": 361.0, "Q1 loss": 10.396429492950439, "Q2 loss": 10.577436779022216, "Mean Target Q": 636.7379853515625, "Mean Q1": 636.7365249023437, "Mean Q2": 636.7372280273438, "critic_loss": 20.97386629486084, "batch_reward": 5.647910053253174, "actor_loss": -637.4755481538318, "actor_target_entropy": -1.0, "actor_entropy": -0.21598502520530943, "alpha_loss": 0.008846456624774469, "alpha_value": 0.17556435075522292, "duration": 154.01341891288757, "step": 45125}
{"episode_reward": 830.1258707388071, "episode": 362.0, "Q1 loss": 9.368754425048827, "Q2 loss": 9.374808368682862, "Mean Target Q": 637.2618583984375, "Mean Q1": 637.2625913085938, "Mean Q2": 637.26276171875, "critic_loss": 18.74356280517578, "batch_reward": 5.647033924102783, "actor_loss": -638.2727474089592, "actor_target_entropy": -1.0, "actor_entropy": -0.20626845102637045, "alpha_loss": 0.00691319569840186, "alpha_value": 0.17485889037448651, "duration": 149.88319540023804, "step": 45250}
{"episode_reward": 838.4489950410768, "episode": 363.0, "Q1 loss": 9.213295429229737, "Q2 loss": 9.082466144561767, "Mean Target Q": 638.11138671875, "Mean Q1": 638.0992978515625, "Mean Q2": 638.0989985351563, "critic_loss": 18.29576153564453, "batch_reward": 5.6639772911071775, "actor_loss": -638.5241912357391, "actor_target_entropy": -1.0, "actor_entropy": -0.2557003384544736, "alpha_loss": -0.0005693030783847447, "alpha_value": 0.17467189289620094, "duration": 154.72609090805054, "step": 45375}
{"episode_reward": 844.9911437044657, "episode": 364.0, "Q1 loss": 9.83081203842163, "Q2 loss": 9.90558824157715, "Mean Target Q": 638.5339892578126, "Mean Q1": 638.537603515625, "Mean Q2": 638.53846484375, "critic_loss": 19.736400299072265, "batch_reward": 5.636268371582031, "actor_loss": -639.0720913794732, "actor_target_entropy": -1.0, "actor_entropy": -0.25853434902045036, "alpha_loss": 0.0017593732899835995, "alpha_value": 0.17458861627230307, "duration": 144.36740684509277, "step": 45500}
{"episode_reward": 835.5965964344059, "episode": 365.0, "Q1 loss": 9.27662168121338, "Q2 loss": 9.291259651184083, "Mean Target Q": 639.5050249023437, "Mean Q1": 639.5091040039063, "Mean Q2": 639.5083461914063, "critic_loss": 18.56788136291504, "batch_reward": 5.646570232391357, "actor_loss": -640.0313197544643, "actor_target_entropy": -1.0, "actor_entropy": -0.25777938181445714, "alpha_loss": -0.004238200189161395, "alpha_value": 0.1746430761343245, "duration": 157.08647799491882, "step": 45625}
{"episode_reward": 823.5682482093936, "episode": 366.0, "Q1 loss": 9.453079008102417, "Q2 loss": 9.482527290344239, "Mean Target Q": 639.8479497070313, "Mean Q1": 639.8461528320313, "Mean Q2": 639.8466323242187, "critic_loss": 18.935606315612795, "batch_reward": 5.648861972808838, "actor_loss": -640.6988289125504, "actor_target_entropy": -1.0, "actor_entropy": -0.2327054537111713, "alpha_loss": 0.005514674127146962, "alpha_value": 0.174641905417572, "duration": 158.64327549934387, "step": 45750}
{"episode_reward": 822.1923900614353, "episode": 367.0, "Q1 loss": 10.330321453094482, "Q2 loss": 10.268921619415282, "Mean Target Q": 640.8194018554688, "Mean Q1": 640.8189140625, "Mean Q2": 640.8179370117188, "critic_loss": 20.59924304962158, "batch_reward": 5.6637234878540035, "actor_loss": -641.7624715169271, "actor_target_entropy": -1.0, "actor_entropy": -0.2602584049815223, "alpha_loss": 0.005021734033814735, "alpha_value": 0.17432161955051056, "duration": 160.80872583389282, "step": 45875}
{"episode_reward": 828.9886548849962, "episode": 368.0, "Q1 loss": 9.954156642913818, "Q2 loss": 9.918507831573486, "Mean Target Q": 641.7618447265625, "Mean Q1": 641.7518349609375, "Mean Q2": 641.7509438476562, "critic_loss": 19.872664527893065, "batch_reward": 5.685373783111572, "actor_loss": -642.3757727838332, "actor_target_entropy": -1.0, "actor_entropy": -0.2194757901372448, "alpha_loss": 0.0048809809677843605, "alpha_value": 0.17365120000703152, "duration": 151.5813765525818, "step": 46000}
{"episode_reward": 823.8506026222833, "episode": 369.0, "Q1 loss": 9.359976318359376, "Q2 loss": 9.433294048309326, "Mean Target Q": 641.7408129882813, "Mean Q1": 641.7331508789063, "Mean Q2": 641.7346958007812, "critic_loss": 18.79327040863037, "batch_reward": 5.654981994628907, "actor_loss": -642.3550899445064, "actor_target_entropy": -1.0, "actor_entropy": -0.20578623693140727, "alpha_loss": 0.008949638237171466, "alpha_value": 0.1732359193223361, "duration": 146.96316647529602, "step": 46125}
{"episode_reward": 832.784031433885, "episode": 370.0, "Q1 loss": 9.552335948944092, "Q2 loss": 9.566774017333984, "Mean Target Q": 642.351255859375, "Mean Q1": 642.3509853515625, "Mean Q2": 642.3530512695313, "critic_loss": 19.11910996246338, "batch_reward": 5.647543735504151, "actor_loss": -642.98779789094, "actor_target_entropy": -1.0, "actor_entropy": -0.25006356018204845, "alpha_loss": 0.006094740883957955, "alpha_value": 0.17248004048548968, "duration": 148.75753736495972, "step": 46250}
{"episode_reward": 832.7858537658162, "episode": 371.0, "Q1 loss": 9.00467991256714, "Q2 loss": 9.00047123336792, "Mean Target Q": 643.0646049804687, "Mean Q1": 643.0670883789063, "Mean Q2": 643.064603515625, "critic_loss": 18.00515114593506, "batch_reward": 5.662365047454834, "actor_loss": -643.9063856336805, "actor_target_entropy": -1.0, "actor_entropy": -0.3117648195179682, "alpha_loss": -0.001396916222773374, "alpha_value": 0.17241253401830967, "duration": 151.32382798194885, "step": 46375}
{"episode_reward": 848.9229546071638, "episode": 372.0, "Q1 loss": 9.349256614685059, "Q2 loss": 9.336385597229004, "Mean Target Q": 643.820087890625, "Mean Q1": 643.8117778320312, "Mean Q2": 643.8132006835938, "critic_loss": 18.685642311096192, "batch_reward": 5.665631023406982, "actor_loss": -644.352776312059, "actor_target_entropy": -1.0, "actor_entropy": -0.2957262598699139, "alpha_loss": 0.0014516112128002269, "alpha_value": 0.172368306468761, "duration": 151.0431773662567, "step": 46500}
{"episode_reward": 823.8119721394263, "episode": 373.0, "Q1 loss": 9.691235580444335, "Q2 loss": 9.685964267730713, "Mean Target Q": 644.4112485351562, "Mean Q1": 644.4183852539062, "Mean Q2": 644.41705078125, "critic_loss": 19.37719984436035, "batch_reward": 5.675869689941406, "actor_loss": -645.3293912372892, "actor_target_entropy": -1.0, "actor_entropy": -0.2844040590146231, "alpha_loss": -0.0031502865022048354, "alpha_value": 0.17236186903456757, "duration": 145.00724864006042, "step": 46625}
{"episode_reward": 765.8959247251222, "episode": 374.0, "Q1 loss": 9.660514427185058, "Q2 loss": 9.827728843688964, "Mean Target Q": 644.8361962890625, "Mean Q1": 644.8254951171875, "Mean Q2": 644.8276650390625, "critic_loss": 19.488243255615235, "batch_reward": 5.657352096557617, "actor_loss": -645.9133704400832, "actor_target_entropy": -1.0, "actor_entropy": -0.2677311390157669, "alpha_loss": 0.0006241578037940687, "alpha_value": 0.17243486339779454, "duration": 154.73312044143677, "step": 46750}
{"episode_reward": 827.4495375130499, "episode": 375.0, "Q1 loss": 10.36240097808838, "Q2 loss": 10.26476118850708, "Mean Target Q": 645.4429990234376, "Mean Q1": 645.4439873046875, "Mean Q2": 645.4410888671875, "critic_loss": 20.62716214752197, "batch_reward": 5.6614557571411135, "actor_loss": -646.0555875263517, "actor_target_entropy": -1.0, "actor_entropy": -0.2768840408987469, "alpha_loss": 0.001418687331135429, "alpha_value": 0.1724333681983482, "duration": 151.7990071773529, "step": 46875}
{"episode_reward": 840.6135978874764, "episode": 376.0, "Q1 loss": 9.268961265563965, "Q2 loss": 9.311074806213378, "Mean Target Q": 646.6463178710937, "Mean Q1": 646.6540610351562, "Mean Q2": 646.6568305664063, "critic_loss": 18.58003600311279, "batch_reward": 5.69230574798584, "actor_loss": -647.2450325258317, "actor_target_entropy": -1.0, "actor_entropy": -0.27646484898944057, "alpha_loss": 0.0016763431823722298, "alpha_value": 0.1722820954578758, "duration": 163.20649433135986, "step": 47000}
{"episode_reward": 841.4965227645268, "episode": 377.0, "Q1 loss": 9.783773544311524, "Q2 loss": 9.917721347808838, "Mean Target Q": 646.93531640625, "Mean Q1": 646.9271474609375, "Mean Q2": 646.9231655273437, "critic_loss": 19.70149493408203, "batch_reward": 5.697612373352051, "actor_loss": -647.6085486033606, "actor_target_entropy": -1.0, "actor_entropy": -0.2777748973596664, "alpha_loss": -0.001439402083171502, "alpha_value": 0.1722815199057078, "duration": 150.01404809951782, "step": 47125}
{"episode_reward": 839.00172678008, "episode": 378.0, "Q1 loss": 9.41361581802368, "Q2 loss": 9.537726348876953, "Mean Target Q": 647.4026689453125, "Mean Q1": 647.3979213867187, "Mean Q2": 647.3973989257812, "critic_loss": 18.951342193603516, "batch_reward": 5.687780590057373, "actor_loss": -648.070788967994, "actor_target_entropy": -1.0, "actor_entropy": -0.25232429273666873, "alpha_loss": 0.0046044979826547205, "alpha_value": 0.1721685463587319, "duration": 147.02103233337402, "step": 47250}
{"episode_reward": 845.4128097476779, "episode": 379.0, "Q1 loss": 10.329134063720703, "Q2 loss": 10.188668300628661, "Mean Target Q": 648.1583579101563, "Mean Q1": 648.1619262695312, "Mean Q2": 648.1633369140625, "critic_loss": 20.517802391052246, "batch_reward": 5.689105773925781, "actor_loss": -648.8298766121031, "actor_target_entropy": -1.0, "actor_entropy": -0.227545089428387, "alpha_loss": 0.005634145323364507, "alpha_value": 0.17162055153204855, "duration": 153.6247992515564, "step": 47375}
{"episode_reward": 833.5065397835679, "episode": 380.0, "Q1 loss": 9.884857757568358, "Q2 loss": 9.870572875976562, "Mean Target Q": 648.2606098632813, "Mean Q1": 648.2571127929688, "Mean Q2": 648.2572412109375, "critic_loss": 19.755430610656738, "batch_reward": 5.656050910949707, "actor_loss": -648.8485658707157, "actor_target_entropy": -1.0, "actor_entropy": -0.2563783675432205, "alpha_loss": -0.000906934420908651, "alpha_value": 0.17164454083697644, "duration": 146.65490865707397, "step": 47500}
{"episode_reward": 828.4007705717976, "episode": 381.0, "Q1 loss": 10.109680660247802, "Q2 loss": 10.104927207946778, "Mean Target Q": 649.0919077148437, "Mean Q1": 649.0895380859375, "Mean Q2": 649.090779296875, "critic_loss": 20.21460787963867, "batch_reward": 5.689566608428955, "actor_loss": -649.7738860599578, "actor_target_entropy": -1.0, "actor_entropy": -0.2254472611442445, "alpha_loss": 0.000999103538647649, "alpha_value": 0.17164244195998105, "duration": 150.21853160858154, "step": 47625}
{"episode_reward": 849.2701260003554, "episode": 382.0, "Q1 loss": 9.41200339126587, "Q2 loss": 9.450882884979247, "Mean Target Q": 650.1224780273437, "Mean Q1": 650.1167290039062, "Mean Q2": 650.1166430664063, "critic_loss": 18.862886222839357, "batch_reward": 5.7120473747253415, "actor_loss": -650.7712067634828, "actor_target_entropy": -1.0, "actor_entropy": -0.25573391371196313, "alpha_loss": -0.0012603096716526535, "alpha_value": 0.17153118029371214, "duration": 150.09355115890503, "step": 47750}
{"episode_reward": 827.9376138676155, "episode": 383.0, "Q1 loss": 8.860769580841064, "Q2 loss": 8.738599647521973, "Mean Target Q": 650.6181284179687, "Mean Q1": 650.6184672851563, "Mean Q2": 650.6182856445313, "critic_loss": 17.599369178771973, "batch_reward": 5.710549606323243, "actor_loss": -651.4674091641865, "actor_target_entropy": -1.0, "actor_entropy": -0.2572303161261574, "alpha_loss": 0.002202032311331658, "alpha_value": 0.1715401226914659, "duration": 149.8912603855133, "step": 47875}
{"episode_reward": 830.5169961700243, "episode": 384.0, "Q1 loss": 9.446637153625488, "Q2 loss": 9.60503483581543, "Mean Target Q": 651.1770454101562, "Mean Q1": 651.1705576171875, "Mean Q2": 651.16965625, "critic_loss": 19.051671951293944, "batch_reward": 5.701051067352295, "actor_loss": -651.9216564547631, "actor_target_entropy": -1.0, "actor_entropy": -0.23893097307412856, "alpha_loss": 0.003978367033039009, "alpha_value": 0.17125722156075404, "duration": 157.0073070526123, "step": 48000}
{"episode_reward": 838.6219381357109, "episode": 385.0, "Q1 loss": 9.393704734802245, "Q2 loss": 9.346022785186767, "Mean Target Q": 651.4814477539062, "Mean Q1": 651.4776391601563, "Mean Q2": 651.4787758789063, "critic_loss": 18.739727493286132, "batch_reward": 5.680148605346679, "actor_loss": -651.9819955977183, "actor_target_entropy": -1.0, "actor_entropy": -0.2368471577527031, "alpha_loss": 0.0016043450469003311, "alpha_value": 0.1710787639178047, "duration": 154.776221036911, "step": 48125}
{"episode_reward": 844.9219734440279, "episode": 386.0, "Q1 loss": 8.9645422000885, "Q2 loss": 8.883449935913086, "Mean Target Q": 652.5789326171875, "Mean Q1": 652.582341796875, "Mean Q2": 652.5822607421875, "critic_loss": 17.84799210357666, "batch_reward": 5.718112892150879, "actor_loss": -653.1240628150201, "actor_target_entropy": -1.0, "actor_entropy": -0.21661464124917984, "alpha_loss": 0.008904100699921048, "alpha_value": 0.17057763521923977, "duration": 152.2989649772644, "step": 48250}
{"episode_reward": 806.6366655875651, "episode": 387.0, "Q1 loss": 9.689074886322022, "Q2 loss": 9.737795753479004, "Mean Target Q": 653.0679067382813, "Mean Q1": 653.0620244140625, "Mean Q2": 653.0622666015626, "critic_loss": 19.426870628356934, "batch_reward": 5.705484237670898, "actor_loss": -653.4597991458953, "actor_target_entropy": -1.0, "actor_entropy": -0.25824368792393854, "alpha_loss": -0.0004802227245702867, "alpha_value": 0.17021195040988177, "duration": 142.22147297859192, "step": 48375}
{"episode_reward": 823.9521386545144, "episode": 388.0, "Q1 loss": 9.937174396514893, "Q2 loss": 9.774037014007568, "Mean Target Q": 653.647908203125, "Mean Q1": 653.6529765625, "Mean Q2": 653.6507802734375, "critic_loss": 19.711211448669435, "batch_reward": 5.714600456237793, "actor_loss": -654.288793748425, "actor_target_entropy": -1.0, "actor_entropy": -0.22430005200928257, "alpha_loss": 0.006060925819310209, "alpha_value": 0.16987482053414688, "duration": 155.78250980377197, "step": 48500}
{"episode_reward": 829.2478558752566, "episode": 389.0, "Q1 loss": 9.444414321899414, "Q2 loss": 9.39066535949707, "Mean Target Q": 654.056029296875, "Mean Q1": 654.0502529296875, "Mean Q2": 654.0532504882813, "critic_loss": 18.835079650878907, "batch_reward": 5.719559894561767, "actor_loss": -654.9075181749132, "actor_target_entropy": -1.0, "actor_entropy": -0.2212932086180127, "alpha_loss": 0.0018782785258418511, "alpha_value": 0.16958239865078945, "duration": 151.85522651672363, "step": 48625}
{"episode_reward": 754.9111569679478, "episode": 390.0, "Q1 loss": 8.831756084442139, "Q2 loss": 9.067523078918457, "Mean Target Q": 654.4351669921875, "Mean Q1": 654.42854296875, "Mean Q2": 654.4272202148437, "critic_loss": 17.899279205322266, "batch_reward": 5.6970476760864255, "actor_loss": -655.3311629756804, "actor_target_entropy": -1.0, "actor_entropy": -0.25121155549441615, "alpha_loss": -0.001963779149058786, "alpha_value": 0.16954353447186085, "duration": 160.49130153656006, "step": 48750}
{"episode_reward": 833.8998662057104, "episode": 391.0, "Q1 loss": 9.116420143127442, "Q2 loss": 8.96224686050415, "Mean Target Q": 655.0694174804687, "Mean Q1": 655.0779575195312, "Mean Q2": 655.0768657226563, "critic_loss": 18.07866700744629, "batch_reward": 5.712594253540039, "actor_loss": -655.7599545433408, "actor_target_entropy": -1.0, "actor_entropy": -0.26535962320982465, "alpha_loss": -0.0018989977108994647, "alpha_value": 0.16975020098181404, "duration": 158.10923600196838, "step": 48875}
{"episode_reward": 845.3747723579763, "episode": 392.0, "Q1 loss": 9.259562618255615, "Q2 loss": 9.192805782318116, "Mean Target Q": 655.4909306640625, "Mean Q1": 655.4805639648438, "Mean Q2": 655.4796357421875, "critic_loss": 18.45236837768555, "batch_reward": 5.69902458190918, "actor_loss": -656.105721750567, "actor_target_entropy": -1.0, "actor_entropy": -0.24623763657385303, "alpha_loss": -0.001776012370453006, "alpha_value": 0.1699379134127282, "duration": 161.12099027633667, "step": 49000}
{"episode_reward": 844.2519955555279, "episode": 393.0, "Q1 loss": 9.386886459350587, "Q2 loss": 9.355549209594727, "Mean Target Q": 656.6300424804688, "Mean Q1": 656.6304887695312, "Mean Q2": 656.63125, "critic_loss": 18.74243571472168, "batch_reward": 5.735402156829834, "actor_loss": -656.9404752216642, "actor_target_entropy": -1.0, "actor_entropy": -0.23279125278904325, "alpha_loss": 8.03318421637255e-05, "alpha_value": 0.1699372566123575, "duration": 144.25186038017273, "step": 49125}
{"episode_reward": 827.3399739039304, "episode": 394.0, "Q1 loss": 9.18945146560669, "Q2 loss": 9.120936367034911, "Mean Target Q": 657.1199379882812, "Mean Q1": 657.1189921875, "Mean Q2": 657.1184565429687, "critic_loss": 18.310387893676758, "batch_reward": 5.730379470825195, "actor_loss": -657.8745599562122, "actor_target_entropy": -1.0, "actor_entropy": -0.3064628962066866, "alpha_loss": -0.001511369131490468, "alpha_value": 0.1700587170293851, "duration": 161.13545656204224, "step": 49250}
{"episode_reward": 831.5794820802694, "episode": 395.0, "Q1 loss": 9.33857036972046, "Q2 loss": 9.261224683761597, "Mean Target Q": 657.5348056640624, "Mean Q1": 657.5356772460938, "Mean Q2": 657.5358515625, "critic_loss": 18.599795066833497, "batch_reward": 5.734959690093994, "actor_loss": -658.3359462193081, "actor_target_entropy": -1.0, "actor_entropy": -0.2730516221315142, "alpha_loss": 0.002016234649567022, "alpha_value": 0.17010714494746515, "duration": 152.94144558906555, "step": 49375}
{"episode_reward": 840.1938084412307, "episode": 396.0, "Q1 loss": 8.91881286239624, "Q2 loss": 8.833757099151612, "Mean Target Q": 658.1596650390625, "Mean Q1": 658.1559013671875, "Mean Q2": 658.157982421875, "critic_loss": 17.752569946289064, "batch_reward": 5.738379425048828, "actor_loss": -658.7039194414692, "actor_target_entropy": -1.0, "actor_entropy": -0.29765404039813625, "alpha_loss": -0.005372622271909589, "alpha_value": 0.17032377532129264, "duration": 149.97042417526245, "step": 49500}
{"episode_reward": 834.894254080438, "episode": 397.0, "Q1 loss": 9.058709419250489, "Q2 loss": 9.007075296401977, "Mean Target Q": 658.4238422851563, "Mean Q1": 658.4227631835937, "Mean Q2": 658.42040234375, "critic_loss": 18.0657847366333, "batch_reward": 5.7195156478881835, "actor_loss": -658.7852715386284, "actor_target_entropy": -1.0, "actor_entropy": -0.2408334156350484, "alpha_loss": 0.002905898986177312, "alpha_value": 0.1701852328937155, "duration": 157.122882604599, "step": 49625}
{"episode_reward": 837.0654725915208, "episode": 398.0, "Q1 loss": 9.80040497970581, "Q2 loss": 9.832281661987304, "Mean Target Q": 659.281837890625, "Mean Q1": 659.27625390625, "Mean Q2": 659.2784252929688, "critic_loss": 19.632686695098876, "batch_reward": 5.742683036804199, "actor_loss": -660.0745465678554, "actor_target_entropy": -1.0, "actor_entropy": -0.21556907147169113, "alpha_loss": 0.011645617032979404, "alpha_value": 0.16978118296256953, "duration": 162.94839644432068, "step": 49750}
{"episode_reward": 832.150487075145, "episode": 399.0, "Q1 loss": 8.710323181152344, "Q2 loss": 8.667558036804198, "Mean Target Q": 659.7386049804687, "Mean Q1": 659.74054296875, "Mean Q2": 659.740509765625, "critic_loss": 17.37788125991821, "batch_reward": 5.737193923950195, "actor_loss": -660.2215324280754, "actor_target_entropy": -1.0, "actor_entropy": -0.24251014609185476, "alpha_loss": 0.002187250063769401, "alpha_value": 0.16900542475615765, "duration": 155.8061990737915, "step": 49875}
{"episode_reward": 835.3781720219205, "episode": 400.0, "Q1 loss": 8.860988718032837, "Q2 loss": 9.032491559982299, "Mean Target Q": 660.2220146484375, "Mean Q1": 660.2137470703125, "Mean Q2": 660.2116684570312, "critic_loss": 17.893480209350585, "batch_reward": 5.7448260231018065, "actor_loss": -660.7763327321699, "actor_target_entropy": -1.0, "actor_entropy": -0.2722164219425571, "alpha_loss": 0.00296546803644648, "alpha_value": 0.16880403610362965, "step": 50000}
{"duration": 178.21789932250977, "step": 50000}
{"episode_reward": 842.0137375795252, "episode": 401.0, "Q1 loss": 9.139571281433106, "Q2 loss": 9.14031580734253, "Mean Target Q": 660.7702880859375, "Mean Q1": 660.7727338867187, "Mean Q2": 660.774576171875, "critic_loss": 18.27988714981079, "batch_reward": 5.744642105102539, "actor_loss": -661.4847615559896, "actor_target_entropy": -1.0, "actor_entropy": -0.23910250479266756, "alpha_loss": 0.004661660927850458, "alpha_value": 0.1684736547358792, "duration": 173.6622190475464, "step": 50125}
{"episode_reward": 830.2582621055597, "episode": 402.0, "Q1 loss": 9.12751481628418, "Q2 loss": 9.036290088653564, "Mean Target Q": 660.9522280273437, "Mean Q1": 660.94688671875, "Mean Q2": 660.9481684570312, "critic_loss": 18.16380492401123, "batch_reward": 5.734738697052002, "actor_loss": -661.4827683971774, "actor_target_entropy": -1.0, "actor_entropy": -0.27055755954596306, "alpha_loss": 0.0006473245373326204, "alpha_value": 0.16847190090539443, "duration": 152.9917140007019, "step": 50250}
{"episode_reward": 838.4460573010182, "episode": 403.0, "Q1 loss": 9.016605060577392, "Q2 loss": 8.998734462738037, "Mean Target Q": 661.6581313476562, "Mean Q1": 661.6608701171875, "Mean Q2": 661.65680078125, "critic_loss": 18.015339599609376, "batch_reward": 5.730447383880615, "actor_loss": -662.2856493753101, "actor_target_entropy": -1.0, "actor_entropy": -0.2531930108865102, "alpha_loss": 0.005648254435361614, "alpha_value": 0.1679701804077762, "duration": 160.02287459373474, "step": 50375}
{"episode_reward": 838.4408046144099, "episode": 404.0, "Q1 loss": 9.700222900390624, "Q2 loss": 9.758415481567383, "Mean Target Q": 662.043140625, "Mean Q1": 662.041380859375, "Mean Q2": 662.044119140625, "critic_loss": 19.458638374328615, "batch_reward": 5.735068367004395, "actor_loss": -662.6521192981351, "actor_target_entropy": -1.0, "actor_entropy": -0.2768208817128212, "alpha_loss": -0.0006317405965209248, "alpha_value": 0.16783646758681278, "duration": 152.7706971168518, "step": 50500}
{"episode_reward": 838.0333726831643, "episode": 405.0, "Q1 loss": 8.99516211128235, "Q2 loss": 9.016270404815673, "Mean Target Q": 663.0252109375, "Mean Q1": 663.02266796875, "Mean Q2": 663.022419921875, "critic_loss": 18.011432460784913, "batch_reward": 5.758595390319824, "actor_loss": -663.4599270290798, "actor_target_entropy": -1.0, "actor_entropy": -0.2658484223343077, "alpha_loss": 0.001691931016033604, "alpha_value": 0.1678976301538832, "duration": 152.1509494781494, "step": 50625}
{"episode_reward": 840.5407525303359, "episode": 406.0, "Q1 loss": 9.487127773284913, "Q2 loss": 9.26487833404541, "Mean Target Q": 663.5013061523438, "Mean Q1": 663.4939375, "Mean Q2": 663.4947875976562, "critic_loss": 18.75200612640381, "batch_reward": 5.760333896636963, "actor_loss": -664.1339308215726, "actor_target_entropy": -1.0, "actor_entropy": -0.262319179792558, "alpha_loss": 0.0022343652334154375, "alpha_value": 0.16760190941979514, "duration": 158.56577110290527, "step": 50750}
{"episode_reward": 837.8314947177255, "episode": 407.0, "Q1 loss": 8.469204872131348, "Q2 loss": 8.458381935119629, "Mean Target Q": 664.0791611328125, "Mean Q1": 664.0780834960938, "Mean Q2": 664.0779741210938, "critic_loss": 16.927586853027343, "batch_reward": 5.762955924987793, "actor_loss": -664.8894808330233, "actor_target_entropy": -1.0, "actor_entropy": -0.2751575954376705, "alpha_loss": 0.0023174117807121504, "alpha_value": 0.16738759997510308, "duration": 149.38452816009521, "step": 50875}
{"episode_reward": 841.021263740868, "episode": 408.0, "Q1 loss": 8.632798122406006, "Q2 loss": 8.581259338378906, "Mean Target Q": 664.2787919921875, "Mean Q1": 664.2825810546875, "Mean Q2": 664.28042578125, "critic_loss": 17.214057441711425, "batch_reward": 5.751388530731202, "actor_loss": -664.8412071966355, "actor_target_entropy": -1.0, "actor_entropy": -0.2527311802391083, "alpha_loss": 0.0041059621557172745, "alpha_value": 0.1671151892500621, "duration": 133.75697946548462, "step": 51000}
{"episode_reward": 836.0610769435654, "episode": 409.0, "Q1 loss": 8.774646144866944, "Q2 loss": 8.797902156829833, "Mean Target Q": 664.8610981445313, "Mean Q1": 664.8581625976562, "Mean Q2": 664.857515625, "critic_loss": 17.572548385620117, "batch_reward": 5.76015926361084, "actor_loss": -665.3039637974331, "actor_target_entropy": -1.0, "actor_entropy": -0.2361759049078775, "alpha_loss": 0.00661075256010961, "alpha_value": 0.16667273819322312, "duration": 136.7858648300171, "step": 51125}
{"episode_reward": 834.618436969478, "episode": 410.0, "Q1 loss": 8.752012584686279, "Q2 loss": 8.796532402038574, "Mean Target Q": 665.5523393554688, "Mean Q1": 665.5469296875, "Mean Q2": 665.5499072265625, "critic_loss": 17.548544944763183, "batch_reward": 5.762493148803711, "actor_loss": -666.331057640814, "actor_target_entropy": -1.0, "actor_entropy": -0.2901247362456014, "alpha_loss": -0.0018321922360618988, "alpha_value": 0.16643635136683993, "duration": 141.8305857181549, "step": 51250}
{"episode_reward": 837.4491897542239, "episode": 411.0, "Q1 loss": 9.545174663543701, "Q2 loss": 9.42025053024292, "Mean Target Q": 665.8546313476562, "Mean Q1": 665.85465625, "Mean Q2": 665.8544208984375, "critic_loss": 18.965425193786622, "batch_reward": 5.755149417877197, "actor_loss": -666.5685618567088, "actor_target_entropy": -1.0, "actor_entropy": -0.27879920365318417, "alpha_loss": 0.0005118016500972093, "alpha_value": 0.1666320533783689, "duration": 136.6464500427246, "step": 51375}
{"episode_reward": 820.6397819081277, "episode": 412.0, "Q1 loss": 9.539231649398804, "Q2 loss": 9.552811130523681, "Mean Target Q": 666.2067045898438, "Mean Q1": 666.2074829101563, "Mean Q2": 666.208787109375, "critic_loss": 19.092042739868162, "batch_reward": 5.755401313781738, "actor_loss": -666.8512878417969, "actor_target_entropy": -1.0, "actor_entropy": -0.2853765497284551, "alpha_loss": -0.0016305617417298978, "alpha_value": 0.16651821997013985, "duration": 138.88700318336487, "step": 51500}
{"episode_reward": 820.5101516934819, "episode": 413.0, "Q1 loss": 9.540941844940185, "Q2 loss": 9.53210864830017, "Mean Target Q": 666.5612377929688, "Mean Q1": 666.5582377929687, "Mean Q2": 666.55723828125, "critic_loss": 19.073050529479982, "batch_reward": 5.748021854400635, "actor_loss": -667.1726858956473, "actor_target_entropy": -1.0, "actor_entropy": -0.2874236352859981, "alpha_loss": -0.0002947329499182247, "alpha_value": 0.16662903466972384, "duration": 140.60583400726318, "step": 51625}
{"episode_reward": 831.1647107616562, "episode": 414.0, "Q1 loss": 9.535221298217774, "Q2 loss": 9.660795330047607, "Mean Target Q": 667.3678032226562, "Mean Q1": 667.3638193359375, "Mean Q2": 667.3627416992188, "critic_loss": 19.196016563415526, "batch_reward": 5.778312183380127, "actor_loss": -668.032971782069, "actor_target_entropy": -1.0, "actor_entropy": -0.27191130648697576, "alpha_loss": 0.004013088270796523, "alpha_value": 0.1666267812448411, "duration": 129.74445104599, "step": 51750}
{"episode_reward": 828.735509158926, "episode": 415.0, "Q1 loss": 8.61009846496582, "Q2 loss": 8.545137023925781, "Mean Target Q": 667.8540727539063, "Mean Q1": 667.8545888671875, "Mean Q2": 667.8560810546875, "critic_loss": 17.15523554611206, "batch_reward": 5.770207145690918, "actor_loss": -668.7890189034598, "actor_target_entropy": -1.0, "actor_entropy": -0.2632198546613966, "alpha_loss": 0.003240750337551747, "alpha_value": 0.16605409062882265, "duration": 134.75253582000732, "step": 51875}
{"episode_reward": 847.1339349480169, "episode": 416.0, "Q1 loss": 8.548248348236084, "Q2 loss": 8.507030237197876, "Mean Target Q": 668.6597338867188, "Mean Q1": 668.65061328125, "Mean Q2": 668.6489619140625, "critic_loss": 17.05527858734131, "batch_reward": 5.799258964538574, "actor_loss": -669.1866021925404, "actor_target_entropy": -1.0, "actor_entropy": -0.27512651657865894, "alpha_loss": 0.00017470976285215828, "alpha_value": 0.16597072383534142, "duration": 135.67645049095154, "step": 52000}
{"episode_reward": 835.5368491939091, "episode": 417.0, "Q1 loss": 9.040826694488526, "Q2 loss": 8.993401679992676, "Mean Target Q": 668.7625336914062, "Mean Q1": 668.7608447265625, "Mean Q2": 668.7617587890625, "critic_loss": 18.034228439331056, "batch_reward": 5.773973625183105, "actor_loss": -669.1546020507812, "actor_target_entropy": -1.0, "actor_entropy": -0.2630181603488468, "alpha_loss": 0.0006900679815324053, "alpha_value": 0.16607072114520988, "duration": 128.61784267425537, "step": 52125}
{"episode_reward": 841.4972960899097, "episode": 418.0, "Q1 loss": 8.886970355987549, "Q2 loss": 9.015255529403687, "Mean Target Q": 669.2676079101562, "Mean Q1": 669.2690639648438, "Mean Q2": 669.2696225585937, "critic_loss": 17.902225959777834, "batch_reward": 5.7844831199646, "actor_loss": -669.5304043677545, "actor_target_entropy": -1.0, "actor_entropy": -0.24956469646384638, "alpha_loss": 0.003175727298272954, "alpha_value": 0.1657463786700286, "duration": 133.50677347183228, "step": 52250}
{"episode_reward": 842.8982752731469, "episode": 419.0, "Q1 loss": 8.56458744430542, "Q2 loss": 8.519186225891113, "Mean Target Q": 670.0174233398437, "Mean Q1": 670.0227163085938, "Mean Q2": 670.023583984375, "critic_loss": 17.083773735046385, "batch_reward": 5.79467412185669, "actor_loss": -670.6178937639509, "actor_target_entropy": -1.0, "actor_entropy": -0.2892872326903873, "alpha_loss": 0.0020146914425172974, "alpha_value": 0.16551909566790066, "duration": 135.27707409858704, "step": 52375}
{"episode_reward": 843.4189745397449, "episode": 420.0, "Q1 loss": 8.307465049743652, "Q2 loss": 8.3162223777771, "Mean Target Q": 670.32152734375, "Mean Q1": 670.31333984375, "Mean Q2": 670.3117153320312, "critic_loss": 16.623687385559084, "batch_reward": 5.79710892868042, "actor_loss": -671.0437425182712, "actor_target_entropy": -1.0, "actor_entropy": -0.2625525062603335, "alpha_loss": 0.00457548268417257, "alpha_value": 0.1652540466819036, "duration": 133.78746891021729, "step": 52500}
{"episode_reward": 833.0618075033454, "episode": 421.0, "Q1 loss": 8.050867366790772, "Q2 loss": 8.116316329956055, "Mean Target Q": 670.7748271484375, "Mean Q1": 670.775796875, "Mean Q2": 670.7765859375, "critic_loss": 16.16718374633789, "batch_reward": 5.7816697692871095, "actor_loss": -671.5473419673859, "actor_target_entropy": -1.0, "actor_entropy": -0.2937355505095588, "alpha_loss": 0.0018902862202450042, "alpha_value": 0.16494777787453582, "duration": 145.0096733570099, "step": 52625}
{"episode_reward": 822.358958668322, "episode": 422.0, "Q1 loss": 9.466274566650391, "Q2 loss": 9.295328601837157, "Mean Target Q": 671.2983774414063, "Mean Q1": 671.2901450195312, "Mean Q2": 671.2887055664063, "critic_loss": 18.761603134155273, "batch_reward": 5.791437179565429, "actor_loss": -671.781514813823, "actor_target_entropy": -1.0, "actor_entropy": -0.2811802702565347, "alpha_loss": -0.00018263711676662489, "alpha_value": 0.1649363000030682, "duration": 136.5828731060028, "step": 52750}
{"episode_reward": 845.799333567823, "episode": 423.0, "Q1 loss": 8.74092200088501, "Q2 loss": 8.528294422149658, "Mean Target Q": 671.6465986328125, "Mean Q1": 671.6491469726562, "Mean Q2": 671.6492119140624, "critic_loss": 17.269216400146483, "batch_reward": 5.792815269470215, "actor_loss": -672.4152628580729, "actor_target_entropy": -1.0, "actor_entropy": -0.2738311049484071, "alpha_loss": 0.0021596282909047745, "alpha_value": 0.1648634712026165, "duration": 129.3831307888031, "step": 52875}
{"episode_reward": 839.9190151208559, "episode": 424.0, "Q1 loss": 8.693962841033935, "Q2 loss": 8.576004905700684, "Mean Target Q": 672.2343237304688, "Mean Q1": 672.2334462890625, "Mean Q2": 672.2345869140624, "critic_loss": 17.269967811584472, "batch_reward": 5.804864807128906, "actor_loss": -673.0514496834047, "actor_target_entropy": -1.0, "actor_entropy": -0.2674418899320787, "alpha_loss": -8.240592245373034e-05, "alpha_value": 0.16472231606147017, "duration": 142.50188875198364, "step": 53000}
{"episode_reward": 834.2782817280179, "episode": 425.0, "Q1 loss": 8.005294830322265, "Q2 loss": 7.9868972282409665, "Mean Target Q": 672.571552734375, "Mean Q1": 672.56489453125, "Mean Q2": 672.5654653320313, "critic_loss": 15.992192127227783, "batch_reward": 5.795544589996338, "actor_loss": -673.2975337921627, "actor_target_entropy": -1.0, "actor_entropy": -0.3032032946745555, "alpha_loss": 6.194152529277499e-06, "alpha_value": 0.16467289887201317, "duration": 139.6906909942627, "step": 53125}
{"episode_reward": 841.1566171432034, "episode": 426.0, "Q1 loss": 8.923279983520509, "Q2 loss": 9.06307525253296, "Mean Target Q": 673.214388671875, "Mean Q1": 673.2162236328124, "Mean Q2": 673.2152412109375, "critic_loss": 17.98635523223877, "batch_reward": 5.806011032104492, "actor_loss": -673.5874692855343, "actor_target_entropy": -1.0, "actor_entropy": -0.269115322299542, "alpha_loss": 0.00187447810763373, "alpha_value": 0.1645804197447949, "duration": 133.58019495010376, "step": 53250}
{"episode_reward": 825.6960977507954, "episode": 427.0, "Q1 loss": 8.792176868438721, "Q2 loss": 8.963390130996704, "Mean Target Q": 673.1326840820312, "Mean Q1": 673.1328251953125, "Mean Q2": 673.1322426757813, "critic_loss": 17.755567016601564, "batch_reward": 5.770022941589356, "actor_loss": -674.2131735181051, "actor_target_entropy": -1.0, "actor_entropy": -0.2638962138739843, "alpha_loss": 0.00634860998529586, "alpha_value": 0.16422365035861244, "duration": 135.8664035797119, "step": 53375}
{"episode_reward": 843.0327746872227, "episode": 428.0, "Q1 loss": 8.574303890228272, "Q2 loss": 8.394088809967041, "Mean Target Q": 673.6516479492187, "Mean Q1": 673.6491137695313, "Mean Q2": 673.6504985351562, "critic_loss": 16.9683927192688, "batch_reward": 5.788273860931397, "actor_loss": -674.257084015877, "actor_target_entropy": -1.0, "actor_entropy": -0.28881525512664546, "alpha_loss": -0.004277414676072376, "alpha_value": 0.16420797110057742, "duration": 133.83635830879211, "step": 53500}
{"episode_reward": 845.3091505862039, "episode": 429.0, "Q1 loss": 9.027450538635254, "Q2 loss": 9.209634227752685, "Mean Target Q": 674.2740883789063, "Mean Q1": 674.272986328125, "Mean Q2": 674.2720551757812, "critic_loss": 18.23708480834961, "batch_reward": 5.784323497772217, "actor_loss": -674.5083986312624, "actor_target_entropy": -1.0, "actor_entropy": -0.23908187590894245, "alpha_loss": 0.0027432160688534617, "alpha_value": 0.16437063094030818, "duration": 133.99954199790955, "step": 53625}
{"episode_reward": 823.9418422564602, "episode": 430.0, "Q1 loss": 8.337281673431397, "Q2 loss": 8.432824464797974, "Mean Target Q": 674.9782646484375, "Mean Q1": 674.9773286132812, "Mean Q2": 674.9768032226563, "critic_loss": 16.770106132507323, "batch_reward": 5.801488948822022, "actor_loss": -675.6552458732359, "actor_target_entropy": -1.0, "actor_entropy": -0.24414416114168783, "alpha_loss": 0.005842356897530055, "alpha_value": 0.16393624659632508, "duration": 144.50452375411987, "step": 53750}
{"episode_reward": 819.1927249794426, "episode": 431.0, "Q1 loss": 8.39483082962036, "Q2 loss": 8.233724117279053, "Mean Target Q": 675.494087890625, "Mean Q1": 675.4929360351563, "Mean Q2": 675.4932700195312, "critic_loss": 16.62855493927002, "batch_reward": 5.818118701934814, "actor_loss": -676.1387057834202, "actor_target_entropy": -1.0, "actor_entropy": -0.260900664187613, "alpha_loss": 0.004308235970148374, "alpha_value": 0.16342796859922254, "duration": 135.76620244979858, "step": 53875}
{"episode_reward": 846.7947873035854, "episode": 432.0, "Q1 loss": 8.62214765548706, "Q2 loss": 8.52601735496521, "Mean Target Q": 675.7481357421875, "Mean Q1": 675.7421157226562, "Mean Q2": 675.7427680664063, "critic_loss": 17.148165046691894, "batch_reward": 5.8009629135131835, "actor_loss": -676.520760813067, "actor_target_entropy": -1.0, "actor_entropy": -0.28677084393078284, "alpha_loss": -0.0015624597548477112, "alpha_value": 0.16328625746382844, "duration": 133.53584575653076, "step": 54000}
{"episode_reward": 839.0634841322725, "episode": 433.0, "Q1 loss": 9.571205806732177, "Q2 loss": 9.535826293945313, "Mean Target Q": 676.3694267578124, "Mean Q1": 676.3707265625, "Mean Q2": 676.3714555664062, "critic_loss": 19.107032096862792, "batch_reward": 5.817131675720215, "actor_loss": -676.746334015377, "actor_target_entropy": -1.0, "actor_entropy": -0.2634324589892039, "alpha_loss": 0.0027708241767767402, "alpha_value": 0.16321328530784823, "duration": 132.1844139099121, "step": 54125}
{"episode_reward": 847.2717024590802, "episode": 434.0, "Q1 loss": 8.16417261505127, "Q2 loss": 7.998837059020996, "Mean Target Q": 676.723060546875, "Mean Q1": 676.72006640625, "Mean Q2": 676.7178251953125, "critic_loss": 16.16300975036621, "batch_reward": 5.810869834899902, "actor_loss": -677.0077898579259, "actor_target_entropy": -1.0, "actor_entropy": -0.2772109155212679, "alpha_loss": -0.0031214287399404473, "alpha_value": 0.1632500646825213, "duration": 142.18192672729492, "step": 54250}
{"episode_reward": 837.702332988737, "episode": 435.0, "Q1 loss": 8.64153164100647, "Q2 loss": 8.48164208984375, "Mean Target Q": 676.8571596679687, "Mean Q1": 676.8556396484375, "Mean Q2": 676.8553120117188, "critic_loss": 17.12317375946045, "batch_reward": 5.804489208221436, "actor_loss": -677.4786280071925, "actor_target_entropy": -1.0, "actor_entropy": -0.2717165459716131, "alpha_loss": 0.00020691126747618592, "alpha_value": 0.16322790405581983, "duration": 138.18048977851868, "step": 54375}
{"episode_reward": 845.7994538214876, "episode": 436.0, "Q1 loss": 8.569753818511963, "Q2 loss": 8.415529331207276, "Mean Target Q": 677.3866962890625, "Mean Q1": 677.3807084960938, "Mean Q2": 677.3825, "critic_loss": 16.98528316116333, "batch_reward": 5.796214332580567, "actor_loss": -678.1458169260333, "actor_target_entropy": -1.0, "actor_entropy": -0.3012486693839873, "alpha_loss": -0.0015708198996200677, "alpha_value": 0.16340912720724327, "duration": 133.9134178161621, "step": 54500}
{"episode_reward": 842.0084182655728, "episode": 437.0, "Q1 loss": 8.531062721252441, "Q2 loss": 8.611814849853516, "Mean Target Q": 678.2249731445313, "Mean Q1": 678.2259848632813, "Mean Q2": 678.2259423828125, "critic_loss": 17.142877555847168, "batch_reward": 5.828908058166504, "actor_loss": -678.7617671906002, "actor_target_entropy": -1.0, "actor_entropy": -0.2634230170931135, "alpha_loss": 0.003125334886597499, "alpha_value": 0.16330892206162606, "duration": 135.83182430267334, "step": 54625}
{"episode_reward": 837.4519822498979, "episode": 438.0, "Q1 loss": 7.790204601287842, "Q2 loss": 7.959040050506592, "Mean Target Q": 678.5062983398437, "Mean Q1": 678.5102436523438, "Mean Q2": 678.509890625, "critic_loss": 15.749244621276855, "batch_reward": 5.830545337677002, "actor_loss": -678.9648821430821, "actor_target_entropy": -1.0, "actor_entropy": -0.2867597656384591, "alpha_loss": 0.00043378215500964755, "alpha_value": 0.16309461635232853, "duration": 136.745836019516, "step": 54750}
{"episode_reward": 840.0835168476077, "episode": 439.0, "Q1 loss": 8.125672857284545, "Q2 loss": 8.057582963943482, "Mean Target Q": 678.6580478515625, "Mean Q1": 678.6482744140625, "Mean Q2": 678.6477641601563, "critic_loss": 16.183255767822267, "batch_reward": 5.817067264556885, "actor_loss": -679.2112930540054, "actor_target_entropy": -1.0, "actor_entropy": -0.26696236928304035, "alpha_loss": 0.00666750159802004, "alpha_value": 0.16289365454430713, "duration": 133.2381136417389, "step": 54875}
{"episode_reward": 828.6837941465649, "episode": 440.0, "Q1 loss": 8.158823499679565, "Q2 loss": 8.109112899780273, "Mean Target Q": 679.5446381835937, "Mean Q1": 679.5463818359375, "Mean Q2": 679.5481108398437, "critic_loss": 16.26793647003174, "batch_reward": 5.8568341979980465, "actor_loss": -679.9748062626009, "actor_target_entropy": -1.0, "actor_entropy": -0.2841928805555067, "alpha_loss": 0.0038757649918777807, "alpha_value": 0.1623543834169552, "step": 55000}
{"duration": 168.31017780303955, "step": 55000}
{"episode_reward": 828.2259367476472, "episode": 441.0, "Q1 loss": 7.783922449111938, "Q2 loss": 7.7709083805084225, "Mean Target Q": 679.644783203125, "Mean Q1": 679.6360166015625, "Mean Q2": 679.6356259765626, "critic_loss": 15.554830841064453, "batch_reward": 5.827499195098877, "actor_loss": -680.1726481119791, "actor_target_entropy": -1.0, "actor_entropy": -0.3000937768864253, "alpha_loss": -0.002018713229705417, "alpha_value": 0.16232502603500115, "duration": 152.703937292099, "step": 55125}
{"episode_reward": 841.2929631748686, "episode": 442.0, "Q1 loss": 8.407333158493042, "Q2 loss": 8.199922208786012, "Mean Target Q": 680.1798442382812, "Mean Q1": 680.1828168945312, "Mean Q2": 680.18217578125, "critic_loss": 16.607255363464354, "batch_reward": 5.8294124526977535, "actor_loss": -680.6282299410913, "actor_target_entropy": -1.0, "actor_entropy": -0.2731866805303481, "alpha_loss": 0.004065282849384652, "alpha_value": 0.16234154055190922, "duration": 150.53118801116943, "step": 55250}
{"episode_reward": 843.8995768408286, "episode": 443.0, "Q1 loss": 8.355961906433105, "Q2 loss": 8.412973922729492, "Mean Target Q": 680.42848828125, "Mean Q1": 680.4290170898438, "Mean Q2": 680.4286127929688, "critic_loss": 16.76893593597412, "batch_reward": 5.8279751091003416, "actor_loss": -680.7392364986359, "actor_target_entropy": -1.0, "actor_entropy": -0.26099417772558, "alpha_loss": 0.0006040056912405859, "alpha_value": 0.16192021550738925, "duration": 149.19747829437256, "step": 55375}
{"episode_reward": 842.7118274670358, "episode": 444.0, "Q1 loss": 8.492614585876465, "Q2 loss": 8.473169229507446, "Mean Target Q": 680.9356284179687, "Mean Q1": 680.9378212890625, "Mean Q2": 680.9393564453125, "critic_loss": 16.965783798217775, "batch_reward": 5.844862838745117, "actor_loss": -681.5841458228326, "actor_target_entropy": -1.0, "actor_entropy": -0.2385936826467514, "alpha_loss": 0.0068095986348306456, "alpha_value": 0.1615973547647832, "duration": 153.2110583782196, "step": 55500}
{"episode_reward": 842.0349273134742, "episode": 445.0, "Q1 loss": 8.197350032806396, "Q2 loss": 8.134294338226319, "Mean Target Q": 681.4527978515625, "Mean Q1": 681.4452426757813, "Mean Q2": 681.4439545898438, "critic_loss": 16.331644355773925, "batch_reward": 5.849930110931396, "actor_loss": -681.7824086991567, "actor_target_entropy": -1.0, "actor_entropy": -0.26918869950468577, "alpha_loss": 0.00402279651080746, "alpha_value": 0.16105485258823324, "duration": 163.68447589874268, "step": 55625}
{"episode_reward": 844.666170188533, "episode": 446.0, "Q1 loss": 7.367354318618775, "Q2 loss": 7.234404357910156, "Mean Target Q": 681.354220703125, "Mean Q1": 681.3532548828125, "Mean Q2": 681.3526826171875, "critic_loss": 14.60175863647461, "batch_reward": 5.812834838867188, "actor_loss": -681.814450171686, "actor_target_entropy": -1.0, "actor_entropy": -0.2755196005586655, "alpha_loss": 0.0005541948466411521, "alpha_value": 0.16099340061877554, "duration": 150.65767121315002, "step": 55750}
{"episode_reward": 847.0131556455905, "episode": 447.0, "Q1 loss": 8.358346961975098, "Q2 loss": 8.243152294158936, "Mean Target Q": 681.9612099609375, "Mean Q1": 681.9538598632812, "Mean Q2": 681.9544453125, "critic_loss": 16.601499252319336, "batch_reward": 5.832790428161621, "actor_loss": -682.724365234375, "actor_target_entropy": -1.0, "actor_entropy": -0.28705515960852307, "alpha_loss": 0.0002055000587706528, "alpha_value": 0.16073631670072416, "duration": 147.48450899124146, "step": 55875}
{"episode_reward": 843.2596961124201, "episode": 448.0, "Q1 loss": 8.85227507019043, "Q2 loss": 8.886876182556152, "Mean Target Q": 682.6649462890625, "Mean Q1": 682.6657993164063, "Mean Q2": 682.6670083007813, "critic_loss": 17.73915119934082, "batch_reward": 5.859310348510742, "actor_loss": -683.0137457078503, "actor_target_entropy": -1.0, "actor_entropy": -0.2982053922549371, "alpha_loss": 0.0005780544578878869, "alpha_value": 0.160861785756388, "duration": 154.6203215122223, "step": 56000}
{"episode_reward": 835.3355868787545, "episode": 449.0, "Q1 loss": 7.728113388061524, "Q2 loss": 7.616267112731934, "Mean Target Q": 682.5800361328126, "Mean Q1": 682.5828032226563, "Mean Q2": 682.5809868164063, "critic_loss": 15.344380527496337, "batch_reward": 5.831947189331054, "actor_loss": -682.8804485987104, "actor_target_entropy": -1.0, "actor_entropy": -0.26000894842639805, "alpha_loss": 0.0012207757626172332, "alpha_value": 0.16075886780511617, "duration": 159.91361021995544, "step": 56125}
{"episode_reward": 840.936676304118, "episode": 450.0, "Q1 loss": 8.21682154083252, "Q2 loss": 8.230865844726562, "Mean Target Q": 683.2405844726562, "Mean Q1": 683.2295532226562, "Mean Q2": 683.2318823242188, "critic_loss": 16.44768742752075, "batch_reward": 5.840127101898194, "actor_loss": -683.5408000330771, "actor_target_entropy": -1.0, "actor_entropy": -0.28222316167046946, "alpha_loss": -0.0006922289687809685, "alpha_value": 0.16079790469232638, "duration": 156.70959758758545, "step": 56250}
{"episode_reward": 843.9669198185809, "episode": 451.0, "Q1 loss": 7.635790704727173, "Q2 loss": 7.753459709167481, "Mean Target Q": 683.6859184570312, "Mean Q1": 683.6877338867188, "Mean Q2": 683.687775390625, "critic_loss": 15.389250389099121, "batch_reward": 5.8580089225769045, "actor_loss": -683.9469701373388, "actor_target_entropy": -1.0, "actor_entropy": -0.2822939181138599, "alpha_loss": 0.0008665678730707556, "alpha_value": 0.16078960762666286, "duration": 151.4685504436493, "step": 56375}
{"episode_reward": 847.2359658025739, "episode": 452.0, "Q1 loss": 7.839322610855103, "Q2 loss": 7.839956132888794, "Mean Target Q": 683.7981372070312, "Mean Q1": 683.8006396484375, "Mean Q2": 683.7999482421875, "critic_loss": 15.679278770446777, "batch_reward": 5.84207929611206, "actor_loss": -684.1131247243574, "actor_target_entropy": -1.0, "actor_entropy": -0.2514227030258025, "alpha_loss": 0.00266595573010554, "alpha_value": 0.16054246116622284, "duration": 154.57226371765137, "step": 56500}
{"episode_reward": 833.279707102401, "episode": 453.0, "Q1 loss": 8.367844593048096, "Q2 loss": 8.230355854034423, "Mean Target Q": 684.3297534179687, "Mean Q1": 684.3310849609375, "Mean Q2": 684.3288959960937, "critic_loss": 16.598200408935547, "batch_reward": 5.854681716918945, "actor_loss": -684.6654343377976, "actor_target_entropy": -1.0, "actor_entropy": -0.26039899247033255, "alpha_loss": 0.002882153002752198, "alpha_value": 0.1603757124824829, "duration": 154.07111525535583, "step": 56625}
{"episode_reward": 840.0436598707811, "episode": 454.0, "Q1 loss": 8.540947574615478, "Q2 loss": 8.527640010833741, "Mean Target Q": 684.6196645507813, "Mean Q1": 684.61211328125, "Mean Q2": 684.6134565429687, "critic_loss": 17.0685876121521, "batch_reward": 5.852225917816162, "actor_loss": -684.9363718340473, "actor_target_entropy": -1.0, "actor_entropy": -0.2707267182488595, "alpha_loss": 0.0030768656363380294, "alpha_value": 0.16008629141125602, "duration": 143.8228144645691, "step": 56750}
{"episode_reward": 846.8202563741875, "episode": 455.0, "Q1 loss": 7.928336959838867, "Q2 loss": 7.8326726837158205, "Mean Target Q": 684.9680634765625, "Mean Q1": 684.973015625, "Mean Q2": 684.9728549804687, "critic_loss": 15.761009609222413, "batch_reward": 5.8431148452758785, "actor_loss": -685.4146651010665, "actor_target_entropy": -1.0, "actor_entropy": -0.279650038196927, "alpha_loss": 0.003103289256123678, "alpha_value": 0.1596777735941044, "duration": 149.4668231010437, "step": 56875}
{"episode_reward": 837.4192712113148, "episode": 456.0, "Q1 loss": 7.284821184158325, "Q2 loss": 7.3134439716339115, "Mean Target Q": 685.4436083984375, "Mean Q1": 685.4356264648437, "Mean Q2": 685.4358422851562, "critic_loss": 14.598265167236327, "batch_reward": 5.858292285919189, "actor_loss": -686.0817723428049, "actor_target_entropy": -1.0, "actor_entropy": -0.3038954583387221, "alpha_loss": -0.005456335613534095, "alpha_value": 0.15985609543172155, "duration": 154.7168688774109, "step": 57000}
{"episode_reward": 833.7281355094296, "episode": 457.0, "Q1 loss": 7.6056510334014895, "Q2 loss": 7.519603246688843, "Mean Target Q": 685.8788178710937, "Mean Q1": 685.88389453125, "Mean Q2": 685.8838159179687, "critic_loss": 15.125254356384277, "batch_reward": 5.866498077392579, "actor_loss": -686.4182497054811, "actor_target_entropy": -1.0, "actor_entropy": -0.2676788130922923, "alpha_loss": 0.004916334372302074, "alpha_value": 0.1598464734525907, "duration": 153.44940519332886, "step": 57125}
{"episode_reward": 839.9352193303064, "episode": 458.0, "Q1 loss": 7.798797174453735, "Q2 loss": 7.860041450500488, "Mean Target Q": 686.257771484375, "Mean Q1": 686.2526997070313, "Mean Q2": 686.2529194335938, "critic_loss": 15.658838611602784, "batch_reward": 5.873054153442383, "actor_loss": -686.6807132844002, "actor_target_entropy": -1.0, "actor_entropy": -0.2642876464993723, "alpha_loss": 0.004756816413118353, "alpha_value": 0.1595176323499145, "duration": 140.6923041343689, "step": 57250}
{"episode_reward": 839.9765277402898, "episode": 459.0, "Q1 loss": 8.758836336135865, "Q2 loss": 8.678575885772705, "Mean Target Q": 686.4440341796875, "Mean Q1": 686.4497768554687, "Mean Q2": 686.447361328125, "critic_loss": 17.437412239074707, "batch_reward": 5.849700191497803, "actor_loss": -686.9271104600695, "actor_target_entropy": -1.0, "actor_entropy": -0.26538538672621287, "alpha_loss": 0.0021415846163613927, "alpha_value": 0.15906510919555672, "duration": 151.44348168373108, "step": 57375}
{"episode_reward": 837.2372124770316, "episode": 460.0, "Q1 loss": 8.274838409423829, "Q2 loss": 8.250436334609985, "Mean Target Q": 687.020623046875, "Mean Q1": 687.0135751953125, "Mean Q2": 687.0153715820312, "critic_loss": 16.525274688720703, "batch_reward": 5.868285961151123, "actor_loss": -687.4540907336819, "actor_target_entropy": -1.0, "actor_entropy": -0.317587754418773, "alpha_loss": -0.002761901942111792, "alpha_value": 0.1592090425618214, "duration": 144.27637243270874, "step": 57500}
{"episode_reward": 843.1185371651393, "episode": 461.0, "Q1 loss": 7.84724747467041, "Q2 loss": 7.757384208679199, "Mean Target Q": 687.376078125, "Mean Q1": 687.3770478515625, "Mean Q2": 687.377921875, "critic_loss": 15.604631721496583, "batch_reward": 5.859224063873291, "actor_loss": -687.7116457015749, "actor_target_entropy": -1.0, "actor_entropy": -0.27015649160695454, "alpha_loss": 0.0022071028545883205, "alpha_value": 0.1591299002600302, "duration": 159.2273349761963, "step": 57625}
{"episode_reward": 838.9307103456161, "episode": 462.0, "Q1 loss": 7.91236686706543, "Q2 loss": 7.838102663040162, "Mean Target Q": 687.7264916992187, "Mean Q1": 687.7216850585937, "Mean Q2": 687.7208408203124, "critic_loss": 15.75046953201294, "batch_reward": 5.872039375305175, "actor_loss": -688.0417332803049, "actor_target_entropy": -1.0, "actor_entropy": -0.30795948327549044, "alpha_loss": -0.003087595548300493, "alpha_value": 0.15912105733767654, "duration": 149.3930778503418, "step": 57750}
{"episode_reward": 813.973654579716, "episode": 463.0, "Q1 loss": 8.796885627746581, "Q2 loss": 8.925524600982666, "Mean Target Q": 687.7921030273437, "Mean Q1": 687.7883134765625, "Mean Q2": 687.789318359375, "critic_loss": 17.722410232543947, "batch_reward": 5.853651332855224, "actor_loss": -688.1514010959202, "actor_target_entropy": -1.0, "actor_entropy": -0.31029880236065577, "alpha_loss": -0.004933937807523069, "alpha_value": 0.15959708630084865, "duration": 155.23562264442444, "step": 57875}
{"episode_reward": 819.088250896061, "episode": 464.0, "Q1 loss": 7.9596348419189455, "Q2 loss": 7.917024351119995, "Mean Target Q": 688.5952666015625, "Mean Q1": 688.5931982421876, "Mean Q2": 688.59283203125, "critic_loss": 15.876659118652343, "batch_reward": 5.876623416900634, "actor_loss": -689.0044624574723, "actor_target_entropy": -1.0, "actor_entropy": -0.3097959468441625, "alpha_loss": -0.0027792525586612044, "alpha_value": 0.1598471502902248, "duration": 151.86858940124512, "step": 58000}
{"episode_reward": 849.7884249168029, "episode": 465.0, "Q1 loss": 7.898017915725708, "Q2 loss": 7.773422342300415, "Mean Target Q": 689.0098681640625, "Mean Q1": 689.0111806640625, "Mean Q2": 689.0129057617188, "critic_loss": 15.671440166473388, "batch_reward": 5.8757004661560055, "actor_loss": -689.329103500124, "actor_target_entropy": -1.0, "actor_entropy": -0.3142376984395678, "alpha_loss": 0.0009843879674990026, "alpha_value": 0.15996172170025438, "duration": 154.28663754463196, "step": 58125}
{"episode_reward": 749.5435228141686, "episode": 466.0, "Q1 loss": 7.424872636795044, "Q2 loss": 7.371583789825439, "Mean Target Q": 689.3158471679687, "Mean Q1": 689.3130087890625, "Mean Q2": 689.312134765625, "critic_loss": 14.79645644378662, "batch_reward": 5.877765682220459, "actor_loss": -689.7627494565902, "actor_target_entropy": -1.0, "actor_entropy": -0.28441580865652333, "alpha_loss": -0.0007275898993435887, "alpha_value": 0.15983327462134878, "duration": 159.63042831420898, "step": 58250}
{"episode_reward": 833.7418393960739, "episode": 467.0, "Q1 loss": 8.35203265953064, "Q2 loss": 8.385179841995239, "Mean Target Q": 689.1183720703125, "Mean Q1": 689.1141220703125, "Mean Q2": 689.1151474609375, "critic_loss": 16.73721245574951, "batch_reward": 5.8501978225708005, "actor_loss": -689.6917056129092, "actor_target_entropy": -1.0, "actor_entropy": -0.299229028206023, "alpha_loss": -0.001312687930222305, "alpha_value": 0.160185486701481, "duration": 147.420902967453, "step": 58375}
{"episode_reward": 599.8686499667164, "episode": 468.0, "Q1 loss": 8.70805665397644, "Q2 loss": 8.606182027816773, "Mean Target Q": 689.9357822265625, "Mean Q1": 689.9318833007812, "Mean Q2": 689.9297622070312, "critic_loss": 17.314238662719728, "batch_reward": 5.876460346221924, "actor_loss": -690.5654109831779, "actor_target_entropy": -1.0, "actor_entropy": -0.3049801266001117, "alpha_loss": 0.001051168815578304, "alpha_value": 0.16017095881588664, "duration": 159.54657983779907, "step": 58500}
{"episode_reward": 736.5613261161402, "episode": 469.0, "Q1 loss": 7.467177745819092, "Q2 loss": 7.478382987976074, "Mean Target Q": 690.3168002929688, "Mean Q1": 690.3179233398438, "Mean Q2": 690.3179545898438, "critic_loss": 14.945560733795165, "batch_reward": 5.868712646484375, "actor_loss": -690.7019740513393, "actor_target_entropy": -1.0, "actor_entropy": -0.2970253248063345, "alpha_loss": -0.0019351852455339025, "alpha_value": 0.16018080990556088, "duration": 155.58056926727295, "step": 58625}
{"episode_reward": 831.3635129406873, "episode": 470.0, "Q1 loss": 8.08613381576538, "Q2 loss": 8.040126741409301, "Mean Target Q": 690.4950395507813, "Mean Q1": 690.490283203125, "Mean Q2": 690.4915317382812, "critic_loss": 16.126260627746582, "batch_reward": 5.874377388000489, "actor_loss": -690.9441656297253, "actor_target_entropy": -1.0, "actor_entropy": -0.2676667150470518, "alpha_loss": 0.003952500481729305, "alpha_value": 0.16002270928335752, "duration": 145.1738715171814, "step": 58750}
{"episode_reward": 815.2180544670753, "episode": 471.0, "Q1 loss": 8.046865966796876, "Q2 loss": 7.831270965576172, "Mean Target Q": 690.7640239257812, "Mean Q1": 690.7701440429687, "Mean Q2": 690.7696435546875, "critic_loss": 15.878136894226074, "batch_reward": 5.881911163330078, "actor_loss": -691.1409263005332, "actor_target_entropy": -1.0, "actor_entropy": -0.29565965691729196, "alpha_loss": -0.00040951838332509236, "alpha_value": 0.15978253720454702, "duration": 149.81304144859314, "step": 58875}
{"episode_reward": 842.9383302120619, "episode": 472.0, "Q1 loss": 8.751560356140137, "Q2 loss": 8.807498538970947, "Mean Target Q": 691.4506220703125, "Mean Q1": 691.4474443359375, "Mean Q2": 691.446568359375, "critic_loss": 17.559058837890625, "batch_reward": 5.891361763000488, "actor_loss": -691.653820407006, "actor_target_entropy": -1.0, "actor_entropy": -0.26604412916687226, "alpha_loss": 0.005457270625723346, "alpha_value": 0.15954722500912233, "duration": 151.2410490512848, "step": 59000}
{"episode_reward": 834.7418935130144, "episode": 473.0, "Q1 loss": 8.510230262756348, "Q2 loss": 8.599145011901856, "Mean Target Q": 691.352939453125, "Mean Q1": 691.3508676757813, "Mean Q2": 691.3510073242187, "critic_loss": 17.109375297546386, "batch_reward": 5.877110092163086, "actor_loss": -692.04102531312, "actor_target_entropy": -1.0, "actor_entropy": -0.25882882139985525, "alpha_loss": 0.005548815333491398, "alpha_value": 0.15909255860207688, "duration": 147.23881435394287, "step": 59125}
{"episode_reward": 827.9255593191733, "episode": 474.0, "Q1 loss": 8.204186542510985, "Q2 loss": 8.168126987457276, "Mean Target Q": 691.7398232421875, "Mean Q1": 691.7337055664062, "Mean Q2": 691.7347958984375, "critic_loss": 16.372313491821288, "batch_reward": 5.874680843353271, "actor_loss": -692.3310064500378, "actor_target_entropy": -1.0, "actor_entropy": -0.2990585947709699, "alpha_loss": 0.0031223413496909123, "alpha_value": 0.15881613877256948, "duration": 149.0985085964203, "step": 59250}
{"episode_reward": 775.5570521535388, "episode": 475.0, "Q1 loss": 7.920753353118896, "Q2 loss": 7.792566488265991, "Mean Target Q": 692.0619897460938, "Mean Q1": 692.0656782226563, "Mean Q2": 692.0647954101562, "critic_loss": 15.7133198928833, "batch_reward": 5.884760837554932, "actor_loss": -692.5578962053571, "actor_target_entropy": -1.0, "actor_entropy": -0.3250819794715397, "alpha_loss": -0.001358076506885626, "alpha_value": 0.15855518868415233, "duration": 150.34922075271606, "step": 59375}
{"episode_reward": 846.9104977161753, "episode": 476.0, "Q1 loss": 7.720245643615723, "Q2 loss": 7.72167804145813, "Mean Target Q": 692.6889169921875, "Mean Q1": 692.6830034179687, "Mean Q2": 692.6855380859375, "critic_loss": 15.441923698425294, "batch_reward": 5.892528476715088, "actor_loss": -693.063469671434, "actor_target_entropy": -1.0, "actor_entropy": -0.2807606494715137, "alpha_loss": 0.004543442391760407, "alpha_value": 0.15857810619093826, "duration": 149.14128375053406, "step": 59500}
{"episode_reward": 836.5103935050225, "episode": 477.0, "Q1 loss": 8.178811962127686, "Q2 loss": 8.019004386901855, "Mean Target Q": 693.0107294921875, "Mean Q1": 693.0078916015625, "Mean Q2": 693.0058935546875, "critic_loss": 16.197816291809083, "batch_reward": 5.8903691177368165, "actor_loss": -693.6926027328249, "actor_target_entropy": -1.0, "actor_entropy": -0.27673069375848014, "alpha_loss": 0.004713265949653255, "alpha_value": 0.1581548701647843, "duration": 152.8146653175354, "step": 59625}
{"episode_reward": 848.5130792358141, "episode": 478.0, "Q1 loss": 7.81632451248169, "Q2 loss": 7.840342113494873, "Mean Target Q": 693.247962890625, "Mean Q1": 693.2442416992187, "Mean Q2": 693.245587890625, "critic_loss": 15.656666587829589, "batch_reward": 5.904406803131104, "actor_loss": -693.4701242754536, "actor_target_entropy": -1.0, "actor_entropy": -0.25278121112815793, "alpha_loss": 0.005883523980305801, "alpha_value": 0.1575788467473657, "duration": 148.02751302719116, "step": 59750}
{"episode_reward": 844.3911769907884, "episode": 479.0, "Q1 loss": 8.191101341247558, "Q2 loss": 8.188568292617799, "Mean Target Q": 693.5475063476563, "Mean Q1": 693.5526137695313, "Mean Q2": 693.5505209960937, "critic_loss": 16.379669555664062, "batch_reward": 5.889071990966797, "actor_loss": -693.810045030382, "actor_target_entropy": -1.0, "actor_entropy": -0.2544859063530725, "alpha_loss": 0.0012824699607869936, "alpha_value": 0.15726395972155996, "duration": 155.11167168617249, "step": 59875}
{"episode_reward": 829.576760601394, "episode": 480.0, "Q1 loss": 7.980383447647094, "Q2 loss": 7.862795150756836, "Mean Target Q": 693.7877358398438, "Mean Q1": 693.7810361328125, "Mean Q2": 693.7826040039063, "critic_loss": 15.843178657531737, "batch_reward": 5.891047901153565, "actor_loss": -694.2790192634828, "actor_target_entropy": -1.0, "actor_entropy": -0.29326175441665037, "alpha_loss": 0.003192515392231965, "alpha_value": 0.15713770184027542, "step": 60000}
{"duration": 173.2962291240692, "step": 60000}
{"episode_reward": 823.3898329587537, "episode": 481.0, "Q1 loss": 8.082487878799439, "Q2 loss": 7.983312530517578, "Mean Target Q": 693.69143359375, "Mean Q1": 693.6908471679687, "Mean Q2": 693.6910361328125, "critic_loss": 16.06580047607422, "batch_reward": 5.87321178817749, "actor_loss": -694.4154198056176, "actor_target_entropy": -1.0, "actor_entropy": -0.28483502188372234, "alpha_loss": 0.001646104438733014, "alpha_value": 0.15687913800077682, "duration": 180.4153606891632, "step": 60125}
{"episode_reward": 849.4427462589941, "episode": 482.0, "Q1 loss": 7.8576461353302, "Q2 loss": 7.81577534866333, "Mean Target Q": 694.2588227539062, "Mean Q1": 694.2579389648438, "Mean Q2": 694.2593857421875, "critic_loss": 15.673421508789062, "batch_reward": 5.883776760101318, "actor_loss": -694.7827404391381, "actor_target_entropy": -1.0, "actor_entropy": -0.29602826675099714, "alpha_loss": 0.0008902111252199017, "alpha_value": 0.15675981337069053, "duration": 155.5810980796814, "step": 60250}
{"episode_reward": 827.2395669017959, "episode": 483.0, "Q1 loss": 7.569156845092773, "Q2 loss": 7.413902473449707, "Mean Target Q": 694.8173134765625, "Mean Q1": 694.8144526367188, "Mean Q2": 694.81294921875, "critic_loss": 14.983059295654297, "batch_reward": 5.893304050445557, "actor_loss": -695.1067659892733, "actor_target_entropy": -1.0, "actor_entropy": -0.2835398768148725, "alpha_loss": 0.004243043088723743, "alpha_value": 0.15648283073162444, "duration": 167.02536129951477, "step": 60375}
{"episode_reward": 833.6595095226786, "episode": 484.0, "Q1 loss": 8.168197265625, "Q2 loss": 8.258663803100585, "Mean Target Q": 695.2852143554687, "Mean Q1": 695.2810454101563, "Mean Q2": 695.2825698242187, "critic_loss": 16.426861099243165, "batch_reward": 5.908731819152832, "actor_loss": -695.5501974782636, "actor_target_entropy": -1.0, "actor_entropy": -0.27393642692796644, "alpha_loss": 0.0010320830962530548, "alpha_value": 0.15631720160774804, "duration": 149.5088996887207, "step": 60500}
{"episode_reward": 837.5695488200847, "episode": 485.0, "Q1 loss": 7.663730430603027, "Q2 loss": 7.61110306930542, "Mean Target Q": 695.3018383789063, "Mean Q1": 695.3140356445313, "Mean Q2": 695.3112333984375, "critic_loss": 15.274833457946777, "batch_reward": 5.894683570861816, "actor_loss": -695.7327473958334, "actor_target_entropy": -1.0, "actor_entropy": -0.26934233402448987, "alpha_loss": 0.0006367293526492421, "alpha_value": 0.15628406519558424, "duration": 146.06682085990906, "step": 60625}
{"episode_reward": 841.1155387559047, "episode": 486.0, "Q1 loss": 7.514604076385498, "Q2 loss": 7.526634725570679, "Mean Target Q": 695.7029301757813, "Mean Q1": 695.6869541015625, "Mean Q2": 695.6885874023437, "critic_loss": 15.04123885345459, "batch_reward": 5.900524402618408, "actor_loss": -696.1731478783393, "actor_target_entropy": -1.0, "actor_entropy": -0.28218960930262843, "alpha_loss": 0.004903603570475694, "alpha_value": 0.15611746283368494, "duration": 153.68251657485962, "step": 60750}
{"episode_reward": 844.9968018601354, "episode": 487.0, "Q1 loss": 7.9521474914550785, "Q2 loss": 7.906476774215698, "Mean Target Q": 695.8380595703125, "Mean Q1": 695.8457939453125, "Mean Q2": 695.84547265625, "critic_loss": 15.858624244689942, "batch_reward": 5.890794059753418, "actor_loss": -696.2043176075769, "actor_target_entropy": -1.0, "actor_entropy": -0.30372788366817294, "alpha_loss": 0.0014189726918832296, "alpha_value": 0.1557096972935795, "duration": 151.6347780227661, "step": 60875}
{"episode_reward": 848.4786270430634, "episode": 488.0, "Q1 loss": 8.211314678192139, "Q2 loss": 8.012831844329835, "Mean Target Q": 696.245859375, "Mean Q1": 696.2428505859375, "Mean Q2": 696.2438266601563, "critic_loss": 16.224146472930908, "batch_reward": 5.893780193328857, "actor_loss": -696.5231411841607, "actor_target_entropy": -1.0, "actor_entropy": -0.2871248791775396, "alpha_loss": -0.0008472814421815377, "alpha_value": 0.1557457811491403, "duration": 151.11310958862305, "step": 61000}
{"episode_reward": 830.9110810231402, "episode": 489.0, "Q1 loss": 8.540001165390015, "Q2 loss": 8.315338418960572, "Mean Target Q": 696.4810537109375, "Mean Q1": 696.4782651367187, "Mean Q2": 696.4750092773437, "critic_loss": 16.855339569091797, "batch_reward": 5.903303848266601, "actor_loss": -696.7442791651166, "actor_target_entropy": -1.0, "actor_entropy": -0.2996679289000375, "alpha_loss": -0.0029931302248899427, "alpha_value": 0.15583537604005365, "duration": 156.28358435630798, "step": 61125}
{"episode_reward": 841.7430705098463, "episode": 490.0, "Q1 loss": 7.916416086196899, "Q2 loss": 7.906595108032227, "Mean Target Q": 697.0330927734375, "Mean Q1": 697.0304423828125, "Mean Q2": 697.0314770507813, "critic_loss": 15.823011283874513, "batch_reward": 5.920529972076416, "actor_loss": -697.3609668362525, "actor_target_entropy": -1.0, "actor_entropy": -0.2988953602410132, "alpha_loss": 0.001950786111035174, "alpha_value": 0.15591014334595582, "duration": 155.2692620754242, "step": 61250}
{"episode_reward": 848.036696391962, "episode": 491.0, "Q1 loss": 7.799167985916138, "Q2 loss": 7.853770824432373, "Mean Target Q": 696.8960024414063, "Mean Q1": 696.9008793945312, "Mean Q2": 696.9002807617187, "critic_loss": 15.652938842773438, "batch_reward": 5.892752479553223, "actor_loss": -697.3938957093254, "actor_target_entropy": -1.0, "actor_entropy": -0.3185514344109429, "alpha_loss": -0.0023073527614571273, "alpha_value": 0.15588252522954643, "duration": 151.6768937110901, "step": 61375}
{"episode_reward": 846.82087453382, "episode": 492.0, "Q1 loss": 8.184519388198852, "Q2 loss": 7.929937263488769, "Mean Target Q": 697.2545224609376, "Mean Q1": 697.2458012695313, "Mean Q2": 697.2485307617187, "critic_loss": 16.11445662689209, "batch_reward": 5.906874820709229, "actor_loss": -697.6099656628024, "actor_target_entropy": -1.0, "actor_entropy": -0.28498879002947963, "alpha_loss": 7.850932513153361e-05, "alpha_value": 0.15594432602537994, "duration": 163.27619194984436, "step": 61500}
{"episode_reward": 837.5977651791569, "episode": 493.0, "Q1 loss": 7.7351366481781, "Q2 loss": 7.73130750465393, "Mean Target Q": 697.7859340820313, "Mean Q1": 697.7818725585937, "Mean Q2": 697.780435546875, "critic_loss": 15.466444232940674, "batch_reward": 5.920276184082031, "actor_loss": -697.7853703574528, "actor_target_entropy": -1.0, "actor_entropy": -0.2870544334725728, "alpha_loss": -0.00044959466091342386, "alpha_value": 0.1560868816790155, "duration": 158.6575722694397, "step": 61625}
{"episode_reward": 842.8668125459416, "episode": 494.0, "Q1 loss": 7.861816263198852, "Q2 loss": 7.904903924942016, "Mean Target Q": 697.9603525390625, "Mean Q1": 697.9714350585938, "Mean Q2": 697.970669921875, "critic_loss": 15.766720161437988, "batch_reward": 5.9193501434326175, "actor_loss": -698.5552269720262, "actor_target_entropy": -1.0, "actor_entropy": -0.31572517295998914, "alpha_loss": -0.0037156738596217285, "alpha_value": 0.1562681545816497, "duration": 161.31037211418152, "step": 61750}
{"episode_reward": 838.7556685200691, "episode": 495.0, "Q1 loss": 7.923966674804688, "Q2 loss": 7.8362017936706545, "Mean Target Q": 698.4508271484375, "Mean Q1": 698.4427290039063, "Mean Q2": 698.4432358398437, "critic_loss": 15.76016845703125, "batch_reward": 5.924286010742187, "actor_loss": -698.8832242451017, "actor_target_entropy": -1.0, "actor_entropy": -0.3136293911744678, "alpha_loss": -0.006209520083512106, "alpha_value": 0.15687725890376933, "duration": 157.5617082118988, "step": 61875}
{"episode_reward": 844.1507403506432, "episode": 496.0, "Q1 loss": 8.456540895462036, "Q2 loss": 8.467593927383422, "Mean Target Q": 698.6870629882812, "Mean Q1": 698.6793315429687, "Mean Q2": 698.6792094726562, "critic_loss": 16.924134784698488, "batch_reward": 5.915747394561768, "actor_loss": -699.357417937248, "actor_target_entropy": -1.0, "actor_entropy": -0.2986680995072088, "alpha_loss": -0.0005368697212918872, "alpha_value": 0.1569912264259617, "duration": 157.70652318000793, "step": 62000}
{"episode_reward": 838.462453295132, "episode": 497.0, "Q1 loss": 7.985103130340576, "Q2 loss": 7.9581070880889895, "Mean Target Q": 698.9245654296875, "Mean Q1": 698.9290239257813, "Mean Q2": 698.9303310546875, "critic_loss": 15.943210296630859, "batch_reward": 5.919259128570556, "actor_loss": -699.2946370442709, "actor_target_entropy": -1.0, "actor_entropy": -0.28279399233204977, "alpha_loss": 0.00012572738341987133, "alpha_value": 0.15706380412364596, "duration": 158.7505829334259, "step": 62125}
{"episode_reward": 842.3859951129625, "episode": 498.0, "Q1 loss": 7.806414161682129, "Q2 loss": 7.79265231704712, "Mean Target Q": 698.9730859375, "Mean Q1": 698.9727954101562, "Mean Q2": 698.9701430664062, "critic_loss": 15.599066482543945, "batch_reward": 5.9055716438293455, "actor_loss": -699.8000852523312, "actor_target_entropy": -1.0, "actor_entropy": -0.2540133248173421, "alpha_loss": -0.0002124642093305386, "alpha_value": 0.1570620249667825, "duration": 162.81792545318604, "step": 62250}
{"episode_reward": 834.8080260431419, "episode": 499.0, "Q1 loss": 7.819138607025146, "Q2 loss": 7.692974212646484, "Mean Target Q": 699.580568359375, "Mean Q1": 699.5733481445312, "Mean Q2": 699.5764223632813, "critic_loss": 15.51211283493042, "batch_reward": 5.917402088165283, "actor_loss": -700.0139412047371, "actor_target_entropy": -1.0, "actor_entropy": -0.282457483193231, "alpha_loss": -0.0013405190122919896, "alpha_value": 0.15711217914187098, "duration": 162.45834851264954, "step": 62375}
{"episode_reward": 839.8302785769131, "episode": 500.0, "Q1 loss": 8.472213817596435, "Q2 loss": 8.484122436523437, "Mean Target Q": 699.9173676757813, "Mean Q1": 699.9143530273437, "Mean Q2": 699.9141435546875, "critic_loss": 16.956336235046386, "batch_reward": 5.932261280059814, "actor_loss": -700.2393611784904, "actor_target_entropy": -1.0, "actor_entropy": -0.28101449531893574, "alpha_loss": -0.0012844439948939026, "alpha_value": 0.1571076301461466, "duration": 157.94235157966614, "step": 62500}
{"episode_reward": 769.3638554346953, "episode": 501.0, "Q1 loss": 8.313996047973633, "Q2 loss": 8.124606983184815, "Mean Target Q": 700.2928486328125, "Mean Q1": 700.2956752929688, "Mean Q2": 700.2958115234375, "critic_loss": 16.43860306549072, "batch_reward": 5.929460472106934, "actor_loss": -700.8214305090526, "actor_target_entropy": -1.0, "actor_entropy": -0.30549291485831853, "alpha_loss": -0.0020781274689065797, "alpha_value": 0.15736802920124535, "duration": 150.9905023574829, "step": 62625}
{"episode_reward": 850.0220139451417, "episode": 502.0, "Q1 loss": 7.746045068740845, "Q2 loss": 7.673637742996216, "Mean Target Q": 700.7662895507813, "Mean Q1": 700.764375, "Mean Q2": 700.7640190429687, "critic_loss": 15.41968286895752, "batch_reward": 5.946606414794922, "actor_loss": -700.9535906391759, "actor_target_entropy": -1.0, "actor_entropy": -0.26276586973859417, "alpha_loss": -0.0026289345828005143, "alpha_value": 0.15751386007471957, "duration": 156.42941284179688, "step": 62750}
{"episode_reward": 843.6800329592153, "episode": 503.0, "Q1 loss": 8.187259426116944, "Q2 loss": 8.216019899368286, "Mean Target Q": 700.8034501953125, "Mean Q1": 700.7985, "Mean Q2": 700.7986274414062, "critic_loss": 16.40327936553955, "batch_reward": 5.929318737030029, "actor_loss": -701.3886302160838, "actor_target_entropy": -1.0, "actor_entropy": -0.27620570219698404, "alpha_loss": 0.0014164330371256386, "alpha_value": 0.15760943755879167, "duration": 151.90785574913025, "step": 62875}
{"episode_reward": 839.7376516238595, "episode": 504.0, "Q1 loss": 7.855221078872681, "Q2 loss": 7.78457629776001, "Mean Target Q": 701.6152875976562, "Mean Q1": 701.6200620117188, "Mean Q2": 701.6178037109376, "critic_loss": 15.639797286987305, "batch_reward": 5.960844039916992, "actor_loss": -701.6305217127646, "actor_target_entropy": -1.0, "actor_entropy": -0.27659042828506036, "alpha_loss": 0.0018383708196662127, "alpha_value": 0.15744208077092017, "duration": 157.3576557636261, "step": 63000}
{"episode_reward": 846.9561005759625, "episode": 505.0, "Q1 loss": 7.496351432800293, "Q2 loss": 7.6133516483306884, "Mean Target Q": 701.5657568359375, "Mean Q1": 701.5616064453125, "Mean Q2": 701.5619467773438, "critic_loss": 15.109703060150146, "batch_reward": 5.945353176116943, "actor_loss": -701.9988161117311, "actor_target_entropy": -1.0, "actor_entropy": -0.3120808078656121, "alpha_loss": 0.0002449476474245626, "alpha_value": 0.15726926637235167, "duration": 146.64327144622803, "step": 63125}
{"episode_reward": 846.7936651776868, "episode": 506.0, "Q1 loss": 7.582059013366699, "Q2 loss": 7.556562547683716, "Mean Target Q": 701.8059643554687, "Mean Q1": 701.8101411132812, "Mean Q2": 701.8111865234375, "critic_loss": 15.138621555328369, "batch_reward": 5.93885485458374, "actor_loss": -702.4189138104839, "actor_target_entropy": -1.0, "actor_entropy": -0.3153979410567591, "alpha_loss": -0.0013389111057134165, "alpha_value": 0.1574331969964412, "duration": 154.94777488708496, "step": 63250}
{"episode_reward": 837.057570584484, "episode": 507.0, "Q1 loss": 8.209306610107422, "Q2 loss": 8.1012015914917, "Mean Target Q": 701.837466796875, "Mean Q1": 701.8243051757812, "Mean Q2": 701.8239614257812, "critic_loss": 16.310508182525634, "batch_reward": 5.92106400680542, "actor_loss": -702.4218188089038, "actor_target_entropy": -1.0, "actor_entropy": -0.29504219430779655, "alpha_loss": 0.0005240549725140371, "alpha_value": 0.15744239717700922, "duration": 153.22145009040833, "step": 63375}
{"episode_reward": 840.445556628847, "episode": 508.0, "Q1 loss": 7.542612705230713, "Q2 loss": 7.631690311431885, "Mean Target Q": 702.1661806640625, "Mean Q1": 702.1663129882812, "Mean Q2": 702.1666704101563, "critic_loss": 15.174303081512452, "batch_reward": 5.934434017181396, "actor_loss": -702.6602714292464, "actor_target_entropy": -1.0, "actor_entropy": -0.2699593988157088, "alpha_loss": 0.0074683140001950725, "alpha_value": 0.15709798553963583, "duration": 153.22122645378113, "step": 63500}
{"episode_reward": 831.5272851151832, "episode": 509.0, "Q1 loss": 8.0633563747406, "Q2 loss": 8.098665321350097, "Mean Target Q": 702.5885463867188, "Mean Q1": 702.588375, "Mean Q2": 702.5885380859374, "critic_loss": 16.16202169418335, "batch_reward": 5.9481667747497555, "actor_loss": -703.2302643306672, "actor_target_entropy": -1.0, "actor_entropy": -0.2934721230514466, "alpha_loss": 0.003829838228522844, "alpha_value": 0.1565928294195121, "duration": 165.17643094062805, "step": 63625}
{"episode_reward": 756.2690917989995, "episode": 510.0, "Q1 loss": 8.164800951004029, "Q2 loss": 7.903052211761475, "Mean Target Q": 702.8494145507813, "Mean Q1": 702.8491689453125, "Mean Q2": 702.8479477539063, "critic_loss": 16.06785311126709, "batch_reward": 5.933469192504883, "actor_loss": -703.4587225144909, "actor_target_entropy": -1.0, "actor_entropy": -0.3103956241280802, "alpha_loss": 0.0004890951339245564, "alpha_value": 0.1562487109787743, "duration": 161.48281979560852, "step": 63750}
{"episode_reward": 840.8284756637777, "episode": 511.0, "Q1 loss": 8.043463508605956, "Q2 loss": 7.9318327102661135, "Mean Target Q": 703.2930747070312, "Mean Q1": 703.2946030273438, "Mean Q2": 703.2974965820313, "critic_loss": 15.975296215057373, "batch_reward": 5.95542032623291, "actor_loss": -703.6911950489831, "actor_target_entropy": -1.0, "actor_entropy": -0.34205774442544057, "alpha_loss": -0.0050469658001222545, "alpha_value": 0.15657198886630147, "duration": 153.35142540931702, "step": 63875}
{"episode_reward": 841.1804448720144, "episode": 512.0, "Q1 loss": 7.456834196090698, "Q2 loss": 7.464002075195313, "Mean Target Q": 703.4661884765625, "Mean Q1": 703.46734765625, "Mean Q2": 703.4664995117188, "critic_loss": 14.920836212158203, "batch_reward": 5.9414453582763675, "actor_loss": -704.1570247527092, "actor_target_entropy": -1.0, "actor_entropy": -0.32220787506911064, "alpha_loss": -0.0012142015583512763, "alpha_value": 0.1569662690491361, "duration": 152.29723262786865, "step": 64000}
{"episode_reward": 847.7167997587359, "episode": 513.0, "Q1 loss": 7.568117317199707, "Q2 loss": 7.488444297790528, "Mean Target Q": 703.7044658203125, "Mean Q1": 703.6920893554687, "Mean Q2": 703.693240234375, "critic_loss": 15.056561687469483, "batch_reward": 5.9505985107421875, "actor_loss": -704.3284543960814, "actor_target_entropy": -1.0, "actor_entropy": -0.30112349206493016, "alpha_loss": 0.00037069640691495605, "alpha_value": 0.1569346811500085, "duration": 150.66942477226257, "step": 64125}
{"episode_reward": 837.8762526224858, "episode": 514.0, "Q1 loss": 7.663950151443482, "Q2 loss": 7.6240892162323, "Mean Target Q": 703.9358984375, "Mean Q1": 703.937466796875, "Mean Q2": 703.9380776367187, "critic_loss": 15.288039379119873, "batch_reward": 5.937260391235352, "actor_loss": -704.361815421812, "actor_target_entropy": -1.0, "actor_entropy": -0.30488428737848033, "alpha_loss": 0.00219269554063137, "alpha_value": 0.15676689139064218, "duration": 154.4363555908203, "step": 64250}
{"episode_reward": 845.4343556147575, "episode": 515.0, "Q1 loss": 7.39970418548584, "Q2 loss": 7.310147930145264, "Mean Target Q": 704.6497705078125, "Mean Q1": 704.6469438476563, "Mean Q2": 704.6457412109374, "critic_loss": 14.709852130889892, "batch_reward": 5.965998596191406, "actor_loss": -704.8468191964286, "actor_target_entropy": -1.0, "actor_entropy": -0.2950939034658765, "alpha_loss": 0.003277094750147727, "alpha_value": 0.1565805940911083, "duration": 157.58482313156128, "step": 64375}
{"episode_reward": 840.9074195836333, "episode": 516.0, "Q1 loss": 8.53333811378479, "Q2 loss": 8.422922916412354, "Mean Target Q": 704.5434755859375, "Mean Q1": 704.5417817382812, "Mean Q2": 704.5401196289063, "critic_loss": 16.95626103591919, "batch_reward": 5.943485809326172, "actor_loss": -704.8272006127143, "actor_target_entropy": -1.0, "actor_entropy": -0.31597329724219536, "alpha_loss": -0.004716133131765791, "alpha_value": 0.15657666879100482, "duration": 149.7017912864685, "step": 64500}
{"episode_reward": 835.0848106060942, "episode": 517.0, "Q1 loss": 8.661617904663085, "Q2 loss": 8.611124105453491, "Mean Target Q": 704.5987646484375, "Mean Q1": 704.5985087890625, "Mean Q2": 704.598048828125, "critic_loss": 17.27274207305908, "batch_reward": 5.931495597839356, "actor_loss": -705.0504537915426, "actor_target_entropy": -1.0, "actor_entropy": -0.31069954780359116, "alpha_loss": -0.0018555845008305615, "alpha_value": 0.15696955862682627, "duration": 157.95790767669678, "step": 64625}
{"episode_reward": 848.387528827887, "episode": 518.0, "Q1 loss": 7.829257919311523, "Q2 loss": 7.888934200286865, "Mean Target Q": 705.2148369140625, "Mean Q1": 705.2150893554688, "Mean Q2": 705.2159731445313, "critic_loss": 15.718192180633546, "batch_reward": 5.94761547088623, "actor_loss": -705.5798448131931, "actor_target_entropy": -1.0, "actor_entropy": -0.27307372852679224, "alpha_loss": 0.005011917651450682, "alpha_value": 0.1568361793232989, "duration": 154.062597990036, "step": 64750}
{"episode_reward": 837.8600528331151, "episode": 519.0, "Q1 loss": 7.939456296920777, "Q2 loss": 8.001662244796753, "Mean Target Q": 705.1200170898437, "Mean Q1": 705.1208935546875, "Mean Q2": 705.1221000976562, "critic_loss": 15.941118556976319, "batch_reward": 5.947919410705566, "actor_loss": -705.4332604786706, "actor_target_entropy": -1.0, "actor_entropy": -0.3418786213511512, "alpha_loss": -0.001442066848366743, "alpha_value": 0.15655460135709212, "duration": 157.9391496181488, "step": 64875}
{"episode_reward": 762.0372803178984, "episode": 520.0, "Q1 loss": 8.234469434738159, "Q2 loss": 8.034069953918458, "Mean Target Q": 705.6843852539063, "Mean Q1": 705.6797109375, "Mean Q2": 705.6798203125, "critic_loss": 16.26853942489624, "batch_reward": 5.961645839691162, "actor_loss": -706.1041082566784, "actor_target_entropy": -1.0, "actor_entropy": -0.2961438060287506, "alpha_loss": 0.0032126313683787182, "alpha_value": 0.15640254510283616, "step": 65000}
{"duration": 175.71669840812683, "step": 65000}
{"episode_reward": 845.921287174498, "episode": 521.0, "Q1 loss": 7.285142978668213, "Q2 loss": 7.277497699737549, "Mean Target Q": 705.7592939453125, "Mean Q1": 705.7630678710938, "Mean Q2": 705.7630961914062, "critic_loss": 14.562640655517578, "batch_reward": 5.945965190887451, "actor_loss": -706.1525355747768, "actor_target_entropy": -1.0, "actor_entropy": -0.27850123151900275, "alpha_loss": 0.00846104659435768, "alpha_value": 0.15611873896829864, "duration": 160.26158928871155, "step": 65125}
{"episode_reward": 839.4558952611058, "episode": 522.0, "Q1 loss": 6.847690170288086, "Q2 loss": 6.959956554412842, "Mean Target Q": 706.58522265625, "Mean Q1": 706.580037109375, "Mean Q2": 706.5798051757813, "critic_loss": 13.807646724700927, "batch_reward": 5.984656074523926, "actor_loss": -706.8473786384828, "actor_target_entropy": -1.0, "actor_entropy": -0.270882127746459, "alpha_loss": 0.00879758214878459, "alpha_value": 0.15519258096805505, "duration": 155.52842378616333, "step": 65250}
{"episode_reward": 841.5460683548689, "episode": 523.0, "Q1 loss": 7.781379991531372, "Q2 loss": 7.64251079750061, "Mean Target Q": 706.41296875, "Mean Q1": 706.4096166992188, "Mean Q2": 706.4112524414063, "critic_loss": 15.423890747070313, "batch_reward": 5.9518674354553225, "actor_loss": -706.684333922371, "actor_target_entropy": -1.0, "actor_entropy": -0.2534871044613066, "alpha_loss": 0.010154365680165707, "alpha_value": 0.15436284388057486, "duration": 147.32244968414307, "step": 65375}
{"episode_reward": 830.9891838785287, "episode": 524.0, "Q1 loss": 7.320314208984375, "Q2 loss": 7.188557649612426, "Mean Target Q": 706.6453549804687, "Mean Q1": 706.6484389648438, "Mean Q2": 706.6446401367187, "critic_loss": 14.508871891021728, "batch_reward": 5.963271659851074, "actor_loss": -707.1628112792969, "actor_target_entropy": -1.0, "actor_entropy": -0.2913285070850003, "alpha_loss": 0.0006508091539745369, "alpha_value": 0.15393279312547467, "duration": 156.25053787231445, "step": 65500}
{"episode_reward": 834.396627108803, "episode": 525.0, "Q1 loss": 7.291397233963012, "Q2 loss": 7.336327354431153, "Mean Target Q": 706.722330078125, "Mean Q1": 706.7156772460937, "Mean Q2": 706.718671875, "critic_loss": 14.627724544525147, "batch_reward": 5.953186389923096, "actor_loss": -707.1048099578373, "actor_target_entropy": -1.0, "actor_entropy": -0.28758303608213154, "alpha_loss": 0.00237310067140719, "alpha_value": 0.15379847736672791, "duration": 157.93999218940735, "step": 65625}
{"episode_reward": 849.7217388253325, "episode": 526.0, "Q1 loss": 8.078843196868897, "Q2 loss": 7.893551252365112, "Mean Target Q": 707.1766459960937, "Mean Q1": 707.1781533203125, "Mean Q2": 707.1771801757812, "critic_loss": 15.972394428253175, "batch_reward": 5.9648293647766115, "actor_loss": -707.5803596742692, "actor_target_entropy": -1.0, "actor_entropy": -0.2950037821165977, "alpha_loss": 0.0034673389989972837, "alpha_value": 0.15336924759156328, "duration": 160.7058665752411, "step": 65750}
{"episode_reward": 844.1985017394542, "episode": 527.0, "Q1 loss": 7.743217473983765, "Q2 loss": 7.713878341674805, "Mean Target Q": 707.3236083984375, "Mean Q1": 707.3174321289063, "Mean Q2": 707.3180219726562, "critic_loss": 15.457095733642578, "batch_reward": 5.97248002243042, "actor_loss": -707.4822910853794, "actor_target_entropy": -1.0, "actor_entropy": -0.3293312064238957, "alpha_loss": -0.0027750010458042935, "alpha_value": 0.15334080997614893, "duration": 151.01508855819702, "step": 65875}
{"episode_reward": 828.3650810044107, "episode": 528.0, "Q1 loss": 7.4396198444366455, "Q2 loss": 7.370150493621826, "Mean Target Q": 707.547169921875, "Mean Q1": 707.5518911132813, "Mean Q2": 707.5514760742187, "critic_loss": 14.809770362854003, "batch_reward": 5.970220603942871, "actor_loss": -708.0901548324093, "actor_target_entropy": -1.0, "actor_entropy": -0.3146810808008717, "alpha_loss": 0.0005995502898229226, "alpha_value": 0.15343217312632848, "duration": 161.92151498794556, "step": 66000}
{"episode_reward": 847.8771223546985, "episode": 529.0, "Q1 loss": 7.206485956192017, "Q2 loss": 7.313480436325073, "Mean Target Q": 707.63123046875, "Mean Q1": 707.6249868164062, "Mean Q2": 707.6265629882812, "critic_loss": 14.519966442108155, "batch_reward": 5.963613452911377, "actor_loss": -707.9468374100942, "actor_target_entropy": -1.0, "actor_entropy": -0.30164320790578447, "alpha_loss": 0.0016098056396927744, "alpha_value": 0.15345981134422426, "duration": 151.80949759483337, "step": 66125}
{"episode_reward": 841.7156196746449, "episode": 530.0, "Q1 loss": 6.715514835357666, "Q2 loss": 6.679774293899536, "Mean Target Q": 707.989875, "Mean Q1": 707.9925678710938, "Mean Q2": 707.98897265625, "critic_loss": 13.39528911972046, "batch_reward": 5.966893787384033, "actor_loss": -708.2045347152218, "actor_target_entropy": -1.0, "actor_entropy": -0.29169747906346477, "alpha_loss": 0.0035071515669715743, "alpha_value": 0.15327166684819793, "duration": 152.55126452445984, "step": 66250}
{"episode_reward": 846.7905530931058, "episode": 531.0, "Q1 loss": 6.48578835105896, "Q2 loss": 6.519310094833374, "Mean Target Q": 708.2810400390625, "Mean Q1": 708.2823608398437, "Mean Q2": 708.2826235351563, "critic_loss": 13.005098449707031, "batch_reward": 5.973213405609131, "actor_loss": -708.8165321955605, "actor_target_entropy": -1.0, "actor_entropy": -0.3141441148897958, "alpha_loss": 0.0057079221569149505, "alpha_value": 0.15283972493682035, "duration": 158.43262720108032, "step": 66375}
{"episode_reward": 823.3671829857501, "episode": 532.0, "Q1 loss": 7.811719459533691, "Q2 loss": 7.831297367095948, "Mean Target Q": 708.2869497070312, "Mean Q1": 708.28651171875, "Mean Q2": 708.2877060546875, "critic_loss": 15.643016819000245, "batch_reward": 5.969620349884033, "actor_loss": -708.7619825793851, "actor_target_entropy": -1.0, "actor_entropy": -0.2538518725383666, "alpha_loss": 0.007443943868331131, "alpha_value": 0.15225619859883602, "duration": 153.35038208961487, "step": 66500}
{"episode_reward": 827.3562758651676, "episode": 533.0, "Q1 loss": 8.805715801239014, "Q2 loss": 8.704841753005981, "Mean Target Q": 708.388908203125, "Mean Q1": 708.3784384765625, "Mean Q2": 708.3783139648438, "critic_loss": 17.51055750656128, "batch_reward": 5.958391010284424, "actor_loss": -708.9656217060392, "actor_target_entropy": -1.0, "actor_entropy": -0.31834378081654746, "alpha_loss": 0.0004494698304269049, "alpha_value": 0.1518104824250215, "duration": 159.88633966445923, "step": 66625}
{"episode_reward": 843.5262249653043, "episode": 534.0, "Q1 loss": 8.091996631622315, "Q2 loss": 8.003473554611206, "Mean Target Q": 708.87464453125, "Mean Q1": 708.87365234375, "Mean Q2": 708.8753452148437, "critic_loss": 16.09547017669678, "batch_reward": 5.966183238983154, "actor_loss": -709.4952776508946, "actor_target_entropy": -1.0, "actor_entropy": -0.29642165115764063, "alpha_loss": 0.0016105948842220729, "alpha_value": 0.15167771130142002, "duration": 149.58319449424744, "step": 66750}
{"episode_reward": 815.9184963182928, "episode": 535.0, "Q1 loss": 6.907805374145508, "Q2 loss": 6.816590087890625, "Mean Target Q": 709.510537109375, "Mean Q1": 709.5113774414062, "Mean Q2": 709.5087045898438, "critic_loss": 13.72439548110962, "batch_reward": 5.992450504302979, "actor_loss": -709.9473324730283, "actor_target_entropy": -1.0, "actor_entropy": -0.31808139691277154, "alpha_loss": 0.001403206926105278, "alpha_value": 0.1515610910139853, "duration": 155.52932167053223, "step": 66875}
{"episode_reward": 833.850539475493, "episode": 536.0, "Q1 loss": 7.1153148021698, "Q2 loss": 7.037394990921021, "Mean Target Q": 709.2603833007812, "Mean Q1": 709.261982421875, "Mean Q2": 709.2623935546875, "critic_loss": 14.152709815979003, "batch_reward": 5.9641042327880855, "actor_loss": -709.6812665385585, "actor_target_entropy": -1.0, "actor_entropy": -0.32927933671782095, "alpha_loss": -0.0023939242011927547, "alpha_value": 0.15161806743884745, "duration": 158.7606430053711, "step": 67000}
{"episode_reward": 828.1562620427195, "episode": 537.0, "Q1 loss": 6.835429487228393, "Q2 loss": 6.828555740356445, "Mean Target Q": 709.5753422851562, "Mean Q1": 709.5750625, "Mean Q2": 709.5760258789062, "critic_loss": 13.663985248565673, "batch_reward": 5.968942604064941, "actor_loss": -709.7695670960442, "actor_target_entropy": -1.0, "actor_entropy": -0.3150890367844748, "alpha_loss": 0.00011580171883993206, "alpha_value": 0.15168748398860835, "duration": 165.69709181785583, "step": 67125}
{"episode_reward": 844.3410116092024, "episode": 538.0, "Q1 loss": 7.8327470359802245, "Q2 loss": 7.761671186447144, "Mean Target Q": 709.921166015625, "Mean Q1": 709.915048828125, "Mean Q2": 709.9155009765625, "critic_loss": 15.594418224334717, "batch_reward": 5.968622257232666, "actor_loss": -710.144303844821, "actor_target_entropy": -1.0, "actor_entropy": -0.3294130621417876, "alpha_loss": -0.0029259737479620644, "alpha_value": 0.15206608935341065, "duration": 156.39965844154358, "step": 67250}
{"episode_reward": 844.7230234903418, "episode": 539.0, "Q1 loss": 7.5959794788360595, "Q2 loss": 7.612199098587036, "Mean Target Q": 710.1763330078124, "Mean Q1": 710.1750693359375, "Mean Q2": 710.1763369140625, "critic_loss": 15.208178619384766, "batch_reward": 5.978488834381103, "actor_loss": -710.4701470269097, "actor_target_entropy": -1.0, "actor_entropy": -0.3055469374808054, "alpha_loss": 0.0008015299034822318, "alpha_value": 0.15203927056930924, "duration": 155.6323206424713, "step": 67375}
{"episode_reward": 840.2696659477606, "episode": 540.0, "Q1 loss": 7.794946090698242, "Q2 loss": 7.927292846679688, "Mean Target Q": 710.38525390625, "Mean Q1": 710.3876259765625, "Mean Q2": 710.3855268554687, "critic_loss": 15.722238914489747, "batch_reward": 5.973105091094971, "actor_loss": -710.5577441800025, "actor_target_entropy": -1.0, "actor_entropy": -0.2686722920306267, "alpha_loss": 0.00618531672667051, "alpha_value": 0.15171707841299514, "duration": 181.28507089614868, "step": 67500}
{"episode_reward": 847.504364380097, "episode": 541.0, "Q1 loss": 7.615175928115844, "Q2 loss": 7.552355558395385, "Mean Target Q": 710.6374331054687, "Mean Q1": 710.6264711914063, "Mean Q2": 710.629078125, "critic_loss": 15.167531570434571, "batch_reward": 5.995553268432618, "actor_loss": -711.1890694754464, "actor_target_entropy": -1.0, "actor_entropy": -0.28841777193167856, "alpha_loss": 0.004229673077278431, "alpha_value": 0.15116540515487198, "duration": 198.97914123535156, "step": 67625}
{"episode_reward": 838.189869867305, "episode": 542.0, "Q1 loss": 7.519779457092286, "Q2 loss": 7.43946653175354, "Mean Target Q": 710.756330078125, "Mean Q1": 710.7544096679687, "Mean Q2": 710.7517465820313, "critic_loss": 14.959246002197265, "batch_reward": 5.97689278793335, "actor_loss": -711.2329574092741, "actor_target_entropy": -1.0, "actor_entropy": -0.3050988018512726, "alpha_loss": -0.0014527078498260029, "alpha_value": 0.1510714450295213, "duration": 193.25877976417542, "step": 67750}
{"episode_reward": 847.7598555884557, "episode": 543.0, "Q1 loss": 7.013732326507569, "Q2 loss": 6.909962610244751, "Mean Target Q": 710.8258149414063, "Mean Q1": 710.8311909179688, "Mean Q2": 710.83251953125, "critic_loss": 13.923694927215577, "batch_reward": 5.965515789031983, "actor_loss": -711.2384566049727, "actor_target_entropy": -1.0, "actor_entropy": -0.2938149370371349, "alpha_loss": 0.0007876415943933858, "alpha_value": 0.15108839494034568, "duration": 181.83139300346375, "step": 67875}
{"episode_reward": 838.1354964814402, "episode": 544.0, "Q1 loss": 7.761277391433715, "Q2 loss": 7.832528745651245, "Mean Target Q": 711.3007607421875, "Mean Q1": 711.3008046875, "Mean Q2": 711.2988173828124, "critic_loss": 15.5938060836792, "batch_reward": 5.980190715789795, "actor_loss": -711.7754290180821, "actor_target_entropy": -1.0, "actor_entropy": -0.31588502060021123, "alpha_loss": -0.0025506691130313783, "alpha_value": 0.1511903264315537, "duration": 185.33616137504578, "step": 68000}
{"episode_reward": 820.8986963955035, "episode": 545.0, "Q1 loss": 7.145001461029053, "Q2 loss": 7.047698358535767, "Mean Target Q": 711.4769809570313, "Mean Q1": 711.4707661132812, "Mean Q2": 711.47419921875, "critic_loss": 14.192699813842774, "batch_reward": 5.988364418029785, "actor_loss": -711.7653527638269, "actor_target_entropy": -1.0, "actor_entropy": -0.28892190754413605, "alpha_loss": 0.004170187525377269, "alpha_value": 0.15097309174721527, "duration": 205.28018736839294, "step": 68125}
{"episode_reward": 849.7157964680151, "episode": 546.0, "Q1 loss": 7.713903087615967, "Q2 loss": 7.585542407989502, "Mean Target Q": 712.0229384765624, "Mean Q1": 712.0241552734375, "Mean Q2": 712.0230263671875, "critic_loss": 15.299445472717284, "batch_reward": 5.996462570190429, "actor_loss": -712.6917468655494, "actor_target_entropy": -1.0, "actor_entropy": -0.29005098751475733, "alpha_loss": 0.004410377709240082, "alpha_value": 0.15059617469267547, "duration": 192.17506885528564, "step": 68250}
{"episode_reward": 821.0371416604546, "episode": 547.0, "Q1 loss": 6.799942628860474, "Q2 loss": 6.682460723876953, "Mean Target Q": 711.857970703125, "Mean Q1": 711.8542934570313, "Mean Q2": 711.8536752929688, "critic_loss": 13.482403312683106, "batch_reward": 5.980453067779541, "actor_loss": -712.175796750992, "actor_target_entropy": -1.0, "actor_entropy": -0.31895223993157584, "alpha_loss": 0.0029026935595856417, "alpha_value": 0.15034595676608578, "duration": 205.15802526474, "step": 68375}
{"episode_reward": 836.1665034418073, "episode": 548.0, "Q1 loss": 7.823951608657837, "Q2 loss": 7.9401908855438235, "Mean Target Q": 712.1677592773437, "Mean Q1": 712.1652822265625, "Mean Q2": 712.1660673828125, "critic_loss": 15.764142475128175, "batch_reward": 5.985870906829834, "actor_loss": -712.6623259513609, "actor_target_entropy": -1.0, "actor_entropy": -0.33208543110278343, "alpha_loss": 0.0009386085552133379, "alpha_value": 0.15006108926495668, "duration": 196.1655879020691, "step": 68500}
{"episode_reward": 767.6261541807099, "episode": 549.0, "Q1 loss": 8.375379425048829, "Q2 loss": 8.37404188156128, "Mean Target Q": 712.3518803710938, "Mean Q1": 712.3508203125, "Mean Q2": 712.3511591796876, "critic_loss": 16.74942135620117, "batch_reward": 5.988413795471192, "actor_loss": -712.7476903521825, "actor_target_entropy": -1.0, "actor_entropy": -0.2964254118620403, "alpha_loss": 0.002605206722999731, "alpha_value": 0.14999590776834326, "duration": 196.44204807281494, "step": 68625}
{"episode_reward": 770.3483358562999, "episode": 550.0, "Q1 loss": 7.371596319198608, "Q2 loss": 7.347915702819824, "Mean Target Q": 712.9962275390625, "Mean Q1": 712.9985053710938, "Mean Q2": 712.9962099609374, "critic_loss": 14.719512042999268, "batch_reward": 6.0153112297058104, "actor_loss": -713.3314533848917, "actor_target_entropy": -1.0, "actor_entropy": -0.28308762874334087, "alpha_loss": 0.004638567999673767, "alpha_value": 0.1496443709801163, "duration": 194.5007758140564, "step": 68750}
{"episode_reward": 841.8537100950282, "episode": 551.0, "Q1 loss": 7.413508333206177, "Q2 loss": 7.263988077163696, "Mean Target Q": 713.0173334960938, "Mean Q1": 713.01673828125, "Mean Q2": 713.017068359375, "critic_loss": 14.677496383666993, "batch_reward": 5.990090114593506, "actor_loss": -713.5551564050099, "actor_target_entropy": -1.0, "actor_entropy": -0.28923277131148745, "alpha_loss": 0.0031462465634658223, "alpha_value": 0.14941125889329357, "duration": 188.8516047000885, "step": 68875}
{"episode_reward": 847.6614535158864, "episode": 552.0, "Q1 loss": 7.162844285964966, "Q2 loss": 7.120759531021118, "Mean Target Q": 713.2439477539062, "Mean Q1": 713.236748046875, "Mean Q2": 713.2359858398438, "critic_loss": 14.283603847503661, "batch_reward": 5.99854988861084, "actor_loss": -713.5110552387853, "actor_target_entropy": -1.0, "actor_entropy": -0.29466332254871247, "alpha_loss": 0.0007758596292396467, "alpha_value": 0.14915591535909833, "duration": 194.42658162117004, "step": 69000}
{"episode_reward": 835.2311665470364, "episode": 553.0, "Q1 loss": 6.708401605606079, "Q2 loss": 6.70061003112793, "Mean Target Q": 713.472576171875, "Mean Q1": 713.4777314453125, "Mean Q2": 713.4777822265625, "critic_loss": 13.409011646270752, "batch_reward": 5.996501514434814, "actor_loss": -713.8839276026166, "actor_target_entropy": -1.0, "actor_entropy": -0.28163476903287193, "alpha_loss": 0.004733722542397796, "alpha_value": 0.14888489773066374, "duration": 192.8062126636505, "step": 69125}
{"episode_reward": 823.9847868911444, "episode": 554.0, "Q1 loss": 6.457435308456421, "Q2 loss": 6.5220579929351805, "Mean Target Q": 713.6919262695312, "Mean Q1": 713.6885029296875, "Mean Q2": 713.6902729492188, "critic_loss": 12.97949326324463, "batch_reward": 5.995188571929932, "actor_loss": -714.1651178175404, "actor_target_entropy": -1.0, "actor_entropy": -0.32205587000616137, "alpha_loss": 0.0010661845444701612, "alpha_value": 0.14867631307658088, "duration": 196.1912281513214, "step": 69250}
{"episode_reward": 837.7501950852728, "episode": 555.0, "Q1 loss": 7.230658605575561, "Q2 loss": 7.217202127456665, "Mean Target Q": 713.7325620117188, "Mean Q1": 713.7313217773437, "Mean Q2": 713.7291450195313, "critic_loss": 14.44786071395874, "batch_reward": 5.9832455444335935, "actor_loss": -714.1252693297371, "actor_target_entropy": -1.0, "actor_entropy": -0.3347768121295505, "alpha_loss": -0.0032935747525669515, "alpha_value": 0.14866328460798992, "duration": 188.18105816841125, "step": 69375}
{"episode_reward": 843.0566230424416, "episode": 556.0, "Q1 loss": 7.443242839813232, "Q2 loss": 7.358455074310303, "Mean Target Q": 713.7885092773438, "Mean Q1": 713.789509765625, "Mean Q2": 713.7903979492188, "critic_loss": 14.801697921752929, "batch_reward": 5.974156852722168, "actor_loss": -714.3152711929813, "actor_target_entropy": -1.0, "actor_entropy": -0.34109021002246487, "alpha_loss": -0.0011752172816364515, "alpha_value": 0.1489834890224196, "duration": 189.0884702205658, "step": 69500}
{"episode_reward": 813.5739950848542, "episode": 557.0, "Q1 loss": 7.54188257598877, "Q2 loss": 7.545150047302246, "Mean Target Q": 714.5787744140625, "Mean Q1": 714.5770288085937, "Mean Q2": 714.577166015625, "critic_loss": 15.087032615661622, "batch_reward": 6.006250030517578, "actor_loss": -714.9323962983631, "actor_target_entropy": -1.0, "actor_entropy": -0.32144589107187965, "alpha_loss": -0.0016523249085164731, "alpha_value": 0.14912068106012666, "duration": 187.52560377120972, "step": 69625}
{"episode_reward": 834.2551435216824, "episode": 558.0, "Q1 loss": 7.50067301940918, "Q2 loss": 7.423756866455078, "Mean Target Q": 714.29610546875, "Mean Q1": 714.2872534179687, "Mean Q2": 714.2888852539063, "critic_loss": 14.924429801940917, "batch_reward": 5.98385799407959, "actor_loss": -715.0235379126764, "actor_target_entropy": -1.0, "actor_entropy": -0.29231650742792314, "alpha_loss": 0.0033104357219511465, "alpha_value": 0.14895927372825482, "duration": 176.030118227005, "step": 69750}
{"episode_reward": 847.6091149115547, "episode": 559.0, "Q1 loss": 7.177320207595825, "Q2 loss": 7.154149423599243, "Mean Target Q": 714.76223828125, "Mean Q1": 714.7624208984375, "Mean Q2": 714.7617348632813, "critic_loss": 14.331469554901123, "batch_reward": 6.000504211425781, "actor_loss": -715.3536590091766, "actor_target_entropy": -1.0, "actor_entropy": -0.3607309507945227, "alpha_loss": 7.213486935056391e-06, "alpha_value": 0.1488107705282, "duration": 188.48998284339905, "step": 69875}
{"episode_reward": 850.5236950461211, "episode": 560.0, "Q1 loss": 7.074835844039917, "Q2 loss": 6.999353942871093, "Mean Target Q": 715.2669702148437, "Mean Q1": 715.2728701171875, "Mean Q2": 715.272515625, "critic_loss": 14.07418980026245, "batch_reward": 6.013758941650391, "actor_loss": -715.8903454196069, "actor_target_entropy": -1.0, "actor_entropy": -0.3100696088325593, "alpha_loss": 0.003993738508377705, "alpha_value": 0.14860248960626604, "step": 70000}
{"duration": 200.5502679347992, "step": 70000}
{"episode_reward": 848.503273682496, "episode": 561.0, "Q1 loss": 6.8823560543060305, "Q2 loss": 6.707013685226441, "Mean Target Q": 715.0655712890625, "Mean Q1": 715.062794921875, "Mean Q2": 715.0619775390625, "critic_loss": 13.589369731903076, "batch_reward": 6.001740013122559, "actor_loss": -715.2644595191592, "actor_target_entropy": -1.0, "actor_entropy": -0.313203810462876, "alpha_loss": 0.0009757886540942959, "alpha_value": 0.14853221403185846, "duration": 220.51569151878357, "step": 70125}
{"episode_reward": 838.1798551773194, "episode": 562.0, "Q1 loss": 6.492321804046631, "Q2 loss": 6.410549638748169, "Mean Target Q": 715.3934926757812, "Mean Q1": 715.3983876953125, "Mean Q2": 715.3985209960938, "critic_loss": 12.902871406555176, "batch_reward": 6.0151915473937985, "actor_loss": -716.1053456952495, "actor_target_entropy": -1.0, "actor_entropy": -0.3092658736052052, "alpha_loss": 0.0023406478144498842, "alpha_value": 0.148287416598061, "duration": 194.44356513023376, "step": 70250}
{"episode_reward": 848.6659009151527, "episode": 563.0, "Q1 loss": 6.979679666519165, "Q2 loss": 6.96202039527893, "Mean Target Q": 715.9146352539062, "Mean Q1": 715.9084111328125, "Mean Q2": 715.9088491210938, "critic_loss": 13.941700134277344, "batch_reward": 6.011122184753418, "actor_loss": -716.6136658683656, "actor_target_entropy": -1.0, "actor_entropy": -0.3265647862165693, "alpha_loss": 0.0018842102708442816, "alpha_value": 0.14814062547565143, "duration": 188.72907257080078, "step": 70375}
{"episode_reward": 829.1531714130954, "episode": 564.0, "Q1 loss": 6.277023323059082, "Q2 loss": 6.367352069854737, "Mean Target Q": 715.5261098632812, "Mean Q1": 715.5208515625, "Mean Q2": 715.5198510742188, "critic_loss": 12.644375366210937, "batch_reward": 5.98311075592041, "actor_loss": -715.901371125252, "actor_target_entropy": -1.0, "actor_entropy": -0.2791729829003734, "alpha_loss": 0.007509473613613556, "alpha_value": 0.1476152691825463, "duration": 186.40845656394958, "step": 70500}
{"episode_reward": 842.9588498269923, "episode": 565.0, "Q1 loss": 6.976909198760986, "Q2 loss": 6.904011344909668, "Mean Target Q": 716.2103486328125, "Mean Q1": 716.2090283203125, "Mean Q2": 716.2102705078125, "critic_loss": 13.880920593261719, "batch_reward": 6.013071578979492, "actor_loss": -716.6471877325149, "actor_target_entropy": -1.0, "actor_entropy": -0.2962142245637046, "alpha_loss": 0.003751266636841354, "alpha_value": 0.14715898052748835, "duration": 177.91008496284485, "step": 70625}
{"episode_reward": 848.9196999739096, "episode": 566.0, "Q1 loss": 7.600169023513794, "Q2 loss": 7.650573657989502, "Mean Target Q": 716.3458076171875, "Mean Q1": 716.3526572265625, "Mean Q2": 716.3523002929687, "critic_loss": 15.250742729187012, "batch_reward": 6.005477001190186, "actor_loss": -716.8965306435862, "actor_target_entropy": -1.0, "actor_entropy": -0.31647288342637403, "alpha_loss": 0.0018550051289850907, "alpha_value": 0.1468835362199599, "duration": 184.98865032196045, "step": 70750}
{"episode_reward": 777.1720618912029, "episode": 567.0, "Q1 loss": 6.901758769989014, "Q2 loss": 6.934024616241455, "Mean Target Q": 716.3958984375, "Mean Q1": 716.3879916992188, "Mean Q2": 716.3885786132812, "critic_loss": 13.835783447265625, "batch_reward": 6.009673347473145, "actor_loss": -717.0612279498388, "actor_target_entropy": -1.0, "actor_entropy": -0.3266466416063763, "alpha_loss": -0.00011527650095226746, "alpha_value": 0.14676107552323575, "duration": 186.62554121017456, "step": 70875}
{"episode_reward": 846.989151793794, "episode": 568.0, "Q1 loss": 6.840099733352661, "Q2 loss": 6.913186622619629, "Mean Target Q": 716.4692275390624, "Mean Q1": 716.467115234375, "Mean Q2": 716.468947265625, "critic_loss": 13.753286399841308, "batch_reward": 5.9973789367675785, "actor_loss": -716.6485172394783, "actor_target_entropy": -1.0, "actor_entropy": -0.330084262836364, "alpha_loss": -0.00184217382470266, "alpha_value": 0.14687968887397573, "duration": 191.30734992027283, "step": 71000}
{"episode_reward": 778.8884078681451, "episode": 569.0, "Q1 loss": 6.946874687194824, "Q2 loss": 6.861886001586914, "Mean Target Q": 716.8421674804688, "Mean Q1": 716.8420541992188, "Mean Q2": 716.840337890625, "critic_loss": 13.80876068496704, "batch_reward": 6.0046393737792965, "actor_loss": -717.3384040953621, "actor_target_entropy": -1.0, "actor_entropy": -0.3341020345687866, "alpha_loss": 0.0007127665393497972, "alpha_value": 0.1469769086700651, "duration": 186.4479205608368, "step": 71125}
{"episode_reward": 834.8678910686922, "episode": 570.0, "Q1 loss": 6.646743974685669, "Q2 loss": 6.64463530921936, "Mean Target Q": 717.2187001953125, "Mean Q1": 717.21869140625, "Mean Q2": 717.2170795898437, "critic_loss": 13.291379371643066, "batch_reward": 6.002545509338379, "actor_loss": -717.5126214796497, "actor_target_entropy": -1.0, "actor_entropy": -0.28507885408978306, "alpha_loss": 0.002356183600627006, "alpha_value": 0.1468525101239713, "duration": 195.7067563533783, "step": 71250}
{"episode_reward": 842.4582274094726, "episode": 571.0, "Q1 loss": 7.476577936172485, "Q2 loss": 7.444693933486938, "Mean Target Q": 717.4520122070312, "Mean Q1": 717.451728515625, "Mean Q2": 717.4536069335937, "critic_loss": 14.921271884918212, "batch_reward": 6.003122707366943, "actor_loss": -717.8749670603919, "actor_target_entropy": -1.0, "actor_entropy": -0.30726735861528487, "alpha_loss": 0.0030657435778439755, "alpha_value": 0.14655108451143584, "duration": 181.29098677635193, "step": 71375}
{"episode_reward": 841.2241963468173, "episode": 572.0, "Q1 loss": 7.575063800811767, "Q2 loss": 7.571643297195434, "Mean Target Q": 717.4789702148438, "Mean Q1": 717.473537109375, "Mean Q2": 717.4732924804688, "critic_loss": 15.146707050323487, "batch_reward": 6.00274182510376, "actor_loss": -717.7928555396295, "actor_target_entropy": -1.0, "actor_entropy": -0.2941663181108813, "alpha_loss": 0.004809268265812387, "alpha_value": 0.14618417169168305, "duration": 193.477698802948, "step": 71500}
{"episode_reward": 830.9878578961489, "episode": 573.0, "Q1 loss": 6.891942750930786, "Q2 loss": 7.014198057174682, "Mean Target Q": 717.7042548828125, "Mean Q1": 717.697056640625, "Mean Q2": 717.6983505859375, "critic_loss": 13.906140846252441, "batch_reward": 6.013221473693847, "actor_loss": -717.9133513919891, "actor_target_entropy": -1.0, "actor_entropy": -0.3108773749499094, "alpha_loss": -0.0017148427857411287, "alpha_value": 0.14593126512943244, "duration": 199.81815457344055, "step": 71625}
{"episode_reward": 825.8895473203451, "episode": 574.0, "Q1 loss": 7.596085313796997, "Q2 loss": 7.473713857650757, "Mean Target Q": 718.3187099609376, "Mean Q1": 718.321392578125, "Mean Q2": 718.322345703125, "critic_loss": 15.069799194335937, "batch_reward": 6.046959316253662, "actor_loss": -718.488053844821, "actor_target_entropy": -1.0, "actor_entropy": -0.32177252803118, "alpha_loss": 0.0021703249301701305, "alpha_value": 0.14598465556689658, "duration": 184.32819843292236, "step": 71750}
{"episode_reward": 846.6614808901386, "episode": 575.0, "Q1 loss": 6.880082511901856, "Q2 loss": 6.9211357383728025, "Mean Target Q": 718.3361665039063, "Mean Q1": 718.33953515625, "Mean Q2": 718.3368803710938, "critic_loss": 13.801218250274658, "batch_reward": 6.007916110992432, "actor_loss": -718.6249970935639, "actor_target_entropy": -1.0, "actor_entropy": -0.28996372577689944, "alpha_loss": 0.004912308722157918, "alpha_value": 0.1456760959583114, "duration": 196.1367380619049, "step": 71875}
{"episode_reward": 837.2856466131303, "episode": 576.0, "Q1 loss": 6.52170756149292, "Q2 loss": 6.535913206100464, "Mean Target Q": 718.3268217773438, "Mean Q1": 718.3220356445313, "Mean Q2": 718.3240556640625, "critic_loss": 13.057620738983154, "batch_reward": 6.026160358428955, "actor_loss": -718.5153267152848, "actor_target_entropy": -1.0, "actor_entropy": -0.34177160263061523, "alpha_loss": -0.006068373367475766, "alpha_value": 0.14569087222205143, "duration": 187.49621558189392, "step": 72000}
{"episode_reward": 838.1675343861773, "episode": 577.0, "Q1 loss": 6.7590951900482175, "Q2 loss": 6.548133312225342, "Mean Target Q": 718.7415068359375, "Mean Q1": 718.7452451171876, "Mean Q2": 718.7430908203125, "critic_loss": 13.307228481292725, "batch_reward": 6.012427532196045, "actor_loss": -719.2208397274926, "actor_target_entropy": -1.0, "actor_entropy": -0.30138363251610406, "alpha_loss": -0.00027165611344759187, "alpha_value": 0.14600252410523445, "duration": 193.8971312046051, "step": 72125}
{"episode_reward": 830.4936417709126, "episode": 578.0, "Q1 loss": 6.567341072082519, "Q2 loss": 6.653232448577881, "Mean Target Q": 718.83230859375, "Mean Q1": 718.8331694335938, "Mean Q2": 718.834107421875, "critic_loss": 13.220573551177978, "batch_reward": 6.014303653717041, "actor_loss": -719.1251358524446, "actor_target_entropy": -1.0, "actor_entropy": -0.3223429077094601, "alpha_loss": 0.0023149501010324928, "alpha_value": 0.1459073537774491, "duration": 191.7010521888733, "step": 72250}
{"episode_reward": 850.8248342079532, "episode": 579.0, "Q1 loss": 7.5438491744995115, "Q2 loss": 7.416277984619141, "Mean Target Q": 719.025716796875, "Mean Q1": 719.0221831054688, "Mean Q2": 719.02174609375, "critic_loss": 14.960127174377442, "batch_reward": 6.020613063812256, "actor_loss": -719.2841864691841, "actor_target_entropy": -1.0, "actor_entropy": -0.32975226546090747, "alpha_loss": -0.0035334814761188767, "alpha_value": 0.14593930779456968, "duration": 190.51382517814636, "step": 72375}
{"episode_reward": 846.0687643165297, "episode": 580.0, "Q1 loss": 7.114634344100952, "Q2 loss": 7.00835606956482, "Mean Target Q": 718.7938940429688, "Mean Q1": 718.7877978515625, "Mean Q2": 718.7874326171875, "critic_loss": 14.122990383148194, "batch_reward": 5.997960475921631, "actor_loss": -719.570553687311, "actor_target_entropy": -1.0, "actor_entropy": -0.355406186994045, "alpha_loss": -0.0024613161954367834, "alpha_value": 0.1463532118684129, "duration": 185.092346906662, "step": 72500}
{"episode_reward": 833.936456351652, "episode": 581.0, "Q1 loss": 7.669534158706665, "Q2 loss": 7.46372441482544, "Mean Target Q": 719.2454072265625, "Mean Q1": 719.2406196289063, "Mean Q2": 719.2393583984375, "critic_loss": 15.133258514404297, "batch_reward": 6.015169719696045, "actor_loss": -719.6253371465774, "actor_target_entropy": -1.0, "actor_entropy": -0.29285126498767305, "alpha_loss": 0.005305080645022884, "alpha_value": 0.14621370891783367, "duration": 190.86378931999207, "step": 72625}
{"episode_reward": 848.3568895851414, "episode": 582.0, "Q1 loss": 6.528588403701782, "Q2 loss": 6.512694208145142, "Mean Target Q": 719.8687778320312, "Mean Q1": 719.87066015625, "Mean Q2": 719.873068359375, "critic_loss": 13.041282539367677, "batch_reward": 6.05608715057373, "actor_loss": -720.1193621235509, "actor_target_entropy": -1.0, "actor_entropy": -0.28410063419611226, "alpha_loss": 0.006866628610183515, "alpha_value": 0.14550126307817024, "duration": 184.77124500274658, "step": 72750}
{"episode_reward": 843.0327962797398, "episode": 583.0, "Q1 loss": 6.477227237701416, "Q2 loss": 6.462868898391724, "Mean Target Q": 719.775109375, "Mean Q1": 719.7781982421875, "Mean Q2": 719.7768842773437, "critic_loss": 12.940096096038818, "batch_reward": 6.01498709487915, "actor_loss": -720.3474324544271, "actor_target_entropy": -1.0, "actor_entropy": -0.33224222205934073, "alpha_loss": 0.0006072393005033807, "alpha_value": 0.14524495207837188, "duration": 194.36330604553223, "step": 72875}
{"episode_reward": 849.2545318767129, "episode": 584.0, "Q1 loss": 6.961642961502076, "Q2 loss": 7.013602596282959, "Mean Target Q": 720.2245776367188, "Mean Q1": 720.2152646484375, "Mean Q2": 720.2152260742188, "critic_loss": 13.975245609283448, "batch_reward": 6.042339191436768, "actor_loss": -720.6920668079007, "actor_target_entropy": -1.0, "actor_entropy": -0.3111762803408407, "alpha_loss": 0.0018980729632124666, "alpha_value": 0.14501258938301678, "duration": 187.21657490730286, "step": 73000}
{"episode_reward": 821.4360540980659, "episode": 585.0, "Q1 loss": 6.884164392471313, "Q2 loss": 6.9908068752288814, "Mean Target Q": 720.1639140625, "Mean Q1": 720.16586328125, "Mean Q2": 720.1686420898437, "critic_loss": 13.874971218109131, "batch_reward": 6.022320152282715, "actor_loss": -720.2704235258557, "actor_target_entropy": -1.0, "actor_entropy": -0.3147621114575674, "alpha_loss": -0.00129576406574675, "alpha_value": 0.14507772485768855, "duration": 188.21412253379822, "step": 73125}
{"episode_reward": 840.6964766104556, "episode": 586.0, "Q1 loss": 6.643605690002442, "Q2 loss": 6.519974203109741, "Mean Target Q": 720.6685390625, "Mean Q1": 720.6684038085938, "Mean Q2": 720.666412109375, "critic_loss": 13.163579833984375, "batch_reward": 6.04053842163086, "actor_loss": -720.9751596758442, "actor_target_entropy": -1.0, "actor_entropy": -0.310888277667184, "alpha_loss": -0.002306472190896109, "alpha_value": 0.145181789005578, "duration": 183.95889377593994, "step": 73250}
{"episode_reward": 851.0535887802465, "episode": 587.0, "Q1 loss": 6.719057434082031, "Q2 loss": 6.655523704528808, "Mean Target Q": 720.763583984375, "Mean Q1": 720.7635522460937, "Mean Q2": 720.7620122070313, "critic_loss": 13.374581115722656, "batch_reward": 6.043574161529541, "actor_loss": -721.193347749256, "actor_target_entropy": -1.0, "actor_entropy": -0.37679356383898904, "alpha_loss": -0.006778513223657178, "alpha_value": 0.1455572388694486, "duration": 196.08033800125122, "step": 73375}
{"episode_reward": 840.9178877143664, "episode": 588.0, "Q1 loss": 6.584320817947388, "Q2 loss": 6.564470495223999, "Mean Target Q": 720.876677734375, "Mean Q1": 720.875916015625, "Mean Q2": 720.8775698242188, "critic_loss": 13.148791286468505, "batch_reward": 6.029556358337403, "actor_loss": -721.4466001449093, "actor_target_entropy": -1.0, "actor_entropy": -0.32459883632198455, "alpha_loss": -0.0024212758101883436, "alpha_value": 0.14608176913992454, "duration": 183.8828902244568, "step": 73500}
{"episode_reward": 812.6246618652184, "episode": 589.0, "Q1 loss": 6.607023956298828, "Q2 loss": 6.5532973136901855, "Mean Target Q": 721.2100048828125, "Mean Q1": 721.2068676757813, "Mean Q2": 721.2064741210937, "critic_loss": 13.160321292877198, "batch_reward": 6.042561000823975, "actor_loss": -721.6128578791543, "actor_target_entropy": -1.0, "actor_entropy": -0.3353832018753839, "alpha_loss": -0.0030640754978069, "alpha_value": 0.14626386588538537, "duration": 194.58101081848145, "step": 73625}
{"episode_reward": 841.0683024419515, "episode": 590.0, "Q1 loss": 6.050595779418945, "Q2 loss": 5.928670202255249, "Mean Target Q": 721.4509770507813, "Mean Q1": 721.4524672851562, "Mean Q2": 721.4540805664062, "critic_loss": 11.979265964508057, "batch_reward": 6.055078868865967, "actor_loss": -721.867439516129, "actor_target_entropy": -1.0, "actor_entropy": -0.32116039602025864, "alpha_loss": 0.0013235696110754243, "alpha_value": 0.1464448009382279, "duration": 186.11965537071228, "step": 73750}
{"episode_reward": 844.6232975494124, "episode": 591.0, "Q1 loss": 7.068678712844848, "Q2 loss": 7.023626222610473, "Mean Target Q": 721.4916748046875, "Mean Q1": 721.486404296875, "Mean Q2": 721.4880737304687, "critic_loss": 14.092304954528808, "batch_reward": 6.042746257781983, "actor_loss": -721.9154420882936, "actor_target_entropy": -1.0, "actor_entropy": -0.34017654685747056, "alpha_loss": 0.0008291050880437805, "alpha_value": 0.14628185166640512, "duration": 193.4213845729828, "step": 73875}
{"episode_reward": 844.6426065792632, "episode": 592.0, "Q1 loss": 6.780978746414185, "Q2 loss": 6.845776050567627, "Mean Target Q": 721.8373583984375, "Mean Q1": 721.8347612304688, "Mean Q2": 721.8325048828125, "critic_loss": 13.626754802703857, "batch_reward": 6.0545980186462405, "actor_loss": -722.1798745432208, "actor_target_entropy": -1.0, "actor_entropy": -0.3156856178276001, "alpha_loss": 0.005578134392928933, "alpha_value": 0.14607949668604275, "duration": 180.40923476219177, "step": 74000}
{"episode_reward": 840.5831678085503, "episode": 593.0, "Q1 loss": 6.606688417434692, "Q2 loss": 6.503249446868897, "Mean Target Q": 721.5072255859375, "Mean Q1": 721.5066391601563, "Mean Q2": 721.5092348632812, "critic_loss": 13.109937839508056, "batch_reward": 6.0251760673522945, "actor_loss": -722.0526694645957, "actor_target_entropy": -1.0, "actor_entropy": -0.2984295688451283, "alpha_loss": 0.0033705844275934236, "alpha_value": 0.14549267462761714, "duration": 188.174245595932, "step": 74125}
{"episode_reward": 818.4497246569321, "episode": 594.0, "Q1 loss": 6.934415014266968, "Q2 loss": 6.971664468765259, "Mean Target Q": 721.9731909179687, "Mean Q1": 721.9748852539062, "Mean Q2": 721.970712890625, "critic_loss": 13.906079483032226, "batch_reward": 6.039918846130371, "actor_loss": -722.2342824628277, "actor_target_entropy": -1.0, "actor_entropy": -0.33438754057691944, "alpha_loss": 0.00031382469610581474, "alpha_value": 0.14538483138238306, "duration": 194.4741871356964, "step": 74250}
{"episode_reward": 831.924706656533, "episode": 595.0, "Q1 loss": 7.986406721115112, "Q2 loss": 7.888823780059814, "Mean Target Q": 722.2619052734375, "Mean Q1": 722.2653271484374, "Mean Q2": 722.2689248046875, "critic_loss": 15.875230575561524, "batch_reward": 6.04029362487793, "actor_loss": -722.1930871388269, "actor_target_entropy": -1.0, "actor_entropy": -0.2708093322931774, "alpha_loss": 0.0048101660352022875, "alpha_value": 0.14512427848273501, "duration": 190.24194169044495, "step": 74375}
{"episode_reward": 821.5728246065886, "episode": 596.0, "Q1 loss": 6.807594635009766, "Q2 loss": 6.835698293685913, "Mean Target Q": 722.1332758789063, "Mean Q1": 722.1290458984375, "Mean Q2": 722.126107421875, "critic_loss": 13.643292907714844, "batch_reward": 6.034596767425537, "actor_loss": -722.4854972593246, "actor_target_entropy": -1.0, "actor_entropy": -0.33060508822241136, "alpha_loss": -0.0019934481974961536, "alpha_value": 0.14504459327987618, "duration": 196.5671615600586, "step": 74500}
{"episode_reward": 846.149016558256, "episode": 597.0, "Q1 loss": 6.4689656925201415, "Q2 loss": 6.3131673412323, "Mean Target Q": 722.3550141601562, "Mean Q1": 722.3480698242188, "Mean Q2": 722.347705078125, "critic_loss": 12.782133041381837, "batch_reward": 6.039828567504883, "actor_loss": -722.7884899321057, "actor_target_entropy": -1.0, "actor_entropy": -0.3286791266429992, "alpha_loss": 1.272114570296946e-06, "alpha_value": 0.14506710152119326, "duration": 189.35649132728577, "step": 74625}
{"episode_reward": 847.2406521353689, "episode": 598.0, "Q1 loss": 6.264336126327515, "Q2 loss": 6.330052234649658, "Mean Target Q": 722.64537890625, "Mean Q1": 722.6465913085938, "Mean Q2": 722.6478588867187, "critic_loss": 12.594388343811035, "batch_reward": 6.041675666809082, "actor_loss": -723.1615364320817, "actor_target_entropy": -1.0, "actor_entropy": -0.31125815116590067, "alpha_loss": 0.003193161061649481, "alpha_value": 0.14492938124787635, "duration": 200.58250093460083, "step": 74750}
{"episode_reward": 841.14261653939, "episode": 599.0, "Q1 loss": 6.466319494247436, "Q2 loss": 6.406968441009521, "Mean Target Q": 722.86583984375, "Mean Q1": 722.8645180664063, "Mean Q2": 722.86537109375, "critic_loss": 12.873287948608398, "batch_reward": 6.052733203887939, "actor_loss": -723.4596024770585, "actor_target_entropy": -1.0, "actor_entropy": -0.33921062899014304, "alpha_loss": 0.0035585359677613253, "alpha_value": 0.14472622532148396, "duration": 190.00788187980652, "step": 74875}
{"episode_reward": 767.2155861100434, "episode": 600.0, "Q1 loss": 7.408472688674927, "Q2 loss": 7.338844585418701, "Mean Target Q": 722.7645439453125, "Mean Q1": 722.7616723632813, "Mean Q2": 722.7605219726563, "critic_loss": 14.74731731414795, "batch_reward": 6.0447571144104, "actor_loss": -722.910645515688, "actor_target_entropy": -1.0, "actor_entropy": -0.35614955281057664, "alpha_loss": -0.0028473189205772452, "alpha_value": 0.14471065563047952, "step": 75000}
{"duration": 211.11243534088135, "step": 75000}
{"episode_reward": 849.2212218766578, "episode": 601.0, "Q1 loss": 6.137053848266602, "Q2 loss": 6.208328947067261, "Mean Target Q": 723.03573046875, "Mean Q1": 723.0346958007813, "Mean Q2": 723.0331552734375, "critic_loss": 12.345382816314697, "batch_reward": 6.042251701354981, "actor_loss": -723.6790965246776, "actor_target_entropy": -1.0, "actor_entropy": -0.3398839689436413, "alpha_loss": 0.002864401113049733, "alpha_value": 0.14455286747568155, "duration": 160.87222266197205, "step": 75125}
{"episode_reward": 843.1519317177731, "episode": 602.0, "Q1 loss": 6.633697057723999, "Q2 loss": 6.693888656616211, "Mean Target Q": 723.0949018554687, "Mean Q1": 723.0944033203125, "Mean Q2": 723.0954487304688, "critic_loss": 13.327585704803466, "batch_reward": 6.04554360961914, "actor_loss": -723.3545207362021, "actor_target_entropy": -1.0, "actor_entropy": -0.3751815812241647, "alpha_loss": -0.0024685170604742224, "alpha_value": 0.1445662796388823, "duration": 188.02866077423096, "step": 75250}
{"episode_reward": 850.9251650657884, "episode": 603.0, "Q1 loss": 6.067692369461059, "Q2 loss": 5.8805990886688235, "Mean Target Q": 723.3141220703125, "Mean Q1": 723.3131826171875, "Mean Q2": 723.3135961914063, "critic_loss": 11.948291484832763, "batch_reward": 6.054481800079346, "actor_loss": -723.7066756959946, "actor_target_entropy": -1.0, "actor_entropy": -0.33378583571267506, "alpha_loss": -0.001258247672388005, "alpha_value": 0.14487867519769276, "duration": 185.29737067222595, "step": 75375}
{"episode_reward": 832.6437824069628, "episode": 604.0, "Q1 loss": 6.0944964237213135, "Q2 loss": 6.055826217651367, "Mean Target Q": 723.3607392578125, "Mean Q1": 723.3600380859375, "Mean Q2": 723.3595859375, "critic_loss": 12.150322677612305, "batch_reward": 6.0294820556640625, "actor_loss": -723.6554398075227, "actor_target_entropy": -1.0, "actor_entropy": -0.3513421570101092, "alpha_loss": -0.0029225116257645912, "alpha_value": 0.1450018024115112, "duration": 179.01068305969238, "step": 75500}
{"episode_reward": 837.1681251477045, "episode": 605.0, "Q1 loss": 6.870348051071167, "Q2 loss": 6.734135292053223, "Mean Target Q": 723.7410087890624, "Mean Q1": 723.7395395507813, "Mean Q2": 723.7384208984375, "critic_loss": 13.604483348846436, "batch_reward": 6.055427593231201, "actor_loss": -724.3315623449901, "actor_target_entropy": -1.0, "actor_entropy": -0.35208015072913396, "alpha_loss": -0.0007990706279607755, "alpha_value": 0.14515053417920262, "duration": 183.88987970352173, "step": 75625}
{"episode_reward": 836.3549943736522, "episode": 606.0, "Q1 loss": 5.966004625320434, "Q2 loss": 5.991053480148316, "Mean Target Q": 724.0181186523438, "Mean Q1": 724.010224609375, "Mean Q2": 724.0117744140625, "critic_loss": 11.95705806350708, "batch_reward": 6.0521029968261715, "actor_loss": -724.2628646358366, "actor_target_entropy": -1.0, "actor_entropy": -0.3335189139170031, "alpha_loss": 0.0015954808069152697, "alpha_value": 0.14523995737054793, "duration": 202.25142335891724, "step": 75750}
{"episode_reward": 835.381764855522, "episode": 607.0, "Q1 loss": 5.801782878875732, "Q2 loss": 5.744796297073364, "Mean Target Q": 724.0173461914062, "Mean Q1": 724.025611328125, "Mean Q2": 724.024654296875, "critic_loss": 11.546579219818115, "batch_reward": 6.046875961303711, "actor_loss": -724.4216512044271, "actor_target_entropy": -1.0, "actor_entropy": -0.2956755147093818, "alpha_loss": 0.0030693821184011915, "alpha_value": 0.14498403650283984, "duration": 184.47162508964539, "step": 75875}
{"episode_reward": 852.1332488846795, "episode": 608.0, "Q1 loss": 5.605854248046875, "Q2 loss": 5.577731628417968, "Mean Target Q": 724.2802377929687, "Mean Q1": 724.2756000976563, "Mean Q2": 724.2770590820312, "critic_loss": 11.183585899353027, "batch_reward": 6.053769187927246, "actor_loss": -724.5099625126009, "actor_target_entropy": -1.0, "actor_entropy": -0.3328485616272496, "alpha_loss": 0.0014776254181690033, "alpha_value": 0.14465850935672075, "duration": 184.10004043579102, "step": 76000}
{"episode_reward": 842.1210971351618, "episode": 609.0, "Q1 loss": 6.2009819221496585, "Q2 loss": 6.232958250045776, "Mean Target Q": 724.4954858398437, "Mean Q1": 724.4921176757813, "Mean Q2": 724.4905415039062, "critic_loss": 12.433940238952637, "batch_reward": 6.054986541748047, "actor_loss": -724.7284352136037, "actor_target_entropy": -1.0, "actor_entropy": -0.3282116921175094, "alpha_loss": 0.002542766892085118, "alpha_value": 0.14457230287054137, "duration": 175.68650150299072, "step": 76125}
{"episode_reward": 850.072147957845, "episode": 610.0, "Q1 loss": 7.266399715423584, "Q2 loss": 7.108469409942627, "Mean Target Q": 724.3240102539063, "Mean Q1": 724.3262802734375, "Mean Q2": 724.3280805664062, "critic_loss": 14.374869060516357, "batch_reward": 6.043993171691895, "actor_loss": -724.6796559979839, "actor_target_entropy": -1.0, "actor_entropy": -0.35052760089597396, "alpha_loss": 0.00039916484233652874, "alpha_value": 0.14440182892909356, "duration": 189.9475085735321, "step": 76250}
{"episode_reward": 842.7876849057494, "episode": 611.0, "Q1 loss": 6.751106521606445, "Q2 loss": 6.726562494277954, "Mean Target Q": 724.7599819335937, "Mean Q1": 724.7650126953125, "Mean Q2": 724.7648564453125, "critic_loss": 13.47766898727417, "batch_reward": 6.065390842437744, "actor_loss": -725.5435626317584, "actor_target_entropy": -1.0, "actor_entropy": -0.3397944039768643, "alpha_loss": 0.0022314441896649816, "alpha_value": 0.1442419074172557, "duration": 181.87288355827332, "step": 76375}
{"episode_reward": 852.632104870652, "episode": 612.0, "Q1 loss": 7.125350317001343, "Q2 loss": 7.080089000701904, "Mean Target Q": 724.66994140625, "Mean Q1": 724.6565693359375, "Mean Q2": 724.6569829101562, "critic_loss": 14.205439273834228, "batch_reward": 6.052348808288574, "actor_loss": -725.0145440870716, "actor_target_entropy": -1.0, "actor_entropy": -0.32167824742294127, "alpha_loss": -6.508591937862577e-05, "alpha_value": 0.1441766097253379, "duration": 179.97383403778076, "step": 76500}
{"episode_reward": 844.9377707485739, "episode": 613.0, "Q1 loss": 6.553358373641967, "Q2 loss": 6.358139993667603, "Mean Target Q": 725.0404487304687, "Mean Q1": 725.045955078125, "Mean Q2": 725.04550390625, "critic_loss": 12.911498329162598, "batch_reward": 6.075340850830078, "actor_loss": -725.1609293619791, "actor_target_entropy": -1.0, "actor_entropy": -0.3239347811729189, "alpha_loss": 0.0003488298010317579, "alpha_value": 0.14405529179604526, "duration": 175.96904349327087, "step": 76625}
{"episode_reward": 840.938385583974, "episode": 614.0, "Q1 loss": 6.679312917709351, "Q2 loss": 6.645007974624634, "Mean Target Q": 724.7971616210938, "Mean Q1": 724.7972895507812, "Mean Q2": 724.7953872070312, "critic_loss": 13.324320930480956, "batch_reward": 6.037958553314209, "actor_loss": -724.7817402501261, "actor_target_entropy": -1.0, "actor_entropy": -0.2949690607286269, "alpha_loss": 0.0005310613252673178, "alpha_value": 0.14407049222683355, "duration": 181.37933087348938, "step": 76750}
{"episode_reward": 839.4205784953691, "episode": 615.0, "Q1 loss": 6.181035299301147, "Q2 loss": 6.155807027816772, "Mean Target Q": 725.6762954101563, "Mean Q1": 725.6721064453125, "Mean Q2": 725.6742548828125, "critic_loss": 12.336842288970947, "batch_reward": 6.086688060760498, "actor_loss": -726.0075489831349, "actor_target_entropy": -1.0, "actor_entropy": -0.32527948040810845, "alpha_loss": 0.004956456503668238, "alpha_value": 0.14385184553417094, "duration": 185.42169642448425, "step": 76875}
{"episode_reward": 848.9925096729681, "episode": 616.0, "Q1 loss": 6.858702732086182, "Q2 loss": 6.796046297073365, "Mean Target Q": 725.2758388671875, "Mean Q1": 725.2746938476563, "Mean Q2": 725.2732265625, "critic_loss": 13.654749019622802, "batch_reward": 6.056123500823975, "actor_loss": -725.3602993872857, "actor_target_entropy": -1.0, "actor_entropy": -0.32054662512194726, "alpha_loss": -0.0001873889874156204, "alpha_value": 0.14360212456577734, "duration": 181.9115126132965, "step": 77000}
{"episode_reward": 839.7650210178815, "episode": 617.0, "Q1 loss": 6.4059780406951905, "Q2 loss": 6.35365150642395, "Mean Target Q": 725.5186171875, "Mean Q1": 725.5150913085937, "Mean Q2": 725.5155610351562, "critic_loss": 12.759629556655884, "batch_reward": 6.052589424133301, "actor_loss": -725.7830113002232, "actor_target_entropy": -1.0, "actor_entropy": -0.32394694856234957, "alpha_loss": 0.0029712923273946795, "alpha_value": 0.14345296080274006, "duration": 180.25581216812134, "step": 77125}
{"episode_reward": 837.1563920831853, "episode": 618.0, "Q1 loss": 6.302037660598755, "Q2 loss": 6.244772905349731, "Mean Target Q": 726.0421572265625, "Mean Q1": 726.0416840820312, "Mean Q2": 726.0431137695313, "critic_loss": 12.546810596466065, "batch_reward": 6.07973310470581, "actor_loss": -726.4866273941532, "actor_target_entropy": -1.0, "actor_entropy": -0.33668647850713423, "alpha_loss": 0.0030582862560667337, "alpha_value": 0.14324330926632228, "duration": 187.50679850578308, "step": 77250}
{"episode_reward": 841.8626834713955, "episode": 619.0, "Q1 loss": 6.658299602508545, "Q2 loss": 6.5069534225463865, "Mean Target Q": 726.0294462890625, "Mean Q1": 726.0321606445312, "Mean Q2": 726.0314921875, "critic_loss": 13.16525299835205, "batch_reward": 6.064674156188965, "actor_loss": -726.613054547991, "actor_target_entropy": -1.0, "actor_entropy": -0.3454250461525387, "alpha_loss": 0.0005637417835671277, "alpha_value": 0.14288668755179598, "duration": 179.36388778686523, "step": 77375}
{"episode_reward": 806.5962933271475, "episode": 620.0, "Q1 loss": 6.958944690704346, "Q2 loss": 7.030720350265503, "Mean Target Q": 726.083498046875, "Mean Q1": 726.0865068359375, "Mean Q2": 726.08627734375, "critic_loss": 13.989665004730224, "batch_reward": 6.056554718017578, "actor_loss": -726.2557186003654, "actor_target_entropy": -1.0, "actor_entropy": -0.34426275256179995, "alpha_loss": 0.0004642349639682159, "alpha_value": 0.14301355598453075, "duration": 187.7622730731964, "step": 77500}
{"episode_reward": 844.0989206348145, "episode": 621.0, "Q1 loss": 6.760930524826049, "Q2 loss": 6.7623899478912355, "Mean Target Q": 726.3224711914063, "Mean Q1": 726.3140717773438, "Mean Q2": 726.314455078125, "critic_loss": 13.52332052230835, "batch_reward": 6.065253093719482, "actor_loss": -726.8455946180555, "actor_target_entropy": -1.0, "actor_entropy": -0.29598782530852724, "alpha_loss": 0.004549627321668797, "alpha_value": 0.1427301582508201, "duration": 184.7249402999878, "step": 77625}
{"episode_reward": 848.7143177213399, "episode": 622.0, "Q1 loss": 5.6438802833557125, "Q2 loss": 5.649841945648193, "Mean Target Q": 726.4928149414062, "Mean Q1": 726.492625, "Mean Q2": 726.492431640625, "critic_loss": 11.293722225189208, "batch_reward": 6.052125507354736, "actor_loss": -726.8075256347656, "actor_target_entropy": -1.0, "actor_entropy": -0.3477867760004536, "alpha_loss": 0.001815044113637639, "alpha_value": 0.14234107425643566, "duration": 184.7558958530426, "step": 77750}
{"episode_reward": 831.0161196351983, "episode": 623.0, "Q1 loss": 7.3612051162719725, "Q2 loss": 7.349882921218872, "Mean Target Q": 726.7252827148437, "Mean Q1": 726.7263022460937, "Mean Q2": 726.7263266601562, "critic_loss": 14.711088005065918, "batch_reward": 6.059823257446289, "actor_loss": -727.0050010075645, "actor_target_entropy": -1.0, "actor_entropy": -0.3476663510950785, "alpha_loss": 0.001794271171092987, "alpha_value": 0.1423473216763469, "duration": 188.59397625923157, "step": 77875}
{"episode_reward": 841.6707125200578, "episode": 624.0, "Q1 loss": 6.163854694366455, "Q2 loss": 6.144242645263672, "Mean Target Q": 726.6839418945312, "Mean Q1": 726.681009765625, "Mean Q2": 726.6802133789063, "critic_loss": 12.308097263336181, "batch_reward": 6.065626811981201, "actor_loss": -727.049304592994, "actor_target_entropy": -1.0, "actor_entropy": -0.33586052300468566, "alpha_loss": 0.0034825889423729913, "alpha_value": 0.14210199569931006, "duration": 185.66895580291748, "step": 78000}
{"episode_reward": 840.9280168920001, "episode": 625.0, "Q1 loss": 6.045903217315674, "Q2 loss": 6.051131715774536, "Mean Target Q": 726.8215590820313, "Mean Q1": 726.8229697265625, "Mean Q2": 726.8224287109375, "critic_loss": 12.097034938812255, "batch_reward": 6.068694965362549, "actor_loss": -726.9009089394222, "actor_target_entropy": -1.0, "actor_entropy": -0.3240737073005192, "alpha_loss": 0.0025949217859537357, "alpha_value": 0.14167051948936882, "duration": 186.360609292984, "step": 78125}
{"episode_reward": 842.606650898702, "episode": 626.0, "Q1 loss": 6.43356639289856, "Q2 loss": 6.277844762802124, "Mean Target Q": 727.4583413085937, "Mean Q1": 727.45785546875, "Mean Q2": 727.459205078125, "critic_loss": 12.711411151885986, "batch_reward": 6.107081279754639, "actor_loss": -728.0534412014869, "actor_target_entropy": -1.0, "actor_entropy": -0.357903225767997, "alpha_loss": 0.0011708017836715425, "alpha_value": 0.14154316962388785, "duration": 179.0462827682495, "step": 78250}
{"episode_reward": 836.4253748349068, "episode": 627.0, "Q1 loss": 5.5095807075500485, "Q2 loss": 5.413788013458252, "Mean Target Q": 727.0303540039063, "Mean Q1": 727.0287602539063, "Mean Q2": 727.0301005859375, "critic_loss": 10.923368728637696, "batch_reward": 6.061358810424805, "actor_loss": -727.2842765687004, "actor_target_entropy": -1.0, "actor_entropy": -0.324524229008054, "alpha_loss": 0.0008528915516633008, "alpha_value": 0.14145513778759822, "duration": 180.50695061683655, "step": 78375}
{"episode_reward": 842.551115267555, "episode": 628.0, "Q1 loss": 6.547366056442261, "Q2 loss": 6.5340923309326175, "Mean Target Q": 727.385595703125, "Mean Q1": 727.379552734375, "Mean Q2": 727.3789326171875, "critic_loss": 13.081458362579346, "batch_reward": 6.075044376373291, "actor_loss": -727.6997838174143, "actor_target_entropy": -1.0, "actor_entropy": -0.32215601205825806, "alpha_loss": 0.0006221941045124925, "alpha_value": 0.1414226640416277, "duration": 190.27426171302795, "step": 78500}
{"episode_reward": 839.5890657978052, "episode": 629.0, "Q1 loss": 6.411137786865234, "Q2 loss": 6.415319732666015, "Mean Target Q": 727.7144682617187, "Mean Q1": 727.710296875, "Mean Q2": 727.7083779296875, "critic_loss": 12.826457592010499, "batch_reward": 6.089139465332031, "actor_loss": -728.4528004479787, "actor_target_entropy": -1.0, "actor_entropy": -0.33583612905608284, "alpha_loss": 0.005440532432181672, "alpha_value": 0.14115814996392276, "duration": 191.60882115364075, "step": 78625}
{"episode_reward": 821.840253880511, "episode": 630.0, "Q1 loss": 6.63681845664978, "Q2 loss": 6.423531467437744, "Mean Target Q": 727.7431040039063, "Mean Q1": 727.7407270507813, "Mean Q2": 727.74198046875, "critic_loss": 13.060349941253662, "batch_reward": 6.08621588897705, "actor_loss": -728.020022484564, "actor_target_entropy": -1.0, "actor_entropy": -0.35613654169344133, "alpha_loss": 0.0021354984191636886, "alpha_value": 0.14085121037834555, "duration": 184.4000325202942, "step": 78750}
{"episode_reward": 831.621096327712, "episode": 631.0, "Q1 loss": 6.124117715835571, "Q2 loss": 6.117706186294556, "Mean Target Q": 727.9683662109375, "Mean Q1": 727.9667065429687, "Mean Q2": 727.9682880859375, "critic_loss": 12.241823917388915, "batch_reward": 6.09860652923584, "actor_loss": -728.3726438492064, "actor_target_entropy": -1.0, "actor_entropy": -0.3715475674659487, "alpha_loss": 0.0024355599834095863, "alpha_value": 0.14059813717703135, "duration": 186.4781289100647, "step": 78875}
{"episode_reward": 812.12714168088, "episode": 632.0, "Q1 loss": 6.1830240135192875, "Q2 loss": 6.079712879180908, "Mean Target Q": 728.1502211914062, "Mean Q1": 728.1589052734375, "Mean Q2": 728.1597314453124, "critic_loss": 12.262736865997315, "batch_reward": 6.101360786437988, "actor_loss": -728.3187600412676, "actor_target_entropy": -1.0, "actor_entropy": -0.3467599778406082, "alpha_loss": 0.0007256391850645623, "alpha_value": 0.140337035822624, "duration": 190.05378127098083, "step": 79000}
{"episode_reward": 834.5953063869043, "episode": 633.0, "Q1 loss": 6.839014373779297, "Q2 loss": 6.8185173091888425, "Mean Target Q": 728.0149750976562, "Mean Q1": 728.0069077148438, "Mean Q2": 728.0044404296875, "critic_loss": 13.657531692504882, "batch_reward": 6.090839118957519, "actor_loss": -728.1949976360987, "actor_target_entropy": -1.0, "actor_entropy": -0.2799219370834411, "alpha_loss": 0.0064357416999955026, "alpha_value": 0.1400706685121297, "duration": 188.70566487312317, "step": 79125}
{"episode_reward": 838.3257994107911, "episode": 634.0, "Q1 loss": 6.5187953777313234, "Q2 loss": 6.361634128570556, "Mean Target Q": 728.1173779296874, "Mean Q1": 728.1197094726563, "Mean Q2": 728.1200756835938, "critic_loss": 12.880429473876953, "batch_reward": 6.08681521987915, "actor_loss": -728.0250175229964, "actor_target_entropy": -1.0, "actor_entropy": -0.33569348867862453, "alpha_loss": -0.0027989225552207037, "alpha_value": 0.139924456753642, "duration": 179.1900932788849, "step": 79250}
{"episode_reward": 844.3294956150687, "episode": 635.0, "Q1 loss": 6.11336741065979, "Q2 loss": 6.1469479808807375, "Mean Target Q": 727.8759223632812, "Mean Q1": 727.8722622070312, "Mean Q2": 727.8738784179687, "critic_loss": 12.260315361022949, "batch_reward": 6.054894298553466, "actor_loss": -728.120128813244, "actor_target_entropy": -1.0, "actor_entropy": -0.29251465390598963, "alpha_loss": 0.0029318343796249893, "alpha_value": 0.1399934341693942, "duration": 186.38611030578613, "step": 79375}
{"episode_reward": 837.656829041051, "episode": 636.0, "Q1 loss": 6.653580453872681, "Q2 loss": 6.636320688247681, "Mean Target Q": 728.749873046875, "Mean Q1": 728.7463115234375, "Mean Q2": 728.743328125, "critic_loss": 13.289901142120362, "batch_reward": 6.098686389923095, "actor_loss": -728.9591093986265, "actor_target_entropy": -1.0, "actor_entropy": -0.34640002346807913, "alpha_loss": -0.00159526483020595, "alpha_value": 0.13982407984742629, "duration": 176.76800441741943, "step": 79500}
{"episode_reward": 822.9793272939119, "episode": 637.0, "Q1 loss": 6.413267425537109, "Q2 loss": 6.371678619384766, "Mean Target Q": 728.3181459960938, "Mean Q1": 728.3190009765625, "Mean Q2": 728.3198837890625, "critic_loss": 12.78494605255127, "batch_reward": 6.062160491943359, "actor_loss": -728.4292796301463, "actor_target_entropy": -1.0, "actor_entropy": -0.330582719000559, "alpha_loss": -0.0025908673729097085, "alpha_value": 0.14005544984594878, "duration": 173.84974312782288, "step": 79625}
{"episode_reward": 823.6133964854744, "episode": 638.0, "Q1 loss": 6.306497325897217, "Q2 loss": 6.358676513671875, "Mean Target Q": 728.7910180664062, "Mean Q1": 728.7877280273437, "Mean Q2": 728.7897973632812, "critic_loss": 12.665173862457275, "batch_reward": 6.0817077941894535, "actor_loss": -729.141604515814, "actor_target_entropy": -1.0, "actor_entropy": -0.3332836651994336, "alpha_loss": -0.0002663334936744744, "alpha_value": 0.14020206814790376, "duration": 178.99269580841064, "step": 79750}
{"episode_reward": 842.0830068575949, "episode": 639.0, "Q1 loss": 7.569943786621094, "Q2 loss": 7.4055060939788815, "Mean Target Q": 728.8226206054687, "Mean Q1": 728.8217412109375, "Mean Q2": 728.8198681640625, "critic_loss": 14.975449886322021, "batch_reward": 6.088675109863281, "actor_loss": -729.3047562856523, "actor_target_entropy": -1.0, "actor_entropy": -0.3431538050136869, "alpha_loss": 0.0005946061823384038, "alpha_value": 0.14021997703382413, "duration": 173.90871858596802, "step": 79875}
{"episode_reward": 843.0576852443666, "episode": 640.0, "Q1 loss": 6.037024349212646, "Q2 loss": 6.095010705947876, "Mean Target Q": 728.9894287109375, "Mean Q1": 728.9900151367187, "Mean Q2": 728.9892451171875, "critic_loss": 12.132035049438477, "batch_reward": 6.078069889068604, "actor_loss": -729.4800277217741, "actor_target_entropy": -1.0, "actor_entropy": -0.3341344489205268, "alpha_loss": -0.0005481080715394308, "alpha_value": 0.14001278190384103, "step": 80000}
{"duration": 199.3673334121704, "step": 80000}
{"episode_reward": 831.8498996175571, "episode": 641.0, "Q1 loss": 5.731616598129272, "Q2 loss": 5.7899755878448484, "Mean Target Q": 729.2366352539062, "Mean Q1": 729.2366538085937, "Mean Q2": 729.2390771484374, "critic_loss": 11.521592205047607, "batch_reward": 6.098591007232666, "actor_loss": -729.4155040922619, "actor_target_entropy": -1.0, "actor_entropy": -0.35162912616654046, "alpha_loss": -0.0028492534377922616, "alpha_value": 0.1402704485612804, "duration": 211.10390830039978, "step": 80125}
{"episode_reward": 844.0166136168672, "episode": 642.0, "Q1 loss": 5.798567434310913, "Q2 loss": 5.806408824920655, "Mean Target Q": 729.5050375976563, "Mean Q1": 729.5076206054688, "Mean Q2": 729.506560546875, "critic_loss": 11.604976173400878, "batch_reward": 6.083461265563965, "actor_loss": -729.9279076360887, "actor_target_entropy": -1.0, "actor_entropy": -0.34121769714740013, "alpha_loss": 3.374618620822026e-05, "alpha_value": 0.140519561093572, "duration": 179.46012139320374, "step": 80250}
{"episode_reward": 835.7783774868193, "episode": 643.0, "Q1 loss": 5.672427940368652, "Q2 loss": 5.628210821151733, "Mean Target Q": 729.6871665039063, "Mean Q1": 729.6860791015625, "Mean Q2": 729.6848041992188, "critic_loss": 11.300638763427735, "batch_reward": 6.105664165496826, "actor_loss": -730.1210646856399, "actor_target_entropy": -1.0, "actor_entropy": -0.36353439518383573, "alpha_loss": -0.002656460909675511, "alpha_value": 0.1405251077077401, "duration": 182.14152240753174, "step": 80375}
{"episode_reward": 833.897485631077, "episode": 644.0, "Q1 loss": 5.85186626625061, "Q2 loss": 5.810862396240235, "Mean Target Q": 729.5668911132813, "Mean Q1": 729.5578081054688, "Mean Q2": 729.5584755859375, "critic_loss": 11.662728645324707, "batch_reward": 6.082566776275635, "actor_loss": -730.0148128386467, "actor_target_entropy": -1.0, "actor_entropy": -0.35069168383075344, "alpha_loss": 0.0005443867374842446, "alpha_value": 0.1406401345397755, "duration": 180.48723936080933, "step": 80500}
{"episode_reward": 845.5342247743529, "episode": 645.0, "Q1 loss": 6.232435211181641, "Q2 loss": 6.369861576080322, "Mean Target Q": 729.6323979492188, "Mean Q1": 729.636357421875, "Mean Q2": 729.6350747070312, "critic_loss": 12.602296775817871, "batch_reward": 6.08087971496582, "actor_loss": -730.0710701109871, "actor_target_entropy": -1.0, "actor_entropy": -0.33600487950302305, "alpha_loss": 0.002995422630134733, "alpha_value": 0.1404169611948577, "duration": 176.6881968975067, "step": 80625}
{"episode_reward": 837.0712405724752, "episode": 646.0, "Q1 loss": 6.302378583908081, "Q2 loss": 6.1397281150817875, "Mean Target Q": 730.0408413085937, "Mean Q1": 730.03870703125, "Mean Q2": 730.0402666015625, "critic_loss": 12.4421067237854, "batch_reward": 6.0972829399108885, "actor_loss": -730.1169896279612, "actor_target_entropy": -1.0, "actor_entropy": -0.3172557459723565, "alpha_loss": 0.0019500799131609739, "alpha_value": 0.14025386750386368, "duration": 175.50396943092346, "step": 80750}
{"episode_reward": 842.442222746974, "episode": 647.0, "Q1 loss": 5.69258408164978, "Q2 loss": 5.6227779293060305, "Mean Target Q": 730.205294921875, "Mean Q1": 730.2097338867187, "Mean Q2": 730.2086713867187, "critic_loss": 11.31536201095581, "batch_reward": 6.09072575378418, "actor_loss": -730.7544478159102, "actor_target_entropy": -1.0, "actor_entropy": -0.3540874511476547, "alpha_loss": -0.0014466051315327013, "alpha_value": 0.14010923523515184, "duration": 169.80133986473083, "step": 80875}
{"episode_reward": 834.5055596310617, "episode": 648.0, "Q1 loss": 7.060146621704101, "Q2 loss": 7.082447957992554, "Mean Target Q": 729.8367158203125, "Mean Q1": 729.8297182617188, "Mean Q2": 729.8308022460938, "critic_loss": 14.142594535827637, "batch_reward": 6.073422103881836, "actor_loss": -729.9219793504284, "actor_target_entropy": -1.0, "actor_entropy": -0.3262468369737748, "alpha_loss": 0.0009729239841802947, "alpha_value": 0.14031512367929252, "duration": 181.2595236301422, "step": 81000}
{"episode_reward": 840.4838877604386, "episode": 649.0, "Q1 loss": 6.01734326171875, "Q2 loss": 5.866688943862915, "Mean Target Q": 730.2070390625, "Mean Q1": 730.206896484375, "Mean Q2": 730.2070659179687, "critic_loss": 11.884032196044922, "batch_reward": 6.094378189086914, "actor_loss": -730.9210466657366, "actor_target_entropy": -1.0, "actor_entropy": -0.3463977128267288, "alpha_loss": 0.0019035238037181516, "alpha_value": 0.14007196744559758, "duration": 172.83346819877625, "step": 81125}
{"episode_reward": 811.5574422389175, "episode": 650.0, "Q1 loss": 5.888478076934814, "Q2 loss": 5.947271804809571, "Mean Target Q": 730.4796186523438, "Mean Q1": 730.4735869140625, "Mean Q2": 730.4721865234375, "critic_loss": 11.835749897003174, "batch_reward": 6.101831043243409, "actor_loss": -730.630139750819, "actor_target_entropy": -1.0, "actor_entropy": -0.32748777082850855, "alpha_loss": 0.0023695055335279432, "alpha_value": 0.13990814148051686, "duration": 179.7230670452118, "step": 81250}
{"episode_reward": 829.5609120473812, "episode": 651.0, "Q1 loss": 6.630116025924683, "Q2 loss": 6.54956116104126, "Mean Target Q": 730.3636821289062, "Mean Q1": 730.3741635742188, "Mean Q2": 730.3742431640625, "critic_loss": 13.179677154541016, "batch_reward": 6.08589013671875, "actor_loss": -730.5787905738467, "actor_target_entropy": -1.0, "actor_entropy": -0.30880952685598345, "alpha_loss": 0.0025037191179950557, "alpha_value": 0.139649378678438, "duration": 179.27923488616943, "step": 81375}
{"episode_reward": 830.1389840806313, "episode": 652.0, "Q1 loss": 6.153015995025635, "Q2 loss": 6.061142372131347, "Mean Target Q": 730.3812104492188, "Mean Q1": 730.3773002929687, "Mean Q2": 730.3788256835937, "critic_loss": 12.214158294677734, "batch_reward": 6.077457706451416, "actor_loss": -730.6377346900201, "actor_target_entropy": -1.0, "actor_entropy": -0.3646277371914156, "alpha_loss": -0.0009400329774155491, "alpha_value": 0.13966203190133766, "duration": 178.61713814735413, "step": 81500}
{"episode_reward": 850.7361981280949, "episode": 653.0, "Q1 loss": 6.276921369552612, "Q2 loss": 6.180415794372559, "Mean Target Q": 730.8406572265625, "Mean Q1": 730.832400390625, "Mean Q2": 730.8320942382812, "critic_loss": 12.457337184906006, "batch_reward": 6.103168590545654, "actor_loss": -731.2757103329614, "actor_target_entropy": -1.0, "actor_entropy": -0.3337727699960981, "alpha_loss": 0.0026632054756942484, "alpha_value": 0.1394456064504417, "duration": 170.76290702819824, "step": 81625}
{"episode_reward": 837.0664430952013, "episode": 654.0, "Q1 loss": 6.185783720016479, "Q2 loss": 6.095230754852295, "Mean Target Q": 730.8656015625, "Mean Q1": 730.8661987304688, "Mean Q2": 730.867544921875, "critic_loss": 12.28101441192627, "batch_reward": 6.096766719818115, "actor_loss": -731.2913798670614, "actor_target_entropy": -1.0, "actor_entropy": -0.3643883567663931, "alpha_loss": -0.0029169149253697644, "alpha_value": 0.1394751747760687, "duration": 177.33089876174927, "step": 81750}
{"episode_reward": 824.2404342345495, "episode": 655.0, "Q1 loss": 5.559147182464599, "Q2 loss": 5.539594871520996, "Mean Target Q": 730.9911123046875, "Mean Q1": 730.9912905273437, "Mean Q2": 730.9914184570313, "critic_loss": 11.098742008209229, "batch_reward": 6.098075004577637, "actor_loss": -731.2252177889385, "actor_target_entropy": -1.0, "actor_entropy": -0.3277394369481102, "alpha_loss": 0.0008972212237985952, "alpha_value": 0.13957813972620184, "duration": 178.4789366722107, "step": 81875}
{"episode_reward": 825.890408410737, "episode": 656.0, "Q1 loss": 6.129515054702758, "Q2 loss": 5.943312206268311, "Mean Target Q": 730.9960893554687, "Mean Q1": 730.993923828125, "Mean Q2": 730.99465234375, "critic_loss": 12.072827239990234, "batch_reward": 6.096956569671631, "actor_loss": -731.33642085906, "actor_target_entropy": -1.0, "actor_entropy": -0.3277197251877477, "alpha_loss": 0.0012336957865514823, "alpha_value": 0.1395215190790259, "duration": 179.55143117904663, "step": 82000}
{"episode_reward": 836.9608637593136, "episode": 657.0, "Q1 loss": 6.046647457122803, "Q2 loss": 5.948542028427124, "Mean Target Q": 731.3081225585937, "Mean Q1": 731.30787890625, "Mean Q2": 731.3066796875, "critic_loss": 11.995189487457276, "batch_reward": 6.106752906799317, "actor_loss": -731.5072409009176, "actor_target_entropy": -1.0, "actor_entropy": -0.30714722592679283, "alpha_loss": 0.003753630237446891, "alpha_value": 0.1393015131751508, "duration": 178.58898305892944, "step": 82125}
{"episode_reward": 817.4757393025159, "episode": 658.0, "Q1 loss": 6.038717584609985, "Q2 loss": 5.981861825942993, "Mean Target Q": 731.3648129882813, "Mean Q1": 731.3643354492187, "Mean Q2": 731.3648310546876, "critic_loss": 12.02057939529419, "batch_reward": 6.099283191680908, "actor_loss": -731.8856201171875, "actor_target_entropy": -1.0, "actor_entropy": -0.3227819677802824, "alpha_loss": 0.002367335523764092, "alpha_value": 0.13901038950581182, "duration": 189.1505069732666, "step": 82250}
{"episode_reward": 828.5776894594769, "episode": 659.0, "Q1 loss": 6.09004128074646, "Q2 loss": 6.117189407348633, "Mean Target Q": 731.4476059570312, "Mean Q1": 731.4459633789063, "Mean Q2": 731.4456000976562, "critic_loss": 12.20723070526123, "batch_reward": 6.096028568267823, "actor_loss": -731.7176707434276, "actor_target_entropy": -1.0, "actor_entropy": -0.3643191480447376, "alpha_loss": -0.0028316419486636444, "alpha_value": 0.13901029021215136, "duration": 182.5645923614502, "step": 82375}
{"episode_reward": 840.1206250135256, "episode": 660.0, "Q1 loss": 6.195717937469483, "Q2 loss": 6.237145975112915, "Mean Target Q": 731.6589311523437, "Mean Q1": 731.6647080078125, "Mean Q2": 731.6621806640625, "critic_loss": 12.432863918304443, "batch_reward": 6.108236679077148, "actor_loss": -731.9885509860131, "actor_target_entropy": -1.0, "actor_entropy": -0.3350026684422647, "alpha_loss": 0.0012612679218422741, "alpha_value": 0.13911736284067702, "duration": 181.1706085205078, "step": 82500}
{"episode_reward": 843.2752792880322, "episode": 661.0, "Q1 loss": 6.9628321609497075, "Q2 loss": 6.912028184890747, "Mean Target Q": 731.5074428710938, "Mean Q1": 731.5006918945312, "Mean Q2": 731.502888671875, "critic_loss": 13.874860378265382, "batch_reward": 6.091994941711426, "actor_loss": -731.8732357933408, "actor_target_entropy": -1.0, "actor_entropy": -0.33589833407174974, "alpha_loss": -0.00044586119567236257, "alpha_value": 0.13911216878220722, "duration": 172.4338035583496, "step": 82625}
{"episode_reward": 831.7508490564038, "episode": 662.0, "Q1 loss": 6.913329544067383, "Q2 loss": 6.96449695777893, "Mean Target Q": 731.7942358398437, "Mean Q1": 731.78932421875, "Mean Q2": 731.789529296875, "critic_loss": 13.877826435089112, "batch_reward": 6.10807201385498, "actor_loss": -732.1385448824975, "actor_target_entropy": -1.0, "actor_entropy": -0.3370447692371184, "alpha_loss": 0.0057275949774550335, "alpha_value": 0.13878906869934238, "duration": 185.39572930335999, "step": 82750}
{"episode_reward": 838.5115258766896, "episode": 663.0, "Q1 loss": 6.716891935348511, "Q2 loss": 6.595683578491211, "Mean Target Q": 731.8803876953125, "Mean Q1": 731.8752705078125, "Mean Q2": 731.8737719726563, "critic_loss": 13.312575458526611, "batch_reward": 6.105142818450927, "actor_loss": -732.1918538411459, "actor_target_entropy": -1.0, "actor_entropy": -0.3721106984312572, "alpha_loss": -0.0028958100795982377, "alpha_value": 0.13876636212089977, "duration": 182.16568994522095, "step": 82875}
{"episode_reward": 822.7913173837725, "episode": 664.0, "Q1 loss": 6.001671483993531, "Q2 loss": 5.952686634063721, "Mean Target Q": 732.0205859375, "Mean Q1": 732.0187543945312, "Mean Q2": 732.0200874023437, "critic_loss": 11.954358142852783, "batch_reward": 6.1075538101196285, "actor_loss": -732.2136171402469, "actor_target_entropy": -1.0, "actor_entropy": -0.38757442370537787, "alpha_loss": -0.004199563206413821, "alpha_value": 0.1389442142943674, "duration": 184.74516034126282, "step": 83000}
{"episode_reward": 847.4401474788796, "episode": 665.0, "Q1 loss": 5.5871155662536625, "Q2 loss": 5.503211116790771, "Mean Target Q": 732.2130063476562, "Mean Q1": 732.217744140625, "Mean Q2": 732.2174770507812, "critic_loss": 11.090326717376708, "batch_reward": 6.110566608428955, "actor_loss": -732.2920851934524, "actor_target_entropy": -1.0, "actor_entropy": -0.3864605956607395, "alpha_loss": -0.00409288705873584, "alpha_value": 0.1393605330365532, "duration": 183.85742282867432, "step": 83125}
{"episode_reward": 847.3002026201336, "episode": 666.0, "Q1 loss": 5.812700210571289, "Q2 loss": 5.743462631225586, "Mean Target Q": 732.4141982421875, "Mean Q1": 732.411083984375, "Mean Q2": 732.4114580078125, "critic_loss": 11.556162788391113, "batch_reward": 6.1161160659790035, "actor_loss": -732.995364281439, "actor_target_entropy": -1.0, "actor_entropy": -0.3557370420425169, "alpha_loss": -0.0025511408664075836, "alpha_value": 0.13968385240415154, "duration": 183.1771252155304, "step": 83250}
{"episode_reward": 842.0966290127554, "episode": 667.0, "Q1 loss": 5.179550022125244, "Q2 loss": 5.227666275024414, "Mean Target Q": 732.1804311523438, "Mean Q1": 732.1849790039063, "Mean Q2": 732.1848818359375, "critic_loss": 10.407216257095337, "batch_reward": 6.092625034332276, "actor_loss": -732.8994925362723, "actor_target_entropy": -1.0, "actor_entropy": -0.34270940839298186, "alpha_loss": -0.00029179238573840213, "alpha_value": 0.1398542521357455, "duration": 194.9262125492096, "step": 83375}
{"episode_reward": 846.8533797455877, "episode": 668.0, "Q1 loss": 5.842833515167237, "Q2 loss": 5.736433349609375, "Mean Target Q": 732.5687407226562, "Mean Q1": 732.561384765625, "Mean Q2": 732.5606416015625, "critic_loss": 11.579266841888428, "batch_reward": 6.10242554473877, "actor_loss": -733.0339808310232, "actor_target_entropy": -1.0, "actor_entropy": -0.3607414023530099, "alpha_loss": -0.0018098226508065577, "alpha_value": 0.13994767896296637, "duration": 205.64191508293152, "step": 83500}
{"episode_reward": 831.8922912710557, "episode": 669.0, "Q1 loss": 5.4080114192962645, "Q2 loss": 5.340148538589477, "Mean Target Q": 732.7508310546875, "Mean Q1": 732.7477109375, "Mean Q2": 732.7501943359375, "critic_loss": 10.74815991973877, "batch_reward": 6.103991416931152, "actor_loss": -732.7664271763393, "actor_target_entropy": -1.0, "actor_entropy": -0.32401963642665316, "alpha_loss": -0.0003895855763749707, "alpha_value": 0.14010919897396087, "duration": 200.15515780448914, "step": 83625}
{"episode_reward": 837.9700250569829, "episode": 670.0, "Q1 loss": 5.901209051132202, "Q2 loss": 5.711752101898194, "Mean Target Q": 732.871091796875, "Mean Q1": 732.8709541015625, "Mean Q2": 732.8696889648437, "critic_loss": 11.612961139678955, "batch_reward": 6.115440319061279, "actor_loss": -733.3964105421497, "actor_target_entropy": -1.0, "actor_entropy": -0.3769254602732197, "alpha_loss": -0.002494668591797592, "alpha_value": 0.14020970180124553, "duration": 199.01893830299377, "step": 83750}
{"episode_reward": 829.230427573341, "episode": 671.0, "Q1 loss": 6.983598970413208, "Q2 loss": 6.991997577667236, "Mean Target Q": 732.7715673828125, "Mean Q1": 732.7777407226563, "Mean Q2": 732.7764829101562, "critic_loss": 13.975596534729004, "batch_reward": 6.0942431182861325, "actor_loss": -733.0757843501984, "actor_target_entropy": -1.0, "actor_entropy": -0.34821339708472054, "alpha_loss": 0.0010468944637400527, "alpha_value": 0.14035492171750225, "duration": 202.4732370376587, "step": 83875}
{"episode_reward": 837.8877144615217, "episode": 672.0, "Q1 loss": 6.113162282943725, "Q2 loss": 6.110393657684326, "Mean Target Q": 733.0052543945312, "Mean Q1": 733.0055083007812, "Mean Q2": 733.0063041992188, "critic_loss": 12.22355595779419, "batch_reward": 6.1234339866638186, "actor_loss": -733.307877079133, "actor_target_entropy": -1.0, "actor_entropy": -0.33638189492687104, "alpha_loss": 0.001760441687844333, "alpha_value": 0.1401369853642968, "duration": 190.01965618133545, "step": 84000}
{"episode_reward": 824.866107551156, "episode": 673.0, "Q1 loss": 6.245666929244996, "Q2 loss": 6.356656867980957, "Mean Target Q": 733.0314653320313, "Mean Q1": 733.026537109375, "Mean Q2": 733.0259501953125, "critic_loss": 12.60232375717163, "batch_reward": 6.097953388214111, "actor_loss": -733.6248246450273, "actor_target_entropy": -1.0, "actor_entropy": -0.33731081135689267, "alpha_loss": 0.001134125192442702, "alpha_value": 0.14002641612156397, "duration": 191.3833200931549, "step": 84125}
{"episode_reward": 835.6493466462739, "episode": 674.0, "Q1 loss": 5.616174757957459, "Q2 loss": 5.5205466804504395, "Mean Target Q": 733.3853500976562, "Mean Q1": 733.3856938476563, "Mean Q2": 733.38628125, "critic_loss": 11.136721481323242, "batch_reward": 6.120903781890869, "actor_loss": -733.7666832708543, "actor_target_entropy": -1.0, "actor_entropy": -0.3165751907133287, "alpha_loss": 0.008206504002784288, "alpha_value": 0.13957621065043355, "duration": 189.93571496009827, "step": 84250}
{"episode_reward": 828.2468809589466, "episode": 675.0, "Q1 loss": 5.77396300315857, "Q2 loss": 5.660453567504883, "Mean Target Q": 733.3207568359375, "Mean Q1": 733.320103515625, "Mean Q2": 733.3195737304687, "critic_loss": 11.43441658782959, "batch_reward": 6.108720439910889, "actor_loss": -733.5058283730159, "actor_target_entropy": -1.0, "actor_entropy": -0.30803945069275207, "alpha_loss": 0.0034904480165254977, "alpha_value": 0.1389446142922795, "duration": 181.35891723632812, "step": 84375}
{"episode_reward": 836.4104433395678, "episode": 676.0, "Q1 loss": 5.090470174789429, "Q2 loss": 5.05533443069458, "Mean Target Q": 733.58780078125, "Mean Q1": 733.5820073242187, "Mean Q2": 733.58234765625, "critic_loss": 10.145804588317871, "batch_reward": 6.119628280639648, "actor_loss": -733.8398378433719, "actor_target_entropy": -1.0, "actor_entropy": -0.3206896483898163, "alpha_loss": 0.0038845309679726918, "alpha_value": 0.13854230851520588, "duration": 186.54924702644348, "step": 84500}
{"episode_reward": 836.4204027422713, "episode": 677.0, "Q1 loss": 6.141557201385498, "Q2 loss": 6.095368051528931, "Mean Target Q": 733.8315629882812, "Mean Q1": 733.831544921875, "Mean Q2": 733.83235546875, "critic_loss": 12.236925235748291, "batch_reward": 6.134384624481201, "actor_loss": -734.3400278242808, "actor_target_entropy": -1.0, "actor_entropy": -0.3335409944965726, "alpha_loss": 0.0026374721829409875, "alpha_value": 0.1383263767189369, "duration": 186.52132153511047, "step": 84625}
{"episode_reward": 829.0996191784241, "episode": 678.0, "Q1 loss": 5.671648471832276, "Q2 loss": 5.726510648727417, "Mean Target Q": 733.881373046875, "Mean Q1": 733.8795307617188, "Mean Q2": 733.8783959960938, "critic_loss": 11.398159074783326, "batch_reward": 6.1252125587463375, "actor_loss": -734.2243868920111, "actor_target_entropy": -1.0, "actor_entropy": -0.3391540079347549, "alpha_loss": 0.0024245993014530187, "alpha_value": 0.13805756848604248, "duration": 190.87403202056885, "step": 84750}
{"episode_reward": 843.1253809131252, "episode": 679.0, "Q1 loss": 6.110582221984863, "Q2 loss": 6.168791044235229, "Mean Target Q": 733.7760405273438, "Mean Q1": 733.7752631835938, "Mean Q2": 733.7767197265625, "critic_loss": 12.279373275756836, "batch_reward": 6.1069276275634765, "actor_loss": -734.3029242621528, "actor_target_entropy": -1.0, "actor_entropy": -0.33383653750495307, "alpha_loss": 0.0015158821858229144, "alpha_value": 0.13776436343865076, "duration": 196.33665823936462, "step": 84875}
{"episode_reward": 835.2687357655396, "episode": 680.0, "Q1 loss": 6.0223604011535645, "Q2 loss": 5.905018030166626, "Mean Target Q": 734.0085009765625, "Mean Q1": 734.0105180664062, "Mean Q2": 734.0092900390625, "critic_loss": 11.927378448486328, "batch_reward": 6.117714809417724, "actor_loss": -734.4364062893775, "actor_target_entropy": -1.0, "actor_entropy": -0.3367474670371702, "alpha_loss": -0.00018749365230060874, "alpha_value": 0.13782185751763446, "step": 85000}
{"duration": 209.91759276390076, "step": 85000}
{"episode_reward": 840.4726855199783, "episode": 681.0, "Q1 loss": 5.563901823043823, "Q2 loss": 5.5660796661376954, "Mean Target Q": 734.127919921875, "Mean Q1": 734.125326171875, "Mean Q2": 734.1268344726562, "critic_loss": 11.12998148727417, "batch_reward": 6.129312309265137, "actor_loss": -734.2662276010665, "actor_target_entropy": -1.0, "actor_entropy": -0.33045184564968894, "alpha_loss": -3.7371180951595306e-05, "alpha_value": 0.137846587604665, "duration": 182.86055827140808, "step": 85125}
{"episode_reward": 836.1768428946827, "episode": 682.0, "Q1 loss": 5.886995708465576, "Q2 loss": 5.937574119567871, "Mean Target Q": 734.246701171875, "Mean Q1": 734.2413168945312, "Mean Q2": 734.2409545898438, "critic_loss": 11.82456978225708, "batch_reward": 6.120069393157959, "actor_loss": -734.6246780887727, "actor_target_entropy": -1.0, "actor_entropy": -0.31988436872920684, "alpha_loss": 0.0033461209123713835, "alpha_value": 0.13758309554417403, "duration": 181.73750066757202, "step": 85250}
{"episode_reward": 848.2800420024115, "episode": 683.0, "Q1 loss": 5.500270763397217, "Q2 loss": 5.584695823669434, "Mean Target Q": 734.4943833007812, "Mean Q1": 734.4968676757812, "Mean Q2": 734.4966064453125, "critic_loss": 11.084966567993163, "batch_reward": 6.126527393341065, "actor_loss": -735.0234733460442, "actor_target_entropy": -1.0, "actor_entropy": -0.33797239263852435, "alpha_loss": 0.0022179288032006415, "alpha_value": 0.13744257771136986, "duration": 183.18246817588806, "step": 85375}
{"episode_reward": 844.5701538676877, "episode": 684.0, "Q1 loss": 5.1456932468414305, "Q2 loss": 5.178213901519776, "Mean Target Q": 734.7019838867187, "Mean Q1": 734.6979921875, "Mean Q2": 734.6966635742187, "critic_loss": 10.323907199859619, "batch_reward": 6.1337213134765625, "actor_loss": -735.1044390278478, "actor_target_entropy": -1.0, "actor_entropy": -0.38729822106899753, "alpha_loss": -0.005140956797291555, "alpha_value": 0.13752088718603694, "duration": 191.03606963157654, "step": 85500}
{"episode_reward": 845.4112142934058, "episode": 685.0, "Q1 loss": 5.554000434875488, "Q2 loss": 5.4574369564056395, "Mean Target Q": 734.7680288085937, "Mean Q1": 734.7674189453126, "Mean Q2": 734.7679624023438, "critic_loss": 11.011437408447266, "batch_reward": 6.140229927062988, "actor_loss": -734.8310769701761, "actor_target_entropy": -1.0, "actor_entropy": -0.3240280674090461, "alpha_loss": 0.0012612299502102865, "alpha_value": 0.1377094007526596, "duration": 179.4494411945343, "step": 85625}
{"episode_reward": 840.2013796845584, "episode": 686.0, "Q1 loss": 5.152466962814331, "Q2 loss": 5.2056104316711425, "Mean Target Q": 734.7462680664063, "Mean Q1": 734.7440419921875, "Mean Q2": 734.7421103515625, "critic_loss": 10.358077396392822, "batch_reward": 6.127159782409668, "actor_loss": -734.9293212890625, "actor_target_entropy": -1.0, "actor_entropy": -0.34064071553368724, "alpha_loss": 0.0036570956355952205, "alpha_value": 0.13754650921782335, "duration": 187.9550998210907, "step": 85750}
{"episode_reward": 834.8362101933874, "episode": 687.0, "Q1 loss": 5.2117910461425785, "Q2 loss": 5.2080629978179935, "Mean Target Q": 734.7311103515625, "Mean Q1": 734.7367934570312, "Mean Q2": 734.739625, "critic_loss": 10.419854068756104, "batch_reward": 6.118340026855469, "actor_loss": -734.8520159040179, "actor_target_entropy": -1.0, "actor_entropy": -0.31610139471197884, "alpha_loss": 0.002727498703207525, "alpha_value": 0.13713678376410746, "duration": 188.52301716804504, "step": 85875}
{"episode_reward": 838.2286628208327, "episode": 688.0, "Q1 loss": 6.1640402688980105, "Q2 loss": 6.016539751052856, "Mean Target Q": 734.9787939453125, "Mean Q1": 734.9744721679688, "Mean Q2": 734.9742294921875, "critic_loss": 12.180580055236817, "batch_reward": 6.137208385467529, "actor_loss": -735.5008013325353, "actor_target_entropy": -1.0, "actor_entropy": -0.31921387127330225, "alpha_loss": 0.0024343698018891437, "alpha_value": 0.13697266993913768, "duration": 189.90727353096008, "step": 86000}
{"episode_reward": 822.7158852204603, "episode": 689.0, "Q1 loss": 5.665706672668457, "Q2 loss": 5.628252990722657, "Mean Target Q": 735.1655034179687, "Mean Q1": 735.1654926757813, "Mean Q2": 735.1643461914063, "critic_loss": 11.293959651947022, "batch_reward": 6.136852005004883, "actor_loss": -735.4778384254092, "actor_target_entropy": -1.0, "actor_entropy": -0.3685122685773032, "alpha_loss": -0.0013883563944892515, "alpha_value": 0.13691000240221282, "duration": 193.41496968269348, "step": 86125}
{"episode_reward": 822.0739647850264, "episode": 690.0, "Q1 loss": 5.675873513221741, "Q2 loss": 5.640504145622254, "Mean Target Q": 735.2950361328125, "Mean Q1": 735.2925913085937, "Mean Q2": 735.2932309570313, "critic_loss": 11.316377628326416, "batch_reward": 6.13692077255249, "actor_loss": -735.5720835039692, "actor_target_entropy": -1.0, "actor_entropy": -0.3477858079056586, "alpha_loss": -0.0012162818541494949, "alpha_value": 0.13694030820848133, "duration": 196.9622402191162, "step": 86250}
{"episode_reward": 836.349189481099, "episode": 691.0, "Q1 loss": 4.962466893196106, "Q2 loss": 4.991743701934815, "Mean Target Q": 735.1977436523438, "Mean Q1": 735.194333984375, "Mean Q2": 735.1936391601563, "critic_loss": 9.954210597991944, "batch_reward": 6.118902900695801, "actor_loss": -735.571763780382, "actor_target_entropy": -1.0, "actor_entropy": -0.3592222049122765, "alpha_loss": -0.0016757559672456294, "alpha_value": 0.13709342519298037, "duration": 180.77093362808228, "step": 86375}
{"episode_reward": 843.1085380996593, "episode": 692.0, "Q1 loss": 5.829433128356934, "Q2 loss": 5.802589338302612, "Mean Target Q": 735.392130859375, "Mean Q1": 735.3930439453125, "Mean Q2": 735.3938198242188, "critic_loss": 11.632022491455078, "batch_reward": 6.138498096466065, "actor_loss": -735.3739653556578, "actor_target_entropy": -1.0, "actor_entropy": -0.328722117889312, "alpha_loss": -0.0005665699211550095, "alpha_value": 0.13718186943774502, "duration": 186.84421920776367, "step": 86500}
{"episode_reward": 831.9439094657477, "episode": 693.0, "Q1 loss": 5.727617712020874, "Q2 loss": 5.71059356880188, "Mean Target Q": 735.4773706054688, "Mean Q1": 735.4761665039063, "Mean Q2": 735.4764765625, "critic_loss": 11.43821128463745, "batch_reward": 6.128743255615235, "actor_loss": -736.1170722113716, "actor_target_entropy": -1.0, "actor_entropy": -0.3906719840708233, "alpha_loss": -0.004434106061198113, "alpha_value": 0.13752940621245152, "duration": 189.0153410434723, "step": 86625}
{"episode_reward": 848.4596582359442, "episode": 694.0, "Q1 loss": 5.769370864868164, "Q2 loss": 5.56508274269104, "Mean Target Q": 735.23034765625, "Mean Q1": 735.2357163085937, "Mean Q2": 735.234662109375, "critic_loss": 11.334453666687011, "batch_reward": 6.109478698730468, "actor_loss": -735.7482024162047, "actor_target_entropy": -1.0, "actor_entropy": -0.34379745611260015, "alpha_loss": -0.0006060317485413004, "alpha_value": 0.13787569436283117, "duration": 190.34059953689575, "step": 86750}
{"episode_reward": 838.1247474508234, "episode": 695.0, "Q1 loss": 5.939390922546386, "Q2 loss": 5.9073279724121095, "Mean Target Q": 735.8250048828126, "Mean Q1": 735.812736328125, "Mean Q2": 735.8144306640625, "critic_loss": 11.846718910217286, "batch_reward": 6.135027530670166, "actor_loss": -736.4296526227679, "actor_target_entropy": -1.0, "actor_entropy": -0.3916622967947097, "alpha_loss": -0.001220656342671386, "alpha_value": 0.13762495276208433, "duration": 184.7829179763794, "step": 86875}
{"episode_reward": 846.9963699319848, "episode": 696.0, "Q1 loss": 5.058419641494751, "Q2 loss": 5.023196016311646, "Mean Target Q": 735.8698540039062, "Mean Q1": 735.8743227539062, "Mean Q2": 735.8735522460937, "critic_loss": 10.081615623474121, "batch_reward": 6.135113216400146, "actor_loss": -736.1355197045111, "actor_target_entropy": -1.0, "actor_entropy": -0.33176498691881856, "alpha_loss": 0.0022949891487857505, "alpha_value": 0.13784313770581244, "duration": 190.09931778907776, "step": 87000}
{"episode_reward": 818.129233867034, "episode": 697.0, "Q1 loss": 5.091989990234375, "Q2 loss": 5.003502145767212, "Mean Target Q": 736.2068823242188, "Mean Q1": 736.2064951171875, "Mean Q2": 736.2061518554688, "critic_loss": 10.095492149353028, "batch_reward": 6.147271057128906, "actor_loss": -736.7375652979291, "actor_target_entropy": -1.0, "actor_entropy": -0.3456631513342025, "alpha_loss": 0.0025965331255325247, "alpha_value": 0.13757526824485383, "duration": 193.03312921524048, "step": 87125}
{"episode_reward": 843.568642847955, "episode": 698.0, "Q1 loss": 5.119453433990478, "Q2 loss": 5.094399312973023, "Mean Target Q": 736.2754560546875, "Mean Q1": 736.2786948242187, "Mean Q2": 736.2794614257813, "critic_loss": 10.213852741241455, "batch_reward": 6.158203521728516, "actor_loss": -736.6446031139743, "actor_target_entropy": -1.0, "actor_entropy": -0.3420565152360547, "alpha_loss": 0.0030996408275959474, "alpha_value": 0.13729687242932287, "duration": 190.95541644096375, "step": 87250}
{"episode_reward": 841.8872364602431, "episode": 699.0, "Q1 loss": 5.014804195404053, "Q2 loss": 4.951164129257202, "Mean Target Q": 736.260283203125, "Mean Q1": 736.2554741210937, "Mean Q2": 736.2551083984375, "critic_loss": 9.965968349456787, "batch_reward": 6.14098994064331, "actor_loss": -736.7093970889136, "actor_target_entropy": -1.0, "actor_entropy": -0.35903690495188273, "alpha_loss": 0.00037865567072812054, "alpha_value": 0.1371155935401113, "duration": 192.76469111442566, "step": 87375}
{"episode_reward": 848.306149936507, "episode": 700.0, "Q1 loss": 4.831489809036255, "Q2 loss": 4.736398252487183, "Mean Target Q": 736.3953857421875, "Mean Q1": 736.3936435546875, "Mean Q2": 736.3922509765625, "critic_loss": 9.567888078689576, "batch_reward": 6.15118155670166, "actor_loss": -736.5924101798765, "actor_target_entropy": -1.0, "actor_entropy": -0.37152279865357185, "alpha_loss": -0.0017324683468623629, "alpha_value": 0.13720883024831232, "duration": 180.11039686203003, "step": 87500}
{"episode_reward": 843.4417323355018, "episode": 701.0, "Q1 loss": 5.1408827066421505, "Q2 loss": 5.106302722930908, "Mean Target Q": 736.6595522460938, "Mean Q1": 736.6622973632813, "Mean Q2": 736.6619409179688, "critic_loss": 10.24718543624878, "batch_reward": 6.163981239318848, "actor_loss": -736.7065555633061, "actor_target_entropy": -1.0, "actor_entropy": -0.33427321153973777, "alpha_loss": 0.0020560387795465805, "alpha_value": 0.13716177676670502, "duration": 185.12927436828613, "step": 87625}
{"episode_reward": 845.9697150296345, "episode": 702.0, "Q1 loss": 5.768368890762329, "Q2 loss": 5.843962755203247, "Mean Target Q": 736.24505078125, "Mean Q1": 736.2423051757812, "Mean Q2": 736.2447778320312, "critic_loss": 11.612331653594971, "batch_reward": 6.125271377563476, "actor_loss": -736.4153235650832, "actor_target_entropy": -1.0, "actor_entropy": -0.2871632734614034, "alpha_loss": 0.00637113980971457, "alpha_value": 0.13678493273831785, "duration": 187.83096504211426, "step": 87750}
{"episode_reward": 809.8457262360546, "episode": 703.0, "Q1 loss": 5.452937633514404, "Q2 loss": 5.425849340438843, "Mean Target Q": 736.3837529296875, "Mean Q1": 736.3768286132813, "Mean Q2": 736.3765283203124, "critic_loss": 10.878787021636963, "batch_reward": 6.1183585319519045, "actor_loss": -736.7776314871652, "actor_target_entropy": -1.0, "actor_entropy": -0.3402651065871829, "alpha_loss": 0.0023945021417198908, "alpha_value": 0.1362528948811854, "duration": 181.29094314575195, "step": 87875}
{"episode_reward": 837.5394490508661, "episode": 704.0, "Q1 loss": 5.542037902832031, "Q2 loss": 5.434679874420166, "Mean Target Q": 736.9663173828125, "Mean Q1": 736.9673188476562, "Mean Q2": 736.9671572265624, "critic_loss": 10.976717784881592, "batch_reward": 6.160295310974121, "actor_loss": -737.3788225727696, "actor_target_entropy": -1.0, "actor_entropy": -0.34550522604296285, "alpha_loss": 0.0037321919733057578, "alpha_value": 0.1359752555464057, "duration": 186.74575853347778, "step": 88000}
{"episode_reward": 835.7447871308724, "episode": 705.0, "Q1 loss": 5.31715954208374, "Q2 loss": 5.192227499961853, "Mean Target Q": 736.8772993164063, "Mean Q1": 736.8786918945312, "Mean Q2": 736.8782446289063, "critic_loss": 10.509387001037597, "batch_reward": 6.151889995574951, "actor_loss": -737.4115978422619, "actor_target_entropy": -1.0, "actor_entropy": -0.4059219341429453, "alpha_loss": -0.00131760663094206, "alpha_value": 0.1359110379623327, "duration": 189.4120969772339, "step": 88125}
{"episode_reward": 845.269877626533, "episode": 706.0, "Q1 loss": 4.77348032951355, "Q2 loss": 4.7622908592224125, "Mean Target Q": 736.9375234375, "Mean Q1": 736.9304399414062, "Mean Q2": 736.93068359375, "critic_loss": 9.535771194458007, "batch_reward": 6.147779682159424, "actor_loss": -737.6990760064895, "actor_target_entropy": -1.0, "actor_entropy": -0.39083181033211367, "alpha_loss": -0.001998155201304584, "alpha_value": 0.1361040574211165, "duration": 177.75332045555115, "step": 88250}
{"episode_reward": 842.1364876580175, "episode": 707.0, "Q1 loss": 5.663716123580933, "Q2 loss": 5.597877750396728, "Mean Target Q": 736.9663842773438, "Mean Q1": 736.9676044921875, "Mean Q2": 736.9676333007812, "critic_loss": 11.261593879699706, "batch_reward": 6.1536178855895995, "actor_loss": -737.1853472997271, "actor_target_entropy": -1.0, "actor_entropy": -0.38898073680817136, "alpha_loss": -0.0010356656903962767, "alpha_value": 0.13623900537004213, "duration": 200.94883847236633, "step": 88375}
{"episode_reward": 822.5313537078428, "episode": 708.0, "Q1 loss": 5.528624626159668, "Q2 loss": 5.571643217086792, "Mean Target Q": 737.1559741210938, "Mean Q1": 737.1595419921875, "Mean Q2": 737.159236328125, "critic_loss": 11.100267810821533, "batch_reward": 6.143321350097656, "actor_loss": -737.3753543976815, "actor_target_entropy": -1.0, "actor_entropy": -0.35348498052166355, "alpha_loss": 0.0002469830590510561, "alpha_value": 0.13626346478207166, "duration": 190.34865140914917, "step": 88500}
{"episode_reward": 827.8880895522822, "episode": 709.0, "Q1 loss": 5.862560459136963, "Q2 loss": 5.922709791183472, "Mean Target Q": 737.1561030273438, "Mean Q1": 737.147443359375, "Mean Q2": 737.1481142578125, "critic_loss": 11.78527019882202, "batch_reward": 6.141684139251709, "actor_loss": -737.8691047789558, "actor_target_entropy": -1.0, "actor_entropy": -0.3997409026774149, "alpha_loss": -0.002536328299717593, "alpha_value": 0.13639576587141786, "duration": 190.84390592575073, "step": 88625}
{"episode_reward": 844.9643422886148, "episode": 710.0, "Q1 loss": 6.1553786859512325, "Q2 loss": 6.213629626274109, "Mean Target Q": 737.5314013671875, "Mean Q1": 737.536171875, "Mean Q2": 737.5357177734375, "critic_loss": 12.369008295059205, "batch_reward": 6.159296363830566, "actor_loss": -737.7841235745337, "actor_target_entropy": -1.0, "actor_entropy": -0.3260526097109241, "alpha_loss": 0.006192295417760408, "alpha_value": 0.13624461294417617, "duration": 195.6281418800354, "step": 88750}
{"episode_reward": 838.091868917955, "episode": 711.0, "Q1 loss": 5.344111059188843, "Q2 loss": 5.203112535476684, "Mean Target Q": 737.3904462890625, "Mean Q1": 737.3917348632813, "Mean Q2": 737.3904633789062, "critic_loss": 10.547223602294922, "batch_reward": 6.1412282371521, "actor_loss": -737.7484605577257, "actor_target_entropy": -1.0, "actor_entropy": -0.3520781984404912, "alpha_loss": 0.0014457613274100282, "alpha_value": 0.13582513954114644, "duration": 190.3417956829071, "step": 88875}
{"episode_reward": 834.5554610769022, "episode": 712.0, "Q1 loss": 5.29740333366394, "Q2 loss": 5.238798505783081, "Mean Target Q": 737.4765087890624, "Mean Q1": 737.4750727539063, "Mean Q2": 737.4771928710937, "critic_loss": 10.53620185470581, "batch_reward": 6.151509326934814, "actor_loss": -737.4989535424018, "actor_target_entropy": -1.0, "actor_entropy": -0.3910948586079382, "alpha_loss": -0.00351371182478033, "alpha_value": 0.13588639142406211, "duration": 196.10359287261963, "step": 89000}
{"episode_reward": 841.273489371948, "episode": 713.0, "Q1 loss": 5.081367911338806, "Q2 loss": 5.018406215667724, "Mean Target Q": 737.6687299804687, "Mean Q1": 737.6637109375, "Mean Q2": 737.6638544921875, "critic_loss": 10.09977412033081, "batch_reward": 6.160962837219238, "actor_loss": -737.7357003348214, "actor_target_entropy": -1.0, "actor_entropy": -0.3890047532225412, "alpha_loss": -0.0021784628412523676, "alpha_value": 0.1362003759698473, "duration": 197.0475194454193, "step": 89125}
{"episode_reward": 843.5209782605406, "episode": 714.0, "Q1 loss": 4.811738240242004, "Q2 loss": 4.7420071611404415, "Mean Target Q": 737.4387514648438, "Mean Q1": 737.4383823242188, "Mean Q2": 737.4362749023437, "critic_loss": 9.553745401382447, "batch_reward": 6.135606746673584, "actor_loss": -737.9027050387475, "actor_target_entropy": -1.0, "actor_entropy": -0.34594164115767323, "alpha_loss": 0.0009688275815513466, "alpha_value": 0.1362339844204831, "duration": 196.54276323318481, "step": 89250}
{"episode_reward": 831.6468780238157, "episode": 715.0, "Q1 loss": 5.06056474685669, "Q2 loss": 5.098796068191528, "Mean Target Q": 737.7541782226563, "Mean Q1": 737.7594965820313, "Mean Q2": 737.7600830078125, "critic_loss": 10.159360816955566, "batch_reward": 6.149778045654297, "actor_loss": -738.0732082790798, "actor_target_entropy": -1.0, "actor_entropy": -0.3941819544822451, "alpha_loss": -0.002414086336521284, "alpha_value": 0.1363267452637968, "duration": 197.3485448360443, "step": 89375}
{"episode_reward": 847.7780115041111, "episode": 716.0, "Q1 loss": 5.502227910995483, "Q2 loss": 5.346621936798096, "Mean Target Q": 737.8354765625, "Mean Q1": 737.8311293945312, "Mean Q2": 737.8318154296875, "critic_loss": 10.848849872589112, "batch_reward": 6.146106147766114, "actor_loss": -738.0384560861895, "actor_target_entropy": -1.0, "actor_entropy": -0.3497244215780689, "alpha_loss": 0.0012780639451868351, "alpha_value": 0.13639767842155542, "duration": 194.61244750022888, "step": 89500}
{"episode_reward": 831.4778458085543, "episode": 717.0, "Q1 loss": 5.055971012115479, "Q2 loss": 5.030385597229004, "Mean Target Q": 737.9697397460938, "Mean Q1": 737.968087890625, "Mean Q2": 737.9652270507812, "critic_loss": 10.086356616973877, "batch_reward": 6.160841220855713, "actor_loss": -738.1531003921751, "actor_target_entropy": -1.0, "actor_entropy": -0.34458253781000775, "alpha_loss": 0.0021854681036775074, "alpha_value": 0.13621509788306674, "duration": 186.21230483055115, "step": 89625}
{"episode_reward": 836.0542633208566, "episode": 718.0, "Q1 loss": 5.383182391166687, "Q2 loss": 5.4742813539505, "Mean Target Q": 738.3379399414063, "Mean Q1": 738.3335141601563, "Mean Q2": 738.3361337890625, "critic_loss": 10.857463756561279, "batch_reward": 6.173593559265137, "actor_loss": -738.6085136167464, "actor_target_entropy": -1.0, "actor_entropy": -0.38954650202105123, "alpha_loss": -0.004814624461540652, "alpha_value": 0.13644151515165176, "duration": 190.53302764892578, "step": 89750}
{"episode_reward": 844.1425639280743, "episode": 719.0, "Q1 loss": 5.213533058166504, "Q2 loss": 5.138769409179687, "Mean Target Q": 738.02628125, "Mean Q1": 738.030224609375, "Mean Q2": 738.0297973632812, "critic_loss": 10.352302436828614, "batch_reward": 6.148203117370605, "actor_loss": -738.248308454241, "actor_target_entropy": -1.0, "actor_entropy": -0.39578523616942146, "alpha_loss": -0.005152901196630583, "alpha_value": 0.13667440421866361, "duration": 199.89082598686218, "step": 89875}
{"episode_reward": 830.9400028687998, "episode": 720.0, "Q1 loss": 5.041210188865661, "Q2 loss": 5.041891037940979, "Mean Target Q": 737.8913208007813, "Mean Q1": 737.8900375976563, "Mean Q2": 737.8898100585938, "critic_loss": 10.083101240158081, "batch_reward": 6.142513584136963, "actor_loss": -738.1764900453629, "actor_target_entropy": -1.0, "actor_entropy": -0.374761605935712, "alpha_loss": -0.0019058687011561087, "alpha_value": 0.13707271198056417, "step": 90000}
{"duration": 210.68380498886108, "step": 90000}
{"episode_reward": 830.067813773001, "episode": 721.0, "Q1 loss": 6.066237451553345, "Q2 loss": 5.960803991317749, "Mean Target Q": 737.8455375976563, "Mean Q1": 737.8407666015624, "Mean Q2": 737.840306640625, "critic_loss": 12.027041385650636, "batch_reward": 6.13577186203003, "actor_loss": -738.2057805137028, "actor_target_entropy": -1.0, "actor_entropy": -0.3940734924778106, "alpha_loss": -0.004394866008725431, "alpha_value": 0.1374516140647973, "duration": 220.91069507598877, "step": 90125}
{"episode_reward": 838.5347642169804, "episode": 722.0, "Q1 loss": 4.981758489608764, "Q2 loss": 4.969329619407654, "Mean Target Q": 738.04198046875, "Mean Q1": 738.0473696289063, "Mean Q2": 738.0472807617188, "critic_loss": 9.95108812713623, "batch_reward": 6.143299926757813, "actor_loss": -738.3931107059602, "actor_target_entropy": -1.0, "actor_entropy": -0.3732797267936891, "alpha_loss": 0.0010739652301004576, "alpha_value": 0.13757808676256367, "duration": 199.3854582309723, "step": 90250}
{"episode_reward": 846.1997042887568, "episode": 723.0, "Q1 loss": 5.276748775482178, "Q2 loss": 5.150710628509522, "Mean Target Q": 738.5590830078125, "Mean Q1": 738.5561904296875, "Mean Q2": 738.5579169921875, "critic_loss": 10.427459392547608, "batch_reward": 6.167273239135742, "actor_loss": -738.8358813089038, "actor_target_entropy": -1.0, "actor_entropy": -0.38239025975030566, "alpha_loss": 0.0022120355399295926, "alpha_value": 0.13739899267808664, "duration": 198.55766677856445, "step": 90375}
{"episode_reward": 842.6568658197211, "episode": 724.0, "Q1 loss": 4.945155645370483, "Q2 loss": 4.863106478691101, "Mean Target Q": 738.5390600585938, "Mean Q1": 738.5399326171874, "Mean Q2": 738.5388959960937, "critic_loss": 9.808262115478515, "batch_reward": 6.16329859161377, "actor_loss": -738.9644942745085, "actor_target_entropy": -1.0, "actor_entropy": -0.32874114619147393, "alpha_loss": 0.0025298377055855046, "alpha_value": 0.13730830585024292, "duration": 185.48659825325012, "step": 90500}
{"episode_reward": 840.1798217477772, "episode": 725.0, "Q1 loss": 4.820845874786377, "Q2 loss": 4.757866460800171, "Mean Target Q": 738.5388173828125, "Mean Q1": 738.533015625, "Mean Q2": 738.5334970703125, "critic_loss": 9.578712337493897, "batch_reward": 6.159855686187744, "actor_loss": -738.5787954179067, "actor_target_entropy": -1.0, "actor_entropy": -0.3799557685852051, "alpha_loss": -0.0020414242883109385, "alpha_value": 0.1371743086687536, "duration": 202.2638201713562, "step": 90625}
{"episode_reward": 844.1002210769311, "episode": 726.0, "Q1 loss": 5.284498722076416, "Q2 loss": 5.248187410354614, "Mean Target Q": 738.5765698242187, "Mean Q1": 738.5802416992187, "Mean Q2": 738.5811782226563, "critic_loss": 10.532686126708985, "batch_reward": 6.153708980560303, "actor_loss": -738.9308255103326, "actor_target_entropy": -1.0, "actor_entropy": -0.3713321599268144, "alpha_loss": 0.0009651825173697885, "alpha_value": 0.13726038805970725, "duration": 186.54304766654968, "step": 90750}
{"episode_reward": 841.0901565381814, "episode": 727.0, "Q1 loss": 4.503784643173217, "Q2 loss": 4.5081790256500245, "Mean Target Q": 738.5634409179687, "Mean Q1": 738.5567119140625, "Mean Q2": 738.5547973632813, "critic_loss": 9.011963634490966, "batch_reward": 6.155777866363525, "actor_loss": -738.8665141756572, "actor_target_entropy": -1.0, "actor_entropy": -0.375797967116038, "alpha_loss": 0.0001461810509984692, "alpha_value": 0.13720066330926328, "duration": 188.50684785842896, "step": 90875}
{"episode_reward": 831.7883050066775, "episode": 728.0, "Q1 loss": 5.214031200408936, "Q2 loss": 5.237239244461059, "Mean Target Q": 738.6353999023438, "Mean Q1": 738.6324111328125, "Mean Q2": 738.63487890625, "critic_loss": 10.451270477294923, "batch_reward": 6.161040576934814, "actor_loss": -738.8501498314643, "actor_target_entropy": -1.0, "actor_entropy": -0.37658279989996263, "alpha_loss": -0.0008603664088783966, "alpha_value": 0.13733061184635326, "duration": 193.50601029396057, "step": 91000}
{"episode_reward": 832.3208053422067, "episode": 729.0, "Q1 loss": 4.860558097839355, "Q2 loss": 4.90914095878601, "Mean Target Q": 738.7861640625, "Mean Q1": 738.7892216796874, "Mean Q2": 738.78860546875, "critic_loss": 9.769699073791504, "batch_reward": 6.1628544197082515, "actor_loss": -738.9967011951264, "actor_target_entropy": -1.0, "actor_entropy": -0.34277081915310453, "alpha_loss": 0.0024649859738669227, "alpha_value": 0.13714567914807269, "duration": 197.26300168037415, "step": 91125}
{"episode_reward": 836.5991162539501, "episode": 730.0, "Q1 loss": 5.606053825378418, "Q2 loss": 5.395390544891358, "Mean Target Q": 738.8820693359374, "Mean Q1": 738.877783203125, "Mean Q2": 738.87903125, "critic_loss": 11.00144436454773, "batch_reward": 6.160324432373047, "actor_loss": -739.2076839323967, "actor_target_entropy": -1.0, "actor_entropy": -0.3226270151715125, "alpha_loss": 0.004680648752142706, "alpha_value": 0.1368751866354133, "duration": 189.461754322052, "step": 91250}
{"episode_reward": 829.7353003120139, "episode": 731.0, "Q1 loss": 5.278509328842163, "Q2 loss": 5.256199649810791, "Mean Target Q": 739.0772236328125, "Mean Q1": 739.0775131835937, "Mean Q2": 739.076228515625, "critic_loss": 10.534708961486816, "batch_reward": 6.166877098083496, "actor_loss": -739.1607675703746, "actor_target_entropy": -1.0, "actor_entropy": -0.3273508591311319, "alpha_loss": 0.004054096372177203, "alpha_value": 0.13638341420455327, "duration": 182.5947871208191, "step": 91375}
{"episode_reward": 841.7422600012472, "episode": 732.0, "Q1 loss": 5.316531995773316, "Q2 loss": 5.217180376052856, "Mean Target Q": 739.7839702148437, "Mean Q1": 739.7867622070313, "Mean Q2": 739.7870571289062, "critic_loss": 10.533712390899659, "batch_reward": 6.204638446807861, "actor_loss": -739.8346124464466, "actor_target_entropy": -1.0, "actor_entropy": -0.29834638656147067, "alpha_loss": 0.007703629446276013, "alpha_value": 0.1358232479270667, "duration": 190.83440041542053, "step": 91500}
{"episode_reward": 848.4067871563927, "episode": 733.0, "Q1 loss": 5.122877378463745, "Q2 loss": 5.12748274898529, "Mean Target Q": 739.3007416992187, "Mean Q1": 739.3023447265625, "Mean Q2": 739.3030732421875, "critic_loss": 10.250360137939452, "batch_reward": 6.171818855285644, "actor_loss": -739.5903882223462, "actor_target_entropy": -1.0, "actor_entropy": -0.3535536215418861, "alpha_loss": 0.0011795616934135082, "alpha_value": 0.13539513673762252, "duration": 185.5176088809967, "step": 91625}
{"episode_reward": 835.0040049629796, "episode": 734.0, "Q1 loss": 5.229642164230347, "Q2 loss": 5.118953170776368, "Mean Target Q": 739.20987890625, "Mean Q1": 739.204267578125, "Mean Q2": 739.2029379882813, "critic_loss": 10.348595302581787, "batch_reward": 6.1579334259033205, "actor_loss": -739.3131526823967, "actor_target_entropy": -1.0, "actor_entropy": -0.3332197819986651, "alpha_loss": 0.0015940619782815056, "alpha_value": 0.13528099835551655, "duration": 192.0903835296631, "step": 91750}
{"episode_reward": 832.2593632834465, "episode": 735.0, "Q1 loss": 5.281686361312866, "Q2 loss": 5.173274532318115, "Mean Target Q": 739.3717666015625, "Mean Q1": 739.3698500976562, "Mean Q2": 739.3710180664062, "critic_loss": 10.454960929870605, "batch_reward": 6.171096351623535, "actor_loss": -739.8526872907366, "actor_target_entropy": -1.0, "actor_entropy": -0.3901528337645152, "alpha_loss": -0.00391438771556649, "alpha_value": 0.13545777797760622, "duration": 192.15930080413818, "step": 91875}
{"episode_reward": 745.8021727431407, "episode": 736.0, "Q1 loss": 5.691402700424194, "Q2 loss": 5.715750383377075, "Mean Target Q": 739.6182216796875, "Mean Q1": 739.6188422851562, "Mean Q2": 739.6169057617187, "critic_loss": 11.407153106689453, "batch_reward": 6.1663368186950684, "actor_loss": -739.828108264554, "actor_target_entropy": -1.0, "actor_entropy": -0.40057879446014283, "alpha_loss": -0.00217032382046924, "alpha_value": 0.13567978003195208, "duration": 192.46799898147583, "step": 92000}
{"episode_reward": 816.4344404849613, "episode": 737.0, "Q1 loss": 4.812384466171265, "Q2 loss": 4.846498508453369, "Mean Target Q": 739.6398374023438, "Mean Q1": 739.6436723632812, "Mean Q2": 739.6442309570313, "critic_loss": 9.658882938385009, "batch_reward": 6.173211727142334, "actor_loss": -739.8431774321057, "actor_target_entropy": -1.0, "actor_entropy": -0.34252993455008857, "alpha_loss": -0.0008840387380341925, "alpha_value": 0.1358960742410911, "duration": 185.51667737960815, "step": 92125}
{"episode_reward": 842.5521149982684, "episode": 738.0, "Q1 loss": 5.507921785354614, "Q2 loss": 5.513787929534912, "Mean Target Q": 739.6400712890625, "Mean Q1": 739.6307568359375, "Mean Q2": 739.63029296875, "critic_loss": 11.021709754943847, "batch_reward": 6.164583236694336, "actor_loss": -739.9593387726815, "actor_target_entropy": -1.0, "actor_entropy": -0.33180198794411075, "alpha_loss": 0.003752538709030036, "alpha_value": 0.1356808031402317, "duration": 187.6176323890686, "step": 92250}
{"episode_reward": 838.9092826457963, "episode": 739.0, "Q1 loss": 5.3778240127563475, "Q2 loss": 5.368388107299805, "Mean Target Q": 739.8579345703125, "Mean Q1": 739.8566577148438, "Mean Q2": 739.85534375, "critic_loss": 10.746212106704712, "batch_reward": 6.171132289886475, "actor_loss": -740.223158094618, "actor_target_entropy": -1.0, "actor_entropy": -0.36348811501548406, "alpha_loss": 0.00028452175181536445, "alpha_value": 0.13547693738665548, "duration": 190.9820899963379, "step": 92375}
{"episode_reward": 830.0494696901003, "episode": 740.0, "Q1 loss": 5.803712064743042, "Q2 loss": 5.759086366653443, "Mean Target Q": 739.8982509765625, "Mean Q1": 739.9003564453125, "Mean Q2": 739.902654296875, "critic_loss": 11.562798450469971, "batch_reward": 6.174602043151856, "actor_loss": -740.097395373929, "actor_target_entropy": -1.0, "actor_entropy": -0.35361865980009877, "alpha_loss": -9.276988848503078e-05, "alpha_value": 0.1355605594122257, "duration": 188.31411147117615, "step": 92500}
{"episode_reward": 841.2191728795543, "episode": 741.0, "Q1 loss": 4.890648630142212, "Q2 loss": 4.889187551498413, "Mean Target Q": 739.963404296875, "Mean Q1": 739.9614272460938, "Mean Q2": 739.9614287109375, "critic_loss": 9.779836193084718, "batch_reward": 6.170563549041748, "actor_loss": -740.1322341192337, "actor_target_entropy": -1.0, "actor_entropy": -0.3564430730683463, "alpha_loss": 0.004046177679103696, "alpha_value": 0.13536510331437665, "duration": 194.26210474967957, "step": 92625}
{"episode_reward": 825.0956101437157, "episode": 742.0, "Q1 loss": 5.303586077690125, "Q2 loss": 5.265631981849671, "Mean Target Q": 740.0272202148437, "Mean Q1": 740.02598046875, "Mean Q2": 740.0266162109375, "critic_loss": 10.569218074798584, "batch_reward": 6.1665275840759275, "actor_loss": -740.0883375598538, "actor_target_entropy": -1.0, "actor_entropy": -0.3624491201293084, "alpha_loss": -0.0005028807152543337, "alpha_value": 0.13520325742155964, "duration": 198.337060213089, "step": 92750}
{"episode_reward": 843.4905548870458, "episode": 743.0, "Q1 loss": 5.166980766296387, "Q2 loss": 5.138918537139893, "Mean Target Q": 740.139494140625, "Mean Q1": 740.1393715820312, "Mean Q2": 740.1384301757812, "critic_loss": 10.305899341583252, "batch_reward": 6.175362400054931, "actor_loss": -740.3980209108383, "actor_target_entropy": -1.0, "actor_entropy": -0.3775159399660807, "alpha_loss": -0.0010087214898140658, "alpha_value": 0.13519301655908492, "duration": 198.57327890396118, "step": 92875}
{"episode_reward": 824.4711089272937, "episode": 744.0, "Q1 loss": 4.983571535110474, "Q2 loss": 4.8911292238235475, "Mean Target Q": 740.4101801757813, "Mean Q1": 740.4094072265625, "Mean Q2": 740.4107431640625, "critic_loss": 9.874700729370117, "batch_reward": 6.184070613861084, "actor_loss": -740.7212051883821, "actor_target_entropy": -1.0, "actor_entropy": -0.3886682770905956, "alpha_loss": -0.0019347043088336865, "alpha_value": 0.1353422821545416, "duration": 184.20595288276672, "step": 93000}
{"episode_reward": 831.7422319223348, "episode": 745.0, "Q1 loss": 5.007444129943847, "Q2 loss": 5.043586055755616, "Mean Target Q": 740.2875395507813, "Mean Q1": 740.2872807617188, "Mean Q2": 740.2874077148438, "critic_loss": 10.051030139923096, "batch_reward": 6.180181133270263, "actor_loss": -740.3125813802084, "actor_target_entropy": -1.0, "actor_entropy": -0.36477405873555985, "alpha_loss": 0.002015488724859934, "alpha_value": 0.1354302798766823, "duration": 190.89892292022705, "step": 93125}
{"episode_reward": 845.7588697632127, "episode": 746.0, "Q1 loss": 5.357890279769897, "Q2 loss": 5.320533851623535, "Mean Target Q": 740.3253662109375, "Mean Q1": 740.3223774414063, "Mean Q2": 740.3224790039062, "critic_loss": 10.67842414855957, "batch_reward": 6.162887474060058, "actor_loss": -740.2284713252898, "actor_target_entropy": -1.0, "actor_entropy": -0.36798837588679406, "alpha_loss": -0.00015624556803114472, "alpha_value": 0.1352720609514812, "duration": 182.6644480228424, "step": 93250}
{"episode_reward": 839.1241500813051, "episode": 747.0, "Q1 loss": 5.161107185363769, "Q2 loss": 5.0265964469909665, "Mean Target Q": 740.3945053710937, "Mean Q1": 740.3882133789062, "Mean Q2": 740.3880517578125, "critic_loss": 10.187703636169434, "batch_reward": 6.177794750213623, "actor_loss": -740.8359229678199, "actor_target_entropy": -1.0, "actor_entropy": -0.3642724525360834, "alpha_loss": 0.002039922641531106, "alpha_value": 0.13511164089466438, "duration": 193.1040177345276, "step": 93375}
{"episode_reward": 814.5820020999265, "episode": 748.0, "Q1 loss": 4.790556106567383, "Q2 loss": 4.734074047088623, "Mean Target Q": 740.8004213867188, "Mean Q1": 740.8041284179687, "Mean Q2": 740.803033203125, "critic_loss": 9.524630146026611, "batch_reward": 6.185602840423584, "actor_loss": -741.085465954196, "actor_target_entropy": -1.0, "actor_entropy": -0.36644027165828214, "alpha_loss": 0.002251548587434715, "alpha_value": 0.13495125054132484, "duration": 196.01767587661743, "step": 93500}
{"episode_reward": 842.5224851568515, "episode": 749.0, "Q1 loss": 4.931422397613526, "Q2 loss": 4.891521802902222, "Mean Target Q": 740.6477119140625, "Mean Q1": 740.6460205078125, "Mean Q2": 740.6459013671875, "critic_loss": 9.822944217681885, "batch_reward": 6.173334613800049, "actor_loss": -741.0072515578497, "actor_target_entropy": -1.0, "actor_entropy": -0.3767894303041791, "alpha_loss": 0.0014497173510284887, "alpha_value": 0.13468826233012202, "duration": 181.28315258026123, "step": 93625}
{"episode_reward": 836.2033417905774, "episode": 750.0, "Q1 loss": 4.982341142654419, "Q2 loss": 5.074837059020996, "Mean Target Q": 740.791681640625, "Mean Q1": 740.7980810546875, "Mean Q2": 740.7965776367188, "critic_loss": 10.057178142547608, "batch_reward": 6.177523681640625, "actor_loss": -741.1226530997984, "actor_target_entropy": -1.0, "actor_entropy": -0.3685604425207261, "alpha_loss": 9.464310114121725e-05, "alpha_value": 0.13469060640856403, "duration": 174.90667700767517, "step": 93750}
{"episode_reward": 846.3016762740494, "episode": 751.0, "Q1 loss": 5.632131319046021, "Q2 loss": 5.648534425735473, "Mean Target Q": 741.17908203125, "Mean Q1": 741.1740307617188, "Mean Q2": 741.1763735351562, "critic_loss": 11.280665782928466, "batch_reward": 6.187457817077637, "actor_loss": -741.2540196010044, "actor_target_entropy": -1.0, "actor_entropy": -0.38171575939844526, "alpha_loss": -0.0002055766267908944, "alpha_value": 0.1346277490157576, "duration": 190.12361240386963, "step": 93875}
{"episode_reward": 844.8889493207366, "episode": 752.0, "Q1 loss": 4.902712812423706, "Q2 loss": 4.945499816894531, "Mean Target Q": 741.1448232421875, "Mean Q1": 741.1425581054688, "Mean Q2": 741.1403657226563, "critic_loss": 9.848212646484376, "batch_reward": 6.1984058837890625, "actor_loss": -741.3709815240676, "actor_target_entropy": -1.0, "actor_entropy": -0.35314211826170644, "alpha_loss": 0.003800797893951136, "alpha_value": 0.13452503075240543, "duration": 182.35877871513367, "step": 94000}
{"episode_reward": 848.6771202093413, "episode": 753.0, "Q1 loss": 5.81183119392395, "Q2 loss": 5.735543113708496, "Mean Target Q": 740.9711572265625, "Mean Q1": 740.9740537109375, "Mean Q2": 740.9744575195313, "critic_loss": 11.54737428665161, "batch_reward": 6.170769443511963, "actor_loss": -741.2527281746031, "actor_target_entropy": -1.0, "actor_entropy": -0.3532608241315872, "alpha_loss": 0.006141193431898183, "alpha_value": 0.1341666470333216, "duration": 180.12374544143677, "step": 94125}
{"episode_reward": 832.5197285084705, "episode": 754.0, "Q1 loss": 6.9391373424530025, "Q2 loss": 6.865861724853516, "Mean Target Q": 741.13309375, "Mean Q1": 741.1242172851563, "Mean Q2": 741.12476171875, "critic_loss": 13.804999084472657, "batch_reward": 6.187652446746826, "actor_loss": -741.3258637459047, "actor_target_entropy": -1.0, "actor_entropy": -0.3341828262613666, "alpha_loss": 0.004875801528067959, "alpha_value": 0.13350546404561203, "duration": 181.08999872207642, "step": 94250}
{"episode_reward": 843.5338014176625, "episode": 755.0, "Q1 loss": 6.050432041168213, "Q2 loss": 6.072432783126831, "Mean Target Q": 740.8832143554688, "Mean Q1": 740.8855498046875, "Mean Q2": 740.8853940429688, "critic_loss": 12.122864818572998, "batch_reward": 6.173887798309326, "actor_loss": -741.0230015345982, "actor_target_entropy": -1.0, "actor_entropy": -0.31937379685659256, "alpha_loss": 0.006459582255162772, "alpha_value": 0.13300808880714843, "duration": 191.46412086486816, "step": 94375}
{"episode_reward": 841.4526891996446, "episode": 756.0, "Q1 loss": 5.842921342849731, "Q2 loss": 5.853679695129395, "Mean Target Q": 741.1032143554687, "Mean Q1": 741.10516015625, "Mean Q2": 741.1067255859375, "critic_loss": 11.696601039886474, "batch_reward": 6.18495246887207, "actor_loss": -741.3109121014995, "actor_target_entropy": -1.0, "actor_entropy": -0.3512558997158081, "alpha_loss": 0.004233061414842885, "alpha_value": 0.132470131776073, "duration": 190.8361120223999, "step": 94500}
{"episode_reward": 842.4728993648775, "episode": 757.0, "Q1 loss": 5.147292907714844, "Q2 loss": 5.139438941955566, "Mean Target Q": 741.189763671875, "Mean Q1": 741.1845766601563, "Mean Q2": 741.1835307617188, "critic_loss": 10.286731838226318, "batch_reward": 6.183408611297607, "actor_loss": -741.8005438910591, "actor_target_entropy": -1.0, "actor_entropy": -0.3626967777335455, "alpha_loss": 0.00117554294411093, "alpha_value": 0.13221496125057888, "duration": 183.3358600139618, "step": 94625}
{"episode_reward": 835.8712096179875, "episode": 758.0, "Q1 loss": 4.946545366287231, "Q2 loss": 4.8735244197845455, "Mean Target Q": 741.2373891601562, "Mean Q1": 741.2424106445312, "Mean Q2": 741.244158203125, "critic_loss": 9.82006978225708, "batch_reward": 6.177101493835449, "actor_loss": -741.3334350585938, "actor_target_entropy": -1.0, "actor_entropy": -0.39247090008951, "alpha_loss": -0.00091304246621627, "alpha_value": 0.13220044407666628, "duration": 196.69759511947632, "step": 94750}
{"episode_reward": 851.4352514638819, "episode": 759.0, "Q1 loss": 4.829659582138062, "Q2 loss": 4.837915735244751, "Mean Target Q": 741.4265786132812, "Mean Q1": 741.4207802734375, "Mean Q2": 741.4207744140625, "critic_loss": 9.667575302124023, "batch_reward": 6.174925285339356, "actor_loss": -741.6755894252232, "actor_target_entropy": -1.0, "actor_entropy": -0.3899662229749892, "alpha_loss": -0.0031763094325830774, "alpha_value": 0.13239838276212557, "duration": 190.6582887172699, "step": 94875}
{"episode_reward": 838.3689059091322, "episode": 760.0, "Q1 loss": 4.876395526885986, "Q2 loss": 4.84623539352417, "Mean Target Q": 741.5868471679687, "Mean Q1": 741.590599609375, "Mean Q2": 741.5875424804688, "critic_loss": 9.722630939483643, "batch_reward": 6.181541942596436, "actor_loss": -741.7029753654234, "actor_target_entropy": -1.0, "actor_entropy": -0.37094433173056574, "alpha_loss": -0.0004132078198205319, "alpha_value": 0.13258001576166803, "step": 95000}
{"duration": 207.10081696510315, "step": 95000}
{"episode_reward": 839.2306908834615, "episode": 761.0, "Q1 loss": 5.099443355560303, "Q2 loss": 5.142092683792114, "Mean Target Q": 741.4120922851563, "Mean Q1": 741.4082260742188, "Mean Q2": 741.4086513671875, "critic_loss": 10.241536083221435, "batch_reward": 6.175493099212646, "actor_loss": -741.4531995985243, "actor_target_entropy": -1.0, "actor_entropy": -0.38811946908632916, "alpha_loss": -0.00234592402176488, "alpha_value": 0.13285853427138436, "duration": 189.4243779182434, "step": 95125}
{"episode_reward": 839.7778180603736, "episode": 762.0, "Q1 loss": 4.668623770713806, "Q2 loss": 4.607800661087036, "Mean Target Q": 741.5358569335938, "Mean Q1": 741.5377705078125, "Mean Q2": 741.5386303710937, "critic_loss": 9.276424455642701, "batch_reward": 6.185726722717285, "actor_loss": -741.818590717931, "actor_target_entropy": -1.0, "actor_entropy": -0.3822744656955042, "alpha_loss": -0.0007504428842014843, "alpha_value": 0.13288172461402314, "duration": 186.21141529083252, "step": 95250}
{"episode_reward": 837.4163026748649, "episode": 763.0, "Q1 loss": 4.608471585273743, "Q2 loss": 4.565628396987915, "Mean Target Q": 741.6532514648437, "Mean Q1": 741.6574350585937, "Mean Q2": 741.65587890625, "critic_loss": 9.174099990844727, "batch_reward": 6.175340335845947, "actor_loss": -742.1868392702133, "actor_target_entropy": -1.0, "actor_entropy": -0.38578422154699055, "alpha_loss": -0.0009983364790160623, "alpha_value": 0.13290788889632413, "duration": 182.17725491523743, "step": 95375}
{"episode_reward": 843.1236357625631, "episode": 764.0, "Q1 loss": 5.4791982536315915, "Q2 loss": 5.454721923828125, "Mean Target Q": 741.9363442382812, "Mean Q1": 741.925060546875, "Mean Q2": 741.9279462890624, "critic_loss": 10.933920146942139, "batch_reward": 6.2094448356628416, "actor_loss": -742.0988169024067, "actor_target_entropy": -1.0, "actor_entropy": -0.37701796620122846, "alpha_loss": 0.003111174591110959, "alpha_value": 0.13281956866611694, "duration": 196.27458548545837, "step": 95500}
{"episode_reward": 843.0245085745387, "episode": 765.0, "Q1 loss": 4.935070180892945, "Q2 loss": 4.990631051063538, "Mean Target Q": 741.8644194335938, "Mean Q1": 741.8657475585937, "Mean Q2": 741.8645327148438, "critic_loss": 9.925701217651367, "batch_reward": 6.189841857910157, "actor_loss": -742.0484066917783, "actor_target_entropy": -1.0, "actor_entropy": -0.3234474833995577, "alpha_loss": 0.0026072434857413763, "alpha_value": 0.13254780484751386, "duration": 188.15776896476746, "step": 95625}
{"episode_reward": 844.7259251081996, "episode": 766.0, "Q1 loss": 5.197389371871949, "Q2 loss": 5.180264194488525, "Mean Target Q": 741.8869614257812, "Mean Q1": 741.885923828125, "Mean Q2": 741.8851928710938, "critic_loss": 10.377653573989868, "batch_reward": 6.183795799255371, "actor_loss": -742.1937964654738, "actor_target_entropy": -1.0, "actor_entropy": -0.3764572989556097, "alpha_loss": -0.0004653399134235036, "alpha_value": 0.13250107532157032, "duration": 189.28143668174744, "step": 95750}
{"episode_reward": 848.91531881705, "episode": 767.0, "Q1 loss": 4.993517135620118, "Q2 loss": 5.003473138809204, "Mean Target Q": 741.8688588867187, "Mean Q1": 741.8677265625, "Mean Q2": 741.8691489257812, "critic_loss": 9.99699024963379, "batch_reward": 6.184621276855469, "actor_loss": -742.0653870597719, "actor_target_entropy": -1.0, "actor_entropy": -0.3364169881457374, "alpha_loss": 0.0034814378789936504, "alpha_value": 0.1323733039283697, "duration": 193.77357697486877, "step": 95875}
{"episode_reward": 826.1451407853418, "episode": 768.0, "Q1 loss": 4.957426923751831, "Q2 loss": 4.832556129455567, "Mean Target Q": 741.8972978515625, "Mean Q1": 741.89693359375, "Mean Q2": 741.8956665039062, "critic_loss": 9.78998296546936, "batch_reward": 6.173105571746826, "actor_loss": -742.5067985288558, "actor_target_entropy": -1.0, "actor_entropy": -0.3568571921317808, "alpha_loss": 0.003287513900901221, "alpha_value": 0.1320260769448436, "duration": 190.84785056114197, "step": 96000}
{"episode_reward": 830.1657164901573, "episode": 769.0, "Q1 loss": 4.477205856323242, "Q2 loss": 4.503724081993103, "Mean Target Q": 742.0294506835937, "Mean Q1": 742.0301831054687, "Mean Q2": 742.029943359375, "critic_loss": 8.980929948806763, "batch_reward": 6.183807476043701, "actor_loss": -742.2403050982763, "actor_target_entropy": -1.0, "actor_entropy": -0.33674118395835634, "alpha_loss": 0.0036228501167710103, "alpha_value": 0.13171505200594202, "duration": 189.5565640926361, "step": 96125}
{"episode_reward": 838.906969220955, "episode": 770.0, "Q1 loss": 5.339437661170959, "Q2 loss": 5.372034812927246, "Mean Target Q": 742.3335063476562, "Mean Q1": 742.3354482421875, "Mean Q2": 742.3359609375, "critic_loss": 10.711472480773926, "batch_reward": 6.194677787780762, "actor_loss": -742.3544154013357, "actor_target_entropy": -1.0, "actor_entropy": -0.366404541557835, "alpha_loss": 0.0001276799716100457, "alpha_value": 0.13136706359173903, "duration": 194.34715390205383, "step": 96250}
{"episode_reward": 830.5200111800966, "episode": 771.0, "Q1 loss": 5.231501916885376, "Q2 loss": 5.2143086929321285, "Mean Target Q": 742.4891474609375, "Mean Q1": 742.4828256835938, "Mean Q2": 742.4836557617188, "critic_loss": 10.445810569763184, "batch_reward": 6.1973341331481935, "actor_loss": -742.7019779265873, "actor_target_entropy": -1.0, "actor_entropy": -0.3963829799303933, "alpha_loss": -0.00017559774855654392, "alpha_value": 0.13143644138802135, "duration": 193.19648623466492, "step": 96375}
{"episode_reward": 841.2073543728869, "episode": 772.0, "Q1 loss": 5.883942663192749, "Q2 loss": 5.884530132293701, "Mean Target Q": 742.5174521484375, "Mean Q1": 742.515103515625, "Mean Q2": 742.515927734375, "critic_loss": 11.768472827911378, "batch_reward": 6.198986907958984, "actor_loss": -742.7695617675781, "actor_target_entropy": -1.0, "actor_entropy": -0.3683754897886707, "alpha_loss": -0.0005829267113679839, "alpha_value": 0.13153746172068204, "duration": 176.69731426239014, "step": 96500}
{"episode_reward": 837.4299726472645, "episode": 773.0, "Q1 loss": 5.365293008804321, "Q2 loss": 5.331822505950928, "Mean Target Q": 742.4514301757813, "Mean Q1": 742.4514814453125, "Mean Q2": 742.4499848632812, "critic_loss": 10.697115503311156, "batch_reward": 6.18989282989502, "actor_loss": -742.8230532691592, "actor_target_entropy": -1.0, "actor_entropy": -0.39321057427497136, "alpha_loss": 0.0005312633491860377, "alpha_value": 0.13150292874637098, "duration": 169.89745569229126, "step": 96625}
{"episode_reward": 843.5884376503284, "episode": 774.0, "Q1 loss": 5.302314095497131, "Q2 loss": 5.242479652404785, "Mean Target Q": 742.7320971679687, "Mean Q1": 742.734466796875, "Mean Q2": 742.7347827148437, "critic_loss": 10.544793758392334, "batch_reward": 6.198658020019531, "actor_loss": -742.9334096600933, "actor_target_entropy": -1.0, "actor_entropy": -0.36664968680950905, "alpha_loss": 0.002614985695183878, "alpha_value": 0.13132336534052647, "duration": 179.08834266662598, "step": 96750}
{"episode_reward": 832.1021181847772, "episode": 775.0, "Q1 loss": 4.98335502243042, "Q2 loss": 4.914088600158691, "Mean Target Q": 742.52576171875, "Mean Q1": 742.5203266601562, "Mean Q2": 742.521603515625, "critic_loss": 9.897443603515624, "batch_reward": 6.1962525749206545, "actor_loss": -742.7520781017486, "actor_target_entropy": -1.0, "actor_entropy": -0.352714667244563, "alpha_loss": 0.002328375267559692, "alpha_value": 0.1311063803809739, "duration": 177.0171980857849, "step": 96875}
{"episode_reward": 830.0341672034934, "episode": 776.0, "Q1 loss": 5.421748413085938, "Q2 loss": 5.399113901138306, "Mean Target Q": 742.5231796875, "Mean Q1": 742.52570703125, "Mean Q2": 742.52477734375, "critic_loss": 10.820862281799316, "batch_reward": 6.185999126434326, "actor_loss": -742.710672686177, "actor_target_entropy": -1.0, "actor_entropy": -0.3935185194976868, "alpha_loss": -0.0011917052005657987, "alpha_value": 0.13102396983764314, "duration": 179.4371736049652, "step": 97000}
{"episode_reward": 832.9797812338038, "episode": 777.0, "Q1 loss": 5.242645275115967, "Q2 loss": 5.302561748504639, "Mean Target Q": 742.3449306640625, "Mean Q1": 742.3470986328125, "Mean Q2": 742.3465654296875, "critic_loss": 10.545206996917724, "batch_reward": 6.185769332885743, "actor_loss": -742.7090909443205, "actor_target_entropy": -1.0, "actor_entropy": -0.3949637356258574, "alpha_loss": -0.0020717888726808483, "alpha_value": 0.13130101286492363, "duration": 184.77948474884033, "step": 97125}
{"episode_reward": 843.8914566482239, "episode": 778.0, "Q1 loss": 5.671322650909424, "Q2 loss": 5.6242087478637695, "Mean Target Q": 742.4480087890626, "Mean Q1": 742.442083984375, "Mean Q2": 742.4426020507813, "critic_loss": 11.295531406402588, "batch_reward": 6.179751541137695, "actor_loss": -742.6700291787424, "actor_target_entropy": -1.0, "actor_entropy": -0.36330742845612185, "alpha_loss": 0.0016468987864021573, "alpha_value": 0.1313079888673416, "duration": 183.29063415527344, "step": 97250}
{"episode_reward": 840.6041307004823, "episode": 779.0, "Q1 loss": 5.337084890365601, "Q2 loss": 5.383380815505982, "Mean Target Q": 742.812361328125, "Mean Q1": 742.8099975585938, "Mean Q2": 742.8101162109375, "critic_loss": 10.720465698242187, "batch_reward": 6.202208820343017, "actor_loss": -743.3247951931423, "actor_target_entropy": -1.0, "actor_entropy": -0.37424865317723105, "alpha_loss": 0.0013772529209890062, "alpha_value": 0.1312116675683832, "duration": 181.07381987571716, "step": 97375}
{"episode_reward": 843.0761069754724, "episode": 780.0, "Q1 loss": 4.854503650665283, "Q2 loss": 4.752376626014709, "Mean Target Q": 742.8712729492188, "Mean Q1": 742.8708891601563, "Mean Q2": 742.8693247070313, "critic_loss": 9.606880252838135, "batch_reward": 6.18959404373169, "actor_loss": -742.9675027170489, "actor_target_entropy": -1.0, "actor_entropy": -0.34377373322363824, "alpha_loss": 0.0032124153973023977, "alpha_value": 0.13098192881278561, "duration": 185.49103450775146, "step": 97500}
{"episode_reward": 844.7981057266079, "episode": 781.0, "Q1 loss": 5.544765386581421, "Q2 loss": 5.453737571716308, "Mean Target Q": 742.858908203125, "Mean Q1": 742.85619140625, "Mean Q2": 742.8563525390625, "critic_loss": 10.998502944946289, "batch_reward": 6.1993887405395505, "actor_loss": -743.1934562562004, "actor_target_entropy": -1.0, "actor_entropy": -0.33459190078197965, "alpha_loss": 0.0015784342983914982, "alpha_value": 0.1306485901035033, "duration": 185.97180604934692, "step": 97625}
{"episode_reward": 839.7852339823608, "episode": 782.0, "Q1 loss": 5.876316917419434, "Q2 loss": 5.711902633666992, "Mean Target Q": 742.7262490234375, "Mean Q1": 742.7327890625, "Mean Q2": 742.7327861328125, "critic_loss": 11.588219535827637, "batch_reward": 6.18055366897583, "actor_loss": -743.0193018759451, "actor_target_entropy": -1.0, "actor_entropy": -0.40101376656563054, "alpha_loss": 0.00015714930580748666, "alpha_value": 0.13057200511997952, "duration": 170.56334376335144, "step": 97750}
{"episode_reward": 836.9753559649856, "episode": 783.0, "Q1 loss": 4.896044576644898, "Q2 loss": 4.756943839073181, "Mean Target Q": 742.8281411132813, "Mean Q1": 742.8240395507812, "Mean Q2": 742.8267143554688, "critic_loss": 9.652988395690919, "batch_reward": 6.173290237426758, "actor_loss": -743.0787062872024, "actor_target_entropy": -1.0, "actor_entropy": -0.34883757526912385, "alpha_loss": 0.006071215399378349, "alpha_value": 0.13041012590760614, "duration": 178.6874008178711, "step": 97875}
{"episode_reward": 844.7170922543769, "episode": 784.0, "Q1 loss": 4.795980900764465, "Q2 loss": 4.728504435539246, "Mean Target Q": 743.300806640625, "Mean Q1": 743.3010239257812, "Mean Q2": 743.3001586914063, "critic_loss": 9.524485328674317, "batch_reward": 6.2079283790588375, "actor_loss": -743.4175168929562, "actor_target_entropy": -1.0, "actor_entropy": -0.3864168462253386, "alpha_loss": 0.0021042613539799687, "alpha_value": 0.12981714139984335, "duration": 177.81799292564392, "step": 98000}
{"episode_reward": 840.7047648720794, "episode": 785.0, "Q1 loss": 4.852599174499511, "Q2 loss": 4.83427867603302, "Mean Target Q": 743.2734130859375, "Mean Q1": 743.2710927734375, "Mean Q2": 743.2708139648438, "critic_loss": 9.686877880096436, "batch_reward": 6.1970022315979, "actor_loss": -743.5387786380828, "actor_target_entropy": -1.0, "actor_entropy": -0.3925882781308795, "alpha_loss": -0.0012905019490669172, "alpha_value": 0.12980497187810258, "duration": 176.7226014137268, "step": 98125}
{"episode_reward": 848.1657013814265, "episode": 786.0, "Q1 loss": 5.6094038162231445, "Q2 loss": 5.486857815742493, "Mean Target Q": 742.9752255859376, "Mean Q1": 742.9711586914062, "Mean Q2": 742.9724965820312, "critic_loss": 11.096261642456055, "batch_reward": 6.184813568115234, "actor_loss": -743.2462089292464, "actor_target_entropy": -1.0, "actor_entropy": -0.3785819642005428, "alpha_loss": 0.000366636878630567, "alpha_value": 0.12985147288510387, "duration": 188.0567443370819, "step": 98250}
{"episode_reward": 832.8300194320727, "episode": 787.0, "Q1 loss": 4.94114877986908, "Q2 loss": 4.775556580543518, "Mean Target Q": 743.3074711914062, "Mean Q1": 743.308060546875, "Mean Q2": 743.3078579101563, "critic_loss": 9.716705341339111, "batch_reward": 6.2004503135681155, "actor_loss": -743.7791999937996, "actor_target_entropy": -1.0, "actor_entropy": -0.39084559915557743, "alpha_loss": -0.00038571221410252507, "alpha_value": 0.1298595581566519, "duration": 182.52369165420532, "step": 98375}
{"episode_reward": 826.5681584623275, "episode": 788.0, "Q1 loss": 4.6708701152801515, "Q2 loss": 4.628146196365356, "Mean Target Q": 743.4769272460937, "Mean Q1": 743.4750498046875, "Mean Q2": 743.476138671875, "critic_loss": 9.299016284942628, "batch_reward": 6.198932106018066, "actor_loss": -743.6794738769531, "actor_target_entropy": -1.0, "actor_entropy": -0.38541369476626, "alpha_loss": -0.00134679974120621, "alpha_value": 0.13004120490115176, "duration": 172.31729912757874, "step": 98500}
{"episode_reward": 830.8489504123891, "episode": 789.0, "Q1 loss": 4.538590349197388, "Q2 loss": 4.605103010177612, "Mean Target Q": 743.4164990234375, "Mean Q1": 743.419361328125, "Mean Q2": 743.4170625, "critic_loss": 9.143693370819092, "batch_reward": 6.193100646972656, "actor_loss": -743.7628493536087, "actor_target_entropy": -1.0, "actor_entropy": -0.38860750056448434, "alpha_loss": 0.0003522733644035364, "alpha_value": 0.12999148705782992, "duration": 162.39740991592407, "step": 98625}
{"episode_reward": 832.1243529142891, "episode": 790.0, "Q1 loss": 4.8130654296875, "Q2 loss": 4.799405905723572, "Mean Target Q": 743.67970703125, "Mean Q1": 743.6736430664063, "Mean Q2": 743.6742978515625, "critic_loss": 9.612471305847167, "batch_reward": 6.204650974273681, "actor_loss": -744.0100904895413, "actor_target_entropy": -1.0, "actor_entropy": -0.40242629810687036, "alpha_loss": 0.0005736051074739906, "alpha_value": 0.12996850684052458, "duration": 175.39998650550842, "step": 98750}
{"episode_reward": 830.2921432599273, "episode": 791.0, "Q1 loss": 4.830263295173645, "Q2 loss": 4.874491303443909, "Mean Target Q": 743.7647177734375, "Mean Q1": 743.7715844726563, "Mean Q2": 743.7710043945312, "critic_loss": 9.704754541397095, "batch_reward": 6.206339351654052, "actor_loss": -744.2426292782739, "actor_target_entropy": -1.0, "actor_entropy": -0.39263521489642916, "alpha_loss": -0.000822349811815435, "alpha_value": 0.13002718027440127, "duration": 182.64596223831177, "step": 98875}
{"episode_reward": 830.1102775078002, "episode": 792.0, "Q1 loss": 4.785940810203552, "Q2 loss": 4.799300875663757, "Mean Target Q": 743.9504516601562, "Mean Q1": 743.9467973632812, "Mean Q2": 743.9465556640625, "critic_loss": 9.585241687774658, "batch_reward": 6.218710437774658, "actor_loss": -744.255630985383, "actor_target_entropy": -1.0, "actor_entropy": -0.3876139574473904, "alpha_loss": -0.0008896203118286306, "alpha_value": 0.12998926931499075, "duration": 183.9752857685089, "step": 99000}
{"episode_reward": 836.0504373389399, "episode": 793.0, "Q1 loss": 5.099570363998413, "Q2 loss": 5.121002177238465, "Mean Target Q": 743.97930078125, "Mean Q1": 743.9768432617187, "Mean Q2": 743.9775004882813, "critic_loss": 10.220572608947753, "batch_reward": 6.200320644378662, "actor_loss": -744.1556774321057, "actor_target_entropy": -1.0, "actor_entropy": -0.39019311420501224, "alpha_loss": 0.0004987409204385052, "alpha_value": 0.13017899998287483, "duration": 174.57454133033752, "step": 99125}
{"episode_reward": 818.7567379644348, "episode": 794.0, "Q1 loss": 4.388058205604553, "Q2 loss": 4.338568862915039, "Mean Target Q": 743.9821166992188, "Mean Q1": 743.981291015625, "Mean Q2": 743.9812529296875, "critic_loss": 8.726627033233642, "batch_reward": 6.206673301696777, "actor_loss": -744.254898563508, "actor_target_entropy": -1.0, "actor_entropy": -0.3605947547381924, "alpha_loss": -0.0006699801625443563, "alpha_value": 0.13007016534016283, "duration": 183.1839735507965, "step": 99250}
{"episode_reward": 833.8569391147696, "episode": 795.0, "Q1 loss": 5.273372966766358, "Q2 loss": 5.271135635375977, "Mean Target Q": 743.9336884765625, "Mean Q1": 743.9350493164062, "Mean Q2": 743.936759765625, "critic_loss": 10.544508617401123, "batch_reward": 6.191191871643066, "actor_loss": -744.250480530754, "actor_target_entropy": -1.0, "actor_entropy": -0.3847077214528644, "alpha_loss": -0.0003637904467593346, "alpha_value": 0.1300687848409884, "duration": 172.452552318573, "step": 99375}
{"episode_reward": 842.6868034877556, "episode": 796.0, "Q1 loss": 4.499423007965088, "Q2 loss": 4.4218419055938725, "Mean Target Q": 743.9621357421875, "Mean Q1": 743.9612749023438, "Mean Q2": 743.9605888671875, "critic_loss": 8.9212649269104, "batch_reward": 6.195749675750732, "actor_loss": -744.3048430412047, "actor_target_entropy": -1.0, "actor_entropy": -0.37306370562122715, "alpha_loss": -5.9790431424194284e-05, "alpha_value": 0.13020240182703532, "duration": 176.95319151878357, "step": 99500}
{"episode_reward": 843.4299591381848, "episode": 797.0, "Q1 loss": 5.110948720932007, "Q2 loss": 5.1834561653137206, "Mean Target Q": 744.1690952148438, "Mean Q1": 744.165107421875, "Mean Q2": 744.1627734375, "critic_loss": 10.294404857635499, "batch_reward": 6.1965819892883305, "actor_loss": -744.4144364614335, "actor_target_entropy": -1.0, "actor_entropy": -0.390561786908952, "alpha_loss": -0.0032956111198660753, "alpha_value": 0.1304064708132411, "duration": 188.92437481880188, "step": 99625}
{"episode_reward": 840.648120336921, "episode": 798.0, "Q1 loss": 5.088120297431946, "Q2 loss": 5.05225862121582, "Mean Target Q": 744.0589252929688, "Mean Q1": 744.0631909179688, "Mean Q2": 744.0643842773437, "critic_loss": 10.140378913879395, "batch_reward": 6.195195003509522, "actor_loss": -744.3938618321573, "actor_target_entropy": -1.0, "actor_entropy": -0.39014204471342023, "alpha_loss": 0.0003539731297942419, "alpha_value": 0.13049363586987062, "duration": 176.92348408699036, "step": 99750}
{"episode_reward": 832.5421893798466, "episode": 799.0, "Q1 loss": 4.5955386753082275, "Q2 loss": 4.555489120483398, "Mean Target Q": 744.3858168945312, "Mean Q1": 744.3812900390625, "Mean Q2": 744.3806762695312, "critic_loss": 9.151027839660644, "batch_reward": 6.217004276275635, "actor_loss": -744.7466760060144, "actor_target_entropy": -1.0, "actor_entropy": -0.35794492657222443, "alpha_loss": 0.00477839340659095, "alpha_value": 0.1302245345600661, "duration": 178.53259754180908, "step": 99875}
{"episode_reward": 838.5059077920957, "episode": 800.0, "Q1 loss": 4.248325348861756, "Q2 loss": 4.240292919258917, "Mean Target Q": 744.3839514947707, "Mean Q1": 744.3811926072643, "Mean Q2": 744.3790529312625, "critic_loss": 8.48861825466156, "batch_reward": 6.209870680685966, "actor_loss": -744.4303293535786, "actor_target_entropy": -1.0, "actor_entropy": -0.34562246357240983, "alpha_loss": 0.0059780313261604354, "alpha_value": 0.12969449868801744, "step": 99999}
