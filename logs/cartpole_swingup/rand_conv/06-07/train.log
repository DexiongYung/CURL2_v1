{"episode_reward": 0.0, "episode": 1.0, "duration": 25.14352512359619, "step": 125}
{"episode_reward": 188.54858664024, "episode": 2.0, "duration": 0.8313755989074707, "step": 250}
{"episode_reward": 148.42677041475667, "episode": 3.0, "duration": 0.8276231288909912, "step": 375}
{"episode_reward": 96.18193741935099, "episode": 4.0, "duration": 0.8194527626037598, "step": 500}
{"episode_reward": 82.30982819659563, "episode": 5.0, "duration": 0.8239727020263672, "step": 625}
{"episode_reward": 198.98424208864233, "episode": 6.0, "duration": 0.8300650119781494, "step": 750}
{"episode_reward": 159.49821390562659, "episode": 7.0, "duration": 0.825178861618042, "step": 875}
{"episode_reward": 113.95622178975879, "episode": 8.0, "duration": 0.8170726299285889, "step": 1000}
{"episode_reward": 89.62519938559855, "episode": 9.0, "Q1 loss": 1.6067881078720092, "Q2 loss": 1.6120264530181885, "Mean Target Q": 1.9537557435035706, "Mean Q1": 1.9406923220660537, "Mean Q2": 1.9396795985996724, "critic_loss": 3.218814556121826, "batch_reward": 1.0388076300621032, "actor_loss": -1.993122861498878, "actor_target_entropy": -1.0, "actor_entropy": 1.1420312198322444, "alpha_loss": 0.13867213677555795, "alpha_value": 0.09974429773073416, "duration": 172.00980424880981, "step": 1125}
{"episode_reward": 86.84197926489995, "episode": 10.0, "Q1 loss": 1.573589201927185, "Q2 loss": 1.5715419178009034, "Mean Target Q": 2.7801225624084474, "Mean Q1": 2.7749947204589844, "Mean Q2": 2.775720365524292, "critic_loss": 3.145131118774414, "batch_reward": 1.0339581017494202, "actor_loss": -2.8349877172900784, "actor_target_entropy": -1.0, "actor_entropy": 1.2030554875250785, "alpha_loss": 0.16278380347836402, "alpha_value": 0.09908312236240216, "duration": 169.3402853012085, "step": 1250}
{"episode_reward": 156.9322033147151, "episode": 11.0, "Q1 loss": 1.5639129934310914, "Q2 loss": 1.5645007514953613, "Mean Target Q": 3.434422706604004, "Mean Q1": 3.4289182548522947, "Mean Q2": 3.4285309829711914, "critic_loss": 3.1284137363433837, "batch_reward": 1.0577249875068664, "actor_loss": -3.4913933050064814, "actor_target_entropy": -1.0, "actor_entropy": 1.049401288940793, "alpha_loss": 0.15585561593373617, "alpha_value": 0.09845585292676964, "duration": 168.6193025112152, "step": 1375}
{"episode_reward": 112.43513262971511, "episode": 12.0, "Q1 loss": 1.5000298528671265, "Q2 loss": 1.4963361148834229, "Mean Target Q": 3.998740390777588, "Mean Q1": 3.998679119110107, "Mean Q2": 3.99919517326355, "critic_loss": 2.9963659706115724, "batch_reward": 1.0251318030357361, "actor_loss": -4.053646576020025, "actor_target_entropy": -1.0, "actor_entropy": 0.9693753882761924, "alpha_loss": 0.15429117843028037, "alpha_value": 0.09785336072918557, "duration": 183.42788124084473, "step": 1500}
{"episode_reward": 66.8470655724356, "episode": 13.0, "Q1 loss": 1.3818331441879272, "Q2 loss": 1.3804824504852296, "Mean Target Q": 4.498366065979004, "Mean Q1": 4.49483353805542, "Mean Q2": 4.494157028198242, "critic_loss": 2.762315586090088, "batch_reward": 0.9626042466163636, "actor_loss": -4.545799618675595, "actor_target_entropy": -1.0, "actor_entropy": 0.9433403232740978, "alpha_loss": 0.15256137081554957, "alpha_value": 0.09725569899111942, "duration": 184.85473895072937, "step": 1625}
{"episode_reward": 39.598770989439416, "episode": 14.0, "Q1 loss": 1.3359554634094237, "Q2 loss": 1.329456862449646, "Mean Target Q": 5.005255664825439, "Mean Q1": 5.002193248748779, "Mean Q2": 5.002118095397949, "critic_loss": 2.665412322998047, "batch_reward": 0.9247102875709534, "actor_loss": -5.044673712022843, "actor_target_entropy": -1.0, "actor_entropy": 0.9723454656139496, "alpha_loss": 0.15405562111446935, "alpha_value": 0.09665835440154678, "duration": 154.30225920677185, "step": 1750}
{"episode_reward": 51.832482017976794, "episode": 15.0, "Q1 loss": 1.3284524097442627, "Q2 loss": 1.3324204931259156, "Mean Target Q": 5.53137604522705, "Mean Q1": 5.529008869171142, "Mean Q2": 5.529631195068359, "critic_loss": 2.660872899055481, "batch_reward": 0.9211786026954651, "actor_loss": -5.570985619983976, "actor_target_entropy": -1.0, "actor_entropy": 1.0163291352135795, "alpha_loss": 0.15407937836079372, "alpha_value": 0.0960622607063667, "duration": 151.74473190307617, "step": 1875}
{"episode_reward": 167.76464932155397, "episode": 16.0, "Q1 loss": 1.3289224271774291, "Q2 loss": 1.3294217653274536, "Mean Target Q": 6.104666027069092, "Mean Q1": 6.1019846534729005, "Mean Q2": 6.102379108428955, "critic_loss": 2.658344181060791, "batch_reward": 0.9464517159461975, "actor_loss": -6.160629072496968, "actor_target_entropy": -1.0, "actor_entropy": 1.0032354737481763, "alpha_loss": 0.15381374979211437, "alpha_value": 0.0954685887099051, "duration": 151.8635482788086, "step": 2000}
{"episode_reward": 207.02645073323157, "episode": 17.0, "Q1 loss": 1.457855875968933, "Q2 loss": 1.4567937774658204, "Mean Target Q": 6.724858390808105, "Mean Q1": 6.720649707794189, "Mean Q2": 6.720772499084473, "critic_loss": 2.9146496505737303, "batch_reward": 0.9989479355812073, "actor_loss": -6.786142530895415, "actor_target_entropy": -1.0, "actor_entropy": 0.9765340250635904, "alpha_loss": 0.15117941938695453, "alpha_value": 0.09488150096123978, "duration": 152.50060606002808, "step": 2125}
{"episode_reward": 225.04462706365175, "episode": 18.0, "Q1 loss": 1.5099545593261718, "Q2 loss": 1.5099023027420044, "Mean Target Q": 7.321665214538574, "Mean Q1": 7.320441761016846, "Mean Q2": 7.320002830505371, "critic_loss": 3.0198568649291992, "batch_reward": 1.017840726852417, "actor_loss": -7.3560725719698015, "actor_target_entropy": -1.0, "actor_entropy": 0.9450839387793695, "alpha_loss": 0.14480869940692379, "alpha_value": 0.09431320471598222, "duration": 153.8336284160614, "step": 2250}
{"episode_reward": 60.16818627263114, "episode": 19.0, "Q1 loss": 1.469884934425354, "Q2 loss": 1.4696632261276246, "Mean Target Q": 7.8879794540405275, "Mean Q1": 7.886417804718017, "Mean Q2": 7.887017448425293, "critic_loss": 2.939548154830933, "batch_reward": 1.0045227489471436, "actor_loss": -7.944235491374182, "actor_target_entropy": -1.0, "actor_entropy": 0.8507776118460155, "alpha_loss": 0.14461054026134432, "alpha_value": 0.09375856714760099, "duration": 188.2300148010254, "step": 2375}
{"episode_reward": 137.57409515589598, "episode": 20.0, "Q1 loss": 1.409977550506592, "Q2 loss": 1.4114549312591553, "Mean Target Q": 8.454100021362304, "Mean Q1": 8.452198516845703, "Mean Q2": 8.451388973236083, "critic_loss": 2.8214324893951415, "batch_reward": 0.9975338201522828, "actor_loss": -8.511666036421254, "actor_target_entropy": -1.0, "actor_entropy": 0.8512104071917073, "alpha_loss": 0.14243790327060607, "alpha_value": 0.09320852697484856, "duration": 178.30692315101624, "step": 2500}
{"episode_reward": 83.48636495626296, "episode": 21.0, "Q1 loss": 1.4356552267074585, "Q2 loss": 1.4349839878082276, "Mean Target Q": 9.019282119750976, "Mean Q1": 9.020426536560059, "Mean Q2": 9.020605888366699, "critic_loss": 2.870639213562012, "batch_reward": 0.9911303815841674, "actor_loss": -9.083238026452443, "actor_target_entropy": -1.0, "actor_entropy": 0.7866166560422807, "alpha_loss": 0.1385146171327621, "alpha_value": 0.09266916888556465, "duration": 171.05531072616577, "step": 2625}
{"episode_reward": 215.4569630259482, "episode": 22.0, "Q1 loss": 1.5168145971298217, "Q2 loss": 1.5165368041992187, "Mean Target Q": 9.615375061035156, "Mean Q1": 9.608499847412109, "Mean Q2": 9.60880990600586, "critic_loss": 3.0333513946533204, "batch_reward": 1.0041171360015868, "actor_loss": -9.658797525590465, "actor_target_entropy": -1.0, "actor_entropy": 0.8184367980687849, "alpha_loss": 0.14045944329231017, "alpha_value": 0.09213633528658792, "duration": 179.5332169532776, "step": 2750}
{"episode_reward": 76.42496265789023, "episode": 23.0, "Q1 loss": 1.487468710899353, "Q2 loss": 1.4858044538497925, "Mean Target Q": 10.179383491516113, "Mean Q1": 10.178802658081056, "Mean Q2": 10.178727058410644, "critic_loss": 2.973273166656494, "batch_reward": 0.9974735250473022, "actor_loss": -10.230605897449312, "actor_target_entropy": -1.0, "actor_entropy": 0.8910009014228034, "alpha_loss": 0.14042897971849594, "alpha_value": 0.09159082618466002, "duration": 173.19263577461243, "step": 2875}
{"episode_reward": 112.39600495507997, "episode": 24.0, "Q1 loss": 1.4604228963851928, "Q2 loss": 1.459564995765686, "Mean Target Q": 10.75471427154541, "Mean Q1": 10.752762763977051, "Mean Q2": 10.75227116394043, "critic_loss": 2.919987897872925, "batch_reward": 0.9928459453582764, "actor_loss": -10.809035885718561, "actor_target_entropy": -1.0, "actor_entropy": 0.8256663391667027, "alpha_loss": 0.1407007115983194, "alpha_value": 0.09105194434490736, "duration": 174.35744190216064, "step": 3000}
{"episode_reward": 97.79146460688438, "episode": 25.0, "Q1 loss": 1.415936511039734, "Q2 loss": 1.4170989971160888, "Mean Target Q": 11.323025314331055, "Mean Q1": 11.32330054473877, "Mean Q2": 11.32351136779785, "critic_loss": 2.833035503387451, "batch_reward": 0.9890094904899597, "actor_loss": -11.375887613447885, "actor_target_entropy": -1.0, "actor_entropy": 0.896886772579617, "alpha_loss": 0.14254370450027407, "alpha_value": 0.09050554698526585, "duration": 174.8217794895172, "step": 3125}
{"episode_reward": 99.15700498467709, "episode": 26.0, "Q1 loss": 1.4099431686401367, "Q2 loss": 1.4084884767532349, "Mean Target Q": 11.880736450195313, "Mean Q1": 11.879454086303712, "Mean Q2": 11.879248680114745, "critic_loss": 2.818431657791138, "batch_reward": 0.979796992301941, "actor_loss": -11.931709197259718, "actor_target_entropy": -1.0, "actor_entropy": 0.8472153150266216, "alpha_loss": 0.13928851893832606, "alpha_value": 0.08996412494352823, "duration": 151.85268902778625, "step": 3250}
{"episode_reward": 79.36565331667819, "episode": 27.0, "Q1 loss": 1.3763555755615235, "Q2 loss": 1.3734036617279053, "Mean Target Q": 12.41776106262207, "Mean Q1": 12.416182823181153, "Mean Q2": 12.417074729919433, "critic_loss": 2.7497592391967776, "batch_reward": 0.9628257541656494, "actor_loss": -12.460952622549874, "actor_target_entropy": -1.0, "actor_entropy": 0.9041557491771759, "alpha_loss": 0.14009793989715122, "alpha_value": 0.08943292820814487, "duration": 152.81251049041748, "step": 3375}
{"episode_reward": 88.45595668789782, "episode": 28.0, "Q1 loss": 1.358622890472412, "Q2 loss": 1.362228307723999, "Mean Target Q": 12.958029792785645, "Mean Q1": 12.957135452270508, "Mean Q2": 12.956703376770019, "critic_loss": 2.720851194381714, "batch_reward": 0.9590270280838012, "actor_loss": -13.004623090067218, "actor_target_entropy": -1.0, "actor_entropy": 0.918281061995414, "alpha_loss": 0.13996606969064282, "alpha_value": 0.08889649867342643, "duration": 176.03571963310242, "step": 3500}
{"episode_reward": 90.04626899091151, "episode": 29.0, "Q1 loss": 1.3332905702590943, "Q2 loss": 1.3325249304771423, "Mean Target Q": 13.480457237243652, "Mean Q1": 13.476446327209473, "Mean Q2": 13.4766231842041, "critic_loss": 2.6658155059814455, "batch_reward": 0.9486771969795227, "actor_loss": -13.529963251144167, "actor_target_entropy": -1.0, "actor_entropy": 0.9427638385030959, "alpha_loss": 0.13923881037367714, "alpha_value": 0.0883623817550231, "duration": 160.55404233932495, "step": 3625}
{"episode_reward": 156.6946486968238, "episode": 30.0, "Q1 loss": 1.3668484406471253, "Q2 loss": 1.367972490310669, "Mean Target Q": 14.022211990356446, "Mean Q1": 14.021186630249023, "Mean Q2": 14.020949516296387, "critic_loss": 2.7348209276199342, "batch_reward": 0.9589495301246643, "actor_loss": -14.062953456755608, "actor_target_entropy": -1.0, "actor_entropy": 0.875234164537922, "alpha_loss": 0.13610328890142903, "alpha_value": 0.08783953781088874, "duration": 168.99631524085999, "step": 3750}
{"episode_reward": 87.52460568206176, "episode": 31.0, "Q1 loss": 1.3053752584457397, "Q2 loss": 1.3024133043289186, "Mean Target Q": 14.533888397216797, "Mean Q1": 14.53353987121582, "Mean Q2": 14.533972679138184, "critic_loss": 2.6077885665893556, "batch_reward": 0.942094600200653, "actor_loss": -14.585039350721571, "actor_target_entropy": -1.0, "actor_entropy": 0.8416748728070941, "alpha_loss": 0.13576558208654796, "alpha_value": 0.08732527660651664, "duration": 172.8215696811676, "step": 3875}
{"episode_reward": 71.83333218715293, "episode": 32.0, "Q1 loss": 1.3529801301956177, "Q2 loss": 1.3528280096054077, "Mean Target Q": 15.064202438354492, "Mean Q1": 15.063247215270996, "Mean Q2": 15.063383697509765, "critic_loss": 2.705808141708374, "batch_reward": 0.9532656021118164, "actor_loss": -15.110564185727027, "actor_target_entropy": -1.0, "actor_entropy": 0.8691240078018557, "alpha_loss": 0.13482213080410035, "alpha_value": 0.08681225795523188, "duration": 185.5088086128235, "step": 4000}
{"episode_reward": 162.15042273631684, "episode": 33.0, "Q1 loss": 1.354639506340027, "Q2 loss": 1.353317976951599, "Mean Target Q": 15.592716522216797, "Mean Q1": 15.59144612121582, "Mean Q2": 15.591274742126465, "critic_loss": 2.7079574890136717, "batch_reward": 0.9487012763023377, "actor_loss": -15.62803474305168, "actor_target_entropy": -1.0, "actor_entropy": 0.885337023507981, "alpha_loss": 0.13558969599387002, "alpha_value": 0.08629866579936359, "duration": 176.28301239013672, "step": 4125}
{"episode_reward": 131.27863595893916, "episode": 34.0, "Q1 loss": 1.3420038261413574, "Q2 loss": 1.3422867364883422, "Mean Target Q": 16.104824699401856, "Mean Q1": 16.101290924072266, "Mean Q2": 16.101007438659668, "critic_loss": 2.6842905673980715, "batch_reward": 0.9478884015083313, "actor_loss": -16.148418549568422, "actor_target_entropy": -1.0, "actor_entropy": 0.8681977549868245, "alpha_loss": 0.13341614748201064, "alpha_value": 0.0857958163004951, "duration": 179.0644359588623, "step": 4250}
{"episode_reward": 63.57050516910347, "episode": 35.0, "Q1 loss": 1.3227495813369752, "Q2 loss": 1.322458948135376, "Mean Target Q": 16.61308039855957, "Mean Q1": 16.61390756225586, "Mean Q2": 16.614219894409178, "critic_loss": 2.645208520889282, "batch_reward": 0.9420690159797669, "actor_loss": -16.659966726151723, "actor_target_entropy": -1.0, "actor_entropy": 0.8468667713422624, "alpha_loss": 0.13242454945095003, "alpha_value": 0.08529141090206604, "duration": 171.6012442111969, "step": 4375}
{"episode_reward": 158.9674329348074, "episode": 36.0, "Q1 loss": 1.3464462327957154, "Q2 loss": 1.3468438787460326, "Mean Target Q": 17.08868553161621, "Mean Q1": 17.085781631469725, "Mean Q2": 17.085297744750978, "critic_loss": 2.693290114402771, "batch_reward": 0.9367807593345642, "actor_loss": -17.123926039664976, "actor_target_entropy": -1.0, "actor_entropy": 0.8607406222051189, "alpha_loss": 0.13214691716336435, "alpha_value": 0.08479312348528088, "duration": 176.7995457649231, "step": 4500}
{"episode_reward": 41.43189263827025, "episode": 37.0, "Q1 loss": 1.332055814743042, "Q2 loss": 1.3371451568603516, "Mean Target Q": 17.44136734008789, "Mean Q1": 17.44003500366211, "Mean Q2": 17.43961032104492, "critic_loss": 2.6692009716033938, "batch_reward": 0.9333591051101685, "actor_loss": -17.47844135950482, "actor_target_entropy": -1.0, "actor_entropy": 0.8983421883885823, "alpha_loss": 0.1333585185190988, "alpha_value": 0.08429200056120766, "duration": 179.85881924629211, "step": 4625}
{"episode_reward": 58.30938155748778, "episode": 38.0, "Q1 loss": 1.3648373317718505, "Q2 loss": 1.369340636253357, "Mean Target Q": 17.48753207397461, "Mean Q1": 17.485162338256835, "Mean Q2": 17.485979232788086, "critic_loss": 2.7341779556274415, "batch_reward": 0.9115895419120789, "actor_loss": -17.527747861800655, "actor_target_entropy": -1.0, "actor_entropy": 0.8788088829286637, "alpha_loss": 0.1312424395113222, "alpha_value": 0.08379461227685503, "duration": 168.01562929153442, "step": 4750}
{"episode_reward": 75.24384864738191, "episode": 39.0, "Q1 loss": 1.4535504903793335, "Q2 loss": 1.4538274173736572, "Mean Target Q": 17.199432006835938, "Mean Q1": 17.202336639404297, "Mean Q2": 17.201597091674806, "critic_loss": 2.907377902984619, "batch_reward": 0.9054572148323059, "actor_loss": -17.242161220974392, "actor_target_entropy": -1.0, "actor_entropy": 0.9402496663350908, "alpha_loss": 0.13042960990042912, "alpha_value": 0.08330592759848993, "duration": 183.2368574142456, "step": 4875}
{"episode_reward": 101.28610942241876, "episode": 40.0, "Q1 loss": 1.6034335765838623, "Q2 loss": 1.5995853986740112, "Mean Target Q": 17.04253993225098, "Mean Q1": 17.038223175048827, "Mean Q2": 17.03886373901367, "critic_loss": 3.2030189685821533, "batch_reward": 0.8973743920326233, "actor_loss": -17.084856094852572, "actor_target_entropy": -1.0, "actor_entropy": 0.9125271093460822, "alpha_loss": 0.13116928009736922, "alpha_value": 0.08281520992920453, "step": 5000}
{"duration": 200.64753079414368, "step": 5000}
{"episode_reward": 98.43451671858571, "episode": 41.0, "Q1 loss": 1.8595325641632081, "Q2 loss": 1.856287398338318, "Mean Target Q": 17.421830490112306, "Mean Q1": 17.42156199645996, "Mean Q2": 17.421439590454103, "critic_loss": 3.715819969177246, "batch_reward": 0.9024336924552917, "actor_loss": -17.41287407042488, "actor_target_entropy": -1.0, "actor_entropy": 0.8987685820413014, "alpha_loss": 0.12914252115620506, "alpha_value": 0.08232854871030175, "duration": 182.24385786056519, "step": 5125}
{"episode_reward": 110.61981540270928, "episode": 42.0, "Q1 loss": 2.2768621587753297, "Q2 loss": 2.2779816646575926, "Mean Target Q": 18.1341619720459, "Mean Q1": 18.133361907958985, "Mean Q2": 18.132825241088867, "critic_loss": 4.554843812942505, "batch_reward": 0.9014093146324158, "actor_loss": -18.1562256351594, "actor_target_entropy": -1.0, "actor_entropy": 0.897616034553897, "alpha_loss": 0.12725882136052655, "alpha_value": 0.08185462475708774, "duration": 178.80236339569092, "step": 5250}
{"episode_reward": 99.80519888842792, "episode": 43.0, "Q1 loss": 2.687424518585205, "Q2 loss": 2.6853099822998048, "Mean Target Q": 18.702247833251953, "Mean Q1": 18.695485244750977, "Mean Q2": 18.695997100830077, "critic_loss": 5.372734500885009, "batch_reward": 0.9027175235748292, "actor_loss": -18.72221435062469, "actor_target_entropy": -1.0, "actor_entropy": 0.9295645772464691, "alpha_loss": 0.12701074400591472, "alpha_value": 0.08137643577393944, "duration": 153.55618143081665, "step": 5375}
{"episode_reward": 65.37150685882563, "episode": 44.0, "Q1 loss": 3.16684769821167, "Q2 loss": 3.16164626121521, "Mean Target Q": 19.11582179260254, "Mean Q1": 19.110072967529298, "Mean Q2": 19.10952439880371, "critic_loss": 6.328493968963623, "batch_reward": 0.9051929612159729, "actor_loss": -19.066846878297866, "actor_target_entropy": -1.0, "actor_entropy": 0.98882592685761, "alpha_loss": 0.12551035119160528, "alpha_value": 0.08090789416857815, "duration": 171.78329801559448, "step": 5500}
{"episode_reward": 155.12340259332373, "episode": 45.0, "Q1 loss": 3.5184867248535157, "Q2 loss": 3.511070474624634, "Mean Target Q": 19.3643683013916, "Mean Q1": 19.3658856048584, "Mean Q2": 19.366297317504884, "critic_loss": 7.029557189941406, "batch_reward": 0.8991113200187683, "actor_loss": -19.367809870886425, "actor_target_entropy": -1.0, "actor_entropy": 0.9889177755704002, "alpha_loss": 0.12065707076163519, "alpha_value": 0.08045195700076639, "duration": 182.75606036186218, "step": 5625}
{"episode_reward": 140.85626527458544, "episode": 46.0, "Q1 loss": 3.6984379653930666, "Q2 loss": 3.6940297870635987, "Mean Target Q": 19.74438719177246, "Mean Q1": 19.73792738342285, "Mean Q2": 19.738462463378905, "critic_loss": 7.392467739105225, "batch_reward": 0.8991877956390381, "actor_loss": -19.723286874832645, "actor_target_entropy": -1.0, "actor_entropy": 0.944496694111055, "alpha_loss": 0.11712286236786074, "alpha_value": 0.08000442807233928, "duration": 174.48795104026794, "step": 5750}
{"episode_reward": 119.86864210576816, "episode": 47.0, "Q1 loss": 4.068167797088623, "Q2 loss": 4.067379373550415, "Mean Target Q": 20.088339981079102, "Mean Q1": 20.087498107910157, "Mean Q2": 20.087402297973632, "critic_loss": 8.135547161102295, "batch_reward": 0.9072719144821167, "actor_loss": -20.114851603432307, "actor_target_entropy": -1.0, "actor_entropy": 0.8956371716090611, "alpha_loss": 0.11228500223822063, "alpha_value": 0.07957797527220217, "duration": 172.7688536643982, "step": 5875}
{"episode_reward": 89.67200511273802, "episode": 48.0, "Q1 loss": 4.304241676330566, "Q2 loss": 4.298521869659424, "Mean Target Q": 20.395665405273437, "Mean Q1": 20.39611785888672, "Mean Q2": 20.396458084106445, "critic_loss": 8.602763523101807, "batch_reward": 0.9086314015388489, "actor_loss": -20.387050597898423, "actor_target_entropy": -1.0, "actor_entropy": 0.8729032028105951, "alpha_loss": 0.1087805720106248, "alpha_value": 0.0791626113322031, "duration": 180.27153372764587, "step": 6000}
{"episode_reward": 147.3578922310577, "episode": 49.0, "Q1 loss": 4.610378561019897, "Q2 loss": 4.603719614028931, "Mean Target Q": 20.791944198608398, "Mean Q1": 20.788647689819335, "Mean Q2": 20.788917755126953, "critic_loss": 9.214098148345947, "batch_reward": 0.9197359218597412, "actor_loss": -20.80791558159722, "actor_target_entropy": -1.0, "actor_entropy": 0.7888771683450729, "alpha_loss": 0.1034006392435422, "alpha_value": 0.07876232497398701, "duration": 175.096506357193, "step": 6125}
{"episode_reward": 265.82239559018734, "episode": 50.0, "Q1 loss": 4.9862687816619875, "Q2 loss": 4.989722942352295, "Mean Target Q": 21.267664581298828, "Mean Q1": 21.266825286865235, "Mean Q2": 21.26618019104004, "critic_loss": 9.975991744995117, "batch_reward": 0.9418565139770508, "actor_loss": -21.307000960073164, "actor_target_entropy": -1.0, "actor_entropy": 0.7763684882271674, "alpha_loss": 0.09799030302993712, "alpha_value": 0.0783808034682815, "duration": 179.04841208457947, "step": 6250}
{"episode_reward": 227.54360375268163, "episode": 51.0, "Q1 loss": 5.338074274063111, "Q2 loss": 5.321904859542847, "Mean Target Q": 21.58826544189453, "Mean Q1": 21.589049377441405, "Mean Q2": 21.58931736755371, "critic_loss": 10.65997915649414, "batch_reward": 0.9490589318275452, "actor_loss": -21.595661617460706, "actor_target_entropy": -1.0, "actor_entropy": 0.7599898444281684, "alpha_loss": 0.09705668013720285, "alpha_value": 0.07800338163713535, "duration": 169.14002919197083, "step": 6375}
{"episode_reward": 121.65000866714223, "episode": 52.0, "Q1 loss": 5.726773960113525, "Q2 loss": 5.724828289031983, "Mean Target Q": 21.999536285400392, "Mean Q1": 21.998165679931642, "Mean Q2": 21.99857241821289, "critic_loss": 11.451602249145507, "batch_reward": 0.9540275192260742, "actor_loss": -22.061123355742424, "actor_target_entropy": -1.0, "actor_entropy": 0.6101361989013611, "alpha_loss": 0.09407082860988955, "alpha_value": 0.07763385200984775, "duration": 174.57881498336792, "step": 6500}
{"episode_reward": 250.63937762996545, "episode": 53.0, "Q1 loss": 6.395063899993897, "Q2 loss": 6.381231281280518, "Mean Target Q": 22.40581201171875, "Mean Q1": 22.406545684814454, "Mean Q2": 22.40620506286621, "critic_loss": 12.77629518890381, "batch_reward": 0.9798459806442261, "actor_loss": -22.496904978676447, "actor_target_entropy": -1.0, "actor_entropy": 0.641953552526141, "alpha_loss": 0.08848808670327776, "alpha_value": 0.07727600112268043, "duration": 189.72259831428528, "step": 6625}
{"episode_reward": 172.77642977366762, "episode": 54.0, "Q1 loss": 6.9120917358398435, "Q2 loss": 6.912206962585449, "Mean Target Q": 22.782115631103515, "Mean Q1": 22.780209350585938, "Mean Q2": 22.780255325317384, "critic_loss": 13.824298683166504, "batch_reward": 0.9708892846107483, "actor_loss": -22.923671014847294, "actor_target_entropy": -1.0, "actor_entropy": 0.5790846424718057, "alpha_loss": 0.07822575852755577, "alpha_value": 0.07694619466416956, "duration": 172.21244597434998, "step": 6750}
{"episode_reward": 10.329601147485773, "episode": 55.0, "Q1 loss": 7.645527435302735, "Q2 loss": 7.627900829315186, "Mean Target Q": 23.18107258605957, "Mean Q1": 23.177049224853516, "Mean Q2": 23.178304794311522, "critic_loss": 15.273428260803223, "batch_reward": 0.9801537432670593, "actor_loss": -23.30496715364002, "actor_target_entropy": -1.0, "actor_entropy": 0.6251029523592146, "alpha_loss": 0.07419138117915108, "alpha_value": 0.07663953745882261, "duration": 192.1720952987671, "step": 6875}
{"episode_reward": 217.06347768240155, "episode": 56.0, "Q1 loss": 8.180044075012207, "Q2 loss": 8.172637977600097, "Mean Target Q": 23.660614379882812, "Mean Q1": 23.659165573120116, "Mean Q2": 23.660333862304686, "critic_loss": 16.352682014465334, "batch_reward": 0.9683726706504822, "actor_loss": -23.803064838532478, "actor_target_entropy": -1.0, "actor_entropy": 0.5820990709527847, "alpha_loss": 0.06621049777153999, "alpha_value": 0.07635483046350204, "duration": 169.33484935760498, "step": 7000}
{"episode_reward": 32.0557471452955, "episode": 57.0, "Q1 loss": 8.55948617553711, "Q2 loss": 8.572491546630859, "Mean Target Q": 24.110210983276367, "Mean Q1": 24.114934036254883, "Mean Q2": 24.1156330871582, "critic_loss": 17.131977699279783, "batch_reward": 0.9645601468086242, "actor_loss": -24.29788099016462, "actor_target_entropy": -1.0, "actor_entropy": 0.47664896836356513, "alpha_loss": 0.05742746106688938, "alpha_value": 0.07609536501220539, "duration": 171.88068437576294, "step": 7125}
{"episode_reward": 120.17651908655073, "episode": 58.0, "Q1 loss": 9.152006069183349, "Q2 loss": 9.146074565887451, "Mean Target Q": 24.666046951293946, "Mean Q1": 24.663683242797852, "Mean Q2": 24.66457308959961, "critic_loss": 18.2980806350708, "batch_reward": 0.9640961890220642, "actor_loss": -24.87430123359926, "actor_target_entropy": -1.0, "actor_entropy": 0.4093224216372736, "alpha_loss": 0.05681385472416878, "alpha_value": 0.07585109848531699, "duration": 163.99437260627747, "step": 7250}
{"episode_reward": 16.675811223340304, "episode": 59.0, "Q1 loss": 10.204402603149415, "Q2 loss": 10.204919242858887, "Mean Target Q": 25.188981903076172, "Mean Q1": 25.18397201538086, "Mean Q2": 25.185903533935548, "critic_loss": 20.409321823120116, "batch_reward": 0.954205855846405, "actor_loss": -25.480775590926882, "actor_target_entropy": -1.0, "actor_entropy": 0.3673949245186079, "alpha_loss": 0.04569724571728517, "alpha_value": 0.07563186018055565, "duration": 164.43557119369507, "step": 7375}
{"episode_reward": 130.6062228595727, "episode": 60.0, "Q1 loss": 10.264822284698486, "Q2 loss": 10.28423518371582, "Mean Target Q": 25.74311015319824, "Mean Q1": 25.744762969970704, "Mean Q2": 25.74482940673828, "critic_loss": 20.549057479858398, "batch_reward": 0.9462020163536071, "actor_loss": -26.035604323110274, "actor_target_entropy": -1.0, "actor_entropy": 0.3956744666061094, "alpha_loss": 0.04452754572154053, "alpha_value": 0.07543516746613595, "duration": 169.44556164741516, "step": 7500}
{"episode_reward": 62.0084514395136, "episode": 61.0, "Q1 loss": 10.866186492919923, "Q2 loss": 10.858473487854004, "Mean Target Q": 26.288557159423828, "Mean Q1": 26.28004315185547, "Mean Q2": 26.28155027770996, "critic_loss": 21.724660110473632, "batch_reward": 0.9378764019012451, "actor_loss": -26.628660837809246, "actor_target_entropy": -1.0, "actor_entropy": 0.33162363796007066, "alpha_loss": 0.03694129614011636, "alpha_value": 0.07524285232420687, "duration": 172.30751276016235, "step": 7625}
{"episode_reward": 149.3159021001736, "episode": 62.0, "Q1 loss": 12.057194213867188, "Q2 loss": 12.048813362121582, "Mean Target Q": 26.913525222778322, "Mean Q1": 26.90983186340332, "Mean Q2": 26.910075607299806, "critic_loss": 24.10600756072998, "batch_reward": 0.950325089931488, "actor_loss": -27.25528895470404, "actor_target_entropy": -1.0, "actor_entropy": 0.3703916160570037, "alpha_loss": 0.03421068092763063, "alpha_value": 0.07508608244076423, "duration": 175.46690821647644, "step": 7750}
{"episode_reward": 177.39980070726904, "episode": 63.0, "Q1 loss": 11.817120193481445, "Q2 loss": 11.801662651062012, "Mean Target Q": 27.966414352416994, "Mean Q1": 27.963803283691405, "Mean Q2": 27.963714050292968, "critic_loss": 23.61878286743164, "batch_reward": 0.9598633732795715, "actor_loss": -28.294433987329878, "actor_target_entropy": -1.0, "actor_entropy": 0.2574156279720011, "alpha_loss": 0.03255209019998946, "alpha_value": 0.07491665890250782, "duration": 174.5577187538147, "step": 7875}
{"episode_reward": 87.55773753344536, "episode": 64.0, "Q1 loss": 12.296542808532715, "Q2 loss": 12.308757495880126, "Mean Target Q": 28.574403442382813, "Mean Q1": 28.56598162841797, "Mean Q2": 28.56709342956543, "critic_loss": 24.60530032348633, "batch_reward": 0.9539924283027649, "actor_loss": -29.025177555699504, "actor_target_entropy": -1.0, "actor_entropy": 0.25812074493977333, "alpha_loss": 0.026948561261017478, "alpha_value": 0.07477148144164095, "duration": 166.9652726650238, "step": 8000}
{"episode_reward": 184.11527574231064, "episode": 65.0, "Q1 loss": 13.781886322021485, "Q2 loss": 13.776688842773437, "Mean Target Q": 29.26999530029297, "Mean Q1": 29.265909133911133, "Mean Q2": 29.265080749511718, "critic_loss": 27.558575134277344, "batch_reward": 0.9668817019462586, "actor_loss": -29.662529021974596, "actor_target_entropy": -1.0, "actor_entropy": 0.11958609766785115, "alpha_loss": 0.02200545588996084, "alpha_value": 0.07464667068087608, "duration": 170.707754611969, "step": 8125}
{"episode_reward": 116.17206947168862, "episode": 66.0, "Q1 loss": 13.174093513488769, "Q2 loss": 13.14741421508789, "Mean Target Q": 29.929049560546876, "Mean Q1": 29.919910263061524, "Mean Q2": 29.921401321411132, "critic_loss": 26.321507614135744, "batch_reward": 0.9625938930511475, "actor_loss": -30.37129851310484, "actor_target_entropy": -1.0, "actor_entropy": 0.08623374250507163, "alpha_loss": 0.018768764155421166, "alpha_value": 0.07454211202088327, "duration": 168.1291446685791, "step": 8250}
{"episode_reward": 163.16971161442677, "episode": 67.0, "Q1 loss": 13.9560419921875, "Q2 loss": 13.940748497009277, "Mean Target Q": 30.767793838500978, "Mean Q1": 30.761783401489257, "Mean Q2": 30.761896118164064, "critic_loss": 27.896790481567383, "batch_reward": 0.9637521109580993, "actor_loss": -31.16793093605647, "actor_target_entropy": -1.0, "actor_entropy": -0.007675948183214854, "alpha_loss": 0.007942332120220517, "alpha_value": 0.07447725947483481, "duration": 183.4750018119812, "step": 8375}
{"episode_reward": 61.32000168425813, "episode": 68.0, "Q1 loss": 14.51108349609375, "Q2 loss": 14.483130912780762, "Mean Target Q": 31.591996719360353, "Mean Q1": 31.585684967041015, "Mean Q2": 31.58585954284668, "critic_loss": 28.99421435546875, "batch_reward": 0.9597380609512329, "actor_loss": -32.00791509689823, "actor_target_entropy": -1.0, "actor_entropy": -0.14597440619141824, "alpha_loss": -0.0029418434001385204, "alpha_value": 0.07445700756831934, "duration": 166.03634595870972, "step": 8500}
{"episode_reward": 56.04327668567542, "episode": 69.0, "Q1 loss": 14.537825721740722, "Q2 loss": 14.494568328857422, "Mean Target Q": 32.26388185119629, "Mean Q1": 32.262824157714846, "Mean Q2": 32.26250082397461, "critic_loss": 29.03239405822754, "batch_reward": 0.9500635952949524, "actor_loss": -32.77384222121466, "actor_target_entropy": -1.0, "actor_entropy": -0.0704066182767588, "alpha_loss": 0.006075268735118684, "alpha_value": 0.07445301883962208, "duration": 175.536146402359, "step": 8625}
{"episode_reward": 109.71841269332161, "episode": 70.0, "Q1 loss": 13.92955492401123, "Q2 loss": 13.886500633239747, "Mean Target Q": 33.01815446472168, "Mean Q1": 33.01194734191895, "Mean Q2": 33.01150312805176, "critic_loss": 27.816055603027344, "batch_reward": 0.9562492599487304, "actor_loss": -33.41061776684177, "actor_target_entropy": -1.0, "actor_entropy": -0.09674926530269365, "alpha_loss": 0.0032427358138750516, "alpha_value": 0.07440931588404788, "duration": 169.59935021400452, "step": 8750}
{"episode_reward": 130.2162354707569, "episode": 71.0, "Q1 loss": 14.282389854431152, "Q2 loss": 14.272955795288086, "Mean Target Q": 33.7938530883789, "Mean Q1": 33.78785343933105, "Mean Q2": 33.78776722717285, "critic_loss": 28.55534565734863, "batch_reward": 0.959111023902893, "actor_loss": -34.328008621458025, "actor_target_entropy": -1.0, "actor_entropy": -0.11939839949269616, "alpha_loss": -0.002065744360960606, "alpha_value": 0.07441472874154828, "duration": 163.33930611610413, "step": 8875}
{"episode_reward": 124.44845926183181, "episode": 72.0, "Q1 loss": 15.000784477233887, "Q2 loss": 14.969956642150878, "Mean Target Q": 34.37755456542969, "Mean Q1": 34.37374243164062, "Mean Q2": 34.372650207519534, "critic_loss": 29.970741073608398, "batch_reward": 0.9592268500328064, "actor_loss": -34.8268911300167, "actor_target_entropy": -1.0, "actor_entropy": 0.02434469759464264, "alpha_loss": 0.005740089375796097, "alpha_value": 0.07440901623212275, "duration": 161.05204510688782, "step": 9000}
{"episode_reward": 94.26622638002922, "episode": 73.0, "Q1 loss": 15.25319132232666, "Q2 loss": 15.296208511352539, "Mean Target Q": 35.29561981201172, "Mean Q1": 35.29175375366211, "Mean Q2": 35.29384603881836, "critic_loss": 30.549399658203125, "batch_reward": 0.944159140586853, "actor_loss": -35.90323735797216, "actor_target_entropy": -1.0, "actor_entropy": -0.01140104178043585, "alpha_loss": -0.0005050184166369339, "alpha_value": 0.07438723470695009, "duration": 164.99906134605408, "step": 9125}
{"episode_reward": 84.70886646273738, "episode": 74.0, "Q1 loss": 13.525608604431152, "Q2 loss": 13.487251564025879, "Mean Target Q": 36.08158721923828, "Mean Q1": 36.08031903076172, "Mean Q2": 36.07950408935547, "critic_loss": 27.012860305786134, "batch_reward": 0.9350971755981445, "actor_loss": -36.77375344307192, "actor_target_entropy": -1.0, "actor_entropy": -0.06205438305774043, "alpha_loss": -0.007895980599231177, "alpha_value": 0.07441759730807945, "duration": 174.99653792381287, "step": 9250}
{"episode_reward": 74.96146872958393, "episode": 75.0, "Q1 loss": 14.04290965270996, "Q2 loss": 14.067883895874024, "Mean Target Q": 36.816723022460934, "Mean Q1": 36.808689666748045, "Mean Q2": 36.807175659179684, "critic_loss": 28.110793594360352, "batch_reward": 0.9318791174888611, "actor_loss": -37.54481839376783, "actor_target_entropy": -1.0, "actor_entropy": -0.04907539099573143, "alpha_loss": -0.010308866006588297, "alpha_value": 0.07447210180480585, "duration": 174.4457585811615, "step": 9375}
{"episode_reward": 56.20998365855843, "episode": 76.0, "Q1 loss": 14.264192436218261, "Q2 loss": 14.314381431579589, "Mean Target Q": 37.77536413574219, "Mean Q1": 37.7752619934082, "Mean Q2": 37.776242889404294, "critic_loss": 28.57857392883301, "batch_reward": 0.9410217428207397, "actor_loss": -38.494933774394376, "actor_target_entropy": -1.0, "actor_entropy": -0.2123119702803031, "alpha_loss": -0.01969012303367978, "alpha_value": 0.07456999741794397, "duration": 174.1515130996704, "step": 9500}
{"episode_reward": 106.37395127585701, "episode": 77.0, "Q1 loss": 13.917720687866211, "Q2 loss": 13.928148727416993, "Mean Target Q": 38.52397256469727, "Mean Q1": 38.51753518676758, "Mean Q2": 38.51818154907227, "critic_loss": 27.845869354248048, "batch_reward": 0.9257516579627991, "actor_loss": -39.34928803216843, "actor_target_entropy": -1.0, "actor_entropy": -0.21950962809136226, "alpha_loss": -0.026238475430993332, "alpha_value": 0.07474312027529108, "duration": 175.37157320976257, "step": 9625}
{"episode_reward": 79.05700894211017, "episode": 78.0, "Q1 loss": 14.546720397949219, "Q2 loss": 14.562439376831055, "Mean Target Q": 39.231302001953125, "Mean Q1": 39.21921551513672, "Mean Q2": 39.21840542602539, "critic_loss": 29.109159698486327, "batch_reward": 0.9304341211318969, "actor_loss": -40.00500808223601, "actor_target_entropy": -1.0, "actor_entropy": -0.10830563073977828, "alpha_loss": -0.02263263314061107, "alpha_value": 0.07493600727083158, "duration": 177.11049127578735, "step": 9750}
{"episode_reward": 76.01632986606167, "episode": 79.0, "Q1 loss": 15.065533615112304, "Q2 loss": 15.11087969970703, "Mean Target Q": 40.12558062744141, "Mean Q1": 40.13058361816406, "Mean Q2": 40.1308772277832, "critic_loss": 30.176413299560547, "batch_reward": 0.934386969089508, "actor_loss": -40.90398643130348, "actor_target_entropy": -1.0, "actor_entropy": -0.1082695818816622, "alpha_loss": -0.01649279437870497, "alpha_value": 0.07509204048527632, "duration": 176.07926201820374, "step": 9875}
{"episode_reward": 150.91818103219217, "episode": 80.0, "Q1 loss": 15.282755592346192, "Q2 loss": 15.393227828979493, "Mean Target Q": 41.15332876586914, "Mean Q1": 41.14690106201172, "Mean Q2": 41.14553280639648, "critic_loss": 30.67598358154297, "batch_reward": 0.9232040376663208, "actor_loss": -41.89811989568895, "actor_target_entropy": -1.0, "actor_entropy": -0.09655249168375327, "alpha_loss": -0.022723588634342436, "alpha_value": 0.07522998002564753, "step": 10000}
{"duration": 186.47582054138184, "step": 10000}
{"episode_reward": 83.45156175553798, "episode": 81.0, "Q1 loss": 15.165767967224122, "Q2 loss": 15.261818656921387, "Mean Target Q": 42.006243225097656, "Mean Q1": 42.00251254272461, "Mean Q2": 42.00306616210938, "critic_loss": 30.427586685180664, "batch_reward": 0.9339030346870423, "actor_loss": -42.89629158141121, "actor_target_entropy": -1.0, "actor_entropy": -0.18210443496585837, "alpha_loss": -0.031059432597387405, "alpha_value": 0.07545609333985917, "duration": 169.14590001106262, "step": 10125}
{"episode_reward": 87.39351745925043, "episode": 82.0, "Q1 loss": 16.327906967163084, "Q2 loss": 16.35702838897705, "Mean Target Q": 42.88309658813476, "Mean Q1": 42.88723348999024, "Mean Q2": 42.8851637878418, "critic_loss": 32.68493533325195, "batch_reward": 0.9312844958305359, "actor_loss": -43.81609042998283, "actor_target_entropy": -1.0, "actor_entropy": -0.13967889398636837, "alpha_loss": -0.03674899053669745, "alpha_value": 0.07573995957498171, "duration": 145.94866228103638, "step": 10250}
{"episode_reward": 179.69367199193448, "episode": 83.0, "Q1 loss": 17.436160926818847, "Q2 loss": 17.437447990417482, "Mean Target Q": 43.682505126953124, "Mean Q1": 43.6624133605957, "Mean Q2": 43.66347860717774, "critic_loss": 34.87360908508301, "batch_reward": 0.9233885169029236, "actor_loss": -44.562214684864834, "actor_target_entropy": -1.0, "actor_entropy": -0.16542419797134778, "alpha_loss": -0.03696748556657916, "alpha_value": 0.0760625990836496, "duration": 148.86666226387024, "step": 10375}
{"episode_reward": 85.761473158849, "episode": 84.0, "Q1 loss": 18.453640426635744, "Q2 loss": 18.44130728149414, "Mean Target Q": 44.71542401123047, "Mean Q1": 44.712727752685545, "Mean Q2": 44.71150531005859, "critic_loss": 36.89494787597656, "batch_reward": 0.9312511801719665, "actor_loss": -45.59233185552782, "actor_target_entropy": -1.0, "actor_entropy": -0.15101815875048838, "alpha_loss": -0.03577628743744666, "alpha_value": 0.07638235267689797, "duration": 169.7900369167328, "step": 10500}
{"episode_reward": 61.097737303506285, "episode": 85.0, "Q1 loss": 18.896795326232912, "Q2 loss": 18.920517517089845, "Mean Target Q": 45.80157962036133, "Mean Q1": 45.79149639892578, "Mean Q2": 45.790454711914066, "critic_loss": 37.81731286621094, "batch_reward": 0.9291391034126282, "actor_loss": -46.66216944134425, "actor_target_entropy": -1.0, "actor_entropy": -0.07592193084576773, "alpha_loss": -0.042947580653523644, "alpha_value": 0.076717544327379, "duration": 181.44999647140503, "step": 10625}
{"episode_reward": 93.20081303621798, "episode": 86.0, "Q1 loss": 16.890033821105956, "Q2 loss": 16.864869331359863, "Mean Target Q": 46.79206167602539, "Mean Q1": 46.79286535644531, "Mean Q2": 46.793645233154294, "critic_loss": 33.75490312194824, "batch_reward": 0.9204717769622802, "actor_loss": -47.81919264024304, "actor_target_entropy": -1.0, "actor_entropy": -0.13495315072096645, "alpha_loss": -0.04606410353294303, "alpha_value": 0.07713882282446403, "duration": 164.61537981033325, "step": 10750}
{"episode_reward": 165.8196802382695, "episode": 87.0, "Q1 loss": 19.130168174743652, "Q2 loss": 19.139101257324217, "Mean Target Q": 47.825627136230466, "Mean Q1": 47.80963446044922, "Mean Q2": 47.80923699951172, "critic_loss": 38.26926937866211, "batch_reward": 0.9194566192626953, "actor_loss": -48.84502986120799, "actor_target_entropy": -1.0, "actor_entropy": -0.009062460801076321, "alpha_loss": -0.04772698527408971, "alpha_value": 0.07755354236476487, "duration": 182.0202260017395, "step": 10875}
{"episode_reward": 20.22061107783877, "episode": 88.0, "Q1 loss": 18.0909906539917, "Q2 loss": 18.097038177490234, "Mean Target Q": 48.88320422363281, "Mean Q1": 48.8798623046875, "Mean Q2": 48.88152996826172, "critic_loss": 36.18802877807617, "batch_reward": 0.909956407546997, "actor_loss": -49.88896049991731, "actor_target_entropy": -1.0, "actor_entropy": 0.13733845741878595, "alpha_loss": -0.04625591164034221, "alpha_value": 0.07799643484510813, "duration": 184.97587537765503, "step": 11000}
{"episode_reward": 27.378031238326383, "episode": 89.0, "Q1 loss": 18.388580787658693, "Q2 loss": 18.47417025756836, "Mean Target Q": 49.926563568115235, "Mean Q1": 49.92192568969727, "Mean Q2": 49.91978063964844, "critic_loss": 36.86275117492676, "batch_reward": 0.9059175777435303, "actor_loss": -51.14771961030506, "actor_target_entropy": -1.0, "actor_entropy": 0.023942294752313978, "alpha_loss": -0.05421434464080939, "alpha_value": 0.07844430195017489, "duration": 165.0266010761261, "step": 11125}
{"episode_reward": 19.226694023332655, "episode": 90.0, "Q1 loss": 17.768705871582032, "Q2 loss": 17.816280052185057, "Mean Target Q": 51.0412106628418, "Mean Q1": 51.03149444580078, "Mean Q2": 51.03190591430664, "critic_loss": 35.584985900878905, "batch_reward": 0.8911396012306213, "actor_loss": -52.155586058093654, "actor_target_entropy": -1.0, "actor_entropy": 0.30113771605876183, "alpha_loss": -0.057074131444096565, "alpha_value": 0.07898370713376456, "duration": 176.6605360507965, "step": 11250}
{"episode_reward": 12.796033666923709, "episode": 91.0, "Q1 loss": 18.424562744140626, "Q2 loss": 18.427059928894042, "Mean Target Q": 52.08346578979492, "Mean Q1": 52.08110333251953, "Mean Q2": 52.082376678466794, "critic_loss": 36.85162272644043, "batch_reward": 0.8858207025527954, "actor_loss": -53.33477304852198, "actor_target_entropy": -1.0, "actor_entropy": 0.29909821493285044, "alpha_loss": -0.06279937822430853, "alpha_value": 0.07955977140929439, "duration": 167.68454599380493, "step": 11375}
{"episode_reward": 82.08074655281017, "episode": 92.0, "Q1 loss": 17.43214781188965, "Q2 loss": 17.540183265686036, "Mean Target Q": 53.16417559814453, "Mean Q1": 53.16187734985352, "Mean Q2": 53.160600067138674, "critic_loss": 34.972331024169925, "batch_reward": 0.8891897015571594, "actor_loss": -54.381855872369584, "actor_target_entropy": -1.0, "actor_entropy": 0.2886939068595248, "alpha_loss": -0.05976094515813935, "alpha_value": 0.0801247936634054, "duration": 161.10922622680664, "step": 11500}
{"episode_reward": 91.31164144196298, "episode": 93.0, "Q1 loss": 19.71396068572998, "Q2 loss": 19.776878677368163, "Mean Target Q": 54.43261434936523, "Mean Q1": 54.42297647094727, "Mean Q2": 54.42361029052734, "critic_loss": 39.490839324951175, "batch_reward": 0.8976496577262878, "actor_loss": -55.76697588723803, "actor_target_entropy": -1.0, "actor_entropy": 0.3239485758637625, "alpha_loss": -0.07093757532891773, "alpha_value": 0.08072037985341257, "duration": 154.37867641448975, "step": 11625}
{"episode_reward": 153.26661373459925, "episode": 94.0, "Q1 loss": 18.3006457901001, "Q2 loss": 18.336756324768068, "Mean Target Q": 55.51802798461914, "Mean Q1": 55.516037567138675, "Mean Q2": 55.5133203125, "critic_loss": 36.63740213012695, "batch_reward": 0.8870097870826721, "actor_loss": -56.86370855762112, "actor_target_entropy": -1.0, "actor_entropy": 0.2587058277380082, "alpha_loss": -0.06640817723687618, "alpha_value": 0.08135438534061751, "duration": 164.3021535873413, "step": 11750}
{"episode_reward": 33.28613546644239, "episode": 95.0, "Q1 loss": 19.163238639831544, "Q2 loss": 19.33088153076172, "Mean Target Q": 56.58179299926758, "Mean Q1": 56.575014068603515, "Mean Q2": 56.57447528076172, "critic_loss": 38.49412008666992, "batch_reward": 0.882432279586792, "actor_loss": -57.98107619512649, "actor_target_entropy": -1.0, "actor_entropy": 0.29500224878863684, "alpha_loss": -0.07109130646974321, "alpha_value": 0.08198872899249551, "duration": 159.1607186794281, "step": 11875}
{"episode_reward": 20.83431989456522, "episode": 96.0, "Q1 loss": 20.04989595031738, "Q2 loss": 20.17798262023926, "Mean Target Q": 57.720061492919925, "Mean Q1": 57.7125998840332, "Mean Q2": 57.71373818969727, "critic_loss": 40.22787861633301, "batch_reward": 0.8739935531616211, "actor_loss": -59.09462295040007, "actor_target_entropy": -1.0, "actor_entropy": 0.33733408994251685, "alpha_loss": -0.0764115811475823, "alpha_value": 0.08265198798872822, "duration": 159.2833616733551, "step": 12000}
{"episode_reward": 29.69971960249661, "episode": 97.0, "Q1 loss": 17.89656912994385, "Q2 loss": 18.072893463134765, "Mean Target Q": 58.92662121582031, "Mean Q1": 58.92486465454102, "Mean Q2": 58.92586325073242, "critic_loss": 35.96946273803711, "batch_reward": 0.8654350252151489, "actor_loss": -60.584005507211835, "actor_target_entropy": -1.0, "actor_entropy": 0.3733446602783506, "alpha_loss": -0.08114899340130034, "alpha_value": 0.08332659567349418, "duration": 152.3955762386322, "step": 12125}
{"episode_reward": 32.62375043187592, "episode": 98.0, "Q1 loss": 19.426606422424317, "Q2 loss": 19.49201319885254, "Mean Target Q": 60.01327963256836, "Mean Q1": 60.000627044677735, "Mean Q2": 60.000081512451175, "critic_loss": 38.91861975097656, "batch_reward": 0.8588446707725524, "actor_loss": -61.63420523366621, "actor_target_entropy": -1.0, "actor_entropy": 0.3412386090044052, "alpha_loss": -0.08134977603631635, "alpha_value": 0.08404922081172463, "duration": 169.42692494392395, "step": 12250}
{"episode_reward": 70.42092712842992, "episode": 99.0, "Q1 loss": 19.161990028381346, "Q2 loss": 19.253858184814455, "Mean Target Q": 61.28513327026367, "Mean Q1": 61.27812805175781, "Mean Q2": 61.278964416503904, "critic_loss": 38.41584805297852, "batch_reward": 0.8574953918457031, "actor_loss": -62.96684737432571, "actor_target_entropy": -1.0, "actor_entropy": 0.35242965084219735, "alpha_loss": -0.08793179052216667, "alpha_value": 0.08475791332355577, "duration": 163.91524457931519, "step": 12375}
{"episode_reward": 50.07322623949344, "episode": 100.0, "Q1 loss": 19.198713119506834, "Q2 loss": 19.324188362121582, "Mean Target Q": 62.492774658203125, "Mean Q1": 62.49715509033203, "Mean Q2": 62.49769769287109, "critic_loss": 38.522901443481445, "batch_reward": 0.8587861628532409, "actor_loss": -64.2453116140058, "actor_target_entropy": -1.0, "actor_entropy": 0.39098520192407793, "alpha_loss": -0.09392992070605678, "alpha_value": 0.0855207082131242, "duration": 157.27748322486877, "step": 12500}
{"episode_reward": 148.4850390293053, "episode": 101.0, "Q1 loss": 19.267941146850585, "Q2 loss": 19.395899948120118, "Mean Target Q": 63.87269039916992, "Mean Q1": 63.87021905517578, "Mean Q2": 63.87162539672852, "critic_loss": 38.66384109497071, "batch_reward": 0.8575052723884583, "actor_loss": -65.48541296096076, "actor_target_entropy": -1.0, "actor_entropy": 0.36227803405315157, "alpha_loss": -0.08913127865110125, "alpha_value": 0.08626605670583674, "duration": 168.26814079284668, "step": 12625}
{"episode_reward": 174.8176860884588, "episode": 102.0, "Q1 loss": 20.27551734161377, "Q2 loss": 20.435556884765624, "Mean Target Q": 65.30594485473632, "Mean Q1": 65.28564401245117, "Mean Q2": 65.28526959228516, "critic_loss": 40.71107421875, "batch_reward": 0.8606634049415588, "actor_loss": -67.0444072600334, "actor_target_entropy": -1.0, "actor_entropy": 0.3325680198688661, "alpha_loss": -0.09171270975662817, "alpha_value": 0.08699006313491371, "duration": 172.84891176223755, "step": 12750}
{"episode_reward": 180.29625763898264, "episode": 103.0, "Q1 loss": 21.07664066314697, "Q2 loss": 21.14328787994385, "Mean Target Q": 66.66203997802734, "Mean Q1": 66.664146484375, "Mean Q2": 66.66543975830078, "critic_loss": 42.219928482055664, "batch_reward": 0.8783317813873291, "actor_loss": -68.46984330434648, "actor_target_entropy": -1.0, "actor_entropy": 0.34607780405453276, "alpha_loss": -0.09604003516927598, "alpha_value": 0.08772094532203399, "duration": 173.61394214630127, "step": 12875}
{"episode_reward": 198.88943333392078, "episode": 104.0, "Q1 loss": 22.601340812683105, "Q2 loss": 22.71484310913086, "Mean Target Q": 67.84133801269532, "Mean Q1": 67.83754815673828, "Mean Q2": 67.8360010986328, "critic_loss": 45.3161838684082, "batch_reward": 0.873605471611023, "actor_loss": -69.58569643574376, "actor_target_entropy": -1.0, "actor_entropy": 0.3514193575228414, "alpha_loss": -0.09986455834680988, "alpha_value": 0.08847758322321425, "duration": 176.76493096351624, "step": 13000}
{"episode_reward": 93.22582674070412, "episode": 105.0, "Q1 loss": 22.98555443572998, "Q2 loss": 23.11858358001709, "Mean Target Q": 69.13138250732422, "Mean Q1": 69.12446417236328, "Mean Q2": 69.12144927978515, "critic_loss": 46.10413798522949, "batch_reward": 0.8647799830436707, "actor_loss": -71.11961461627294, "actor_target_entropy": -1.0, "actor_entropy": 0.3646461958923037, "alpha_loss": -0.09778349349896114, "alpha_value": 0.08920439785793313, "duration": 174.67464208602905, "step": 13125}
{"episode_reward": 160.01428879434914, "episode": 106.0, "Q1 loss": 24.643928482055664, "Q2 loss": 24.697092262268065, "Mean Target Q": 70.81739831542968, "Mean Q1": 70.80436877441406, "Mean Q2": 70.80844073486328, "critic_loss": 49.34102070617676, "batch_reward": 0.8798154878616333, "actor_loss": -72.72920768491683, "actor_target_entropy": -1.0, "actor_entropy": 0.34574158081123907, "alpha_loss": -0.10161525888308402, "alpha_value": 0.08996259463131742, "duration": 177.57866597175598, "step": 13250}
{"episode_reward": 182.71586922854263, "episode": 107.0, "Q1 loss": 25.904591217041016, "Q2 loss": 25.96712107849121, "Mean Target Q": 72.4546810913086, "Mean Q1": 72.4508878173828, "Mean Q2": 72.44941070556641, "critic_loss": 51.87171209716797, "batch_reward": 0.8934321532249451, "actor_loss": -74.44258941165985, "actor_target_entropy": -1.0, "actor_entropy": 0.3227171926271348, "alpha_loss": -0.09312934724111406, "alpha_value": 0.0906824242783452, "duration": 166.22145676612854, "step": 13375}
{"episode_reward": 83.9373751531625, "episode": 108.0, "Q1 loss": 25.207884552001953, "Q2 loss": 25.347281326293945, "Mean Target Q": 73.88664044189453, "Mean Q1": 73.87460113525391, "Mean Q2": 73.87331909179687, "critic_loss": 50.55516580200195, "batch_reward": 0.8853532104492188, "actor_loss": -75.86310060562626, "actor_target_entropy": -1.0, "actor_entropy": 0.35145173269894814, "alpha_loss": -0.10832131726126518, "alpha_value": 0.09139642540636383, "duration": 158.42328000068665, "step": 13500}
{"episode_reward": 177.34550372067332, "episode": 109.0, "Q1 loss": 26.929668014526367, "Q2 loss": 27.022047149658203, "Mean Target Q": 75.43326849365235, "Mean Q1": 75.44022119140625, "Mean Q2": 75.439814453125, "critic_loss": 53.95171502685547, "batch_reward": 0.8802194547653198, "actor_loss": -77.45474812341115, "actor_target_entropy": -1.0, "actor_entropy": 0.3438614020271907, "alpha_loss": -0.10531419917704567, "alpha_value": 0.09215498310696565, "duration": 171.68391919136047, "step": 13625}
{"episode_reward": 38.199610105644076, "episode": 110.0, "Q1 loss": 29.254879898071287, "Q2 loss": 29.319154144287108, "Mean Target Q": 76.92706390380859, "Mean Q1": 76.91459924316406, "Mean Q2": 76.91459088134765, "critic_loss": 58.57403381347656, "batch_reward": 0.879505811214447, "actor_loss": -78.90371753323463, "actor_target_entropy": -1.0, "actor_entropy": 0.3708162665847809, "alpha_loss": -0.10968451922939669, "alpha_value": 0.09290965083432683, "duration": 167.75070595741272, "step": 13750}
{"episode_reward": 47.76975739069012, "episode": 111.0, "Q1 loss": 27.79100570678711, "Q2 loss": 27.88389680480957, "Mean Target Q": 78.40125598144532, "Mean Q1": 78.38552355957032, "Mean Q2": 78.38569494628906, "critic_loss": 55.67490252685547, "batch_reward": 0.8749854059219361, "actor_loss": -80.38086882091704, "actor_target_entropy": -1.0, "actor_entropy": 0.34440105751393335, "alpha_loss": -0.10560067151747053, "alpha_value": 0.09366694204821198, "duration": 151.3983883857727, "step": 13875}
{"episode_reward": 182.76142222421475, "episode": 112.0, "Q1 loss": 28.985975677490234, "Q2 loss": 29.10794007873535, "Mean Target Q": 80.0338719482422, "Mean Q1": 80.02400616455078, "Mean Q2": 80.0272260131836, "critic_loss": 58.09391580200195, "batch_reward": 0.8778978362083435, "actor_loss": -82.20484026016727, "actor_target_entropy": -1.0, "actor_entropy": 0.3598247836193731, "alpha_loss": -0.11183152984707587, "alpha_value": 0.09438668813396606, "duration": 156.93366599082947, "step": 14000}
{"episode_reward": 149.49528794922543, "episode": 113.0, "Q1 loss": 29.545747940063478, "Q2 loss": 29.612151977539064, "Mean Target Q": 81.68490637207032, "Mean Q1": 81.68671307373047, "Mean Q2": 81.68550793457031, "critic_loss": 59.15790023803711, "batch_reward": 0.8757767796516418, "actor_loss": -83.78211163717603, "actor_target_entropy": -1.0, "actor_entropy": 0.36817674882828244, "alpha_loss": -0.10758866334245318, "alpha_value": 0.09513831809876533, "duration": 163.58608555793762, "step": 14125}
{"episode_reward": 37.80374443784479, "episode": 114.0, "Q1 loss": 28.692980270385743, "Q2 loss": 28.695196502685548, "Mean Target Q": 83.19505389404297, "Mean Q1": 83.18397094726562, "Mean Q2": 83.18219848632812, "critic_loss": 57.388176818847654, "batch_reward": 0.8744605965614319, "actor_loss": -85.43676487092048, "actor_target_entropy": -1.0, "actor_entropy": 0.32808582004039516, "alpha_loss": -0.10905652324999532, "alpha_value": 0.09585640373291827, "duration": 164.5399613380432, "step": 14250}
{"episode_reward": 157.2197117352048, "episode": 115.0, "Q1 loss": 27.469899276733397, "Q2 loss": 27.513281372070313, "Mean Target Q": 84.67201776123046, "Mean Q1": 84.65938293457032, "Mean Q2": 84.66155383300782, "critic_loss": 54.9831809387207, "batch_reward": 0.8861825823783874, "actor_loss": -86.81812795003255, "actor_target_entropy": -1.0, "actor_entropy": 0.351290615305068, "alpha_loss": -0.10926288259880883, "alpha_value": 0.09660049526945783, "duration": 165.24689435958862, "step": 14375}
{"episode_reward": 188.06201714474116, "episode": 116.0, "Q1 loss": 27.236985397338866, "Q2 loss": 27.209720062255858, "Mean Target Q": 86.08211865234375, "Mean Q1": 86.07568420410156, "Mean Q2": 86.0755322265625, "critic_loss": 54.446705474853516, "batch_reward": 0.88839129114151, "actor_loss": -88.24300458354335, "actor_target_entropy": -1.0, "actor_entropy": 0.3722353267573541, "alpha_loss": -0.10700405725548344, "alpha_value": 0.0973167833715522, "duration": 159.65021657943726, "step": 14500}
{"episode_reward": 107.39417330892267, "episode": 117.0, "Q1 loss": 28.60968232727051, "Q2 loss": 28.673744995117186, "Mean Target Q": 87.46105505371094, "Mean Q1": 87.44728912353516, "Mean Q2": 87.45061956787109, "critic_loss": 57.28342724609375, "batch_reward": 0.8882826547622681, "actor_loss": -89.39275384327722, "actor_target_entropy": -1.0, "actor_entropy": 0.33840706057491754, "alpha_loss": -0.10286771044844673, "alpha_value": 0.0979950250349415, "duration": 169.3605558872223, "step": 14625}
{"episode_reward": 218.37620420212468, "episode": 118.0, "Q1 loss": 27.350134872436524, "Q2 loss": 27.27954119873047, "Mean Target Q": 88.81289636230468, "Mean Q1": 88.80219244384766, "Mean Q2": 88.80116967773438, "critic_loss": 54.62967623901367, "batch_reward": 0.8915575046539307, "actor_loss": -90.64309495495212, "actor_target_entropy": -1.0, "actor_entropy": 0.3532519672186144, "alpha_loss": -0.10367846789379273, "alpha_value": 0.09866951974018018, "duration": 165.5900113582611, "step": 14750}
{"episode_reward": 130.24329938630174, "episode": 119.0, "Q1 loss": 27.9460908203125, "Q2 loss": 27.939534149169923, "Mean Target Q": 90.21780444335937, "Mean Q1": 90.2132025756836, "Mean Q2": 90.21388562011718, "critic_loss": 55.885624877929686, "batch_reward": 0.8951715354919434, "actor_loss": -92.0553716023763, "actor_target_entropy": -1.0, "actor_entropy": 0.35943322924394455, "alpha_loss": -0.09867702471831488, "alpha_value": 0.09933274789438676, "duration": 140.329514503479, "step": 14875}
{"episode_reward": 63.88329427743803, "episode": 120.0, "Q1 loss": 26.068358306884765, "Q2 loss": 26.151088775634765, "Mean Target Q": 91.34513543701172, "Mean Q1": 91.33811486816407, "Mean Q2": 91.33617218017578, "critic_loss": 52.219447052001954, "batch_reward": 0.9000998950004577, "actor_loss": -93.1031111440351, "actor_target_entropy": -1.0, "actor_entropy": 0.3158693602008204, "alpha_loss": -0.10309580016520715, "alpha_value": 0.10001073835095572, "step": 15000}
{"duration": 131.79565930366516, "step": 15000}
{"episode_reward": 217.45192554931236, "episode": 121.0, "Q1 loss": 25.459832458496095, "Q2 loss": 25.410358047485353, "Mean Target Q": 92.89856744384765, "Mean Q1": 92.89445245361328, "Mean Q2": 92.89407446289063, "critic_loss": 50.87019046020508, "batch_reward": 0.9072611880302429, "actor_loss": -94.71681613013858, "actor_target_entropy": -1.0, "actor_entropy": 0.3197256083053256, "alpha_loss": -0.10026319868980892, "alpha_value": 0.10067902044071148, "duration": 127.27097129821777, "step": 15125}
{"episode_reward": 64.26446494627285, "episode": 122.0, "Q1 loss": 25.79828970336914, "Q2 loss": 25.774230407714843, "Mean Target Q": 94.096318359375, "Mean Q1": 94.09179376220703, "Mean Q2": 94.09397784423828, "critic_loss": 51.57252038574219, "batch_reward": 0.9019252181053161, "actor_loss": -96.02057623094127, "actor_target_entropy": -1.0, "actor_entropy": 0.3711010347450933, "alpha_loss": -0.09782314745168533, "alpha_value": 0.10133818582969013, "duration": 133.29381132125854, "step": 15250}
{"episode_reward": 234.30828812707287, "episode": 123.0, "Q1 loss": 25.16077944946289, "Q2 loss": 25.074474456787108, "Mean Target Q": 95.10587744140625, "Mean Q1": 95.1018560180664, "Mean Q2": 95.09957122802734, "critic_loss": 50.23525408935547, "batch_reward": 0.906184121131897, "actor_loss": -96.84366317022415, "actor_target_entropy": -1.0, "actor_entropy": 0.31629651098970385, "alpha_loss": -0.08930992435604806, "alpha_value": 0.10195146046548674, "duration": 128.9437985420227, "step": 15375}
{"episode_reward": 214.27609105491572, "episode": 124.0, "Q1 loss": 25.574770599365234, "Q2 loss": 25.518534858703614, "Mean Target Q": 96.46681848144532, "Mean Q1": 96.44948620605469, "Mean Q2": 96.45166900634766, "critic_loss": 51.0933053894043, "batch_reward": 0.9135535945892334, "actor_loss": -98.15770992155998, "actor_target_entropy": -1.0, "actor_entropy": 0.2914512222332339, "alpha_loss": -0.09264856661039014, "alpha_value": 0.1025555486464174, "duration": 137.4837064743042, "step": 15500}
{"episode_reward": 222.11023366264186, "episode": 125.0, "Q1 loss": 25.49132992553711, "Q2 loss": 25.5544541015625, "Mean Target Q": 97.88587396240234, "Mean Q1": 97.87823895263672, "Mean Q2": 97.87613793945313, "critic_loss": 51.045783966064455, "batch_reward": 0.9322954053878785, "actor_loss": -99.6462918236142, "actor_target_entropy": -1.0, "actor_entropy": 0.29568420728993794, "alpha_loss": -0.09325729452428363, "alpha_value": 0.1031943081329986, "duration": 133.10296082496643, "step": 15625}
{"episode_reward": 199.90042669274234, "episode": 126.0, "Q1 loss": 24.699150665283202, "Q2 loss": 24.874743911743163, "Mean Target Q": 98.98008221435546, "Mean Q1": 98.96888159179687, "Mean Q2": 98.9687247314453, "critic_loss": 49.57389437866211, "batch_reward": 0.9207280631065369, "actor_loss": -100.79804426623929, "actor_target_entropy": -1.0, "actor_entropy": 0.2727018085218245, "alpha_loss": -0.08879202730473011, "alpha_value": 0.10380014321550862, "duration": 137.82237887382507, "step": 15750}
{"episode_reward": 193.20941053066812, "episode": 127.0, "Q1 loss": 24.379266860961913, "Q2 loss": 24.42037924194336, "Mean Target Q": 100.21535784912109, "Mean Q1": 100.22059796142578, "Mean Q2": 100.22151293945312, "critic_loss": 48.79964639282227, "batch_reward": 0.9369185290336609, "actor_loss": -101.95348588247148, "actor_target_entropy": -1.0, "actor_entropy": 0.26507723709893605, "alpha_loss": -0.09246765975914305, "alpha_value": 0.10441930144412523, "duration": 141.83609127998352, "step": 15875}
{"episode_reward": 163.4421825176322, "episode": 128.0, "Q1 loss": 24.44031134033203, "Q2 loss": 24.506119506835937, "Mean Target Q": 101.4438203125, "Mean Q1": 101.43548809814453, "Mean Q2": 101.43494677734375, "critic_loss": 48.94643087768555, "batch_reward": 0.925162015914917, "actor_loss": -103.16006026729461, "actor_target_entropy": -1.0, "actor_entropy": 0.2914529099099098, "alpha_loss": -0.08387036297109819, "alpha_value": 0.10504088653756408, "duration": 148.48604273796082, "step": 16000}
{"episode_reward": 190.98991562697174, "episode": 129.0, "Q1 loss": 23.764107421875, "Q2 loss": 23.68514535522461, "Mean Target Q": 102.53597406005859, "Mean Q1": 102.52512475585938, "Mean Q2": 102.52572290039062, "critic_loss": 47.44925271606445, "batch_reward": 0.9397710990905762, "actor_loss": -104.18323189871651, "actor_target_entropy": -1.0, "actor_entropy": 0.2360212579369545, "alpha_loss": -0.08685702280629248, "alpha_value": 0.10562213741013424, "duration": 141.654522895813, "step": 16125}
{"episode_reward": 203.61377728508654, "episode": 130.0, "Q1 loss": 22.31756544494629, "Q2 loss": 22.24617581176758, "Mean Target Q": 103.63460443115234, "Mean Q1": 103.62671325683594, "Mean Q2": 103.62729217529296, "critic_loss": 44.56374145507812, "batch_reward": 0.9343953328132629, "actor_loss": -105.26365600093719, "actor_target_entropy": -1.0, "actor_entropy": 0.25953395382290884, "alpha_loss": -0.08924435613857161, "alpha_value": 0.1062502676399878, "duration": 129.7961802482605, "step": 16250}
{"episode_reward": 54.09747081410886, "episode": 131.0, "Q1 loss": 23.213025436401367, "Q2 loss": 23.200199768066405, "Mean Target Q": 104.74161120605469, "Mean Q1": 104.73245233154297, "Mean Q2": 104.73289971923828, "critic_loss": 46.41322503662109, "batch_reward": 0.9399746913909912, "actor_loss": -106.47373780750092, "actor_target_entropy": -1.0, "actor_entropy": 0.20037421465866148, "alpha_loss": -0.08672335247198741, "alpha_value": 0.10686388256365938, "duration": 132.86913800239563, "step": 16375}
{"episode_reward": 172.80419371441303, "episode": 132.0, "Q1 loss": 22.924650650024414, "Q2 loss": 23.089180297851563, "Mean Target Q": 105.97913055419922, "Mean Q1": 105.97725006103515, "Mean Q2": 105.97585437011719, "critic_loss": 46.013830902099606, "batch_reward": 0.9476745710372925, "actor_loss": -107.6361827235068, "actor_target_entropy": -1.0, "actor_entropy": 0.22030740955303754, "alpha_loss": -0.0793379541005819, "alpha_value": 0.10745753765947977, "duration": 127.59056401252747, "step": 16500}
{"episode_reward": 165.43807778422587, "episode": 133.0, "Q1 loss": 22.022766014099123, "Q2 loss": 22.09812661743164, "Mean Target Q": 107.15184252929687, "Mean Q1": 107.14804693603516, "Mean Q2": 107.14822912597656, "critic_loss": 44.12089254760742, "batch_reward": 0.9422316327095032, "actor_loss": -108.89251006595673, "actor_target_entropy": -1.0, "actor_entropy": 0.1738591424766041, "alpha_loss": -0.08609343059952297, "alpha_value": 0.10806693107305614, "duration": 145.64355278015137, "step": 16625}
{"episode_reward": 237.2828897273946, "episode": 134.0, "Q1 loss": 21.713369537353515, "Q2 loss": 21.70999183654785, "Mean Target Q": 108.28939898681641, "Mean Q1": 108.28386505126953, "Mean Q2": 108.2863267211914, "critic_loss": 43.42336141967773, "batch_reward": 0.9524198002815246, "actor_loss": -109.94915143905148, "actor_target_entropy": -1.0, "actor_entropy": 0.20879294795374717, "alpha_loss": -0.0814290607287999, "alpha_value": 0.10870549348205309, "duration": 160.50640726089478, "step": 16750}
{"episode_reward": 130.16443219103115, "episode": 135.0, "Q1 loss": 22.171187393188475, "Q2 loss": 22.120882438659667, "Mean Target Q": 109.28839404296875, "Mean Q1": 109.27565148925781, "Mean Q2": 109.27577954101562, "critic_loss": 44.29206986999512, "batch_reward": 0.9444206848144531, "actor_loss": -110.84878128293961, "actor_target_entropy": -1.0, "actor_entropy": 0.182875760077011, "alpha_loss": -0.07112279977826845, "alpha_value": 0.10924145044103596, "duration": 168.08079290390015, "step": 16875}
{"episode_reward": 202.37394552714764, "episode": 136.0, "Q1 loss": 21.82819511413574, "Q2 loss": 21.972482055664063, "Mean Target Q": 110.71297106933594, "Mean Q1": 110.71798846435547, "Mean Q2": 110.71542864990235, "critic_loss": 43.80067720031738, "batch_reward": 0.962792465209961, "actor_loss": -112.14363787251133, "actor_target_entropy": -1.0, "actor_entropy": 0.16882452140412024, "alpha_loss": -0.0712728094790251, "alpha_value": 0.1097773590981952, "duration": 160.89009761810303, "step": 17000}
{"episode_reward": 207.04735754320376, "episode": 137.0, "Q1 loss": 20.36529975128174, "Q2 loss": 20.47710620880127, "Mean Target Q": 111.66209490966797, "Mean Q1": 111.63769458007812, "Mean Q2": 111.64001611328125, "critic_loss": 40.84240603637695, "batch_reward": 0.9618669981956482, "actor_loss": -113.00536201113746, "actor_target_entropy": -1.0, "actor_entropy": 0.18850085322582533, "alpha_loss": -0.07347938625348939, "alpha_value": 0.11032992577960365, "duration": 155.72487115859985, "step": 17125}
{"episode_reward": 136.26843137429688, "episode": 138.0, "Q1 loss": 20.771493209838866, "Q2 loss": 20.808144363403322, "Mean Target Q": 112.72023944091796, "Mean Q1": 112.72458966064453, "Mean Q2": 112.72290539550781, "critic_loss": 41.579637619018555, "batch_reward": 0.972251600265503, "actor_loss": -114.3244370491274, "actor_target_entropy": -1.0, "actor_entropy": 0.15358542452656454, "alpha_loss": -0.08510912371979605, "alpha_value": 0.11094416899843852, "duration": 166.60666131973267, "step": 17250}
{"episode_reward": 229.89583338608935, "episode": 139.0, "Q1 loss": 20.32329842376709, "Q2 loss": 20.371104919433595, "Mean Target Q": 113.53669470214844, "Mean Q1": 113.52536267089843, "Mean Q2": 113.52665869140625, "critic_loss": 40.694403259277344, "batch_reward": 0.9643801884651184, "actor_loss": -115.01806604294549, "actor_target_entropy": -1.0, "actor_entropy": 0.18950791314007745, "alpha_loss": -0.0708970758058722, "alpha_value": 0.11155629039046427, "duration": 176.1724555492401, "step": 17375}
{"episode_reward": 220.5868923827119, "episode": 140.0, "Q1 loss": 19.1357177734375, "Q2 loss": 19.235030853271486, "Mean Target Q": 114.66626788330078, "Mean Q1": 114.66007897949218, "Mean Q2": 114.66135565185547, "critic_loss": 38.37074864196777, "batch_reward": 0.9822114992141724, "actor_loss": -116.14407348632812, "actor_target_entropy": -1.0, "actor_entropy": 0.19022704426559708, "alpha_loss": -0.07330074209359384, "alpha_value": 0.1121322874719769, "duration": 175.65201449394226, "step": 17500}
{"episode_reward": 203.2117249339828, "episode": 141.0, "Q1 loss": 19.5937903213501, "Q2 loss": 19.68821035003662, "Mean Target Q": 115.68048657226562, "Mean Q1": 115.67720764160157, "Mean Q2": 115.67619720458984, "critic_loss": 39.282000595092775, "batch_reward": 0.9832244815826416, "actor_loss": -117.23052046034071, "actor_target_entropy": -1.0, "actor_entropy": 0.16132507958109416, "alpha_loss": -0.07710833723346393, "alpha_value": 0.11273394289165499, "duration": 170.88763070106506, "step": 17625}
{"episode_reward": 195.77425510769962, "episode": 142.0, "Q1 loss": 19.007609535217284, "Q2 loss": 19.033961135864256, "Mean Target Q": 116.38995007324219, "Mean Q1": 116.3804365234375, "Mean Q2": 116.38170379638672, "critic_loss": 38.04157096862793, "batch_reward": 0.9905220236778259, "actor_loss": -117.86400062807145, "actor_target_entropy": -1.0, "actor_entropy": 0.19914707204987925, "alpha_loss": -0.06956229629295488, "alpha_value": 0.11333735610671317, "duration": 192.7086923122406, "step": 17750}
{"episode_reward": 218.90555660792498, "episode": 143.0, "Q1 loss": 18.740788314819337, "Q2 loss": 18.74106452178955, "Mean Target Q": 117.3400933227539, "Mean Q1": 117.33548712158203, "Mean Q2": 117.3348374633789, "critic_loss": 37.481852905273435, "batch_reward": 1.000950243473053, "actor_loss": -118.85168021065849, "actor_target_entropy": -1.0, "actor_entropy": 0.2035268403234936, "alpha_loss": -0.07834199289717371, "alpha_value": 0.1139549887215085, "duration": 173.92335152626038, "step": 17875}
{"episode_reward": 247.6799812635248, "episode": 144.0, "Q1 loss": 18.727007347106934, "Q2 loss": 18.72163889312744, "Mean Target Q": 118.05508581542969, "Mean Q1": 118.05061657714843, "Mean Q2": 118.05000073242188, "critic_loss": 37.44864619445801, "batch_reward": 0.9941166405677795, "actor_loss": -119.43252169701361, "actor_target_entropy": -1.0, "actor_entropy": 0.24310473040226968, "alpha_loss": -0.0759761466855003, "alpha_value": 0.11459219647642965, "duration": 179.1417841911316, "step": 18000}
{"episode_reward": 185.62151714582862, "episode": 145.0, "Q1 loss": 17.650245056152343, "Q2 loss": 17.70882431793213, "Mean Target Q": 118.88227453613281, "Mean Q1": 118.88216076660156, "Mean Q2": 118.88285052490234, "critic_loss": 35.35906958007813, "batch_reward": 1.0064406332969666, "actor_loss": -120.18236783951048, "actor_target_entropy": -1.0, "actor_entropy": 0.26363478204797186, "alpha_loss": -0.07097301791821208, "alpha_value": 0.11521477191551614, "duration": 178.1910560131073, "step": 18125}
{"episode_reward": 162.11503792954784, "episode": 146.0, "Q1 loss": 16.999031730651854, "Q2 loss": 17.08128981781006, "Mean Target Q": 119.71159686279297, "Mean Q1": 119.70027185058593, "Mean Q2": 119.69974676513672, "critic_loss": 34.08032147216797, "batch_reward": 0.9999964699745179, "actor_loss": -121.07031631469727, "actor_target_entropy": -1.0, "actor_entropy": 0.24347355889697228, "alpha_loss": -0.06728186037751936, "alpha_value": 0.1158058272838981, "duration": 177.39313530921936, "step": 18250}
{"episode_reward": 183.0896163535356, "episode": 147.0, "Q1 loss": 16.91683324432373, "Q2 loss": 16.994789405822754, "Mean Target Q": 120.48837219238281, "Mean Q1": 120.48153869628906, "Mean Q2": 120.48238397216797, "critic_loss": 33.91162274169922, "batch_reward": 1.014016715526581, "actor_loss": -121.83072819785467, "actor_target_entropy": -1.0, "actor_entropy": 0.2586247703385732, "alpha_loss": -0.0703709948039244, "alpha_value": 0.11640278763120468, "duration": 163.64972019195557, "step": 18375}
{"episode_reward": 256.6254995670232, "episode": 148.0, "Q1 loss": 16.82099609375, "Q2 loss": 16.854609313964843, "Mean Target Q": 121.25153076171875, "Mean Q1": 121.24068328857422, "Mean Q2": 121.24038122558593, "critic_loss": 33.67560536193848, "batch_reward": 1.009492075443268, "actor_loss": -122.45749479724515, "actor_target_entropy": -1.0, "actor_entropy": 0.20823320049432018, "alpha_loss": -0.05831787011195575, "alpha_value": 0.11697396502709413, "duration": 179.03192782402039, "step": 18500}
{"episode_reward": 213.3114317697568, "episode": 149.0, "Q1 loss": 16.822308006286622, "Q2 loss": 16.95956965637207, "Mean Target Q": 122.00603430175781, "Mean Q1": 122.00508685302735, "Mean Q2": 122.0049984741211, "critic_loss": 33.78187777709961, "batch_reward": 1.0206584725379944, "actor_loss": -123.34420473613436, "actor_target_entropy": -1.0, "actor_entropy": 0.266247824307472, "alpha_loss": -0.07328549148662696, "alpha_value": 0.11756749295729846, "duration": 176.20767521858215, "step": 18625}
{"episode_reward": 253.47744343869965, "episode": 150.0, "Q1 loss": 16.992292602539063, "Q2 loss": 16.97433344268799, "Mean Target Q": 122.93081072998046, "Mean Q1": 122.92919860839844, "Mean Q2": 122.92867687988281, "critic_loss": 33.9666261138916, "batch_reward": 1.02230544090271, "actor_loss": -124.36274165491903, "actor_target_entropy": -1.0, "actor_entropy": 0.23868155335226365, "alpha_loss": -0.07781267556692323, "alpha_value": 0.11827636510868896, "duration": 192.85255336761475, "step": 18750}
{"episode_reward": 222.07042075503233, "episode": 151.0, "Q1 loss": 15.249496940612794, "Q2 loss": 15.275890647888184, "Mean Target Q": 123.74439929199218, "Mean Q1": 123.74361639404297, "Mean Q2": 123.74370855712891, "critic_loss": 30.525387619018556, "batch_reward": 1.0333411078453063, "actor_loss": -125.08594040643601, "actor_target_entropy": -1.0, "actor_entropy": 0.30065367217101746, "alpha_loss": -0.08187838927620933, "alpha_value": 0.11899619568876262, "duration": 170.0372006893158, "step": 18875}
{"episode_reward": 165.37645064094775, "episode": 152.0, "Q1 loss": 17.062958168029784, "Q2 loss": 17.113833709716797, "Mean Target Q": 124.64770874023438, "Mean Q1": 124.62882110595703, "Mean Q2": 124.63040557861328, "critic_loss": 34.17679197692871, "batch_reward": 1.0347139186859131, "actor_loss": -126.01777919646233, "actor_target_entropy": -1.0, "actor_entropy": 0.2719032959111275, "alpha_loss": -0.06982194271779829, "alpha_value": 0.11969714231130943, "duration": 179.19157147407532, "step": 19000}
{"episode_reward": 245.09636590482359, "episode": 153.0, "Q1 loss": 15.601376098632812, "Q2 loss": 15.593391532897948, "Mean Target Q": 125.28947229003906, "Mean Q1": 125.2940767211914, "Mean Q2": 125.29322802734374, "critic_loss": 31.19476776123047, "batch_reward": 1.0435558261871338, "actor_loss": -126.47135017031715, "actor_target_entropy": -1.0, "actor_entropy": 0.2475792004002465, "alpha_loss": -0.06774513163263836, "alpha_value": 0.12033896273667816, "duration": 174.2822141647339, "step": 19125}
{"episode_reward": 249.25505573082464, "episode": 154.0, "Q1 loss": 15.071976570129394, "Q2 loss": 15.104423248291015, "Mean Target Q": 125.86113793945313, "Mean Q1": 125.8548159790039, "Mean Q2": 125.854681640625, "critic_loss": 30.176399765014647, "batch_reward": 1.039879060268402, "actor_loss": -127.15138503043882, "actor_target_entropy": -1.0, "actor_entropy": 0.2476433401386584, "alpha_loss": -0.06878221275344971, "alpha_value": 0.12095394977883134, "duration": 172.23767733573914, "step": 19250}
{"episode_reward": 243.68061219517799, "episode": 155.0, "Q1 loss": 14.92729689025879, "Q2 loss": 14.898810684204102, "Mean Target Q": 126.66948663330078, "Mean Q1": 126.6664853515625, "Mean Q2": 126.665443359375, "critic_loss": 29.82610758972168, "batch_reward": 1.0550803718566895, "actor_loss": -127.94193836999318, "actor_target_entropy": -1.0, "actor_entropy": 0.23276431929497493, "alpha_loss": -0.06408300271464719, "alpha_value": 0.12158688665649983, "duration": 158.28385663032532, "step": 19375}
{"episode_reward": 255.24900043661444, "episode": 156.0, "Q1 loss": 14.97129987335205, "Q2 loss": 15.116735618591308, "Mean Target Q": 127.33253344726562, "Mean Q1": 127.32739959716797, "Mean Q2": 127.32781689453125, "critic_loss": 30.088035461425783, "batch_reward": 1.053388689517975, "actor_loss": -128.68510375484342, "actor_target_entropy": -1.0, "actor_entropy": 0.23670134849606023, "alpha_loss": -0.06688884705785782, "alpha_value": 0.12223815379184705, "duration": 143.7320499420166, "step": 19500}
{"episode_reward": 196.95606161559454, "episode": 157.0, "Q1 loss": 14.843737899780274, "Q2 loss": 14.821361740112305, "Mean Target Q": 127.9590966796875, "Mean Q1": 127.94909216308594, "Mean Q2": 127.9505073852539, "critic_loss": 29.665099563598634, "batch_reward": 1.0589293537139892, "actor_loss": -129.26428803943452, "actor_target_entropy": -1.0, "actor_entropy": 0.26931181124278475, "alpha_loss": -0.07327399810864813, "alpha_value": 0.12291908966339124, "duration": 147.81617546081543, "step": 19625}
{"episode_reward": 211.56969587175183, "episode": 158.0, "Q1 loss": 15.291622749328614, "Q2 loss": 15.297182418823242, "Mean Target Q": 128.69623657226563, "Mean Q1": 128.69904559326173, "Mean Q2": 128.6983577270508, "critic_loss": 30.588805084228515, "batch_reward": 1.0650006794929505, "actor_loss": -129.99729968655495, "actor_target_entropy": -1.0, "actor_entropy": 0.24536661208877641, "alpha_loss": -0.07000951060364323, "alpha_value": 0.12362701567245292, "duration": 149.80108308792114, "step": 19750}
{"episode_reward": 190.93220028020198, "episode": 159.0, "Q1 loss": 14.412388359069825, "Q2 loss": 14.574443550109864, "Mean Target Q": 129.40947912597656, "Mean Q1": 129.40330407714845, "Mean Q2": 129.40060858154297, "critic_loss": 28.98683190917969, "batch_reward": 1.069169596195221, "actor_loss": -130.50012425013952, "actor_target_entropy": -1.0, "actor_entropy": 0.26016979333427215, "alpha_loss": -0.06297665050933285, "alpha_value": 0.12430021406772347, "duration": 145.9225208759308, "step": 19875}
{"episode_reward": 227.54781365772143, "episode": 160.0, "Q1 loss": 14.452257865905763, "Q2 loss": 14.45892852783203, "Mean Target Q": 130.04183349609374, "Mean Q1": 130.0261417236328, "Mean Q2": 130.02840368652343, "critic_loss": 28.911186294555662, "batch_reward": 1.0702104787826539, "actor_loss": -131.2893310054656, "actor_target_entropy": -1.0, "actor_entropy": 0.2601961507912605, "alpha_loss": -0.07070833696953711, "alpha_value": 0.12495970783849003, "step": 20000}
{"duration": 143.70675539970398, "step": 20000}
{"episode_reward": 201.7128227436302, "episode": 161.0, "Q1 loss": 14.346192817687989, "Q2 loss": 14.318503829956054, "Mean Target Q": 130.68663415527342, "Mean Q1": 130.6927442626953, "Mean Q2": 130.69330700683594, "critic_loss": 28.66469662475586, "batch_reward": 1.080624391555786, "actor_loss": -131.9135502406529, "actor_target_entropy": -1.0, "actor_entropy": 0.26584193027681774, "alpha_loss": -0.06855378619262151, "alpha_value": 0.12567341635041673, "duration": 135.60231757164001, "step": 20125}
{"episode_reward": 289.52348178887837, "episode": 162.0, "Q1 loss": 14.754763458251952, "Q2 loss": 14.6742486038208, "Mean Target Q": 131.34496142578126, "Mean Q1": 131.34210925292967, "Mean Q2": 131.3421640625, "critic_loss": 29.429011947631835, "batch_reward": 1.0873402314186096, "actor_loss": -132.68125620195943, "actor_target_entropy": -1.0, "actor_entropy": 0.2478372892064433, "alpha_loss": -0.06443929618164417, "alpha_value": 0.12635927568570257, "duration": 149.79974222183228, "step": 20250}
{"episode_reward": 256.82593224449266, "episode": 163.0, "Q1 loss": 14.061569381713868, "Q2 loss": 14.041278694152831, "Mean Target Q": 131.8653829345703, "Mean Q1": 131.85636645507813, "Mean Q2": 131.85764794921874, "critic_loss": 28.102848037719728, "batch_reward": 1.0850146141052246, "actor_loss": -132.99350314670139, "actor_target_entropy": -1.0, "actor_entropy": 0.23309713649371314, "alpha_loss": -0.06489761286075153, "alpha_value": 0.12704574500603696, "duration": 166.3096296787262, "step": 20375}
{"episode_reward": 194.90924080543405, "episode": 164.0, "Q1 loss": 13.705927383422852, "Q2 loss": 13.690533409118652, "Mean Target Q": 132.5880477294922, "Mean Q1": 132.57849267578126, "Mean Q2": 132.57579858398438, "critic_loss": 27.396460754394532, "batch_reward": 1.0873918700218201, "actor_loss": -133.79830563452936, "actor_target_entropy": -1.0, "actor_entropy": 0.22835470111139358, "alpha_loss": -0.061578688121611075, "alpha_value": 0.12770305542965543, "duration": 169.43373727798462, "step": 20500}
{"episode_reward": 71.10896382743675, "episode": 165.0, "Q1 loss": 13.255629936218261, "Q2 loss": 13.28434920501709, "Mean Target Q": 133.26659899902344, "Mean Q1": 133.26384765625, "Mean Q2": 133.26604711914064, "critic_loss": 26.539979095458985, "batch_reward": 1.0919220204353333, "actor_loss": -134.35670543852308, "actor_target_entropy": -1.0, "actor_entropy": 0.18704323352329313, "alpha_loss": -0.0645045077516919, "alpha_value": 0.12837599376590636, "duration": 161.87871670722961, "step": 20625}
{"episode_reward": 142.66000228892963, "episode": 166.0, "Q1 loss": 12.273564498901367, "Q2 loss": 12.219611961364746, "Mean Target Q": 133.73829736328125, "Mean Q1": 133.7356278076172, "Mean Q2": 133.73607702636718, "critic_loss": 24.493176483154297, "batch_reward": 1.0889537634849549, "actor_loss": -134.70284960346837, "actor_target_entropy": -1.0, "actor_entropy": 0.20219100687292316, "alpha_loss": -0.06626128279153377, "alpha_value": 0.12911278802309054, "duration": 171.5705943107605, "step": 20750}
{"episode_reward": 270.29099854101594, "episode": 167.0, "Q1 loss": 12.409846519470214, "Q2 loss": 12.442969291687012, "Mean Target Q": 134.31504431152345, "Mean Q1": 134.30629357910155, "Mean Q2": 134.3041387939453, "critic_loss": 24.852815872192384, "batch_reward": 1.0898515095710755, "actor_loss": -135.42733764648438, "actor_target_entropy": -1.0, "actor_entropy": 0.26387601688740747, "alpha_loss": -0.0651499145324268, "alpha_value": 0.12982400859556537, "duration": 161.17910718917847, "step": 20875}
{"episode_reward": 229.14860817382035, "episode": 168.0, "Q1 loss": 12.275979759216309, "Q2 loss": 12.31684758758545, "Mean Target Q": 134.96021545410156, "Mean Q1": 134.96006994628905, "Mean Q2": 134.96076318359374, "critic_loss": 24.592827377319335, "batch_reward": 1.0934101581573485, "actor_loss": -135.9413801623929, "actor_target_entropy": -1.0, "actor_entropy": 0.2528490213857543, "alpha_loss": -0.0633075415126739, "alpha_value": 0.13052774321163274, "duration": 180.20937180519104, "step": 21000}
{"episode_reward": 127.689032153154, "episode": 169.0, "Q1 loss": 12.290496467590332, "Q2 loss": 12.306411674499511, "Mean Target Q": 135.42901782226562, "Mean Q1": 135.42613244628907, "Mean Q2": 135.42512426757813, "critic_loss": 24.596908142089845, "batch_reward": 1.0928329339027405, "actor_loss": -136.40418812585256, "actor_target_entropy": -1.0, "actor_entropy": 0.2214804862936338, "alpha_loss": -0.05473160072569809, "alpha_value": 0.13117932074340616, "duration": 169.10859179496765, "step": 21125}
{"episode_reward": 187.87641295532993, "episode": 170.0, "Q1 loss": 12.196775901794433, "Q2 loss": 12.234320518493652, "Mean Target Q": 136.17897106933594, "Mean Q1": 136.17436083984376, "Mean Q2": 136.17203356933595, "critic_loss": 24.431096435546873, "batch_reward": 1.099706304550171, "actor_loss": -137.15479377008253, "actor_target_entropy": -1.0, "actor_entropy": 0.22202963766551786, "alpha_loss": -0.05493744357579177, "alpha_value": 0.1318180932818189, "duration": 181.8574676513672, "step": 21250}
{"episode_reward": 221.90864846751697, "episode": 171.0, "Q1 loss": 11.938684623718261, "Q2 loss": 11.9372127532959, "Mean Target Q": 136.57175830078126, "Mean Q1": 136.56526684570312, "Mean Q2": 136.5685469970703, "critic_loss": 23.875897369384766, "batch_reward": 1.09760822057724, "actor_loss": -137.69647289457777, "actor_target_entropy": -1.0, "actor_entropy": 0.18039932935720399, "alpha_loss": -0.054346608500632027, "alpha_value": 0.13246388178365046, "duration": 183.4932873249054, "step": 21375}
{"episode_reward": 208.13231356469515, "episode": 172.0, "Q1 loss": 11.858724716186524, "Q2 loss": 11.895617317199706, "Mean Target Q": 137.244578125, "Mean Q1": 137.23768713378905, "Mean Q2": 137.23721606445312, "critic_loss": 23.754342109680177, "batch_reward": 1.1128757886886598, "actor_loss": -138.30511646886026, "actor_target_entropy": -1.0, "actor_entropy": 0.21752137943140923, "alpha_loss": -0.05660343963292337, "alpha_value": 0.133113876682098, "duration": 168.2918255329132, "step": 21500}
{"episode_reward": 189.70216669151807, "episode": 173.0, "Q1 loss": 11.819279777526855, "Q2 loss": 11.803037628173827, "Mean Target Q": 137.87153283691407, "Mean Q1": 137.87341845703125, "Mean Q2": 137.8727042236328, "critic_loss": 23.622317459106444, "batch_reward": 1.1119430508613586, "actor_loss": -138.79730951218377, "actor_target_entropy": -1.0, "actor_entropy": 0.21049215827905943, "alpha_loss": -0.04388037865005788, "alpha_value": 0.13372276763498356, "duration": 171.52404475212097, "step": 21625}
{"episode_reward": 239.5891412031711, "episode": 174.0, "Q1 loss": 11.50758041381836, "Q2 loss": 11.48082437133789, "Mean Target Q": 138.21947790527344, "Mean Q1": 138.21357751464845, "Mean Q2": 138.21480834960937, "critic_loss": 22.988404708862305, "batch_reward": 1.1119329471588135, "actor_loss": -139.17271004953693, "actor_target_entropy": -1.0, "actor_entropy": 0.20440506896064167, "alpha_loss": -0.04266566371605281, "alpha_value": 0.13426278814112463, "duration": 163.52883768081665, "step": 21750}
{"episode_reward": 214.2524427722387, "episode": 175.0, "Q1 loss": 11.692854904174805, "Q2 loss": 11.785731910705566, "Mean Target Q": 138.8433525390625, "Mean Q1": 138.83875744628907, "Mean Q2": 138.83693676757812, "critic_loss": 23.478586753845214, "batch_reward": 1.1147389025688172, "actor_loss": -139.86587693956164, "actor_target_entropy": -1.0, "actor_entropy": 0.18313583660693394, "alpha_loss": -0.04956156692452847, "alpha_value": 0.1348165085995618, "duration": 145.72318720817566, "step": 21875}
{"episode_reward": 192.0157325597207, "episode": 176.0, "Q1 loss": 11.577931617736816, "Q2 loss": 11.532988174438476, "Mean Target Q": 139.36059887695313, "Mean Q1": 139.3550645751953, "Mean Q2": 139.35675317382814, "critic_loss": 23.110919876098635, "batch_reward": 1.117399670600891, "actor_loss": -140.39000455794795, "actor_target_entropy": -1.0, "actor_entropy": 0.15909336762683046, "alpha_loss": -0.045269040661233086, "alpha_value": 0.13541637530620557, "duration": 157.31278157234192, "step": 22000}
{"episode_reward": 66.04389438100873, "episode": 177.0, "Q1 loss": 11.61517901611328, "Q2 loss": 11.600116111755371, "Mean Target Q": 139.91067260742187, "Mean Q1": 139.90834753417968, "Mean Q2": 139.90662463378905, "critic_loss": 23.215295150756837, "batch_reward": 1.1118489518165589, "actor_loss": -140.87662106468565, "actor_target_entropy": -1.0, "actor_entropy": 0.18169562565901923, "alpha_loss": -0.048855634849695934, "alpha_value": 0.13604463349492565, "duration": 137.9136028289795, "step": 22125}
{"episode_reward": 229.63302857608153, "episode": 178.0, "Q1 loss": 11.400313026428222, "Q2 loss": 11.395736511230469, "Mean Target Q": 140.3931220703125, "Mean Q1": 140.39292517089845, "Mean Q2": 140.394357421875, "critic_loss": 22.796049621582032, "batch_reward": 1.125397276878357, "actor_loss": -141.36475495369203, "actor_target_entropy": -1.0, "actor_entropy": 0.1939439511587543, "alpha_loss": -0.04118603212578643, "alpha_value": 0.1366372813012116, "duration": 127.31636428833008, "step": 22250}
{"episode_reward": 119.26810191378121, "episode": 179.0, "Q1 loss": 11.383131439208984, "Q2 loss": 11.348314506530762, "Mean Target Q": 140.75464782714843, "Mean Q1": 140.74597534179688, "Mean Q2": 140.7454005126953, "critic_loss": 22.73144593811035, "batch_reward": 1.1074221591949462, "actor_loss": -141.6984378875248, "actor_target_entropy": -1.0, "actor_entropy": 0.19648983501016148, "alpha_loss": -0.04588319260686163, "alpha_value": 0.1372427947251307, "duration": 146.88445353507996, "step": 22375}
{"episode_reward": 167.19614896162736, "episode": 180.0, "Q1 loss": 11.170745136260987, "Q2 loss": 11.22283570098877, "Mean Target Q": 141.19289392089843, "Mean Q1": 141.18876916503908, "Mean Q2": 141.18899157714844, "critic_loss": 22.393580772399904, "batch_reward": 1.1154582056999207, "actor_loss": -142.0549082602224, "actor_target_entropy": -1.0, "actor_entropy": 0.1862045435174819, "alpha_loss": -0.04079757557220517, "alpha_value": 0.13782460386676926, "duration": 153.95894169807434, "step": 22500}
{"episode_reward": 200.61133647866313, "episode": 181.0, "Q1 loss": 10.996802459716797, "Q2 loss": 11.007730892181396, "Mean Target Q": 141.72711303710938, "Mean Q1": 141.7214599609375, "Mean Q2": 141.72207580566408, "critic_loss": 22.00453338623047, "batch_reward": 1.1329275560379028, "actor_loss": -142.67269679478235, "actor_target_entropy": -1.0, "actor_entropy": 0.16372746731790286, "alpha_loss": -0.041162166892299575, "alpha_value": 0.1383755896127236, "duration": 167.63751864433289, "step": 22625}
{"episode_reward": 196.6280597018836, "episode": 182.0, "Q1 loss": 10.75981706237793, "Q2 loss": 10.805218597412109, "Mean Target Q": 142.20621276855468, "Mean Q1": 142.20886877441407, "Mean Q2": 142.20713342285157, "critic_loss": 21.56503564453125, "batch_reward": 1.1287904424667359, "actor_loss": -143.05353103145475, "actor_target_entropy": -1.0, "actor_entropy": 0.1427805504250911, "alpha_loss": -0.03696090502724532, "alpha_value": 0.13896138670342725, "duration": 172.58893966674805, "step": 22750}
{"episode_reward": 184.87632530218482, "episode": 183.0, "Q1 loss": 11.204222789764405, "Q2 loss": 11.20559464263916, "Mean Target Q": 142.58888439941407, "Mean Q1": 142.58875817871095, "Mean Q2": 142.59036572265626, "critic_loss": 22.409817428588866, "batch_reward": 1.1345212960243225, "actor_loss": -143.36689927842883, "actor_target_entropy": -1.0, "actor_entropy": 0.1666086335030813, "alpha_loss": -0.0330772251371176, "alpha_value": 0.13947608304291848, "duration": 161.44444489479065, "step": 22875}
{"episode_reward": 198.59119911957933, "episode": 184.0, "Q1 loss": 11.086277057647704, "Q2 loss": 11.127840766906738, "Mean Target Q": 142.93851110839844, "Mean Q1": 142.92920886230468, "Mean Q2": 142.93013635253905, "critic_loss": 22.214117782592773, "batch_reward": 1.1353569011688232, "actor_loss": -143.78572943902785, "actor_target_entropy": -1.0, "actor_entropy": 0.16047384963941672, "alpha_loss": -0.031132289700420392, "alpha_value": 0.1399281063291297, "duration": 163.59443306922913, "step": 23000}
{"episode_reward": 193.65324985856174, "episode": 185.0, "Q1 loss": 10.8851318359375, "Q2 loss": 10.818735832214356, "Mean Target Q": 143.45141516113281, "Mean Q1": 143.45125415039064, "Mean Q2": 143.44887036132812, "critic_loss": 21.70386770629883, "batch_reward": 1.1357104606628419, "actor_loss": -144.2352835034567, "actor_target_entropy": -1.0, "actor_entropy": 0.1383657610369107, "alpha_loss": -0.02858842240409955, "alpha_value": 0.14040214505337942, "duration": 176.1958885192871, "step": 23125}
{"episode_reward": 230.08996463212276, "episode": 186.0, "Q1 loss": 11.270782779693603, "Q2 loss": 11.250999740600585, "Mean Target Q": 143.751552734375, "Mean Q1": 143.7517930908203, "Mean Q2": 143.75282482910157, "critic_loss": 22.521782554626466, "batch_reward": 1.1413063135147095, "actor_loss": -144.62818884080457, "actor_target_entropy": -1.0, "actor_entropy": 0.1729959872581305, "alpha_loss": -0.03179951406444513, "alpha_value": 0.1408756605968805, "duration": 157.64729285240173, "step": 23250}
{"episode_reward": 203.68810235960345, "episode": 187.0, "Q1 loss": 10.91683415222168, "Q2 loss": 10.90768758392334, "Mean Target Q": 144.30029187011718, "Mean Q1": 144.28764001464845, "Mean Q2": 144.28748168945313, "critic_loss": 21.824521743774415, "batch_reward": 1.1423315143585204, "actor_loss": -145.1283448234437, "actor_target_entropy": -1.0, "actor_entropy": 0.1867752925507606, "alpha_loss": -0.033000378082284614, "alpha_value": 0.1414144641981141, "duration": 155.24891591072083, "step": 23375}
{"episode_reward": 171.70259769599738, "episode": 188.0, "Q1 loss": 10.4881623878479, "Q2 loss": 10.531305973052978, "Mean Target Q": 144.69184118652345, "Mean Q1": 144.693603515625, "Mean Q2": 144.69432678222657, "critic_loss": 21.01946842956543, "batch_reward": 1.1434439945220947, "actor_loss": -145.5024177797379, "actor_target_entropy": -1.0, "actor_entropy": 0.15675593848009745, "alpha_loss": -0.037532820756877625, "alpha_value": 0.14194527704631069, "duration": 170.8392734527588, "step": 23500}
{"episode_reward": 296.53441159543115, "episode": 189.0, "Q1 loss": 10.469468143463136, "Q2 loss": 10.470532962799073, "Mean Target Q": 145.10978161621094, "Mean Q1": 145.09976965332032, "Mean Q2": 145.1006171875, "critic_loss": 20.940001121520996, "batch_reward": 1.146196349143982, "actor_loss": -146.045896984282, "actor_target_entropy": -1.0, "actor_entropy": 0.19154460917389582, "alpha_loss": -0.03661206110365807, "alpha_value": 0.1426084538783911, "duration": 172.7715446949005, "step": 23625}
{"episode_reward": 50.60481733165406, "episode": 190.0, "Q1 loss": 10.5808514213562, "Q2 loss": 10.440525646209716, "Mean Target Q": 145.6067325439453, "Mean Q1": 145.60277392578126, "Mean Q2": 145.60364001464845, "critic_loss": 21.02137706756592, "batch_reward": 1.1499761877059937, "actor_loss": -146.33380914503527, "actor_target_entropy": -1.0, "actor_entropy": 0.1775039999235061, "alpha_loss": -0.03347480232496896, "alpha_value": 0.14318832178030924, "duration": 167.87456011772156, "step": 23750}
{"episode_reward": 151.85550905333218, "episode": 191.0, "Q1 loss": 10.595755466461181, "Q2 loss": 10.584129901885987, "Mean Target Q": 145.91057751464842, "Mean Q1": 145.91137268066407, "Mean Q2": 145.91123474121093, "critic_loss": 21.17988543701172, "batch_reward": 1.1504481115341187, "actor_loss": -146.69759235684833, "actor_target_entropy": -1.0, "actor_entropy": 0.17784401667969568, "alpha_loss": -0.029463984393736438, "alpha_value": 0.14373677942332277, "duration": 174.73969173431396, "step": 23875}
{"episode_reward": 216.53959793278753, "episode": 192.0, "Q1 loss": 10.93331436920166, "Q2 loss": 10.9093754196167, "Mean Target Q": 146.31559155273436, "Mean Q1": 146.3118524169922, "Mean Q2": 146.30979040527345, "critic_loss": 21.842689880371093, "batch_reward": 1.1507476749420167, "actor_loss": -147.18074675529235, "actor_target_entropy": -1.0, "actor_entropy": 0.15949475404716307, "alpha_loss": -0.027392572610669078, "alpha_value": 0.14422775445897262, "duration": 170.84644722938538, "step": 24000}
{"episode_reward": 280.2081515746324, "episode": 193.0, "Q1 loss": 10.020575244903565, "Q2 loss": 10.057821640014648, "Mean Target Q": 146.8370037841797, "Mean Q1": 146.83601281738282, "Mean Q2": 146.83631530761718, "critic_loss": 20.0783969039917, "batch_reward": 1.154702070236206, "actor_loss": -147.67773849245103, "actor_target_entropy": -1.0, "actor_entropy": 0.17921689347851844, "alpha_loss": -0.035545958856505064, "alpha_value": 0.14483826100983643, "duration": 172.4294192790985, "step": 24125}
{"episode_reward": 150.6189403344932, "episode": 194.0, "Q1 loss": 10.839070602416992, "Q2 loss": 10.741336540222168, "Mean Target Q": 147.4218508300781, "Mean Q1": 147.41970080566406, "Mean Q2": 147.4215965576172, "critic_loss": 21.58040725708008, "batch_reward": 1.167814679145813, "actor_loss": -148.2571009974326, "actor_target_entropy": -1.0, "actor_entropy": 0.1715757117396401, "alpha_loss": -0.033652815539690274, "alpha_value": 0.14546255608377362, "duration": 181.20277190208435, "step": 24250}
{"episode_reward": 237.16050981199376, "episode": 195.0, "Q1 loss": 10.382174304962158, "Q2 loss": 10.283220134735107, "Mean Target Q": 147.6722547607422, "Mean Q1": 147.6629921875, "Mean Q2": 147.66296643066406, "critic_loss": 20.66539436340332, "batch_reward": 1.1486982574462892, "actor_loss": -148.52003454783605, "actor_target_entropy": -1.0, "actor_entropy": 0.15197928620886708, "alpha_loss": -0.02876499719503853, "alpha_value": 0.14605081925120553, "duration": 169.06738591194153, "step": 24375}
{"episode_reward": 178.31183521699504, "episode": 196.0, "Q1 loss": 10.033211883544922, "Q2 loss": 9.970698238372803, "Mean Target Q": 147.955548828125, "Mean Q1": 147.9556251220703, "Mean Q2": 147.95721594238282, "critic_loss": 20.003910110473633, "batch_reward": 1.16678586101532, "actor_loss": -148.74280252764302, "actor_target_entropy": -1.0, "actor_entropy": 0.14489675524284043, "alpha_loss": -0.027668943185539495, "alpha_value": 0.14661818919098035, "duration": 176.45768642425537, "step": 24500}
{"episode_reward": 187.90812394856113, "episode": 197.0, "Q1 loss": 10.361262252807617, "Q2 loss": 10.381308155059815, "Mean Target Q": 148.42635559082032, "Mean Q1": 148.42767687988282, "Mean Q2": 148.42710998535156, "critic_loss": 20.74257042694092, "batch_reward": 1.1655522928237916, "actor_loss": -149.2726585751488, "actor_target_entropy": -1.0, "actor_entropy": 0.15199385784448138, "alpha_loss": -0.030368120527811467, "alpha_value": 0.14719029993558896, "duration": 184.40611147880554, "step": 24625}
{"episode_reward": 241.95623163205943, "episode": 198.0, "Q1 loss": 10.395587467193604, "Q2 loss": 10.40129462814331, "Mean Target Q": 148.95701525878906, "Mean Q1": 148.9482706298828, "Mean Q2": 148.94799426269532, "critic_loss": 20.79688208770752, "batch_reward": 1.1661109848022462, "actor_loss": -149.76893468056954, "actor_target_entropy": -1.0, "actor_entropy": 0.18810841080642515, "alpha_loss": -0.02471479145817519, "alpha_value": 0.1477204556934662, "duration": 167.6526038646698, "step": 24750}
{"episode_reward": 222.31675004004802, "episode": 199.0, "Q1 loss": 10.168215530395507, "Q2 loss": 10.19064665222168, "Mean Target Q": 149.28814697265625, "Mean Q1": 149.27758728027345, "Mean Q2": 149.27831005859375, "critic_loss": 20.358862159729004, "batch_reward": 1.167290862083435, "actor_loss": -150.12994142562624, "actor_target_entropy": -1.0, "actor_entropy": 0.15307533705518359, "alpha_loss": -0.025224922598147438, "alpha_value": 0.14824584445864522, "duration": 170.6510944366455, "step": 24875}
{"episode_reward": 208.5587751464965, "episode": 200.0, "Q1 loss": 10.051798950195312, "Q2 loss": 10.0085326461792, "Mean Target Q": 149.7735651855469, "Mean Q1": 149.78176904296876, "Mean Q2": 149.78026416015626, "critic_loss": 20.06033155822754, "batch_reward": 1.17269734954834, "actor_loss": -150.59686746904927, "actor_target_entropy": -1.0, "actor_entropy": 0.13825246153940116, "alpha_loss": -0.020732288718253614, "alpha_value": 0.1487233928717164, "step": 25000}
{"duration": 183.18866562843323, "step": 25000}
{"episode_reward": 246.85200941995714, "episode": 201.0, "Q1 loss": 10.343532096862793, "Q2 loss": 10.30733910369873, "Mean Target Q": 150.12796252441407, "Mean Q1": 150.11872436523439, "Mean Q2": 150.11783459472656, "critic_loss": 20.650871116638182, "batch_reward": 1.1784159049987792, "actor_loss": -150.9195343501984, "actor_target_entropy": -1.0, "actor_entropy": 0.11541731710294409, "alpha_loss": -0.018047021053332304, "alpha_value": 0.14909417805914452, "duration": 178.20842027664185, "step": 25125}
{"episode_reward": 166.57830928021374, "episode": 202.0, "Q1 loss": 10.151000156402588, "Q2 loss": 10.13127452468872, "Mean Target Q": 150.49249890136718, "Mean Q1": 150.49076098632813, "Mean Q2": 150.48969091796874, "critic_loss": 20.282274787902832, "batch_reward": 1.1704349098205566, "actor_loss": -151.29264216269218, "actor_target_entropy": -1.0, "actor_entropy": 0.11079420482799891, "alpha_loss": -0.016741425895522678, "alpha_value": 0.14952962782630852, "duration": 166.079487323761, "step": 25250}
{"episode_reward": 132.85693059409817, "episode": 203.0, "Q1 loss": 10.224646339416504, "Q2 loss": 10.282807258605956, "Mean Target Q": 150.81318212890625, "Mean Q1": 150.80969665527343, "Mean Q2": 150.8113623046875, "critic_loss": 20.507453536987306, "batch_reward": 1.17831925201416, "actor_loss": -151.69664534311445, "actor_target_entropy": -1.0, "actor_entropy": 0.12844158194604374, "alpha_loss": -0.021706364583224058, "alpha_value": 0.14999280398203624, "duration": 157.07392501831055, "step": 25375}
{"episode_reward": 169.4718347624397, "episode": 204.0, "Q1 loss": 10.21787716293335, "Q2 loss": 10.215859409332275, "Mean Target Q": 151.12164025878906, "Mean Q1": 151.1174443359375, "Mean Q2": 151.11785791015626, "critic_loss": 20.43373657989502, "batch_reward": 1.181065276145935, "actor_loss": -151.92449705062373, "actor_target_entropy": -1.0, "actor_entropy": 0.12321154902418775, "alpha_loss": -0.02066661235726168, "alpha_value": 0.15047000072918718, "duration": 172.72843074798584, "step": 25500}
{"episode_reward": 202.14131526214098, "episode": 205.0, "Q1 loss": 9.808629024505615, "Q2 loss": 9.855476303100586, "Mean Target Q": 151.62125463867187, "Mean Q1": 151.62078210449218, "Mean Q2": 151.61919470214843, "critic_loss": 19.6641053314209, "batch_reward": 1.182956048965454, "actor_loss": -152.5263478112599, "actor_target_entropy": -1.0, "actor_entropy": 0.12200019272073867, "alpha_loss": -0.020365701496808067, "alpha_value": 0.1509131693500195, "duration": 163.60295414924622, "step": 25625}
{"episode_reward": 215.68271158761962, "episode": 206.0, "Q1 loss": 9.921427585601807, "Q2 loss": 9.895360626220704, "Mean Target Q": 151.92027880859376, "Mean Q1": 151.9153575439453, "Mean Q2": 151.91614123535157, "critic_loss": 19.816788261413574, "batch_reward": 1.185667776107788, "actor_loss": -152.79402209866433, "actor_target_entropy": -1.0, "actor_entropy": 0.1332433203295354, "alpha_loss": -0.021019786032998273, "alpha_value": 0.15143550707524098, "duration": 178.65435981750488, "step": 25750}
{"episode_reward": 222.8367236770834, "episode": 207.0, "Q1 loss": 9.793840515136718, "Q2 loss": 9.78826774597168, "Mean Target Q": 152.25928735351562, "Mean Q1": 152.26215454101563, "Mean Q2": 152.26397106933592, "critic_loss": 19.582108222961427, "batch_reward": 1.1918964405059815, "actor_loss": -153.07165600004652, "actor_target_entropy": -1.0, "actor_entropy": 0.15028994317565644, "alpha_loss": -0.020958482764572614, "alpha_value": 0.15195074079867724, "duration": 187.67162990570068, "step": 25875}
{"episode_reward": 216.66250639046703, "episode": 208.0, "Q1 loss": 10.298645927429199, "Q2 loss": 10.31254029083252, "Mean Target Q": 152.6803298339844, "Mean Q1": 152.67335205078126, "Mean Q2": 152.6738553466797, "critic_loss": 20.611186210632326, "batch_reward": 1.1836479377746583, "actor_loss": -153.57937425182712, "actor_target_entropy": -1.0, "actor_entropy": 0.10686769657918523, "alpha_loss": -0.019123589458514847, "alpha_value": 0.15247305947610523, "duration": 169.6404323577881, "step": 26000}
{"episode_reward": 218.27714106234777, "episode": 209.0, "Q1 loss": 10.112358840942383, "Q2 loss": 10.065961170196534, "Mean Target Q": 153.04592126464843, "Mean Q1": 153.04380493164064, "Mean Q2": 153.0437236328125, "critic_loss": 20.178320014953613, "batch_reward": 1.1888943576812745, "actor_loss": -153.94810679602244, "actor_target_entropy": -1.0, "actor_entropy": 0.11229154307927404, "alpha_loss": -0.02454517500489832, "alpha_value": 0.15302826540221712, "duration": 164.11315250396729, "step": 26125}
{"episode_reward": 227.9230778961631, "episode": 210.0, "Q1 loss": 10.496213470458985, "Q2 loss": 10.42187406539917, "Mean Target Q": 153.34670227050782, "Mean Q1": 153.3465549316406, "Mean Q2": 153.34534326171874, "critic_loss": 20.918087493896483, "batch_reward": 1.1882277698516845, "actor_loss": -154.16221495597594, "actor_target_entropy": -1.0, "actor_entropy": 0.11897984055441714, "alpha_loss": -0.018412368075411405, "alpha_value": 0.1535952514537764, "duration": 174.98867654800415, "step": 26250}
{"episode_reward": 292.97622208492703, "episode": 211.0, "Q1 loss": 10.809209064483642, "Q2 loss": 10.812490036010741, "Mean Target Q": 153.7736389160156, "Mean Q1": 153.76558056640624, "Mean Q2": 153.7692813720703, "critic_loss": 21.6216990814209, "batch_reward": 1.198567702293396, "actor_loss": -154.60023111010355, "actor_target_entropy": -1.0, "actor_entropy": 0.0894399688150438, "alpha_loss": -0.015640872835536442, "alpha_value": 0.15409681079124182, "duration": 175.23801279067993, "step": 26375}
{"episode_reward": 209.80603671327535, "episode": 212.0, "Q1 loss": 11.20751318359375, "Q2 loss": 11.18288209915161, "Mean Target Q": 154.10147973632812, "Mean Q1": 154.0970086669922, "Mean Q2": 154.09249377441407, "critic_loss": 22.390395210266114, "batch_reward": 1.1981856327056886, "actor_loss": -154.9800095096711, "actor_target_entropy": -1.0, "actor_entropy": 0.11249547674050255, "alpha_loss": -0.014354021440545518, "alpha_value": 0.15444616130459735, "duration": 173.07947993278503, "step": 26500}
{"episode_reward": 282.2359841889638, "episode": 213.0, "Q1 loss": 10.449837326049805, "Q2 loss": 10.414098182678222, "Mean Target Q": 154.42487646484375, "Mean Q1": 154.42514599609376, "Mean Q2": 154.4271003417969, "critic_loss": 20.86393541717529, "batch_reward": 1.203849048614502, "actor_loss": -155.31519862583704, "actor_target_entropy": -1.0, "actor_entropy": 0.13572583489474796, "alpha_loss": -0.01422785353913371, "alpha_value": 0.15485261271554002, "duration": 143.8545253276825, "step": 26625}
{"episode_reward": 221.09967491662846, "episode": 214.0, "Q1 loss": 10.60340470123291, "Q2 loss": 10.667692153930664, "Mean Target Q": 154.85671740722657, "Mean Q1": 154.85050439453124, "Mean Q2": 154.8522293701172, "critic_loss": 21.271096893310546, "batch_reward": 1.2119546461105346, "actor_loss": -155.84718618085307, "actor_target_entropy": -1.0, "actor_entropy": 0.15234563535740298, "alpha_loss": -0.01459500432247296, "alpha_value": 0.15527957141047213, "duration": 182.66930103302002, "step": 26750}
{"episode_reward": 211.6813229520511, "episode": 215.0, "Q1 loss": 10.749761848449706, "Q2 loss": 10.739487083435058, "Mean Target Q": 155.06870703125, "Mean Q1": 155.06860375976564, "Mean Q2": 155.06687512207031, "critic_loss": 21.489248908996583, "batch_reward": 1.2043403472900391, "actor_loss": -155.96266561841207, "actor_target_entropy": -1.0, "actor_entropy": 0.15339989221048733, "alpha_loss": -0.010728399413416074, "alpha_value": 0.15566423864415105, "duration": 179.114324092865, "step": 26875}
{"episode_reward": 253.87810943333764, "episode": 216.0, "Q1 loss": 11.08367739868164, "Q2 loss": 11.013039047241211, "Mean Target Q": 155.41672534179688, "Mean Q1": 155.41216381835937, "Mean Q2": 155.4131014404297, "critic_loss": 22.09671649169922, "batch_reward": 1.2130061769485474, "actor_loss": -156.38102623724168, "actor_target_entropy": -1.0, "actor_entropy": 0.19753286963508976, "alpha_loss": -0.01340473949488613, "alpha_value": 0.15603332372003245, "duration": 162.98362803459167, "step": 27000}
{"episode_reward": 173.77062202438097, "episode": 217.0, "Q1 loss": 11.326457077026367, "Q2 loss": 11.261469772338867, "Mean Target Q": 155.84630029296875, "Mean Q1": 155.85191247558595, "Mean Q2": 155.84862658691407, "critic_loss": 22.587926849365235, "batch_reward": 1.2140087594985962, "actor_loss": -156.7347436329675, "actor_target_entropy": -1.0, "actor_entropy": 0.1362840278399369, "alpha_loss": -0.018841663020707312, "alpha_value": 0.15654473117135254, "duration": 182.86003851890564, "step": 27125}
{"episode_reward": 240.8462323346139, "episode": 218.0, "Q1 loss": 11.308708175659179, "Q2 loss": 11.338186897277833, "Mean Target Q": 156.1830098876953, "Mean Q1": 156.17168566894532, "Mean Q2": 156.17472985839845, "critic_loss": 22.646895111083985, "batch_reward": 1.220623384475708, "actor_loss": -157.15449893090033, "actor_target_entropy": -1.0, "actor_entropy": 0.12039002408123305, "alpha_loss": -0.020611646990742413, "alpha_value": 0.1571517101975122, "duration": 158.49657011032104, "step": 27250}
{"episode_reward": 134.1661847150794, "episode": 219.0, "Q1 loss": 11.427180923461915, "Q2 loss": 11.448520362854003, "Mean Target Q": 156.5753786621094, "Mean Q1": 156.57278173828124, "Mean Q2": 156.5714431152344, "critic_loss": 22.875701278686524, "batch_reward": 1.223383912086487, "actor_loss": -157.49378749302454, "actor_target_entropy": -1.0, "actor_entropy": 0.1652811085657468, "alpha_loss": -0.022549263866884366, "alpha_value": 0.15782463452877016, "duration": 171.03372740745544, "step": 27375}
{"episode_reward": 202.50004906836946, "episode": 220.0, "Q1 loss": 11.068183959960937, "Q2 loss": 10.99292812347412, "Mean Target Q": 156.75650646972656, "Mean Q1": 156.7563692626953, "Mean Q2": 156.75718981933593, "critic_loss": 22.061111946105957, "batch_reward": 1.2050308246612549, "actor_loss": -157.61725247290826, "actor_target_entropy": -1.0, "actor_entropy": 0.15431717446734827, "alpha_loss": -0.012598402711803154, "alpha_value": 0.15840682252675417, "duration": 175.2236304283142, "step": 27500}
{"episode_reward": 152.76666610034923, "episode": 221.0, "Q1 loss": 10.88651121520996, "Q2 loss": 10.838071823120117, "Mean Target Q": 157.18156750488282, "Mean Q1": 157.17909350585938, "Mean Q2": 157.1798146972656, "critic_loss": 21.72458302307129, "batch_reward": 1.217463716506958, "actor_loss": -158.13173542325458, "actor_target_entropy": -1.0, "actor_entropy": 0.1529620530468131, "alpha_loss": -0.012554043672964095, "alpha_value": 0.1588474313272642, "duration": 179.76280331611633, "step": 27625}
{"episode_reward": 170.87608044473234, "episode": 222.0, "Q1 loss": 11.545324699401856, "Q2 loss": 11.531302688598632, "Mean Target Q": 157.41770471191407, "Mean Q1": 157.41736181640624, "Mean Q2": 157.41544140625, "critic_loss": 23.076627334594725, "batch_reward": 1.214068244934082, "actor_loss": -158.380739027454, "actor_target_entropy": -1.0, "actor_entropy": 0.17124715429400245, "alpha_loss": -0.008342939141702147, "alpha_value": 0.1592185122341539, "duration": 182.4374520778656, "step": 27750}
{"episode_reward": 213.47260631695534, "episode": 223.0, "Q1 loss": 10.689376693725587, "Q2 loss": 10.664991165161133, "Mean Target Q": 157.76658239746095, "Mean Q1": 157.7611964111328, "Mean Q2": 157.76398388671876, "critic_loss": 21.354367935180665, "batch_reward": 1.2165142936706543, "actor_loss": -158.66344488234748, "actor_target_entropy": -1.0, "actor_entropy": 0.165955931303047, "alpha_loss": -0.010026112939822413, "alpha_value": 0.1594585631707334, "duration": 163.97349786758423, "step": 27875}
{"episode_reward": 188.86241869396005, "episode": 224.0, "Q1 loss": 10.733135795593261, "Q2 loss": 10.70376531982422, "Mean Target Q": 158.1588397216797, "Mean Q1": 158.15599584960938, "Mean Q2": 158.15485998535155, "critic_loss": 21.436901123046876, "batch_reward": 1.2246166286468505, "actor_loss": -159.10665179837136, "actor_target_entropy": -1.0, "actor_entropy": 0.14201737895247438, "alpha_loss": -0.016388816612532303, "alpha_value": 0.15995954380052857, "duration": 180.2646622657776, "step": 28000}
{"episode_reward": 278.78601453273774, "episode": 225.0, "Q1 loss": 11.00000119781494, "Q2 loss": 11.025078742980957, "Mean Target Q": 158.55052819824218, "Mean Q1": 158.5459677734375, "Mean Q2": 158.54575451660156, "critic_loss": 22.025079864501954, "batch_reward": 1.2311265201568604, "actor_loss": -159.47891937740266, "actor_target_entropy": -1.0, "actor_entropy": 0.14573002174969704, "alpha_loss": -0.009242757402789143, "alpha_value": 0.16041365633941498, "duration": 175.91637635231018, "step": 28125}
{"episode_reward": 267.0390670753749, "episode": 226.0, "Q1 loss": 10.826401260375977, "Q2 loss": 10.812263603210448, "Mean Target Q": 158.7295643310547, "Mean Q1": 158.7220213623047, "Mean Q2": 158.7203095703125, "critic_loss": 21.63866487121582, "batch_reward": 1.2282349424362182, "actor_loss": -159.6457750874181, "actor_target_entropy": -1.0, "actor_entropy": 0.14003249960801295, "alpha_loss": -0.012706776322316258, "alpha_value": 0.16086573877510033, "duration": 168.55653190612793, "step": 28250}
{"episode_reward": 213.43063664011842, "episode": 227.0, "Q1 loss": 11.016909774780274, "Q2 loss": 11.081938514709472, "Mean Target Q": 159.05863317871095, "Mean Q1": 159.06582446289062, "Mean Q2": 159.06568237304688, "critic_loss": 22.098848281860352, "batch_reward": 1.23611093044281, "actor_loss": -159.98089430067273, "actor_target_entropy": -1.0, "actor_entropy": 0.14700119117540972, "alpha_loss": -0.006870845746662881, "alpha_value": 0.16114960304275797, "duration": 165.22490215301514, "step": 28375}
{"episode_reward": 132.04757518339454, "episode": 228.0, "Q1 loss": 11.192847095489501, "Q2 loss": 11.193300048828124, "Mean Target Q": 159.50026159667968, "Mean Q1": 159.49400695800782, "Mean Q2": 159.4956473388672, "critic_loss": 22.38614710998535, "batch_reward": 1.2346233959197999, "actor_loss": -160.43620324903918, "actor_target_entropy": -1.0, "actor_entropy": 0.14392223677808239, "alpha_loss": -0.008281644392428138, "alpha_value": 0.16148628568710077, "duration": 169.40829944610596, "step": 28500}
{"episode_reward": 168.88875320439112, "episode": 229.0, "Q1 loss": 11.255771995544434, "Q2 loss": 11.196418395996094, "Mean Target Q": 159.6824442138672, "Mean Q1": 159.68308520507813, "Mean Q2": 159.6820009765625, "critic_loss": 22.452190307617187, "batch_reward": 1.2257257480621337, "actor_loss": -160.58309984964038, "actor_target_entropy": -1.0, "actor_entropy": 0.180321308325917, "alpha_loss": -0.00815113493063975, "alpha_value": 0.16186564930500313, "duration": 178.23876905441284, "step": 28625}
{"episode_reward": 252.10474820202913, "episode": 230.0, "Q1 loss": 10.865353034973145, "Q2 loss": 10.800338188171386, "Mean Target Q": 160.09405603027344, "Mean Q1": 160.08132678222657, "Mean Q2": 160.08290100097656, "critic_loss": 21.665691207885743, "batch_reward": 1.2384328231811523, "actor_loss": -161.0287566646453, "actor_target_entropy": -1.0, "actor_entropy": 0.13626961518199213, "alpha_loss": -0.011279511918884612, "alpha_value": 0.16220357913655958, "duration": 178.0482075214386, "step": 28750}
{"episode_reward": 198.60096375145997, "episode": 231.0, "Q1 loss": 10.721858612060547, "Q2 loss": 10.68429759979248, "Mean Target Q": 160.31959887695314, "Mean Q1": 160.3195557861328, "Mean Q2": 160.3225812988281, "critic_loss": 21.406156127929687, "batch_reward": 1.22474782371521, "actor_loss": -161.20025077698722, "actor_target_entropy": -1.0, "actor_entropy": 0.1420117692933196, "alpha_loss": -0.011112112566710465, "alpha_value": 0.1626453968193655, "duration": 174.07077765464783, "step": 28875}
{"episode_reward": 191.1502138476277, "episode": 232.0, "Q1 loss": 10.729966209411621, "Q2 loss": 10.720006637573242, "Mean Target Q": 160.63986560058595, "Mean Q1": 160.6409248046875, "Mean Q2": 160.63758520507812, "critic_loss": 21.449972869873047, "batch_reward": 1.2397731742858886, "actor_loss": -161.62478859193862, "actor_target_entropy": -1.0, "actor_entropy": 0.14386382717038354, "alpha_loss": -0.014577144336315894, "alpha_value": 0.1631672089539812, "duration": 160.8964605331421, "step": 29000}
{"episode_reward": 223.29679278992077, "episode": 233.0, "Q1 loss": 10.560711353302002, "Q2 loss": 10.579263690948487, "Mean Target Q": 160.91891650390625, "Mean Q1": 160.9162684326172, "Mean Q2": 160.91544604492188, "critic_loss": 21.13997508239746, "batch_reward": 1.2435732679367066, "actor_loss": -161.84224688817585, "actor_target_entropy": -1.0, "actor_entropy": 0.11750365861706318, "alpha_loss": -0.018389744610185662, "alpha_value": 0.16391163756730817, "duration": 171.33957481384277, "step": 29125}
{"episode_reward": 289.07425621884306, "episode": 234.0, "Q1 loss": 10.74793798828125, "Q2 loss": 10.758726882934571, "Mean Target Q": 161.24778796386718, "Mean Q1": 161.24911975097658, "Mean Q2": 161.24773034667967, "critic_loss": 21.50666481781006, "batch_reward": 1.2479054956436157, "actor_loss": -162.1646447950794, "actor_target_entropy": -1.0, "actor_entropy": 0.14276099499435194, "alpha_loss": -0.01409100216152447, "alpha_value": 0.16463071455276138, "duration": 163.0247287750244, "step": 29250}
{"episode_reward": 183.5682403810135, "episode": 235.0, "Q1 loss": 10.749027500152588, "Q2 loss": 10.626000728607178, "Mean Target Q": 161.5391162109375, "Mean Q1": 161.53119812011718, "Mean Q2": 161.53389916992188, "critic_loss": 21.375028366088866, "batch_reward": 1.248381856918335, "actor_loss": -162.46702914767795, "actor_target_entropy": -1.0, "actor_entropy": 0.16012602914420385, "alpha_loss": -0.010354626744556877, "alpha_value": 0.16519826229256102, "duration": 171.2530620098114, "step": 29375}
{"episode_reward": 190.95393068637895, "episode": 236.0, "Q1 loss": 10.763621498107911, "Q2 loss": 10.736151580810548, "Mean Target Q": 161.68710705566406, "Mean Q1": 161.6779522705078, "Mean Q2": 161.6749403076172, "critic_loss": 21.49977308654785, "batch_reward": 1.2360941553115845, "actor_loss": -162.51325865714782, "actor_target_entropy": -1.0, "actor_entropy": 0.1541528947831642, "alpha_loss": -0.00921745258270793, "alpha_value": 0.16558662072867514, "duration": 179.83357739448547, "step": 29500}
{"episode_reward": 144.90994644232592, "episode": 237.0, "Q1 loss": 11.148167922973633, "Q2 loss": 11.119266193389892, "Mean Target Q": 162.08042736816407, "Mean Q1": 162.08171716308593, "Mean Q2": 162.08317602539063, "critic_loss": 22.267434173583986, "batch_reward": 1.2531145048141479, "actor_loss": -163.09114316910032, "actor_target_entropy": -1.0, "actor_entropy": 0.1750559283509141, "alpha_loss": -0.007726325890019772, "alpha_value": 0.16584994484138663, "duration": 176.44304275512695, "step": 29625}
{"episode_reward": 227.48141528460891, "episode": 238.0, "Q1 loss": 10.854335876464845, "Q2 loss": 10.853928550720214, "Mean Target Q": 162.4655262451172, "Mean Q1": 162.4661875, "Mean Q2": 162.46579516601562, "critic_loss": 21.708264503479004, "batch_reward": 1.2480222673416137, "actor_loss": -163.3343011179278, "actor_target_entropy": -1.0, "actor_entropy": 0.12718729861080647, "alpha_loss": -0.01190547588198716, "alpha_value": 0.1663504267396384, "duration": 177.37038278579712, "step": 29750}
{"episode_reward": 230.34573337861028, "episode": 239.0, "Q1 loss": 10.725860572814941, "Q2 loss": 10.660897499084472, "Mean Target Q": 162.673337890625, "Mean Q1": 162.67044384765626, "Mean Q2": 162.67240209960937, "critic_loss": 21.386757995605468, "batch_reward": 1.2588579921722411, "actor_loss": -163.58452545650422, "actor_target_entropy": -1.0, "actor_entropy": 0.14215218660140794, "alpha_loss": -0.010547437828906353, "alpha_value": 0.16684008454385157, "duration": 165.08192443847656, "step": 29875}
{"episode_reward": 186.34260056365255, "episode": 240.0, "Q1 loss": 10.91639143371582, "Q2 loss": 10.946861236572266, "Mean Target Q": 162.94508508300783, "Mean Q1": 162.944681640625, "Mean Q2": 162.94284143066406, "critic_loss": 21.86325274658203, "batch_reward": 1.24791681098938, "actor_loss": -163.92262883340157, "actor_target_entropy": -1.0, "actor_entropy": 0.15199815115380672, "alpha_loss": -0.013016533084033478, "alpha_value": 0.16744570547972976, "step": 30000}
{"duration": 184.22742986679077, "step": 30000}
{"episode_reward": 187.16678966535127, "episode": 241.0, "Q1 loss": 10.852283157348634, "Q2 loss": 10.845201927185059, "Mean Target Q": 163.23242932128906, "Mean Q1": 163.22741748046874, "Mean Q2": 163.22650549316407, "critic_loss": 21.697485107421876, "batch_reward": 1.2536639938354492, "actor_loss": -164.19550529358878, "actor_target_entropy": -1.0, "actor_entropy": 0.13684770269762903, "alpha_loss": -0.010939484473229164, "alpha_value": 0.1679459358314899, "duration": 178.0579731464386, "step": 30125}
{"episode_reward": 178.41795879231123, "episode": 242.0, "Q1 loss": 10.936925720214843, "Q2 loss": 10.97622747039795, "Mean Target Q": 163.45628381347657, "Mean Q1": 163.45226892089843, "Mean Q2": 163.45375024414062, "critic_loss": 21.913153244018556, "batch_reward": 1.2486463022232055, "actor_loss": -164.39064173544608, "actor_target_entropy": -1.0, "actor_entropy": 0.11772262118756771, "alpha_loss": -0.011014622853948705, "alpha_value": 0.16849677731255389, "duration": 166.47769236564636, "step": 30250}
{"episode_reward": 176.4719976774302, "episode": 243.0, "Q1 loss": 10.582594551086427, "Q2 loss": 10.564560447692871, "Mean Target Q": 163.81304833984376, "Mean Q1": 163.80422802734375, "Mean Q2": 163.80223449707032, "critic_loss": 21.147155014038084, "batch_reward": 1.256075475692749, "actor_loss": -164.71523103259858, "actor_target_entropy": -1.0, "actor_entropy": 0.1502703313553144, "alpha_loss": -0.009129138105356741, "alpha_value": 0.16900490079095212, "duration": 170.52863192558289, "step": 30375}
{"episode_reward": 180.02345229396448, "episode": 244.0, "Q1 loss": 11.147212089538574, "Q2 loss": 11.087016166687011, "Mean Target Q": 164.07285510253905, "Mean Q1": 164.08215795898437, "Mean Q2": 164.0842264404297, "critic_loss": 22.234228240966797, "batch_reward": 1.2605002393722535, "actor_loss": -164.92041483233052, "actor_target_entropy": -1.0, "actor_entropy": 0.13058068299846304, "alpha_loss": -0.01062745190668671, "alpha_value": 0.16949389025529887, "duration": 176.37062573432922, "step": 30500}
{"episode_reward": 240.81296658351872, "episode": 245.0, "Q1 loss": 10.992621643066407, "Q2 loss": 11.02147727203369, "Mean Target Q": 164.35892004394532, "Mean Q1": 164.3532255859375, "Mean Q2": 164.35354321289063, "critic_loss": 22.01409893798828, "batch_reward": 1.2637454023361205, "actor_loss": -165.25764489552333, "actor_target_entropy": -1.0, "actor_entropy": 0.12326679559099296, "alpha_loss": -0.017948377640947463, "alpha_value": 0.17024801670739997, "duration": 170.20423364639282, "step": 30625}
{"episode_reward": 266.38246420439305, "episode": 246.0, "Q1 loss": 11.163002601623536, "Q2 loss": 11.080015274047852, "Mean Target Q": 164.72222521972657, "Mean Q1": 164.70596533203124, "Mean Q2": 164.7063739013672, "critic_loss": 22.243017860412596, "batch_reward": 1.2590256576538086, "actor_loss": -165.6981471892326, "actor_target_entropy": -1.0, "actor_entropy": 0.14935222305657883, "alpha_loss": -0.013556024087818279, "alpha_value": 0.170963979032562, "duration": 159.718008518219, "step": 30750}
{"episode_reward": 275.0416530048161, "episode": 247.0, "Q1 loss": 11.216128662109375, "Q2 loss": 11.228855087280273, "Mean Target Q": 165.08609545898437, "Mean Q1": 165.0936619873047, "Mean Q2": 165.09462707519532, "critic_loss": 22.444983825683593, "batch_reward": 1.273470950126648, "actor_loss": -165.9742719862196, "actor_target_entropy": -1.0, "actor_entropy": 0.16599313215544773, "alpha_loss": -0.016486769386877615, "alpha_value": 0.17176780293773722, "duration": 175.54565715789795, "step": 30875}
{"episode_reward": 193.0588096506369, "episode": 248.0, "Q1 loss": 10.918806999206543, "Q2 loss": 10.898901275634765, "Mean Target Q": 165.33044873046876, "Mean Q1": 165.3218701171875, "Mean Q2": 165.32098217773438, "critic_loss": 21.817708251953125, "batch_reward": 1.2657328786849975, "actor_loss": -166.2810568040417, "actor_target_entropy": -1.0, "actor_entropy": 0.1580386691756787, "alpha_loss": -0.016745162250909714, "alpha_value": 0.17260511976913032, "duration": 169.41245818138123, "step": 31000}
{"episode_reward": 267.2801823467323, "episode": 249.0, "Q1 loss": 11.01340810394287, "Q2 loss": 10.96593157196045, "Mean Target Q": 165.56866857910157, "Mean Q1": 165.57265393066407, "Mean Q2": 165.57088623046874, "critic_loss": 21.979339645385743, "batch_reward": 1.268262393951416, "actor_loss": -166.59687054346477, "actor_target_entropy": -1.0, "actor_entropy": 0.17610518149440252, "alpha_loss": -0.014349727523660967, "alpha_value": 0.1732885103111666, "duration": 159.86971783638, "step": 31125}
{"episode_reward": 273.627615922013, "episode": 250.0, "Q1 loss": 10.783555824279786, "Q2 loss": 10.816229461669922, "Mean Target Q": 166.02351062011718, "Mean Q1": 166.01758032226562, "Mean Q2": 166.01970300292967, "critic_loss": 21.599785369873047, "batch_reward": 1.2818842153549195, "actor_loss": -166.9321001114384, "actor_target_entropy": -1.0, "actor_entropy": 0.17616102315725818, "alpha_loss": -0.0051647386468586425, "alpha_value": 0.1738211217089331, "duration": 171.10929703712463, "step": 31250}
{"episode_reward": 274.36931649431534, "episode": 251.0, "Q1 loss": 11.124882202148438, "Q2 loss": 11.185736335754395, "Mean Target Q": 166.3328095703125, "Mean Q1": 166.3336788330078, "Mean Q2": 166.33063525390625, "critic_loss": 22.31061851501465, "batch_reward": 1.2867673606872558, "actor_loss": -167.25824362134176, "actor_target_entropy": -1.0, "actor_entropy": 0.16692683112526696, "alpha_loss": -0.01412540327181064, "alpha_value": 0.1743952681408803, "duration": 171.95582747459412, "step": 31375}
{"episode_reward": 241.75775053500948, "episode": 252.0, "Q1 loss": 10.904285705566407, "Q2 loss": 10.87233277130127, "Mean Target Q": 166.60429272460937, "Mean Q1": 166.59617602539063, "Mean Q2": 166.59804016113281, "critic_loss": 21.776618362426756, "batch_reward": 1.279292158126831, "actor_loss": -167.44822520594442, "actor_target_entropy": -1.0, "actor_entropy": 0.15911970047220106, "alpha_loss": -0.010263708450140492, "alpha_value": 0.17498827258906283, "duration": 169.06882452964783, "step": 31500}
{"episode_reward": 250.79525813256558, "episode": 253.0, "Q1 loss": 10.436514587402344, "Q2 loss": 10.345525310516358, "Mean Target Q": 166.89826086425782, "Mean Q1": 166.89771252441406, "Mean Q2": 166.89805505371095, "critic_loss": 20.782039916992186, "batch_reward": 1.2963507623672486, "actor_loss": -167.8382815406436, "actor_target_entropy": -1.0, "actor_entropy": 0.16613402343281206, "alpha_loss": -0.014341055323177624, "alpha_value": 0.175586480663517, "duration": 170.26706099510193, "step": 31625}
{"episode_reward": 259.9445298865993, "episode": 254.0, "Q1 loss": 10.62804125213623, "Q2 loss": 10.6732123336792, "Mean Target Q": 167.1632371826172, "Mean Q1": 167.15694116210938, "Mean Q2": 167.15490905761717, "critic_loss": 21.301253616333007, "batch_reward": 1.2924617433547974, "actor_loss": -168.08198793472783, "actor_target_entropy": -1.0, "actor_entropy": 0.1856062765563688, "alpha_loss": -0.01603393153768153, "alpha_value": 0.17632690396255093, "duration": 177.49286937713623, "step": 31750}
{"episode_reward": 148.89517246913002, "episode": 255.0, "Q1 loss": 10.728053443908692, "Q2 loss": 10.679652027130127, "Mean Target Q": 167.605130859375, "Mean Q1": 167.60555822753906, "Mean Q2": 167.60705310058594, "critic_loss": 21.407705474853515, "batch_reward": 1.2975536623001098, "actor_loss": -168.49874345083086, "actor_target_entropy": -1.0, "actor_entropy": 0.16725948866870669, "alpha_loss": -0.008098253906364478, "alpha_value": 0.177087509955397, "duration": 185.02922344207764, "step": 31875}
{"episode_reward": 190.0097804098883, "episode": 256.0, "Q1 loss": 10.973752731323243, "Q2 loss": 10.96385637664795, "Mean Target Q": 167.88368225097656, "Mean Q1": 167.88260131835938, "Mean Q2": 167.88306274414063, "critic_loss": 21.93760905456543, "batch_reward": 1.298166036605835, "actor_loss": -168.753054957236, "actor_target_entropy": -1.0, "actor_entropy": 0.17710859106192667, "alpha_loss": -0.00980941508333349, "alpha_value": 0.1775645530586488, "duration": 165.89744305610657, "step": 32000}
{"episode_reward": 233.1049429436289, "episode": 257.0, "Q1 loss": 10.231358932495118, "Q2 loss": 10.23672268295288, "Mean Target Q": 168.02430725097656, "Mean Q1": 168.02532348632812, "Mean Q2": 168.02352490234375, "critic_loss": 20.468081573486327, "batch_reward": 1.2867754497528077, "actor_loss": -168.8738001263331, "actor_target_entropy": -1.0, "actor_entropy": 0.14809605059406114, "alpha_loss": -0.005804894857906869, "alpha_value": 0.17796224835545812, "duration": 180.83447861671448, "step": 32125}
{"episode_reward": 259.40245708627884, "episode": 258.0, "Q1 loss": 10.321356052398682, "Q2 loss": 10.315631450653076, "Mean Target Q": 168.34344482421875, "Mean Q1": 168.3361018066406, "Mean Q2": 168.33595263671876, "critic_loss": 20.636987503051756, "batch_reward": 1.2941597299575807, "actor_loss": -169.17327585527974, "actor_target_entropy": -1.0, "actor_entropy": 0.16841805810409208, "alpha_loss": -0.004931504453246993, "alpha_value": 0.17827599231300065, "duration": 173.12755370140076, "step": 32250}
{"episode_reward": 328.161494339063, "episode": 259.0, "Q1 loss": 10.518812644958496, "Q2 loss": 10.557990730285644, "Mean Target Q": 168.63224353027343, "Mean Q1": 168.62278796386718, "Mean Q2": 168.62410314941405, "critic_loss": 21.07680335998535, "batch_reward": 1.298148175239563, "actor_loss": -169.56664627317397, "actor_target_entropy": -1.0, "actor_entropy": 0.1429239749642355, "alpha_loss": -0.0056742674076101845, "alpha_value": 0.1786162728790282, "duration": 177.9248480796814, "step": 32375}
{"episode_reward": 160.59674189609237, "episode": 260.0, "Q1 loss": 10.114300361633301, "Q2 loss": 10.092099365234375, "Mean Target Q": 168.88267822265624, "Mean Q1": 168.89069030761718, "Mean Q2": 168.88902978515625, "critic_loss": 20.206399810791016, "batch_reward": 1.296069571495056, "actor_loss": -169.77387262159777, "actor_target_entropy": -1.0, "actor_entropy": 0.17065436939799017, "alpha_loss": -0.005720408678415322, "alpha_value": 0.17888555697234695, "duration": 156.1793818473816, "step": 32500}
{"episode_reward": 250.0044808822285, "episode": 261.0, "Q1 loss": 10.231392471313477, "Q2 loss": 10.25216609954834, "Mean Target Q": 169.231279296875, "Mean Q1": 169.2236086425781, "Mean Q2": 169.2242177734375, "critic_loss": 20.48355859375, "batch_reward": 1.307824538230896, "actor_loss": -170.1190674796937, "actor_target_entropy": -1.0, "actor_entropy": 0.16084788940728656, "alpha_loss": -0.008292742757244951, "alpha_value": 0.17929280245813653, "duration": 165.6842544078827, "step": 32625}
{"episode_reward": 195.68172900654773, "episode": 262.0, "Q1 loss": 10.32309281539917, "Q2 loss": 10.380516983032226, "Mean Target Q": 169.35664270019532, "Mean Q1": 169.35525830078126, "Mean Q2": 169.35560961914064, "critic_loss": 20.703609870910643, "batch_reward": 1.3121487379074097, "actor_loss": -170.23692740163494, "actor_target_entropy": -1.0, "actor_entropy": 0.1580974849001054, "alpha_loss": -0.004489626502618194, "alpha_value": 0.17958828108494226, "duration": 162.08215594291687, "step": 32750}
{"episode_reward": 210.53406388579276, "episode": 263.0, "Q1 loss": 10.568251319885254, "Q2 loss": 10.508714752197266, "Mean Target Q": 169.5997263183594, "Mean Q1": 169.59762463378905, "Mean Q2": 169.59663159179686, "critic_loss": 21.076966094970704, "batch_reward": 1.3039533443450928, "actor_loss": -170.47226799858942, "actor_target_entropy": -1.0, "actor_entropy": 0.2018173515560135, "alpha_loss": -0.008759002799966506, "alpha_value": 0.1799904697758101, "duration": 187.83144068717957, "step": 32875}
{"episode_reward": 223.64351953421505, "episode": 264.0, "Q1 loss": 10.302806907653808, "Q2 loss": 10.258947280883788, "Mean Target Q": 169.83634729003907, "Mean Q1": 169.8354677734375, "Mean Q2": 169.83567297363282, "critic_loss": 20.561754135131835, "batch_reward": 1.292540555000305, "actor_loss": -170.77243165046937, "actor_target_entropy": -1.0, "actor_entropy": 0.2037598455865537, "alpha_loss": -0.01466246948186909, "alpha_value": 0.18060608282958854, "duration": 171.26732301712036, "step": 33000}
{"episode_reward": 193.1063614486708, "episode": 265.0, "Q1 loss": 10.852085086822509, "Q2 loss": 10.861486839294434, "Mean Target Q": 170.06638073730468, "Mean Q1": 170.06759057617188, "Mean Q2": 170.06689489746094, "critic_loss": 21.71357192993164, "batch_reward": 1.2998873357772827, "actor_loss": -170.97265043712798, "actor_target_entropy": -1.0, "actor_entropy": 0.18682738127452986, "alpha_loss": -0.0066011365122413115, "alpha_value": 0.1814027797396127, "duration": 176.8077573776245, "step": 33125}
{"episode_reward": 210.13889692122277, "episode": 266.0, "Q1 loss": 10.332428482055665, "Q2 loss": 10.366945709228515, "Mean Target Q": 170.45862231445312, "Mean Q1": 170.4515725097656, "Mean Q2": 170.45311022949218, "critic_loss": 20.699374237060546, "batch_reward": 1.3219360237121582, "actor_loss": -171.43639472223097, "actor_target_entropy": -1.0, "actor_entropy": 0.1580386812528295, "alpha_loss": -0.00985566138913254, "alpha_value": 0.18186334819955596, "duration": 182.06375241279602, "step": 33250}
{"episode_reward": 258.3127696299888, "episode": 267.0, "Q1 loss": 10.522449165344238, "Q2 loss": 10.485655570983887, "Mean Target Q": 170.72137231445313, "Mean Q1": 170.71695922851563, "Mean Q2": 170.71636315917968, "critic_loss": 21.00810478973389, "batch_reward": 1.3202963218688966, "actor_loss": -171.68358188205295, "actor_target_entropy": -1.0, "actor_entropy": 0.16846556399786283, "alpha_loss": -0.010555373988897792, "alpha_value": 0.18249138980329538, "duration": 175.73245310783386, "step": 33375}
{"episode_reward": 260.353055908651, "episode": 268.0, "Q1 loss": 10.413369995117188, "Q2 loss": 10.409422683715821, "Mean Target Q": 171.00130493164062, "Mean Q1": 171.0043642578125, "Mean Q2": 171.00549206542968, "critic_loss": 20.822792724609375, "batch_reward": 1.3232587032318115, "actor_loss": -171.82997254402406, "actor_target_entropy": -1.0, "actor_entropy": 0.18776954878722468, "alpha_loss": -0.009240646088015168, "alpha_value": 0.18312728365184303, "duration": 173.61662411689758, "step": 33500}
{"episode_reward": 333.8232593881476, "episode": 269.0, "Q1 loss": 10.97628450012207, "Q2 loss": 11.013810962677002, "Mean Target Q": 171.24831494140625, "Mean Q1": 171.24435009765625, "Mean Q2": 171.24279138183593, "critic_loss": 21.990095428466798, "batch_reward": 1.312613883972168, "actor_loss": -172.12324814569382, "actor_target_entropy": -1.0, "actor_entropy": 0.2100738188813603, "alpha_loss": -0.003338055720271927, "alpha_value": 0.18347054794852485, "duration": 175.23836183547974, "step": 33625}
{"episode_reward": 187.90315423639785, "episode": 270.0, "Q1 loss": 10.510352359771728, "Q2 loss": 10.479464469909669, "Mean Target Q": 171.41413903808595, "Mean Q1": 171.40598474121094, "Mean Q2": 171.4059471435547, "critic_loss": 20.989816833496093, "batch_reward": 1.3276415243148805, "actor_loss": -172.22578700896233, "actor_target_entropy": -1.0, "actor_entropy": 0.18924044919831137, "alpha_loss": -0.0018464663693110548, "alpha_value": 0.18354319351572648, "duration": 164.24884009361267, "step": 33750}
{"episode_reward": 266.2224753761913, "episode": 271.0, "Q1 loss": 10.6771512298584, "Q2 loss": 10.673853225708008, "Mean Target Q": 171.69785498046875, "Mean Q1": 171.7014083251953, "Mean Q2": 171.7016240234375, "critic_loss": 21.35100440979004, "batch_reward": 1.3233667917251586, "actor_loss": -172.58050851973277, "actor_target_entropy": -1.0, "actor_entropy": 0.1962310497959455, "alpha_loss": -0.006122060833380572, "alpha_value": 0.18378921419443575, "duration": 184.95859003067017, "step": 33875}
{"episode_reward": 282.8951543729336, "episode": 272.0, "Q1 loss": 11.189858993530274, "Q2 loss": 11.246171897888184, "Mean Target Q": 172.0491181640625, "Mean Q1": 172.04256518554686, "Mean Q2": 172.04336389160156, "critic_loss": 22.43603096008301, "batch_reward": 1.3239091472625732, "actor_loss": -172.93500149634576, "actor_target_entropy": -1.0, "actor_entropy": 0.1804976285465302, "alpha_loss": -0.00640915997979802, "alpha_value": 0.18432187946428497, "duration": 167.87324166297913, "step": 34000}
{"episode_reward": 252.74051145158484, "episode": 273.0, "Q1 loss": 11.061910667419433, "Q2 loss": 11.135442638397217, "Mean Target Q": 172.26811181640625, "Mean Q1": 172.269537109375, "Mean Q2": 172.26922509765626, "critic_loss": 22.19735336303711, "batch_reward": 1.3302381811141968, "actor_loss": -173.15614246186755, "actor_target_entropy": -1.0, "actor_entropy": 0.1742774693975373, "alpha_loss": -0.008328094978683762, "alpha_value": 0.18494949700281857, "duration": 166.23911094665527, "step": 34125}
{"episode_reward": 271.3490072094701, "episode": 274.0, "Q1 loss": 11.27048469543457, "Q2 loss": 11.198142639160157, "Mean Target Q": 172.56794372558593, "Mean Q1": 172.5649969482422, "Mean Q2": 172.56628601074217, "critic_loss": 22.468627365112305, "batch_reward": 1.3424302234649659, "actor_loss": -173.4355180801884, "actor_target_entropy": -1.0, "actor_entropy": 0.20251330366778758, "alpha_loss": -0.013046514286073826, "alpha_value": 0.1854508836129389, "duration": 178.13471674919128, "step": 34250}
{"episode_reward": 226.91633574466792, "episode": 275.0, "Q1 loss": 11.002818992614745, "Q2 loss": 10.88091355895996, "Mean Target Q": 172.85789221191405, "Mean Q1": 172.85755517578124, "Mean Q2": 172.85485461425782, "critic_loss": 21.883732559204102, "batch_reward": 1.3403698272705078, "actor_loss": -173.79773021879652, "actor_target_entropy": -1.0, "actor_entropy": 0.17977025253432138, "alpha_loss": -0.006993376856876744, "alpha_value": 0.1860749781018825, "duration": 164.05659699440002, "step": 34375}
{"episode_reward": 275.17332522175593, "episode": 276.0, "Q1 loss": 10.82003184890747, "Q2 loss": 10.767357894897462, "Mean Target Q": 172.97992456054686, "Mean Q1": 172.97737109375, "Mean Q2": 172.97864501953126, "critic_loss": 21.587389877319335, "batch_reward": 1.3398638734817505, "actor_loss": -173.92486006213772, "actor_target_entropy": -1.0, "actor_entropy": 0.19353822534603457, "alpha_loss": -0.014666135246384769, "alpha_value": 0.18685465246155547, "duration": 171.9854018688202, "step": 34500}
{"episode_reward": 362.6656402610637, "episode": 277.0, "Q1 loss": 11.375396247863769, "Q2 loss": 11.335309112548828, "Mean Target Q": 173.4496123046875, "Mean Q1": 173.44730126953124, "Mean Q2": 173.44717321777344, "critic_loss": 22.710705352783204, "batch_reward": 1.3457722206115723, "actor_loss": -174.45318022228423, "actor_target_entropy": -1.0, "actor_entropy": 0.18317362536040563, "alpha_loss": -0.011313123340230612, "alpha_value": 0.18766117010420497, "duration": 176.79592537879944, "step": 34625}
{"episode_reward": 224.69168519442198, "episode": 278.0, "Q1 loss": 11.344829917907715, "Q2 loss": 11.389114013671875, "Mean Target Q": 173.7423045654297, "Mean Q1": 173.73819982910157, "Mean Q2": 173.73908337402344, "critic_loss": 22.733943908691405, "batch_reward": 1.3451985788345338, "actor_loss": -174.65485086748677, "actor_target_entropy": -1.0, "actor_entropy": 0.18651006154475674, "alpha_loss": -8.553018673293053e-06, "alpha_value": 0.1880507470706691, "duration": 171.0278422832489, "step": 34750}
{"episode_reward": 204.2718094602389, "episode": 279.0, "Q1 loss": 11.128462829589843, "Q2 loss": 11.152627677917481, "Mean Target Q": 173.90262524414064, "Mean Q1": 173.89191662597656, "Mean Q2": 173.88981762695312, "critic_loss": 22.281090454101562, "batch_reward": 1.3429287338256837, "actor_loss": -174.7501978798518, "actor_target_entropy": -1.0, "actor_entropy": 0.19781084737134358, "alpha_loss": -0.006765685775982482, "alpha_value": 0.18830393301677545, "duration": 184.63427901268005, "step": 34875}
{"episode_reward": 254.13035076263236, "episode": 280.0, "Q1 loss": 11.116395050048828, "Q2 loss": 11.066919380187988, "Mean Target Q": 174.10532141113282, "Mean Q1": 174.11683666992187, "Mean Q2": 174.11652087402345, "critic_loss": 22.183314392089844, "batch_reward": 1.3492017345428466, "actor_loss": -175.08374761766004, "actor_target_entropy": -1.0, "actor_entropy": 0.19244015264895656, "alpha_loss": -0.007712742816957254, "alpha_value": 0.18888654084707998, "step": 35000}
{"duration": 200.23707342147827, "step": 35000}
{"episode_reward": 232.3488325492109, "episode": 281.0, "Q1 loss": 11.132729652404786, "Q2 loss": 11.105963661193847, "Mean Target Q": 174.46017736816407, "Mean Q1": 174.4483916015625, "Mean Q2": 174.45120715332033, "critic_loss": 22.23869337463379, "batch_reward": 1.3468491525650024, "actor_loss": -175.3247818719773, "actor_target_entropy": -1.0, "actor_entropy": 0.1903131798737579, "alpha_loss": -0.006698366818166087, "alpha_value": 0.18934023989699292, "duration": 187.42039108276367, "step": 35125}
{"episode_reward": 240.88346468795527, "episode": 282.0, "Q1 loss": 11.187227005004884, "Q2 loss": 11.141862136840821, "Mean Target Q": 174.74722607421876, "Mean Q1": 174.74196862792968, "Mean Q2": 174.73906176757814, "critic_loss": 22.329089141845703, "batch_reward": 1.3546248836517334, "actor_loss": -175.71161060948526, "actor_target_entropy": -1.0, "actor_entropy": 0.21213658766881113, "alpha_loss": -0.004737976071004185, "alpha_value": 0.18974469562263216, "duration": 184.0968635082245, "step": 35250}
{"episode_reward": 244.2812507661931, "episode": 283.0, "Q1 loss": 11.087579330444337, "Q2 loss": 11.098193946838379, "Mean Target Q": 174.88261755371093, "Mean Q1": 174.87989331054686, "Mean Q2": 174.88086157226562, "critic_loss": 22.185773300170897, "batch_reward": 1.348735016822815, "actor_loss": -175.76571170867436, "actor_target_entropy": -1.0, "actor_entropy": 0.1897261563747648, "alpha_loss": -0.0069072369009345064, "alpha_value": 0.19009136455175032, "duration": 185.7527208328247, "step": 35375}
{"episode_reward": 224.92145556842198, "episode": 284.0, "Q1 loss": 11.4067779006958, "Q2 loss": 11.355102493286132, "Mean Target Q": 175.22310607910157, "Mean Q1": 175.22086767578125, "Mean Q2": 175.2223055419922, "critic_loss": 22.76188037109375, "batch_reward": 1.3694930639266967, "actor_loss": -176.130855437248, "actor_target_entropy": -1.0, "actor_entropy": 0.16700102959669405, "alpha_loss": -0.009926056059362788, "alpha_value": 0.1905782293582525, "duration": 161.43235635757446, "step": 35500}
{"episode_reward": 210.88776021365328, "episode": 285.0, "Q1 loss": 11.608979751586913, "Q2 loss": 11.607378982543946, "Mean Target Q": 175.4127440185547, "Mean Q1": 175.41448815917968, "Mean Q2": 175.4158145751953, "critic_loss": 23.216358779907228, "batch_reward": 1.3597646226882936, "actor_loss": -176.25190274677578, "actor_target_entropy": -1.0, "actor_entropy": 0.19254072102171088, "alpha_loss": -0.004472632674382083, "alpha_value": 0.19119451374281088, "duration": 178.0651388168335, "step": 35625}
{"episode_reward": 209.93991933033917, "episode": 286.0, "Q1 loss": 10.999381690979003, "Q2 loss": 10.939918815612794, "Mean Target Q": 175.67322265625, "Mean Q1": 175.6715593261719, "Mean Q2": 175.66905029296876, "critic_loss": 21.93930059814453, "batch_reward": 1.3654172077178954, "actor_loss": -176.58906973561932, "actor_target_entropy": -1.0, "actor_entropy": 0.20043030441288026, "alpha_loss": -0.006341724908129583, "alpha_value": 0.19157895732011296, "duration": 170.31485724449158, "step": 35750}
{"episode_reward": 273.2417103802473, "episode": 287.0, "Q1 loss": 11.367341972351074, "Q2 loss": 11.31295220565796, "Mean Target Q": 175.94517358398437, "Mean Q1": 175.94145275878907, "Mean Q2": 175.94296569824218, "critic_loss": 22.680294174194337, "batch_reward": 1.3583850860595703, "actor_loss": -176.88576374356708, "actor_target_entropy": -1.0, "actor_entropy": 0.17249311151958646, "alpha_loss": -0.003323816280398104, "alpha_value": 0.1920163097798347, "duration": 182.6513650417328, "step": 35875}
{"episode_reward": 288.9052024760241, "episode": 288.0, "Q1 loss": 11.474376647949219, "Q2 loss": 11.545000953674316, "Mean Target Q": 176.09713720703124, "Mean Q1": 176.09560388183593, "Mean Q2": 176.0944931640625, "critic_loss": 23.019377532958984, "batch_reward": 1.3586761550903321, "actor_loss": -177.0070328251008, "actor_target_entropy": -1.0, "actor_entropy": 0.17744217356366496, "alpha_loss": -0.003837072478246785, "alpha_value": 0.19221926095036426, "duration": 171.63057446479797, "step": 36000}
{"episode_reward": 251.370012744943, "episode": 289.0, "Q1 loss": 11.558937019348145, "Q2 loss": 11.4818784866333, "Mean Target Q": 176.49542822265624, "Mean Q1": 176.4982380371094, "Mean Q2": 176.4950487060547, "critic_loss": 23.0408154296875, "batch_reward": 1.3697880582809447, "actor_loss": -177.5330820234995, "actor_target_entropy": -1.0, "actor_entropy": 0.18021737346573483, "alpha_loss": -0.005234205731309004, "alpha_value": 0.19250329449051523, "duration": 178.83484029769897, "step": 36125}
{"episode_reward": 258.39463507818385, "episode": 290.0, "Q1 loss": 11.892019500732422, "Q2 loss": 11.857850875854492, "Mean Target Q": 176.63791955566407, "Mean Q1": 176.6264035644531, "Mean Q2": 176.63082751464844, "critic_loss": 23.749870468139648, "batch_reward": 1.3718497066497803, "actor_loss": -177.53241631292528, "actor_target_entropy": -1.0, "actor_entropy": 0.2120967843840199, "alpha_loss": -0.0058697683646553945, "alpha_value": 0.19290286378758192, "duration": 185.67139792442322, "step": 36250}
{"episode_reward": 212.57952287745218, "episode": 291.0, "Q1 loss": 11.54906666946411, "Q2 loss": 11.462069900512695, "Mean Target Q": 176.9479393310547, "Mean Q1": 176.95268188476564, "Mean Q2": 176.95219396972655, "critic_loss": 23.0111365814209, "batch_reward": 1.37985884475708, "actor_loss": -177.86651926192027, "actor_target_entropy": -1.0, "actor_entropy": 0.20638574305034818, "alpha_loss": -0.0041644170932057835, "alpha_value": 0.19332154162128817, "duration": 188.8059446811676, "step": 36375}
{"episode_reward": 111.5627388998655, "episode": 292.0, "Q1 loss": 11.335113403320312, "Q2 loss": 11.315388366699219, "Mean Target Q": 177.14088073730468, "Mean Q1": 177.13430493164063, "Mean Q2": 177.1330535888672, "critic_loss": 22.650501846313478, "batch_reward": 1.3737307806015016, "actor_loss": -178.0872057022587, "actor_target_entropy": -1.0, "actor_entropy": 0.16661310766733461, "alpha_loss": -0.008545784155778106, "alpha_value": 0.1938413576363369, "duration": 191.73392987251282, "step": 36500}
{"episode_reward": 191.81389620786803, "episode": 293.0, "Q1 loss": 10.968880813598632, "Q2 loss": 10.971738594055175, "Mean Target Q": 177.42911315917968, "Mean Q1": 177.4268553466797, "Mean Q2": 177.428234375, "critic_loss": 21.940619354248046, "batch_reward": 1.3703147897720336, "actor_loss": -178.35895453559027, "actor_target_entropy": -1.0, "actor_entropy": 0.21175668341299844, "alpha_loss": -0.003949610900784295, "alpha_value": 0.19420012510219328, "duration": 172.79491710662842, "step": 36625}
{"episode_reward": 216.5769151834848, "episode": 294.0, "Q1 loss": 11.100897117614746, "Q2 loss": 11.004610313415528, "Mean Target Q": 177.61593725585936, "Mean Q1": 177.6075888671875, "Mean Q2": 177.60683361816407, "critic_loss": 22.105507446289064, "batch_reward": 1.3657300138473512, "actor_loss": -178.5308837890625, "actor_target_entropy": -1.0, "actor_entropy": 0.19981487215526642, "alpha_loss": 0.002155017772419078, "alpha_value": 0.19411871276857443, "duration": 193.13525080680847, "step": 36750}
{"episode_reward": 208.87802483990455, "episode": 295.0, "Q1 loss": 11.362490127563477, "Q2 loss": 11.36196110534668, "Mean Target Q": 177.98132934570313, "Mean Q1": 177.9823975830078, "Mean Q2": 177.9837781982422, "critic_loss": 22.724451187133788, "batch_reward": 1.3745336866378783, "actor_loss": -178.84092470199343, "actor_target_entropy": -1.0, "actor_entropy": 0.2085659619834688, "alpha_loss": -0.006063984538842406, "alpha_value": 0.19448873197792593, "duration": 173.86065578460693, "step": 36875}
{"episode_reward": 267.84518803602225, "episode": 296.0, "Q1 loss": 11.108233589172363, "Q2 loss": 11.06717984008789, "Mean Target Q": 178.10050073242186, "Mean Q1": 178.1019229736328, "Mean Q2": 178.09955541992187, "critic_loss": 22.17541346740723, "batch_reward": 1.362203833580017, "actor_loss": -179.05059346845073, "actor_target_entropy": -1.0, "actor_entropy": 0.21298122814586085, "alpha_loss": -0.008017976541117194, "alpha_value": 0.19475908098722536, "duration": 188.97493982315063, "step": 37000}
{"episode_reward": 272.3420846590691, "episode": 297.0, "Q1 loss": 11.29381575012207, "Q2 loss": 11.23043154144287, "Mean Target Q": 178.49411047363282, "Mean Q1": 178.48870849609375, "Mean Q2": 178.48853234863282, "critic_loss": 22.524247268676756, "batch_reward": 1.385073040008545, "actor_loss": -179.45376925998264, "actor_target_entropy": -1.0, "actor_entropy": 0.2248327656397744, "alpha_loss": -7.488749300440152e-05, "alpha_value": 0.19537563460895402, "duration": 191.9033489227295, "step": 37125}
{"episode_reward": 298.9115104832643, "episode": 298.0, "Q1 loss": 11.362199089050293, "Q2 loss": 11.39743337249756, "Mean Target Q": 178.7780330810547, "Mean Q1": 178.77856115722656, "Mean Q2": 178.77786987304688, "critic_loss": 22.759632461547852, "batch_reward": 1.3876644163131713, "actor_loss": -179.6412323982485, "actor_target_entropy": -1.0, "actor_entropy": 0.18603137820478408, "alpha_loss": -0.0020012198215080125, "alpha_value": 0.19542479230980558, "duration": 173.88357663154602, "step": 37250}
{"episode_reward": 227.3915683100431, "episode": 299.0, "Q1 loss": 11.31636036682129, "Q2 loss": 11.281311614990233, "Mean Target Q": 179.0182626953125, "Mean Q1": 179.00659423828125, "Mean Q2": 179.0084805908203, "critic_loss": 22.597671966552735, "batch_reward": 1.3793015270233153, "actor_loss": -179.97506592765686, "actor_target_entropy": -1.0, "actor_entropy": 0.20133102626081498, "alpha_loss": -0.005158860421192552, "alpha_value": 0.19552447655831046, "duration": 175.7951991558075, "step": 37375}
{"episode_reward": 296.3949751387886, "episode": 300.0, "Q1 loss": 11.162342628479005, "Q2 loss": 11.07259447479248, "Mean Target Q": 179.1956495361328, "Mean Q1": 179.19712072753907, "Mean Q2": 179.19721899414063, "critic_loss": 22.234937133789064, "batch_reward": 1.3871579351425172, "actor_loss": -180.06375614289314, "actor_target_entropy": -1.0, "actor_entropy": 0.19230984968523826, "alpha_loss": -0.0011337200468856722, "alpha_value": 0.19588080568148658, "duration": 188.94028735160828, "step": 37500}
{"episode_reward": 210.83852365629457, "episode": 301.0, "Q1 loss": 11.217245483398438, "Q2 loss": 11.210139205932617, "Mean Target Q": 179.4704245605469, "Mean Q1": 179.4701778564453, "Mean Q2": 179.47093310546876, "critic_loss": 22.427384658813477, "batch_reward": 1.3850830812454225, "actor_loss": -180.41295054602244, "actor_target_entropy": -1.0, "actor_entropy": 0.2430499993146412, "alpha_loss": -0.005739501902892712, "alpha_value": 0.1960370063057713, "duration": 183.48943543434143, "step": 37625}
{"episode_reward": 283.4070328757936, "episode": 302.0, "Q1 loss": 11.35360749053955, "Q2 loss": 11.402403427124023, "Mean Target Q": 179.8197149658203, "Mean Q1": 179.82083251953125, "Mean Q2": 179.8194051513672, "critic_loss": 22.756010971069337, "batch_reward": 1.3892870359420777, "actor_loss": -180.80331027123236, "actor_target_entropy": -1.0, "actor_entropy": 0.22051458132843818, "alpha_loss": -0.010045368479745041, "alpha_value": 0.19660649096065425, "duration": 172.09716153144836, "step": 37750}
{"episode_reward": 268.74611299753667, "episode": 303.0, "Q1 loss": 11.171091255187989, "Q2 loss": 11.140577362060547, "Mean Target Q": 180.03619763183593, "Mean Q1": 180.03179650878906, "Mean Q2": 180.0330440673828, "critic_loss": 22.311668624877928, "batch_reward": 1.384198408126831, "actor_loss": -180.95622229197667, "actor_target_entropy": -1.0, "actor_entropy": 0.2345317985330309, "alpha_loss": -0.003277462145816239, "alpha_value": 0.1970100472891642, "duration": 172.90061378479004, "step": 37875}
{"episode_reward": 204.08216861633485, "episode": 304.0, "Q1 loss": 11.359257934570312, "Q2 loss": 11.29487587738037, "Mean Target Q": 180.18584692382814, "Mean Q1": 180.1815479736328, "Mean Q2": 180.18238549804687, "critic_loss": 22.654133865356446, "batch_reward": 1.3934476079940796, "actor_loss": -181.03301509734123, "actor_target_entropy": -1.0, "actor_entropy": 0.21731605356739414, "alpha_loss": -0.002426582998821452, "alpha_value": 0.1972951258986209, "duration": 173.23344326019287, "step": 38000}
{"episode_reward": 271.4254764507849, "episode": 305.0, "Q1 loss": 11.422656005859375, "Q2 loss": 11.420118392944335, "Mean Target Q": 180.442736328125, "Mean Q1": 180.4469415283203, "Mean Q2": 180.44562133789063, "critic_loss": 22.842774398803712, "batch_reward": 1.3995136814117433, "actor_loss": -181.3296135796441, "actor_target_entropy": -1.0, "actor_entropy": 0.2259543568841995, "alpha_loss": -0.000847727485326311, "alpha_value": 0.19742670546091165, "duration": 177.4490613937378, "step": 38125}
{"episode_reward": 186.16071371870484, "episode": 306.0, "Q1 loss": 11.420304481506347, "Q2 loss": 11.336325103759766, "Mean Target Q": 180.661666015625, "Mean Q1": 180.6578981933594, "Mean Q2": 180.65799499511718, "critic_loss": 22.75662957763672, "batch_reward": 1.396426197052002, "actor_loss": -181.56849005914503, "actor_target_entropy": -1.0, "actor_entropy": 0.19615523949746164, "alpha_loss": -0.008397956506439274, "alpha_value": 0.19780880745835008, "duration": 169.71450924873352, "step": 38250}
{"episode_reward": 216.25299364240067, "episode": 307.0, "Q1 loss": 11.205319526672364, "Q2 loss": 11.183228134155273, "Mean Target Q": 180.94425366210936, "Mean Q1": 180.93965576171874, "Mean Q2": 180.9389034423828, "critic_loss": 22.38854768371582, "batch_reward": 1.403447278022766, "actor_loss": -181.9607960534474, "actor_target_entropy": -1.0, "actor_entropy": 0.19361172427260687, "alpha_loss": -0.017224010523586047, "alpha_value": 0.19873686687493672, "duration": 179.9177737236023, "step": 38375}
{"episode_reward": 310.5217392048762, "episode": 308.0, "Q1 loss": 11.614598796844483, "Q2 loss": 11.558238456726075, "Mean Target Q": 181.15656225585937, "Mean Q1": 181.1522119140625, "Mean Q2": 181.15116552734375, "critic_loss": 23.17283726501465, "batch_reward": 1.401512731552124, "actor_loss": -182.03638138309603, "actor_target_entropy": -1.0, "actor_entropy": 0.2072643773299792, "alpha_loss": -0.004042033566116926, "alpha_value": 0.19952427321118918, "duration": 167.92061185836792, "step": 38500}
{"episode_reward": 196.12184888175534, "episode": 309.0, "Q1 loss": 11.30562880706787, "Q2 loss": 11.216549827575683, "Mean Target Q": 181.479455078125, "Mean Q1": 181.4827432861328, "Mean Q2": 181.4849080810547, "critic_loss": 22.522178619384764, "batch_reward": 1.407993085861206, "actor_loss": -182.34125773111978, "actor_target_entropy": -1.0, "actor_entropy": 0.2020830495489968, "alpha_loss": -0.009379041133566744, "alpha_value": 0.20004573328162947, "duration": 197.25449514389038, "step": 38625}
{"episode_reward": 234.26816206052825, "episode": 310.0, "Q1 loss": 11.59803052520752, "Q2 loss": 11.562293182373047, "Mean Target Q": 181.68710510253905, "Mean Q1": 181.6748370361328, "Mean Q2": 181.6755057373047, "critic_loss": 23.160323760986326, "batch_reward": 1.409129511833191, "actor_loss": -182.51388549804688, "actor_target_entropy": -1.0, "actor_entropy": 0.18063097987924853, "alpha_loss": -0.003385841399581442, "alpha_value": 0.20038113800609927, "duration": 180.132141828537, "step": 38750}
{"episode_reward": 352.7188466347296, "episode": 311.0, "Q1 loss": 12.365397857666016, "Q2 loss": 12.301292640686036, "Mean Target Q": 181.90115234375, "Mean Q1": 181.9045546875, "Mean Q2": 181.90275158691406, "critic_loss": 24.666690628051757, "batch_reward": 1.4079870042800904, "actor_loss": -182.76334126790366, "actor_target_entropy": -1.0, "actor_entropy": 0.20229490385169074, "alpha_loss": 0.001552586715357999, "alpha_value": 0.20056695627229423, "duration": 174.13427233695984, "step": 38875}
{"episode_reward": 254.3970010951636, "episode": 312.0, "Q1 loss": 12.354707168579102, "Q2 loss": 12.315339378356933, "Mean Target Q": 182.22132153320314, "Mean Q1": 182.224654296875, "Mean Q2": 182.2258377685547, "critic_loss": 24.670046630859375, "batch_reward": 1.4237135696411132, "actor_loss": -183.0408243979177, "actor_target_entropy": -1.0, "actor_entropy": 0.22160549618063435, "alpha_loss": 0.008554287765535616, "alpha_value": 0.200290043938307, "duration": 179.2168219089508, "step": 39000}
{"episode_reward": 217.26080215129969, "episode": 313.0, "Q1 loss": 11.192245895385742, "Q2 loss": 11.114619041442872, "Mean Target Q": 182.4552110595703, "Mean Q1": 182.4474031982422, "Mean Q2": 182.4443408203125, "critic_loss": 22.306864898681642, "batch_reward": 1.4147621297836304, "actor_loss": -183.28554498581659, "actor_target_entropy": -1.0, "actor_entropy": 0.22140757195533267, "alpha_loss": -0.0031294094930802074, "alpha_value": 0.19992199743408215, "duration": 186.98685216903687, "step": 39125}
{"episode_reward": 252.6748188419745, "episode": 314.0, "Q1 loss": 11.512997932434082, "Q2 loss": 11.435265815734864, "Mean Target Q": 182.70096545410155, "Mean Q1": 182.70304614257813, "Mean Q2": 182.7049083251953, "critic_loss": 22.948263854980468, "batch_reward": 1.4106290044784546, "actor_loss": -183.69569249306954, "actor_target_entropy": -1.0, "actor_entropy": 0.22531554968126358, "alpha_loss": -0.002578947659311516, "alpha_value": 0.20018701510963208, "duration": 179.50437831878662, "step": 39250}
{"episode_reward": 310.6753871935411, "episode": 315.0, "Q1 loss": 11.817725357055664, "Q2 loss": 11.79826268005371, "Mean Target Q": 182.91200451660157, "Mean Q1": 182.90332275390625, "Mean Q2": 182.90270556640624, "critic_loss": 23.615987991333007, "batch_reward": 1.418819306373596, "actor_loss": -183.7986355736142, "actor_target_entropy": -1.0, "actor_entropy": 0.23975979501292818, "alpha_loss": -0.0066692829834267735, "alpha_value": 0.20049792487899123, "duration": 190.68066096305847, "step": 39375}
{"episode_reward": 138.0200362336307, "episode": 316.0, "Q1 loss": 11.283093482971191, "Q2 loss": 11.223824356079101, "Mean Target Q": 183.16187634277344, "Mean Q1": 183.16284020996093, "Mean Q2": 183.16244665527344, "critic_loss": 22.50691777038574, "batch_reward": 1.409131962776184, "actor_loss": -184.0138889435799, "actor_target_entropy": -1.0, "actor_entropy": 0.2132596488921873, "alpha_loss": -0.004140165944268266, "alpha_value": 0.2008584534822134, "duration": 173.58271956443787, "step": 39500}
{"episode_reward": 302.76160553869016, "episode": 317.0, "Q1 loss": 11.479735137939453, "Q2 loss": 11.444324455261231, "Mean Target Q": 183.35768078613282, "Mean Q1": 183.35446704101562, "Mean Q2": 183.35356994628907, "critic_loss": 22.924059494018554, "batch_reward": 1.4170768957138062, "actor_loss": -184.32079060872397, "actor_target_entropy": -1.0, "actor_entropy": 0.25074261024830835, "alpha_loss": -0.006788093493216568, "alpha_value": 0.20126919067760826, "duration": 186.20057463645935, "step": 39625}
{"episode_reward": 309.28188629952615, "episode": 318.0, "Q1 loss": 11.522747367858887, "Q2 loss": 11.523249366760254, "Mean Target Q": 183.71432458496093, "Mean Q1": 183.711728515625, "Mean Q2": 183.7142889404297, "critic_loss": 23.04599673461914, "batch_reward": 1.4155488271713257, "actor_loss": -184.59809432491178, "actor_target_entropy": -1.0, "actor_entropy": 0.20675718327683787, "alpha_loss": -0.006097129508552532, "alpha_value": 0.20179554670901576, "duration": 191.42439937591553, "step": 39750}
{"episode_reward": 274.50902460692976, "episode": 319.0, "Q1 loss": 11.722330429077148, "Q2 loss": 11.700878776550294, "Mean Target Q": 183.89230346679688, "Mean Q1": 183.88681201171875, "Mean Q2": 183.88649743652343, "critic_loss": 23.42320915222168, "batch_reward": 1.4189777688980103, "actor_loss": -184.7156451997303, "actor_target_entropy": -1.0, "actor_entropy": 0.23428855741780902, "alpha_loss": 0.0027791940891701314, "alpha_value": 0.20186696232419538, "duration": 196.40821313858032, "step": 39875}
{"episode_reward": 267.7462817543993, "episode": 320.0, "Q1 loss": 11.622783409118652, "Q2 loss": 11.579951545715332, "Mean Target Q": 184.13407922363282, "Mean Q1": 184.1318760986328, "Mean Q2": 184.13034924316406, "critic_loss": 23.202734970092774, "batch_reward": 1.4221514568328857, "actor_loss": -185.03363012498426, "actor_target_entropy": -1.0, "actor_entropy": 0.22083918389774138, "alpha_loss": -0.008323458567892591, "alpha_value": 0.2021301983897332, "step": 40000}
{"duration": 206.97127747535706, "step": 40000}
{"episode_reward": 197.74794609864605, "episode": 321.0, "Q1 loss": 12.381781379699706, "Q2 loss": 12.268478652954101, "Mean Target Q": 184.40278869628906, "Mean Q1": 184.4076358642578, "Mean Q2": 184.40766625976562, "critic_loss": 24.650260025024416, "batch_reward": 1.4225739641189574, "actor_loss": -185.32515631781683, "actor_target_entropy": -1.0, "actor_entropy": 0.22973471052116817, "alpha_loss": -0.009917457277576128, "alpha_value": 0.20268928736790467, "duration": 186.74341940879822, "step": 40125}
{"episode_reward": 217.92696649265054, "episode": 322.0, "Q1 loss": 12.167402954101563, "Q2 loss": 12.176520004272462, "Mean Target Q": 184.65000769042967, "Mean Q1": 184.64428466796875, "Mean Q2": 184.64714587402344, "critic_loss": 24.343922958374023, "batch_reward": 1.4267779207229614, "actor_loss": -185.58179473876953, "actor_target_entropy": -1.0, "actor_entropy": 0.2309249619082097, "alpha_loss": -0.011153727446893049, "alpha_value": 0.20338894326586748, "duration": 194.56509947776794, "step": 40250}
{"episode_reward": 232.9430577667926, "episode": 323.0, "Q1 loss": 12.406132362365723, "Q2 loss": 12.322279083251953, "Mean Target Q": 184.87842346191405, "Mean Q1": 184.8709475097656, "Mean Q2": 184.86817504882814, "critic_loss": 24.728411422729494, "batch_reward": 1.4293967247009278, "actor_loss": -185.8667740594773, "actor_target_entropy": -1.0, "actor_entropy": 0.21031098528986886, "alpha_loss": -0.009955769486074883, "alpha_value": 0.20415417395471228, "duration": 175.76350951194763, "step": 40375}
{"episode_reward": 259.56252553054276, "episode": 324.0, "Q1 loss": 11.498416389465332, "Q2 loss": 11.497327644348145, "Mean Target Q": 185.2524971923828, "Mean Q1": 185.2562205810547, "Mean Q2": 185.25711157226561, "critic_loss": 22.995744064331056, "batch_reward": 1.4356270980834962, "actor_loss": -186.02544870684224, "actor_target_entropy": -1.0, "actor_entropy": 0.22678959225454637, "alpha_loss": -0.007986984211921452, "alpha_value": 0.2048538561515748, "duration": 188.2897117137909, "step": 40500}
{"episode_reward": 153.29085853539456, "episode": 325.0, "Q1 loss": 11.451819519042969, "Q2 loss": 11.40505941772461, "Mean Target Q": 185.42336474609374, "Mean Q1": 185.41988830566407, "Mean Q2": 185.41972497558595, "critic_loss": 22.85687893676758, "batch_reward": 1.4319947099685668, "actor_loss": -186.39450000581286, "actor_target_entropy": -1.0, "actor_entropy": 0.23626404503981271, "alpha_loss": -0.009965875468749021, "alpha_value": 0.2054913560066379, "duration": 188.4717617034912, "step": 40625}
{"episode_reward": 247.96875665632516, "episode": 326.0, "Q1 loss": 11.630637443542481, "Q2 loss": 11.547444236755371, "Mean Target Q": 185.76313415527343, "Mean Q1": 185.75256689453124, "Mean Q2": 185.75185388183593, "critic_loss": 23.178081649780275, "batch_reward": 1.4283258743286134, "actor_loss": -186.6779772850775, "actor_target_entropy": -1.0, "actor_entropy": 0.2345514107615717, "alpha_loss": -0.010073111437621617, "alpha_value": 0.20616503122650215, "duration": 185.08683276176453, "step": 40750}
{"episode_reward": 158.66590334509695, "episode": 327.0, "Q1 loss": 11.856055068969727, "Q2 loss": 11.85623802947998, "Mean Target Q": 185.97500891113282, "Mean Q1": 185.97782055664064, "Mean Q2": 185.97762023925782, "critic_loss": 23.71229313659668, "batch_reward": 1.4363627862930297, "actor_loss": -186.8583027673146, "actor_target_entropy": -1.0, "actor_entropy": 0.24624320367972055, "alpha_loss": -0.006816200156223088, "alpha_value": 0.20684563705310424, "duration": 188.36481618881226, "step": 40875}
{"episode_reward": 192.3475921553885, "episode": 328.0, "Q1 loss": 11.771047859191894, "Q2 loss": 11.755222602844238, "Mean Target Q": 186.13682373046876, "Mean Q1": 186.13753759765626, "Mean Q2": 186.13946691894532, "critic_loss": 23.526270416259766, "batch_reward": 1.4369457244873047, "actor_loss": -187.14253727082283, "actor_target_entropy": -1.0, "actor_entropy": 0.25123347738577473, "alpha_loss": -0.0065243540842446586, "alpha_value": 0.20743080574949466, "duration": 185.87929606437683, "step": 41000}
{"episode_reward": 243.9621227034936, "episode": 329.0, "Q1 loss": 11.76531982421875, "Q2 loss": 11.679261932373047, "Mean Target Q": 186.32562622070313, "Mean Q1": 186.31494116210936, "Mean Q2": 186.31311474609376, "critic_loss": 23.44458187866211, "batch_reward": 1.430632984161377, "actor_loss": -187.29604012625558, "actor_target_entropy": -1.0, "actor_entropy": 0.24873043123691801, "alpha_loss": -0.010790767026178184, "alpha_value": 0.2079147970810444, "duration": 183.49934482574463, "step": 41125}
{"episode_reward": 238.57386551598998, "episode": 330.0, "Q1 loss": 11.74727278137207, "Q2 loss": 11.674955108642578, "Mean Target Q": 186.54321691894532, "Mean Q1": 186.5504044189453, "Mean Q2": 186.54874743652343, "critic_loss": 23.42222785949707, "batch_reward": 1.4323123893737792, "actor_loss": -187.5023232736895, "actor_target_entropy": -1.0, "actor_entropy": 0.2549039123039092, "alpha_loss": -0.005713189223540887, "alpha_value": 0.2085488457326222, "duration": 194.80114793777466, "step": 41250}
{"episode_reward": 267.56494069009005, "episode": 331.0, "Q1 loss": 11.579582099914552, "Q2 loss": 11.53367995452881, "Mean Target Q": 186.81922241210938, "Mean Q1": 186.81349145507812, "Mean Q2": 186.81585046386718, "critic_loss": 23.11326206970215, "batch_reward": 1.4389407453536986, "actor_loss": -187.78227984716023, "actor_target_entropy": -1.0, "actor_entropy": 0.2722858881193494, "alpha_loss": -0.008044976650530266, "alpha_value": 0.20912275359734442, "duration": 183.98194479942322, "step": 41375}
{"episode_reward": 303.5278069646837, "episode": 332.0, "Q1 loss": 11.653033134460449, "Q2 loss": 11.583592834472656, "Mean Target Q": 187.18245471191406, "Mean Q1": 187.1789686279297, "Mean Q2": 187.1780047607422, "critic_loss": 23.2366259765625, "batch_reward": 1.434715274810791, "actor_loss": -188.0570356307491, "actor_target_entropy": -1.0, "actor_entropy": 0.2768382360377619, "alpha_loss": -0.002632443398808039, "alpha_value": 0.20950100274179714, "duration": 192.45886278152466, "step": 41500}
{"episode_reward": 292.44370429566095, "episode": 333.0, "Q1 loss": 11.986149322509766, "Q2 loss": 11.959294151306151, "Mean Target Q": 187.38893359375, "Mean Q1": 187.38634521484374, "Mean Q2": 187.38380993652345, "critic_loss": 23.945443420410157, "batch_reward": 1.4499031019210815, "actor_loss": -188.2896028548952, "actor_target_entropy": -1.0, "actor_entropy": 0.28167212293261573, "alpha_loss": -0.00546813624659701, "alpha_value": 0.20990181188372717, "duration": 189.2998502254486, "step": 41625}
{"episode_reward": 345.0884964406383, "episode": 334.0, "Q1 loss": 11.482234237670898, "Q2 loss": 11.410160583496094, "Mean Target Q": 187.59262939453126, "Mean Q1": 187.590400390625, "Mean Q2": 187.59250622558594, "critic_loss": 22.892394912719727, "batch_reward": 1.4529281120300293, "actor_loss": -188.45970104586692, "actor_target_entropy": -1.0, "actor_entropy": 0.25644633991103016, "alpha_loss": -0.004975967304480653, "alpha_value": 0.2102001594073844, "duration": 198.23315954208374, "step": 41750}
{"episode_reward": 275.3488856176235, "episode": 335.0, "Q1 loss": 11.717153861999511, "Q2 loss": 11.725650619506835, "Mean Target Q": 187.88873132324218, "Mean Q1": 187.8874559326172, "Mean Q2": 187.8864461669922, "critic_loss": 23.442804443359375, "batch_reward": 1.45105460357666, "actor_loss": -188.7180478535001, "actor_target_entropy": -1.0, "actor_entropy": 0.2495663244099844, "alpha_loss": -0.0026171493255311533, "alpha_value": 0.21047872231523201, "duration": 195.39443802833557, "step": 41875}
{"episode_reward": 216.54619516487722, "episode": 336.0, "Q1 loss": 11.643820686340332, "Q2 loss": 11.565084724426269, "Mean Target Q": 188.01096240234375, "Mean Q1": 188.00532727050782, "Mean Q2": 188.0067462158203, "critic_loss": 23.208905487060548, "batch_reward": 1.4558497838973998, "actor_loss": -188.9134255686114, "actor_target_entropy": -1.0, "actor_entropy": 0.276854996719668, "alpha_loss": -0.006658239252564888, "alpha_value": 0.21075782769917265, "duration": 205.79027557373047, "step": 42000}
{"episode_reward": 334.7443973498414, "episode": 337.0, "Q1 loss": 11.852191551208495, "Q2 loss": 11.79947120666504, "Mean Target Q": 188.25352087402345, "Mean Q1": 188.2506142578125, "Mean Q2": 188.250501953125, "critic_loss": 23.651662719726563, "batch_reward": 1.4502736721038818, "actor_loss": -189.10194421192958, "actor_target_entropy": -1.0, "actor_entropy": 0.27532688185336096, "alpha_loss": -0.008326482188533105, "alpha_value": 0.21127184196125207, "duration": 192.27258038520813, "step": 42125}
{"episode_reward": 270.03312510290397, "episode": 338.0, "Q1 loss": 11.979751167297364, "Q2 loss": 11.923539588928223, "Mean Target Q": 188.53987023925782, "Mean Q1": 188.53937170410157, "Mean Q2": 188.53893872070313, "critic_loss": 23.903290695190428, "batch_reward": 1.4511027603149413, "actor_loss": -189.46736243463332, "actor_target_entropy": -1.0, "actor_entropy": 0.2374110796278523, "alpha_loss": -0.00400903096963321, "alpha_value": 0.21184287723316556, "duration": 185.7374472618103, "step": 42250}
{"episode_reward": 263.19865377884275, "episode": 339.0, "Q1 loss": 11.880432159423828, "Q2 loss": 11.909702461242675, "Mean Target Q": 188.74273034667968, "Mean Q1": 188.74731860351562, "Mean Q2": 188.74799450683594, "critic_loss": 23.790134689331055, "batch_reward": 1.463457184791565, "actor_loss": -189.67024691142734, "actor_target_entropy": -1.0, "actor_entropy": 0.2694567061132855, "alpha_loss": -0.009277920031713115, "alpha_value": 0.2122448232068707, "duration": 208.19638848304749, "step": 42375}
{"episode_reward": 220.14583186992306, "episode": 340.0, "Q1 loss": 11.751805290222167, "Q2 loss": 11.724726684570312, "Mean Target Q": 189.0081845703125, "Mean Q1": 189.00267260742189, "Mean Q2": 189.00191259765626, "critic_loss": 23.476532028198243, "batch_reward": 1.4557627429962159, "actor_loss": -189.97582097207345, "actor_target_entropy": -1.0, "actor_entropy": 0.2646074982420091, "alpha_loss": -0.011349240620245015, "alpha_value": 0.21308417382531533, "duration": 195.13343119621277, "step": 42500}
{"episode_reward": 256.6875513950091, "episode": 341.0, "Q1 loss": 11.538231010437011, "Q2 loss": 11.490674903869628, "Mean Target Q": 189.1833494873047, "Mean Q1": 189.17902124023436, "Mean Q2": 189.17991943359374, "critic_loss": 23.028905853271485, "batch_reward": 1.4616417388916016, "actor_loss": -190.1056106809586, "actor_target_entropy": -1.0, "actor_entropy": 0.2744324481676495, "alpha_loss": -0.003297303078903092, "alpha_value": 0.21373523888554838, "duration": 201.0776264667511, "step": 42625}
{"episode_reward": 239.12708285825747, "episode": 342.0, "Q1 loss": 12.003344711303711, "Q2 loss": 11.959014312744142, "Mean Target Q": 189.43866845703124, "Mean Q1": 189.43398315429687, "Mean Q2": 189.43243310546876, "critic_loss": 23.96235905456543, "batch_reward": 1.465774432182312, "actor_loss": -190.27958137758316, "actor_target_entropy": -1.0, "actor_entropy": 0.2440806209079681, "alpha_loss": 0.0026110136175468085, "alpha_value": 0.21374311772332089, "duration": 189.3987419605255, "step": 42750}
{"episode_reward": 191.70869576086153, "episode": 343.0, "Q1 loss": 11.766819885253906, "Q2 loss": 11.791328590393066, "Mean Target Q": 189.61457678222655, "Mean Q1": 189.6147724609375, "Mean Q2": 189.6149403076172, "critic_loss": 23.558148406982422, "batch_reward": 1.4589128475189208, "actor_loss": -190.5089598156157, "actor_target_entropy": -1.0, "actor_entropy": 0.2353400427197653, "alpha_loss": -0.0023001498664684946, "alpha_value": 0.21374970196335513, "duration": 189.57720184326172, "step": 42875}
{"episode_reward": 222.34296167361362, "episode": 344.0, "Q1 loss": 12.201647239685059, "Q2 loss": 12.144583335876465, "Mean Target Q": 189.85369409179688, "Mean Q1": 189.849513671875, "Mean Q2": 189.84885314941405, "critic_loss": 24.346230560302736, "batch_reward": 1.4737236938476563, "actor_loss": -190.67280996999432, "actor_target_entropy": -1.0, "actor_entropy": 0.27441100848297917, "alpha_loss": -0.0019909804461583974, "alpha_value": 0.21395061404827537, "duration": 173.04325699806213, "step": 43000}
{"episode_reward": 296.2132921475702, "episode": 345.0, "Q1 loss": 12.07595711517334, "Q2 loss": 12.048912574768066, "Mean Target Q": 190.00774645996094, "Mean Q1": 190.00799731445312, "Mean Q2": 190.0106484375, "critic_loss": 24.124869689941406, "batch_reward": 1.4629750547409057, "actor_loss": -190.88341025700646, "actor_target_entropy": -1.0, "actor_entropy": 0.2630392192375092, "alpha_loss": 0.004030656402132341, "alpha_value": 0.2139197452746754, "duration": 163.79022979736328, "step": 43125}
{"episode_reward": 240.6854831230509, "episode": 346.0, "Q1 loss": 11.583494087219238, "Q2 loss": 11.505380447387695, "Mean Target Q": 190.15622290039062, "Mean Q1": 190.1506827392578, "Mean Q2": 190.15065405273438, "critic_loss": 23.088874572753905, "batch_reward": 1.4735398368835448, "actor_loss": -191.1270257273028, "actor_target_entropy": -1.0, "actor_entropy": 0.2361123867092594, "alpha_loss": -0.002754849015599898, "alpha_value": 0.21371059483949698, "duration": 153.5002248287201, "step": 43250}
{"episode_reward": 257.88475423548164, "episode": 347.0, "Q1 loss": 11.768820266723633, "Q2 loss": 11.657461807250977, "Mean Target Q": 190.27370739746092, "Mean Q1": 190.2723807373047, "Mean Q2": 190.2721551513672, "critic_loss": 23.426282119750976, "batch_reward": 1.4633184509277344, "actor_loss": -191.1462162562779, "actor_target_entropy": -1.0, "actor_entropy": 0.25260631408956313, "alpha_loss": 0.003999352165024787, "alpha_value": 0.21366361555720872, "duration": 163.65664672851562, "step": 43375}
{"episode_reward": 248.6183131950268, "episode": 348.0, "Q1 loss": 11.595809280395509, "Q2 loss": 11.519322410583497, "Mean Target Q": 190.64585095214844, "Mean Q1": 190.6443555908203, "Mean Q2": 190.643365234375, "critic_loss": 23.115131759643553, "batch_reward": 1.4699521141052245, "actor_loss": -191.5035631733556, "actor_target_entropy": -1.0, "actor_entropy": 0.27067587560703676, "alpha_loss": -0.0012264169392085845, "alpha_value": 0.21367525797023226, "duration": 171.39554834365845, "step": 43500}
{"episode_reward": 274.2340703796008, "episode": 349.0, "Q1 loss": 11.69731078338623, "Q2 loss": 11.575428833007813, "Mean Target Q": 190.82238940429687, "Mean Q1": 190.82212963867187, "Mean Q2": 190.8219580078125, "critic_loss": 23.272739639282225, "batch_reward": 1.4786245737075805, "actor_loss": -191.69498189290366, "actor_target_entropy": -1.0, "actor_entropy": 0.28521368995545404, "alpha_loss": -0.006824166676591313, "alpha_value": 0.21390439890087104, "duration": 182.1289186477661, "step": 43625}
{"episode_reward": 271.5041265509685, "episode": 350.0, "Q1 loss": 11.721619148254394, "Q2 loss": 11.640126815795899, "Mean Target Q": 190.90981225585938, "Mean Q1": 190.90561010742186, "Mean Q2": 190.90747668457033, "critic_loss": 23.361746032714844, "batch_reward": 1.469631236076355, "actor_loss": -191.8309811007592, "actor_target_entropy": -1.0, "actor_entropy": 0.28247300030723693, "alpha_loss": 0.004635330120612296, "alpha_value": 0.21399413338083684, "duration": 205.65432119369507, "step": 43750}
{"episode_reward": 329.44070360020953, "episode": 351.0, "Q1 loss": 11.747500801086426, "Q2 loss": 11.687717399597169, "Mean Target Q": 191.18686877441405, "Mean Q1": 191.186267578125, "Mean Q2": 191.18612622070313, "critic_loss": 23.435218231201173, "batch_reward": 1.470801640510559, "actor_loss": -192.09271748860678, "actor_target_entropy": -1.0, "actor_entropy": 0.27641902509189786, "alpha_loss": -0.0016104753447016553, "alpha_value": 0.21402235916809859, "duration": 184.30996918678284, "step": 43875}
{"episode_reward": 313.7918376733794, "episode": 352.0, "Q1 loss": 11.531483421325683, "Q2 loss": 11.480025093078613, "Mean Target Q": 191.3782166748047, "Mean Q1": 191.37822131347656, "Mean Q2": 191.37712731933593, "critic_loss": 23.01150848388672, "batch_reward": 1.4721600427627564, "actor_loss": -192.36702408329134, "actor_target_entropy": -1.0, "actor_entropy": 0.2922061275570623, "alpha_loss": -0.007114269996001836, "alpha_value": 0.21433642334591516, "duration": 189.12468028068542, "step": 44000}
{"episode_reward": 290.79032699657574, "episode": 353.0, "Q1 loss": 11.892403076171876, "Q2 loss": 11.888811935424805, "Mean Target Q": 191.61584143066406, "Mean Q1": 191.6092960205078, "Mean Q2": 191.60830432128907, "critic_loss": 23.781215057373046, "batch_reward": 1.48584801197052, "actor_loss": -192.5361577594091, "actor_target_entropy": -1.0, "actor_entropy": 0.2836648746142312, "alpha_loss": 0.001830010129774492, "alpha_value": 0.21455912332552243, "duration": 184.33310079574585, "step": 44125}
{"episode_reward": 223.67355978232663, "episode": 354.0, "Q1 loss": 11.747257972717286, "Q2 loss": 11.652251991271973, "Mean Target Q": 191.84385754394532, "Mean Q1": 191.84310864257813, "Mean Q2": 191.84448193359376, "critic_loss": 23.399509963989257, "batch_reward": 1.4883238334655762, "actor_loss": -192.75515919346964, "actor_target_entropy": -1.0, "actor_entropy": 0.26382517502192526, "alpha_loss": -0.003033050918020308, "alpha_value": 0.2143733698821926, "duration": 198.00160360336304, "step": 44250}
{"episode_reward": 227.94974664708278, "episode": 355.0, "Q1 loss": 11.572865303039551, "Q2 loss": 11.615851921081543, "Mean Target Q": 192.00446520996093, "Mean Q1": 191.99771252441406, "Mean Q2": 191.99915441894532, "critic_loss": 23.18871726989746, "batch_reward": 1.4809473714828492, "actor_loss": -192.88740854414684, "actor_target_entropy": -1.0, "actor_entropy": 0.28408101319320617, "alpha_loss": -0.0001365208373745046, "alpha_value": 0.21476453242953997, "duration": 186.5963683128357, "step": 44375}
{"episode_reward": 272.2984480699032, "episode": 356.0, "Q1 loss": 11.811933883666992, "Q2 loss": 11.691284187316894, "Mean Target Q": 192.22272937011718, "Mean Q1": 192.2218865966797, "Mean Q2": 192.219435546875, "critic_loss": 23.503218032836916, "batch_reward": 1.4837366752624512, "actor_loss": -193.11865775815903, "actor_target_entropy": -1.0, "actor_entropy": 0.27223237123220195, "alpha_loss": 0.0027007961780914375, "alpha_value": 0.21455874070775446, "duration": 196.79861330986023, "step": 44500}
{"episode_reward": 176.76304504913836, "episode": 357.0, "Q1 loss": 11.468499267578125, "Q2 loss": 11.466440834045411, "Mean Target Q": 192.49497802734376, "Mean Q1": 192.48834399414062, "Mean Q2": 192.4887587890625, "critic_loss": 22.93494009399414, "batch_reward": 1.4940351285934448, "actor_loss": -193.35749913775732, "actor_target_entropy": -1.0, "actor_entropy": 0.2714320040411419, "alpha_loss": -0.007713210149963815, "alpha_value": 0.21475372865261946, "duration": 190.36476373672485, "step": 44625}
{"episode_reward": 276.54846369052365, "episode": 358.0, "Q1 loss": 11.66816722869873, "Q2 loss": 11.658158554077149, "Mean Target Q": 192.6220439453125, "Mean Q1": 192.62157470703124, "Mean Q2": 192.62123364257812, "critic_loss": 23.326325805664062, "batch_reward": 1.4836888875961303, "actor_loss": -193.4695279521327, "actor_target_entropy": -1.0, "actor_entropy": 0.26613571975500355, "alpha_loss": -0.0021588045187414654, "alpha_value": 0.21507870799437023, "duration": 190.96483445167542, "step": 44750}
{"episode_reward": 233.30244841134626, "episode": 359.0, "Q1 loss": 11.700304168701171, "Q2 loss": 11.71008024597168, "Mean Target Q": 192.7783634033203, "Mean Q1": 192.77978918457032, "Mean Q2": 192.78192626953125, "critic_loss": 23.410384368896484, "batch_reward": 1.4986990156173705, "actor_loss": -193.63668459937685, "actor_target_entropy": -1.0, "actor_entropy": 0.27447162403000724, "alpha_loss": 0.005146365856663102, "alpha_value": 0.2150814454523924, "duration": 194.0077245235443, "step": 44875}
{"episode_reward": 183.95465957377058, "episode": 360.0, "Q1 loss": 11.355585189819337, "Q2 loss": 11.330461112976074, "Mean Target Q": 192.92089221191407, "Mean Q1": 192.91237609863282, "Mean Q2": 192.91221643066407, "critic_loss": 22.686046249389648, "batch_reward": 1.4834151010513306, "actor_loss": -193.77957547095514, "actor_target_entropy": -1.0, "actor_entropy": 0.2742895951434489, "alpha_loss": 0.0036013302949046895, "alpha_value": 0.21460816021204637, "step": 45000}
{"duration": 210.88124442100525, "step": 45000}
{"episode_reward": 199.4445413809476, "episode": 361.0, "Q1 loss": 11.295626182556152, "Q2 loss": 11.168883659362793, "Mean Target Q": 193.1831424560547, "Mean Q1": 193.18725927734374, "Mean Q2": 193.18551708984376, "critic_loss": 22.464509872436523, "batch_reward": 1.489414834022522, "actor_loss": -194.00931851826016, "actor_target_entropy": -1.0, "actor_entropy": 0.26989427989437464, "alpha_loss": 0.001014384579667378, "alpha_value": 0.21447734547071082, "duration": 188.69506001472473, "step": 45125}
{"episode_reward": 204.37139012726038, "episode": 362.0, "Q1 loss": 11.91812801361084, "Q2 loss": 11.792635177612304, "Mean Target Q": 193.32319201660155, "Mean Q1": 193.31990197753908, "Mean Q2": 193.32041345214844, "critic_loss": 23.710763244628907, "batch_reward": 1.4816570558547975, "actor_loss": -194.16869624968498, "actor_target_entropy": -1.0, "actor_entropy": 0.29446305286499763, "alpha_loss": 2.0320885889833013e-05, "alpha_value": 0.2145704784846451, "duration": 189.33987140655518, "step": 45250}
{"episode_reward": 239.02233538767584, "episode": 363.0, "Q1 loss": 11.36418544769287, "Q2 loss": 11.408477081298829, "Mean Target Q": 193.5820322265625, "Mean Q1": 193.5809510498047, "Mean Q2": 193.58097631835938, "critic_loss": 22.77266256713867, "batch_reward": 1.499471336364746, "actor_loss": -194.47920808337983, "actor_target_entropy": -1.0, "actor_entropy": 0.2666266253070226, "alpha_loss": -0.0012451503832366258, "alpha_value": 0.21446337729785467, "duration": 197.57063674926758, "step": 45375}
{"episode_reward": 300.12410708530103, "episode": 364.0, "Q1 loss": 11.352423500061034, "Q2 loss": 11.26691603088379, "Mean Target Q": 193.73078161621095, "Mean Q1": 193.72601440429688, "Mean Q2": 193.727140625, "critic_loss": 22.61933950805664, "batch_reward": 1.4960613689422608, "actor_loss": -194.63184701242756, "actor_target_entropy": -1.0, "actor_entropy": 0.26314933706195126, "alpha_loss": -0.005133131740524644, "alpha_value": 0.21481276334302313, "duration": 192.06244945526123, "step": 45500}
{"episode_reward": 271.01687552320465, "episode": 365.0, "Q1 loss": 11.816934616088867, "Q2 loss": 11.759374313354492, "Mean Target Q": 193.94958374023437, "Mean Q1": 193.94447802734376, "Mean Q2": 193.94354455566406, "critic_loss": 23.576308959960937, "batch_reward": 1.4990322408676147, "actor_loss": -194.82140701536147, "actor_target_entropy": -1.0, "actor_entropy": 0.2768669907772352, "alpha_loss": -5.0249254508387475e-05, "alpha_value": 0.21496234818232723, "duration": 190.63614988327026, "step": 45625}
{"episode_reward": 222.57992742926828, "episode": 366.0, "Q1 loss": 11.72956704711914, "Q2 loss": 11.685769020080567, "Mean Target Q": 194.08479553222656, "Mean Q1": 194.08164685058594, "Mean Q2": 194.0807763671875, "critic_loss": 23.415336044311523, "batch_reward": 1.495051022529602, "actor_loss": -194.95331794984878, "actor_target_entropy": -1.0, "actor_entropy": 0.2507675790017651, "alpha_loss": -0.002914008650658352, "alpha_value": 0.2152124482299881, "duration": 200.07276678085327, "step": 45750}
{"episode_reward": 238.69434341522918, "episode": 367.0, "Q1 loss": 11.666754997253419, "Q2 loss": 11.673625190734864, "Mean Target Q": 194.251892578125, "Mean Q1": 194.2471124267578, "Mean Q2": 194.24862939453126, "critic_loss": 23.34038020324707, "batch_reward": 1.5063414793014527, "actor_loss": -195.13349405924478, "actor_target_entropy": -1.0, "actor_entropy": 0.2659080721556194, "alpha_loss": 0.007237439136213017, "alpha_value": 0.21506899030699433, "duration": 189.0561318397522, "step": 45875}
{"episode_reward": 223.16679474400974, "episode": 368.0, "Q1 loss": 11.490429801940918, "Q2 loss": 11.469714820861816, "Mean Target Q": 194.42927416992188, "Mean Q1": 194.43263757324218, "Mean Q2": 194.43252185058594, "critic_loss": 22.960144638061525, "batch_reward": 1.4871480493545532, "actor_loss": -195.20964074903918, "actor_target_entropy": -1.0, "actor_entropy": 0.28388441185797414, "alpha_loss": 0.007331826855548688, "alpha_value": 0.21431159432878982, "duration": 185.82402873039246, "step": 46000}
{"episode_reward": 151.34423419304758, "episode": 369.0, "Q1 loss": 11.8276552734375, "Q2 loss": 11.852356353759765, "Mean Target Q": 194.723025390625, "Mean Q1": 194.71420324707032, "Mean Q2": 194.7115690917969, "critic_loss": 23.680011688232423, "batch_reward": 1.502335753440857, "actor_loss": -195.5831068735274, "actor_target_entropy": -1.0, "actor_entropy": 0.2776632701593732, "alpha_loss": 0.0015867710435053422, "alpha_value": 0.21394646637926046, "duration": 198.49990701675415, "step": 46125}
{"episode_reward": 250.56173366219937, "episode": 370.0, "Q1 loss": 11.72639421081543, "Q2 loss": 11.67394401550293, "Mean Target Q": 194.87554272460937, "Mean Q1": 194.87606823730468, "Mean Q2": 194.87698107910157, "critic_loss": 23.400338134765626, "batch_reward": 1.4908987102508544, "actor_loss": -195.78875289424772, "actor_target_entropy": -1.0, "actor_entropy": 0.29805920417270354, "alpha_loss": -0.006477482993373527, "alpha_value": 0.2141383246580896, "duration": 195.10846090316772, "step": 46250}
{"episode_reward": 125.53705881788355, "episode": 371.0, "Q1 loss": 11.251177429199219, "Q2 loss": 11.2581293258667, "Mean Target Q": 195.14222497558595, "Mean Q1": 195.14238720703125, "Mean Q2": 195.14208056640626, "critic_loss": 22.509306686401366, "batch_reward": 1.4924352865219117, "actor_loss": -196.1610342358786, "actor_target_entropy": -1.0, "actor_entropy": 0.24580316742261252, "alpha_loss": -0.01243907791407158, "alpha_value": 0.2149481343820913, "duration": 186.09688258171082, "step": 46375}
{"episode_reward": 203.0615987973881, "episode": 372.0, "Q1 loss": 12.249045875549317, "Q2 loss": 12.115359596252441, "Mean Target Q": 195.1895216064453, "Mean Q1": 195.18614196777344, "Mean Q2": 195.1910859375, "critic_loss": 24.364405487060548, "batch_reward": 1.4980660543441773, "actor_loss": -196.0550091651178, "actor_target_entropy": -1.0, "actor_entropy": 0.24094788369632536, "alpha_loss": -0.002815285494791404, "alpha_value": 0.21549228126952205, "duration": 197.39979767799377, "step": 46500}
{"episode_reward": 306.067073320613, "episode": 373.0, "Q1 loss": 11.889579055786132, "Q2 loss": 11.858598449707031, "Mean Target Q": 195.57241442871094, "Mean Q1": 195.568884765625, "Mean Q2": 195.56429650878906, "critic_loss": 23.748177520751952, "batch_reward": 1.4960687189102173, "actor_loss": -196.41707550533235, "actor_target_entropy": -1.0, "actor_entropy": 0.24678488241301644, "alpha_loss": -0.00041809715774087676, "alpha_value": 0.21552809417015426, "duration": 197.36283445358276, "step": 46625}
{"episode_reward": 252.10212095552015, "episode": 374.0, "Q1 loss": 11.720686653137207, "Q2 loss": 11.72180248260498, "Mean Target Q": 195.60614111328124, "Mean Q1": 195.604765625, "Mean Q2": 195.60711193847655, "critic_loss": 23.44248907470703, "batch_reward": 1.5019984722137452, "actor_loss": -196.47199101601876, "actor_target_entropy": -1.0, "actor_entropy": 0.2696815397470228, "alpha_loss": 0.0026989861207473423, "alpha_value": 0.2155971127176641, "duration": 186.73290634155273, "step": 46750}
{"episode_reward": 250.12195190176652, "episode": 375.0, "Q1 loss": 11.629391273498536, "Q2 loss": 11.55059358215332, "Mean Target Q": 195.81121704101562, "Mean Q1": 195.82014489746095, "Mean Q2": 195.82076171875, "critic_loss": 23.179984893798828, "batch_reward": 1.4895472526550293, "actor_loss": -196.5618906172495, "actor_target_entropy": -1.0, "actor_entropy": 0.2905883663703525, "alpha_loss": 0.0014916096725279377, "alpha_value": 0.21541000227085577, "duration": 197.9113917350769, "step": 46875}
{"episode_reward": 235.6433284402057, "episode": 376.0, "Q1 loss": 12.112373397827149, "Q2 loss": 11.991083763122559, "Mean Target Q": 196.00901684570312, "Mean Q1": 195.9994298095703, "Mean Q2": 195.99802416992188, "critic_loss": 24.103457275390625, "batch_reward": 1.5016896085739135, "actor_loss": -196.87091187507875, "actor_target_entropy": -1.0, "actor_entropy": 0.2624373308593227, "alpha_loss": -0.001195865863513562, "alpha_value": 0.21542793630510063, "duration": 196.46253275871277, "step": 47000}
{"episode_reward": 321.80255815426995, "episode": 377.0, "Q1 loss": 11.939454238891601, "Q2 loss": 11.885110122680665, "Mean Target Q": 196.21384484863282, "Mean Q1": 196.21378454589845, "Mean Q2": 196.2139836425781, "critic_loss": 23.82456428527832, "batch_reward": 1.510416834831238, "actor_loss": -197.04077414860802, "actor_target_entropy": -1.0, "actor_entropy": 0.26164724062832573, "alpha_loss": 0.0016751738139502113, "alpha_value": 0.21539181261739915, "duration": 188.08669114112854, "step": 47125}
{"episode_reward": 287.0711952756958, "episode": 378.0, "Q1 loss": 11.481799377441407, "Q2 loss": 11.467322090148926, "Mean Target Q": 196.37113793945312, "Mean Q1": 196.3664045410156, "Mean Q2": 196.36517700195313, "critic_loss": 22.94912138366699, "batch_reward": 1.509680338859558, "actor_loss": -197.19204687303113, "actor_target_entropy": -1.0, "actor_entropy": 0.2432414884528806, "alpha_loss": -0.006039313436861361, "alpha_value": 0.21555872726546518, "duration": 188.1006531715393, "step": 47250}
{"episode_reward": 265.84370423203796, "episode": 379.0, "Q1 loss": 11.92995245361328, "Q2 loss": 11.94341170501709, "Mean Target Q": 196.6176083984375, "Mean Q1": 196.61814111328124, "Mean Q2": 196.61647485351563, "critic_loss": 23.873364196777345, "batch_reward": 1.5149147577285766, "actor_loss": -197.53828599717883, "actor_target_entropy": -1.0, "actor_entropy": 0.27269559554637424, "alpha_loss": 0.0013663300963503028, "alpha_value": 0.21580173717403814, "duration": 182.86077904701233, "step": 47375}
{"episode_reward": 185.80746669190458, "episode": 380.0, "Q1 loss": 11.869569389343262, "Q2 loss": 11.882657104492187, "Mean Target Q": 196.84481909179686, "Mean Q1": 196.84029846191407, "Mean Q2": 196.84168200683592, "critic_loss": 23.752226470947267, "batch_reward": 1.5212435798645019, "actor_loss": -197.78911910518522, "actor_target_entropy": -1.0, "actor_entropy": 0.2844598555276471, "alpha_loss": -0.0012006484114775254, "alpha_value": 0.21565470690622318, "duration": 201.60687279701233, "step": 47500}
{"episode_reward": 337.1969602280471, "episode": 381.0, "Q1 loss": 11.91974961090088, "Q2 loss": 11.970094505310058, "Mean Target Q": 197.01018322753907, "Mean Q1": 197.01217309570313, "Mean Q2": 197.01236865234375, "critic_loss": 23.889844161987305, "batch_reward": 1.5177991123199464, "actor_loss": -197.94628034319197, "actor_target_entropy": -1.0, "actor_entropy": 0.27575273173195974, "alpha_loss": -0.0010924488638660737, "alpha_value": 0.21558798374534988, "duration": 180.173442363739, "step": 47625}
{"episode_reward": 303.5619579958201, "episode": 382.0, "Q1 loss": 11.944063507080077, "Q2 loss": 11.87493051147461, "Mean Target Q": 197.1951219482422, "Mean Q1": 197.18851403808594, "Mean Q2": 197.18592492675782, "critic_loss": 23.81899403381348, "batch_reward": 1.518542486190796, "actor_loss": -198.05296547182144, "actor_target_entropy": -1.0, "actor_entropy": 0.29953451406571174, "alpha_loss": 7.183375513000834e-05, "alpha_value": 0.2157667017230178, "duration": 168.82863855361938, "step": 47750}
{"episode_reward": 273.9956387853619, "episode": 383.0, "Q1 loss": 11.923697578430176, "Q2 loss": 11.927686271667481, "Mean Target Q": 197.33287646484376, "Mean Q1": 197.33205078125, "Mean Q2": 197.3319227294922, "critic_loss": 23.85138381958008, "batch_reward": 1.5273226175308228, "actor_loss": -198.04114932105654, "actor_target_entropy": -1.0, "actor_entropy": 0.2799500290836607, "alpha_loss": 0.0072067683887860135, "alpha_value": 0.215517261930983, "duration": 179.189617395401, "step": 47875}
{"episode_reward": 261.80063531394194, "episode": 384.0, "Q1 loss": 11.813334167480468, "Q2 loss": 11.743203575134277, "Mean Target Q": 197.52625415039063, "Mean Q1": 197.52560314941405, "Mean Q2": 197.5267706298828, "critic_loss": 23.55653775024414, "batch_reward": 1.5238062133789063, "actor_loss": -198.37881494337512, "actor_target_entropy": -1.0, "actor_entropy": 0.29037223828415715, "alpha_loss": -0.0020887037014378413, "alpha_value": 0.21520531444424343, "duration": 170.81946063041687, "step": 48000}
{"episode_reward": 243.9102785191938, "episode": 385.0, "Q1 loss": 11.856601356506347, "Q2 loss": 11.878684894561768, "Mean Target Q": 197.7727706298828, "Mean Q1": 197.76385314941408, "Mean Q2": 197.7638681640625, "critic_loss": 23.73528630065918, "batch_reward": 1.5142435073852538, "actor_loss": -198.61533949110242, "actor_target_entropy": -1.0, "actor_entropy": 0.28334252914739033, "alpha_loss": 0.0009519832083097999, "alpha_value": 0.21534993195258617, "duration": 169.19636940956116, "step": 48125}
{"episode_reward": 250.41615498649526, "episode": 386.0, "Q1 loss": 11.969287879943847, "Q2 loss": 11.958209533691406, "Mean Target Q": 197.85627709960937, "Mean Q1": 197.85838208007812, "Mean Q2": 197.86028649902343, "critic_loss": 23.927497421264647, "batch_reward": 1.5205372581481933, "actor_loss": -198.77267283778036, "actor_target_entropy": -1.0, "actor_entropy": 0.2511214291857135, "alpha_loss": -3.642372171124143e-05, "alpha_value": 0.2152912523302421, "duration": 171.0799548625946, "step": 48250}
{"episode_reward": 194.80517668442116, "episode": 387.0, "Q1 loss": 11.507468734741211, "Q2 loss": 11.48034381866455, "Mean Target Q": 198.14676428222657, "Mean Q1": 198.1388016357422, "Mean Q2": 198.13694018554688, "critic_loss": 22.98781251525879, "batch_reward": 1.5194039993286133, "actor_loss": -199.06258041139634, "actor_target_entropy": -1.0, "actor_entropy": 0.2609625009317247, "alpha_loss": -0.0004294169687902525, "alpha_value": 0.215421896393325, "duration": 175.43213200569153, "step": 48375}
{"episode_reward": 120.74595889014873, "episode": 388.0, "Q1 loss": 11.87825774383545, "Q2 loss": 11.794078002929687, "Mean Target Q": 198.3230692138672, "Mean Q1": 198.32349938964845, "Mean Q2": 198.3233740234375, "critic_loss": 23.672335739135743, "batch_reward": 1.5201301803588867, "actor_loss": -199.28330304545742, "actor_target_entropy": -1.0, "actor_entropy": 0.25290531713155007, "alpha_loss": -0.0011634365768141805, "alpha_value": 0.21537604767761434, "duration": 176.9211049079895, "step": 48500}
{"episode_reward": 241.68515430991908, "episode": 389.0, "Q1 loss": 12.176492126464844, "Q2 loss": 12.087587692260742, "Mean Target Q": 198.5259002685547, "Mean Q1": 198.52377294921874, "Mean Q2": 198.5232149658203, "critic_loss": 24.264079788208008, "batch_reward": 1.5115586833953858, "actor_loss": -199.44691709488157, "actor_target_entropy": -1.0, "actor_entropy": 0.28172438721808174, "alpha_loss": -0.0028700559226322976, "alpha_value": 0.21546505833115542, "duration": 167.42287516593933, "step": 48625}
{"episode_reward": 197.68055448300194, "episode": 390.0, "Q1 loss": 11.456388175964355, "Q2 loss": 11.408352745056153, "Mean Target Q": 198.67636096191407, "Mean Q1": 198.67140441894531, "Mean Q2": 198.6717823486328, "critic_loss": 22.864740844726562, "batch_reward": 1.517820478439331, "actor_loss": -199.53145771641886, "actor_target_entropy": -1.0, "actor_entropy": 0.2864107318943547, "alpha_loss": 0.00277423154893181, "alpha_value": 0.2155560951629185, "duration": 181.48313927650452, "step": 48750}
{"episode_reward": 220.49382814302777, "episode": 391.0, "Q1 loss": 11.721483726501464, "Q2 loss": 11.735358818054198, "Mean Target Q": 198.99847583007812, "Mean Q1": 198.9966942138672, "Mean Q2": 198.99735302734376, "critic_loss": 23.456842559814454, "batch_reward": 1.525599630355835, "actor_loss": -199.85200694250682, "actor_target_entropy": -1.0, "actor_entropy": 0.26202602069529274, "alpha_loss": 0.005919668694130248, "alpha_value": 0.2153038271781701, "duration": 175.4642014503479, "step": 48875}
{"episode_reward": 210.76445797324516, "episode": 392.0, "Q1 loss": 11.767294609069824, "Q2 loss": 11.693836364746094, "Mean Target Q": 199.0687431640625, "Mean Q1": 199.06339697265625, "Mean Q2": 199.0647255859375, "critic_loss": 23.461130950927735, "batch_reward": 1.5068275699615479, "actor_loss": -200.08342644476122, "actor_target_entropy": -1.0, "actor_entropy": 0.24848217757478838, "alpha_loss": 0.004386069771322993, "alpha_value": 0.21471559675723978, "duration": 182.8772521018982, "step": 49000}
{"episode_reward": 239.18935189481573, "episode": 393.0, "Q1 loss": 12.011693496704101, "Q2 loss": 11.94821546936035, "Mean Target Q": 199.35122595214844, "Mean Q1": 199.3523262939453, "Mean Q2": 199.3509520263672, "critic_loss": 23.95990899658203, "batch_reward": 1.5355421743392945, "actor_loss": -200.21126495845735, "actor_target_entropy": -1.0, "actor_entropy": 0.24473879072401258, "alpha_loss": -0.00020500561518092003, "alpha_value": 0.21466203050208338, "duration": 179.58239912986755, "step": 49125}
{"episode_reward": 317.04854459506777, "episode": 394.0, "Q1 loss": 11.853022064208984, "Q2 loss": 11.851890609741211, "Mean Target Q": 199.44575524902345, "Mean Q1": 199.44835192871093, "Mean Q2": 199.45056225585938, "critic_loss": 23.70491275024414, "batch_reward": 1.5173835172653198, "actor_loss": -200.46781109225364, "actor_target_entropy": -1.0, "actor_entropy": 0.25934400097016364, "alpha_loss": -0.002433109423896718, "alpha_value": 0.21478372394878234, "duration": 170.18886542320251, "step": 49250}
{"episode_reward": 248.86724972358917, "episode": 395.0, "Q1 loss": 11.970893096923827, "Q2 loss": 11.903204330444336, "Mean Target Q": 199.45882641601563, "Mean Q1": 199.45249755859376, "Mean Q2": 199.4503817138672, "critic_loss": 23.87409750366211, "batch_reward": 1.5071956424713135, "actor_loss": -200.4303673638238, "actor_target_entropy": -1.0, "actor_entropy": 0.2815881454282337, "alpha_loss": 0.0009443044610735443, "alpha_value": 0.21480936668057204, "duration": 182.25167798995972, "step": 49375}
{"episode_reward": 284.54048304075445, "episode": 396.0, "Q1 loss": 12.172483833312988, "Q2 loss": 12.183980979919433, "Mean Target Q": 199.77925012207032, "Mean Q1": 199.77763049316405, "Mean Q2": 199.77760754394532, "critic_loss": 24.356464874267576, "batch_reward": 1.5172515811920166, "actor_loss": -200.67710482689643, "actor_target_entropy": -1.0, "actor_entropy": 0.2606967776533096, "alpha_loss": 0.006901994120374682, "alpha_value": 0.21451738389154643, "duration": 177.34758806228638, "step": 49500}
{"episode_reward": 302.21909192791094, "episode": 397.0, "Q1 loss": 12.197824462890624, "Q2 loss": 12.122859672546387, "Mean Target Q": 200.1711473388672, "Mean Q1": 200.17365783691406, "Mean Q2": 200.17285620117187, "critic_loss": 24.320684097290037, "batch_reward": 1.5422324275970458, "actor_loss": -201.0977536156064, "actor_target_entropy": -1.0, "actor_entropy": 0.2505704337169254, "alpha_loss": 0.004198525566607714, "alpha_value": 0.21402852706409065, "duration": 173.7190923690796, "step": 49625}
{"episode_reward": 206.86725575975686, "episode": 398.0, "Q1 loss": 12.637926208496093, "Q2 loss": 12.606461059570313, "Mean Target Q": 200.3509309082031, "Mean Q1": 200.34656091308594, "Mean Q2": 200.34816174316407, "critic_loss": 25.24438720703125, "batch_reward": 1.5249723825454713, "actor_loss": -201.28811793173514, "actor_target_entropy": -1.0, "actor_entropy": 0.2757853833177397, "alpha_loss": -0.0015975085909538452, "alpha_value": 0.21389301695612503, "duration": 152.2358512878418, "step": 49750}
{"episode_reward": 264.8459396412052, "episode": 399.0, "Q1 loss": 12.324470031738281, "Q2 loss": 12.353826301574706, "Mean Target Q": 200.542478515625, "Mean Q1": 200.53909545898438, "Mean Q2": 200.53801806640624, "critic_loss": 24.678296325683593, "batch_reward": 1.529286681175232, "actor_loss": -201.47659761943515, "actor_target_entropy": -1.0, "actor_entropy": 0.29479788220117964, "alpha_loss": 0.002074519235138146, "alpha_value": 0.21388932685793277, "duration": 145.73658156394958, "step": 49875}
{"episode_reward": 249.68319736773276, "episode": 400.0, "Q1 loss": 12.45817694091797, "Q2 loss": 12.419202888488769, "Mean Target Q": 200.69867346191407, "Mean Q1": 200.69877673339843, "Mean Q2": 200.70002734375, "critic_loss": 24.87737986755371, "batch_reward": 1.5347871465682983, "actor_loss": -201.67020563925468, "actor_target_entropy": -1.0, "actor_entropy": 0.28036778179868577, "alpha_loss": -0.002322044306164307, "alpha_value": 0.21391269085356818, "step": 50000}
{"duration": 184.29531121253967, "step": 50000}
{"episode_reward": 306.33399452044455, "episode": 401.0, "Q1 loss": 12.477683265686036, "Q2 loss": 12.5022021484375, "Mean Target Q": 200.91768395996093, "Mean Q1": 200.92022497558594, "Mean Q2": 200.91837329101563, "critic_loss": 24.979885345458985, "batch_reward": 1.5420251121520996, "actor_loss": -201.84492952861484, "actor_target_entropy": -1.0, "actor_entropy": 0.2997957413631772, "alpha_loss": -0.006711112475761819, "alpha_value": 0.21443122606028914, "duration": 183.99784064292908, "step": 50125}
{"episode_reward": 279.5359855601229, "episode": 402.0, "Q1 loss": 12.751086502075195, "Q2 loss": 12.753525932312012, "Mean Target Q": 201.0796053466797, "Mean Q1": 201.07137744140624, "Mean Q2": 201.07336840820312, "critic_loss": 25.504612426757813, "batch_reward": 1.5452213354110718, "actor_loss": -201.97607864872103, "actor_target_entropy": -1.0, "actor_entropy": 0.2548819650565424, "alpha_loss": -0.004169730721191774, "alpha_value": 0.21471273654308212, "duration": 187.3295350074768, "step": 50250}
{"episode_reward": 233.4980904317145, "episode": 403.0, "Q1 loss": 12.62139207458496, "Q2 loss": 12.612689712524414, "Mean Target Q": 201.27225842285156, "Mean Q1": 201.26971618652342, "Mean Q2": 201.2649669189453, "critic_loss": 25.234081832885742, "batch_reward": 1.5415942888259888, "actor_loss": -202.27801804315476, "actor_target_entropy": -1.0, "actor_entropy": 0.25426891493418863, "alpha_loss": -0.007814757296785949, "alpha_value": 0.21507476895682764, "duration": 168.61519575119019, "step": 50375}
{"episode_reward": 288.3685663393247, "episode": 404.0, "Q1 loss": 12.80927175140381, "Q2 loss": 12.641639533996582, "Mean Target Q": 201.4216495361328, "Mean Q1": 201.42404260253906, "Mean Q2": 201.42709521484375, "critic_loss": 25.45091133117676, "batch_reward": 1.5297734966278076, "actor_loss": -202.28715958133822, "actor_target_entropy": -1.0, "actor_entropy": 0.28397203765569196, "alpha_loss": -0.004775816488320068, "alpha_value": 0.21564550373605657, "duration": 173.78771138191223, "step": 50500}
{"episode_reward": 221.4592446192749, "episode": 405.0, "Q1 loss": 12.592152473449707, "Q2 loss": 12.587932510375976, "Mean Target Q": 201.73152661132812, "Mean Q1": 201.72695629882813, "Mean Q2": 201.7272703857422, "critic_loss": 25.180084838867188, "batch_reward": 1.547517349243164, "actor_loss": -202.6868642171224, "actor_target_entropy": -1.0, "actor_entropy": 0.25130411083736115, "alpha_loss": -0.006049304546433545, "alpha_value": 0.21610729052621525, "duration": 178.98998999595642, "step": 50625}
{"episode_reward": 248.51974819871134, "episode": 406.0, "Q1 loss": 12.598633728027345, "Q2 loss": 12.535792106628419, "Mean Target Q": 201.79451953125, "Mean Q1": 201.79573767089843, "Mean Q2": 201.7952452392578, "critic_loss": 25.134425827026366, "batch_reward": 1.5296627016067506, "actor_loss": -202.71622343986266, "actor_target_entropy": -1.0, "actor_entropy": 0.27050030856363233, "alpha_loss": -0.0033899500830880096, "alpha_value": 0.21662261683700804, "duration": 165.65054845809937, "step": 50750}
{"episode_reward": 228.96646408291917, "episode": 407.0, "Q1 loss": 12.161385620117187, "Q2 loss": 12.22433268737793, "Mean Target Q": 202.08309594726563, "Mean Q1": 202.07360314941405, "Mean Q2": 202.0745244140625, "critic_loss": 24.38571826171875, "batch_reward": 1.5485225563049316, "actor_loss": -202.98717171805245, "actor_target_entropy": -1.0, "actor_entropy": 0.2754198934823748, "alpha_loss": -0.0018038508973808752, "alpha_value": 0.21674943145530018, "duration": 181.1776783466339, "step": 50875}
{"episode_reward": 315.6826957507225, "episode": 408.0, "Q1 loss": 12.261064628601074, "Q2 loss": 12.204414680480957, "Mean Target Q": 202.22587365722657, "Mean Q1": 202.22671130371094, "Mean Q2": 202.22777990722656, "critic_loss": 24.465479370117187, "batch_reward": 1.5428950967788697, "actor_loss": -203.07112170803933, "actor_target_entropy": -1.0, "actor_entropy": 0.29058371364108976, "alpha_loss": -0.000654280670137415, "alpha_value": 0.2166901463891135, "duration": 186.4289231300354, "step": 51000}
{"episode_reward": 282.16756653222586, "episode": 409.0, "Q1 loss": 12.677181602478028, "Q2 loss": 12.5785199508667, "Mean Target Q": 202.41698962402344, "Mean Q1": 202.40876110839844, "Mean Q2": 202.40842211914062, "critic_loss": 25.255701629638672, "batch_reward": 1.5435191164016724, "actor_loss": -203.39715067545572, "actor_target_entropy": -1.0, "actor_entropy": 0.2644306447297808, "alpha_loss": -0.005531439352558837, "alpha_value": 0.21700167321470193, "duration": 192.26014161109924, "step": 51125}
{"episode_reward": 244.47970232093698, "episode": 410.0, "Q1 loss": 11.941029014587402, "Q2 loss": 11.969156028747559, "Mean Target Q": 202.58353784179687, "Mean Q1": 202.5883282470703, "Mean Q2": 202.58868774414063, "critic_loss": 23.910184982299803, "batch_reward": 1.5482574062347412, "actor_loss": -203.54754441784274, "actor_target_entropy": -1.0, "actor_entropy": 0.2673352990419634, "alpha_loss": -0.008245580636280319, "alpha_value": 0.21756590628985314, "duration": 175.38539671897888, "step": 51250}
{"episode_reward": 77.73143292769825, "episode": 411.0, "Q1 loss": 12.477439575195312, "Q2 loss": 12.367214317321777, "Mean Target Q": 202.83175927734376, "Mean Q1": 202.82459924316407, "Mean Q2": 202.82308947753907, "critic_loss": 24.84465397644043, "batch_reward": 1.5565985565185547, "actor_loss": -203.80543178982205, "actor_target_entropy": -1.0, "actor_entropy": 0.2670712809241007, "alpha_loss": -0.009180846287765436, "alpha_value": 0.21832245181204593, "duration": 185.45553922653198, "step": 51375}
{"episode_reward": 279.6659620037242, "episode": 412.0, "Q1 loss": 12.1260923538208, "Q2 loss": 12.031099197387695, "Mean Target Q": 203.00455004882812, "Mean Q1": 203.00859692382812, "Mean Q2": 203.0091181640625, "critic_loss": 24.15719157409668, "batch_reward": 1.5501138935089112, "actor_loss": -203.86336369668282, "actor_target_entropy": -1.0, "actor_entropy": 0.28576331513543285, "alpha_loss": 0.00010456416695829361, "alpha_value": 0.21874366033403445, "duration": 171.11431622505188, "step": 51500}
{"episode_reward": 174.7320992925186, "episode": 413.0, "Q1 loss": 12.253711128234864, "Q2 loss": 12.277017578125, "Mean Target Q": 203.16807958984376, "Mean Q1": 203.16540698242187, "Mean Q2": 203.16715576171876, "critic_loss": 24.530728729248047, "batch_reward": 1.5505673742294313, "actor_loss": -204.08314756363157, "actor_target_entropy": -1.0, "actor_entropy": 0.28251060228499153, "alpha_loss": 0.0055705685878083815, "alpha_value": 0.21865731703365354, "duration": 184.82312679290771, "step": 51625}
{"episode_reward": 290.8290291035894, "episode": 414.0, "Q1 loss": 12.511924495697022, "Q2 loss": 12.525972785949707, "Mean Target Q": 203.31044091796875, "Mean Q1": 203.30543005371095, "Mean Q2": 203.30294165039064, "critic_loss": 25.037897216796875, "batch_reward": 1.538639169692993, "actor_loss": -204.28489758891445, "actor_target_entropy": -1.0, "actor_entropy": 0.3116862973378551, "alpha_loss": 0.0026474821854442837, "alpha_value": 0.2181086953637948, "duration": 177.1514127254486, "step": 51750}
{"episode_reward": 228.84274757891794, "episode": 415.0, "Q1 loss": 12.926430763244628, "Q2 loss": 12.884571418762206, "Mean Target Q": 203.5426561279297, "Mean Q1": 203.54218090820314, "Mean Q2": 203.54326879882814, "critic_loss": 25.811002212524414, "batch_reward": 1.5473663272857665, "actor_loss": -204.4702901688833, "actor_target_entropy": -1.0, "actor_entropy": 0.30383292289953384, "alpha_loss": 0.007558214226885448, "alpha_value": 0.217700840942887, "duration": 191.41724038124084, "step": 51875}
{"episode_reward": 285.4010870698667, "episode": 416.0, "Q1 loss": 12.60966040802002, "Q2 loss": 12.626975616455079, "Mean Target Q": 203.68011657714842, "Mean Q1": 203.6811572265625, "Mean Q2": 203.68009973144532, "critic_loss": 25.236636032104492, "batch_reward": 1.5521101675033568, "actor_loss": -204.56255242132372, "actor_target_entropy": -1.0, "actor_entropy": 0.2973471336787747, "alpha_loss": 0.009119279615040268, "alpha_value": 0.21703760031621522, "duration": 169.87199926376343, "step": 52000}
{"episode_reward": 238.79610503356858, "episode": 417.0, "Q1 loss": 12.108092819213867, "Q2 loss": 11.992011268615723, "Mean Target Q": 203.85100854492188, "Mean Q1": 203.84073388671874, "Mean Q2": 203.8418123779297, "critic_loss": 24.10010403442383, "batch_reward": 1.5593456754684447, "actor_loss": -204.69146728515625, "actor_target_entropy": -1.0, "actor_entropy": 0.2889030775617039, "alpha_loss": 0.0041502057537732145, "alpha_value": 0.21657675063811688, "duration": 180.17613744735718, "step": 52125}
{"episode_reward": 238.82704550705841, "episode": 418.0, "Q1 loss": 12.40374462890625, "Q2 loss": 12.248879684448243, "Mean Target Q": 204.0462305908203, "Mean Q1": 204.04511938476563, "Mean Q2": 204.04445080566407, "critic_loss": 24.652624328613282, "batch_reward": 1.5535936908721923, "actor_loss": -205.06699962000692, "actor_target_entropy": -1.0, "actor_entropy": 0.29261759356144934, "alpha_loss": -0.0015945272039501897, "alpha_value": 0.2163818758182108, "duration": 174.0750858783722, "step": 52250}
{"episode_reward": 308.4255894393041, "episode": 419.0, "Q1 loss": 11.994827285766602, "Q2 loss": 11.961035102844239, "Mean Target Q": 204.20493676757812, "Mean Q1": 204.1981759033203, "Mean Q2": 204.19835314941406, "critic_loss": 23.95586233520508, "batch_reward": 1.5503082275390625, "actor_loss": -205.1884041438027, "actor_target_entropy": -1.0, "actor_entropy": 0.2655136824127228, "alpha_loss": -0.008187139074185066, "alpha_value": 0.2167421506851802, "duration": 189.454904794693, "step": 52375}
{"episode_reward": 229.99964483648762, "episode": 420.0, "Q1 loss": 12.321088012695313, "Q2 loss": 12.335339378356933, "Mean Target Q": 204.43328161621093, "Mean Q1": 204.43523889160156, "Mean Q2": 204.4369874267578, "critic_loss": 24.65642738342285, "batch_reward": 1.5573874616622925, "actor_loss": -205.33207161195816, "actor_target_entropy": -1.0, "actor_entropy": 0.25250018676442487, "alpha_loss": -0.0031984094229917373, "alpha_value": 0.2173612988581781, "duration": 186.0356593132019, "step": 52500}
{"episode_reward": 284.0084306258588, "episode": 421.0, "Q1 loss": 12.571737564086915, "Q2 loss": 12.657855735778808, "Mean Target Q": 204.72649047851561, "Mean Q1": 204.72340026855468, "Mean Q2": 204.72080749511719, "critic_loss": 25.229593292236327, "batch_reward": 1.5547195558547973, "actor_loss": -205.74229431152344, "actor_target_entropy": -1.0, "actor_entropy": 0.2757023362413285, "alpha_loss": -0.008637787548766013, "alpha_value": 0.21781912444042506, "duration": 178.05688500404358, "step": 52625}
{"episode_reward": 304.66429852734825, "episode": 422.0, "Q1 loss": 14.512813949584961, "Q2 loss": 14.543651321411133, "Mean Target Q": 204.83881970214844, "Mean Q1": 204.8342341308594, "Mean Q2": 204.83452661132813, "critic_loss": 29.056465301513672, "batch_reward": 1.5656753997802735, "actor_loss": -205.72196911227317, "actor_target_entropy": -1.0, "actor_entropy": 0.2770373725122021, "alpha_loss": 0.0008634927817770551, "alpha_value": 0.2181363011784816, "duration": 184.1793987751007, "step": 52750}
{"episode_reward": 200.74852482320378, "episode": 423.0, "Q1 loss": 12.728984466552735, "Q2 loss": 12.593548934936523, "Mean Target Q": 205.1351806640625, "Mean Q1": 205.13236071777345, "Mean Q2": 205.1349483642578, "critic_loss": 25.322533447265624, "batch_reward": 1.569133765220642, "actor_loss": -206.08375718858508, "actor_target_entropy": -1.0, "actor_entropy": 0.2582714453576103, "alpha_loss": -0.002544523477332578, "alpha_value": 0.21825352350370403, "duration": 182.59576177597046, "step": 52875}
{"episode_reward": 278.90065381315543, "episode": 424.0, "Q1 loss": 12.682619659423828, "Q2 loss": 12.698325798034668, "Mean Target Q": 205.14266479492187, "Mean Q1": 205.14329333496093, "Mean Q2": 205.13982153320313, "critic_loss": 25.38094534301758, "batch_reward": 1.5604835891723632, "actor_loss": -206.06905684932585, "actor_target_entropy": -1.0, "actor_entropy": 0.2856204329479125, "alpha_loss": -0.0030129220592038284, "alpha_value": 0.2183442954240966, "duration": 178.23282194137573, "step": 53000}
{"episode_reward": 333.1992989575361, "episode": 425.0, "Q1 loss": 12.367007827758789, "Q2 loss": 12.268180320739747, "Mean Target Q": 205.2442891845703, "Mean Q1": 205.23836767578126, "Mean Q2": 205.239927734375, "critic_loss": 24.63518812561035, "batch_reward": 1.557598505973816, "actor_loss": -206.18285817948598, "actor_target_entropy": -1.0, "actor_entropy": 0.2769571047217127, "alpha_loss": -0.0035189236218612346, "alpha_value": 0.21864475600927244, "duration": 185.99703764915466, "step": 53125}
{"episode_reward": 301.5474299152673, "episode": 426.0, "Q1 loss": 12.177820388793945, "Q2 loss": 12.150372329711914, "Mean Target Q": 205.58870959472657, "Mean Q1": 205.58999682617187, "Mean Q2": 205.59142309570314, "critic_loss": 24.32819273376465, "batch_reward": 1.5716771335601807, "actor_loss": -206.5724588209583, "actor_target_entropy": -1.0, "actor_entropy": 0.286204569041729, "alpha_loss": -0.0008854770942801429, "alpha_value": 0.21871032914040814, "duration": 178.25939273834229, "step": 53250}
{"episode_reward": 423.0810803024192, "episode": 427.0, "Q1 loss": 12.556111930847168, "Q2 loss": 12.606361862182617, "Mean Target Q": 205.77098669433593, "Mean Q1": 205.772376953125, "Mean Q2": 205.77112512207032, "critic_loss": 25.16247380065918, "batch_reward": 1.5849403324127198, "actor_loss": -206.7422158377511, "actor_target_entropy": -1.0, "actor_entropy": 0.24985174148801773, "alpha_loss": -4.4793620454295285e-05, "alpha_value": 0.21870888825429963, "duration": 179.2160587310791, "step": 53375}
{"episode_reward": 254.77380777953033, "episode": 428.0, "Q1 loss": 12.200821022033692, "Q2 loss": 12.126014015197754, "Mean Target Q": 205.70576538085936, "Mean Q1": 205.70506127929687, "Mean Q2": 205.7054288330078, "critic_loss": 24.326834945678712, "batch_reward": 1.558916132926941, "actor_loss": -206.55802031486266, "actor_target_entropy": -1.0, "actor_entropy": 0.27368037318510396, "alpha_loss": -0.0017867892240774968, "alpha_value": 0.2187877507353792, "duration": 175.478435754776, "step": 53500}
{"episode_reward": 257.4387648787796, "episode": 429.0, "Q1 loss": 12.520833786010742, "Q2 loss": 12.503286933898925, "Mean Target Q": 206.08344262695311, "Mean Q1": 206.0753349609375, "Mean Q2": 206.07519287109375, "critic_loss": 25.02412074279785, "batch_reward": 1.5725511093139648, "actor_loss": -207.04324994768416, "actor_target_entropy": -1.0, "actor_entropy": 0.2652280529340108, "alpha_loss": -0.010621216247922607, "alpha_value": 0.21940303711801523, "duration": 180.21973061561584, "step": 53625}
{"episode_reward": 226.6525673779772, "episode": 430.0, "Q1 loss": 13.104254707336425, "Q2 loss": 13.12081159210205, "Mean Target Q": 206.15280859375, "Mean Q1": 206.1572692871094, "Mean Q2": 206.15659313964844, "critic_loss": 26.225066299438478, "batch_reward": 1.5602700786590575, "actor_loss": -207.06905586488784, "actor_target_entropy": -1.0, "actor_entropy": 0.2443564475303696, "alpha_loss": 0.0014753644241981448, "alpha_value": 0.21984449560827676, "duration": 174.38940334320068, "step": 53750}
{"episode_reward": 361.9696753650673, "episode": 431.0, "Q1 loss": 12.696098609924316, "Q2 loss": 12.750921096801758, "Mean Target Q": 206.34197717285156, "Mean Q1": 206.33048022460937, "Mean Q2": 206.33013134765625, "critic_loss": 25.447019638061523, "batch_reward": 1.576090940475464, "actor_loss": -207.1583227732825, "actor_target_entropy": -1.0, "actor_entropy": 0.29667187352029106, "alpha_loss": 0.001983807856468336, "alpha_value": 0.21951163965004356, "duration": 173.8216896057129, "step": 53875}
{"episode_reward": 222.08873132927374, "episode": 432.0, "Q1 loss": 12.871772003173827, "Q2 loss": 12.902242874145507, "Mean Target Q": 206.44253259277343, "Mean Q1": 206.44429699707032, "Mean Q2": 206.44572802734376, "critic_loss": 25.774014892578126, "batch_reward": 1.5743080186843872, "actor_loss": -207.2182380922379, "actor_target_entropy": -1.0, "actor_entropy": 0.2943164547604899, "alpha_loss": -0.004657758198933856, "alpha_value": 0.219678894627792, "duration": 175.99813890457153, "step": 54000}
{"episode_reward": 89.65926571622579, "episode": 433.0, "Q1 loss": 12.985729309082032, "Q2 loss": 13.05834661102295, "Mean Target Q": 206.4585703125, "Mean Q1": 206.45630053710937, "Mean Q2": 206.456923828125, "critic_loss": 26.04407583618164, "batch_reward": 1.5743031015396118, "actor_loss": -207.36657642182848, "actor_target_entropy": -1.0, "actor_entropy": 0.2791679065142359, "alpha_loss": -0.0073034080846737775, "alpha_value": 0.22009245039506412, "duration": 187.70588898658752, "step": 54125}
{"episode_reward": 22.000987255272566, "episode": 434.0, "Q1 loss": 12.345223945617676, "Q2 loss": 12.40460034942627, "Mean Target Q": 206.82511401367188, "Mean Q1": 206.82267150878906, "Mean Q2": 206.820822265625, "critic_loss": 24.749824295043947, "batch_reward": 1.5822122173309325, "actor_loss": -207.71427228373867, "actor_target_entropy": -1.0, "actor_entropy": 0.2895267651446404, "alpha_loss": -0.004700958845205605, "alpha_value": 0.22054152284362707, "duration": 190.98301029205322, "step": 54250}
{"episode_reward": 315.75737447424956, "episode": 435.0, "Q1 loss": 12.769713806152344, "Q2 loss": 12.691647010803223, "Mean Target Q": 206.918265625, "Mean Q1": 206.92074682617186, "Mean Q2": 206.92261596679688, "critic_loss": 25.46136085510254, "batch_reward": 1.572770136833191, "actor_loss": -207.8189195905413, "actor_target_entropy": -1.0, "actor_entropy": 0.2725984995800351, "alpha_loss": -0.007879157870313123, "alpha_value": 0.22121343051276918, "duration": 190.12828159332275, "step": 54375}
{"episode_reward": 244.94977562998758, "episode": 436.0, "Q1 loss": 12.513584228515626, "Q2 loss": 12.53351300048828, "Mean Target Q": 206.97918884277342, "Mean Q1": 206.97455395507814, "Mean Q2": 206.97293664550782, "critic_loss": 25.047097122192383, "batch_reward": 1.564399694442749, "actor_loss": -207.9668724306168, "actor_target_entropy": -1.0, "actor_entropy": 0.27608319588245883, "alpha_loss": -0.005553959192888391, "alpha_value": 0.22168348595694085, "duration": 175.66243076324463, "step": 54500}
{"episode_reward": 265.8590030367892, "episode": 437.0, "Q1 loss": 12.643236579895019, "Q2 loss": 12.646226211547852, "Mean Target Q": 207.13143200683595, "Mean Q1": 207.1224393310547, "Mean Q2": 207.12346435546874, "critic_loss": 25.289462753295897, "batch_reward": 1.572069058418274, "actor_loss": -208.0716259668744, "actor_target_entropy": -1.0, "actor_entropy": 0.27398418292166693, "alpha_loss": -0.007606279949421093, "alpha_value": 0.22208511602069803, "duration": 178.26701736450195, "step": 54625}
{"episode_reward": 166.89699843674543, "episode": 438.0, "Q1 loss": 12.468408325195313, "Q2 loss": 12.51339524078369, "Mean Target Q": 207.39284741210938, "Mean Q1": 207.39983666992188, "Mean Q2": 207.39980725097655, "critic_loss": 24.98180354309082, "batch_reward": 1.585374309539795, "actor_loss": -208.26586323399698, "actor_target_entropy": -1.0, "actor_entropy": 0.26625527633774665, "alpha_loss": -0.012011914975911139, "alpha_value": 0.22284483090396548, "duration": 170.9120910167694, "step": 54750}
{"episode_reward": 359.52080059618777, "episode": 439.0, "Q1 loss": 13.410119300842284, "Q2 loss": 13.350004608154297, "Mean Target Q": 207.50142065429688, "Mean Q1": 207.4959677734375, "Mean Q2": 207.49532397460936, "critic_loss": 26.76012400817871, "batch_reward": 1.5785242834091187, "actor_loss": -208.4747566344246, "actor_target_entropy": -1.0, "actor_entropy": 0.2626856792540777, "alpha_loss": -0.004831724929519826, "alpha_value": 0.22363417683427883, "duration": 192.04016494750977, "step": 54875}
{"episode_reward": 222.9368519018872, "episode": 440.0, "Q1 loss": 13.034332817077637, "Q2 loss": 13.108024139404296, "Mean Target Q": 207.5324493408203, "Mean Q1": 207.53002124023436, "Mean Q2": 207.53069091796874, "critic_loss": 26.14235688781738, "batch_reward": 1.5750485591888428, "actor_loss": -208.48911556120842, "actor_target_entropy": -1.0, "actor_entropy": 0.3033083095665901, "alpha_loss": -0.0029124065617760343, "alpha_value": 0.2238071269715824, "step": 55000}
{"duration": 189.59409713745117, "step": 55000}
{"episode_reward": 291.193332912734, "episode": 441.0, "Q1 loss": 12.903357177734375, "Q2 loss": 12.837778205871581, "Mean Target Q": 207.69669982910156, "Mean Q1": 207.68988903808594, "Mean Q2": 207.68981091308595, "critic_loss": 25.741135391235353, "batch_reward": 1.5748392457962037, "actor_loss": -208.6362554156591, "actor_target_entropy": -1.0, "actor_entropy": 0.2747192077693485, "alpha_loss": -0.001627828432468786, "alpha_value": 0.22394671796928078, "duration": 168.04532933235168, "step": 55125}
{"episode_reward": 222.02718749197925, "episode": 442.0, "Q1 loss": 13.087207778930663, "Q2 loss": 13.011427238464355, "Mean Target Q": 207.9626259765625, "Mean Q1": 207.9571639404297, "Mean Q2": 207.96055310058594, "critic_loss": 26.098634979248047, "batch_reward": 1.5730917692184447, "actor_loss": -208.82252551663308, "actor_target_entropy": -1.0, "actor_entropy": 0.3147153851966704, "alpha_loss": -0.0022494214316529614, "alpha_value": 0.22411470037747833, "duration": 182.0822594165802, "step": 55250}
{"episode_reward": 327.86330685385235, "episode": 443.0, "Q1 loss": 12.726426490783691, "Q2 loss": 12.692252380371094, "Mean Target Q": 208.1693564453125, "Mean Q1": 208.17725573730468, "Mean Q2": 208.17529748535156, "critic_loss": 25.41867886352539, "batch_reward": 1.5725387468338012, "actor_loss": -209.08544655451698, "actor_target_entropy": -1.0, "actor_entropy": 0.2764757963873091, "alpha_loss": -0.001057286218311342, "alpha_value": 0.22438013280938526, "duration": 175.12522673606873, "step": 55375}
{"episode_reward": 266.9413493906896, "episode": 444.0, "Q1 loss": 12.715750999450684, "Q2 loss": 12.679578674316407, "Mean Target Q": 208.31968505859376, "Mean Q1": 208.3108094482422, "Mean Q2": 208.30908520507813, "critic_loss": 25.395329681396483, "batch_reward": 1.5890843057632447, "actor_loss": -209.26808781777657, "actor_target_entropy": -1.0, "actor_entropy": 0.26915041237108167, "alpha_loss": -0.010757069486463744, "alpha_value": 0.2247289491430141, "duration": 181.34838032722473, "step": 55500}
{"episode_reward": 269.83644001951194, "episode": 445.0, "Q1 loss": 12.793465141296387, "Q2 loss": 12.900017196655273, "Mean Target Q": 208.4941807861328, "Mean Q1": 208.4991846923828, "Mean Q2": 208.499595703125, "critic_loss": 25.693482330322265, "batch_reward": 1.5860619497299195, "actor_loss": -209.4266328357515, "actor_target_entropy": -1.0, "actor_entropy": 0.2813900668942739, "alpha_loss": -0.013411299096390841, "alpha_value": 0.22553508649109189, "duration": 181.10993337631226, "step": 55625}
{"episode_reward": 217.08688140354963, "episode": 446.0, "Q1 loss": 15.172559394836426, "Q2 loss": 15.08750609588623, "Mean Target Q": 208.67867321777345, "Mean Q1": 208.67549621582032, "Mean Q2": 208.67441735839844, "critic_loss": 30.26006544494629, "batch_reward": 1.5812358074188233, "actor_loss": -209.5207748413086, "actor_target_entropy": -1.0, "actor_entropy": 0.29624966940572184, "alpha_loss": -0.0006793342237811416, "alpha_value": 0.2262641256686177, "duration": 185.90936541557312, "step": 55750}
{"episode_reward": 272.32139419341024, "episode": 447.0, "Q1 loss": 12.898485412597656, "Q2 loss": 12.856541236877442, "Mean Target Q": 208.85383508300782, "Mean Q1": 208.84542346191407, "Mean Q2": 208.84622827148436, "critic_loss": 25.755026672363282, "batch_reward": 1.5786531581878662, "actor_loss": -209.80826895577567, "actor_target_entropy": -1.0, "actor_entropy": 0.30928567619550795, "alpha_loss": -0.00020136693788189736, "alpha_value": 0.2261042294047635, "duration": 190.42832446098328, "step": 55875}
{"episode_reward": 354.464445640279, "episode": 448.0, "Q1 loss": 12.903499855041504, "Q2 loss": 12.857264106750488, "Mean Target Q": 209.02331164550782, "Mean Q1": 209.02375903320313, "Mean Q2": 209.0260986328125, "critic_loss": 25.76076399230957, "batch_reward": 1.5862748975753784, "actor_loss": -209.84365524784212, "actor_target_entropy": -1.0, "actor_entropy": 0.287806571491303, "alpha_loss": -0.00812364683201116, "alpha_value": 0.22654001471067264, "duration": 197.60355377197266, "step": 56000}
{"episode_reward": 262.34700789278764, "episode": 449.0, "Q1 loss": 12.45098706817627, "Q2 loss": 12.372371620178223, "Mean Target Q": 209.1716024169922, "Mean Q1": 209.16882775878906, "Mean Q2": 209.16809448242188, "critic_loss": 24.823358673095704, "batch_reward": 1.584038345336914, "actor_loss": -210.01217845129588, "actor_target_entropy": -1.0, "actor_entropy": 0.3013575401098009, "alpha_loss": -0.0008992843795567751, "alpha_value": 0.22700776539523682, "duration": 165.8662314414978, "step": 56125}
{"episode_reward": 274.1313845678093, "episode": 450.0, "Q1 loss": 12.842901931762695, "Q2 loss": 12.753211433410645, "Mean Target Q": 209.40770825195312, "Mean Q1": 209.40244799804688, "Mean Q2": 209.40303588867187, "critic_loss": 25.5961134185791, "batch_reward": 1.5935108032226561, "actor_loss": -210.35240788613595, "actor_target_entropy": -1.0, "actor_entropy": 0.30509981464955116, "alpha_loss": -0.0034551004871665953, "alpha_value": 0.22708856623208296, "duration": 160.49998569488525, "step": 56250}
{"episode_reward": 128.9900694247511, "episode": 451.0, "Q1 loss": 12.750401123046874, "Q2 loss": 12.587187995910645, "Mean Target Q": 209.43989208984374, "Mean Q1": 209.4406180419922, "Mean Q2": 209.43936779785156, "critic_loss": 25.337589111328125, "batch_reward": 1.5883035850524903, "actor_loss": -210.29505871969556, "actor_target_entropy": -1.0, "actor_entropy": 0.30988864600658417, "alpha_loss": 0.006688681996560523, "alpha_value": 0.2269135327203876, "duration": 185.35185265541077, "step": 56375}
{"episode_reward": 234.98452224088862, "episode": 452.0, "Q1 loss": 12.877533782958984, "Q2 loss": 12.880161109924316, "Mean Target Q": 209.57294213867186, "Mean Q1": 209.57105493164062, "Mean Q2": 209.5730086669922, "critic_loss": 25.757694869995117, "batch_reward": 1.5976395025253296, "actor_loss": -210.5074977259482, "actor_target_entropy": -1.0, "actor_entropy": 0.3226493061069519, "alpha_loss": 0.009860040323298064, "alpha_value": 0.2262329597543587, "duration": 163.46955943107605, "step": 56500}
{"episode_reward": 250.85291370007909, "episode": 453.0, "Q1 loss": 12.938435920715332, "Q2 loss": 12.895220428466796, "Mean Target Q": 209.81311975097657, "Mean Q1": 209.81283251953124, "Mean Q2": 209.81268908691408, "critic_loss": 25.833656326293944, "batch_reward": 1.594121247291565, "actor_loss": -210.71754988413008, "actor_target_entropy": -1.0, "actor_entropy": 0.28459694461217, "alpha_loss": 0.0019440913521167305, "alpha_value": 0.22592579633320814, "duration": 158.91023588180542, "step": 56625}
{"episode_reward": 172.8540116874469, "episode": 454.0, "Q1 loss": 12.79362110900879, "Q2 loss": 12.827791320800781, "Mean Target Q": 209.9396287841797, "Mean Q1": 209.93341674804688, "Mean Q2": 209.93270300292968, "critic_loss": 25.62141242980957, "batch_reward": 1.597587697982788, "actor_loss": -210.92647897043537, "actor_target_entropy": -1.0, "actor_entropy": 0.2877610234483596, "alpha_loss": -0.007650908796236881, "alpha_value": 0.22599024563137868, "duration": 163.84074687957764, "step": 56750}
{"episode_reward": 288.5054250147882, "episode": 455.0, "Q1 loss": 12.62368563079834, "Q2 loss": 12.582027877807617, "Mean Target Q": 210.05853100585938, "Mean Q1": 210.06047961425782, "Mean Q2": 210.05999536132813, "critic_loss": 25.205713485717773, "batch_reward": 1.5881725530624389, "actor_loss": -211.03002178858196, "actor_target_entropy": -1.0, "actor_entropy": 0.2710072405281521, "alpha_loss": -0.0055643796647292755, "alpha_value": 0.22660937828757416, "duration": 166.90589666366577, "step": 56875}
{"episode_reward": 314.9715467992007, "episode": 456.0, "Q1 loss": 13.55884928894043, "Q2 loss": 13.491354553222656, "Mean Target Q": 210.25749487304688, "Mean Q1": 210.2560427246094, "Mean Q2": 210.25561437988281, "critic_loss": 27.050203994750976, "batch_reward": 1.5936317701339722, "actor_loss": -211.28362840221774, "actor_target_entropy": -1.0, "actor_entropy": 0.27941870809562747, "alpha_loss": -0.008088719749432658, "alpha_value": 0.22724688796735545, "duration": 154.81182837486267, "step": 57000}
{"episode_reward": 265.322643551764, "episode": 457.0, "Q1 loss": 12.939998008728027, "Q2 loss": 12.969140716552735, "Mean Target Q": 210.31147875976563, "Mean Q1": 210.30846240234376, "Mean Q2": 210.30910986328124, "critic_loss": 25.909138748168946, "batch_reward": 1.5939732780456544, "actor_loss": -211.21009390694755, "actor_target_entropy": -1.0, "actor_entropy": 0.3015068956310787, "alpha_loss": -0.006525956212528168, "alpha_value": 0.22774061790048142, "duration": 167.4857153892517, "step": 57125}
{"episode_reward": 205.6510695103451, "episode": 458.0, "Q1 loss": 13.085687622070312, "Q2 loss": 13.032213676452637, "Mean Target Q": 210.54378942871094, "Mean Q1": 210.5443327636719, "Mean Q2": 210.54269152832032, "critic_loss": 26.117901290893556, "batch_reward": 1.5977956361770629, "actor_loss": -211.47835171607232, "actor_target_entropy": -1.0, "actor_entropy": 0.2810700307449987, "alpha_loss": -0.002418464053452255, "alpha_value": 0.22795680703976434, "duration": 158.93116283416748, "step": 57250}
{"episode_reward": 188.3684331069191, "episode": 459.0, "Q1 loss": 13.080421760559082, "Q2 loss": 12.929394401550294, "Mean Target Q": 210.52536108398436, "Mean Q1": 210.52363244628907, "Mean Q2": 210.52490844726563, "critic_loss": 26.009816192626953, "batch_reward": 1.5882786445617676, "actor_loss": -211.3819848923456, "actor_target_entropy": -1.0, "actor_entropy": 0.2875343161442923, "alpha_loss": -0.005968047235722816, "alpha_value": 0.22832766453716996, "duration": 168.40720772743225, "step": 57375}
{"episode_reward": 86.90495556361881, "episode": 460.0, "Q1 loss": 13.123460716247559, "Q2 loss": 13.161152313232423, "Mean Target Q": 210.71531506347657, "Mean Q1": 210.7107360839844, "Mean Q2": 210.71011853027343, "critic_loss": 26.284613021850586, "batch_reward": 1.5890334949493408, "actor_loss": -211.71327381749308, "actor_target_entropy": -1.0, "actor_entropy": 0.28758335954719977, "alpha_loss": -0.00987164695717154, "alpha_value": 0.22897384395353607, "duration": 170.0388309955597, "step": 57500}
{"episode_reward": 178.91926203093465, "episode": 461.0, "Q1 loss": 13.112491134643555, "Q2 loss": 13.00595701599121, "Mean Target Q": 210.949859375, "Mean Q1": 210.9489892578125, "Mean Q2": 210.94939514160157, "critic_loss": 26.118448181152345, "batch_reward": 1.5984752492904664, "actor_loss": -211.800784156436, "actor_target_entropy": -1.0, "actor_entropy": 0.31367833557583036, "alpha_loss": -0.009904561431280203, "alpha_value": 0.22982968265086418, "duration": 173.444274187088, "step": 57625}
{"episode_reward": 168.37346958512913, "episode": 462.0, "Q1 loss": 12.84884049987793, "Q2 loss": 12.832633323669434, "Mean Target Q": 211.0220946044922, "Mean Q1": 211.011572265625, "Mean Q2": 211.01148156738282, "critic_loss": 25.681473907470703, "batch_reward": 1.5940917434692383, "actor_loss": -211.97028055498677, "actor_target_entropy": -1.0, "actor_entropy": 0.3149730209862032, "alpha_loss": 0.002773677607277228, "alpha_value": 0.23000145739098785, "duration": 164.0273118019104, "step": 57750}
{"episode_reward": 131.38440542290593, "episode": 463.0, "Q1 loss": 12.791583457946777, "Q2 loss": 12.839756050109862, "Mean Target Q": 211.17072668457033, "Mean Q1": 211.17293969726563, "Mean Q2": 211.1734461669922, "critic_loss": 25.631339599609376, "batch_reward": 1.5864044904708863, "actor_loss": -212.10065762958828, "actor_target_entropy": -1.0, "actor_entropy": 0.2761784374477371, "alpha_loss": -0.0015037599914071579, "alpha_value": 0.229740317054031, "duration": 149.8125879764557, "step": 57875}
{"episode_reward": 270.56108929457724, "episode": 464.0, "Q1 loss": 13.528560020446777, "Q2 loss": 13.437595176696778, "Mean Target Q": 211.24671643066407, "Mean Q1": 211.23948767089843, "Mean Q2": 211.2410643310547, "critic_loss": 26.966155181884766, "batch_reward": 1.596483302116394, "actor_loss": -212.21199897027785, "actor_target_entropy": -1.0, "actor_entropy": 0.3164054275520386, "alpha_loss": -0.003957337617213207, "alpha_value": 0.22995348071414734, "duration": 152.9967818260193, "step": 58000}
{"episode_reward": 225.94313873946487, "episode": 465.0, "Q1 loss": 13.182844696044922, "Q2 loss": 13.174684280395509, "Mean Target Q": 211.55621655273438, "Mean Q1": 211.5565164794922, "Mean Q2": 211.55662463378906, "critic_loss": 26.357528915405272, "batch_reward": 1.5973429746627807, "actor_loss": -212.4866933671255, "actor_target_entropy": -1.0, "actor_entropy": 0.3099598489583485, "alpha_loss": -0.003806829725998262, "alpha_value": 0.23033838332686624, "duration": 168.21713852882385, "step": 58125}
{"episode_reward": 330.8426935134958, "episode": 466.0, "Q1 loss": 14.618776626586914, "Q2 loss": 14.566956695556641, "Mean Target Q": 211.57084729003907, "Mean Q1": 211.57669946289062, "Mean Q2": 211.5763642578125, "critic_loss": 29.18573335266113, "batch_reward": 1.5953912057876587, "actor_loss": -212.49114768735825, "actor_target_entropy": -1.0, "actor_entropy": 0.31943074830116763, "alpha_loss": -0.0031025569938543823, "alpha_value": 0.23054624479439972, "duration": 153.37182211875916, "step": 58250}
{"episode_reward": 123.07646771729941, "episode": 467.0, "Q1 loss": 13.374570526123048, "Q2 loss": 13.34364141845703, "Mean Target Q": 211.7309931640625, "Mean Q1": 211.72827819824218, "Mean Q2": 211.72614807128906, "critic_loss": 26.718211898803713, "batch_reward": 1.5952193040847777, "actor_loss": -212.70068238273498, "actor_target_entropy": -1.0, "actor_entropy": 0.30949794229060884, "alpha_loss": -0.0012633860395807358, "alpha_value": 0.23074740380387837, "duration": 148.61178040504456, "step": 58375}
{"episode_reward": 159.6130663693803, "episode": 468.0, "Q1 loss": 13.279936233520507, "Q2 loss": 13.305997383117676, "Mean Target Q": 211.89809240722656, "Mean Q1": 211.88754064941406, "Mean Q2": 211.888701171875, "critic_loss": 26.585933654785155, "batch_reward": 1.5842778882980346, "actor_loss": -212.83768167803365, "actor_target_entropy": -1.0, "actor_entropy": 0.2869130726302824, "alpha_loss": -0.006454301477905603, "alpha_value": 0.23098882839175044, "duration": 175.73380184173584, "step": 58500}
{"episode_reward": 158.46187284390274, "episode": 469.0, "Q1 loss": 13.381670486450195, "Q2 loss": 13.371536750793457, "Mean Target Q": 211.95594372558594, "Mean Q1": 211.95976843261718, "Mean Q2": 211.96029748535156, "critic_loss": 26.75320718383789, "batch_reward": 1.5855489559173583, "actor_loss": -212.98311941964286, "actor_target_entropy": -1.0, "actor_entropy": 0.2926156140036053, "alpha_loss": -0.009608228894187108, "alpha_value": 0.2317423098751995, "duration": 176.65293383598328, "step": 58625}
{"episode_reward": 140.22417104246543, "episode": 470.0, "Q1 loss": 13.18842286682129, "Q2 loss": 13.180926292419434, "Mean Target Q": 212.34837902832032, "Mean Q1": 212.34603247070314, "Mean Q2": 212.34654150390625, "critic_loss": 26.369348999023437, "batch_reward": 1.6001412754058837, "actor_loss": -213.34300970262098, "actor_target_entropy": -1.0, "actor_entropy": 0.2849403783198326, "alpha_loss": -0.012724852091782996, "alpha_value": 0.2324174287523628, "duration": 164.7362461090088, "step": 58750}
{"episode_reward": 276.94344631408256, "episode": 471.0, "Q1 loss": 13.115292030334473, "Q2 loss": 12.971704345703126, "Mean Target Q": 212.54007592773436, "Mean Q1": 212.54053735351562, "Mean Q2": 212.5380147705078, "critic_loss": 26.086996505737304, "batch_reward": 1.6038424730300904, "actor_loss": -213.57630678207155, "actor_target_entropy": -1.0, "actor_entropy": 0.2938149155132354, "alpha_loss": -0.007650861893558786, "alpha_value": 0.23327234371347397, "duration": 170.86617469787598, "step": 58875}
{"episode_reward": 371.7257302982367, "episode": 472.0, "Q1 loss": 12.951677925109863, "Q2 loss": 12.910517288208007, "Mean Target Q": 212.76065026855468, "Mean Q1": 212.75074389648438, "Mean Q2": 212.75135961914063, "critic_loss": 25.862195190429688, "batch_reward": 1.6028896408081055, "actor_loss": -213.62642546622985, "actor_target_entropy": -1.0, "actor_entropy": 0.28387939353143016, "alpha_loss": -0.004864397973212744, "alpha_value": 0.23379349098637014, "duration": 145.997652053833, "step": 59000}
{"episode_reward": 68.75525903521202, "episode": 473.0, "Q1 loss": 12.998727653503417, "Q2 loss": 12.914156929016114, "Mean Target Q": 212.87519104003906, "Mean Q1": 212.88037133789064, "Mean Q2": 212.88090405273437, "critic_loss": 25.91288459777832, "batch_reward": 1.6002694463729858, "actor_loss": -213.90356566414002, "actor_target_entropy": -1.0, "actor_entropy": 0.3022976761299466, "alpha_loss": -0.00839667914376136, "alpha_value": 0.23421609825703557, "duration": 163.74907517433167, "step": 59125}
{"episode_reward": 340.3248176147069, "episode": 474.0, "Q1 loss": 13.073156188964843, "Q2 loss": 13.042045249938965, "Mean Target Q": 213.08031103515626, "Mean Q1": 213.07206494140624, "Mean Q2": 213.07399182128907, "critic_loss": 26.115201446533202, "batch_reward": 1.5996877737045287, "actor_loss": -214.02753546930128, "actor_target_entropy": -1.0, "actor_entropy": 0.2866330903864676, "alpha_loss": -0.0038583755245312087, "alpha_value": 0.23454275964216656, "duration": 164.76262021064758, "step": 59250}
{"episode_reward": 78.9608492480289, "episode": 475.0, "Q1 loss": 13.188745811462402, "Q2 loss": 13.127087699890136, "Mean Target Q": 213.23252905273438, "Mean Q1": 213.23312890625, "Mean Q2": 213.23181396484375, "critic_loss": 26.31583345031738, "batch_reward": 1.58941948223114, "actor_loss": -214.12299068390377, "actor_target_entropy": -1.0, "actor_entropy": 0.31819274099100203, "alpha_loss": -0.00036750033143020814, "alpha_value": 0.2349015414242547, "duration": 162.86595916748047, "step": 59375}
{"episode_reward": 212.00272622828606, "episode": 476.0, "Q1 loss": 12.927823524475098, "Q2 loss": 12.886427436828614, "Mean Target Q": 213.33167761230467, "Mean Q1": 213.3285478515625, "Mean Q2": 213.32882739257812, "critic_loss": 25.814250915527342, "batch_reward": 1.5870281467437743, "actor_loss": -214.27177183089717, "actor_target_entropy": -1.0, "actor_entropy": 0.32073842758132565, "alpha_loss": 0.0012766201417112061, "alpha_value": 0.23495233766490226, "duration": 155.0197570323944, "step": 59500}
{"episode_reward": 307.0644078626438, "episode": 477.0, "Q1 loss": 13.235886909484863, "Q2 loss": 13.259078262329101, "Mean Target Q": 213.5702520751953, "Mean Q1": 213.57434826660156, "Mean Q2": 213.57585815429687, "critic_loss": 26.49496531677246, "batch_reward": 1.5927177267074586, "actor_loss": -214.52610827249194, "actor_target_entropy": -1.0, "actor_entropy": 0.3166833037421817, "alpha_loss": -0.0010141719184401962, "alpha_value": 0.23474331748335725, "duration": 160.98679876327515, "step": 59625}
{"episode_reward": 286.4873389516799, "episode": 478.0, "Q1 loss": 13.312157928466798, "Q2 loss": 13.218061004638672, "Mean Target Q": 213.55581005859375, "Mean Q1": 213.5448049316406, "Mean Q2": 213.54377673339843, "critic_loss": 26.530218994140625, "batch_reward": 1.59281747341156, "actor_loss": -214.50781717608052, "actor_target_entropy": -1.0, "actor_entropy": 0.3051940255588101, "alpha_loss": -0.004778210689584094, "alpha_value": 0.23498071860932299, "duration": 167.91811060905457, "step": 59750}
{"episode_reward": 223.25253096503295, "episode": 479.0, "Q1 loss": 13.433959426879882, "Q2 loss": 13.496089561462401, "Mean Target Q": 213.83573461914062, "Mean Q1": 213.8410382080078, "Mean Q2": 213.8398760986328, "critic_loss": 26.9300489654541, "batch_reward": 1.60566184425354, "actor_loss": -214.81425936259922, "actor_target_entropy": -1.0, "actor_entropy": 0.31272967183400713, "alpha_loss": -0.006837144597536988, "alpha_value": 0.2354522413667447, "duration": 169.98469638824463, "step": 59875}
{"episode_reward": 150.57465614859387, "episode": 480.0, "Q1 loss": 13.61896703338623, "Q2 loss": 13.574045768737793, "Mean Target Q": 214.16361071777345, "Mean Q1": 214.16109985351562, "Mean Q2": 214.16291760253907, "critic_loss": 27.193012832641603, "batch_reward": 1.6067081718444824, "actor_loss": -215.20096809633316, "actor_target_entropy": -1.0, "actor_entropy": 0.3292274119392518, "alpha_loss": -0.004436266679887569, "alpha_value": 0.235900223574836, "step": 60000}
{"duration": 181.80762100219727, "step": 60000}
{"episode_reward": 344.357698092401, "episode": 481.0, "Q1 loss": 13.196416534423829, "Q2 loss": 13.1696689453125, "Mean Target Q": 214.23184692382813, "Mean Q1": 214.22627075195314, "Mean Q2": 214.22241125488281, "critic_loss": 26.36608544921875, "batch_reward": 1.5975251884460449, "actor_loss": -215.23429701063367, "actor_target_entropy": -1.0, "actor_entropy": 0.32643754070713404, "alpha_loss": -0.002478913481657704, "alpha_value": 0.23610914947513828, "duration": 170.1122498512268, "step": 60125}
{"episode_reward": 241.0670705400414, "episode": 482.0, "Q1 loss": 13.592369216918945, "Q2 loss": 13.514451072692871, "Mean Target Q": 214.5206805419922, "Mean Q1": 214.52033837890625, "Mean Q2": 214.52519372558595, "critic_loss": 27.1068203125, "batch_reward": 1.6039975442886352, "actor_loss": -215.5575652583953, "actor_target_entropy": -1.0, "actor_entropy": 0.33310267906035146, "alpha_loss": -0.004982702039752996, "alpha_value": 0.23633400239517346, "duration": 152.27113485336304, "step": 60250}
{"episode_reward": 205.63309877189852, "episode": 483.0, "Q1 loss": 13.484320945739746, "Q2 loss": 13.431345909118653, "Mean Target Q": 214.62715051269532, "Mean Q1": 214.62400512695314, "Mean Q2": 214.6210675048828, "critic_loss": 26.915666915893556, "batch_reward": 1.6069755744934082, "actor_loss": -215.54067145453558, "actor_target_entropy": -1.0, "actor_entropy": 0.3122742987341351, "alpha_loss": 0.0022529942419616477, "alpha_value": 0.2364877961295202, "duration": 158.21007418632507, "step": 60375}
{"episode_reward": 217.8630682064465, "episode": 484.0, "Q1 loss": 13.21109292602539, "Q2 loss": 13.108474731445312, "Mean Target Q": 214.78307055664064, "Mean Q1": 214.775943359375, "Mean Q2": 214.77805737304686, "critic_loss": 26.319567749023438, "batch_reward": 1.5995970449447632, "actor_loss": -215.91317133749686, "actor_target_entropy": -1.0, "actor_entropy": 0.32836365747836327, "alpha_loss": 0.005670190293101534, "alpha_value": 0.23627427037937057, "duration": 159.26042675971985, "step": 60500}
{"episode_reward": 158.41123332076447, "episode": 485.0, "Q1 loss": 13.239918785095215, "Q2 loss": 13.078581230163575, "Mean Target Q": 214.9175017089844, "Mean Q1": 214.92131091308593, "Mean Q2": 214.91993505859375, "critic_loss": 26.318499862670897, "batch_reward": 1.600513602256775, "actor_loss": -215.83448791503906, "actor_target_entropy": -1.0, "actor_entropy": 0.33400793586458477, "alpha_loss": -0.010390981403549038, "alpha_value": 0.23626146949074878, "duration": 167.6525797843933, "step": 60625}
{"episode_reward": 287.26386701395575, "episode": 486.0, "Q1 loss": 12.938901969909669, "Q2 loss": 12.939715309143066, "Mean Target Q": 215.2932919921875, "Mean Q1": 215.28470104980468, "Mean Q2": 215.28602734375, "critic_loss": 25.878617309570313, "batch_reward": 1.6086524829864501, "actor_loss": -216.38451016333795, "actor_target_entropy": -1.0, "actor_entropy": 0.2801676068094469, "alpha_loss": -0.018634548850147235, "alpha_value": 0.23747123769350426, "duration": 169.10408735275269, "step": 60750}
{"episode_reward": 161.99564430397993, "episode": 487.0, "Q1 loss": 13.199129745483399, "Q2 loss": 13.235506408691407, "Mean Target Q": 215.230685546875, "Mean Q1": 215.22992565917968, "Mean Q2": 215.22907360839844, "critic_loss": 26.434636154174804, "batch_reward": 1.5989603118896485, "actor_loss": -216.249021499876, "actor_target_entropy": -1.0, "actor_entropy": 0.29770037058799986, "alpha_loss": -0.0066792018977659086, "alpha_value": 0.23846115667269827, "duration": 165.86721014976501, "step": 60875}
{"episode_reward": 75.26348707377191, "episode": 488.0, "Q1 loss": 13.756362586975097, "Q2 loss": 13.760394920349121, "Mean Target Q": 215.557521484375, "Mean Q1": 215.55645458984375, "Mean Q2": 215.557009765625, "critic_loss": 27.516757446289063, "batch_reward": 1.6064428062438965, "actor_loss": -216.47765005788494, "actor_target_entropy": -1.0, "actor_entropy": 0.3015374461970022, "alpha_loss": -0.005593588316602813, "alpha_value": 0.23881508618115552, "duration": 166.62366366386414, "step": 61000}
{"episode_reward": 87.57159295642045, "episode": 489.0, "Q1 loss": 13.376613243103026, "Q2 loss": 13.341728477478027, "Mean Target Q": 215.5728973388672, "Mean Q1": 215.5716687011719, "Mean Q2": 215.572462890625, "critic_loss": 26.718341705322267, "batch_reward": 1.593878987312317, "actor_loss": -216.57808285667784, "actor_target_entropy": -1.0, "actor_entropy": 0.2923881359516628, "alpha_loss": -0.02362512739463931, "alpha_value": 0.23994822343086297, "duration": 164.04682064056396, "step": 61125}
{"episode_reward": 125.12958588014432, "episode": 490.0, "Q1 loss": 13.958047386169433, "Q2 loss": 13.893171165466308, "Mean Target Q": 215.79956298828125, "Mean Q1": 215.8044884033203, "Mean Q2": 215.80347534179688, "critic_loss": 27.851218475341796, "batch_reward": 1.5997832593917847, "actor_loss": -216.8560069914787, "actor_target_entropy": -1.0, "actor_entropy": 0.2908865057172314, "alpha_loss": -0.009333929921981067, "alpha_value": 0.24120226103709905, "duration": 163.38447785377502, "step": 61250}
{"episode_reward": 238.85217789169755, "episode": 491.0, "Q1 loss": 13.285130363464356, "Q2 loss": 13.18583984375, "Mean Target Q": 215.82474658203125, "Mean Q1": 215.81625598144532, "Mean Q2": 215.81819018554688, "critic_loss": 26.47097016906738, "batch_reward": 1.5928101768493652, "actor_loss": -216.86511835976253, "actor_target_entropy": -1.0, "actor_entropy": 0.3042484838811178, "alpha_loss": -0.01145623629498813, "alpha_value": 0.24178454663871002, "duration": 168.34101748466492, "step": 61375}
{"episode_reward": 172.14305226455394, "episode": 492.0, "Q1 loss": 13.498713264465332, "Q2 loss": 13.395151634216308, "Mean Target Q": 215.86899841308593, "Mean Q1": 215.87172973632812, "Mean Q2": 215.8702257080078, "critic_loss": 26.89386479187012, "batch_reward": 1.587136785507202, "actor_loss": -216.82592921103202, "actor_target_entropy": -1.0, "actor_entropy": 0.3156933075478, "alpha_loss": -0.005509291031968689, "alpha_value": 0.24256995949181634, "duration": 167.6667664051056, "step": 61500}
{"episode_reward": 112.9286374945564, "episode": 493.0, "Q1 loss": 13.875933708190917, "Q2 loss": 13.836143417358398, "Mean Target Q": 216.23131860351563, "Mean Q1": 216.22707104492187, "Mean Q2": 216.226564453125, "critic_loss": 27.712077087402342, "batch_reward": 1.6009796199798585, "actor_loss": -217.23726593501985, "actor_target_entropy": -1.0, "actor_entropy": 0.3318269300082373, "alpha_loss": -0.010254413604603283, "alpha_value": 0.24314733555019763, "duration": 161.2026801109314, "step": 61625}
{"episode_reward": 152.84273669285227, "episode": 494.0, "Q1 loss": 14.084362800598145, "Q2 loss": 14.080981437683105, "Mean Target Q": 216.2853028564453, "Mean Q1": 216.28522485351561, "Mean Q2": 216.28423205566406, "critic_loss": 28.165344345092773, "batch_reward": 1.5993006067276, "actor_loss": -217.38768325313444, "actor_target_entropy": -1.0, "actor_entropy": 0.31752821274342075, "alpha_loss": 0.0022251583380444397, "alpha_value": 0.24333492701922374, "duration": 170.0438895225525, "step": 61750}
{"episode_reward": 177.2560777666547, "episode": 495.0, "Q1 loss": 13.08096450805664, "Q2 loss": 13.035552688598633, "Mean Target Q": 216.33562829589843, "Mean Q1": 216.32181091308593, "Mean Q2": 216.32455920410158, "critic_loss": 26.116517349243164, "batch_reward": 1.586289545059204, "actor_loss": -217.2805379231771, "actor_target_entropy": -1.0, "actor_entropy": 0.33578970555275206, "alpha_loss": -9.220109010736148e-05, "alpha_value": 0.24335438421966832, "duration": 167.0445671081543, "step": 61875}
{"episode_reward": 228.47735232441704, "episode": 496.0, "Q1 loss": 14.223964973449707, "Q2 loss": 14.294424247741699, "Mean Target Q": 216.64598889160158, "Mean Q1": 216.64953564453126, "Mean Q2": 216.64850756835938, "critic_loss": 28.518389221191406, "batch_reward": 1.599216215133667, "actor_loss": -217.68589733492942, "actor_target_entropy": -1.0, "actor_entropy": 0.29103618740074094, "alpha_loss": 2.1665400239608942e-05, "alpha_value": 0.24337270152699614, "duration": 160.86877727508545, "step": 62000}
{"episode_reward": 255.37564185228086, "episode": 497.0, "Q1 loss": 14.12445174407959, "Q2 loss": 13.992937393188477, "Mean Target Q": 216.67656616210937, "Mean Q1": 216.67807165527344, "Mean Q2": 216.67820812988282, "critic_loss": 28.11738897705078, "batch_reward": 1.6017724142074585, "actor_loss": -217.6378658234127, "actor_target_entropy": -1.0, "actor_entropy": 0.3301854015342773, "alpha_loss": 0.005516081427534421, "alpha_value": 0.24303946643764, "duration": 165.3768274784088, "step": 62125}
{"episode_reward": 177.9141016347727, "episode": 498.0, "Q1 loss": 13.97796915435791, "Q2 loss": 13.87405573272705, "Mean Target Q": 216.73914184570313, "Mean Q1": 216.72867736816406, "Mean Q2": 216.72963122558593, "critic_loss": 27.852024841308594, "batch_reward": 1.5994858102798462, "actor_loss": -217.68649070493638, "actor_target_entropy": -1.0, "actor_entropy": 0.3066848432344775, "alpha_loss": -0.004117260957437177, "alpha_value": 0.24304373216489433, "duration": 168.77614450454712, "step": 62250}
{"episode_reward": 241.18967135103648, "episode": 499.0, "Q1 loss": 13.648923713684082, "Q2 loss": 13.770532699584962, "Mean Target Q": 216.87392956542968, "Mean Q1": 216.8709169921875, "Mean Q2": 216.87105310058593, "critic_loss": 27.41945637512207, "batch_reward": 1.5988531417846679, "actor_loss": -217.87548464820497, "actor_target_entropy": -1.0, "actor_entropy": 0.32817232324963524, "alpha_loss": -0.0025361079449159286, "alpha_value": 0.2432296440657244, "duration": 169.185293674469, "step": 62375}
{"episode_reward": 117.37570215389928, "episode": 500.0, "Q1 loss": 13.838835609436035, "Q2 loss": 13.754348281860352, "Mean Target Q": 217.1460095214844, "Mean Q1": 217.14723071289063, "Mean Q2": 217.14583142089845, "critic_loss": 27.59318395996094, "batch_reward": 1.5989789171218871, "actor_loss": -218.1389861568328, "actor_target_entropy": -1.0, "actor_entropy": 0.3039623136001249, "alpha_loss": -0.005791039412630902, "alpha_value": 0.24360344552442112, "duration": 167.01113891601562, "step": 62500}
{"episode_reward": 199.20340198397568, "episode": 501.0, "Q1 loss": 14.38236994934082, "Q2 loss": 14.347259963989258, "Mean Target Q": 217.227189453125, "Mean Q1": 217.2225927734375, "Mean Q2": 217.2218992919922, "critic_loss": 28.72962986755371, "batch_reward": 1.6008370237350464, "actor_loss": -218.16771443684897, "actor_target_entropy": -1.0, "actor_entropy": 0.3335121652436635, "alpha_loss": -0.0025815165579496395, "alpha_value": 0.2441163134811634, "duration": 157.000905752182, "step": 62625}
{"episode_reward": 231.4662033911667, "episode": 502.0, "Q1 loss": 14.350279281616212, "Q2 loss": 14.318956314086915, "Mean Target Q": 217.1584152832031, "Mean Q1": 217.1571357421875, "Mean Q2": 217.15910498046875, "critic_loss": 28.66923550415039, "batch_reward": 1.5867108497619629, "actor_loss": -218.1353302001953, "actor_target_entropy": -1.0, "actor_entropy": 0.3515645553988795, "alpha_loss": 0.00014947287948621857, "alpha_value": 0.2439734699461368, "duration": 153.48142051696777, "step": 62750}
{"episode_reward": 219.5916048837201, "episode": 503.0, "Q1 loss": 14.17361492919922, "Q2 loss": 14.2207523727417, "Mean Target Q": 217.4549719238281, "Mean Q1": 217.45341577148437, "Mean Q2": 217.45220336914062, "critic_loss": 28.394367248535158, "batch_reward": 1.5898563947677613, "actor_loss": -218.38729809957837, "actor_target_entropy": -1.0, "actor_entropy": 0.3370428281644034, "alpha_loss": -0.007112465384933684, "alpha_value": 0.24413190147226335, "duration": 168.4954535961151, "step": 62875}
{"episode_reward": 190.26078830092925, "episode": 504.0, "Q1 loss": 13.560223953247071, "Q2 loss": 13.58880795288086, "Mean Target Q": 217.4436435546875, "Mean Q1": 217.44694580078124, "Mean Q2": 217.44823559570312, "critic_loss": 27.14903187561035, "batch_reward": 1.5946670570373536, "actor_loss": -218.5029048304404, "actor_target_entropy": -1.0, "actor_entropy": 0.32696772655171735, "alpha_loss": -0.004743002129778746, "alpha_value": 0.2447262371566797, "duration": 163.86402869224548, "step": 63000}
{"episode_reward": 139.9735262788356, "episode": 505.0, "Q1 loss": 13.8084146194458, "Q2 loss": 13.789354415893555, "Mean Target Q": 217.72933166503907, "Mean Q1": 217.72533227539063, "Mean Q2": 217.7260966796875, "critic_loss": 27.597769027709962, "batch_reward": 1.6060571842193603, "actor_loss": -218.8531748453776, "actor_target_entropy": -1.0, "actor_entropy": 0.31917693619690246, "alpha_loss": -0.005140927856758473, "alpha_value": 0.24495046545972504, "duration": 165.10331678390503, "step": 63125}
{"episode_reward": 227.47494600112756, "episode": 506.0, "Q1 loss": 13.812116165161132, "Q2 loss": 13.853031715393067, "Mean Target Q": 217.88686828613282, "Mean Q1": 217.877029296875, "Mean Q2": 217.87703833007814, "critic_loss": 27.66514794921875, "batch_reward": 1.595891263961792, "actor_loss": -218.88595654887538, "actor_target_entropy": -1.0, "actor_entropy": 0.33139847483365764, "alpha_loss": -0.0024859950532235445, "alpha_value": 0.2452920397450113, "duration": 162.18430495262146, "step": 63250}
{"episode_reward": 191.44066146625067, "episode": 507.0, "Q1 loss": 14.155215484619141, "Q2 loss": 14.128544540405274, "Mean Target Q": 217.9959443359375, "Mean Q1": 218.00215075683593, "Mean Q2": 218.00135961914063, "critic_loss": 28.28375988769531, "batch_reward": 1.5927431545257569, "actor_loss": -219.06046888563367, "actor_target_entropy": -1.0, "actor_entropy": 0.321259443722074, "alpha_loss": -0.004280512590730001, "alpha_value": 0.24546617958363193, "duration": 165.1331605911255, "step": 63375}
{"episode_reward": 162.90286342916974, "episode": 508.0, "Q1 loss": 14.455939865112304, "Q2 loss": 14.407099220275878, "Mean Target Q": 218.16766674804688, "Mean Q1": 218.1625739746094, "Mean Q2": 218.16241296386718, "critic_loss": 28.863039093017576, "batch_reward": 1.6008856782913208, "actor_loss": -219.2100320631458, "actor_target_entropy": -1.0, "actor_entropy": 0.3437971816428246, "alpha_loss": -0.0009707559572322475, "alpha_value": 0.24584012753685158, "duration": 169.8069064617157, "step": 63500}
{"episode_reward": 201.1090359583002, "episode": 509.0, "Q1 loss": 13.946793075561523, "Q2 loss": 13.879728469848633, "Mean Target Q": 218.44712658691407, "Mean Q1": 218.44552661132812, "Mean Q2": 218.44477258300782, "critic_loss": 27.826521469116212, "batch_reward": 1.6064886350631713, "actor_loss": -219.48815336681548, "actor_target_entropy": -1.0, "actor_entropy": 0.3359110028970809, "alpha_loss": 7.4498636263703546e-06, "alpha_value": 0.24587961709151457, "duration": 167.42547249794006, "step": 63625}
{"episode_reward": 248.76588616750763, "episode": 510.0, "Q1 loss": 14.055631217956543, "Q2 loss": 13.914096977233887, "Mean Target Q": 218.53527294921875, "Mean Q1": 218.53146887207032, "Mean Q2": 218.53114562988281, "critic_loss": 27.96972804260254, "batch_reward": 1.6022704114913942, "actor_loss": -219.58094910652406, "actor_target_entropy": -1.0, "actor_entropy": 0.34141378104686737, "alpha_loss": 0.003125183334979679, "alpha_value": 0.24572667325325584, "duration": 165.4565875530243, "step": 63750}
{"episode_reward": 276.12304203144123, "episode": 511.0, "Q1 loss": 14.26624641418457, "Q2 loss": 14.194263481140137, "Mean Target Q": 218.53265197753908, "Mean Q1": 218.5286356201172, "Mean Q2": 218.5305655517578, "critic_loss": 28.4605099029541, "batch_reward": 1.5887464818954469, "actor_loss": -219.52993847074964, "actor_target_entropy": -1.0, "actor_entropy": 0.3288978695396393, "alpha_loss": 0.006221363904871165, "alpha_value": 0.24544162461144745, "duration": 159.71134114265442, "step": 63875}
{"episode_reward": 183.41183214260116, "episode": 512.0, "Q1 loss": 14.331889625549316, "Q2 loss": 14.346358108520509, "Mean Target Q": 218.590244140625, "Mean Q1": 218.58327404785157, "Mean Q2": 218.58377697753906, "critic_loss": 28.678247695922853, "batch_reward": 1.5989350166320802, "actor_loss": -219.5199954125189, "actor_target_entropy": -1.0, "actor_entropy": 0.346116601699783, "alpha_loss": 0.0029373757105561034, "alpha_value": 0.24495856394250543, "duration": 161.12600898742676, "step": 64000}
{"episode_reward": 189.2415334191288, "episode": 513.0, "Q1 loss": 14.588540664672852, "Q2 loss": 14.44013388824463, "Mean Target Q": 218.7603145751953, "Mean Q1": 218.77167016601564, "Mean Q2": 218.77039904785155, "critic_loss": 29.028674545288087, "batch_reward": 1.5993021097183227, "actor_loss": -219.78643120659723, "actor_target_entropy": -1.0, "actor_entropy": 0.3066548425999899, "alpha_loss": -0.0005706887182203077, "alpha_value": 0.24501087474343644, "duration": 171.8099970817566, "step": 64125}
{"episode_reward": 180.29214576244706, "episode": 514.0, "Q1 loss": 14.449742904663086, "Q2 loss": 14.394571830749511, "Mean Target Q": 218.86563549804688, "Mean Q1": 218.85670764160156, "Mean Q2": 218.8562275390625, "critic_loss": 28.844314544677733, "batch_reward": 1.5872528047561645, "actor_loss": -219.98406121038622, "actor_target_entropy": -1.0, "actor_entropy": 0.3353525926509211, "alpha_loss": 0.0014242318143407183, "alpha_value": 0.24502942781607498, "duration": 161.7382836341858, "step": 64250}
{"episode_reward": 176.74522659932836, "episode": 515.0, "Q1 loss": 14.80379148864746, "Q2 loss": 14.840985549926758, "Mean Target Q": 219.02548791503907, "Mean Q1": 219.0221697998047, "Mean Q2": 219.0214128417969, "critic_loss": 29.64477702331543, "batch_reward": 1.59955655670166, "actor_loss": -220.0997062562004, "actor_target_entropy": -1.0, "actor_entropy": 0.35322066573869615, "alpha_loss": -0.003631376624403019, "alpha_value": 0.2449998692071609, "duration": 148.98228359222412, "step": 64375}
{"episode_reward": 296.66189106745014, "episode": 516.0, "Q1 loss": 14.131550521850587, "Q2 loss": 14.156160263061523, "Mean Target Q": 219.22555444335939, "Mean Q1": 219.22770080566406, "Mean Q2": 219.22593981933593, "critic_loss": 28.287710693359376, "batch_reward": 1.5876822328567506, "actor_loss": -220.49683970789755, "actor_target_entropy": -1.0, "actor_entropy": 0.35884364333844954, "alpha_loss": -0.001158304458048435, "alpha_value": 0.24515148295999503, "duration": 169.44728803634644, "step": 64500}
{"episode_reward": 146.3770657568641, "episode": 517.0, "Q1 loss": 14.503475494384766, "Q2 loss": 14.507270858764649, "Mean Target Q": 219.34589514160157, "Mean Q1": 219.3457449951172, "Mean Q2": 219.34632873535156, "critic_loss": 29.01074613952637, "batch_reward": 1.5933769235610962, "actor_loss": -220.29749915713356, "actor_target_entropy": -1.0, "actor_entropy": 0.3468027881213597, "alpha_loss": -8.059329249792629e-06, "alpha_value": 0.24520139926516007, "duration": 172.496928691864, "step": 64625}
{"episode_reward": 165.0821095864725, "episode": 518.0, "Q1 loss": 13.808690612792969, "Q2 loss": 13.827466072082519, "Mean Target Q": 219.46501623535156, "Mean Q1": 219.45959289550783, "Mean Q2": 219.45997863769531, "critic_loss": 27.63615672302246, "batch_reward": 1.5950199327468872, "actor_loss": -220.38958026516823, "actor_target_entropy": -1.0, "actor_entropy": 0.3467473012785758, "alpha_loss": 0.00031427133663166913, "alpha_value": 0.2451468227139702, "duration": 170.27398109436035, "step": 64750}
{"episode_reward": 221.0964457514835, "episode": 519.0, "Q1 loss": 14.877125473022462, "Q2 loss": 14.844010452270508, "Mean Target Q": 219.68426928710937, "Mean Q1": 219.6870518798828, "Mean Q2": 219.69141833496093, "critic_loss": 29.721135803222655, "batch_reward": 1.6005107660293578, "actor_loss": -220.74716065421936, "actor_target_entropy": -1.0, "actor_entropy": 0.32111999037719907, "alpha_loss": -0.011087573403196911, "alpha_value": 0.24543546910591416, "duration": 169.72949981689453, "step": 64875}
{"episode_reward": 66.22386307938073, "episode": 520.0, "Q1 loss": 14.403570945739746, "Q2 loss": 14.36726043701172, "Mean Target Q": 219.80089086914063, "Mean Q1": 219.79618981933595, "Mean Q2": 219.7918681640625, "critic_loss": 28.77083137512207, "batch_reward": 1.5942279844284057, "actor_loss": -220.96961655155306, "actor_target_entropy": -1.0, "actor_entropy": 0.3366324161329577, "alpha_loss": -0.008162361062732675, "alpha_value": 0.24648477277558925, "step": 65000}
{"duration": 179.628276348114, "step": 65000}
{"episode_reward": 96.64814655240906, "episode": 521.0, "Q1 loss": 14.990305473327636, "Q2 loss": 15.116751159667968, "Mean Target Q": 220.04075354003905, "Mean Q1": 220.04137512207032, "Mean Q2": 220.0428251953125, "critic_loss": 30.107056564331053, "batch_reward": 1.5914163236618042, "actor_loss": -221.096922859313, "actor_target_entropy": -1.0, "actor_entropy": 0.3359547754128774, "alpha_loss": 0.004365693855409821, "alpha_value": 0.2464397626021596, "duration": 171.82861876487732, "step": 65125}
{"episode_reward": 39.082652203508985, "episode": 522.0, "Q1 loss": 14.663599220275879, "Q2 loss": 14.629386283874512, "Mean Target Q": 220.13157739257812, "Mean Q1": 220.12738696289063, "Mean Q2": 220.1282852783203, "critic_loss": 29.292985565185546, "batch_reward": 1.5898801136016845, "actor_loss": -221.22486336000503, "actor_target_entropy": -1.0, "actor_entropy": 0.3231779728685656, "alpha_loss": -0.00462906317590105, "alpha_value": 0.2464924119709188, "duration": 177.294109582901, "step": 65250}
{"episode_reward": 248.73471618603787, "episode": 523.0, "Q1 loss": 14.554605575561524, "Q2 loss": 14.51217332458496, "Mean Target Q": 220.357630859375, "Mean Q1": 220.35447766113282, "Mean Q2": 220.35292724609374, "critic_loss": 29.066778884887697, "batch_reward": 1.599262020111084, "actor_loss": -221.4574948265439, "actor_target_entropy": -1.0, "actor_entropy": 0.33083583958565244, "alpha_loss": -0.00017621445779999098, "alpha_value": 0.24680268031962913, "duration": 168.9459753036499, "step": 65375}
{"episode_reward": 202.28600183251595, "episode": 524.0, "Q1 loss": 14.722480560302735, "Q2 loss": 14.689364143371582, "Mean Target Q": 220.48065014648438, "Mean Q1": 220.47735705566407, "Mean Q2": 220.48070849609374, "critic_loss": 29.411844665527344, "batch_reward": 1.5906832504272461, "actor_loss": -221.5818136892011, "actor_target_entropy": -1.0, "actor_entropy": 0.3236984269272897, "alpha_loss": -0.0009915407713232262, "alpha_value": 0.2467471645451429, "duration": 160.32063031196594, "step": 65500}
{"episode_reward": 208.10640526750606, "episode": 525.0, "Q1 loss": 14.662197746276856, "Q2 loss": 14.671784606933594, "Mean Target Q": 220.72030224609375, "Mean Q1": 220.71742797851562, "Mean Q2": 220.71347204589844, "critic_loss": 29.333982391357424, "batch_reward": 1.5959483337402345, "actor_loss": -221.74104769267734, "actor_target_entropy": -1.0, "actor_entropy": 0.3471782403805899, "alpha_loss": -0.006203149530356602, "alpha_value": 0.24700588786141411, "duration": 162.76634621620178, "step": 65625}
{"episode_reward": 291.69997961671186, "episode": 526.0, "Q1 loss": 14.983639770507812, "Q2 loss": 14.880378021240235, "Mean Target Q": 220.94757873535156, "Mean Q1": 220.94620666503906, "Mean Q2": 220.9494715576172, "critic_loss": 29.86401786804199, "batch_reward": 1.5843040075302124, "actor_loss": -222.1846904139365, "actor_target_entropy": -1.0, "actor_entropy": 0.32576686768762525, "alpha_loss": 0.0028147883375265427, "alpha_value": 0.2472140050182968, "duration": 157.21976804733276, "step": 65750}
{"episode_reward": 94.12283028278577, "episode": 527.0, "Q1 loss": 17.96905121612549, "Q2 loss": 17.922870223999023, "Mean Target Q": 220.97321557617187, "Mean Q1": 220.9645197753906, "Mean Q2": 220.9644111328125, "critic_loss": 35.89192155456543, "batch_reward": 1.5973866147994995, "actor_loss": -222.136963859437, "actor_target_entropy": -1.0, "actor_entropy": 0.36169478817591594, "alpha_loss": 0.0021254828584099574, "alpha_value": 0.24691391898175225, "duration": 165.90195274353027, "step": 65875}
{"episode_reward": 293.50855588411673, "episode": 528.0, "Q1 loss": 16.771695472717287, "Q2 loss": 16.724926162719726, "Mean Target Q": 221.3145535888672, "Mean Q1": 221.31747705078126, "Mean Q2": 221.31663537597657, "critic_loss": 33.49662159729004, "batch_reward": 1.593378662109375, "actor_loss": -222.33952233099168, "actor_target_entropy": -1.0, "actor_entropy": 0.35165837310975595, "alpha_loss": 0.0027256310474307785, "alpha_value": 0.2466680367745575, "duration": 171.78764939308167, "step": 66000}
{"episode_reward": 299.7310386926408, "episode": 529.0, "Q1 loss": 15.42007177734375, "Q2 loss": 15.409085021972656, "Mean Target Q": 221.55046105957032, "Mean Q1": 221.54388354492187, "Mean Q2": 221.54522814941407, "critic_loss": 30.82915673828125, "batch_reward": 1.591601770401001, "actor_loss": -222.63821556454613, "actor_target_entropy": -1.0, "actor_entropy": 0.3700771109452323, "alpha_loss": 0.0032938995365319507, "alpha_value": 0.2467066089010578, "duration": 172.61940097808838, "step": 66125}
{"episode_reward": 259.45152966594776, "episode": 530.0, "Q1 loss": 14.460413627624511, "Q2 loss": 14.478523078918457, "Mean Target Q": 221.48329333496093, "Mean Q1": 221.4771533203125, "Mean Q2": 221.47457885742188, "critic_loss": 28.938936630249025, "batch_reward": 1.5896611671447753, "actor_loss": -222.54839940224923, "actor_target_entropy": -1.0, "actor_entropy": 0.362149344336602, "alpha_loss": -0.003008690809140042, "alpha_value": 0.24639681911161132, "duration": 168.2846200466156, "step": 66250}
{"episode_reward": 238.33322894510587, "episode": 531.0, "Q1 loss": 14.562638465881347, "Q2 loss": 14.55993962097168, "Mean Target Q": 221.70599462890624, "Mean Q1": 221.71393579101561, "Mean Q2": 221.71470654296874, "critic_loss": 29.122577911376954, "batch_reward": 1.6040908288955689, "actor_loss": -222.7920399014912, "actor_target_entropy": -1.0, "actor_entropy": 0.3466965929856376, "alpha_loss": -0.0017381364050956946, "alpha_value": 0.24662583703395552, "duration": 168.85424327850342, "step": 66375}
{"episode_reward": 172.15486314186833, "episode": 532.0, "Q1 loss": 14.37890665435791, "Q2 loss": 14.314268997192382, "Mean Target Q": 221.82122180175782, "Mean Q1": 221.81627282714842, "Mean Q2": 221.81703637695313, "critic_loss": 28.693175689697267, "batch_reward": 1.5828630828857422, "actor_loss": -222.96666102255546, "actor_target_entropy": -1.0, "actor_entropy": 0.3791776285056145, "alpha_loss": -0.004525439629721786, "alpha_value": 0.24698253016522526, "duration": 167.7961220741272, "step": 66500}
{"episode_reward": 208.65168546276433, "episode": 533.0, "Q1 loss": 14.119524536132813, "Q2 loss": 14.142875061035156, "Mean Target Q": 222.0706339111328, "Mean Q1": 222.06542529296874, "Mean Q2": 222.062953125, "critic_loss": 28.262399551391603, "batch_reward": 1.5957568616867066, "actor_loss": -223.13638668968565, "actor_target_entropy": -1.0, "actor_entropy": 0.35542227351476274, "alpha_loss": -0.0020609234481872548, "alpha_value": 0.24734227306297898, "duration": 287.6235816478729, "step": 66625}
{"episode_reward": 207.015092722007, "episode": 534.0, "Q1 loss": 14.605989006042481, "Q2 loss": 14.540123748779298, "Mean Target Q": 222.08165405273436, "Mean Q1": 222.07363525390625, "Mean Q2": 222.0769094238281, "critic_loss": 29.146112701416016, "batch_reward": 1.5908058280944823, "actor_loss": -223.204962207425, "actor_target_entropy": -1.0, "actor_entropy": 0.3416704458575095, "alpha_loss": -0.012289869264819689, "alpha_value": 0.2474729660851213, "duration": 312.0312924385071, "step": 66750}
{"episode_reward": 205.6407275530086, "episode": 535.0, "Q1 loss": 14.118693801879882, "Q2 loss": 14.096579963684082, "Mean Target Q": 222.35089392089844, "Mean Q1": 222.3518643798828, "Mean Q2": 222.35170666503907, "critic_loss": 28.215273880004883, "batch_reward": 1.5963197803497315, "actor_loss": -223.36159382169208, "actor_target_entropy": -1.0, "actor_entropy": 0.37256860591116403, "alpha_loss": -0.0051738547072524115, "alpha_value": 0.24826084323284686, "duration": 290.71002221107483, "step": 66875}
{"episode_reward": 160.01230316452575, "episode": 536.0, "Q1 loss": 14.329803833007812, "Q2 loss": 14.31975846862793, "Mean Target Q": 222.36214428710937, "Mean Q1": 222.36039184570313, "Mean Q2": 222.35985791015625, "critic_loss": 28.649562393188475, "batch_reward": 1.5935733528137208, "actor_loss": -223.3696522866526, "actor_target_entropy": -1.0, "actor_entropy": 0.3538412442130427, "alpha_loss": 0.0020636851193323253, "alpha_value": 0.24851174794468014, "duration": 245.1870174407959, "step": 67000}
{"episode_reward": 240.64121053861186, "episode": 537.0, "Q1 loss": 14.224086860656739, "Q2 loss": 14.342948150634765, "Mean Target Q": 222.57012060546876, "Mean Q1": 222.57013623046876, "Mean Q2": 222.56964318847656, "critic_loss": 28.567034927368162, "batch_reward": 1.5944801578521728, "actor_loss": -223.64908248659165, "actor_target_entropy": -1.0, "actor_entropy": 0.35853345857726204, "alpha_loss": -0.0016692776846448107, "alpha_value": 0.24846177284277246, "duration": 251.7458975315094, "step": 67125}
{"episode_reward": 229.85630650638555, "episode": 538.0, "Q1 loss": 13.939954322814941, "Q2 loss": 13.894179412841797, "Mean Target Q": 222.75060498046875, "Mean Q1": 222.7499873046875, "Mean Q2": 222.74998315429687, "critic_loss": 27.83413377380371, "batch_reward": 1.6119042596817017, "actor_loss": -223.82511631135017, "actor_target_entropy": -1.0, "actor_entropy": 0.3615248277783394, "alpha_loss": -0.01139481392719092, "alpha_value": 0.24891944478643951, "duration": 231.08396553993225, "step": 67250}
{"episode_reward": 291.04105296205694, "episode": 539.0, "Q1 loss": 13.984311851501465, "Q2 loss": 14.019379035949708, "Mean Target Q": 223.00888244628905, "Mean Q1": 223.00454235839842, "Mean Q2": 223.0033937988281, "critic_loss": 28.00369076538086, "batch_reward": 1.6040764627456665, "actor_loss": -224.2326129731678, "actor_target_entropy": -1.0, "actor_entropy": 0.31764204681865754, "alpha_loss": -0.018728006091560164, "alpha_value": 0.24986709805478088, "duration": 224.7171287536621, "step": 67375}
{"episode_reward": 183.33225904869042, "episode": 540.0, "Q1 loss": 13.741681663513184, "Q2 loss": 13.732642623901366, "Mean Target Q": 223.1517938232422, "Mean Q1": 223.15588928222655, "Mean Q2": 223.15629711914062, "critic_loss": 27.474324188232423, "batch_reward": 1.5989190559387207, "actor_loss": -224.18087866998488, "actor_target_entropy": -1.0, "actor_entropy": 0.33248337238065656, "alpha_loss": -0.017611174979397366, "alpha_value": 0.25122457149642907, "duration": 169.74681329727173, "step": 67500}
{"episode_reward": 61.721388591215366, "episode": 541.0, "Q1 loss": 14.140271705627441, "Q2 loss": 14.155437568664551, "Mean Target Q": 223.28779431152344, "Mean Q1": 223.27952185058595, "Mean Q2": 223.27958642578125, "critic_loss": 28.29570913696289, "batch_reward": 1.5962524547576904, "actor_loss": -224.31078447614397, "actor_target_entropy": -1.0, "actor_entropy": 0.35220113065507674, "alpha_loss": -0.01660983942242132, "alpha_value": 0.2523388288997194, "duration": 193.31899571418762, "step": 67625}
{"episode_reward": 151.975815671646, "episode": 542.0, "Q1 loss": 14.280140419006347, "Q2 loss": 14.173085304260255, "Mean Target Q": 223.4083145751953, "Mean Q1": 223.41536145019532, "Mean Q2": 223.41576818847656, "critic_loss": 28.453225708007814, "batch_reward": 1.597354552268982, "actor_loss": -224.49495007914882, "actor_target_entropy": -1.0, "actor_entropy": 0.3684661739295529, "alpha_loss": -0.0018610105241438555, "alpha_value": 0.2531863412269811, "duration": 181.56905508041382, "step": 67750}
{"episode_reward": 212.1289548948323, "episode": 543.0, "Q1 loss": 15.136878387451173, "Q2 loss": 15.294969673156737, "Mean Target Q": 223.51467102050782, "Mean Q1": 223.50432592773439, "Mean Q2": 223.50667065429687, "critic_loss": 30.431848022460937, "batch_reward": 1.578808825492859, "actor_loss": -224.66674441382997, "actor_target_entropy": -1.0, "actor_entropy": 0.38678400052918327, "alpha_loss": -0.005782934814868938, "alpha_value": 0.2533500480799543, "duration": 183.06411719322205, "step": 67875}
{"episode_reward": 224.3615387595472, "episode": 544.0, "Q1 loss": 14.470359741210938, "Q2 loss": 14.528800407409667, "Mean Target Q": 223.42392016601562, "Mean Q1": 223.42027380371093, "Mean Q2": 223.42002416992187, "critic_loss": 28.999160110473632, "batch_reward": 1.590233344078064, "actor_loss": -224.57486774075417, "actor_target_entropy": -1.0, "actor_entropy": 0.3570190038411848, "alpha_loss": -0.00012408304891939605, "alpha_value": 0.2534027336105074, "duration": 197.40232014656067, "step": 68000}
{"episode_reward": 201.28015765457985, "episode": 545.0, "Q1 loss": 15.016236503601075, "Q2 loss": 14.878477210998534, "Mean Target Q": 223.74032287597657, "Mean Q1": 223.74175610351563, "Mean Q2": 223.7431641845703, "critic_loss": 29.894713775634767, "batch_reward": 1.5845772075653075, "actor_loss": -224.8201681470114, "actor_target_entropy": -1.0, "actor_entropy": 0.3615758896820129, "alpha_loss": -0.005842990892392303, "alpha_value": 0.25377842744957685, "duration": 213.33419919013977, "step": 68125}
{"episode_reward": 216.5833839034574, "episode": 546.0, "Q1 loss": 14.441667213439942, "Q2 loss": 14.485074829101562, "Mean Target Q": 223.9469709472656, "Mean Q1": 223.94407006835937, "Mean Q2": 223.94410217285156, "critic_loss": 28.926742080688477, "batch_reward": 1.5993087902069092, "actor_loss": -225.0842814291677, "actor_target_entropy": -1.0, "actor_entropy": 0.36323732642396805, "alpha_loss": 0.0016214335262174568, "alpha_value": 0.2537082203544504, "duration": 207.09514379501343, "step": 68250}
{"episode_reward": 236.81023432066792, "episode": 547.0, "Q1 loss": 14.720624588012695, "Q2 loss": 14.733864418029786, "Mean Target Q": 224.06123754882813, "Mean Q1": 224.05638537597656, "Mean Q2": 224.05752514648438, "critic_loss": 29.454489059448242, "batch_reward": 1.592775309562683, "actor_loss": -225.13290405273438, "actor_target_entropy": -1.0, "actor_entropy": 0.3726554129804884, "alpha_loss": 0.006773426663130522, "alpha_value": 0.2535731638744282, "duration": 224.04772019386292, "step": 68375}
{"episode_reward": 250.16764829123088, "episode": 548.0, "Q1 loss": 14.257633560180665, "Q2 loss": 14.283901847839356, "Mean Target Q": 224.13029553222657, "Mean Q1": 224.13341052246093, "Mean Q2": 224.13013830566408, "critic_loss": 28.541535537719728, "batch_reward": 1.6010175495147705, "actor_loss": -225.14960135183026, "actor_target_entropy": -1.0, "actor_entropy": 0.3713937281600891, "alpha_loss": 0.008294084068057277, "alpha_value": 0.2531156645599489, "duration": 191.2545359134674, "step": 68500}
{"episode_reward": 248.72976980891195, "episode": 549.0, "Q1 loss": 14.352512771606445, "Q2 loss": 14.24241040802002, "Mean Target Q": 224.24992028808595, "Mean Q1": 224.24267919921874, "Mean Q2": 224.24240954589843, "critic_loss": 28.594923278808594, "batch_reward": 1.5941257343292237, "actor_loss": -225.3394303094773, "actor_target_entropy": -1.0, "actor_entropy": 0.3599683448435768, "alpha_loss": -0.003576793678341404, "alpha_value": 0.2530295312208057, "duration": 182.42351484298706, "step": 68625}
{"episode_reward": 219.8310670391574, "episode": 550.0, "Q1 loss": 14.3744013671875, "Q2 loss": 14.379210769653321, "Mean Target Q": 224.41872973632812, "Mean Q1": 224.4095968017578, "Mean Q2": 224.41190502929686, "critic_loss": 28.753612182617186, "batch_reward": 1.599475884437561, "actor_loss": -225.53959606539817, "actor_target_entropy": -1.0, "actor_entropy": 0.3574147940643372, "alpha_loss": -0.0013231560062136381, "alpha_value": 0.2529733954368873, "duration": 168.42242431640625, "step": 68750}
{"episode_reward": 269.3240970093818, "episode": 551.0, "Q1 loss": 15.498004028320313, "Q2 loss": 15.51883413696289, "Mean Target Q": 224.74634240722656, "Mean Q1": 224.7528155517578, "Mean Q2": 224.750994140625, "critic_loss": 31.01683821105957, "batch_reward": 1.5976959037780762, "actor_loss": -225.82170952690973, "actor_target_entropy": -1.0, "actor_entropy": 0.3426700532436371, "alpha_loss": -0.0005074452815784349, "alpha_value": 0.253124633322183, "duration": 175.51926517486572, "step": 68875}
{"episode_reward": 263.0558358448292, "episode": 552.0, "Q1 loss": 14.863916130065919, "Q2 loss": 14.856621505737305, "Mean Target Q": 224.7486221923828, "Mean Q1": 224.73906762695313, "Mean Q2": 224.74150073242188, "critic_loss": 29.72053759765625, "batch_reward": 1.5933542976379393, "actor_loss": -225.72182809152912, "actor_target_entropy": -1.0, "actor_entropy": 0.3437444634975926, "alpha_loss": 0.012732115224935114, "alpha_value": 0.2525978715204332, "duration": 167.619065284729, "step": 69000}
{"episode_reward": 236.99775124696777, "episode": 553.0, "Q1 loss": 14.675015441894532, "Q2 loss": 14.618831436157226, "Mean Target Q": 224.97030737304686, "Mean Q1": 224.96727868652343, "Mean Q2": 224.96658361816407, "critic_loss": 29.29384701538086, "batch_reward": 1.6024810419082642, "actor_loss": -226.15648808554997, "actor_target_entropy": -1.0, "actor_entropy": 0.34889974764415194, "alpha_loss": 1.4364578953338048e-05, "alpha_value": 0.25233240887402675, "duration": 168.84807324409485, "step": 69125}
{"episode_reward": 248.53758788487485, "episode": 554.0, "Q1 loss": 14.617202606201172, "Q2 loss": 14.565588066101075, "Mean Target Q": 225.15402014160156, "Mean Q1": 225.15458972167968, "Mean Q2": 225.15343334960937, "critic_loss": 29.182790588378907, "batch_reward": 1.6096796979904175, "actor_loss": -226.18141494258757, "actor_target_entropy": -1.0, "actor_entropy": 0.3523297100778549, "alpha_loss": -0.02242548277436365, "alpha_value": 0.2529307033200951, "duration": 168.49161458015442, "step": 69250}
{"episode_reward": 249.3802727386686, "episode": 555.0, "Q1 loss": 14.38364917755127, "Q2 loss": 14.32745425415039, "Mean Target Q": 225.34450622558595, "Mean Q1": 225.34392443847656, "Mean Q2": 225.34363244628906, "critic_loss": 28.71110336303711, "batch_reward": 1.6052841367721558, "actor_loss": -226.34078180222284, "actor_target_entropy": -1.0, "actor_entropy": 0.32451072997517055, "alpha_loss": -0.031165316176142484, "alpha_value": 0.2548298123558871, "duration": 167.1946668624878, "step": 69375}
{"episode_reward": 235.29589579887596, "episode": 556.0, "Q1 loss": 14.595198677062989, "Q2 loss": 14.464950874328613, "Mean Target Q": 225.55370751953126, "Mean Q1": 225.54787121582032, "Mean Q2": 225.5514288330078, "critic_loss": 29.060149597167968, "batch_reward": 1.6130072565078735, "actor_loss": -226.68682713662423, "actor_target_entropy": -1.0, "actor_entropy": 0.34637899168076053, "alpha_loss": -0.016145349239870425, "alpha_value": 0.25641329368488397, "duration": 193.86836695671082, "step": 69500}
{"episode_reward": 215.16003386076957, "episode": 557.0, "Q1 loss": 14.30089444732666, "Q2 loss": 14.308683898925782, "Mean Target Q": 225.612013671875, "Mean Q1": 225.61379418945313, "Mean Q2": 225.61189428710938, "critic_loss": 28.609578414916992, "batch_reward": 1.6070660133361816, "actor_loss": -226.76706077938988, "actor_target_entropy": -1.0, "actor_entropy": 0.3732217715846168, "alpha_loss": -0.0055411620442533775, "alpha_value": 0.2571716613060071, "duration": 186.7570903301239, "step": 69625}
{"episode_reward": 255.6472666990796, "episode": 558.0, "Q1 loss": 14.357125343322753, "Q2 loss": 14.181728675842285, "Mean Target Q": 225.47117333984374, "Mean Q1": 225.4691317138672, "Mean Q2": 225.47151086425782, "critic_loss": 28.538853897094725, "batch_reward": 1.5861778297424316, "actor_loss": -226.6038838048135, "actor_target_entropy": -1.0, "actor_entropy": 0.3514952068367312, "alpha_loss": -0.015984982804154918, "alpha_value": 0.2580645420347919, "duration": 207.56704258918762, "step": 69750}
{"episode_reward": 251.99096820477456, "episode": 559.0, "Q1 loss": 14.655820983886718, "Q2 loss": 14.666160652160645, "Mean Target Q": 225.87163439941406, "Mean Q1": 225.86937243652343, "Mean Q2": 225.86858984375, "critic_loss": 29.321981735229492, "batch_reward": 1.605437313079834, "actor_loss": -226.95190986754403, "actor_target_entropy": -1.0, "actor_entropy": 0.3860623642565712, "alpha_loss": 0.007214196410680574, "alpha_value": 0.2582497585360644, "duration": 201.11342334747314, "step": 69875}
{"episode_reward": 174.86169550394317, "episode": 560.0, "Q1 loss": 14.406940834045411, "Q2 loss": 14.32710390472412, "Mean Target Q": 225.93835974121095, "Mean Q1": 225.93260327148437, "Mean Q2": 225.93032092285156, "critic_loss": 28.73404479980469, "batch_reward": 1.6120269174575805, "actor_loss": -226.96897469797443, "actor_target_entropy": -1.0, "actor_entropy": 0.36758878442548937, "alpha_loss": 0.0013258918488938962, "alpha_value": 0.25780480971622655, "step": 70000}
{"duration": 207.35941815376282, "step": 70000}
{"episode_reward": 202.69864234779538, "episode": 561.0, "Q1 loss": 14.131467948913574, "Q2 loss": 14.105474822998048, "Mean Target Q": 225.9586317138672, "Mean Q1": 225.96061889648436, "Mean Q2": 225.9626162109375, "critic_loss": 28.236942687988282, "batch_reward": 1.5974646234512329, "actor_loss": -226.91245863172742, "actor_target_entropy": -1.0, "actor_entropy": 0.3508810055634332, "alpha_loss": 0.003320279157912684, "alpha_value": 0.2576803425561205, "duration": 191.46583795547485, "step": 70125}
{"episode_reward": 291.9958664463632, "episode": 562.0, "Q1 loss": 15.354029327392578, "Q2 loss": 15.377446884155274, "Mean Target Q": 226.340953125, "Mean Q1": 226.33303894042967, "Mean Q2": 226.33340893554688, "critic_loss": 30.73147621154785, "batch_reward": 1.6101342668533325, "actor_loss": -227.55759799095893, "actor_target_entropy": -1.0, "actor_entropy": 0.36844871890160347, "alpha_loss": -0.005112403177566106, "alpha_value": 0.2576755995844767, "duration": 204.11971831321716, "step": 70250}
{"episode_reward": 253.79302401126435, "episode": 563.0, "Q1 loss": 15.157882080078124, "Q2 loss": 15.095506401062012, "Mean Target Q": 226.45615197753907, "Mean Q1": 226.4651904296875, "Mean Q2": 226.46454797363282, "critic_loss": 30.25338848876953, "batch_reward": 1.6096195182800292, "actor_loss": -227.51785593184215, "actor_target_entropy": -1.0, "actor_entropy": 0.35764910328009775, "alpha_loss": 0.001144571713955393, "alpha_value": 0.2577738197867042, "duration": 167.77426099777222, "step": 70375}
{"episode_reward": 101.76746367749168, "episode": 564.0, "Q1 loss": 14.881372291564942, "Q2 loss": 14.993097770690918, "Mean Target Q": 226.51674963378906, "Mean Q1": 226.51313391113283, "Mean Q2": 226.51000903320312, "critic_loss": 29.874469985961912, "batch_reward": 1.6095973834991455, "actor_loss": -227.5324426466419, "actor_target_entropy": -1.0, "actor_entropy": 0.3877714930042144, "alpha_loss": 0.0038936400650850227, "alpha_value": 0.2576887087532958, "duration": 158.2848060131073, "step": 70500}
{"episode_reward": 221.39018021746372, "episode": 565.0, "Q1 loss": 15.519355598449707, "Q2 loss": 15.439265037536622, "Mean Target Q": 226.73555895996094, "Mean Q1": 226.72716552734374, "Mean Q2": 226.73040075683593, "critic_loss": 30.95862055969238, "batch_reward": 1.6055798845291138, "actor_loss": -227.7260051908947, "actor_target_entropy": -1.0, "actor_entropy": 0.36529099515506197, "alpha_loss": 0.012683465803367279, "alpha_value": 0.2571380818219308, "duration": 164.91286754608154, "step": 70625}
{"episode_reward": 250.0192909796736, "episode": 566.0, "Q1 loss": 14.962441986083984, "Q2 loss": 14.914519287109375, "Mean Target Q": 226.65886328125, "Mean Q1": 226.66437854003905, "Mean Q2": 226.66383068847657, "critic_loss": 29.876961212158204, "batch_reward": 1.5962351427078247, "actor_loss": -227.7843285837481, "actor_target_entropy": -1.0, "actor_entropy": 0.39473237914423787, "alpha_loss": -0.0024640781076384647, "alpha_value": 0.2567083389447765, "duration": 157.84387755393982, "step": 70750}
{"episode_reward": 193.2571875927512, "episode": 567.0, "Q1 loss": 14.61609065246582, "Q2 loss": 14.543537895202636, "Mean Target Q": 226.764947265625, "Mean Q1": 226.76076245117187, "Mean Q2": 226.7588231201172, "critic_loss": 29.15962841796875, "batch_reward": 1.6022390537261963, "actor_loss": -227.75201585557727, "actor_target_entropy": -1.0, "actor_entropy": 0.3781505288585784, "alpha_loss": 0.001200042228909239, "alpha_value": 0.25687442201636274, "duration": 184.38757967948914, "step": 70875}
{"episode_reward": 217.98789090915642, "episode": 568.0, "Q1 loss": 14.443922897338867, "Q2 loss": 14.487361831665039, "Mean Target Q": 226.86281994628905, "Mean Q1": 226.8527567138672, "Mean Q2": 226.85331042480468, "critic_loss": 28.931284744262694, "batch_reward": 1.6001111364364624, "actor_loss": -227.96412068028604, "actor_target_entropy": -1.0, "actor_entropy": 0.3705030006747092, "alpha_loss": -0.012112848873760912, "alpha_value": 0.2571194248030798, "duration": 200.8479926586151, "step": 71000}
{"episode_reward": 225.67918901678934, "episode": 569.0, "Q1 loss": 15.349222892761231, "Q2 loss": 15.307937065124511, "Mean Target Q": 226.95481945800782, "Mean Q1": 226.95671020507814, "Mean Q2": 226.95772839355467, "critic_loss": 30.657159927368163, "batch_reward": 1.6103722190856933, "actor_loss": -228.15235174269904, "actor_target_entropy": -1.0, "actor_entropy": 0.3563129547096434, "alpha_loss": -0.004865134818597682, "alpha_value": 0.2578542405778444, "duration": 194.03731775283813, "step": 71125}
{"episode_reward": 238.58592716839053, "episode": 570.0, "Q1 loss": 14.59097525024414, "Q2 loss": 14.616308570861817, "Mean Target Q": 227.20019921875, "Mean Q1": 227.19270056152342, "Mean Q2": 227.19260864257814, "critic_loss": 29.207283798217773, "batch_reward": 1.598919358253479, "actor_loss": -228.26044094947076, "actor_target_entropy": -1.0, "actor_entropy": 0.3785596619690618, "alpha_loss": 2.7244084424549534e-05, "alpha_value": 0.257851646091369, "duration": 190.85346007347107, "step": 71250}
{"episode_reward": 242.63337079952524, "episode": 571.0, "Q1 loss": 14.115231071472168, "Q2 loss": 14.134963928222657, "Mean Target Q": 227.14460205078126, "Mean Q1": 227.14093493652345, "Mean Q2": 227.13880102539062, "critic_loss": 28.250195022583007, "batch_reward": 1.5959163312911988, "actor_loss": -228.30033511207216, "actor_target_entropy": -1.0, "actor_entropy": 0.38355731065311127, "alpha_loss": -0.00975771138669982, "alpha_value": 0.2582783073107851, "duration": 191.5209836959839, "step": 71375}
{"episode_reward": 241.38363451025415, "episode": 572.0, "Q1 loss": 13.874326118469238, "Q2 loss": 13.873964431762696, "Mean Target Q": 227.46990808105468, "Mean Q1": 227.46585766601564, "Mean Q2": 227.46888171386718, "critic_loss": 27.74829051208496, "batch_reward": 1.6076161947250367, "actor_loss": -228.43699645996094, "actor_target_entropy": -1.0, "actor_entropy": 0.3710726816808024, "alpha_loss": -0.0007997443861958961, "alpha_value": 0.2586986133336282, "duration": 205.93588089942932, "step": 71500}
{"episode_reward": 290.61057599381957, "episode": 573.0, "Q1 loss": 14.438811569213867, "Q2 loss": 14.396376808166504, "Mean Target Q": 227.60348901367186, "Mean Q1": 227.60749206542968, "Mean Q2": 227.60617333984376, "critic_loss": 28.835188385009765, "batch_reward": 1.5985302619934083, "actor_loss": -228.6349140954396, "actor_target_entropy": -1.0, "actor_entropy": 0.3690784270801241, "alpha_loss": 0.007951873942233977, "alpha_value": 0.2583281506896759, "duration": 177.56400179862976, "step": 71625}
{"episode_reward": 195.77780877302817, "episode": 574.0, "Q1 loss": 13.984241744995117, "Q2 loss": 13.978249618530274, "Mean Target Q": 227.70943286132814, "Mean Q1": 227.7089393310547, "Mean Q2": 227.70802783203126, "critic_loss": 27.96249133300781, "batch_reward": 1.614816656112671, "actor_loss": -228.58614718529486, "actor_target_entropy": -1.0, "actor_entropy": 0.3521936473346526, "alpha_loss": 0.007714970799673709, "alpha_value": 0.2578211644861725, "duration": 166.307843208313, "step": 71750}
{"episode_reward": 195.78821499139542, "episode": 575.0, "Q1 loss": 14.317381202697755, "Q2 loss": 14.294516357421875, "Mean Target Q": 227.67919604492187, "Mean Q1": 227.67532165527345, "Mean Q2": 227.67754614257814, "critic_loss": 28.61189764404297, "batch_reward": 1.6001185579299926, "actor_loss": -228.5894487169054, "actor_target_entropy": -1.0, "actor_entropy": 0.3746899825239938, "alpha_loss": 0.01382135327846285, "alpha_value": 0.2571524641847541, "duration": 177.44176983833313, "step": 71875}
{"episode_reward": 234.50638350887004, "episode": 576.0, "Q1 loss": 14.443311698913574, "Q2 loss": 14.39775503540039, "Mean Target Q": 227.78315270996094, "Mean Q1": 227.7842677001953, "Mean Q2": 227.78468005371093, "critic_loss": 28.841066711425782, "batch_reward": 1.6102060689926148, "actor_loss": -228.96990105413622, "actor_target_entropy": -1.0, "actor_entropy": 0.35132898053815287, "alpha_loss": 0.0020601499540310714, "alpha_value": 0.2565327053063284, "duration": 169.50440907478333, "step": 72000}
{"episode_reward": 243.06577289367326, "episode": 577.0, "Q1 loss": 15.00014675140381, "Q2 loss": 14.921952186584473, "Mean Target Q": 227.95019348144533, "Mean Q1": 227.94940783691408, "Mean Q2": 227.9468858642578, "critic_loss": 29.922098999023437, "batch_reward": 1.6004945468902587, "actor_loss": -229.08428519112724, "actor_target_entropy": -1.0, "actor_entropy": 0.34400855832629734, "alpha_loss": -0.009249763740670113, "alpha_value": 0.2567132061055267, "duration": 158.56129574775696, "step": 72125}
{"episode_reward": 248.14300352530117, "episode": 578.0, "Q1 loss": 14.7386861038208, "Q2 loss": 14.80125218963623, "Mean Target Q": 228.0996727294922, "Mean Q1": 228.0954532470703, "Mean Q2": 228.09814489746094, "critic_loss": 29.539938262939454, "batch_reward": 1.6085162343978883, "actor_loss": -229.11953735351562, "actor_target_entropy": -1.0, "actor_entropy": 0.3579437886514971, "alpha_loss": -0.0012608557045760175, "alpha_value": 0.2571698060086755, "duration": 172.27995610237122, "step": 72250}
{"episode_reward": 296.7588163376854, "episode": 579.0, "Q1 loss": 15.35569800567627, "Q2 loss": 15.363533027648925, "Mean Target Q": 228.3721845703125, "Mean Q1": 228.37196276855468, "Mean Q2": 228.36809313964844, "critic_loss": 30.719231063842773, "batch_reward": 1.6126907405853272, "actor_loss": -229.3043246799045, "actor_target_entropy": -1.0, "actor_entropy": 0.34646126486006235, "alpha_loss": 0.009096100652915618, "alpha_value": 0.25685263545137865, "duration": 182.0061960220337, "step": 72375}
{"episode_reward": 238.9340977917587, "episode": 580.0, "Q1 loss": 14.275100448608399, "Q2 loss": 14.234604766845703, "Mean Target Q": 228.21087072753906, "Mean Q1": 228.20365759277342, "Mean Q2": 228.2076785888672, "critic_loss": 28.509705123901366, "batch_reward": 1.6177052774429321, "actor_loss": -229.2458060479933, "actor_target_entropy": -1.0, "actor_entropy": 0.3894895901603083, "alpha_loss": 0.007542192684336295, "alpha_value": 0.25624326519934637, "duration": 162.900865316391, "step": 72500}
{"episode_reward": 210.4289518998086, "episode": 581.0, "Q1 loss": 14.247799255371094, "Q2 loss": 14.232052513122559, "Mean Target Q": 228.40536999511718, "Mean Q1": 228.40719616699218, "Mean Q2": 228.40419396972655, "critic_loss": 28.47985173034668, "batch_reward": 1.6151980199813842, "actor_loss": -229.49262346540178, "actor_target_entropy": -1.0, "actor_entropy": 0.37212299023355755, "alpha_loss": 0.004924379259584442, "alpha_value": 0.2556530962101272, "duration": 181.15851831436157, "step": 72625}
{"episode_reward": 296.75340375563366, "episode": 582.0, "Q1 loss": 14.548502769470215, "Q2 loss": 14.559706085205079, "Mean Target Q": 228.4162869873047, "Mean Q1": 228.41428759765626, "Mean Q2": 228.41595922851562, "critic_loss": 29.108208892822265, "batch_reward": 1.6091052350997925, "actor_loss": -229.50625979515814, "actor_target_entropy": -1.0, "actor_entropy": 0.3424840127268145, "alpha_loss": -0.007929065734178068, "alpha_value": 0.2557222367853026, "duration": 176.30557107925415, "step": 72750}
{"episode_reward": 255.70997555154506, "episode": 583.0, "Q1 loss": 14.519842407226562, "Q2 loss": 14.476973937988282, "Mean Target Q": 228.481126953125, "Mean Q1": 228.48259997558594, "Mean Q2": 228.48085205078124, "critic_loss": 28.996816482543945, "batch_reward": 1.6069596090316773, "actor_loss": -229.4823225717696, "actor_target_entropy": -1.0, "actor_entropy": 0.33911613031985266, "alpha_loss": -0.002011586363161249, "alpha_value": 0.2563455203199894, "duration": 159.177725315094, "step": 72875}
{"episode_reward": 234.37847406787853, "episode": 584.0, "Q1 loss": 14.625727012634277, "Q2 loss": 14.64675030517578, "Mean Target Q": 228.690783203125, "Mean Q1": 228.6832158203125, "Mean Q2": 228.6828477783203, "critic_loss": 29.272477249145506, "batch_reward": 1.6197787761688232, "actor_loss": -229.95687890821887, "actor_target_entropy": -1.0, "actor_entropy": 0.352125070268108, "alpha_loss": -0.011583890570628067, "alpha_value": 0.2566676020445415, "duration": 155.58202648162842, "step": 73000}
{"episode_reward": 261.7353933236325, "episode": 585.0, "Q1 loss": 14.627802284240722, "Q2 loss": 14.542073936462403, "Mean Target Q": 228.7842625732422, "Mean Q1": 228.7833994140625, "Mean Q2": 228.78512646484376, "critic_loss": 29.169876205444336, "batch_reward": 1.6002788677215576, "actor_loss": -229.79638986738902, "actor_target_entropy": -1.0, "actor_entropy": 0.3632533150532889, "alpha_loss": -0.0036621253405298504, "alpha_value": 0.25732591642702235, "duration": 168.10157561302185, "step": 73125}
{"episode_reward": 226.99394297075577, "episode": 586.0, "Q1 loss": 14.519331916809081, "Q2 loss": 14.467598770141601, "Mean Target Q": 228.9040500488281, "Mean Q1": 228.89838842773437, "Mean Q2": 228.8971553955078, "critic_loss": 28.986930709838866, "batch_reward": 1.6070359296798706, "actor_loss": -229.96878962362968, "actor_target_entropy": -1.0, "actor_entropy": 0.38277269803708597, "alpha_loss": 0.0017904992320484693, "alpha_value": 0.2573132057188873, "duration": 164.2285635471344, "step": 73250}
{"episode_reward": 193.84587832213887, "episode": 587.0, "Q1 loss": 15.522247550964355, "Q2 loss": 15.440642463684082, "Mean Target Q": 228.9888018798828, "Mean Q1": 228.99117736816407, "Mean Q2": 228.99009765625, "critic_loss": 30.962889907836914, "batch_reward": 1.606282780647278, "actor_loss": -230.04251946343317, "actor_target_entropy": -1.0, "actor_entropy": 0.3819329459515829, "alpha_loss": 0.009922033896492351, "alpha_value": 0.25677370864909743, "duration": 163.59205508232117, "step": 73375}
{"episode_reward": 124.47459031590012, "episode": 588.0, "Q1 loss": 15.441745010375977, "Q2 loss": 15.400737388610839, "Mean Target Q": 229.09891625976562, "Mean Q1": 229.08923681640624, "Mean Q2": 229.092041015625, "critic_loss": 30.84248239135742, "batch_reward": 1.6190315227508545, "actor_loss": -230.15162166472405, "actor_target_entropy": -1.0, "actor_entropy": 0.38909846784607055, "alpha_loss": 0.006883821589121175, "alpha_value": 0.25640785729382387, "duration": 204.62234258651733, "step": 73500}
{"episode_reward": 194.8827079517222, "episode": 589.0, "Q1 loss": 14.872728141784668, "Q2 loss": 14.890383712768555, "Mean Target Q": 229.16901525878907, "Mean Q1": 229.17027282714844, "Mean Q2": 229.17022033691407, "critic_loss": 29.76311183166504, "batch_reward": 1.6147313652038575, "actor_loss": -230.18572634742372, "actor_target_entropy": -1.0, "actor_entropy": 0.3768356243769328, "alpha_loss": -0.0018057142133041033, "alpha_value": 0.2561487768717923, "duration": 196.79818773269653, "step": 73625}
{"episode_reward": 170.51325370300978, "episode": 590.0, "Q1 loss": 14.979575370788574, "Q2 loss": 14.889609741210938, "Mean Target Q": 229.1676553955078, "Mean Q1": 229.16595739746094, "Mean Q2": 229.165607421875, "critic_loss": 29.869185272216797, "batch_reward": 1.6183891935348511, "actor_loss": -230.2896243679908, "actor_target_entropy": -1.0, "actor_entropy": 0.36868819978929335, "alpha_loss": 0.005270550166436982, "alpha_value": 0.2562230630215913, "duration": 206.01792931556702, "step": 73750}
{"episode_reward": 244.08561955468372, "episode": 591.0, "Q1 loss": 14.980353240966798, "Q2 loss": 15.045919815063476, "Mean Target Q": 229.40697424316406, "Mean Q1": 229.40855126953124, "Mean Q2": 229.40900952148436, "critic_loss": 30.026272994995118, "batch_reward": 1.616274881362915, "actor_loss": -230.38407316662017, "actor_target_entropy": -1.0, "actor_entropy": 0.36883508496814305, "alpha_loss": 0.004087382620791831, "alpha_value": 0.25572041009065055, "duration": 210.71246576309204, "step": 73875}
{"episode_reward": 186.3443346379804, "episode": 592.0, "Q1 loss": 14.46804054260254, "Q2 loss": 14.407783111572266, "Mean Target Q": 229.46341174316407, "Mean Q1": 229.46568286132813, "Mean Q2": 229.46563317871093, "critic_loss": 28.87582371520996, "batch_reward": 1.6142558126449584, "actor_loss": -230.47582761702998, "actor_target_entropy": -1.0, "actor_entropy": 0.37857081092173056, "alpha_loss": -0.0010844442820657164, "alpha_value": 0.2556396867487698, "duration": 215.06091618537903, "step": 74000}
{"episode_reward": 227.62523875271015, "episode": 593.0, "Q1 loss": 14.823900520324708, "Q2 loss": 14.854669372558593, "Mean Target Q": 229.52747705078124, "Mean Q1": 229.51933068847657, "Mean Q2": 229.5183291015625, "critic_loss": 29.678569931030275, "batch_reward": 1.616669542312622, "actor_loss": -230.53028966510107, "actor_target_entropy": -1.0, "actor_entropy": 0.40846392133879283, "alpha_loss": 0.007662889300032504, "alpha_value": 0.2553073808489276, "duration": 198.02363419532776, "step": 74125}
{"episode_reward": 242.97222046977137, "episode": 594.0, "Q1 loss": 14.934498870849609, "Q2 loss": 14.88624045562744, "Mean Target Q": 229.60808032226564, "Mean Q1": 229.60405041503907, "Mean Q2": 229.60517272949218, "critic_loss": 29.8207393951416, "batch_reward": 1.612858081817627, "actor_loss": -230.67900011616368, "actor_target_entropy": -1.0, "actor_entropy": 0.3657012846200697, "alpha_loss": -0.0071054231413009185, "alpha_value": 0.2553660374909378, "duration": 206.63688111305237, "step": 74250}
{"episode_reward": 186.8389482488584, "episode": 595.0, "Q1 loss": 15.389465629577638, "Q2 loss": 15.295159057617187, "Mean Target Q": 229.7551317138672, "Mean Q1": 229.75937902832032, "Mean Q2": 229.75654174804689, "critic_loss": 30.684624771118163, "batch_reward": 1.6124124212265014, "actor_loss": -230.79208422464038, "actor_target_entropy": -1.0, "actor_entropy": 0.38013830307930235, "alpha_loss": 0.0032468344018395457, "alpha_value": 0.2556290840025528, "duration": 213.86474776268005, "step": 74375}
{"episode_reward": 268.4759451902399, "episode": 596.0, "Q1 loss": 15.65889680480957, "Q2 loss": 15.65841692352295, "Mean Target Q": 229.8453623046875, "Mean Q1": 229.83455627441407, "Mean Q2": 229.83588293457032, "critic_loss": 31.317313751220702, "batch_reward": 1.622541344642639, "actor_loss": -230.97645248905306, "actor_target_entropy": -1.0, "actor_entropy": 0.3443762657623137, "alpha_loss": 0.008060276271745322, "alpha_value": 0.2551214923232855, "duration": 205.43250107765198, "step": 74500}
{"episode_reward": 246.47298125965284, "episode": 597.0, "Q1 loss": 14.881756065368652, "Q2 loss": 14.855123657226562, "Mean Target Q": 229.94840686035155, "Mean Q1": 229.9487869873047, "Mean Q2": 229.94729675292967, "critic_loss": 29.736879730224608, "batch_reward": 1.6119148483276367, "actor_loss": -231.0069802904886, "actor_target_entropy": -1.0, "actor_entropy": 0.33659989067486357, "alpha_loss": -0.005427227928377096, "alpha_value": 0.2548560485171696, "duration": 211.89673256874084, "step": 74625}
{"episode_reward": 82.25236371843417, "episode": 598.0, "Q1 loss": 15.362286064147948, "Q2 loss": 15.314256828308105, "Mean Target Q": 230.00155395507812, "Mean Q1": 230.00035021972656, "Mean Q2": 230.00346423339843, "critic_loss": 30.67654280090332, "batch_reward": 1.602577612876892, "actor_loss": -231.17540962465347, "actor_target_entropy": -1.0, "actor_entropy": 0.343899275987379, "alpha_loss": -0.005507053829909813, "alpha_value": 0.2554251149961936, "duration": 219.107031583786, "step": 74750}
{"episode_reward": 187.42273044960484, "episode": 599.0, "Q1 loss": 15.133087875366211, "Q2 loss": 15.091000236511231, "Mean Target Q": 230.0815294189453, "Mean Q1": 230.0830028076172, "Mean Q2": 230.0813924560547, "critic_loss": 30.224088119506835, "batch_reward": 1.6138688459396362, "actor_loss": -231.12911091153583, "actor_target_entropy": -1.0, "actor_entropy": 0.3559035114825718, "alpha_loss": 0.012749680510116003, "alpha_value": 0.2551547940392534, "duration": 218.68487286567688, "step": 74875}
{"episode_reward": 254.82254779411943, "episode": 600.0, "Q1 loss": 15.232629150390625, "Q2 loss": 15.18476557159424, "Mean Target Q": 230.11682446289063, "Mean Q1": 230.11183203125, "Mean Q2": 230.10993908691407, "critic_loss": 30.41739456176758, "batch_reward": 1.6186266317367555, "actor_loss": -231.21413987682712, "actor_target_entropy": -1.0, "actor_entropy": 0.372412069189933, "alpha_loss": 0.010493623753709177, "alpha_value": 0.254445545905604, "step": 75000}
{"duration": 213.4869019985199, "step": 75000}
{"episode_reward": 165.79304169056542, "episode": 601.0, "Q1 loss": 15.131512870788574, "Q2 loss": 15.248383094787597, "Mean Target Q": 230.2305264892578, "Mean Q1": 230.22292614746092, "Mean Q2": 230.2239666748047, "critic_loss": 30.37989596557617, "batch_reward": 1.6143648433685303, "actor_loss": -231.2398662264385, "actor_target_entropy": -1.0, "actor_entropy": 0.37324178881115383, "alpha_loss": 0.0002231585778414257, "alpha_value": 0.2540129523349945, "duration": 195.45671439170837, "step": 75125}
{"episode_reward": 192.2664073766855, "episode": 602.0, "Q1 loss": 14.345001251220703, "Q2 loss": 14.404185234069825, "Mean Target Q": 230.14395166015626, "Mean Q1": 230.1411368408203, "Mean Q2": 230.1408557128906, "critic_loss": 28.7491865234375, "batch_reward": 1.6054061737060548, "actor_loss": -231.15657757174583, "actor_target_entropy": -1.0, "actor_entropy": 0.38820729765199846, "alpha_loss": 0.00790277789271767, "alpha_value": 0.25368705953428305, "duration": 213.10348272323608, "step": 75250}
{"episode_reward": 161.78400657960657, "episode": 603.0, "Q1 loss": 14.880377044677735, "Q2 loss": 14.825324745178223, "Mean Target Q": 230.25981079101564, "Mean Q1": 230.26209155273438, "Mean Q2": 230.26081970214844, "critic_loss": 29.705701782226562, "batch_reward": 1.6046847620010376, "actor_loss": -231.3686244904049, "actor_target_entropy": -1.0, "actor_entropy": 0.37205828371502103, "alpha_loss": -0.010782679165935232, "alpha_value": 0.25385033216124725, "duration": 197.97150492668152, "step": 75375}
{"episode_reward": 277.0465324687652, "episode": 604.0, "Q1 loss": 14.607462677001953, "Q2 loss": 14.589183158874512, "Mean Target Q": 230.29951513671875, "Mean Q1": 230.3018341064453, "Mean Q2": 230.30299938964845, "critic_loss": 29.196645904541015, "batch_reward": 1.6153875255584718, "actor_loss": -231.466185785109, "actor_target_entropy": -1.0, "actor_entropy": 0.39768222743465054, "alpha_loss": -0.0031937733367686312, "alpha_value": 0.25444456725285003, "duration": 208.43859481811523, "step": 75500}
{"episode_reward": 253.929593354038, "episode": 605.0, "Q1 loss": 15.067363121032715, "Q2 loss": 15.136508567810058, "Mean Target Q": 230.5239697265625, "Mean Q1": 230.52112255859376, "Mean Q2": 230.52122717285155, "critic_loss": 30.203871612548827, "batch_reward": 1.6101189966201783, "actor_loss": -231.507814437624, "actor_target_entropy": -1.0, "actor_entropy": 0.38283097838598584, "alpha_loss": -0.0001889149702730633, "alpha_value": 0.2543764048577263, "duration": 216.2542028427124, "step": 75625}
{"episode_reward": 324.86416600936207, "episode": 606.0, "Q1 loss": 15.167666641235352, "Q2 loss": 15.044077629089356, "Mean Target Q": 230.6100595703125, "Mean Q1": 230.61369958496093, "Mean Q2": 230.61315112304686, "critic_loss": 30.21174429321289, "batch_reward": 1.6128660478591919, "actor_loss": -231.71506894019342, "actor_target_entropy": -1.0, "actor_entropy": 0.38519442081451416, "alpha_loss": -0.0022661722107459943, "alpha_value": 0.2544868789259848, "duration": 220.15552163124084, "step": 75750}
{"episode_reward": 229.95457940458022, "episode": 607.0, "Q1 loss": 15.421586013793945, "Q2 loss": 15.396022048950195, "Mean Target Q": 230.75790942382812, "Mean Q1": 230.74705419921875, "Mean Q2": 230.74822351074218, "critic_loss": 30.817608062744142, "batch_reward": 1.6076228303909301, "actor_loss": -231.8989504859561, "actor_target_entropy": -1.0, "actor_entropy": 0.3780284259054396, "alpha_loss": -2.690519405794995e-05, "alpha_value": 0.25464843280069144, "duration": 219.05442810058594, "step": 75875}
{"episode_reward": 226.87202937821343, "episode": 608.0, "Q1 loss": 14.953836898803711, "Q2 loss": 14.959393386840821, "Mean Target Q": 231.03534924316406, "Mean Q1": 231.0357159423828, "Mean Q2": 231.03464331054687, "critic_loss": 29.913230255126955, "batch_reward": 1.6130229711532593, "actor_loss": -232.0365743329448, "actor_target_entropy": -1.0, "actor_entropy": 0.38348106318904507, "alpha_loss": 0.010640296525502156, "alpha_value": 0.25428367163733967, "duration": 219.84605288505554, "step": 76000}
{"episode_reward": 281.4643477200297, "episode": 609.0, "Q1 loss": 15.09824131011963, "Q2 loss": 15.005440940856934, "Mean Target Q": 231.08574926757814, "Mean Q1": 231.08382421875, "Mean Q2": 231.08501611328126, "critic_loss": 30.103682144165038, "batch_reward": 1.61801096534729, "actor_loss": -232.17368837386843, "actor_target_entropy": -1.0, "actor_entropy": 0.3754395426265777, "alpha_loss": -0.005750595222389888, "alpha_value": 0.25389962290007256, "duration": 218.07047176361084, "step": 76125}
{"episode_reward": 175.3021406448849, "episode": 610.0, "Q1 loss": 14.44777717590332, "Q2 loss": 14.39491429901123, "Mean Target Q": 231.06214807128907, "Mean Q1": 231.0581848144531, "Mean Q2": 231.0588513183594, "critic_loss": 28.842691482543945, "batch_reward": 1.620246121406555, "actor_loss": -232.03497363675027, "actor_target_entropy": -1.0, "actor_entropy": 0.355661554442298, "alpha_loss": 0.0018782622383667095, "alpha_value": 0.2542378234900669, "duration": 218.4689040184021, "step": 76250}
{"episode_reward": 221.57983794222764, "episode": 611.0, "Q1 loss": 14.902029891967773, "Q2 loss": 14.838138862609863, "Mean Target Q": 231.0145450439453, "Mean Q1": 231.01077734375, "Mean Q2": 231.0082313232422, "critic_loss": 29.740168823242186, "batch_reward": 1.6210914354324342, "actor_loss": -232.00156584240142, "actor_target_entropy": -1.0, "actor_entropy": 0.40888965129852295, "alpha_loss": 0.00715091658593525, "alpha_value": 0.25376587319359356, "duration": 225.00893139839172, "step": 76375}
{"episode_reward": 237.44591760627037, "episode": 612.0, "Q1 loss": 15.067640815734864, "Q2 loss": 15.120985191345214, "Mean Target Q": 231.1976025390625, "Mean Q1": 231.1967081298828, "Mean Q2": 231.19828088378907, "critic_loss": 30.188626022338866, "batch_reward": 1.6252934265136718, "actor_loss": -232.115842511577, "actor_target_entropy": -1.0, "actor_entropy": 0.36742434963103265, "alpha_loss": -0.006518463491492214, "alpha_value": 0.25376084223148243, "duration": 216.47112464904785, "step": 76500}
{"episode_reward": 244.5638282665694, "episode": 613.0, "Q1 loss": 14.635129119873048, "Q2 loss": 14.548075729370117, "Mean Target Q": 231.21456506347656, "Mean Q1": 231.21366040039064, "Mean Q2": 231.21253564453124, "critic_loss": 29.18320491027832, "batch_reward": 1.6112911396026612, "actor_loss": -232.2667713468037, "actor_target_entropy": -1.0, "actor_entropy": 0.3789760172367096, "alpha_loss": 0.007211607418924806, "alpha_value": 0.25375156641448665, "duration": 205.70094513893127, "step": 76625}
{"episode_reward": 222.13250451505874, "episode": 614.0, "Q1 loss": 15.039158714294434, "Q2 loss": 15.06822634124756, "Mean Target Q": 231.35293127441406, "Mean Q1": 231.3495089111328, "Mean Q2": 231.35095874023438, "critic_loss": 30.10738507080078, "batch_reward": 1.6162583866119384, "actor_loss": -232.5108613044985, "actor_target_entropy": -1.0, "actor_entropy": 0.35522951377976325, "alpha_loss": 0.004827947226247841, "alpha_value": 0.25344317030959934, "duration": 191.8956961631775, "step": 76750}
{"episode_reward": 212.88930063791602, "episode": 615.0, "Q1 loss": 14.833887283325195, "Q2 loss": 14.850385635375977, "Mean Target Q": 231.42303588867188, "Mean Q1": 231.42199487304688, "Mean Q2": 231.42259851074218, "critic_loss": 29.684272857666016, "batch_reward": 1.620095820426941, "actor_loss": -232.5934368315197, "actor_target_entropy": -1.0, "actor_entropy": 0.3534210227311604, "alpha_loss": 0.0015721538895001961, "alpha_value": 0.25305759835891717, "duration": 181.94638776779175, "step": 76875}
{"episode_reward": 247.5985252128682, "episode": 616.0, "Q1 loss": 14.585887489318848, "Q2 loss": 14.632989807128906, "Mean Target Q": 231.6130877685547, "Mean Q1": 231.6041611328125, "Mean Q2": 231.60466040039063, "critic_loss": 29.21887724304199, "batch_reward": 1.6179017810821532, "actor_loss": -232.66609634891634, "actor_target_entropy": -1.0, "actor_entropy": 0.37497941092137366, "alpha_loss": 0.007546033612602661, "alpha_value": 0.2528543286261675, "duration": 182.15080451965332, "step": 77000}
{"episode_reward": 113.94754604427199, "episode": 617.0, "Q1 loss": 15.927220680236816, "Q2 loss": 15.954813751220703, "Mean Target Q": 231.69564379882812, "Mean Q1": 231.7002462158203, "Mean Q2": 231.6969930419922, "critic_loss": 31.88203446960449, "batch_reward": 1.6123361854553222, "actor_loss": -232.6896502782428, "actor_target_entropy": -1.0, "actor_entropy": 0.32709462964345537, "alpha_loss": 0.006946789501752291, "alpha_value": 0.2522961036739667, "duration": 175.4048421382904, "step": 77125}
{"episode_reward": 128.852409244653, "episode": 618.0, "Q1 loss": 15.560533813476562, "Q2 loss": 15.49356566619873, "Mean Target Q": 231.71961303710938, "Mean Q1": 231.71259899902344, "Mean Q2": 231.7147188720703, "critic_loss": 31.054099349975587, "batch_reward": 1.6252419576644896, "actor_loss": -232.69308471679688, "actor_target_entropy": -1.0, "actor_entropy": 0.37401949157637937, "alpha_loss": -0.0067281543029352065, "alpha_value": 0.25219242824588906, "duration": 187.57255959510803, "step": 77250}
{"episode_reward": 202.31815452167285, "episode": 619.0, "Q1 loss": 15.278503524780273, "Q2 loss": 15.20990251159668, "Mean Target Q": 231.7533282470703, "Mean Q1": 231.7601405029297, "Mean Q2": 231.76129833984376, "critic_loss": 30.488406036376954, "batch_reward": 1.623191152572632, "actor_loss": -232.75970216781374, "actor_target_entropy": -1.0, "actor_entropy": 0.37142664477938697, "alpha_loss": 0.011780573025582329, "alpha_value": 0.2519065167582357, "duration": 185.52232575416565, "step": 77375}
{"episode_reward": 239.2564026116052, "episode": 620.0, "Q1 loss": 14.688090156555175, "Q2 loss": 14.753872817993164, "Mean Target Q": 231.82603857421876, "Mean Q1": 231.81749182128905, "Mean Q2": 231.81365881347656, "critic_loss": 29.44196301269531, "batch_reward": 1.622881772041321, "actor_loss": -232.87025500882058, "actor_target_entropy": -1.0, "actor_entropy": 0.35594160277997294, "alpha_loss": 0.005740837289786507, "alpha_value": 0.2512981917913241, "duration": 172.38228940963745, "step": 77500}
{"episode_reward": 253.69392576524518, "episode": 621.0, "Q1 loss": 15.30719499206543, "Q2 loss": 15.295460922241212, "Mean Target Q": 231.88713891601563, "Mean Q1": 231.88900268554687, "Mean Q2": 231.8905428466797, "critic_loss": 30.602655838012694, "batch_reward": 1.6173485374450685, "actor_loss": -232.85856265113466, "actor_target_entropy": -1.0, "actor_entropy": 0.3511261831200312, "alpha_loss": 0.0047925308324574005, "alpha_value": 0.25091960373251904, "duration": 187.6216492652893, "step": 77625}
{"episode_reward": 171.4283628941147, "episode": 622.0, "Q1 loss": 15.06944320678711, "Q2 loss": 15.135242485046387, "Mean Target Q": 231.94921850585936, "Mean Q1": 231.9461983642578, "Mean Q2": 231.94523669433593, "critic_loss": 30.204685638427733, "batch_reward": 1.6199284410476684, "actor_loss": -233.03219063051284, "actor_target_entropy": -1.0, "actor_entropy": 0.35176344263938164, "alpha_loss": 0.006571888593175719, "alpha_value": 0.2506125942095662, "duration": 171.90868616104126, "step": 77750}
{"episode_reward": 180.92467234369045, "episode": 623.0, "Q1 loss": 15.085321533203125, "Q2 loss": 15.0378617477417, "Mean Target Q": 232.1264139404297, "Mean Q1": 232.12048510742187, "Mean Q2": 232.120146484375, "critic_loss": 30.12318339538574, "batch_reward": 1.6298570852279664, "actor_loss": -233.1583261641245, "actor_target_entropy": -1.0, "actor_entropy": 0.35931119559303165, "alpha_loss": 0.005019841298076605, "alpha_value": 0.250014838004304, "duration": 191.42638540267944, "step": 77875}
{"episode_reward": 81.2272894626654, "episode": 624.0, "Q1 loss": 15.30769010925293, "Q2 loss": 15.304390190124511, "Mean Target Q": 232.21439990234376, "Mean Q1": 232.221494140625, "Mean Q2": 232.2228663330078, "critic_loss": 30.612080322265626, "batch_reward": 1.6155236625671388, "actor_loss": -233.16439720892137, "actor_target_entropy": -1.0, "actor_entropy": 0.3606335806750482, "alpha_loss": 0.0009496305250532685, "alpha_value": 0.24985281102585913, "duration": 177.30889105796814, "step": 78000}
{"episode_reward": 153.57750914725713, "episode": 625.0, "Q1 loss": 15.597927436828613, "Q2 loss": 15.490418800354004, "Mean Target Q": 232.21877233886718, "Mean Q1": 232.21471618652345, "Mean Q2": 232.21515808105468, "critic_loss": 31.088346252441408, "batch_reward": 1.613615261077881, "actor_loss": -233.25952899266804, "actor_target_entropy": -1.0, "actor_entropy": 0.3560930235045297, "alpha_loss": 0.003996715934518429, "alpha_value": 0.24958323675014205, "duration": 176.19963550567627, "step": 78125}
{"episode_reward": 203.62578073376295, "episode": 626.0, "Q1 loss": 15.292849449157714, "Q2 loss": 15.27102473449707, "Mean Target Q": 232.13040759277345, "Mean Q1": 232.12470947265626, "Mean Q2": 232.124744140625, "critic_loss": 30.56387417602539, "batch_reward": 1.6059848966598511, "actor_loss": -233.12303161621094, "actor_target_entropy": -1.0, "actor_entropy": 0.3369921138209681, "alpha_loss": 0.01601949512522908, "alpha_value": 0.2489760164616431, "duration": 179.90646386146545, "step": 78250}
{"episode_reward": 210.4796931803377, "episode": 627.0, "Q1 loss": 14.859849723815918, "Q2 loss": 14.883637962341309, "Mean Target Q": 232.32841748046874, "Mean Q1": 232.3261563720703, "Mean Q2": 232.32572424316407, "critic_loss": 29.743487731933595, "batch_reward": 1.6244859008789063, "actor_loss": -233.42442321777344, "actor_target_entropy": -1.0, "actor_entropy": 0.36090870130629765, "alpha_loss": 0.011883361095059958, "alpha_value": 0.24776719642595377, "duration": 177.77868700027466, "step": 78375}
{"episode_reward": 197.91300414696732, "episode": 628.0, "Q1 loss": 15.529663375854492, "Q2 loss": 15.397998397827148, "Mean Target Q": 232.4792244873047, "Mean Q1": 232.47472021484376, "Mean Q2": 232.4740020751953, "critic_loss": 30.927661773681642, "batch_reward": 1.6286965866088867, "actor_loss": -233.64552577849358, "actor_target_entropy": -1.0, "actor_entropy": 0.34484785554870484, "alpha_loss": 0.0030799405630527726, "alpha_value": 0.24739904875665966, "duration": 176.25344491004944, "step": 78500}
{"episode_reward": 207.6638469672682, "episode": 629.0, "Q1 loss": 15.288037940979004, "Q2 loss": 15.329958389282227, "Mean Target Q": 232.45154528808592, "Mean Q1": 232.44764392089843, "Mean Q2": 232.44717626953124, "critic_loss": 30.617996368408203, "batch_reward": 1.6151778507232666, "actor_loss": -233.51048835875497, "actor_target_entropy": -1.0, "actor_entropy": 0.3548260250734904, "alpha_loss": 0.005046988903943982, "alpha_value": 0.2471322015697569, "duration": 182.3858358860016, "step": 78625}
{"episode_reward": 262.35451264591006, "episode": 630.0, "Q1 loss": 15.327272834777832, "Q2 loss": 15.306138748168946, "Mean Target Q": 232.41899255371095, "Mean Q1": 232.42341760253908, "Mean Q2": 232.42434912109374, "critic_loss": 30.633411590576173, "batch_reward": 1.6259317779541016, "actor_loss": -233.48819880331718, "actor_target_entropy": -1.0, "actor_entropy": 0.3806269024648974, "alpha_loss": 0.0005570840608749179, "alpha_value": 0.2469313521745349, "duration": 181.23629999160767, "step": 78750}
{"episode_reward": 238.26158861597452, "episode": 631.0, "Q1 loss": 15.865904151916505, "Q2 loss": 15.798169395446777, "Mean Target Q": 232.47983056640626, "Mean Q1": 232.4749892578125, "Mean Q2": 232.47802038574218, "critic_loss": 31.66407341003418, "batch_reward": 1.621900514602661, "actor_loss": -233.53431628999255, "actor_target_entropy": -1.0, "actor_entropy": 0.3411754085904076, "alpha_loss": 0.0025587439766183257, "alpha_value": 0.24691133605860066, "duration": 176.52213501930237, "step": 78875}
{"episode_reward": 153.38688605399207, "episode": 632.0, "Q1 loss": 15.987090431213378, "Q2 loss": 16.031751640319825, "Mean Target Q": 232.73225598144532, "Mean Q1": 232.7350841064453, "Mean Q2": 232.7311776123047, "critic_loss": 32.01884211730957, "batch_reward": 1.623921127319336, "actor_loss": -233.7596693961851, "actor_target_entropy": -1.0, "actor_entropy": 0.36029933441069817, "alpha_loss": -0.0011631909217084608, "alpha_value": 0.24680894778363083, "duration": 175.1124722957611, "step": 79000}
{"episode_reward": 184.4448990516481, "episode": 633.0, "Q1 loss": 15.637398880004882, "Q2 loss": 15.599193664550782, "Mean Target Q": 232.612419921875, "Mean Q1": 232.60515576171875, "Mean Q2": 232.605712890625, "critic_loss": 31.236592636108398, "batch_reward": 1.6185629148483276, "actor_loss": -233.66400122264074, "actor_target_entropy": -1.0, "actor_entropy": 0.34409785743743654, "alpha_loss": -0.0002981722133145446, "alpha_value": 0.2468059618865709, "duration": 182.81190586090088, "step": 79125}
{"episode_reward": 98.35437028727432, "episode": 634.0, "Q1 loss": 15.469868743896484, "Q2 loss": 15.57188533782959, "Mean Target Q": 232.65567517089843, "Mean Q1": 232.64509924316405, "Mean Q2": 232.6467528076172, "critic_loss": 31.041754119873048, "batch_reward": 1.623348816871643, "actor_loss": -233.82283659904235, "actor_target_entropy": -1.0, "actor_entropy": 0.35529268172479445, "alpha_loss": -0.010993086475683677, "alpha_value": 0.24723168372806512, "duration": 181.05704593658447, "step": 79250}
{"episode_reward": 264.11228411659175, "episode": 635.0, "Q1 loss": 15.020117576599121, "Q2 loss": 14.992998802185058, "Mean Target Q": 232.60498425292968, "Mean Q1": 232.6126467285156, "Mean Q2": 232.61006408691406, "critic_loss": 30.01311640930176, "batch_reward": 1.6199952001571656, "actor_loss": -233.65014139811197, "actor_target_entropy": -1.0, "actor_entropy": 0.3800532921912178, "alpha_loss": -0.005995801018018808, "alpha_value": 0.24777553696077764, "duration": 180.75087690353394, "step": 79375}
{"episode_reward": 207.32254520728225, "episode": 636.0, "Q1 loss": 15.166352920532226, "Q2 loss": 15.194731132507325, "Mean Target Q": 232.7034035644531, "Mean Q1": 232.69867834472657, "Mean Q2": 232.69890844726564, "critic_loss": 30.361084075927735, "batch_reward": 1.6217782564163208, "actor_loss": -233.85569492463142, "actor_target_entropy": -1.0, "actor_entropy": 0.3423424259789528, "alpha_loss": -0.0017474246128732639, "alpha_value": 0.24822950241004132, "duration": 174.29133200645447, "step": 79500}
{"episode_reward": 145.42716789714476, "episode": 637.0, "Q1 loss": 15.811370513916016, "Q2 loss": 15.794528816223144, "Mean Target Q": 232.61930590820313, "Mean Q1": 232.62353662109376, "Mean Q2": 232.623302734375, "critic_loss": 31.6058992767334, "batch_reward": 1.6015327835083009, "actor_loss": -233.672119625031, "actor_target_entropy": -1.0, "actor_entropy": 0.3605116605758667, "alpha_loss": 0.007274651474925497, "alpha_value": 0.24793488857567825, "duration": 191.96479415893555, "step": 79625}
{"episode_reward": 257.4680058242214, "episode": 638.0, "Q1 loss": 15.331981071472168, "Q2 loss": 15.341065406799316, "Mean Target Q": 232.78031811523437, "Mean Q1": 232.77928430175783, "Mean Q2": 232.78070532226562, "critic_loss": 30.673046463012696, "batch_reward": 1.6118457794189454, "actor_loss": -233.9389202979303, "actor_target_entropy": -1.0, "actor_entropy": 0.36869134393430525, "alpha_loss": -0.0025655070353569763, "alpha_value": 0.2478912452689118, "duration": 178.65371417999268, "step": 79750}
{"episode_reward": 181.87044489836566, "episode": 639.0, "Q1 loss": 15.517554725646972, "Q2 loss": 15.410319519042968, "Mean Target Q": 232.80037060546874, "Mean Q1": 232.78754809570313, "Mean Q2": 232.78682373046874, "critic_loss": 30.927874114990235, "batch_reward": 1.6171286449432374, "actor_loss": -233.84800090487042, "actor_target_entropy": -1.0, "actor_entropy": 0.3739363409224011, "alpha_loss": -0.014990609098551056, "alpha_value": 0.24847527526433422, "duration": 172.0482873916626, "step": 79875}
{"episode_reward": 224.55846508903042, "episode": 640.0, "Q1 loss": 15.827691467285156, "Q2 loss": 15.751908226013184, "Mean Target Q": 233.060150390625, "Mean Q1": 233.06674755859376, "Mean Q2": 233.06643920898438, "critic_loss": 31.579599670410158, "batch_reward": 1.61876908493042, "actor_loss": -234.22992534022177, "actor_target_entropy": -1.0, "actor_entropy": 0.34421321990028503, "alpha_loss": -0.0006660941045641178, "alpha_value": 0.2490395363795215, "step": 80000}
{"duration": 184.14111757278442, "step": 80000}
{"episode_reward": 161.94804071659954, "episode": 641.0, "Q1 loss": 16.027494636535643, "Q2 loss": 15.927489532470704, "Mean Target Q": 233.12650305175782, "Mean Q1": 233.12274182128905, "Mean Q2": 233.12319372558593, "critic_loss": 31.954984191894532, "batch_reward": 1.6193319158554078, "actor_loss": -234.36441645546566, "actor_target_entropy": -1.0, "actor_entropy": 0.34747289523245795, "alpha_loss": 0.001911220026187717, "alpha_value": 0.2490136466977624, "duration": 175.650000333786, "step": 80125}
{"episode_reward": 178.12956892778132, "episode": 642.0, "Q1 loss": 15.715136520385743, "Q2 loss": 15.612022407531738, "Mean Target Q": 233.26446313476563, "Mean Q1": 233.26301501464843, "Mean Q2": 233.2626375732422, "critic_loss": 31.327158935546876, "batch_reward": 1.6184791355133057, "actor_loss": -234.37611512214906, "actor_target_entropy": -1.0, "actor_entropy": 0.37120313942432404, "alpha_loss": -0.0102615530242122, "alpha_value": 0.24934104777552393, "duration": 182.4143192768097, "step": 80250}
{"episode_reward": 182.1891516418864, "episode": 643.0, "Q1 loss": 15.693911109924317, "Q2 loss": 15.721584312438965, "Mean Target Q": 233.09539147949218, "Mean Q1": 233.09481030273437, "Mean Q2": 233.0944559326172, "critic_loss": 31.41549540710449, "batch_reward": 1.6091329135894776, "actor_loss": -234.1327134389726, "actor_target_entropy": -1.0, "actor_entropy": 0.3588599155819605, "alpha_loss": 0.0043494625955760955, "alpha_value": 0.2494899655088684, "duration": 175.7654333114624, "step": 80375}
{"episode_reward": 40.393089963517575, "episode": 644.0, "Q1 loss": 16.000269683837892, "Q2 loss": 16.06727119445801, "Mean Target Q": 233.11605871582032, "Mean Q1": 233.1130798339844, "Mean Q2": 233.1139074707031, "critic_loss": 32.067540893554686, "batch_reward": 1.6095752172470092, "actor_loss": -234.2005644767515, "actor_target_entropy": -1.0, "actor_entropy": 0.3553013957796558, "alpha_loss": -0.013596633114972181, "alpha_value": 0.2497969782272642, "duration": 165.33992385864258, "step": 80500}
{"episode_reward": 128.278171015047, "episode": 645.0, "Q1 loss": 15.686996643066406, "Q2 loss": 15.56789747619629, "Mean Target Q": 233.33252307128907, "Mean Q1": 233.32868005371094, "Mean Q2": 233.32660522460938, "critic_loss": 31.254894134521486, "batch_reward": 1.6123542146682739, "actor_loss": -234.37083507719495, "actor_target_entropy": -1.0, "actor_entropy": 0.3864780515432358, "alpha_loss": -0.005347017424240235, "alpha_value": 0.2504721514710756, "duration": 171.92271041870117, "step": 80625}
{"episode_reward": 199.97859649088588, "episode": 646.0, "Q1 loss": 15.590020858764648, "Q2 loss": 15.523213394165039, "Mean Target Q": 233.36614819335938, "Mean Q1": 233.3620048828125, "Mean Q2": 233.36409313964845, "critic_loss": 31.11323422241211, "batch_reward": 1.6137861757278442, "actor_loss": -234.47595067178048, "actor_target_entropy": -1.0, "actor_entropy": 0.35918566728791884, "alpha_loss": -0.00097847762968271, "alpha_value": 0.2507682204051041, "duration": 171.16770434379578, "step": 80750}
{"episode_reward": 177.940783598154, "episode": 647.0, "Q1 loss": 17.170218505859374, "Q2 loss": 17.167948600769044, "Mean Target Q": 233.4631932373047, "Mean Q1": 233.46041247558594, "Mean Q2": 233.45887109375, "critic_loss": 34.33816702270508, "batch_reward": 1.617091844558716, "actor_loss": -234.52496725415426, "actor_target_entropy": -1.0, "actor_entropy": 0.3487987042892547, "alpha_loss": -0.0027306951427211366, "alpha_value": 0.2510798306490461, "duration": 189.35649013519287, "step": 80875}
{"episode_reward": 80.07557502149741, "episode": 648.0, "Q1 loss": 15.71201361846924, "Q2 loss": 15.62374983215332, "Mean Target Q": 233.48746716308594, "Mean Q1": 233.48606982421876, "Mean Q2": 233.4894326171875, "critic_loss": 31.335763412475586, "batch_reward": 1.6143397636413575, "actor_loss": -234.55857775288243, "actor_target_entropy": -1.0, "actor_entropy": 0.3778890443425025, "alpha_loss": -0.007656591497511874, "alpha_value": 0.25114033104656897, "duration": 186.3633451461792, "step": 81000}
{"episode_reward": 101.06363496315132, "episode": 649.0, "Q1 loss": 14.939730850219727, "Q2 loss": 14.940341896057129, "Mean Target Q": 233.54701635742188, "Mean Q1": 233.54719519042968, "Mean Q2": 233.54416711425782, "critic_loss": 29.88007276916504, "batch_reward": 1.6120962781906127, "actor_loss": -234.60762532552084, "actor_target_entropy": -1.0, "actor_entropy": 0.376538537324421, "alpha_loss": -0.0030844079123602975, "alpha_value": 0.25164664986120683, "duration": 181.71323490142822, "step": 81125}
{"episode_reward": 31.71467481834566, "episode": 650.0, "Q1 loss": 15.362204536437988, "Q2 loss": 15.374929145812988, "Mean Target Q": 233.6626903076172, "Mean Q1": 233.65922827148438, "Mean Q2": 233.6601774902344, "critic_loss": 30.737133529663087, "batch_reward": 1.6184850759506226, "actor_loss": -234.77440667921496, "actor_target_entropy": -1.0, "actor_entropy": 0.3614448006114652, "alpha_loss": -0.0058842040410625835, "alpha_value": 0.25215404291472265, "duration": 185.29190278053284, "step": 81250}
{"episode_reward": 18.24731494323443, "episode": 651.0, "Q1 loss": 15.43653971862793, "Q2 loss": 15.318913734436036, "Mean Target Q": 233.80308947753906, "Mean Q1": 233.80853356933594, "Mean Q2": 233.8042707519531, "critic_loss": 30.755453506469728, "batch_reward": 1.6099900703430177, "actor_loss": -234.9306124732608, "actor_target_entropy": -1.0, "actor_entropy": 0.3879192093062022, "alpha_loss": -0.0049947889610415415, "alpha_value": 0.2526865018186165, "duration": 189.8090422153473, "step": 81375}
{"episode_reward": 48.07646359286531, "episode": 652.0, "Q1 loss": 17.624287635803224, "Q2 loss": 17.64210624694824, "Mean Target Q": 233.8912081298828, "Mean Q1": 233.88093823242187, "Mean Q2": 233.88344836425782, "critic_loss": 35.26639389038086, "batch_reward": 1.6008981142044068, "actor_loss": -235.0120138352917, "actor_target_entropy": -1.0, "actor_entropy": 0.35836139513600257, "alpha_loss": -0.02703375493236367, "alpha_value": 0.25356566957435533, "duration": 182.26720190048218, "step": 81500}
{"episode_reward": 175.7246644873749, "episode": 653.0, "Q1 loss": 16.108890602111817, "Q2 loss": 16.123203819274902, "Mean Target Q": 234.16543579101562, "Mean Q1": 234.1542147216797, "Mean Q2": 234.15613110351563, "critic_loss": 32.23209436035156, "batch_reward": 1.6106487159729004, "actor_loss": -235.06099446614584, "actor_target_entropy": -1.0, "actor_entropy": 0.4056559853137486, "alpha_loss": 0.0011903870673406693, "alpha_value": 0.25474678630618086, "duration": 171.63825511932373, "step": 81625}
{"episode_reward": 143.5939100169702, "episode": 654.0, "Q1 loss": 15.063416770935058, "Q2 loss": 15.103149520874023, "Mean Target Q": 234.120263671875, "Mean Q1": 234.1301134033203, "Mean Q2": 234.12857177734375, "critic_loss": 30.1665662689209, "batch_reward": 1.6053104753494263, "actor_loss": -235.41570897256173, "actor_target_entropy": -1.0, "actor_entropy": 0.36178566227036135, "alpha_loss": -0.008847309407898254, "alpha_value": 0.25503272358165247, "duration": 171.6654269695282, "step": 81750}
{"episode_reward": 153.92280026854493, "episode": 655.0, "Q1 loss": 14.99032405090332, "Q2 loss": 14.904223419189453, "Mean Target Q": 234.18142443847657, "Mean Q1": 234.17138671875, "Mean Q2": 234.17364965820312, "critic_loss": 29.894547561645506, "batch_reward": 1.5979066152572632, "actor_loss": -235.36466204930866, "actor_target_entropy": -1.0, "actor_entropy": 0.37392387598279925, "alpha_loss": -0.002719909294567529, "alpha_value": 0.25552455310151184, "duration": 175.34141039848328, "step": 81875}
{"episode_reward": 68.02347099542061, "episode": 656.0, "Q1 loss": 15.008952522277832, "Q2 loss": 15.130157302856444, "Mean Target Q": 234.234388671875, "Mean Q1": 234.2396876220703, "Mean Q2": 234.24070080566406, "critic_loss": 30.139109954833984, "batch_reward": 1.5985469913482666, "actor_loss": -235.34700873590285, "actor_target_entropy": -1.0, "actor_entropy": 0.3388264847378577, "alpha_loss": -0.0036552477658035295, "alpha_value": 0.2558910631289028, "duration": 176.8128912448883, "step": 82000}
{"episode_reward": 94.4458518172456, "episode": 657.0, "Q1 loss": 15.073183708190918, "Q2 loss": 14.968933143615722, "Mean Target Q": 234.3790069580078, "Mean Q1": 234.37364208984374, "Mean Q2": 234.37062084960937, "critic_loss": 30.04211688232422, "batch_reward": 1.5974466381072998, "actor_loss": -235.4592030843099, "actor_target_entropy": -1.0, "actor_entropy": 0.392691175142924, "alpha_loss": -0.011262328504392552, "alpha_value": 0.2561103344937576, "duration": 182.06555914878845, "step": 82125}
{"episode_reward": 161.18992548443535, "episode": 658.0, "Q1 loss": 15.005134788513184, "Q2 loss": 14.873874626159669, "Mean Target Q": 234.37207482910156, "Mean Q1": 234.36635021972657, "Mean Q2": 234.36598474121095, "critic_loss": 29.879009506225586, "batch_reward": 1.590599588394165, "actor_loss": -235.49777517011088, "actor_target_entropy": -1.0, "actor_entropy": 0.38332381219633166, "alpha_loss": -0.010586318796530606, "alpha_value": 0.2569381398226031, "duration": 179.19921684265137, "step": 82250}
{"episode_reward": 29.83041931268833, "episode": 659.0, "Q1 loss": 14.445531913757325, "Q2 loss": 14.499673652648926, "Mean Target Q": 234.50978344726562, "Mean Q1": 234.51325537109375, "Mean Q2": 234.51370544433593, "critic_loss": 28.94520558166504, "batch_reward": 1.5908525295257567, "actor_loss": -235.71297660706534, "actor_target_entropy": -1.0, "actor_entropy": 0.36894525469295564, "alpha_loss": -0.002540523031105598, "alpha_value": 0.2575674102103054, "duration": 171.1396086215973, "step": 82375}
{"episode_reward": 167.8577950780967, "episode": 660.0, "Q1 loss": 14.431871795654297, "Q2 loss": 14.477569557189941, "Mean Target Q": 234.6562333984375, "Mean Q1": 234.6529990234375, "Mean Q2": 234.65238732910157, "critic_loss": 28.90944140625, "batch_reward": 1.5985228710174562, "actor_loss": -235.75560981996597, "actor_target_entropy": -1.0, "actor_entropy": 0.37233797052214224, "alpha_loss": -0.002486520300378963, "alpha_value": 0.25799657178511626, "duration": 168.75475764274597, "step": 82500}
{"episode_reward": 118.48761265174488, "episode": 661.0, "Q1 loss": 15.098994377136231, "Q2 loss": 14.95825242614746, "Mean Target Q": 234.5224450683594, "Mean Q1": 234.5213299560547, "Mean Q2": 234.51976586914063, "critic_loss": 30.057246673583986, "batch_reward": 1.587033203125, "actor_loss": -235.68343341161335, "actor_target_entropy": -1.0, "actor_entropy": 0.3907090515371353, "alpha_loss": 0.0036335901490279605, "alpha_value": 0.2577757438771041, "duration": 179.5136411190033, "step": 82625}
{"episode_reward": 155.03413523068323, "episode": 662.0, "Q1 loss": 15.712726448059081, "Q2 loss": 15.73852084350586, "Mean Target Q": 234.65275854492188, "Mean Q1": 234.65879833984374, "Mean Q2": 234.66344201660155, "critic_loss": 31.451247283935547, "batch_reward": 1.583318350791931, "actor_loss": -235.88320406021612, "actor_target_entropy": -1.0, "actor_entropy": 0.3732846042802257, "alpha_loss": -0.012995462000910793, "alpha_value": 0.25813269577609527, "duration": 193.68827748298645, "step": 82750}
{"episode_reward": 36.797855369213394, "episode": 663.0, "Q1 loss": 15.613295402526855, "Q2 loss": 15.561056228637696, "Mean Target Q": 234.8244560546875, "Mean Q1": 234.8166690673828, "Mean Q2": 234.81576440429689, "critic_loss": 31.174351669311523, "batch_reward": 1.591710039138794, "actor_loss": -235.9388669937376, "actor_target_entropy": -1.0, "actor_entropy": 0.37029748374507543, "alpha_loss": -0.0026061714863375067, "alpha_value": 0.25857864876194425, "duration": 177.49515795707703, "step": 82875}
{"episode_reward": 157.317626288402, "episode": 664.0, "Q1 loss": 15.293151062011718, "Q2 loss": 15.316054679870605, "Mean Target Q": 235.01564758300782, "Mean Q1": 235.01312829589844, "Mean Q2": 235.0118828125, "critic_loss": 30.609205764770508, "batch_reward": 1.6004911851882935, "actor_loss": -236.1041769212292, "actor_target_entropy": -1.0, "actor_entropy": 0.3621847627143706, "alpha_loss": -0.0008702071255914146, "alpha_value": 0.25864534818586377, "duration": 180.8746829032898, "step": 83000}
{"episode_reward": 24.46467133534152, "episode": 665.0, "Q1 loss": 15.775556396484374, "Q2 loss": 15.731706665039063, "Mean Target Q": 234.93243762207032, "Mean Q1": 234.92168579101562, "Mean Q2": 234.9228592529297, "critic_loss": 31.50726298522949, "batch_reward": 1.5865123538970947, "actor_loss": -236.1360057043651, "actor_target_entropy": -1.0, "actor_entropy": 0.40258300257107565, "alpha_loss": -0.0011899111467221426, "alpha_value": 0.2589505559105762, "duration": 191.00036931037903, "step": 83125}
{"episode_reward": 102.66188221835407, "episode": 666.0, "Q1 loss": 15.8809331741333, "Q2 loss": 15.827142890930176, "Mean Target Q": 234.99474768066406, "Mean Q1": 234.998921875, "Mean Q2": 234.99914196777343, "critic_loss": 31.70807601928711, "batch_reward": 1.5874914121627808, "actor_loss": -236.2133995794481, "actor_target_entropy": -1.0, "actor_entropy": 0.36303161973914794, "alpha_loss": 0.009486710526905353, "alpha_value": 0.25847713327287797, "duration": 179.7072970867157, "step": 83250}
{"episode_reward": 166.81852935675306, "episode": 667.0, "Q1 loss": 15.181251876831055, "Q2 loss": 15.14936952972412, "Mean Target Q": 235.03359020996095, "Mean Q1": 235.03537927246094, "Mean Q2": 235.03390856933595, "critic_loss": 30.330621490478517, "batch_reward": 1.5785177268981934, "actor_loss": -236.31690543038505, "actor_target_entropy": -1.0, "actor_entropy": 0.39196228626228513, "alpha_loss": -0.0028079141093979754, "alpha_value": 0.2581268144243694, "duration": 176.93705916404724, "step": 83375}
{"episode_reward": 175.44776237607968, "episode": 668.0, "Q1 loss": 15.88606273651123, "Q2 loss": 15.79576638031006, "Mean Target Q": 235.29211047363282, "Mean Q1": 235.2839267578125, "Mean Q2": 235.28514868164064, "critic_loss": 31.68182893371582, "batch_reward": 1.5887948513031005, "actor_loss": -236.4798350180349, "actor_target_entropy": -1.0, "actor_entropy": 0.38741460082031065, "alpha_loss": -0.013830045666245202, "alpha_value": 0.2589479439454553, "duration": 180.61757588386536, "step": 83500}
{"episode_reward": 54.29455165735506, "episode": 669.0, "Q1 loss": 15.724061920166015, "Q2 loss": 15.59022608947754, "Mean Target Q": 235.23550402832032, "Mean Q1": 235.2377244873047, "Mean Q2": 235.23733715820313, "critic_loss": 31.31428793334961, "batch_reward": 1.5883785543441773, "actor_loss": -236.54193454318576, "actor_target_entropy": -1.0, "actor_entropy": 0.3671345497880663, "alpha_loss": -0.009733856496741139, "alpha_value": 0.25960395163521677, "duration": 179.9750461578369, "step": 83625}
{"episode_reward": 142.91525920537418, "episode": 670.0, "Q1 loss": 15.81861328125, "Q2 loss": 15.907537445068359, "Mean Target Q": 235.17459741210936, "Mean Q1": 235.17309521484376, "Mean Q2": 235.17379943847655, "critic_loss": 31.726150772094726, "batch_reward": 1.5853766756057739, "actor_loss": -236.48663822297127, "actor_target_entropy": -1.0, "actor_entropy": 0.36754319071769714, "alpha_loss": -0.010774773909830518, "alpha_value": 0.2604255262179219, "duration": 194.91577458381653, "step": 83750}
{"episode_reward": 36.41455401442104, "episode": 671.0, "Q1 loss": 15.108672103881837, "Q2 loss": 15.161412055969238, "Mean Target Q": 235.33289978027344, "Mean Q1": 235.33208862304687, "Mean Q2": 235.3316025390625, "critic_loss": 30.270084091186522, "batch_reward": 1.5837609357833862, "actor_loss": -236.5738033718533, "actor_target_entropy": -1.0, "actor_entropy": 0.3548013929809843, "alpha_loss": -0.025561406744629263, "alpha_value": 0.2617185916468, "duration": 174.95124173164368, "step": 83875}
{"episode_reward": 183.2954698308385, "episode": 672.0, "Q1 loss": 15.36209979248047, "Q2 loss": 15.329526023864746, "Mean Target Q": 235.52698400878907, "Mean Q1": 235.52211853027345, "Mean Q2": 235.52299389648437, "critic_loss": 30.691625762939452, "batch_reward": 1.5798413772583009, "actor_loss": -236.92804324242377, "actor_target_entropy": -1.0, "actor_entropy": 0.3774860385925539, "alpha_loss": -0.009571778756986943, "alpha_value": 0.2632946604261036, "duration": 178.19271731376648, "step": 84000}
{"episode_reward": 44.429656203033566, "episode": 673.0, "Q1 loss": 15.875352912902832, "Q2 loss": 15.8166450881958, "Mean Target Q": 235.60222497558593, "Mean Q1": 235.59774487304688, "Mean Q2": 235.5980811767578, "critic_loss": 31.69199816894531, "batch_reward": 1.586007363319397, "actor_loss": -236.8302740672278, "actor_target_entropy": -1.0, "actor_entropy": 0.37119761677015395, "alpha_loss": -0.00642162832313232, "alpha_value": 0.26376530819103533, "duration": 178.4346423149109, "step": 84125}
{"episode_reward": 39.97926350196299, "episode": 674.0, "Q1 loss": 16.593142471313477, "Q2 loss": 16.602073013305663, "Mean Target Q": 235.5014597167969, "Mean Q1": 235.5021943359375, "Mean Q2": 235.50026306152344, "critic_loss": 33.19521542358398, "batch_reward": 1.5781093425750732, "actor_loss": -236.84006967852193, "actor_target_entropy": -1.0, "actor_entropy": 0.3691584261194352, "alpha_loss": -0.010728086461313069, "alpha_value": 0.2643011177637228, "duration": 186.70275378227234, "step": 84250}
{"episode_reward": 14.2328808929028, "episode": 675.0, "Q1 loss": 16.35144231414795, "Q2 loss": 16.301579849243165, "Mean Target Q": 235.8326328125, "Mean Q1": 235.83205822753905, "Mean Q2": 235.8308796386719, "critic_loss": 32.65302209472656, "batch_reward": 1.591683632850647, "actor_loss": -237.01500326489645, "actor_target_entropy": -1.0, "actor_entropy": 0.38053792336630443, "alpha_loss": -0.009948347310816485, "alpha_value": 0.2648443830510469, "duration": 172.85807347297668, "step": 84375}
{"episode_reward": 42.801679898781494, "episode": 676.0, "Q1 loss": 15.893060165405274, "Q2 loss": 15.834070152282715, "Mean Target Q": 235.70112048339843, "Mean Q1": 235.69757446289063, "Mean Q2": 235.70108447265625, "critic_loss": 31.727130233764647, "batch_reward": 1.5814425582885743, "actor_loss": -236.95083765829764, "actor_target_entropy": -1.0, "actor_entropy": 0.394883812675553, "alpha_loss": -0.015397807102530234, "alpha_value": 0.26571346424767894, "duration": 185.88503313064575, "step": 84500}
{"episode_reward": 48.75304303025105, "episode": 677.0, "Q1 loss": 15.778734352111817, "Q2 loss": 15.761592758178711, "Mean Target Q": 235.78922631835937, "Mean Q1": 235.78570092773438, "Mean Q2": 235.7840234375, "critic_loss": 31.540327041625975, "batch_reward": 1.5636698169708252, "actor_loss": -237.0242178780692, "actor_target_entropy": -1.0, "actor_entropy": 0.35486213650022236, "alpha_loss": -0.014729007381931065, "alpha_value": 0.26722084492752385, "duration": 163.88512015342712, "step": 84625}
{"episode_reward": 177.67506083948777, "episode": 678.0, "Q1 loss": 15.43371826171875, "Q2 loss": 15.46873146057129, "Mean Target Q": 235.95612548828126, "Mean Q1": 235.95394128417968, "Mean Q2": 235.95174597167968, "critic_loss": 30.90244984436035, "batch_reward": 1.5703597259521485, "actor_loss": -237.1945320867723, "actor_target_entropy": -1.0, "actor_entropy": 0.3754545680938228, "alpha_loss": -0.00974718657051844, "alpha_value": 0.2677095355600859, "duration": 186.16463160514832, "step": 84750}
{"episode_reward": 69.72870147585381, "episode": 679.0, "Q1 loss": 16.10200117492676, "Q2 loss": 16.06577970123291, "Mean Target Q": 235.90233654785158, "Mean Q1": 235.90351208496094, "Mean Q2": 235.9024792480469, "critic_loss": 32.16778080749512, "batch_reward": 1.5548422584533692, "actor_loss": -237.25455995589968, "actor_target_entropy": -1.0, "actor_entropy": 0.397005326691128, "alpha_loss": -0.012015793539051498, "alpha_value": 0.26874659751971597, "duration": 182.12458276748657, "step": 84875}
{"episode_reward": 39.41463291886227, "episode": 680.0, "Q1 loss": 16.27954007720947, "Q2 loss": 16.170331382751463, "Mean Target Q": 236.03310571289063, "Mean Q1": 236.03288842773438, "Mean Q2": 236.03460485839844, "critic_loss": 32.449871383666995, "batch_reward": 1.561278962135315, "actor_loss": -237.30148536928237, "actor_target_entropy": -1.0, "actor_entropy": 0.39394572905955777, "alpha_loss": -0.011032604503505412, "alpha_value": 0.26927622603823004, "step": 85000}
{"duration": 184.32517051696777, "step": 85000}
{"episode_reward": 10.159158225145346, "episode": 681.0, "Q1 loss": 15.708539115905761, "Q2 loss": 15.606943840026856, "Mean Target Q": 236.23307690429687, "Mean Q1": 236.2323251953125, "Mean Q2": 236.2314775390625, "critic_loss": 31.315483016967775, "batch_reward": 1.568682026863098, "actor_loss": -237.55634465293278, "actor_target_entropy": -1.0, "actor_entropy": 0.37748986056872774, "alpha_loss": -0.01413137166731296, "alpha_value": 0.27045660262545207, "duration": 181.54767632484436, "step": 85125}
{"episode_reward": 148.9178047578347, "episode": 682.0, "Q1 loss": 16.176304908752442, "Q2 loss": 16.189743743896486, "Mean Target Q": 236.3347852783203, "Mean Q1": 236.32921752929687, "Mean Q2": 236.33128771972656, "critic_loss": 32.366048660278324, "batch_reward": 1.5739277963638305, "actor_loss": -237.61533798709993, "actor_target_entropy": -1.0, "actor_entropy": 0.381072360661722, "alpha_loss": -0.021349156699744205, "alpha_value": 0.2715802964318614, "duration": 190.03145694732666, "step": 85250}
{"episode_reward": 134.36927669478752, "episode": 683.0, "Q1 loss": 15.543793197631835, "Q2 loss": 15.474672966003418, "Mean Target Q": 236.46812634277345, "Mean Q1": 236.4627762451172, "Mean Q2": 236.46374621582032, "critic_loss": 31.018466262817384, "batch_reward": 1.5645341243743895, "actor_loss": -237.60696265811012, "actor_target_entropy": -1.0, "actor_entropy": 0.3813808560371399, "alpha_loss": -0.034986276963045675, "alpha_value": 0.27348546850004013, "duration": 169.25641012191772, "step": 85375}
{"episode_reward": 11.112739147001976, "episode": 684.0, "Q1 loss": 15.610358558654784, "Q2 loss": 15.610547340393067, "Mean Target Q": 236.40054064941407, "Mean Q1": 236.4041561279297, "Mean Q2": 236.40297485351562, "critic_loss": 31.220905975341797, "batch_reward": 1.5664983901977538, "actor_loss": -237.62225489462577, "actor_target_entropy": -1.0, "actor_entropy": 0.4174142513544329, "alpha_loss": -0.012044536073752228, "alpha_value": 0.2749621191080018, "duration": 169.53846669197083, "step": 85500}
{"episode_reward": 108.8755657465826, "episode": 685.0, "Q1 loss": 15.058193672180176, "Q2 loss": 15.156801864624024, "Mean Target Q": 236.54052868652343, "Mean Q1": 236.5282830810547, "Mean Q2": 236.52768395996094, "critic_loss": 30.214995407104492, "batch_reward": 1.56271457195282, "actor_loss": -237.7373315720331, "actor_target_entropy": -1.0, "actor_entropy": 0.4021959193642177, "alpha_loss": -0.01620871433618641, "alpha_value": 0.27583256232318554, "duration": 195.01348996162415, "step": 85625}
{"episode_reward": 182.86671455790267, "episode": 686.0, "Q1 loss": 15.91484203338623, "Q2 loss": 15.913170028686524, "Mean Target Q": 236.76566845703124, "Mean Q1": 236.77491052246094, "Mean Q2": 236.775599609375, "critic_loss": 31.828012252807618, "batch_reward": 1.573128791809082, "actor_loss": -238.11344294394218, "actor_target_entropy": -1.0, "actor_entropy": 0.4056750093736956, "alpha_loss": -0.010368491218785846, "alpha_value": 0.2767708044174953, "duration": 184.356183052063, "step": 85750}
{"episode_reward": 43.039572903008875, "episode": 687.0, "Q1 loss": 16.183127815246582, "Q2 loss": 16.146950508117676, "Mean Target Q": 236.76887377929688, "Mean Q1": 236.75825109863283, "Mean Q2": 236.75845935058595, "critic_loss": 32.33007843017578, "batch_reward": 1.5560355548858642, "actor_loss": -237.99014790852866, "actor_target_entropy": -1.0, "actor_entropy": 0.4140590840861911, "alpha_loss": -0.007299181753917346, "alpha_value": 0.2773855370018149, "duration": 179.12826371192932, "step": 85875}
{"episode_reward": 179.43560229464637, "episode": 688.0, "Q1 loss": 15.817657402038574, "Q2 loss": 15.903922470092773, "Mean Target Q": 236.8448409423828, "Mean Q1": 236.84600366210938, "Mean Q2": 236.84735400390625, "critic_loss": 31.721579727172852, "batch_reward": 1.5665103778839111, "actor_loss": -238.0369166712607, "actor_target_entropy": -1.0, "actor_entropy": 0.42466968057617066, "alpha_loss": -0.0018880180939431152, "alpha_value": 0.27783323490945616, "duration": 191.52181959152222, "step": 86000}
{"episode_reward": 52.58926828800494, "episode": 689.0, "Q1 loss": 15.847258850097656, "Q2 loss": 15.748146713256835, "Mean Target Q": 236.96845568847655, "Mean Q1": 236.9608916015625, "Mean Q2": 236.960431640625, "critic_loss": 31.59540557861328, "batch_reward": 1.566091209411621, "actor_loss": -238.37283809601314, "actor_target_entropy": -1.0, "actor_entropy": 0.3704374096696339, "alpha_loss": -0.014338986201596165, "alpha_value": 0.2780444593207522, "duration": 177.3359832763672, "step": 86125}
{"episode_reward": 137.51213114358157, "episode": 690.0, "Q1 loss": 15.855424690246583, "Q2 loss": 15.81540089416504, "Mean Target Q": 237.20010900878907, "Mean Q1": 237.2117872314453, "Mean Q2": 237.21219763183595, "critic_loss": 31.67082554626465, "batch_reward": 1.547887942314148, "actor_loss": -238.39387389152282, "actor_target_entropy": -1.0, "actor_entropy": 0.4110762885501308, "alpha_loss": 0.0012511120688530706, "alpha_value": 0.27893810030791516, "duration": 179.9699993133545, "step": 86250}
{"episode_reward": 155.6925357286922, "episode": 691.0, "Q1 loss": 16.17426802062988, "Q2 loss": 16.190083580017088, "Mean Target Q": 237.22772216796875, "Mean Q1": 237.223125, "Mean Q2": 237.2197238769531, "critic_loss": 32.364351669311525, "batch_reward": 1.5597907848358155, "actor_loss": -238.44643268887958, "actor_target_entropy": -1.0, "actor_entropy": 0.4038799882881225, "alpha_loss": 0.004340165581125471, "alpha_value": 0.27839609575402785, "duration": 184.3630177974701, "step": 86375}
{"episode_reward": 55.99159077717355, "episode": 692.0, "Q1 loss": 15.424724555969238, "Q2 loss": 15.376120002746582, "Mean Target Q": 237.27635546875, "Mean Q1": 237.26762536621095, "Mean Q2": 237.27036010742188, "critic_loss": 30.800844619750976, "batch_reward": 1.5630534629821777, "actor_loss": -238.4651122554656, "actor_target_entropy": -1.0, "actor_entropy": 0.421787973373167, "alpha_loss": 0.0022988343431103613, "alpha_value": 0.2782786993660433, "duration": 172.9011092185974, "step": 86500}
{"episode_reward": 58.49508529837834, "episode": 693.0, "Q1 loss": 14.929727439880372, "Q2 loss": 14.909037094116211, "Mean Target Q": 237.39149206542967, "Mean Q1": 237.38914453125, "Mean Q2": 237.3889903564453, "critic_loss": 29.838764450073242, "batch_reward": 1.546413393974304, "actor_loss": -238.66744002084883, "actor_target_entropy": -1.0, "actor_entropy": 0.4085790964346083, "alpha_loss": 0.00031916815639724806, "alpha_value": 0.2781225366890995, "duration": 168.83301711082458, "step": 86625}
{"episode_reward": 59.09301166745679, "episode": 694.0, "Q1 loss": 15.097611221313477, "Q2 loss": 14.979830680847169, "Mean Target Q": 237.47604089355468, "Mean Q1": 237.47340759277344, "Mean Q2": 237.4743330078125, "critic_loss": 30.07744190979004, "batch_reward": 1.5486940307617187, "actor_loss": -238.70160428939326, "actor_target_entropy": -1.0, "actor_entropy": 0.40461245275312857, "alpha_loss": -0.011897660746809936, "alpha_value": 0.2786216807878428, "duration": 177.06366229057312, "step": 86750}
{"episode_reward": 174.88074574203895, "episode": 695.0, "Q1 loss": 15.261025665283203, "Q2 loss": 15.267021560668946, "Mean Target Q": 237.5205732421875, "Mean Q1": 237.51715161132813, "Mean Q2": 237.51392797851562, "critic_loss": 30.52804721069336, "batch_reward": 1.550406177520752, "actor_loss": -238.80057077559215, "actor_target_entropy": -1.0, "actor_entropy": 0.40465085799731904, "alpha_loss": -0.017875893747374888, "alpha_value": 0.2792769978182741, "duration": 180.1362931728363, "step": 86875}
{"episode_reward": 116.69799185076974, "episode": 696.0, "Q1 loss": 15.230782638549805, "Q2 loss": 15.235023963928223, "Mean Target Q": 237.34726794433593, "Mean Q1": 237.3466817626953, "Mean Q2": 237.34937158203124, "critic_loss": 30.465806564331054, "batch_reward": 1.5458939838409425, "actor_loss": -238.754033488612, "actor_target_entropy": -1.0, "actor_entropy": 0.39498353965820804, "alpha_loss": -0.007714275067912475, "alpha_value": 0.28050281706209534, "duration": 166.82339668273926, "step": 87000}
{"episode_reward": 163.41019812246643, "episode": 697.0, "Q1 loss": 15.845385215759277, "Q2 loss": 15.865643478393554, "Mean Target Q": 237.53764916992188, "Mean Q1": 237.5388292236328, "Mean Q2": 237.53777856445313, "critic_loss": 31.71102876281738, "batch_reward": 1.5565410776138306, "actor_loss": -238.67512052021328, "actor_target_entropy": -1.0, "actor_entropy": 0.4193069201613229, "alpha_loss": -0.002709142224390119, "alpha_value": 0.2808202258264955, "duration": 175.01733303070068, "step": 87125}
{"episode_reward": 41.656095923921534, "episode": 698.0, "Q1 loss": 15.334931274414062, "Q2 loss": 15.249822128295898, "Mean Target Q": 237.66935803222657, "Mean Q1": 237.6689324951172, "Mean Q2": 237.6675810546875, "critic_loss": 30.58475340270996, "batch_reward": 1.5477380704879762, "actor_loss": -238.8190445438508, "actor_target_entropy": -1.0, "actor_entropy": 0.4031972000675817, "alpha_loss": -0.007409333825982627, "alpha_value": 0.2812691230298875, "duration": 156.83025455474854, "step": 87250}
{"episode_reward": 41.65844955309194, "episode": 699.0, "Q1 loss": 16.089254608154295, "Q2 loss": 16.04664492034912, "Mean Target Q": 237.5690867919922, "Mean Q1": 237.56043103027343, "Mean Q2": 237.5607266845703, "critic_loss": 32.135899490356444, "batch_reward": 1.5594754543304443, "actor_loss": -238.83300708589098, "actor_target_entropy": -1.0, "actor_entropy": 0.3489289203333476, "alpha_loss": -0.006183610094474658, "alpha_value": 0.2814075643166658, "duration": 154.89649271965027, "step": 87375}
{"episode_reward": 162.80097513363066, "episode": 700.0, "Q1 loss": 15.876980621337891, "Q2 loss": 15.86315673828125, "Mean Target Q": 237.74997241210937, "Mean Q1": 237.75381481933593, "Mean Q2": 237.7522188720703, "critic_loss": 31.740137268066405, "batch_reward": 1.5457700567245483, "actor_loss": -238.98412273776145, "actor_target_entropy": -1.0, "actor_entropy": 0.40775273740291595, "alpha_loss": -0.012501687333438425, "alpha_value": 0.2821304910497273, "duration": 163.51116633415222, "step": 87500}
{"episode_reward": 30.08952707393522, "episode": 701.0, "Q1 loss": 15.869072845458984, "Q2 loss": 15.913258209228516, "Mean Target Q": 237.85132727050782, "Mean Q1": 237.84739282226562, "Mean Q2": 237.8471600341797, "critic_loss": 31.78233090209961, "batch_reward": 1.5385626010894775, "actor_loss": -239.20426311190167, "actor_target_entropy": -1.0, "actor_entropy": 0.41818905113235355, "alpha_loss": -0.024756739411266552, "alpha_value": 0.2835286270256037, "duration": 155.90502452850342, "step": 87625}
{"episode_reward": 88.52267611345783, "episode": 702.0, "Q1 loss": 15.420663299560546, "Q2 loss": 15.458652809143066, "Mean Target Q": 238.05241564941406, "Mean Q1": 238.05656884765625, "Mean Q2": 238.0577060546875, "critic_loss": 30.87931607055664, "batch_reward": 1.550340973854065, "actor_loss": -239.24588160361014, "actor_target_entropy": -1.0, "actor_entropy": 0.40642249824539306, "alpha_loss": -0.009189997514289233, "alpha_value": 0.2846643749264332, "duration": 162.09751772880554, "step": 87750}
{"episode_reward": 45.172334186803965, "episode": 703.0, "Q1 loss": 16.200587699890136, "Q2 loss": 16.17653009033203, "Mean Target Q": 238.2191260986328, "Mean Q1": 238.2075428466797, "Mean Q2": 238.20757385253907, "critic_loss": 32.37711784362793, "batch_reward": 1.5368053312301635, "actor_loss": -239.4934791686043, "actor_target_entropy": -1.0, "actor_entropy": 0.43061254563785734, "alpha_loss": -0.012248878352462298, "alpha_value": 0.2854452236234854, "duration": 161.79088687896729, "step": 87875}
{"episode_reward": 163.7537103951764, "episode": 704.0, "Q1 loss": 15.576426559448242, "Q2 loss": 15.592421630859375, "Mean Target Q": 238.0681018066406, "Mean Q1": 238.06433471679688, "Mean Q2": 238.06446166992188, "critic_loss": 31.168848159790038, "batch_reward": 1.5322270021438598, "actor_loss": -239.34463968584615, "actor_target_entropy": -1.0, "actor_entropy": 0.43279396622411664, "alpha_loss": -0.0027072610213391243, "alpha_value": 0.285825543126395, "duration": 151.715758562088, "step": 88000}
{"episode_reward": 72.82758380925613, "episode": 705.0, "Q1 loss": 15.543482032775879, "Q2 loss": 15.502199760437012, "Mean Target Q": 238.2107080078125, "Mean Q1": 238.21925463867188, "Mean Q2": 238.22085131835937, "critic_loss": 31.04568182373047, "batch_reward": 1.5422675895690918, "actor_loss": -239.49343968951513, "actor_target_entropy": -1.0, "actor_entropy": 0.443762542236419, "alpha_loss": -0.004306113406542748, "alpha_value": 0.28633077390344736, "duration": 155.59502935409546, "step": 88125}
{"episode_reward": 11.379291691268392, "episode": 706.0, "Q1 loss": 15.834034309387206, "Q2 loss": 15.73435506439209, "Mean Target Q": 238.13105810546875, "Mean Q1": 238.12223352050782, "Mean Q2": 238.1212879638672, "critic_loss": 31.568389465332032, "batch_reward": 1.5349453887939453, "actor_loss": -239.5401146181168, "actor_target_entropy": -1.0, "actor_entropy": 0.44820285564468754, "alpha_loss": -0.0029852676633445006, "alpha_value": 0.28646396039510136, "duration": 155.54659223556519, "step": 88250}
{"episode_reward": 43.98855658398024, "episode": 707.0, "Q1 loss": 17.5200396194458, "Q2 loss": 17.59231386566162, "Mean Target Q": 238.4458848876953, "Mean Q1": 238.44370324707032, "Mean Q2": 238.4450889892578, "critic_loss": 35.11235342407227, "batch_reward": 1.5459525957107545, "actor_loss": -239.67925855848523, "actor_target_entropy": -1.0, "actor_entropy": 0.44395173542083255, "alpha_loss": -0.004919369985896443, "alpha_value": 0.28693362264487793, "duration": 153.09993886947632, "step": 88375}
{"episode_reward": 73.43258774141164, "episode": 708.0, "Q1 loss": 15.487824234008789, "Q2 loss": 15.427808334350585, "Mean Target Q": 238.52229467773438, "Mean Q1": 238.52133056640625, "Mean Q2": 238.52036779785155, "critic_loss": 30.91563264465332, "batch_reward": 1.5336410398483276, "actor_loss": -239.6689699234501, "actor_target_entropy": -1.0, "actor_entropy": 0.4268620845771605, "alpha_loss": -0.0016210767019900583, "alpha_value": 0.2868844475415041, "duration": 159.398752450943, "step": 88500}
{"episode_reward": 46.47536100682556, "episode": 709.0, "Q1 loss": 15.295264930725098, "Q2 loss": 15.195932426452636, "Mean Target Q": 238.36587377929686, "Mean Q1": 238.36370849609375, "Mean Q2": 238.3645419921875, "critic_loss": 30.491197387695312, "batch_reward": 1.5223811674118042, "actor_loss": -239.62320890880767, "actor_target_entropy": -1.0, "actor_entropy": 0.4377021638173906, "alpha_loss": -0.01048177839552481, "alpha_value": 0.2872756968368061, "duration": 154.0715343952179, "step": 88625}
{"episode_reward": 53.54981617725711, "episode": 710.0, "Q1 loss": 15.649644989013671, "Q2 loss": 15.620101219177245, "Mean Target Q": 238.5948465576172, "Mean Q1": 238.5985266113281, "Mean Q2": 238.59614428710938, "critic_loss": 31.26974626159668, "batch_reward": 1.5293765439987184, "actor_loss": -240.00370591686618, "actor_target_entropy": -1.0, "actor_entropy": 0.4026642071623956, "alpha_loss": 0.0008218706390189548, "alpha_value": 0.2877673929970037, "duration": 156.61162614822388, "step": 88750}
{"episode_reward": 184.79175233599872, "episode": 711.0, "Q1 loss": 15.314531127929687, "Q2 loss": 15.368986831665039, "Mean Target Q": 238.71659240722656, "Mean Q1": 238.7102178955078, "Mean Q2": 238.71104321289062, "critic_loss": 30.683517974853515, "batch_reward": 1.5421560850143432, "actor_loss": -240.01648118760852, "actor_target_entropy": -1.0, "actor_entropy": 0.4275894642822326, "alpha_loss": -0.004947611481867849, "alpha_value": 0.28779284996981314, "duration": 155.81227254867554, "step": 88875}
{"episode_reward": 24.827330854443534, "episode": 712.0, "Q1 loss": 15.285073852539062, "Q2 loss": 15.307670341491699, "Mean Target Q": 238.9161727294922, "Mean Q1": 238.9099969482422, "Mean Q2": 238.91107360839842, "critic_loss": 30.592744064331054, "batch_reward": 1.5347570390701295, "actor_loss": -240.28006473664314, "actor_target_entropy": -1.0, "actor_entropy": 0.433708613437991, "alpha_loss": -0.010752755129003836, "alpha_value": 0.28842490398605175, "duration": 163.13108897209167, "step": 89000}
{"episode_reward": 48.3867339015061, "episode": 713.0, "Q1 loss": 15.058431892395019, "Q2 loss": 15.05066000366211, "Mean Target Q": 238.78102209472655, "Mean Q1": 238.78581481933594, "Mean Q2": 238.78551586914062, "critic_loss": 30.109091873168946, "batch_reward": 1.5265871114730836, "actor_loss": -240.1144830612909, "actor_target_entropy": -1.0, "actor_entropy": 0.4321985798222678, "alpha_loss": -0.009704277943080616, "alpha_value": 0.28932068368650515, "duration": 149.5409915447235, "step": 89125}
{"episode_reward": 176.6191077104651, "episode": 714.0, "Q1 loss": 15.605724090576173, "Q2 loss": 15.563633010864258, "Mean Target Q": 239.0945509033203, "Mean Q1": 239.0901755371094, "Mean Q2": 239.08940625, "critic_loss": 31.169357208251952, "batch_reward": 1.536278757095337, "actor_loss": -240.46055652249245, "actor_target_entropy": -1.0, "actor_entropy": 0.40957816810377184, "alpha_loss": -0.006060379516002873, "alpha_value": 0.28975939355370983, "duration": 133.5712022781372, "step": 89250}
{"episode_reward": 136.3539266105191, "episode": 715.0, "Q1 loss": 16.408978073120117, "Q2 loss": 16.251962310791015, "Mean Target Q": 239.10968969726562, "Mean Q1": 239.11305004882811, "Mean Q2": 239.11060546875, "critic_loss": 32.66094044494629, "batch_reward": 1.5318047037124634, "actor_loss": -240.6075236002604, "actor_target_entropy": -1.0, "actor_entropy": 0.4297644079677642, "alpha_loss": -0.01761348085064027, "alpha_value": 0.2907589638640669, "duration": 155.99328780174255, "step": 89375}
{"episode_reward": 73.12125779636816, "episode": 716.0, "Q1 loss": 15.742313301086426, "Q2 loss": 15.74328158569336, "Mean Target Q": 239.33676049804689, "Mean Q1": 239.33550134277343, "Mean Q2": 239.33652099609375, "critic_loss": 31.485594924926758, "batch_reward": 1.5293997287750245, "actor_loss": -240.64079210835118, "actor_target_entropy": -1.0, "actor_entropy": 0.43007188602801294, "alpha_loss": -0.009158985728713414, "alpha_value": 0.29153893690860605, "duration": 153.30762910842896, "step": 89500}
{"episode_reward": 187.92999598691125, "episode": 717.0, "Q1 loss": 15.624885437011718, "Q2 loss": 15.570235877990722, "Mean Target Q": 239.45481298828125, "Mean Q1": 239.44584460449218, "Mean Q2": 239.44803161621093, "critic_loss": 31.19512127685547, "batch_reward": 1.5306722221374511, "actor_loss": -240.77294364808097, "actor_target_entropy": -1.0, "actor_entropy": 0.42293986015849644, "alpha_loss": -0.0013493514538461726, "alpha_value": 0.2918962236563866, "duration": 155.32967329025269, "step": 89625}
{"episode_reward": 191.64708217987533, "episode": 718.0, "Q1 loss": 16.057613807678223, "Q2 loss": 16.017228973388672, "Mean Target Q": 239.27201245117186, "Mean Q1": 239.2730871582031, "Mean Q2": 239.27065734863282, "critic_loss": 32.074842895507814, "batch_reward": 1.520286114692688, "actor_loss": -240.63658609697896, "actor_target_entropy": -1.0, "actor_entropy": 0.4523833591130472, "alpha_loss": -0.005692697700954253, "alpha_value": 0.2922995707915267, "duration": 154.95974397659302, "step": 89750}
{"episode_reward": 188.96966864842116, "episode": 719.0, "Q1 loss": 16.128705200195313, "Q2 loss": 16.06696496582031, "Mean Target Q": 239.55795068359376, "Mean Q1": 239.55571899414062, "Mean Q2": 239.5567822265625, "critic_loss": 32.19567022705078, "batch_reward": 1.5223721284866334, "actor_loss": -240.85453142438615, "actor_target_entropy": -1.0, "actor_entropy": 0.46840099304441424, "alpha_loss": -0.002229715176370172, "alpha_value": 0.29250425976561656, "duration": 161.28043031692505, "step": 89875}
{"episode_reward": 230.11318256781465, "episode": 720.0, "Q1 loss": 15.960172416687012, "Q2 loss": 15.933933326721192, "Mean Target Q": 239.72406420898437, "Mean Q1": 239.72310327148438, "Mean Q2": 239.72343627929686, "critic_loss": 31.894105728149412, "batch_reward": 1.533205973625183, "actor_loss": -240.90269051828693, "actor_target_entropy": -1.0, "actor_entropy": 0.4430459646448012, "alpha_loss": -0.004484779531917264, "alpha_value": 0.2929453584163813, "step": 90000}
{"duration": 169.25296330451965, "step": 90000}
{"episode_reward": 75.86259633341446, "episode": 721.0, "Q1 loss": 16.18625475311279, "Q2 loss": 16.170826416015625, "Mean Target Q": 239.66849536132813, "Mean Q1": 239.67164794921874, "Mean Q2": 239.66946936035157, "critic_loss": 32.35708114624023, "batch_reward": 1.5266961889266968, "actor_loss": -240.9664028107174, "actor_target_entropy": -1.0, "actor_entropy": 0.4567005156524598, "alpha_loss": -5.3646556648706636e-05, "alpha_value": 0.2930992515186921, "duration": 150.00695371627808, "step": 90125}
{"episode_reward": 184.54812548347684, "episode": 722.0, "Q1 loss": 15.972664978027344, "Q2 loss": 15.859849906921387, "Mean Target Q": 239.83148901367187, "Mean Q1": 239.82172351074217, "Mean Q2": 239.8246483154297, "critic_loss": 31.832514846801757, "batch_reward": 1.5250063552856445, "actor_loss": -241.15108293102634, "actor_target_entropy": -1.0, "actor_entropy": 0.4552377539296304, "alpha_loss": 0.004914714109843537, "alpha_value": 0.292945814938283, "duration": 157.54707145690918, "step": 90250}
{"episode_reward": 102.9493502280905, "episode": 723.0, "Q1 loss": 16.54797050476074, "Q2 loss": 16.55736450958252, "Mean Target Q": 239.74848352050782, "Mean Q1": 239.74759899902344, "Mean Q2": 239.74544140625, "critic_loss": 33.10533505249023, "batch_reward": 1.5214305639266967, "actor_loss": -241.0454351031591, "actor_target_entropy": -1.0, "actor_entropy": 0.45457822226342703, "alpha_loss": -0.0018681681452555553, "alpha_value": 0.29274574143156246, "duration": 149.86527252197266, "step": 90375}
{"episode_reward": 187.6717033821242, "episode": 724.0, "Q1 loss": 16.41751103973389, "Q2 loss": 16.472499839782714, "Mean Target Q": 239.77304138183592, "Mean Q1": 239.76719580078125, "Mean Q2": 239.7689285888672, "critic_loss": 32.89001075744629, "batch_reward": 1.5302294578552247, "actor_loss": -241.21939283801663, "actor_target_entropy": -1.0, "actor_entropy": 0.4090657190930459, "alpha_loss": -0.012584002910091752, "alpha_value": 0.2931632245920715, "duration": 152.16724824905396, "step": 90500}
{"episode_reward": 153.23472408355136, "episode": 725.0, "Q1 loss": 16.37132873535156, "Q2 loss": 16.417194931030274, "Mean Target Q": 239.7237264404297, "Mean Q1": 239.72562854003905, "Mean Q2": 239.7230438232422, "critic_loss": 32.78852374267578, "batch_reward": 1.514590735435486, "actor_loss": -241.02178591773622, "actor_target_entropy": -1.0, "actor_entropy": 0.4300605948009188, "alpha_loss": -0.015958427436768063, "alpha_value": 0.29442596675756566, "duration": 145.16591906547546, "step": 90625}
{"episode_reward": 64.99527700845184, "episode": 726.0, "Q1 loss": 16.05934378051758, "Q2 loss": 16.157023849487306, "Mean Target Q": 240.0115048828125, "Mean Q1": 240.0079462890625, "Mean Q2": 240.0081317138672, "critic_loss": 32.21636767578125, "batch_reward": 1.5322766075134278, "actor_loss": -241.3038111040669, "actor_target_entropy": -1.0, "actor_entropy": 0.4339580103274315, "alpha_loss": -0.010712625124611921, "alpha_value": 0.2950878853840192, "duration": 151.29724073410034, "step": 90750}
{"episode_reward": 98.94623148603634, "episode": 727.0, "Q1 loss": 16.56487863922119, "Q2 loss": 16.538585090637206, "Mean Target Q": 240.00131982421874, "Mean Q1": 240.0056328125, "Mean Q2": 240.00536584472655, "critic_loss": 33.10346374511719, "batch_reward": 1.5092916269302368, "actor_loss": -241.33868432423426, "actor_target_entropy": -1.0, "actor_entropy": 0.44232891949396286, "alpha_loss": -3.319217764314205e-05, "alpha_value": 0.29565578979743345, "duration": 151.40703654289246, "step": 90875}
{"episode_reward": 103.93507012308969, "episode": 728.0, "Q1 loss": 16.21339668273926, "Q2 loss": 16.24219831085205, "Mean Target Q": 240.24012268066406, "Mean Q1": 240.23236462402343, "Mean Q2": 240.23397900390626, "critic_loss": 32.455594970703125, "batch_reward": 1.5274410104751588, "actor_loss": -241.5097139420048, "actor_target_entropy": -1.0, "actor_entropy": 0.44389363738798326, "alpha_loss": -0.0090032969676559, "alpha_value": 0.2960621318963141, "duration": 154.55029582977295, "step": 91000}
{"episode_reward": 32.915330891074184, "episode": 729.0, "Q1 loss": 16.13211614227295, "Q2 loss": 16.179878509521483, "Mean Target Q": 240.08175, "Mean Q1": 240.07674194335937, "Mean Q2": 240.07384375, "critic_loss": 32.31199452209473, "batch_reward": 1.5125044984817504, "actor_loss": -241.56729077535962, "actor_target_entropy": -1.0, "actor_entropy": 0.4551485970852867, "alpha_loss": -0.009606783950908316, "alpha_value": 0.2967378142796845, "duration": 156.0003695487976, "step": 91125}
{"episode_reward": 170.23062097581462, "episode": 730.0, "Q1 loss": 17.171976341247557, "Q2 loss": 17.2051138381958, "Mean Target Q": 240.2613759765625, "Mean Q1": 240.26521948242188, "Mean Q2": 240.26797399902344, "critic_loss": 34.37709027099609, "batch_reward": 1.5222322750091553, "actor_loss": -241.72343297158517, "actor_target_entropy": -1.0, "actor_entropy": 0.4482094491681745, "alpha_loss": 0.007472282831346796, "alpha_value": 0.29690580041754067, "duration": 155.7833113670349, "step": 91250}
{"episode_reward": 27.423980597437307, "episode": 731.0, "Q1 loss": 16.656683052062988, "Q2 loss": 16.569996810913086, "Mean Target Q": 240.30913061523438, "Mean Q1": 240.30826892089843, "Mean Q2": 240.30573669433593, "critic_loss": 33.22667990112305, "batch_reward": 1.5182976894378661, "actor_loss": -241.73731873527404, "actor_target_entropy": -1.0, "actor_entropy": 0.4301781550286308, "alpha_loss": -0.007907041481563024, "alpha_value": 0.29673076970835666, "duration": 149.37233591079712, "step": 91375}
{"episode_reward": 136.3438835945053, "episode": 732.0, "Q1 loss": 16.224191772460937, "Q2 loss": 16.09324250793457, "Mean Target Q": 240.52467517089843, "Mean Q1": 240.51677673339844, "Mean Q2": 240.51878161621093, "critic_loss": 32.31743441772461, "batch_reward": 1.518428734779358, "actor_loss": -241.9092254638672, "actor_target_entropy": -1.0, "actor_entropy": 0.43484838643381674, "alpha_loss": -0.023034028633828123, "alpha_value": 0.29796520050706343, "duration": 154.3206126689911, "step": 91500}
{"episode_reward": 152.90383146927863, "episode": 733.0, "Q1 loss": 16.60249200439453, "Q2 loss": 16.578550582885743, "Mean Target Q": 240.6472725830078, "Mean Q1": 240.6445147705078, "Mean Q2": 240.64430126953124, "critic_loss": 33.181042419433595, "batch_reward": 1.5190647249221803, "actor_loss": -242.00841413225447, "actor_target_entropy": -1.0, "actor_entropy": 0.4451032744513618, "alpha_loss": -0.00020313979170861698, "alpha_value": 0.29895027018497466, "duration": 152.69092750549316, "step": 91625}
{"episode_reward": 65.02544137450302, "episode": 734.0, "Q1 loss": 17.088391059875487, "Q2 loss": 16.94651273345947, "Mean Target Q": 240.7927781982422, "Mean Q1": 240.79176635742186, "Mean Q2": 240.79319384765626, "critic_loss": 34.034903869628906, "batch_reward": 1.5255091161727905, "actor_loss": -242.04129446706463, "actor_target_entropy": -1.0, "actor_entropy": 0.4353423008034306, "alpha_loss": -0.00875789292096611, "alpha_value": 0.2986936926862154, "duration": 160.88751888275146, "step": 91750}
{"episode_reward": 55.71438540729879, "episode": 735.0, "Q1 loss": 16.735113441467284, "Q2 loss": 16.861645362854002, "Mean Target Q": 240.89063122558593, "Mean Q1": 240.8941599121094, "Mean Q2": 240.89234130859376, "critic_loss": 33.596758728027346, "batch_reward": 1.523787525177002, "actor_loss": -242.25008719308036, "actor_target_entropy": -1.0, "actor_entropy": 0.4358960101528773, "alpha_loss": -0.016896790695480175, "alpha_value": 0.29999656610235514, "duration": 155.46523094177246, "step": 91875}
{"episode_reward": 25.920428421813508, "episode": 736.0, "Q1 loss": 17.116278549194337, "Q2 loss": 17.08629349517822, "Mean Target Q": 240.99042626953124, "Mean Q1": 240.9797841796875, "Mean Q2": 240.980474609375, "critic_loss": 34.20257203674316, "batch_reward": 1.5153909044265748, "actor_loss": -242.4412632603799, "actor_target_entropy": -1.0, "actor_entropy": 0.420950400252496, "alpha_loss": -0.008737666562439935, "alpha_value": 0.300621333012738, "duration": 152.1853244304657, "step": 92000}
{"episode_reward": 191.7730437183734, "episode": 737.0, "Q1 loss": 16.604842796325684, "Q2 loss": 16.616490325927735, "Mean Target Q": 241.0131862792969, "Mean Q1": 241.01303369140626, "Mean Q2": 241.0140432128906, "critic_loss": 33.22133299255371, "batch_reward": 1.5193121299743653, "actor_loss": -242.44712756928942, "actor_target_entropy": -1.0, "actor_entropy": 0.43697674690730987, "alpha_loss": -0.006895314820761245, "alpha_value": 0.30132818864309413, "duration": 157.14200949668884, "step": 92125}
{"episode_reward": 156.81699168050454, "episode": 738.0, "Q1 loss": 16.665597274780275, "Q2 loss": 16.589095886230467, "Mean Target Q": 241.10323083496093, "Mean Q1": 241.10296313476562, "Mean Q2": 241.10182971191406, "critic_loss": 33.25469319152832, "batch_reward": 1.5165553312301636, "actor_loss": -242.5033237088111, "actor_target_entropy": -1.0, "actor_entropy": 0.46490314122169246, "alpha_loss": 0.0039111122098420895, "alpha_value": 0.30137410590665265, "duration": 150.4047384262085, "step": 92250}
{"episode_reward": 95.80466056756157, "episode": 739.0, "Q1 loss": 16.55191586303711, "Q2 loss": 16.504008094787597, "Mean Target Q": 241.2001943359375, "Mean Q1": 241.19973876953125, "Mean Q2": 241.19902355957032, "critic_loss": 33.05592398071289, "batch_reward": 1.5093918466567993, "actor_loss": -242.64191037132628, "actor_target_entropy": -1.0, "actor_entropy": 0.4504626398048704, "alpha_loss": -0.011530764766835741, "alpha_value": 0.3016367145602613, "duration": 148.95906829833984, "step": 92375}
{"episode_reward": 25.708319444686897, "episode": 740.0, "Q1 loss": 16.204716636657714, "Q2 loss": 16.297391334533692, "Mean Target Q": 241.30507580566407, "Mean Q1": 241.30397534179687, "Mean Q2": 241.30676904296874, "critic_loss": 32.502107772827145, "batch_reward": 1.5146753215789794, "actor_loss": -242.7537590765184, "actor_target_entropy": -1.0, "actor_entropy": 0.44951982988465217, "alpha_loss": -0.010958355333235475, "alpha_value": 0.30256630650457955, "duration": 150.66609930992126, "step": 92500}
{"episode_reward": 181.42723135624186, "episode": 741.0, "Q1 loss": 15.96905576324463, "Q2 loss": 15.847569641113282, "Mean Target Q": 241.34587707519532, "Mean Q1": 241.3425625, "Mean Q2": 241.34020153808595, "critic_loss": 31.816625350952147, "batch_reward": 1.5030023908615113, "actor_loss": -242.76993185376364, "actor_target_entropy": -1.0, "actor_entropy": 0.458252955996801, "alpha_loss": -0.007295097139412685, "alpha_value": 0.3030382151164206, "duration": 154.0749442577362, "step": 92625}
{"episode_reward": 157.11376906378317, "episode": 742.0, "Q1 loss": 16.30120531463623, "Q2 loss": 16.291862632751464, "Mean Target Q": 241.5439794921875, "Mean Q1": 241.54096130371093, "Mean Q2": 241.54093896484375, "critic_loss": 32.593067947387695, "batch_reward": 1.5142261638641357, "actor_loss": -243.0646517353673, "actor_target_entropy": -1.0, "actor_entropy": 0.44210364116776374, "alpha_loss": -0.00673707299715569, "alpha_value": 0.3037898991869993, "duration": 156.4510145187378, "step": 92750}
{"episode_reward": 43.0559163529535, "episode": 743.0, "Q1 loss": 16.07842470550537, "Q2 loss": 16.098524322509764, "Mean Target Q": 241.55229797363282, "Mean Q1": 241.55568981933592, "Mean Q2": 241.5580244140625, "critic_loss": 32.17694905090332, "batch_reward": 1.5051182651519774, "actor_loss": -243.00457473028274, "actor_target_entropy": -1.0, "actor_entropy": 0.42572534131625345, "alpha_loss": -0.019403553604783994, "alpha_value": 0.3046081582643519, "duration": 150.54859828948975, "step": 92875}
{"episode_reward": 6.416902073833941, "episode": 744.0, "Q1 loss": 15.768363586425782, "Q2 loss": 15.852808288574218, "Mean Target Q": 241.8705555419922, "Mean Q1": 241.8589696044922, "Mean Q2": 241.8590164794922, "critic_loss": 31.621171875, "batch_reward": 1.5179273853302002, "actor_loss": -243.2750719131962, "actor_target_entropy": -1.0, "actor_entropy": 0.45432557021417924, "alpha_loss": -0.009769217163744954, "alpha_value": 0.30587371120639295, "duration": 152.88202166557312, "step": 93000}
{"episode_reward": 55.55862234757396, "episode": 745.0, "Q1 loss": 16.30519718170166, "Q2 loss": 16.26371420288086, "Mean Target Q": 241.9403468017578, "Mean Q1": 241.94037243652343, "Mean Q2": 241.93902197265626, "critic_loss": 32.56891134643555, "batch_reward": 1.5028162488937378, "actor_loss": -243.38459027002727, "actor_target_entropy": -1.0, "actor_entropy": 0.4311780622081151, "alpha_loss": -0.004190118377289128, "alpha_value": 0.3063562604590878, "duration": 161.61646962165833, "step": 93125}
{"episode_reward": 179.2174622310328, "episode": 746.0, "Q1 loss": 16.260406181335448, "Q2 loss": 16.350386672973634, "Mean Target Q": 241.8383516845703, "Mean Q1": 241.8393127441406, "Mean Q2": 241.83968359375, "critic_loss": 32.61079286193848, "batch_reward": 1.5030809688568114, "actor_loss": -243.28572894680886, "actor_target_entropy": -1.0, "actor_entropy": 0.4467455018912592, "alpha_loss": 0.016043201404353304, "alpha_value": 0.30579270361629185, "duration": 154.44946932792664, "step": 93250}
{"episode_reward": 115.46486153512991, "episode": 747.0, "Q1 loss": 16.197643043518067, "Q2 loss": 16.235626998901367, "Mean Target Q": 242.07528564453125, "Mean Q1": 242.07266455078124, "Mean Q2": 242.07195446777342, "critic_loss": 32.43327003479004, "batch_reward": 1.502857442855835, "actor_loss": -243.47870236351378, "actor_target_entropy": -1.0, "actor_entropy": 0.46328547076573445, "alpha_loss": -0.010472216887310856, "alpha_value": 0.30568822437511195, "duration": 164.14129638671875, "step": 93375}
{"episode_reward": 179.57426505250595, "episode": 748.0, "Q1 loss": 16.272361907958985, "Q2 loss": 16.27976565551758, "Mean Target Q": 242.21095935058594, "Mean Q1": 242.21094653320313, "Mean Q2": 242.2103299560547, "critic_loss": 32.55212739562988, "batch_reward": 1.4980794763565064, "actor_loss": -243.65518385364163, "actor_target_entropy": -1.0, "actor_entropy": 0.47857685242929765, "alpha_loss": -0.005031200565187441, "alpha_value": 0.3061358603249628, "duration": 160.31460428237915, "step": 93500}
{"episode_reward": 182.476171215598, "episode": 749.0, "Q1 loss": 15.997070892333983, "Q2 loss": 15.95196639251709, "Mean Target Q": 242.09357116699218, "Mean Q1": 242.08150915527344, "Mean Q2": 242.08431726074218, "critic_loss": 31.94903729248047, "batch_reward": 1.4916554021835327, "actor_loss": -243.4068637424045, "actor_target_entropy": -1.0, "actor_entropy": 0.4757814402618105, "alpha_loss": -0.0017979613889659207, "alpha_value": 0.30588274970102114, "duration": 165.65835213661194, "step": 93625}
{"episode_reward": 151.79306434084563, "episode": 750.0, "Q1 loss": 16.642235885620117, "Q2 loss": 16.484970512390138, "Mean Target Q": 242.26322888183594, "Mean Q1": 242.27405639648438, "Mean Q2": 242.27407275390624, "critic_loss": 33.127206268310545, "batch_reward": 1.5052694816589356, "actor_loss": -243.5813711843183, "actor_target_entropy": -1.0, "actor_entropy": 0.46991718920969194, "alpha_loss": 0.021029358575751465, "alpha_value": 0.30600357281896523, "duration": 157.79168486595154, "step": 93750}
{"episode_reward": 18.84340190376072, "episode": 751.0, "Q1 loss": 16.268210578918456, "Q2 loss": 16.32959841156006, "Mean Target Q": 242.19673669433593, "Mean Q1": 242.1892042236328, "Mean Q2": 242.1879670410156, "critic_loss": 32.59780894470215, "batch_reward": 1.5072279777526856, "actor_loss": -243.68151976570252, "actor_target_entropy": -1.0, "actor_entropy": 0.4319372356884063, "alpha_loss": 0.0011889906674032173, "alpha_value": 0.3048754917126535, "duration": 152.94687819480896, "step": 93875}
{"episode_reward": 174.64059760638253, "episode": 752.0, "Q1 loss": 17.0381939163208, "Q2 loss": 16.949571502685547, "Mean Target Q": 242.18624108886718, "Mean Q1": 242.18103393554688, "Mean Q2": 242.18088146972656, "critic_loss": 33.98776545715332, "batch_reward": 1.5036000251770019, "actor_loss": -243.7465340398973, "actor_target_entropy": -1.0, "actor_entropy": 0.47354620695114136, "alpha_loss": -0.004936751184774743, "alpha_value": 0.3050656450618291, "duration": 155.42488646507263, "step": 94000}
{"episode_reward": 159.21547585425054, "episode": 753.0, "Q1 loss": 16.234679298400877, "Q2 loss": 16.26695499420166, "Mean Target Q": 242.40278686523436, "Mean Q1": 242.40200024414062, "Mean Q2": 242.40099157714843, "critic_loss": 32.50163423156738, "batch_reward": 1.510519676208496, "actor_loss": -243.85577441018725, "actor_target_entropy": -1.0, "actor_entropy": 0.4538746703238714, "alpha_loss": -0.003243064001527807, "alpha_value": 0.3053887492254524, "duration": 165.90741801261902, "step": 94125}
{"episode_reward": 40.64503645791736, "episode": 754.0, "Q1 loss": 16.732025268554686, "Q2 loss": 16.681761375427246, "Mean Target Q": 242.5408046875, "Mean Q1": 242.54008422851564, "Mean Q2": 242.54089770507812, "critic_loss": 33.413786727905276, "batch_reward": 1.5070388746261596, "actor_loss": -243.9707038633285, "actor_target_entropy": -1.0, "actor_entropy": 0.4325604462815869, "alpha_loss": -0.014243771964233489, "alpha_value": 0.3057387676674289, "duration": 155.12173676490784, "step": 94250}
{"episode_reward": 110.6222582106222, "episode": 755.0, "Q1 loss": 15.911146499633789, "Q2 loss": 15.850347633361816, "Mean Target Q": 242.53716748046875, "Mean Q1": 242.5356346435547, "Mean Q2": 242.53681103515626, "critic_loss": 31.76149415588379, "batch_reward": 1.4954320058822632, "actor_loss": -243.94480314708892, "actor_target_entropy": -1.0, "actor_entropy": 0.4597689003225357, "alpha_loss": -0.01317596280326446, "alpha_value": 0.3067316278263322, "duration": 159.06586003303528, "step": 94375}
{"episode_reward": 172.77711562674745, "episode": 756.0, "Q1 loss": 17.55560994720459, "Q2 loss": 17.545809539794924, "Mean Target Q": 242.61353454589843, "Mean Q1": 242.61303527832033, "Mean Q2": 242.61256103515626, "critic_loss": 35.10141952514648, "batch_reward": 1.4877902460098267, "actor_loss": -244.05113023327243, "actor_target_entropy": -1.0, "actor_entropy": 0.4748926220401641, "alpha_loss": -0.006870912757867407, "alpha_value": 0.3077611252545035, "duration": 147.28536105155945, "step": 94500}
{"episode_reward": 52.830319012769294, "episode": 757.0, "Q1 loss": 19.35185894012451, "Q2 loss": 19.590922119140625, "Mean Target Q": 242.8988377685547, "Mean Q1": 242.89666235351564, "Mean Q2": 242.89267260742187, "critic_loss": 38.942780960083006, "batch_reward": 1.503726809501648, "actor_loss": -244.2704591296968, "actor_target_entropy": -1.0, "actor_entropy": 0.4763534925286732, "alpha_loss": 0.005491351021365041, "alpha_value": 0.30781219485076944, "duration": 152.636155128479, "step": 94625}
{"episode_reward": 80.40980559661159, "episode": 758.0, "Q1 loss": 17.089339469909667, "Q2 loss": 17.049169372558595, "Mean Target Q": 243.00156298828125, "Mean Q1": 242.9916875, "Mean Q2": 242.99814672851562, "critic_loss": 34.138508880615234, "batch_reward": 1.5085492887496947, "actor_loss": -244.27944626346712, "actor_target_entropy": -1.0, "actor_entropy": 0.4880147725343704, "alpha_loss": 0.009153004416504936, "alpha_value": 0.3067053379159125, "duration": 166.05461192131042, "step": 94750}
{"episode_reward": 49.81245368592941, "episode": 759.0, "Q1 loss": 16.147002334594728, "Q2 loss": 16.12153098297119, "Mean Target Q": 242.931671875, "Mean Q1": 242.9357879638672, "Mean Q2": 242.9341242675781, "critic_loss": 32.26853324890137, "batch_reward": 1.4964940452575684, "actor_loss": -244.22969321599084, "actor_target_entropy": -1.0, "actor_entropy": 0.46629251657970366, "alpha_loss": -0.0016403831135008544, "alpha_value": 0.30667446493163447, "duration": 153.39073204994202, "step": 94875}
{"episode_reward": 184.75527936178946, "episode": 760.0, "Q1 loss": 16.387986625671388, "Q2 loss": 16.220469924926757, "Mean Target Q": 242.81787255859376, "Mean Q1": 242.81364990234374, "Mean Q2": 242.8140340576172, "critic_loss": 32.608456497192385, "batch_reward": 1.495364212989807, "actor_loss": -244.19912498228013, "actor_target_entropy": -1.0, "actor_entropy": 0.47934054415072164, "alpha_loss": -0.011814061387051497, "alpha_value": 0.30727460668818785, "step": 95000}
{"duration": 168.43614268302917, "step": 95000}
{"episode_reward": 18.378737890774868, "episode": 761.0, "Q1 loss": 16.00441259765625, "Q2 loss": 15.918073181152344, "Mean Target Q": 243.07769055175783, "Mean Q1": 243.08399890136718, "Mean Q2": 243.08082250976562, "critic_loss": 31.92248583984375, "batch_reward": 1.4866950645446777, "actor_loss": -244.49229334271143, "actor_target_entropy": -1.0, "actor_entropy": 0.46761052854477414, "alpha_loss": -0.018390610536915205, "alpha_value": 0.30839163558323074, "duration": 152.50859570503235, "step": 95125}
{"episode_reward": 148.39163765326683, "episode": 762.0, "Q1 loss": 16.074694137573243, "Q2 loss": 16.15176819610596, "Mean Target Q": 243.18253479003906, "Mean Q1": 243.17740563964844, "Mean Q2": 243.1802716064453, "critic_loss": 32.22646228027344, "batch_reward": 1.493817229270935, "actor_loss": -244.62196546985257, "actor_target_entropy": -1.0, "actor_entropy": 0.46262441335185883, "alpha_loss": -0.006413158697767123, "alpha_value": 0.30906334406647734, "duration": 155.3105754852295, "step": 95250}
{"episode_reward": 52.37136003753095, "episode": 763.0, "Q1 loss": 16.760475997924804, "Q2 loss": 16.695536712646483, "Mean Target Q": 243.2768527832031, "Mean Q1": 243.26897399902344, "Mean Q2": 243.2684619140625, "critic_loss": 33.456012649536135, "batch_reward": 1.500295721054077, "actor_loss": -244.63146415589347, "actor_target_entropy": -1.0, "actor_entropy": 0.46679732108873034, "alpha_loss": 0.003526311626450883, "alpha_value": 0.3093187723434686, "duration": 155.29151821136475, "step": 95375}
{"episode_reward": 35.637238409443896, "episode": 764.0, "Q1 loss": 16.403310302734376, "Q2 loss": 16.33687243652344, "Mean Target Q": 243.2600545654297, "Mean Q1": 243.26040966796876, "Mean Q2": 243.26153393554688, "critic_loss": 32.74018278503418, "batch_reward": 1.4909865055084228, "actor_loss": -244.69822889758694, "actor_target_entropy": -1.0, "actor_entropy": 0.47196529421114153, "alpha_loss": 0.00694713726519577, "alpha_value": 0.3088163534660299, "duration": 162.6909031867981, "step": 95500}
{"episode_reward": 50.620078319413295, "episode": 765.0, "Q1 loss": 16.306310104370116, "Q2 loss": 16.314696250915528, "Mean Target Q": 243.13357507324218, "Mean Q1": 243.13001647949218, "Mean Q2": 243.1311669921875, "critic_loss": 32.62100637817383, "batch_reward": 1.4879458961486816, "actor_loss": -244.4485853891524, "actor_target_entropy": -1.0, "actor_entropy": 0.4698410379508185, "alpha_loss": -0.002412825482823546, "alpha_value": 0.3087933364730705, "duration": 156.60604739189148, "step": 95625}
{"episode_reward": 165.31612152026932, "episode": 766.0, "Q1 loss": 16.0643119430542, "Q2 loss": 16.025016304016113, "Mean Target Q": 243.44049853515625, "Mean Q1": 243.44111096191406, "Mean Q2": 243.4372420654297, "critic_loss": 32.08932830810547, "batch_reward": 1.4899380092620849, "actor_loss": -244.92423765120967, "actor_target_entropy": -1.0, "actor_entropy": 0.4746104392313188, "alpha_loss": -0.0067808164185994575, "alpha_value": 0.30877704719006693, "duration": 159.04703307151794, "step": 95750}
{"episode_reward": 158.47364140682146, "episode": 767.0, "Q1 loss": 17.09030059814453, "Q2 loss": 17.022697814941406, "Mean Target Q": 243.46626489257812, "Mean Q1": 243.46115551757813, "Mean Q2": 243.4635352783203, "critic_loss": 34.112998260498046, "batch_reward": 1.4756880750656127, "actor_loss": -244.91332111661396, "actor_target_entropy": -1.0, "actor_entropy": 0.4596285763240996, "alpha_loss": -0.012518212457911836, "alpha_value": 0.30958394046857846, "duration": 155.39363312721252, "step": 95875}
{"episode_reward": 172.29470171709738, "episode": 768.0, "Q1 loss": 17.250723899841308, "Q2 loss": 17.27099069213867, "Mean Target Q": 243.7138172607422, "Mean Q1": 243.71458557128906, "Mean Q2": 243.71431433105468, "critic_loss": 34.521714538574216, "batch_reward": 1.485026728630066, "actor_loss": -245.0850859611265, "actor_target_entropy": -1.0, "actor_entropy": 0.48531084291396603, "alpha_loss": 0.009852868966728209, "alpha_value": 0.3100279107241751, "duration": 137.21115374565125, "step": 96000}
{"episode_reward": 40.73605355321276, "episode": 769.0, "Q1 loss": 16.85509959411621, "Q2 loss": 16.916761856079102, "Mean Target Q": 243.80836010742186, "Mean Q1": 243.80496252441407, "Mean Q2": 243.8060401611328, "critic_loss": 33.771861618041996, "batch_reward": 1.488237916946411, "actor_loss": -245.2719949389261, "actor_target_entropy": -1.0, "actor_entropy": 0.4650314942238823, "alpha_loss": 0.006586231025201934, "alpha_value": 0.30913526279606307, "duration": 133.11020302772522, "step": 96125}
{"episode_reward": 181.6403835906446, "episode": 770.0, "Q1 loss": 17.594683296203613, "Q2 loss": 17.523057807922363, "Mean Target Q": 243.90234558105467, "Mean Q1": 243.8993740234375, "Mean Q2": 243.8994012451172, "critic_loss": 35.117741088867184, "batch_reward": 1.4842858953475953, "actor_loss": -245.41080524075417, "actor_target_entropy": -1.0, "actor_entropy": 0.4690047728438531, "alpha_loss": -0.002066143142480043, "alpha_value": 0.30881401738890446, "duration": 131.720317363739, "step": 96250}
{"episode_reward": 179.14599332213916, "episode": 771.0, "Q1 loss": 16.732869583129883, "Q2 loss": 16.769319595336913, "Mean Target Q": 244.0262021484375, "Mean Q1": 244.02445153808594, "Mean Q2": 244.02484777832032, "critic_loss": 33.502189254760744, "batch_reward": 1.4772249517440796, "actor_loss": -245.57542225671193, "actor_target_entropy": -1.0, "actor_entropy": 0.5045509631671603, "alpha_loss": -0.00872362262406756, "alpha_value": 0.3095512077851209, "duration": 137.9804289340973, "step": 96375}
{"episode_reward": 174.15001291661494, "episode": 772.0, "Q1 loss": 17.181877212524412, "Q2 loss": 17.04821756744385, "Mean Target Q": 244.04168273925782, "Mean Q1": 244.04432824707033, "Mean Q2": 244.04180529785157, "critic_loss": 34.23009478759766, "batch_reward": 1.4794432744979857, "actor_loss": -245.6136007001323, "actor_target_entropy": -1.0, "actor_entropy": 0.45084302319634345, "alpha_loss": -0.008133291946573844, "alpha_value": 0.3099212855000459, "duration": 130.49442768096924, "step": 96500}
{"episode_reward": 14.52852849336694, "episode": 773.0, "Q1 loss": 16.451003158569335, "Q2 loss": 16.45687557220459, "Mean Target Q": 244.08459033203124, "Mean Q1": 244.07100354003907, "Mean Q2": 244.07507067871094, "critic_loss": 32.907878768920895, "batch_reward": 1.4877858514785767, "actor_loss": -245.51184760199652, "actor_target_entropy": -1.0, "actor_entropy": 0.4730651203602079, "alpha_loss": -0.006181426553262604, "alpha_value": 0.31063707591808004, "duration": 140.85040521621704, "step": 96625}
{"episode_reward": 183.28258257919813, "episode": 774.0, "Q1 loss": 17.18718558502197, "Q2 loss": 17.2465322265625, "Mean Target Q": 244.22683068847655, "Mean Q1": 244.23243408203126, "Mean Q2": 244.22952673339844, "critic_loss": 34.43371792602539, "batch_reward": 1.4755022487640381, "actor_loss": -245.84793632261216, "actor_target_entropy": -1.0, "actor_entropy": 0.49784236233080587, "alpha_loss": -0.00160964117610767, "alpha_value": 0.31078590598072475, "duration": 132.84665298461914, "step": 96750}
{"episode_reward": 193.26639968165446, "episode": 775.0, "Q1 loss": 18.42241399383545, "Q2 loss": 18.370678451538087, "Mean Target Q": 244.49859692382813, "Mean Q1": 244.4885841064453, "Mean Q2": 244.48964233398436, "critic_loss": 36.79309278869629, "batch_reward": 1.4746589641571044, "actor_loss": -246.10047161768352, "actor_target_entropy": -1.0, "actor_entropy": 0.46702995990949964, "alpha_loss": 0.0031847553290722387, "alpha_value": 0.31088970027444585, "duration": 138.09709429740906, "step": 96875}
{"episode_reward": 137.29959959029074, "episode": 776.0, "Q1 loss": 16.996638679504393, "Q2 loss": 17.072947570800782, "Mean Target Q": 244.679482421875, "Mean Q1": 244.686, "Mean Q2": 244.6845096435547, "critic_loss": 34.0695863494873, "batch_reward": 1.490766975402832, "actor_loss": -246.22240324943297, "actor_target_entropy": -1.0, "actor_entropy": 0.4957875119101617, "alpha_loss": 0.00753360993469194, "alpha_value": 0.3102984649235836, "duration": 131.15953373908997, "step": 97000}
{"episode_reward": 152.7171582159459, "episode": 777.0, "Q1 loss": 16.531435119628906, "Q2 loss": 16.492649559020997, "Mean Target Q": 244.64031408691406, "Mean Q1": 244.6363074951172, "Mean Q2": 244.63717053222655, "critic_loss": 33.02408464050293, "batch_reward": 1.4794523859024047, "actor_loss": -246.19398619636658, "actor_target_entropy": -1.0, "actor_entropy": 0.48035486823036555, "alpha_loss": 0.00039977354869719534, "alpha_value": 0.3100409625168962, "duration": 155.6961691379547, "step": 97125}
{"episode_reward": 176.33834314801393, "episode": 778.0, "Q1 loss": 16.24119679260254, "Q2 loss": 16.140395210266114, "Mean Target Q": 244.77658142089842, "Mean Q1": 244.78261596679687, "Mean Q2": 244.78153125, "critic_loss": 32.381592178344725, "batch_reward": 1.4729203252792358, "actor_loss": -246.2325173654864, "actor_target_entropy": -1.0, "actor_entropy": 0.4850219786167145, "alpha_loss": 0.0006995272086632829, "alpha_value": 0.31003514188137504, "duration": 155.5626049041748, "step": 97250}
{"episode_reward": 153.9835989031367, "episode": 779.0, "Q1 loss": 17.148778602600096, "Q2 loss": 17.238574447631837, "Mean Target Q": 244.84730493164062, "Mean Q1": 244.84348876953126, "Mean Q2": 244.84133666992187, "critic_loss": 34.387353057861326, "batch_reward": 1.4777248249053956, "actor_loss": -246.26624407087053, "actor_target_entropy": -1.0, "actor_entropy": 0.4975366232887147, "alpha_loss": -0.005533465709064215, "alpha_value": 0.3102125720498933, "duration": 151.68734574317932, "step": 97375}
{"episode_reward": 166.21203301689368, "episode": 780.0, "Q1 loss": 16.608846252441406, "Q2 loss": 16.596423011779784, "Mean Target Q": 245.10571948242188, "Mean Q1": 245.09700646972655, "Mean Q2": 245.0988427734375, "critic_loss": 33.2052692565918, "batch_reward": 1.478373140335083, "actor_loss": -246.60228507749497, "actor_target_entropy": -1.0, "actor_entropy": 0.46144375445381286, "alpha_loss": -0.007796682199583419, "alpha_value": 0.3105446814774968, "duration": 151.8848021030426, "step": 97500}
{"episode_reward": 157.09194938955432, "episode": 781.0, "Q1 loss": 16.706748107910155, "Q2 loss": 16.68125464630127, "Mean Target Q": 245.21930090332032, "Mean Q1": 245.22518115234374, "Mean Q2": 245.226064453125, "critic_loss": 33.38800268554687, "batch_reward": 1.474496795654297, "actor_loss": -246.75776260618179, "actor_target_entropy": -1.0, "actor_entropy": 0.47910451889038086, "alpha_loss": -0.02305800370532014, "alpha_value": 0.3117727342844773, "duration": 151.18166851997375, "step": 97625}
{"episode_reward": 181.42366743548203, "episode": 782.0, "Q1 loss": 16.470481338500978, "Q2 loss": 16.5014545211792, "Mean Target Q": 245.56934533691407, "Mean Q1": 245.5588435058594, "Mean Q2": 245.55784130859374, "critic_loss": 32.97193588256836, "batch_reward": 1.4878277063369751, "actor_loss": -247.01085441343247, "actor_target_entropy": -1.0, "actor_entropy": 0.43390663496909604, "alpha_loss": -0.029028375850870244, "alpha_value": 0.3134797853638678, "duration": 154.9409737586975, "step": 97750}
{"episode_reward": 40.42506187108538, "episode": 783.0, "Q1 loss": 16.441339294433593, "Q2 loss": 16.53479660797119, "Mean Target Q": 245.5392626953125, "Mean Q1": 245.54717370605468, "Mean Q2": 245.54784497070312, "critic_loss": 32.976135757446286, "batch_reward": 1.4787545318603517, "actor_loss": -247.10021173386346, "actor_target_entropy": -1.0, "actor_entropy": 0.4854644768767887, "alpha_loss": -0.009771508164703846, "alpha_value": 0.3149693451543699, "duration": 150.13522481918335, "step": 97875}
{"episode_reward": 190.34610391049492, "episode": 784.0, "Q1 loss": 17.51676779937744, "Q2 loss": 17.48535343170166, "Mean Target Q": 245.82936059570312, "Mean Q1": 245.81559252929688, "Mean Q2": 245.81508911132812, "critic_loss": 35.00212127685547, "batch_reward": 1.4763264112472534, "actor_loss": -247.21847854122038, "actor_target_entropy": -1.0, "actor_entropy": 0.46290859051289096, "alpha_loss": 0.021181037856055605, "alpha_value": 0.3147564110777862, "duration": 151.60994172096252, "step": 98000}
{"episode_reward": 138.91713604925783, "episode": 785.0, "Q1 loss": 16.103044288635253, "Q2 loss": 16.10139459991455, "Mean Target Q": 245.65847045898437, "Mean Q1": 245.66694750976563, "Mean Q2": 245.66664538574219, "critic_loss": 32.20443872070312, "batch_reward": 1.4785869636535645, "actor_loss": -247.02886526925224, "actor_target_entropy": -1.0, "actor_entropy": 0.4669640811662825, "alpha_loss": 0.011689565406875714, "alpha_value": 0.3133791167196471, "duration": 157.856751203537, "step": 98125}
{"episode_reward": 17.54674091767275, "episode": 786.0, "Q1 loss": 16.50429556274414, "Q2 loss": 16.45987547302246, "Mean Target Q": 245.75846411132812, "Mean Q1": 245.75095434570312, "Mean Q2": 245.7521707763672, "critic_loss": 32.964171157836915, "batch_reward": 1.4903556680679322, "actor_loss": -247.11930256505167, "actor_target_entropy": -1.0, "actor_entropy": 0.4871215945289981, "alpha_loss": 0.008878981750909119, "alpha_value": 0.3126591280165684, "duration": 162.06236171722412, "step": 98250}
{"episode_reward": 182.08561206912282, "episode": 787.0, "Q1 loss": 16.198884727478028, "Q2 loss": 16.18276593017578, "Mean Target Q": 245.95906262207032, "Mean Q1": 245.95334802246094, "Mean Q2": 245.9523370361328, "critic_loss": 32.3816506652832, "batch_reward": 1.478762812614441, "actor_loss": -247.34818352593317, "actor_target_entropy": -1.0, "actor_entropy": 0.4949242624025496, "alpha_loss": 0.013415166590776708, "alpha_value": 0.3119011523770492, "duration": 156.60545444488525, "step": 98375}
{"episode_reward": 181.9582498091632, "episode": 788.0, "Q1 loss": 15.835137229919434, "Q2 loss": 15.782277076721192, "Mean Target Q": 245.86526953125, "Mean Q1": 245.86405029296876, "Mean Q2": 245.86599084472655, "critic_loss": 31.617414428710937, "batch_reward": 1.4703187170028686, "actor_loss": -247.28373053766066, "actor_target_entropy": -1.0, "actor_entropy": 0.478351769908782, "alpha_loss": 0.009855881750193094, "alpha_value": 0.31118848621627354, "duration": 156.0107560157776, "step": 98500}
{"episode_reward": 174.16621872313982, "episode": 789.0, "Q1 loss": 15.770998062133788, "Q2 loss": 15.754704887390137, "Mean Target Q": 245.9975068359375, "Mean Q1": 245.99394140625, "Mean Q2": 245.99267956542968, "critic_loss": 31.52570297241211, "batch_reward": 1.4863572092056274, "actor_loss": -247.39834715828064, "actor_target_entropy": -1.0, "actor_entropy": 0.49837403401495917, "alpha_loss": 0.014656163485986846, "alpha_value": 0.31019217544692373, "duration": 147.3107123374939, "step": 98625}
{"episode_reward": 19.327027719599325, "episode": 790.0, "Q1 loss": 15.751883010864258, "Q2 loss": 15.784352294921876, "Mean Target Q": 245.9126239013672, "Mean Q1": 245.9091190185547, "Mean Q2": 245.90983898925782, "critic_loss": 31.536235366821288, "batch_reward": 1.4731184043884278, "actor_loss": -247.38187531502015, "actor_target_entropy": -1.0, "actor_entropy": 0.491528473554119, "alpha_loss": -0.002214375639244193, "alpha_value": 0.310012941774907, "duration": 147.3214554786682, "step": 98750}
{"episode_reward": 145.18824633966216, "episode": 791.0, "Q1 loss": 16.081116035461427, "Q2 loss": 16.016621116638184, "Mean Target Q": 246.16936938476562, "Mean Q1": 246.17263989257813, "Mean Q2": 246.1707469482422, "critic_loss": 32.09773701477051, "batch_reward": 1.4727253046035766, "actor_loss": -247.7231217641679, "actor_target_entropy": -1.0, "actor_entropy": 0.48392791312838357, "alpha_loss": -0.025961754374235632, "alpha_value": 0.3107487210932995, "duration": 159.53867411613464, "step": 98875}
{"episode_reward": 157.1771896924514, "episode": 792.0, "Q1 loss": 16.176711837768554, "Q2 loss": 16.184393600463867, "Mean Target Q": 246.35035693359376, "Mean Q1": 246.3477098388672, "Mean Q2": 246.34747473144532, "critic_loss": 32.36110546875, "batch_reward": 1.4828355875015258, "actor_loss": -247.82983029273248, "actor_target_entropy": -1.0, "actor_entropy": 0.46663002141060367, "alpha_loss": -0.014551831612123116, "alpha_value": 0.31206460198812863, "duration": 159.20949602127075, "step": 99000}
{"episode_reward": 36.12182483550593, "episode": 793.0, "Q1 loss": 15.638954383850098, "Q2 loss": 15.668356285095214, "Mean Target Q": 246.25486389160156, "Mean Q1": 246.25606958007813, "Mean Q2": 246.25954040527344, "critic_loss": 31.307310485839842, "batch_reward": 1.4655104665756225, "actor_loss": -247.75587996225508, "actor_target_entropy": -1.0, "actor_entropy": 0.5061532131263188, "alpha_loss": -0.007185894286348706, "alpha_value": 0.3128968646640213, "duration": 185.9804093837738, "step": 99125}
{"episode_reward": 70.67465312787368, "episode": 794.0, "Q1 loss": 17.354694770812987, "Q2 loss": 17.312155433654784, "Mean Target Q": 246.6060076904297, "Mean Q1": 246.60748010253906, "Mean Q2": 246.6040966796875, "critic_loss": 34.66685040283203, "batch_reward": 1.4767481727600098, "actor_loss": -247.99450019098097, "actor_target_entropy": -1.0, "actor_entropy": 0.47126064233241544, "alpha_loss": -0.0022878402904156717, "alpha_value": 0.31330737807867276, "duration": 181.40020966529846, "step": 99250}
{"episode_reward": 164.03662939298667, "episode": 795.0, "Q1 loss": 16.69914005279541, "Q2 loss": 16.685179466247558, "Mean Target Q": 246.55015356445313, "Mean Q1": 246.54830871582033, "Mean Q2": 246.55031323242187, "critic_loss": 33.38431971740722, "batch_reward": 1.4663984603881837, "actor_loss": -248.0290309361049, "actor_target_entropy": -1.0, "actor_entropy": 0.4929801074285356, "alpha_loss": -0.00840577393740652, "alpha_value": 0.3134333727425115, "duration": 178.5673222541809, "step": 99375}
{"episode_reward": 153.62763851905268, "episode": 796.0, "Q1 loss": 16.30283683013916, "Q2 loss": 16.16533168029785, "Mean Target Q": 246.57690856933593, "Mean Q1": 246.56895239257813, "Mean Q2": 246.57082421875, "critic_loss": 32.46816860961914, "batch_reward": 1.4651901874542237, "actor_loss": -248.14378627654045, "actor_target_entropy": -1.0, "actor_entropy": 0.4678369150046379, "alpha_loss": -0.010744515143620272, "alpha_value": 0.314471812822297, "duration": 171.90508031845093, "step": 99500}
{"episode_reward": 177.74871521545634, "episode": 797.0, "Q1 loss": 16.257357513427735, "Q2 loss": 16.304383346557618, "Mean Target Q": 246.61930029296875, "Mean Q1": 246.61098193359376, "Mean Q2": 246.60923559570313, "critic_loss": 32.56174085998535, "batch_reward": 1.4685602655410768, "actor_loss": -248.24017915271577, "actor_target_entropy": -1.0, "actor_entropy": 0.4744690278219798, "alpha_loss": -0.007836002583009384, "alpha_value": 0.3148352268133391, "duration": 184.94011569023132, "step": 99625}
{"episode_reward": 149.64456793097983, "episode": 798.0, "Q1 loss": 16.399316558837892, "Q2 loss": 16.377985450744628, "Mean Target Q": 246.5898516845703, "Mean Q1": 246.58980786132813, "Mean Q2": 246.59223266601563, "critic_loss": 32.77730209350586, "batch_reward": 1.4612132177352906, "actor_loss": -248.08177111225743, "actor_target_entropy": -1.0, "actor_entropy": 0.48374334362245375, "alpha_loss": -0.005409085390818936, "alpha_value": 0.3153695249157901, "duration": 171.60277676582336, "step": 99750}
{"episode_reward": 30.158743930316337, "episode": 799.0, "Q1 loss": 16.54653576660156, "Q2 loss": 16.519145904541016, "Mean Target Q": 246.74530603027344, "Mean Q1": 246.7476463623047, "Mean Q2": 246.74426232910156, "critic_loss": 33.06568180847168, "batch_reward": 1.4771541004180908, "actor_loss": -248.31046307276165, "actor_target_entropy": -1.0, "actor_entropy": 0.49561702495529536, "alpha_loss": -0.006329265500729282, "alpha_value": 0.31552592537452695, "duration": 181.75367546081543, "step": 99875}
{"episode_reward": 13.118064691671218, "episode": 800.0, "Q1 loss": 16.48866923393742, "Q2 loss": 16.442416268010295, "Mean Target Q": 246.72901682699882, "Mean Q1": 246.72608824699157, "Mean Q2": 246.7239184225759, "critic_loss": 32.931085448111254, "batch_reward": 1.477063924074173, "actor_loss": -248.0823740805349, "actor_target_entropy": -1.0, "actor_entropy": 0.4860709506657816, "alpha_loss": 0.002190027213204772, "alpha_value": 0.31591753807978573, "step": 99999}
