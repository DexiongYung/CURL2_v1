{"episode_reward": 0.0, "episode": 1.0, "duration": 20.775434494018555, "step": 250}
{"episode_reward": 5.0, "episode": 2.0, "duration": 0.7317824363708496, "step": 500}
{"episode_reward": 0.0, "episode": 3.0, "duration": 0.7321486473083496, "step": 750}
{"episode_reward": 0.0, "episode": 4.0, "duration": 0.7308902740478516, "step": 1000}
{"episode_reward": 201.0, "episode": 5.0, "batch_reward": 0.2528515625, "critic_loss": 0.9706124938130378, "actor_loss": -0.6708727077841758, "actor_target_entropy": -2.0, "actor_entropy": 2.469330229282379, "alpha_loss": 0.31252229410409926, "alpha_value": 0.09941512395369971, "duration": 75.35404086112976, "step": 1250}
{"episode_reward": 99.0, "episode": 6.0, "batch_reward": 0.26053125, "critic_loss": 0.4642687177658081, "actor_loss": -1.0808209805488587, "actor_target_entropy": -2.0, "actor_entropy": 2.5107942848205567, "alpha_loss": 0.30675169587135315, "alpha_value": 0.09817621185119235, "duration": 75.56740164756775, "step": 1500}
{"episode_reward": 97.0, "episode": 7.0, "batch_reward": 0.2457890625, "critic_loss": 0.4642365021705627, "actor_loss": -1.5070597200393676, "actor_target_entropy": -2.0, "actor_entropy": 2.396833812713623, "alpha_loss": 0.27655147671699526, "alpha_value": 0.09706129909348202, "duration": 75.62116837501526, "step": 1750}
{"episode_reward": 0.0, "episode": 8.0, "batch_reward": 0.21846875, "critic_loss": 0.41258998411893844, "actor_loss": -1.9679023456573486, "actor_target_entropy": -2.0, "actor_entropy": 2.357738977432251, "alpha_loss": 0.2632553173303604, "alpha_value": 0.0959752836348087, "duration": 75.77733182907104, "step": 2000}
{"episode_reward": 20.0, "episode": 9.0, "batch_reward": 0.19503125, "critic_loss": 0.7213456449508667, "actor_loss": -2.5209197187423706, "actor_target_entropy": -2.0, "actor_entropy": 2.272409119606018, "alpha_loss": 0.24462043273448944, "alpha_value": 0.09493366346980765, "duration": 75.82564854621887, "step": 2250}
{"episode_reward": 18.0, "episode": 10.0, "batch_reward": 0.186171875, "critic_loss": 0.765033635020256, "actor_loss": -3.290500110626221, "actor_target_entropy": -2.0, "actor_entropy": 2.201947410583496, "alpha_loss": 0.22381037175655366, "alpha_value": 0.09394291038311103, "duration": 75.81995487213135, "step": 2500}
{"episode_reward": 0.0, "episode": 11.0, "batch_reward": 0.291359375, "critic_loss": 1.5490844328403472, "actor_loss": -5.209106645584106, "actor_target_entropy": -2.0, "actor_entropy": 2.181012208938599, "alpha_loss": 0.1871988205909729, "alpha_value": 0.09303725794175909, "duration": 75.79772782325745, "step": 2750}
{"episode_reward": 826.0, "episode": 12.0, "batch_reward": 0.44596875, "critic_loss": 1.2376817972660066, "actor_loss": -7.822904273986817, "actor_target_entropy": -2.0, "actor_entropy": 2.1218063945770265, "alpha_loss": 0.15598572462797164, "alpha_value": 0.09226094510134833, "duration": 75.89954423904419, "step": 3000}
{"episode_reward": 0.0, "episode": 13.0, "batch_reward": 0.4097734375, "critic_loss": 1.616096339225769, "actor_loss": -9.657188999176025, "actor_target_entropy": -2.0, "actor_entropy": 1.99595920753479, "alpha_loss": 0.12238995295763015, "alpha_value": 0.0915792973172485, "duration": 75.81629657745361, "step": 3250}
{"episode_reward": 0.0, "episode": 14.0, "batch_reward": 0.4022578125, "critic_loss": 1.9279734811782836, "actor_loss": -11.519018608093262, "actor_target_entropy": -2.0, "actor_entropy": 1.8966789999008178, "alpha_loss": 0.07562092535197734, "alpha_value": 0.09107168039875588, "duration": 75.8365249633789, "step": 3500}
{"episode_reward": 347.0, "episode": 15.0, "batch_reward": 0.4840546875, "critic_loss": 2.49899658536911, "actor_loss": -13.933182456970215, "actor_target_entropy": -2.0, "actor_entropy": 1.8230782327651978, "alpha_loss": 0.06322904248535634, "alpha_value": 0.09071086280132602, "duration": 75.82113552093506, "step": 3750}
{"episode_reward": 465.0, "episode": 16.0, "batch_reward": 0.588203125, "critic_loss": 2.8707987666130066, "actor_loss": -17.196132675170897, "actor_target_entropy": -2.0, "actor_entropy": 1.6495997762680055, "alpha_loss": 0.07211288356781007, "alpha_value": 0.09031996261723892, "duration": 75.90054059028625, "step": 4000}
{"episode_reward": 422.0, "episode": 17.0, "batch_reward": 0.6078359375, "critic_loss": 2.7151844544410704, "actor_loss": -19.699091842651367, "actor_target_entropy": -2.0, "actor_entropy": 1.6096016778945923, "alpha_loss": 0.07951329490542412, "alpha_value": 0.0898428817646168, "duration": 75.8044867515564, "step": 4250}
{"episode_reward": 10.0, "episode": 18.0, "batch_reward": 0.5746796875, "critic_loss": 2.8984301505088808, "actor_loss": -21.361334930419922, "actor_target_entropy": -2.0, "actor_entropy": 1.5799956674575806, "alpha_loss": 0.07919115760922432, "alpha_value": 0.0893059917185525, "duration": 75.86836504936218, "step": 4500}
{"episode_reward": 0.0, "episode": 19.0, "batch_reward": 0.560125, "critic_loss": 2.0949264616966246, "actor_loss": -23.24029296875, "actor_target_entropy": -2.0, "actor_entropy": 1.552714940071106, "alpha_loss": 0.08385210087895394, "alpha_value": 0.08873115484279287, "duration": 75.9101951122284, "step": 4750}
{"episode_reward": 239.0, "episode": 20.0, "batch_reward": 0.58678125, "critic_loss": 2.5205092668533324, "actor_loss": -24.398202728271485, "actor_target_entropy": -2.0, "actor_entropy": 1.5938995323181153, "alpha_loss": 0.07999799713492393, "alpha_value": 0.08812832417007306, "step": 5000}
{"duration": 93.66590404510498, "step": 5000}
{"episode_reward": 213.0, "episode": 21.0, "batch_reward": 0.6723203125, "critic_loss": 2.750855916023254, "actor_loss": -27.444941650390625, "actor_target_entropy": -2.0, "actor_entropy": 1.5558533411026, "alpha_loss": 0.075099738240242, "alpha_value": 0.08753652725076949, "duration": 75.57578802108765, "step": 5250}
{"episode_reward": 952.0, "episode": 22.0, "batch_reward": 0.73759375, "critic_loss": 2.9056566848754883, "actor_loss": -30.54572280883789, "actor_target_entropy": -2.0, "actor_entropy": 1.5929963903427125, "alpha_loss": 0.06659280395507812, "alpha_value": 0.08694828676011261, "duration": 75.76518273353577, "step": 5500}
{"episode_reward": 114.0, "episode": 23.0, "batch_reward": 0.8018046875, "critic_loss": 2.7262721939086916, "actor_loss": -33.65566705322266, "actor_target_entropy": -2.0, "actor_entropy": 1.5996865787506103, "alpha_loss": 0.05295936480164528, "alpha_value": 0.08645496934235826, "duration": 75.8935182094574, "step": 5750}
{"episode_reward": 994.0, "episode": 24.0, "batch_reward": 0.861984375, "critic_loss": 3.5159933519363404, "actor_loss": -38.21033999633789, "actor_target_entropy": -2.0, "actor_entropy": 1.5454140701293946, "alpha_loss": 0.03213415551930666, "alpha_value": 0.08607168850683126, "duration": 75.83303666114807, "step": 6000}
{"episode_reward": 14.0, "episode": 25.0, "batch_reward": 0.895328125, "critic_loss": 3.1412655897140502, "actor_loss": -42.763652526855466, "actor_target_entropy": -2.0, "actor_entropy": 1.5014712200164795, "alpha_loss": 0.027062248538713904, "alpha_value": 0.08581615861404863, "duration": 75.82240343093872, "step": 6250}
{"episode_reward": 958.0, "episode": 26.0, "batch_reward": 0.9390546875, "critic_loss": 3.3184618673324584, "actor_loss": -46.578552978515624, "actor_target_entropy": -2.0, "actor_entropy": 1.4933203802108765, "alpha_loss": 0.018072663160972297, "alpha_value": 0.08557833984465744, "duration": 75.87985968589783, "step": 6500}
{"episode_reward": 4.0, "episode": 27.0, "batch_reward": 0.92271875, "critic_loss": 3.1595601043701174, "actor_loss": -48.690958129882816, "actor_target_entropy": -2.0, "actor_entropy": 1.496306987762451, "alpha_loss": 0.01696106343343854, "alpha_value": 0.085407630771064, "duration": 75.87712216377258, "step": 6750}
{"episode_reward": 183.0, "episode": 28.0, "batch_reward": 0.9004765625, "critic_loss": 3.399654035568237, "actor_loss": -50.77846878051758, "actor_target_entropy": -2.0, "actor_entropy": 1.4628198165893556, "alpha_loss": 0.012124402356334031, "alpha_value": 0.0852416269439542, "duration": 75.84323191642761, "step": 7000}
{"episode_reward": 211.0, "episode": 29.0, "batch_reward": 0.969203125, "critic_loss": 3.3740217084884643, "actor_loss": -54.75213394165039, "actor_target_entropy": -2.0, "actor_entropy": 1.3872790594100952, "alpha_loss": -0.0008889723643660545, "alpha_value": 0.08515642168250974, "duration": 75.8006739616394, "step": 7250}
{"episode_reward": 931.0, "episode": 30.0, "batch_reward": 1.0473125, "critic_loss": 3.5675063743591306, "actor_loss": -58.69975485229492, "actor_target_entropy": -2.0, "actor_entropy": 1.2666005992889404, "alpha_loss": -0.014070034044794738, "alpha_value": 0.0852690375475471, "duration": 75.93327713012695, "step": 7500}
{"episode_reward": 881.0, "episode": 31.0, "batch_reward": 1.081390625, "critic_loss": 3.7840762462615967, "actor_loss": -62.38513897705078, "actor_target_entropy": -2.0, "actor_entropy": 1.186881079673767, "alpha_loss": -0.011580851934850216, "alpha_value": 0.08543559327267393, "duration": 75.84258389472961, "step": 7750}
{"episode_reward": 49.0, "episode": 32.0, "batch_reward": 1.0794609375, "critic_loss": 3.9120139179229736, "actor_loss": -64.76770498657227, "actor_target_entropy": -2.0, "actor_entropy": 1.150724895954132, "alpha_loss": -0.015769246252253653, "alpha_value": 0.08563690274532103, "duration": 75.90032529830933, "step": 8000}
{"episode_reward": 641.0, "episode": 33.0, "batch_reward": 1.15334375, "critic_loss": 3.590568060874939, "actor_loss": -68.50315017700196, "actor_target_entropy": -2.0, "actor_entropy": 1.0662092266082763, "alpha_loss": -0.020543899235315622, "alpha_value": 0.0859169633069475, "duration": 75.88141107559204, "step": 8250}
{"episode_reward": 960.0, "episode": 34.0, "batch_reward": 1.2102890625, "critic_loss": 3.86647380065918, "actor_loss": -72.49083502197266, "actor_target_entropy": -2.0, "actor_entropy": 1.0450880246162415, "alpha_loss": -0.021397887613624333, "alpha_value": 0.08627442451911442, "duration": 75.92174410820007, "step": 8500}
{"episode_reward": 780.0, "episode": 35.0, "batch_reward": 1.283328125, "critic_loss": 4.049578994750976, "actor_loss": -76.46605065917969, "actor_target_entropy": -2.0, "actor_entropy": 1.0463119401931762, "alpha_loss": -0.021913506234064697, "alpha_value": 0.08665102722791172, "duration": 75.89640879631042, "step": 8750}
{"episode_reward": 961.0, "episode": 36.0, "batch_reward": 1.3599921875, "critic_loss": 3.963030926704407, "actor_loss": -80.18193170166016, "actor_target_entropy": -2.0, "actor_entropy": 1.0044138555526734, "alpha_loss": -0.021709675271995365, "alpha_value": 0.08703801675072599, "duration": 75.89753437042236, "step": 9000}
{"episode_reward": 975.0, "episode": 37.0, "batch_reward": 1.3641328125, "critic_loss": 3.686092674255371, "actor_loss": -83.91969201660156, "actor_target_entropy": -2.0, "actor_entropy": 1.0031657729148864, "alpha_loss": -0.026800836119800806, "alpha_value": 0.08751682943776212, "duration": 75.8954861164093, "step": 9250}
{"episode_reward": 0.0, "episode": 38.0, "batch_reward": 1.3880703125, "critic_loss": 3.627520615577698, "actor_loss": -88.17388336181641, "actor_target_entropy": -2.0, "actor_entropy": 1.0295490856170655, "alpha_loss": -0.026679175203200428, "alpha_value": 0.08807522602552045, "duration": 75.89515209197998, "step": 9500}
{"episode_reward": 976.0, "episode": 39.0, "batch_reward": 1.4545859375, "critic_loss": 3.5756762189865112, "actor_loss": -92.07064086914062, "actor_target_entropy": -2.0, "actor_entropy": 1.022881570339203, "alpha_loss": -0.02604131251387298, "alpha_value": 0.08861914862879916, "duration": 75.88215279579163, "step": 9750}
{"episode_reward": 882.0, "episode": 40.0, "batch_reward": 1.472078125, "critic_loss": 3.86440691947937, "actor_loss": -95.00727893066406, "actor_target_entropy": -2.0, "actor_entropy": 1.0174359784126281, "alpha_loss": -0.019781688719056546, "alpha_value": 0.08916784921228912, "step": 10000}
{"duration": 93.71496748924255, "step": 10000}
{"episode_reward": 464.0, "episode": 41.0, "batch_reward": 1.5210078125, "critic_loss": 3.6164276962280275, "actor_loss": -98.42686987304687, "actor_target_entropy": -2.0, "actor_entropy": 1.0173517169952393, "alpha_loss": -0.02305794064886868, "alpha_value": 0.08970285659435931, "duration": 75.52185225486755, "step": 10250}
{"episode_reward": 889.0, "episode": 42.0, "batch_reward": 1.571328125, "critic_loss": 4.095319614410401, "actor_loss": -102.36198919677734, "actor_target_entropy": -2.0, "actor_entropy": 1.0233623476028442, "alpha_loss": -0.019672399953007697, "alpha_value": 0.09019141464673233, "duration": 75.80714535713196, "step": 10500}
{"episode_reward": 987.0, "episode": 43.0, "batch_reward": 1.592140625, "critic_loss": 3.750637354850769, "actor_loss": -106.81798742675781, "actor_target_entropy": -2.0, "actor_entropy": 1.0082173867225648, "alpha_loss": -0.021177831046283246, "alpha_value": 0.09075267068635626, "duration": 75.8220272064209, "step": 10750}
{"episode_reward": 578.0, "episode": 44.0, "batch_reward": 1.5989453125, "critic_loss": 3.9962360954284666, "actor_loss": -109.3584730834961, "actor_target_entropy": -2.0, "actor_entropy": 1.0194436531066895, "alpha_loss": -0.020036417255178095, "alpha_value": 0.09133576707811364, "duration": 75.82779145240784, "step": 11000}
{"episode_reward": 12.0, "episode": 45.0, "batch_reward": 1.5898828125, "critic_loss": 4.431050579071045, "actor_loss": -111.3708267211914, "actor_target_entropy": -2.0, "actor_entropy": 1.017352740764618, "alpha_loss": -0.013061708051245659, "alpha_value": 0.09180835995328265, "duration": 75.89450788497925, "step": 11250}
{"episode_reward": 717.0, "episode": 46.0, "batch_reward": 1.6267109375, "critic_loss": 4.136743274688721, "actor_loss": -114.92631689453125, "actor_target_entropy": -2.0, "actor_entropy": 1.0021788320541383, "alpha_loss": -0.01643646314740181, "alpha_value": 0.09226462424054457, "duration": 75.86012053489685, "step": 11500}
{"episode_reward": 987.0, "episode": 47.0, "batch_reward": 1.6360390625, "critic_loss": 5.352519933700561, "actor_loss": -118.45531237792969, "actor_target_entropy": -2.0, "actor_entropy": 1.0232302227020265, "alpha_loss": -0.020034695876762272, "alpha_value": 0.0928239090492545, "duration": 75.9305191040039, "step": 11750}
{"episode_reward": 19.0, "episode": 48.0, "batch_reward": 1.6384921875, "critic_loss": 5.368594200134277, "actor_loss": -122.04390307617187, "actor_target_entropy": -2.0, "actor_entropy": 1.0258063945770264, "alpha_loss": -0.017206171847879887, "alpha_value": 0.09349071749364268, "duration": 75.90902400016785, "step": 12000}
{"episode_reward": 933.0, "episode": 49.0, "batch_reward": 1.685328125, "critic_loss": 4.947866147994995, "actor_loss": -125.67895477294923, "actor_target_entropy": -2.0, "actor_entropy": 0.9903521385192872, "alpha_loss": -0.01476501166075468, "alpha_value": 0.09406343522151209, "duration": 75.8969361782074, "step": 12250}
{"episode_reward": 896.0, "episode": 50.0, "batch_reward": 1.730640625, "critic_loss": 5.264295606613159, "actor_loss": -128.84989239501954, "actor_target_entropy": -2.0, "actor_entropy": 0.984839518070221, "alpha_loss": -0.014857352651655675, "alpha_value": 0.09460493435952234, "duration": 75.9162745475769, "step": 12500}
{"episode_reward": 944.0, "episode": 51.0, "batch_reward": 1.72784375, "critic_loss": 4.482267137527466, "actor_loss": -131.0892550048828, "actor_target_entropy": -2.0, "actor_entropy": 0.9607502040863037, "alpha_loss": -0.005825059929862619, "alpha_value": 0.09506116844297688, "duration": 75.90222382545471, "step": 12750}
{"episode_reward": 0.0, "episode": 52.0, "batch_reward": 1.71290625, "critic_loss": 5.102808712005615, "actor_loss": -133.09453845214844, "actor_target_entropy": -2.0, "actor_entropy": 0.9292503471374511, "alpha_loss": 0.0014991956520825625, "alpha_value": 0.09513166733333898, "duration": 75.85454487800598, "step": 13000}
{"episode_reward": 207.0, "episode": 53.0, "batch_reward": 1.684875, "critic_loss": 5.425241737365723, "actor_loss": -135.0343996582031, "actor_target_entropy": -2.0, "actor_entropy": 0.9348549551963806, "alpha_loss": 0.0036943813525140284, "alpha_value": 0.09497257004584497, "duration": 75.87402582168579, "step": 13250}
{"episode_reward": 0.0, "episode": 54.0, "batch_reward": 1.6577578125, "critic_loss": 6.63558286857605, "actor_loss": -135.85029724121094, "actor_target_entropy": -2.0, "actor_entropy": 0.9768678941726685, "alpha_loss": 0.0025179003514349462, "alpha_value": 0.0949139009912479, "duration": 75.87595009803772, "step": 13500}
{"episode_reward": 52.0, "episode": 55.0, "batch_reward": 1.6530078125, "critic_loss": 5.99105770111084, "actor_loss": -137.98934411621093, "actor_target_entropy": -2.0, "actor_entropy": 0.9974374585151672, "alpha_loss": 0.011229285570792854, "alpha_value": 0.09457413346844054, "duration": 75.92965292930603, "step": 13750}
{"episode_reward": 968.0, "episode": 56.0, "batch_reward": 1.67240625, "critic_loss": 5.717586417198181, "actor_loss": -141.20252429199218, "actor_target_entropy": -2.0, "actor_entropy": 1.0108803572654723, "alpha_loss": 0.010842675190418958, "alpha_value": 0.09397440476268992, "duration": 75.88350772857666, "step": 14000}
{"episode_reward": 0.0, "episode": 57.0, "batch_reward": 1.6629609375, "critic_loss": 6.652894060134888, "actor_loss": -143.89915539550782, "actor_target_entropy": -2.0, "actor_entropy": 0.9901253533363342, "alpha_loss": 0.012173481365665793, "alpha_value": 0.09336075470223003, "duration": 75.91122961044312, "step": 14250}
{"episode_reward": 982.0, "episode": 58.0, "batch_reward": 1.666515625, "critic_loss": 7.804463499069214, "actor_loss": -146.1775439453125, "actor_target_entropy": -2.0, "actor_entropy": 1.0128224897384643, "alpha_loss": 0.011343684520572423, "alpha_value": 0.09288433136632046, "duration": 75.87408661842346, "step": 14500}
{"episode_reward": 5.0, "episode": 59.0, "batch_reward": 1.6398984375, "critic_loss": 6.508846591949463, "actor_loss": -146.9902908935547, "actor_target_entropy": -2.0, "actor_entropy": 0.9577195138931275, "alpha_loss": 0.008288170848973096, "alpha_value": 0.0922289152437582, "duration": 75.88200068473816, "step": 14750}
{"episode_reward": 175.0, "episode": 60.0, "batch_reward": 1.6635546875, "critic_loss": 5.0664390230178835, "actor_loss": -149.575314453125, "actor_target_entropy": -2.0, "actor_entropy": 0.9537475557327271, "alpha_loss": 0.004575255228206516, "alpha_value": 0.09191518562245396, "step": 15000}
{"duration": 93.78905367851257, "step": 15000}
{"episode_reward": 873.0, "episode": 61.0, "batch_reward": 1.6909921875, "critic_loss": 6.791666407585144, "actor_loss": -152.3609141845703, "actor_target_entropy": -2.0, "actor_entropy": 0.9262513270378113, "alpha_loss": 0.004077888607978821, "alpha_value": 0.09165377656643216, "duration": 75.59922099113464, "step": 15250}
{"episode_reward": 980.0, "episode": 62.0, "batch_reward": 1.6948125, "critic_loss": 5.6116225099563595, "actor_loss": -154.20449096679687, "actor_target_entropy": -2.0, "actor_entropy": 0.9063576374053955, "alpha_loss": 0.0010261203981935978, "alpha_value": 0.0915339126305369, "duration": 75.53605961799622, "step": 15500}
{"episode_reward": 0.0, "episode": 63.0, "batch_reward": 1.6661328125, "critic_loss": 5.20041770362854, "actor_loss": -155.90432165527343, "actor_target_entropy": -2.0, "actor_entropy": 0.9378380308151245, "alpha_loss": 0.005034689196385443, "alpha_value": 0.09140611746369767, "duration": 75.73498249053955, "step": 15750}
{"episode_reward": 0.0, "episode": 64.0, "batch_reward": 1.671078125, "critic_loss": 7.462800631523132, "actor_loss": -157.72264147949218, "actor_target_entropy": -2.0, "actor_entropy": 0.9502888073921204, "alpha_loss": 0.0066038778629153964, "alpha_value": 0.09095165286058607, "duration": 75.84834575653076, "step": 16000}
{"episode_reward": 894.0, "episode": 65.0, "batch_reward": 1.70596875, "critic_loss": 5.100395520210266, "actor_loss": -160.23449853515626, "actor_target_entropy": -2.0, "actor_entropy": 0.8942888541221619, "alpha_loss": 0.0097021198682487, "alpha_value": 0.0903999009524687, "duration": 75.79494881629944, "step": 16250}
{"episode_reward": 976.0, "episode": 66.0, "batch_reward": 1.717859375, "critic_loss": 5.70537805557251, "actor_loss": -162.7551378173828, "actor_target_entropy": -2.0, "actor_entropy": 0.855946216583252, "alpha_loss": 0.003834274297580123, "alpha_value": 0.09002559730485378, "duration": 75.75248980522156, "step": 16500}
{"episode_reward": 0.0, "episode": 67.0, "batch_reward": 1.7047109375, "critic_loss": 6.658305054664612, "actor_loss": -163.72898474121095, "actor_target_entropy": -2.0, "actor_entropy": 0.8174089841842651, "alpha_loss": 0.005869519901461899, "alpha_value": 0.08963180874922132, "duration": 75.8077700138092, "step": 16750}
{"episode_reward": 966.0, "episode": 68.0, "batch_reward": 1.7453359375, "critic_loss": 11.536845460891724, "actor_loss": -165.93999597167968, "actor_target_entropy": -2.0, "actor_entropy": 0.9150147895812988, "alpha_loss": 0.0020267337532714007, "alpha_value": 0.0893778809345016, "duration": 75.83226799964905, "step": 17000}
{"episode_reward": 987.0, "episode": 69.0, "batch_reward": 1.7717890625, "critic_loss": 6.9712288951873775, "actor_loss": -168.97839392089844, "actor_target_entropy": -2.0, "actor_entropy": 0.894057665348053, "alpha_loss": 0.004774939482100308, "alpha_value": 0.0890861990539456, "duration": 75.7861852645874, "step": 17250}
{"episode_reward": 961.0, "episode": 70.0, "batch_reward": 1.8066484375, "critic_loss": 6.551233158111573, "actor_loss": -171.97947961425783, "actor_target_entropy": -2.0, "actor_entropy": 0.8435273170471191, "alpha_loss": 0.003973812889307737, "alpha_value": 0.08877157013388191, "duration": 75.81274485588074, "step": 17500}
{"episode_reward": 924.0, "episode": 71.0, "batch_reward": 1.8208046875, "critic_loss": 6.506885303497315, "actor_loss": -174.05602770996094, "actor_target_entropy": -2.0, "actor_entropy": 0.8307885308265686, "alpha_loss": 0.005007105896249414, "alpha_value": 0.08847508330825658, "duration": 75.83285808563232, "step": 17750}
{"episode_reward": 840.0, "episode": 72.0, "batch_reward": 1.84959375, "critic_loss": 8.434652473449708, "actor_loss": -176.06882360839845, "actor_target_entropy": -2.0, "actor_entropy": 0.8012821946144104, "alpha_loss": 0.004867832064628601, "alpha_value": 0.08811061239717644, "duration": 75.75158023834229, "step": 18000}
{"episode_reward": 929.0, "episode": 73.0, "batch_reward": 1.880671875, "critic_loss": 6.732557555198669, "actor_loss": -178.24649841308593, "actor_target_entropy": -2.0, "actor_entropy": 0.7622916083335877, "alpha_loss": 0.010509139318950474, "alpha_value": 0.08763607183102907, "duration": 75.79344725608826, "step": 18250}
{"episode_reward": 955.0, "episode": 74.0, "batch_reward": 1.8860703125, "critic_loss": 16.036659009933473, "actor_loss": -180.40454516601562, "actor_target_entropy": -2.0, "actor_entropy": 0.8364819388389587, "alpha_loss": 0.006667203127406538, "alpha_value": 0.08685941991442171, "duration": 75.74644899368286, "step": 18500}
{"episode_reward": 0.0, "episode": 75.0, "batch_reward": 1.8895859375, "critic_loss": 5.448434326171875, "actor_loss": -183.23846862792968, "actor_target_entropy": -2.0, "actor_entropy": 0.7297354898452759, "alpha_loss": 0.008837153068743647, "alpha_value": 0.08634322064978238, "duration": 75.7990608215332, "step": 18750}
{"episode_reward": 986.0, "episode": 76.0, "batch_reward": 1.90440625, "critic_loss": 5.221842804908753, "actor_loss": -185.42844738769531, "actor_target_entropy": -2.0, "actor_entropy": 0.6985720300674438, "alpha_loss": 0.0057864766288548706, "alpha_value": 0.0857319325845474, "duration": 75.85063457489014, "step": 19000}
{"episode_reward": 953.0, "episode": 77.0, "batch_reward": 1.91428125, "critic_loss": 5.143811388015747, "actor_loss": -187.87569274902344, "actor_target_entropy": -2.0, "actor_entropy": 0.678659107208252, "alpha_loss": 0.010240013011731207, "alpha_value": 0.08513960441957302, "duration": 75.81334686279297, "step": 19250}
{"episode_reward": 3.0, "episode": 78.0, "batch_reward": 1.89746875, "critic_loss": 5.32316068649292, "actor_loss": -188.99318139648437, "actor_target_entropy": -2.0, "actor_entropy": 0.6938564319610596, "alpha_loss": 0.010472157989628613, "alpha_value": 0.08435990382445657, "duration": 75.76021885871887, "step": 19500}
{"episode_reward": 848.0, "episode": 79.0, "batch_reward": 1.901171875, "critic_loss": 5.033295946121216, "actor_loss": -190.51802514648438, "actor_target_entropy": -2.0, "actor_entropy": 0.7327218866348266, "alpha_loss": 0.009052589837461709, "alpha_value": 0.08359850969465675, "duration": 75.79211139678955, "step": 19750}
{"episode_reward": 0.0, "episode": 80.0, "batch_reward": 1.8938125, "critic_loss": 5.638508981704712, "actor_loss": -191.8926661376953, "actor_target_entropy": -2.0, "actor_entropy": 0.7427598376274109, "alpha_loss": 0.004829405404627323, "alpha_value": 0.08309470639449082, "step": 20000}
{"duration": 93.80895948410034, "step": 20000}
{"episode_reward": 980.0, "episode": 81.0, "batch_reward": 1.922328125, "critic_loss": 5.237737559318543, "actor_loss": -194.36695190429688, "actor_target_entropy": -2.0, "actor_entropy": 0.7475995626449585, "alpha_loss": 0.0075647858073934916, "alpha_value": 0.08270275078558267, "duration": 75.64598631858826, "step": 20250}
{"episode_reward": 1000.0, "episode": 82.0, "batch_reward": 1.9495, "critic_loss": 5.257163077354432, "actor_loss": -196.4127490234375, "actor_target_entropy": -2.0, "actor_entropy": 0.7449794931411743, "alpha_loss": 0.007292650036979467, "alpha_value": 0.08207537086755619, "duration": 75.49714136123657, "step": 20500}
{"episode_reward": 972.0, "episode": 83.0, "batch_reward": 1.957875, "critic_loss": 6.626929493904114, "actor_loss": -198.0729821777344, "actor_target_entropy": -2.0, "actor_entropy": 0.7296727023124695, "alpha_loss": 0.011008955047931522, "alpha_value": 0.08136719840856771, "duration": 75.66841721534729, "step": 20750}
{"episode_reward": 0.0, "episode": 84.0, "batch_reward": 1.9549375, "critic_loss": 8.888805488586426, "actor_loss": -198.92091552734374, "actor_target_entropy": -2.0, "actor_entropy": 0.7317334299087525, "alpha_loss": 0.011789482741151006, "alpha_value": 0.08052152564572733, "duration": 75.73219013214111, "step": 21000}
{"episode_reward": 935.0, "episode": 85.0, "batch_reward": 1.9573125, "critic_loss": 10.284198141098022, "actor_loss": -200.5071463623047, "actor_target_entropy": -2.0, "actor_entropy": 0.7414774374961853, "alpha_loss": 0.00684337433706969, "alpha_value": 0.07982547555693463, "duration": 75.725013256073, "step": 21250}
{"episode_reward": 0.0, "episode": 86.0, "batch_reward": 1.9508046875, "critic_loss": 6.211049535751343, "actor_loss": -202.64098779296876, "actor_target_entropy": -2.0, "actor_entropy": 0.7294494533538818, "alpha_loss": 0.004912999371998012, "alpha_value": 0.07937611295403679, "duration": 75.8666033744812, "step": 21500}
{"episode_reward": 947.0, "episode": 87.0, "batch_reward": 1.9638359375, "critic_loss": 7.147075680732727, "actor_loss": -204.61698937988282, "actor_target_entropy": -2.0, "actor_entropy": 0.6941577172279358, "alpha_loss": 0.0020452005062252285, "alpha_value": 0.07913981402095338, "duration": 75.79438281059265, "step": 21750}
{"episode_reward": 961.0, "episode": 88.0, "batch_reward": 1.997875, "critic_loss": 7.424051473617554, "actor_loss": -207.31158642578126, "actor_target_entropy": -2.0, "actor_entropy": 0.7157722811698913, "alpha_loss": 0.0035422105612233283, "alpha_value": 0.07890938217344694, "duration": 75.83090305328369, "step": 22000}
{"episode_reward": 972.0, "episode": 89.0, "batch_reward": 1.993859375, "critic_loss": 6.092770577430725, "actor_loss": -209.17174047851563, "actor_target_entropy": -2.0, "actor_entropy": 0.6542908749580383, "alpha_loss": 0.005910430726595223, "alpha_value": 0.0785710782581552, "duration": 75.80583381652832, "step": 22250}
{"episode_reward": 0.0, "episode": 90.0, "batch_reward": 1.9868984375, "critic_loss": 8.461806893348694, "actor_loss": -210.98770129394532, "actor_target_entropy": -2.0, "actor_entropy": 0.6716915645599365, "alpha_loss": 0.002436529827769846, "alpha_value": 0.07825270992584032, "duration": 75.85200667381287, "step": 22500}
{"episode_reward": 967.0, "episode": 91.0, "batch_reward": 2.0053671875, "critic_loss": 18.873972404479982, "actor_loss": -212.6747021484375, "actor_target_entropy": -2.0, "actor_entropy": 0.6432457752227784, "alpha_loss": 0.006319010084029287, "alpha_value": 0.07797964288797357, "duration": 75.76506805419922, "step": 22750}
{"episode_reward": 979.0, "episode": 92.0, "batch_reward": 2.02903125, "critic_loss": 20.482007829666138, "actor_loss": -214.27887719726561, "actor_target_entropy": -2.0, "actor_entropy": 0.6781515629291535, "alpha_loss": 0.0013915701443329453, "alpha_value": 0.07749549358413987, "duration": 75.84390592575073, "step": 23000}
{"episode_reward": 929.0, "episode": 93.0, "batch_reward": 2.05425, "critic_loss": 23.788037940979002, "actor_loss": -216.55944104003908, "actor_target_entropy": -2.0, "actor_entropy": 0.6902809672355652, "alpha_loss": -0.0013200970366597175, "alpha_value": 0.0775021631808672, "duration": 84.69643211364746, "step": 23250}
{"episode_reward": 971.0, "episode": 94.0, "batch_reward": 2.0776171875, "critic_loss": 34.42959299087524, "actor_loss": -218.4868771972656, "actor_target_entropy": -2.0, "actor_entropy": 0.7195978302955628, "alpha_loss": 0.002502471040934324, "alpha_value": 0.07740567956294035, "duration": 106.78997421264648, "step": 23500}
{"episode_reward": 904.0, "episode": 95.0, "batch_reward": 2.0904140625, "critic_loss": 31.866590475082397, "actor_loss": -219.92956591796874, "actor_target_entropy": -2.0, "actor_entropy": 0.64079842877388, "alpha_loss": -0.00493806447647512, "alpha_value": 0.07752049731965518, "duration": 80.41600108146667, "step": 23750}
{"episode_reward": 998.0, "episode": 96.0, "batch_reward": 2.0980703125, "critic_loss": 67.81390573501587, "actor_loss": -222.02648205566408, "actor_target_entropy": -2.0, "actor_entropy": 0.672097562789917, "alpha_loss": -0.023965570118278264, "alpha_value": 0.07858837237486908, "duration": 77.85726499557495, "step": 24000}
{"episode_reward": 986.0, "episode": 97.0, "batch_reward": 2.1205234375, "critic_loss": 142.77980432891846, "actor_loss": -226.36549169921875, "actor_target_entropy": -2.0, "actor_entropy": 0.7094025790691376, "alpha_loss": -0.04946884578466416, "alpha_value": 0.08093099670929782, "duration": 76.20026659965515, "step": 24250}
{"episode_reward": 920.0, "episode": 98.0, "batch_reward": 2.136875, "critic_loss": 137.45489958953857, "actor_loss": -231.75308740234374, "actor_target_entropy": -2.0, "actor_entropy": 0.5234266107082367, "alpha_loss": -0.056611008241772655, "alpha_value": 0.0830148235719284, "duration": 76.03921723365784, "step": 24500}
{"episode_reward": 748.0, "episode": 99.0, "batch_reward": 2.14090625, "critic_loss": 178.68630590820314, "actor_loss": -236.22051538085938, "actor_target_entropy": -2.0, "actor_entropy": 0.4290083956420422, "alpha_loss": -0.0697521723806858, "alpha_value": 0.08521946361001358, "duration": 77.00428581237793, "step": 24750}
{"episode_reward": 9.0, "episode": 100.0, "batch_reward": 2.116671875, "critic_loss": 171.0682727355957, "actor_loss": -237.77501635742186, "actor_target_entropy": -2.0, "actor_entropy": 0.40404592609405515, "alpha_loss": -0.05647275531291961, "alpha_value": 0.08709959142735287, "step": 25000}
{"duration": 93.92748641967773, "step": 25000}
{"episode_reward": 5.0, "episode": 101.0, "batch_reward": 2.0904921875, "critic_loss": 166.47642431640625, "actor_loss": -238.52820532226562, "actor_target_entropy": -2.0, "actor_entropy": 0.4385435473918915, "alpha_loss": -0.04331678984314203, "alpha_value": 0.08849471658563254, "duration": 76.00202345848083, "step": 25250}
{"episode_reward": 11.0, "episode": 102.0, "batch_reward": 2.073875, "critic_loss": 113.6405085067749, "actor_loss": -240.7631953125, "actor_target_entropy": -2.0, "actor_entropy": 0.4816733615398407, "alpha_loss": -0.041882828265428544, "alpha_value": 0.08958817355406089, "duration": 75.70463418960571, "step": 25500}
{"episode_reward": 0.0, "episode": 103.0, "batch_reward": 2.0564921875, "critic_loss": 99.14279042816162, "actor_loss": -240.30453356933594, "actor_target_entropy": -2.0, "actor_entropy": 0.4397091822624207, "alpha_loss": -0.04196744078397751, "alpha_value": 0.0907342769614808, "duration": 76.51268887519836, "step": 25750}
{"episode_reward": 683.0, "episode": 104.0, "batch_reward": 2.05028125, "critic_loss": 91.53122483062744, "actor_loss": -241.20110205078126, "actor_target_entropy": -2.0, "actor_entropy": 0.4478143116235733, "alpha_loss": -0.04562594929337502, "alpha_value": 0.09191603770554177, "duration": 75.75221490859985, "step": 26000}
{"episode_reward": 30.0, "episode": 105.0, "batch_reward": 2.0396015625, "critic_loss": 97.47552054595947, "actor_loss": -242.8070124511719, "actor_target_entropy": -2.0, "actor_entropy": 0.43243034958839416, "alpha_loss": -0.03285907792299986, "alpha_value": 0.09301191444333426, "duration": 75.86017394065857, "step": 26250}
{"episode_reward": 608.0, "episode": 106.0, "batch_reward": 2.0592890625, "critic_loss": 92.36865884399414, "actor_loss": -244.70291711425782, "actor_target_entropy": -2.0, "actor_entropy": 0.44732515096664427, "alpha_loss": -0.03237142276018858, "alpha_value": 0.09390299758072287, "duration": 75.71615958213806, "step": 26500}
{"episode_reward": 884.0, "episode": 107.0, "batch_reward": 2.05990625, "critic_loss": 80.82657215881348, "actor_loss": -246.31220971679687, "actor_target_entropy": -2.0, "actor_entropy": 0.46031904077529906, "alpha_loss": -0.044594249539077285, "alpha_value": 0.09500045212821184, "duration": 75.95758628845215, "step": 26750}
{"episode_reward": 0.0, "episode": 108.0, "batch_reward": 2.0528125, "critic_loss": 97.42495664978027, "actor_loss": -250.96950988769532, "actor_target_entropy": -2.0, "actor_entropy": 0.47428614675998687, "alpha_loss": -0.05315523560345173, "alpha_value": 0.0963508960188292, "duration": 75.75047016143799, "step": 27000}
{"episode_reward": 985.0, "episode": 109.0, "batch_reward": 2.0604453125, "critic_loss": 82.27150814056397, "actor_loss": -253.97720959472656, "actor_target_entropy": -2.0, "actor_entropy": 0.43377664852142334, "alpha_loss": -0.04461656995862722, "alpha_value": 0.09769623170829816, "duration": 75.90932631492615, "step": 27250}
{"episode_reward": 446.0, "episode": 110.0, "batch_reward": 2.060296875, "critic_loss": 109.60617223358155, "actor_loss": -256.2464338378906, "actor_target_entropy": -2.0, "actor_entropy": 0.5420915331840516, "alpha_loss": -0.05190407033264637, "alpha_value": 0.09909083890690931, "duration": 75.72347164154053, "step": 27500}
{"episode_reward": 0.0, "episode": 111.0, "batch_reward": 2.034875, "critic_loss": 118.16239944458007, "actor_loss": -256.70842553710935, "actor_target_entropy": -2.0, "actor_entropy": 0.46845935583114623, "alpha_loss": -0.04641146498918533, "alpha_value": 0.10040042925054447, "duration": 75.887211561203, "step": 27750}
{"episode_reward": 652.0, "episode": 112.0, "batch_reward": 2.0340390625, "critic_loss": 91.71978276062012, "actor_loss": -255.6131971435547, "actor_target_entropy": -2.0, "actor_entropy": 0.43765829277038576, "alpha_loss": -0.021857139175757767, "alpha_value": 0.10147620804432358, "duration": 75.75460124015808, "step": 28000}
{"episode_reward": 0.0, "episode": 113.0, "batch_reward": 2.0344375, "critic_loss": 84.04057671356202, "actor_loss": -256.1824334716797, "actor_target_entropy": -2.0, "actor_entropy": 0.49680660009384153, "alpha_loss": -0.020633403327316047, "alpha_value": 0.10199562074669559, "duration": 76.04078507423401, "step": 28250}
{"episode_reward": 921.0, "episode": 114.0, "batch_reward": 2.0355703125, "critic_loss": 94.05007595825195, "actor_loss": -257.7040079345703, "actor_target_entropy": -2.0, "actor_entropy": 0.544335524559021, "alpha_loss": -0.017193165060132742, "alpha_value": 0.10253678004261096, "duration": 75.90972352027893, "step": 28500}
{"episode_reward": 5.0, "episode": 115.0, "batch_reward": 2.0126953125, "critic_loss": 90.97165491485596, "actor_loss": -258.7864445800781, "actor_target_entropy": -2.0, "actor_entropy": 0.5365569014549255, "alpha_loss": -0.02133141266182065, "alpha_value": 0.10308313203605764, "duration": 76.09984827041626, "step": 28750}
{"episode_reward": 0.0, "episode": 116.0, "batch_reward": 2.018625, "critic_loss": 105.74201663970948, "actor_loss": -263.0478563232422, "actor_target_entropy": -2.0, "actor_entropy": 0.5522640874385834, "alpha_loss": -0.03250377969443798, "alpha_value": 0.10406101834044248, "duration": 75.96833539009094, "step": 29000}
{"episode_reward": 959.0, "episode": 117.0, "batch_reward": 2.0335, "critic_loss": 107.51210609436035, "actor_loss": -266.34399609375, "actor_target_entropy": -2.0, "actor_entropy": 0.5454015843868255, "alpha_loss": -0.03990432778187096, "alpha_value": 0.10527261757551942, "duration": 76.15472054481506, "step": 29250}
{"episode_reward": 927.0, "episode": 118.0, "batch_reward": 2.0184375, "critic_loss": 117.65262036132812, "actor_loss": -269.36722033691404, "actor_target_entropy": -2.0, "actor_entropy": 0.559797236442566, "alpha_loss": -0.04477832015044987, "alpha_value": 0.10670864048967306, "duration": 75.77755689620972, "step": 29500}
{"episode_reward": 0.0, "episode": 119.0, "batch_reward": 2.0095, "critic_loss": 121.2289971923828, "actor_loss": -271.7981722412109, "actor_target_entropy": -2.0, "actor_entropy": 0.5745892257690429, "alpha_loss": -0.05091000708937645, "alpha_value": 0.10833234638788224, "duration": 75.75866365432739, "step": 29750}
{"episode_reward": 0.0, "episode": 120.0, "batch_reward": 1.9941328125, "critic_loss": 135.82534301757812, "actor_loss": -276.7692352294922, "actor_target_entropy": -2.0, "actor_entropy": 0.581981550693512, "alpha_loss": -0.05531180460751057, "alpha_value": 0.11013677467426068, "step": 30000}
{"duration": 93.7162013053894, "step": 30000}
{"episode_reward": 49.0, "episode": 121.0, "batch_reward": 1.9836015625, "critic_loss": 117.02171694946288, "actor_loss": -282.59240942382814, "actor_target_entropy": -2.0, "actor_entropy": 0.5747905402183533, "alpha_loss": -0.04952304611355066, "alpha_value": 0.11172214707515057, "duration": 75.68180251121521, "step": 30250}
{"episode_reward": 0.0, "episode": 122.0, "batch_reward": 1.9739296875, "critic_loss": 120.76180636596679, "actor_loss": -292.4579287109375, "actor_target_entropy": -2.0, "actor_entropy": 0.5674508311748505, "alpha_loss": -0.04471975262090564, "alpha_value": 0.11319250278727717, "duration": 75.73779249191284, "step": 30500}
{"episode_reward": 0.0, "episode": 123.0, "batch_reward": 1.961171875, "critic_loss": 120.17915325927734, "actor_loss": -295.3344074707031, "actor_target_entropy": -2.0, "actor_entropy": 0.5654978489875794, "alpha_loss": -0.02830349032767117, "alpha_value": 0.11435180720828389, "duration": 75.51880526542664, "step": 30750}
{"episode_reward": 965.0, "episode": 124.0, "batch_reward": 1.9745078125, "critic_loss": 105.15027964782715, "actor_loss": -299.53301611328123, "actor_target_entropy": -2.0, "actor_entropy": 0.5303270888328552, "alpha_loss": -0.02960000866651535, "alpha_value": 0.11529680931236397, "duration": 75.78817510604858, "step": 31000}
{"episode_reward": 945.0, "episode": 125.0, "batch_reward": 1.9739453125, "critic_loss": 104.78244786071777, "actor_loss": -308.2185056152344, "actor_target_entropy": -2.0, "actor_entropy": 0.5852760615348815, "alpha_loss": -0.030669348791241644, "alpha_value": 0.1163271725291792, "duration": 75.73986315727234, "step": 31250}
{"episode_reward": 58.0, "episode": 126.0, "batch_reward": 1.97840625, "critic_loss": 89.85190609741211, "actor_loss": -310.6317983398437, "actor_target_entropy": -2.0, "actor_entropy": 0.5803980448246002, "alpha_loss": -0.026633102785795927, "alpha_value": 0.11728365066629157, "duration": 75.98424625396729, "step": 31500}
{"episode_reward": 765.0, "episode": 127.0, "batch_reward": 1.9776484375, "critic_loss": 77.80088638305664, "actor_loss": -314.745564453125, "actor_target_entropy": -2.0, "actor_entropy": 0.5810674464702607, "alpha_loss": -0.013984394289553165, "alpha_value": 0.11804903597963098, "duration": 75.90526962280273, "step": 31750}
{"episode_reward": 12.0, "episode": 128.0, "batch_reward": 1.95596875, "critic_loss": 63.16678291320801, "actor_loss": -318.9613271484375, "actor_target_entropy": -2.0, "actor_entropy": 0.6004378826618194, "alpha_loss": -0.009446403941139579, "alpha_value": 0.11854285980789461, "duration": 75.73203706741333, "step": 32000}
{"episode_reward": 0.0, "episode": 129.0, "batch_reward": 1.9565234375, "critic_loss": 58.12562107086182, "actor_loss": -317.8687487792969, "actor_target_entropy": -2.0, "actor_entropy": 0.6241214280128479, "alpha_loss": -0.002101554850116372, "alpha_value": 0.1187595329527206, "duration": 75.95544123649597, "step": 32250}
{"episode_reward": 893.0, "episode": 130.0, "batch_reward": 1.9503984375, "critic_loss": 51.51567615509033, "actor_loss": -320.70016186523435, "actor_target_entropy": -2.0, "actor_entropy": 0.6819969620704651, "alpha_loss": -0.0035313063561916353, "alpha_value": 0.1187799689074417, "duration": 75.82466268539429, "step": 32500}
{"episode_reward": 131.0, "episode": 131.0, "batch_reward": 1.951875, "critic_loss": 48.769024070739746, "actor_loss": -322.47634130859376, "actor_target_entropy": -2.0, "actor_entropy": 0.6859633126258851, "alpha_loss": -0.00433356676530093, "alpha_value": 0.11898272163073365, "duration": 76.73333501815796, "step": 32750}
{"episode_reward": 897.0, "episode": 132.0, "batch_reward": 1.9699140625, "critic_loss": 48.164585556030275, "actor_loss": -322.421732421875, "actor_target_entropy": -2.0, "actor_entropy": 0.7448234114646911, "alpha_loss": -0.0001682985620573163, "alpha_value": 0.11922326176667473, "duration": 75.87634754180908, "step": 33000}
{"episode_reward": 869.0, "episode": 133.0, "batch_reward": 1.9671328125, "critic_loss": 50.67387770080566, "actor_loss": -325.6825205078125, "actor_target_entropy": -2.0, "actor_entropy": 0.755829083442688, "alpha_loss": 0.005692311405204237, "alpha_value": 0.11895291101062795, "duration": 75.94221806526184, "step": 33250}
{"episode_reward": 0.0, "episode": 134.0, "batch_reward": 1.961265625, "critic_loss": 41.364643676757815, "actor_loss": -326.9889343261719, "actor_target_entropy": -2.0, "actor_entropy": 0.7823323788642883, "alpha_loss": 0.0017327086636796593, "alpha_value": 0.11875581530424166, "duration": 75.85231590270996, "step": 33500}
{"episode_reward": 749.0, "episode": 135.0, "batch_reward": 1.9616484375, "critic_loss": 44.15940357971191, "actor_loss": -328.24564575195313, "actor_target_entropy": -2.0, "actor_entropy": 0.7857799210548401, "alpha_loss": 0.0069465062711387875, "alpha_value": 0.11859545718230835, "duration": 75.76201748847961, "step": 33750}
{"episode_reward": 0.0, "episode": 136.0, "batch_reward": 1.9581015625, "critic_loss": 45.17675776672363, "actor_loss": -328.74944995117187, "actor_target_entropy": -2.0, "actor_entropy": 0.7866253728866577, "alpha_loss": 0.0029866730691865085, "alpha_value": 0.11824551108777555, "duration": 75.91953468322754, "step": 34000}
{"episode_reward": 913.0, "episode": 137.0, "batch_reward": 1.9726953125, "critic_loss": 39.760745155334476, "actor_loss": -327.4848735351562, "actor_target_entropy": -2.0, "actor_entropy": 0.7945865178108216, "alpha_loss": 0.006553205667063594, "alpha_value": 0.11801005116916233, "duration": 75.87371063232422, "step": 34250}
{"episode_reward": 688.0, "episode": 138.0, "batch_reward": 1.962984375, "critic_loss": 43.347658851623535, "actor_loss": -330.0194631347656, "actor_target_entropy": -2.0, "actor_entropy": 0.7760077605247497, "alpha_loss": 0.00554658579826355, "alpha_value": 0.11757858558387536, "duration": 75.89410829544067, "step": 34500}
{"episode_reward": 0.0, "episode": 139.0, "batch_reward": 1.9521484375, "critic_loss": 40.2607052230835, "actor_loss": -330.88501904296874, "actor_target_entropy": -2.0, "actor_entropy": 0.7671884126663208, "alpha_loss": 0.009950797739438712, "alpha_value": 0.11718067084448557, "duration": 75.8245701789856, "step": 34750}
{"episode_reward": 45.0, "episode": 140.0, "batch_reward": 1.942765625, "critic_loss": 45.28519123840332, "actor_loss": -330.08228247070315, "actor_target_entropy": -2.0, "actor_entropy": 0.7880929222106934, "alpha_loss": 0.012450123423710465, "alpha_value": 0.11647129378386557, "step": 35000}
{"duration": 93.83787107467651, "step": 35000}
{"episode_reward": 0.0, "episode": 141.0, "batch_reward": 1.9393515625, "critic_loss": 40.63461477661133, "actor_loss": -329.4162644042969, "actor_target_entropy": -2.0, "actor_entropy": 0.8001472797393799, "alpha_loss": 0.008180892263539135, "alpha_value": 0.11568938666319727, "duration": 75.74649548530579, "step": 35250}
{"episode_reward": 952.0, "episode": 142.0, "batch_reward": 1.9278828125, "critic_loss": 38.35631874847412, "actor_loss": -327.4715625, "actor_target_entropy": -2.0, "actor_entropy": 0.7895474481582642, "alpha_loss": 0.005453428892884403, "alpha_value": 0.11531278588128, "duration": 75.837970495224, "step": 35500}
{"episode_reward": 0.0, "episode": 143.0, "batch_reward": 1.92896875, "critic_loss": 40.394874717712405, "actor_loss": -328.23608178710936, "actor_target_entropy": -2.0, "actor_entropy": 0.821047933101654, "alpha_loss": 0.005872239105403423, "alpha_value": 0.11493957039099272, "duration": 75.66480660438538, "step": 35750}
{"episode_reward": 973.0, "episode": 144.0, "batch_reward": 1.950203125, "critic_loss": 37.077022735595705, "actor_loss": -328.8546162109375, "actor_target_entropy": -2.0, "actor_entropy": 0.7940538148880005, "alpha_loss": 0.004176575417630375, "alpha_value": 0.11452060025573352, "duration": 75.76790022850037, "step": 36000}
{"episode_reward": 886.0, "episode": 145.0, "batch_reward": 1.9426953125, "critic_loss": 37.28426316833496, "actor_loss": -331.83512890625, "actor_target_entropy": -2.0, "actor_entropy": 0.8174723596572876, "alpha_loss": 0.0007487197183072567, "alpha_value": 0.1143316828802564, "duration": 75.73397254943848, "step": 36250}
{"episode_reward": 0.0, "episode": 146.0, "batch_reward": 1.946828125, "critic_loss": 36.21110372161865, "actor_loss": -332.8423395996094, "actor_target_entropy": -2.0, "actor_entropy": 0.8286792402267456, "alpha_loss": -0.001785223875194788, "alpha_value": 0.1144213311967687, "duration": 75.76513481140137, "step": 36500}
{"episode_reward": 0.0, "episode": 147.0, "batch_reward": 1.9349296875, "critic_loss": 37.60419709777832, "actor_loss": -329.69785302734374, "actor_target_entropy": -2.0, "actor_entropy": 0.8366140723228455, "alpha_loss": 0.0051530296821147206, "alpha_value": 0.11427742897812075, "duration": 75.78925013542175, "step": 36750}
{"episode_reward": 813.0, "episode": 148.0, "batch_reward": 1.9350546875, "critic_loss": 42.114307975769044, "actor_loss": -332.12576513671877, "actor_target_entropy": -2.0, "actor_entropy": 0.8017521176338196, "alpha_loss": 0.005542718913406134, "alpha_value": 0.11383406488769762, "duration": 75.81125116348267, "step": 37000}
{"episode_reward": 433.0, "episode": 149.0, "batch_reward": 1.9281015625, "critic_loss": 38.56307484436035, "actor_loss": -334.96173779296873, "actor_target_entropy": -2.0, "actor_entropy": 0.7733743333816528, "alpha_loss": 0.007618828497827053, "alpha_value": 0.1133265769016759, "duration": 75.80956435203552, "step": 37250}
{"episode_reward": 0.0, "episode": 150.0, "batch_reward": 1.9245234375, "critic_loss": 37.56111368560791, "actor_loss": -331.9484765625, "actor_target_entropy": -2.0, "actor_entropy": 0.7900905866622925, "alpha_loss": -0.0007934057964012026, "alpha_value": 0.11307541259534419, "duration": 75.76377129554749, "step": 37500}
{"episode_reward": 321.0, "episode": 151.0, "batch_reward": 1.930453125, "critic_loss": 37.65228199768067, "actor_loss": -331.9951662597656, "actor_target_entropy": -2.0, "actor_entropy": 0.8193220834732056, "alpha_loss": 0.004029321984387934, "alpha_value": 0.11285311873687423, "duration": 75.81705641746521, "step": 37750}
{"episode_reward": 965.0, "episode": 152.0, "batch_reward": 1.92396875, "critic_loss": 37.29887464904785, "actor_loss": -333.81346948242185, "actor_target_entropy": -2.0, "actor_entropy": 0.8213834762573242, "alpha_loss": 0.0007634206935763359, "alpha_value": 0.11276778567025042, "duration": 75.92905879020691, "step": 38000}
{"episode_reward": 0.0, "episode": 153.0, "batch_reward": 1.908859375, "critic_loss": 35.25089183807373, "actor_loss": -332.90272436523435, "actor_target_entropy": -2.0, "actor_entropy": 0.8561277794837951, "alpha_loss": -0.0002299331594258547, "alpha_value": 0.11282277864266847, "duration": 75.82404685020447, "step": 38250}
{"episode_reward": 0.0, "episode": 154.0, "batch_reward": 1.9030078125, "critic_loss": 34.904502990722655, "actor_loss": -333.83864135742186, "actor_target_entropy": -2.0, "actor_entropy": 0.792541298866272, "alpha_loss": 0.008117592135444284, "alpha_value": 0.11244921583890798, "duration": 75.93086981773376, "step": 38500}
{"episode_reward": 4.0, "episode": 155.0, "batch_reward": 1.8829609375, "critic_loss": 35.35948361968994, "actor_loss": -334.02970166015626, "actor_target_entropy": -2.0, "actor_entropy": 0.7811887917518616, "alpha_loss": 0.00989761679712683, "alpha_value": 0.11151772349203051, "duration": 75.83292961120605, "step": 38750}
{"episode_reward": 0.0, "episode": 156.0, "batch_reward": 1.8814453125, "critic_loss": 32.16090439605713, "actor_loss": -334.0428256835938, "actor_target_entropy": -2.0, "actor_entropy": 0.7545277667045593, "alpha_loss": 0.013556230946443974, "alpha_value": 0.11046103896994935, "duration": 75.91119956970215, "step": 39000}
{"episode_reward": 7.0, "episode": 157.0, "batch_reward": 1.8599140625, "critic_loss": 33.74070629882812, "actor_loss": -333.29995751953123, "actor_target_entropy": -2.0, "actor_entropy": 0.7810159540176391, "alpha_loss": 0.0063352518556639556, "alpha_value": 0.10976008561159918, "duration": 75.7835636138916, "step": 39250}
{"episode_reward": 0.0, "episode": 158.0, "batch_reward": 1.8695625, "critic_loss": 35.538230560302736, "actor_loss": -335.3717741699219, "actor_target_entropy": -2.0, "actor_entropy": 0.7652599649429321, "alpha_loss": 0.007917298810556531, "alpha_value": 0.10913133251975796, "duration": 75.8516583442688, "step": 39500}
{"episode_reward": 969.0, "episode": 159.0, "batch_reward": 1.8833046875, "critic_loss": 33.314973899841306, "actor_loss": -335.0626884765625, "actor_target_entropy": -2.0, "actor_entropy": 0.7763152480125427, "alpha_loss": 0.004744223145768047, "alpha_value": 0.1085527474757441, "duration": 75.85880780220032, "step": 39750}
{"episode_reward": 928.0, "episode": 160.0, "batch_reward": 1.8895625, "critic_loss": 31.419596244812013, "actor_loss": -335.16701586914064, "actor_target_entropy": -2.0, "actor_entropy": 0.7233120899200439, "alpha_loss": 0.007286487120203674, "alpha_value": 0.10802383193453105, "step": 40000}
{"duration": 93.78551435470581, "step": 40000}
{"episode_reward": 849.0, "episode": 161.0, "batch_reward": 1.8931171875, "critic_loss": 32.911365936279296, "actor_loss": -336.59639038085936, "actor_target_entropy": -2.0, "actor_entropy": 0.7601123847961426, "alpha_loss": 0.006731218745000661, "alpha_value": 0.10743518305639918, "duration": 75.77769827842712, "step": 40250}
{"episode_reward": 897.0, "episode": 162.0, "batch_reward": 1.8898046875, "critic_loss": 34.243232124328614, "actor_loss": -336.24664916992185, "actor_target_entropy": -2.0, "actor_entropy": 0.7173104677200317, "alpha_loss": 0.00871599877346307, "alpha_value": 0.10669251581883253, "duration": 75.73255562782288, "step": 40500}
{"episode_reward": 0.0, "episode": 163.0, "batch_reward": 1.8979453125, "critic_loss": 31.966651458740234, "actor_loss": -338.08746826171875, "actor_target_entropy": -2.0, "actor_entropy": 0.7464258189201355, "alpha_loss": 0.0033251607031561433, "alpha_value": 0.10626305511762514, "duration": 75.66937828063965, "step": 40750}
{"episode_reward": 949.0, "episode": 164.0, "batch_reward": 1.89825, "critic_loss": 31.636786071777344, "actor_loss": -339.0247807617188, "actor_target_entropy": -2.0, "actor_entropy": 0.7438397727012634, "alpha_loss": 0.007238740339875221, "alpha_value": 0.10569082742783006, "duration": 75.79785203933716, "step": 41000}
{"episode_reward": 0.0, "episode": 165.0, "batch_reward": 1.8894375, "critic_loss": 30.81353289794922, "actor_loss": -337.40746264648436, "actor_target_entropy": -2.0, "actor_entropy": 0.69695010471344, "alpha_loss": 0.008460749547928572, "alpha_value": 0.10500937257056642, "duration": 75.77921319007874, "step": 41250}
{"episode_reward": 907.0, "episode": 166.0, "batch_reward": 1.9169609375, "critic_loss": 32.87834440612793, "actor_loss": -341.12808081054686, "actor_target_entropy": -2.0, "actor_entropy": 0.6987755823135376, "alpha_loss": 0.007337939471472055, "alpha_value": 0.1042548320674595, "duration": 75.80174827575684, "step": 41500}
{"episode_reward": 951.0, "episode": 167.0, "batch_reward": 1.920859375, "critic_loss": 33.73665985870361, "actor_loss": -336.7199296875, "actor_target_entropy": -2.0, "actor_entropy": 0.6816372728347778, "alpha_loss": 0.00749162074830383, "alpha_value": 0.10376222980818692, "duration": 75.76550078392029, "step": 41750}
{"episode_reward": 548.0, "episode": 168.0, "batch_reward": 1.9192734375, "critic_loss": 30.430014823913574, "actor_loss": -338.01228515625, "actor_target_entropy": -2.0, "actor_entropy": 0.6527351441383362, "alpha_loss": 0.006976271261461079, "alpha_value": 0.10304600576557432, "duration": 75.75855803489685, "step": 42000}
{"episode_reward": 705.0, "episode": 169.0, "batch_reward": 1.9245546875, "critic_loss": 29.704234603881837, "actor_loss": -338.98890991210936, "actor_target_entropy": -2.0, "actor_entropy": 0.6732287940979004, "alpha_loss": 0.0014982019867748023, "alpha_value": 0.10266299553447979, "duration": 75.79161095619202, "step": 42250}
{"episode_reward": 945.0, "episode": 170.0, "batch_reward": 1.930859375, "critic_loss": 28.996286056518553, "actor_loss": -337.369796875, "actor_target_entropy": -2.0, "actor_entropy": 0.6772973003387451, "alpha_loss": 0.0034484103694558143, "alpha_value": 0.10247198851013538, "duration": 75.77173113822937, "step": 42500}
{"episode_reward": 933.0, "episode": 171.0, "batch_reward": 1.943453125, "critic_loss": 28.985118019104004, "actor_loss": -341.0042822265625, "actor_target_entropy": -2.0, "actor_entropy": 0.6888479595184326, "alpha_loss": 0.0003175927484408021, "alpha_value": 0.1022599103020287, "duration": 75.85149264335632, "step": 42750}
{"episode_reward": 969.0, "episode": 172.0, "batch_reward": 1.955015625, "critic_loss": 28.35514101409912, "actor_loss": -339.71437109375, "actor_target_entropy": -2.0, "actor_entropy": 0.7151939649581909, "alpha_loss": 0.003566196233034134, "alpha_value": 0.10210008938054019, "duration": 75.80854821205139, "step": 43000}
{"episode_reward": 8.0, "episode": 173.0, "batch_reward": 1.955859375, "critic_loss": 27.870267181396486, "actor_loss": -340.8752958984375, "actor_target_entropy": -2.0, "actor_entropy": 0.6771868081092834, "alpha_loss": 0.002957537149079144, "alpha_value": 0.10175341826866564, "duration": 75.77072310447693, "step": 43250}
{"episode_reward": 992.0, "episode": 174.0, "batch_reward": 1.9489921875, "critic_loss": 27.039206230163575, "actor_loss": -339.45369067382813, "actor_target_entropy": -2.0, "actor_entropy": 0.7049536104202271, "alpha_loss": 0.0013302639797329902, "alpha_value": 0.10160617510020288, "duration": 75.79580688476562, "step": 43500}
{"episode_reward": 14.0, "episode": 175.0, "batch_reward": 1.94653125, "critic_loss": 26.38106575012207, "actor_loss": -340.96964916992187, "actor_target_entropy": -2.0, "actor_entropy": 0.6792587952613831, "alpha_loss": -0.0008931927653029561, "alpha_value": 0.10155194183090482, "duration": 75.81337642669678, "step": 43750}
{"episode_reward": 987.0, "episode": 176.0, "batch_reward": 1.958453125, "critic_loss": 26.30892214202881, "actor_loss": -340.20748608398435, "actor_target_entropy": -2.0, "actor_entropy": 0.6961706318855285, "alpha_loss": 0.005529649050440639, "alpha_value": 0.10138591997005468, "duration": 75.71887803077698, "step": 44000}
{"episode_reward": 0.0, "episode": 177.0, "batch_reward": 1.933703125, "critic_loss": 26.076411865234373, "actor_loss": -339.8332312011719, "actor_target_entropy": -2.0, "actor_entropy": 0.6800709850788117, "alpha_loss": 0.002162253453396261, "alpha_value": 0.10097362792914454, "duration": 75.80928826332092, "step": 44250}
{"episode_reward": 18.0, "episode": 178.0, "batch_reward": 1.947796875, "critic_loss": 26.874448837280273, "actor_loss": -338.59195288085937, "actor_target_entropy": -2.0, "actor_entropy": 0.6934785761833191, "alpha_loss": 0.003807691656984389, "alpha_value": 0.1006260999085173, "duration": 75.82506203651428, "step": 44500}
{"episode_reward": 996.0, "episode": 179.0, "batch_reward": 1.950703125, "critic_loss": 24.83290821838379, "actor_loss": -340.63545874023436, "actor_target_entropy": -2.0, "actor_entropy": 0.6787408666610718, "alpha_loss": 0.010287262924946845, "alpha_value": 0.10001730269731669, "duration": 75.7420129776001, "step": 44750}
{"episode_reward": 915.0, "episode": 180.0, "batch_reward": 1.9552890625, "critic_loss": 26.680891822814942, "actor_loss": -341.137779296875, "actor_target_entropy": -2.0, "actor_entropy": 0.6857848906517029, "alpha_loss": 0.006915667033754289, "alpha_value": 0.0991609738298858, "step": 45000}
{"duration": 93.67073082923889, "step": 45000}
{"episode_reward": 692.0, "episode": 181.0, "batch_reward": 1.9625390625, "critic_loss": 25.260665626525878, "actor_loss": -341.47093994140624, "actor_target_entropy": -2.0, "actor_entropy": 0.7016771287918091, "alpha_loss": 0.009357134980149567, "alpha_value": 0.09847982022860723, "duration": 75.79987215995789, "step": 45250}
{"episode_reward": 961.0, "episode": 182.0, "batch_reward": 1.97, "critic_loss": 25.212822639465333, "actor_loss": -340.64892895507813, "actor_target_entropy": -2.0, "actor_entropy": 0.7085825781822205, "alpha_loss": 0.0039644094146788125, "alpha_value": 0.09779008824074312, "duration": 75.72036004066467, "step": 45500}
{"episode_reward": 826.0, "episode": 183.0, "batch_reward": 1.9816171875, "critic_loss": 24.78554734802246, "actor_loss": -341.9875856933594, "actor_target_entropy": -2.0, "actor_entropy": 0.6978828377723694, "alpha_loss": 0.007093548832461238, "alpha_value": 0.0972253664450504, "duration": 75.79336595535278, "step": 45750}
{"episode_reward": 966.0, "episode": 184.0, "batch_reward": 1.9776796875, "critic_loss": 23.89670810699463, "actor_loss": -342.3332683105469, "actor_target_entropy": -2.0, "actor_entropy": 0.6560409865379333, "alpha_loss": 0.008506741859018802, "alpha_value": 0.09646944130613012, "duration": 75.6442220211029, "step": 46000}
{"episode_reward": 775.0, "episode": 185.0, "batch_reward": 1.9830234375, "critic_loss": 25.276323982238768, "actor_loss": -341.8451982421875, "actor_target_entropy": -2.0, "actor_entropy": 0.6476564707756043, "alpha_loss": 0.0015141832968220115, "alpha_value": 0.09602143931895087, "duration": 75.68612551689148, "step": 46250}
{"episode_reward": 490.0, "episode": 186.0, "batch_reward": 1.985171875, "critic_loss": 24.579717262268066, "actor_loss": -342.054568359375, "actor_target_entropy": -2.0, "actor_entropy": 0.6518577198982238, "alpha_loss": 0.00938581305462867, "alpha_value": 0.09556544709780515, "duration": 75.78357863426208, "step": 46500}
{"episode_reward": 0.0, "episode": 187.0, "batch_reward": 1.97159375, "critic_loss": 24.124475036621092, "actor_loss": -341.0926237792969, "actor_target_entropy": -2.0, "actor_entropy": 0.6361352968215942, "alpha_loss": 0.007377817924134433, "alpha_value": 0.09476014929917927, "duration": 75.81755065917969, "step": 46750}
{"episode_reward": 649.0, "episode": 188.0, "batch_reward": 1.9831015625, "critic_loss": 24.218982376098634, "actor_loss": -343.58810693359374, "actor_target_entropy": -2.0, "actor_entropy": 0.6432650375366211, "alpha_loss": 0.007965399057138712, "alpha_value": 0.09408686095468674, "duration": 75.80267906188965, "step": 47000}
{"episode_reward": 0.0, "episode": 189.0, "batch_reward": 1.9806953125, "critic_loss": 22.926162101745607, "actor_loss": -343.0893869628906, "actor_target_entropy": -2.0, "actor_entropy": 0.653297481060028, "alpha_loss": 0.003367817098274827, "alpha_value": 0.09352175036592468, "duration": 75.8261330127716, "step": 47250}
{"episode_reward": 989.0, "episode": 190.0, "batch_reward": 1.9808359375, "critic_loss": 24.25357261657715, "actor_loss": -344.4861943359375, "actor_target_entropy": -2.0, "actor_entropy": 0.6297450003623962, "alpha_loss": 0.008163209149613977, "alpha_value": 0.09304529535543214, "duration": 75.87590217590332, "step": 47500}
{"episode_reward": 429.0, "episode": 191.0, "batch_reward": 1.9763984375, "critic_loss": 23.51464298629761, "actor_loss": -342.8255417480469, "actor_target_entropy": -2.0, "actor_entropy": 0.5909829568862915, "alpha_loss": 0.0070151110291481016, "alpha_value": 0.09221962610185983, "duration": 75.74870681762695, "step": 47750}
{"episode_reward": 0.0, "episode": 192.0, "batch_reward": 1.9795703125, "critic_loss": 23.394190910339354, "actor_loss": -343.57934228515626, "actor_target_entropy": -2.0, "actor_entropy": 0.6141138942241668, "alpha_loss": 0.00760164594464004, "alpha_value": 0.09171479351819875, "duration": 75.86350154876709, "step": 48000}
{"episode_reward": 756.0, "episode": 193.0, "batch_reward": 1.9830703125, "critic_loss": 23.80363856124878, "actor_loss": -343.5587541503906, "actor_target_entropy": -2.0, "actor_entropy": 0.633938812494278, "alpha_loss": 0.003623459571041167, "alpha_value": 0.0910962801361558, "duration": 75.82816314697266, "step": 48250}
{"episode_reward": 990.0, "episode": 194.0, "batch_reward": 1.9969453125, "critic_loss": 22.952774116516114, "actor_loss": -344.25585131835936, "actor_target_entropy": -2.0, "actor_entropy": 0.6394850435256958, "alpha_loss": 0.00419278870197013, "alpha_value": 0.09074844571197109, "duration": 75.79838943481445, "step": 48500}
{"episode_reward": 914.0, "episode": 195.0, "batch_reward": 2.0017734375, "critic_loss": 24.047978340148926, "actor_loss": -345.62959790039065, "actor_target_entropy": -2.0, "actor_entropy": 0.6557018327713012, "alpha_loss": 0.0012797548240050674, "alpha_value": 0.09034529942122599, "duration": 75.84504294395447, "step": 48750}
{"episode_reward": 980.0, "episode": 196.0, "batch_reward": 2.00565625, "critic_loss": 23.056887619018553, "actor_loss": -345.76135424804687, "actor_target_entropy": -2.0, "actor_entropy": 0.623942633152008, "alpha_loss": 0.00455858007259667, "alpha_value": 0.09015321841755522, "duration": 75.83117747306824, "step": 49000}
{"episode_reward": 684.0, "episode": 197.0, "batch_reward": 2.01309375, "critic_loss": 21.486598609924318, "actor_loss": -344.105966796875, "actor_target_entropy": -2.0, "actor_entropy": 0.635870444059372, "alpha_loss": 0.005886703587137163, "alpha_value": 0.0897062938406813, "duration": 75.84014248847961, "step": 49250}
{"episode_reward": 951.0, "episode": 198.0, "batch_reward": 2.0278125, "critic_loss": 23.1605131149292, "actor_loss": -345.56512548828124, "actor_target_entropy": -2.0, "actor_entropy": 0.6583880553245545, "alpha_loss": 0.0033139309054240583, "alpha_value": 0.0892349838397918, "duration": 75.893883228302, "step": 49500}
{"episode_reward": 958.0, "episode": 199.0, "batch_reward": 2.022171875, "critic_loss": 22.106833042144775, "actor_loss": -346.9024340820313, "actor_target_entropy": -2.0, "actor_entropy": 0.6028234362602234, "alpha_loss": 0.003759517503902316, "alpha_value": 0.08892224056032787, "duration": 75.86486601829529, "step": 49750}
{"episode_reward": 32.0, "episode": 200.0, "batch_reward": 2.0249140625, "critic_loss": 22.654295532226563, "actor_loss": -346.505837890625, "actor_target_entropy": -2.0, "actor_entropy": 0.6455950136184693, "alpha_loss": 0.00490637436369434, "alpha_value": 0.08851120189090389, "step": 50000}
{"duration": 93.95507550239563, "step": 50000}
{"episode_reward": 788.0, "episode": 201.0, "batch_reward": 2.0285, "critic_loss": 23.52008470916748, "actor_loss": -347.06087109375, "actor_target_entropy": -2.0, "actor_entropy": 0.6045582113265991, "alpha_loss": 0.00459572512935847, "alpha_value": 0.0880671732150896, "duration": 75.66599297523499, "step": 50250}
{"episode_reward": 953.0, "episode": 202.0, "batch_reward": 2.038921875, "critic_loss": 23.39560004425049, "actor_loss": -348.3109140625, "actor_target_entropy": -2.0, "actor_entropy": 0.6049782047271729, "alpha_loss": 0.006395943881012499, "alpha_value": 0.08747017821383557, "duration": 75.7451663017273, "step": 50500}
{"episode_reward": 960.0, "episode": 203.0, "batch_reward": 2.0538359375, "critic_loss": 22.350115028381346, "actor_loss": -347.81961499023436, "actor_target_entropy": -2.0, "actor_entropy": 0.6206646766662598, "alpha_loss": 0.006422268905676902, "alpha_value": 0.08695376381790748, "duration": 75.7443733215332, "step": 50750}
{"episode_reward": 981.0, "episode": 204.0, "batch_reward": 2.071734375, "critic_loss": 22.762631004333496, "actor_loss": -349.00987255859377, "actor_target_entropy": -2.0, "actor_entropy": 0.6098557541370392, "alpha_loss": 0.0004619966559112072, "alpha_value": 0.08656741826668887, "duration": 75.5742290019989, "step": 51000}
{"episode_reward": 990.0, "episode": 205.0, "batch_reward": 2.06484375, "critic_loss": 22.537699268341065, "actor_loss": -347.49852734375, "actor_target_entropy": -2.0, "actor_entropy": 0.6652949719429017, "alpha_loss": -0.0004944327012635768, "alpha_value": 0.0865849619087969, "duration": 75.79431867599487, "step": 51250}
{"episode_reward": 986.0, "episode": 206.0, "batch_reward": 2.070515625, "critic_loss": 23.990299057006837, "actor_loss": -348.036876953125, "actor_target_entropy": -2.0, "actor_entropy": 0.6225257680416107, "alpha_loss": -0.002968872572295368, "alpha_value": 0.0868357966212065, "duration": 75.83979511260986, "step": 51500}
{"episode_reward": 111.0, "episode": 207.0, "batch_reward": 2.0721171875, "critic_loss": 23.45037018585205, "actor_loss": -348.9479326171875, "actor_target_entropy": -2.0, "actor_entropy": 0.6319852142333985, "alpha_loss": -0.00020982559304684402, "alpha_value": 0.08690085254073569, "duration": 75.87987923622131, "step": 51750}
{"episode_reward": 999.0, "episode": 208.0, "batch_reward": 2.0733125, "critic_loss": 22.53236604309082, "actor_loss": -349.34694262695314, "actor_target_entropy": -2.0, "actor_entropy": 0.6938393354415894, "alpha_loss": -0.003312755585182458, "alpha_value": 0.08711877347753534, "duration": 75.79709768295288, "step": 52000}
{"episode_reward": 230.0, "episode": 209.0, "batch_reward": 2.06465625, "critic_loss": 22.648057273864747, "actor_loss": -347.09728125, "actor_target_entropy": -2.0, "actor_entropy": 0.6821466851234436, "alpha_loss": -0.004456173850223422, "alpha_value": 0.08750944376356476, "duration": 75.87560319900513, "step": 52250}
{"episode_reward": 954.0, "episode": 210.0, "batch_reward": 2.0916796875, "critic_loss": 23.66935689544678, "actor_loss": -347.5045178222656, "actor_target_entropy": -2.0, "actor_entropy": 0.6840480456352234, "alpha_loss": -0.00308514114189893, "alpha_value": 0.08781732344428009, "duration": 75.87367367744446, "step": 52500}
{"episode_reward": 958.0, "episode": 211.0, "batch_reward": 2.0783046875, "critic_loss": 23.549690155029296, "actor_loss": -346.4267846679688, "actor_target_entropy": -2.0, "actor_entropy": 0.7245756378173828, "alpha_loss": -0.004451945331413299, "alpha_value": 0.08836124575296052, "duration": 75.9011754989624, "step": 52750}
{"episode_reward": 910.0, "episode": 212.0, "batch_reward": 2.0924375, "critic_loss": 24.74555805206299, "actor_loss": -348.73487744140624, "actor_target_entropy": -2.0, "actor_entropy": 0.6877399382591247, "alpha_loss": -0.0031004097540862858, "alpha_value": 0.08865097455438205, "duration": 75.87197399139404, "step": 53000}
{"episode_reward": 878.0, "episode": 213.0, "batch_reward": 2.1074140625, "critic_loss": 25.401342681884767, "actor_loss": -348.2968540039063, "actor_target_entropy": -2.0, "actor_entropy": 0.696863034248352, "alpha_loss": -0.0075852471925318245, "alpha_value": 0.08910684817119252, "duration": 75.82412934303284, "step": 53250}
{"episode_reward": 971.0, "episode": 214.0, "batch_reward": 2.106078125, "critic_loss": 25.365182174682616, "actor_loss": -348.7050241699219, "actor_target_entropy": -2.0, "actor_entropy": 0.6892382164001465, "alpha_loss": -0.009427766339853406, "alpha_value": 0.09012042386414656, "duration": 75.87987184524536, "step": 53500}
{"episode_reward": 992.0, "episode": 215.0, "batch_reward": 2.1208203125, "critic_loss": 25.03730164337158, "actor_loss": -349.495814453125, "actor_target_entropy": -2.0, "actor_entropy": 0.7149140691757202, "alpha_loss": -0.007900864840950816, "alpha_value": 0.09087877920143178, "duration": 75.85391640663147, "step": 53750}
{"episode_reward": 988.0, "episode": 216.0, "batch_reward": 2.1183359375, "critic_loss": 24.735929428100587, "actor_loss": -349.6273857421875, "actor_target_entropy": -2.0, "actor_entropy": 0.7375934100151063, "alpha_loss": -0.011182747380807996, "alpha_value": 0.0918732901668063, "duration": 75.88139319419861, "step": 54000}
{"episode_reward": 0.0, "episode": 217.0, "batch_reward": 2.121546875, "critic_loss": 25.3435848236084, "actor_loss": -349.3304074707031, "actor_target_entropy": -2.0, "actor_entropy": 0.7467842807769776, "alpha_loss": -0.009746203134767711, "alpha_value": 0.09288620034854836, "duration": 75.92304182052612, "step": 54250}
{"episode_reward": 959.0, "episode": 218.0, "batch_reward": 2.107296875, "critic_loss": 26.6434395904541, "actor_loss": -349.6310124511719, "actor_target_entropy": -2.0, "actor_entropy": 0.691901888847351, "alpha_loss": -0.0015322457645088434, "alpha_value": 0.09342141900098529, "duration": 75.90922141075134, "step": 54500}
{"episode_reward": 1.0, "episode": 219.0, "batch_reward": 2.1118203125, "critic_loss": 26.97332148742676, "actor_loss": -350.5981796875, "actor_target_entropy": -2.0, "actor_entropy": 0.7254129314422607, "alpha_loss": -0.003057711847126484, "alpha_value": 0.09354256056383745, "duration": 75.97371125221252, "step": 54750}
{"episode_reward": 590.0, "episode": 220.0, "batch_reward": 2.12125, "critic_loss": 27.614705474853515, "actor_loss": -351.7358078613281, "actor_target_entropy": -2.0, "actor_entropy": 0.7312377743721008, "alpha_loss": -0.00481176639162004, "alpha_value": 0.09387426205828245, "step": 55000}
{"duration": 93.81840443611145, "step": 55000}
{"episode_reward": 425.0, "episode": 221.0, "batch_reward": 2.109328125, "critic_loss": 26.214671119689942, "actor_loss": -352.3169270019531, "actor_target_entropy": -2.0, "actor_entropy": 0.7275582628250122, "alpha_loss": -0.008819971857592463, "alpha_value": 0.0945897104491493, "duration": 75.72214722633362, "step": 55250}
{"episode_reward": 7.0, "episode": 222.0, "batch_reward": 2.10840625, "critic_loss": 28.854456733703614, "actor_loss": -351.754658203125, "actor_target_entropy": -2.0, "actor_entropy": 0.7363206615447998, "alpha_loss": -0.007608199504669756, "alpha_value": 0.09521961617212113, "duration": 75.87826371192932, "step": 55500}
{"episode_reward": 981.0, "episode": 223.0, "batch_reward": 2.1122890625, "critic_loss": 29.33033957672119, "actor_loss": -352.40866845703124, "actor_target_entropy": -2.0, "actor_entropy": 0.7590479979515076, "alpha_loss": -0.013316580807790161, "alpha_value": 0.09628201823752108, "duration": 75.93080472946167, "step": 55750}
{"episode_reward": 950.0, "episode": 224.0, "batch_reward": 2.1090234375, "critic_loss": 27.32749552154541, "actor_loss": -352.6803974609375, "actor_target_entropy": -2.0, "actor_entropy": 0.7774732890129089, "alpha_loss": -0.01251083762384951, "alpha_value": 0.09736481532037382, "duration": 75.79329013824463, "step": 56000}
{"episode_reward": 0.0, "episode": 225.0, "batch_reward": 2.1077734375, "critic_loss": 27.35572444152832, "actor_loss": -352.97395874023437, "actor_target_entropy": -2.0, "actor_entropy": 0.7950398054122925, "alpha_loss": -0.006207887032069266, "alpha_value": 0.09831549403244161, "duration": 75.64207911491394, "step": 56250}
{"episode_reward": 919.0, "episode": 226.0, "batch_reward": 2.1114140625, "critic_loss": 25.457595291137697, "actor_loss": -353.7138786621094, "actor_target_entropy": -2.0, "actor_entropy": 0.786994080543518, "alpha_loss": 0.0007616251120343804, "alpha_value": 0.09849544115619159, "duration": 76.5222156047821, "step": 56500}
{"episode_reward": 4.0, "episode": 227.0, "batch_reward": 2.0988828125, "critic_loss": 26.873178916931153, "actor_loss": -352.03193017578127, "actor_target_entropy": -2.0, "actor_entropy": 0.8020530853271485, "alpha_loss": -0.0012387733338400722, "alpha_value": 0.09849396412071344, "duration": 75.90802025794983, "step": 56750}
{"episode_reward": 1.0, "episode": 228.0, "batch_reward": 2.0941171875, "critic_loss": 26.24528275299072, "actor_loss": -351.64302709960936, "actor_target_entropy": -2.0, "actor_entropy": 0.7520620989799499, "alpha_loss": 0.008022121516987682, "alpha_value": 0.09835820218240846, "duration": 75.8708484172821, "step": 57000}
{"episode_reward": 291.0, "episode": 229.0, "batch_reward": 2.08765625, "critic_loss": 24.79046435546875, "actor_loss": -350.8905947265625, "actor_target_entropy": -2.0, "actor_entropy": 0.7432792010307312, "alpha_loss": 0.008387580652255564, "alpha_value": 0.09749079862409377, "duration": 75.86813163757324, "step": 57250}
{"episode_reward": 6.0, "episode": 230.0, "batch_reward": 2.0874296875, "critic_loss": 24.300175437927248, "actor_loss": -350.7591750488281, "actor_target_entropy": -2.0, "actor_entropy": 0.7172230548858642, "alpha_loss": 0.004156879279762506, "alpha_value": 0.09684431104524466, "duration": 75.86993265151978, "step": 57500}
{"episode_reward": 983.0, "episode": 231.0, "batch_reward": 2.0873828125, "critic_loss": 23.8969083404541, "actor_loss": -351.0740231933594, "actor_target_entropy": -2.0, "actor_entropy": 0.7303318424224854, "alpha_loss": 0.004101795832626522, "alpha_value": 0.09656399969969763, "duration": 75.94472026824951, "step": 57750}
{"episode_reward": 0.0, "episode": 232.0, "batch_reward": 2.0787734375, "critic_loss": 23.289350326538084, "actor_loss": -351.04919067382815, "actor_target_entropy": -2.0, "actor_entropy": 0.7558264212608338, "alpha_loss": 0.007476619470398873, "alpha_value": 0.09599768454680611, "duration": 75.95652961730957, "step": 58000}
{"episode_reward": 28.0, "episode": 233.0, "batch_reward": 2.0708203125, "critic_loss": 22.609355125427246, "actor_loss": -348.54673486328124, "actor_target_entropy": -2.0, "actor_entropy": 0.7029040036201477, "alpha_loss": 0.008439800129272043, "alpha_value": 0.09527133930043238, "duration": 75.88550114631653, "step": 58250}
{"episode_reward": 46.0, "episode": 234.0, "batch_reward": 2.0681640625, "critic_loss": 23.008426395416258, "actor_loss": -349.67557739257813, "actor_target_entropy": -2.0, "actor_entropy": 0.7024672713279724, "alpha_loss": 0.007651374652050435, "alpha_value": 0.09449167253360521, "duration": 75.9310233592987, "step": 58500}
{"episode_reward": 458.0, "episode": 235.0, "batch_reward": 2.073953125, "critic_loss": 23.71774758911133, "actor_loss": -350.1895056152344, "actor_target_entropy": -2.0, "actor_entropy": 0.6851445045471192, "alpha_loss": 0.009346799112856389, "alpha_value": 0.0936476242733268, "duration": 75.93720006942749, "step": 58750}
{"episode_reward": 955.0, "episode": 236.0, "batch_reward": 2.085171875, "critic_loss": 21.743515827178957, "actor_loss": -350.44902392578126, "actor_target_entropy": -2.0, "actor_entropy": 0.675390923500061, "alpha_loss": 0.009230148220434786, "alpha_value": 0.09286853962514476, "duration": 75.88559222221375, "step": 59000}
{"episode_reward": 958.0, "episode": 237.0, "batch_reward": 2.082265625, "critic_loss": 21.540390632629393, "actor_loss": -351.2354360351562, "actor_target_entropy": -2.0, "actor_entropy": 0.6774213800430298, "alpha_loss": 0.0072773908679373564, "alpha_value": 0.09206896823905802, "duration": 75.90950059890747, "step": 59250}
{"episode_reward": 973.0, "episode": 238.0, "batch_reward": 2.0864765625, "critic_loss": 20.969266345977783, "actor_loss": -349.1542976074219, "actor_target_entropy": -2.0, "actor_entropy": 0.7365660338401795, "alpha_loss": 0.0035915626659989357, "alpha_value": 0.09160657066826863, "duration": 75.89756679534912, "step": 59500}
{"episode_reward": 15.0, "episode": 239.0, "batch_reward": 2.0833671875, "critic_loss": 21.15307275772095, "actor_loss": -348.58042016601564, "actor_target_entropy": -2.0, "actor_entropy": 0.7172947754859924, "alpha_loss": 0.0018444624473340809, "alpha_value": 0.09144751098178767, "duration": 75.88345956802368, "step": 59750}
{"episode_reward": 979.0, "episode": 240.0, "batch_reward": 2.0813671875, "critic_loss": 20.67410953903198, "actor_loss": -347.7893591308594, "actor_target_entropy": -2.0, "actor_entropy": 0.7554043164253235, "alpha_loss": 0.0033283152813091874, "alpha_value": 0.09107011454158172, "step": 60000}
{"duration": 93.88115167617798, "step": 60000}
{"episode_reward": 38.0, "episode": 241.0, "batch_reward": 2.07378125, "critic_loss": 20.702646335601806, "actor_loss": -347.93438842773435, "actor_target_entropy": -2.0, "actor_entropy": 0.7831171116828919, "alpha_loss": 0.002009924588724971, "alpha_value": 0.09092363381250346, "duration": 75.74990034103394, "step": 60250}
{"episode_reward": 723.0, "episode": 242.0, "batch_reward": 2.093421875, "critic_loss": 20.707039432525633, "actor_loss": -348.0439934082031, "actor_target_entropy": -2.0, "actor_entropy": 0.7576882886886597, "alpha_loss": 0.004247994351200759, "alpha_value": 0.0906028736916942, "duration": 75.70723748207092, "step": 60500}
{"episode_reward": 970.0, "episode": 243.0, "batch_reward": 2.0927734375, "critic_loss": 20.022432723999025, "actor_loss": -348.8672084960937, "actor_target_entropy": -2.0, "actor_entropy": 0.7651100144386291, "alpha_loss": 0.0047969590723514555, "alpha_value": 0.09022867498563035, "duration": 75.75784134864807, "step": 60750}
{"episode_reward": 17.0, "episode": 244.0, "batch_reward": 2.0698515625, "critic_loss": 19.69401305770874, "actor_loss": -346.36055029296875, "actor_target_entropy": -2.0, "actor_entropy": 0.7573216495513916, "alpha_loss": 0.004564405689481646, "alpha_value": 0.08977943748365583, "duration": 75.86461520195007, "step": 61000}
{"episode_reward": 0.0, "episode": 245.0, "batch_reward": 2.07128125, "critic_loss": 20.133100311279296, "actor_loss": -346.1463425292969, "actor_target_entropy": -2.0, "actor_entropy": 0.8164352402687073, "alpha_loss": 0.0028387819323688747, "alpha_value": 0.08938127234088028, "duration": 75.5708556175232, "step": 61250}
{"episode_reward": 35.0, "episode": 246.0, "batch_reward": 2.0529921875, "critic_loss": 20.137400142669676, "actor_loss": -346.0686875, "actor_target_entropy": -2.0, "actor_entropy": 0.7919207630157471, "alpha_loss": 0.0015388369597494603, "alpha_value": 0.08918002557000797, "duration": 75.88765454292297, "step": 61500}
{"episode_reward": 985.0, "episode": 247.0, "batch_reward": 2.0688515625, "critic_loss": 19.71382761001587, "actor_loss": -346.0959091796875, "actor_target_entropy": -2.0, "actor_entropy": 0.759171627998352, "alpha_loss": 0.003879123509861529, "alpha_value": 0.0889761041709757, "duration": 75.77349805831909, "step": 61750}
{"episode_reward": 967.0, "episode": 248.0, "batch_reward": 2.0787890625, "critic_loss": 19.71294343948364, "actor_loss": -345.67092724609375, "actor_target_entropy": -2.0, "actor_entropy": 0.751509304523468, "alpha_loss": 0.007045324898324907, "alpha_value": 0.08832248333746402, "duration": 75.82070231437683, "step": 62000}
{"episode_reward": 966.0, "episode": 249.0, "batch_reward": 2.0791328125, "critic_loss": 19.015528785705566, "actor_loss": -344.7429411621094, "actor_target_entropy": -2.0, "actor_entropy": 0.7283190360069275, "alpha_loss": 0.0088317307010293, "alpha_value": 0.08750727706137394, "duration": 75.81178522109985, "step": 62250}
{"episode_reward": 5.0, "episode": 250.0, "batch_reward": 2.09078125, "critic_loss": 19.332212898254394, "actor_loss": -345.38738061523435, "actor_target_entropy": -2.0, "actor_entropy": 0.7411498537063599, "alpha_loss": 0.004941693481057882, "alpha_value": 0.08690903749119981, "duration": 75.81301951408386, "step": 62500}
{"episode_reward": 994.0, "episode": 251.0, "batch_reward": 2.0863515625, "critic_loss": 18.08176546859741, "actor_loss": -344.7444130859375, "actor_target_entropy": -2.0, "actor_entropy": 0.7370183820724487, "alpha_loss": 0.005797146033495665, "alpha_value": 0.08640502006125961, "duration": 75.85137462615967, "step": 62750}
{"episode_reward": 32.0, "episode": 252.0, "batch_reward": 2.082453125, "critic_loss": 18.781561611175537, "actor_loss": -343.5571066894531, "actor_target_entropy": -2.0, "actor_entropy": 0.7404565587043762, "alpha_loss": 0.00930379926878959, "alpha_value": 0.08564222576907697, "duration": 75.84052848815918, "step": 63000}
{"episode_reward": 989.0, "episode": 253.0, "batch_reward": 2.0828515625, "critic_loss": 19.127276985168457, "actor_loss": -343.36305029296875, "actor_target_entropy": -2.0, "actor_entropy": 0.6873402109146118, "alpha_loss": 0.006865726221352815, "alpha_value": 0.08483916101456512, "duration": 75.84415864944458, "step": 63250}
{"episode_reward": 873.0, "episode": 254.0, "batch_reward": 2.0944375, "critic_loss": 18.855803798675538, "actor_loss": -343.2510988769531, "actor_target_entropy": -2.0, "actor_entropy": 0.7066021823883056, "alpha_loss": 0.004729076748713851, "alpha_value": 0.08426180205508517, "duration": 75.71146607398987, "step": 63500}
{"episode_reward": 985.0, "episode": 255.0, "batch_reward": 2.09209375, "critic_loss": 19.484674060821533, "actor_loss": -343.54601708984376, "actor_target_entropy": -2.0, "actor_entropy": 0.7445000267028808, "alpha_loss": 0.0026005869517102837, "alpha_value": 0.08396107708308856, "duration": 75.77245163917542, "step": 63750}
{"episode_reward": 4.0, "episode": 256.0, "batch_reward": 2.086578125, "critic_loss": 18.664021278381348, "actor_loss": -342.2477395019531, "actor_target_entropy": -2.0, "actor_entropy": 0.7474094510078431, "alpha_loss": 0.001587305845692754, "alpha_value": 0.08383469179421375, "duration": 75.78866648674011, "step": 64000}
{"episode_reward": 995.0, "episode": 257.0, "batch_reward": 2.1079375, "critic_loss": 19.20407523727417, "actor_loss": -344.0092133789062, "actor_target_entropy": -2.0, "actor_entropy": 0.7089787096977234, "alpha_loss": 0.001804500836879015, "alpha_value": 0.0836644379771814, "duration": 75.78734993934631, "step": 64250}
{"episode_reward": 954.0, "episode": 258.0, "batch_reward": 2.1087734375, "critic_loss": 18.718081764221193, "actor_loss": -344.6508525390625, "actor_target_entropy": -2.0, "actor_entropy": 0.6926581025123596, "alpha_loss": 0.004256435092072934, "alpha_value": 0.08333390169753467, "duration": 75.8516173362732, "step": 64500}
{"episode_reward": 1000.0, "episode": 259.0, "batch_reward": 2.117125, "critic_loss": 19.130415508270264, "actor_loss": -344.24100830078123, "actor_target_entropy": -2.0, "actor_entropy": 0.7112707357406616, "alpha_loss": 0.005802974189631641, "alpha_value": 0.08274108270750088, "duration": 75.80195140838623, "step": 64750}
{"episode_reward": 973.0, "episode": 260.0, "batch_reward": 2.120765625, "critic_loss": 18.380224529266357, "actor_loss": -344.8026845703125, "actor_target_entropy": -2.0, "actor_entropy": 0.7368688158988953, "alpha_loss": 0.002793870753142983, "alpha_value": 0.08245796120206383, "step": 65000}
{"duration": 93.71691942214966, "step": 65000}
{"episode_reward": 857.0, "episode": 261.0, "batch_reward": 2.134859375, "critic_loss": 18.11116305923462, "actor_loss": -344.90758471679686, "actor_target_entropy": -2.0, "actor_entropy": 0.7343227987289429, "alpha_loss": -0.0013764980603009462, "alpha_value": 0.08233717525830829, "duration": 75.75454425811768, "step": 65250}
{"episode_reward": 936.0, "episode": 262.0, "batch_reward": 2.1330546875, "critic_loss": 18.37577942276001, "actor_loss": -344.17511938476565, "actor_target_entropy": -2.0, "actor_entropy": 0.7913750629425049, "alpha_loss": -0.0017661340339109302, "alpha_value": 0.08255350055796525, "duration": 75.78321647644043, "step": 65500}
{"episode_reward": 975.0, "episode": 263.0, "batch_reward": 2.1325078125, "critic_loss": 19.435446224212647, "actor_loss": -344.1891828613281, "actor_target_entropy": -2.0, "actor_entropy": 0.7130867691040039, "alpha_loss": 0.00547915459331125, "alpha_value": 0.08231080536830433, "duration": 75.87349963188171, "step": 65750}
{"episode_reward": 965.0, "episode": 264.0, "batch_reward": 2.1496015625, "critic_loss": 18.337775360107422, "actor_loss": -345.0666127929687, "actor_target_entropy": -2.0, "actor_entropy": 0.7175775156021118, "alpha_loss": 0.0014576526544988156, "alpha_value": 0.08198759076635186, "duration": 75.78287744522095, "step": 66000}
{"episode_reward": 976.0, "episode": 265.0, "batch_reward": 2.15375, "critic_loss": 18.175458740234376, "actor_loss": -345.3734826660156, "actor_target_entropy": -2.0, "actor_entropy": 0.7172241563796997, "alpha_loss": 0.002413912014104426, "alpha_value": 0.08170481438740458, "duration": 75.63597965240479, "step": 66250}
{"episode_reward": 976.0, "episode": 266.0, "batch_reward": 2.1460234375, "critic_loss": 17.82690549850464, "actor_loss": -346.5557712402344, "actor_target_entropy": -2.0, "actor_entropy": 0.715292603969574, "alpha_loss": 0.0019297460624948144, "alpha_value": 0.08148861335795943, "duration": 75.58438038825989, "step": 66500}
{"episode_reward": 340.0, "episode": 267.0, "batch_reward": 2.1498515625, "critic_loss": 18.18346873855591, "actor_loss": -345.86290258789063, "actor_target_entropy": -2.0, "actor_entropy": 0.7184380798339843, "alpha_loss": 0.0006445449963212014, "alpha_value": 0.08139105084799507, "duration": 75.69207048416138, "step": 66750}
{"episode_reward": 0.0, "episode": 268.0, "batch_reward": 2.1455703125, "critic_loss": 18.11927932357788, "actor_loss": -343.95067919921877, "actor_target_entropy": -2.0, "actor_entropy": 0.7370571193695068, "alpha_loss": 0.0066357428818009795, "alpha_value": 0.08101394627417063, "duration": 75.80886268615723, "step": 67000}
{"episode_reward": 8.0, "episode": 269.0, "batch_reward": 2.132828125, "critic_loss": 18.691389961242677, "actor_loss": -344.390349609375, "actor_target_entropy": -2.0, "actor_entropy": 0.7220425424575806, "alpha_loss": 0.0031215291125699877, "alpha_value": 0.08058619714145736, "duration": 75.91331553459167, "step": 67250}
{"episode_reward": 979.0, "episode": 270.0, "batch_reward": 2.137953125, "critic_loss": 19.087468116760252, "actor_loss": -343.396048828125, "actor_target_entropy": -2.0, "actor_entropy": 0.6895127401351929, "alpha_loss": 0.0030078301727771758, "alpha_value": 0.08013759058866413, "duration": 75.84207320213318, "step": 67500}
{"episode_reward": 966.0, "episode": 271.0, "batch_reward": 2.159546875, "critic_loss": 18.158013668060303, "actor_loss": -344.1915217285156, "actor_target_entropy": -2.0, "actor_entropy": 0.6717030620574951, "alpha_loss": 0.003249953133519739, "alpha_value": 0.07986840527723968, "duration": 75.90873217582703, "step": 67750}
{"episode_reward": 992.0, "episode": 272.0, "batch_reward": 2.16209375, "critic_loss": 17.70628298187256, "actor_loss": -343.874685546875, "actor_target_entropy": -2.0, "actor_entropy": 0.7214706220626831, "alpha_loss": 0.0020034741545096038, "alpha_value": 0.07953394460147375, "duration": 75.88668179512024, "step": 68000}
{"episode_reward": 623.0, "episode": 273.0, "batch_reward": 2.1601328125, "critic_loss": 18.444565048217772, "actor_loss": -342.29957568359373, "actor_target_entropy": -2.0, "actor_entropy": 0.7294035930633544, "alpha_loss": -0.0005004389029927552, "alpha_value": 0.07949602914051654, "duration": 75.93702745437622, "step": 68250}
{"episode_reward": 980.0, "episode": 274.0, "batch_reward": 2.169375, "critic_loss": 18.030595508575438, "actor_loss": -342.2981357421875, "actor_target_entropy": -2.0, "actor_entropy": 0.7273472337722778, "alpha_loss": 0.003668246641755104, "alpha_value": 0.079385616147163, "duration": 75.86452317237854, "step": 68500}
{"episode_reward": 955.0, "episode": 275.0, "batch_reward": 2.169078125, "critic_loss": 18.32037181854248, "actor_loss": -342.5481379394531, "actor_target_entropy": -2.0, "actor_entropy": 0.6991488881111145, "alpha_loss": 0.0015296250944957137, "alpha_value": 0.0791202454429027, "duration": 75.9599723815918, "step": 68750}
{"episode_reward": 0.0, "episode": 276.0, "batch_reward": 2.1579921875, "critic_loss": 18.67705812072754, "actor_loss": -341.66952099609375, "actor_target_entropy": -2.0, "actor_entropy": 0.7317840437889099, "alpha_loss": 0.0007804386736825109, "alpha_value": 0.07887436464446826, "duration": 75.91263103485107, "step": 69000}
{"episode_reward": 0.0, "episode": 277.0, "batch_reward": 2.151625, "critic_loss": 18.101072830200195, "actor_loss": -341.3309533691406, "actor_target_entropy": -2.0, "actor_entropy": 0.7291595516204834, "alpha_loss": -0.0016394345592707395, "alpha_value": 0.07898726925220063, "duration": 75.93760323524475, "step": 69250}
{"episode_reward": 929.0, "episode": 278.0, "batch_reward": 2.1744453125, "critic_loss": 18.682484588623048, "actor_loss": -342.07122119140627, "actor_target_entropy": -2.0, "actor_entropy": 0.7395149102210998, "alpha_loss": -0.0014314966714009643, "alpha_value": 0.07912512250145773, "duration": 75.91508960723877, "step": 69500}
{"episode_reward": 959.0, "episode": 279.0, "batch_reward": 2.1643125, "critic_loss": 18.516002067565918, "actor_loss": -341.61819189453126, "actor_target_entropy": -2.0, "actor_entropy": 0.6956500692367553, "alpha_loss": -0.0021585141429677607, "alpha_value": 0.07940486773329557, "duration": 75.93211221694946, "step": 69750}
{"episode_reward": 799.0, "episode": 280.0, "batch_reward": 2.164578125, "critic_loss": 17.84355619812012, "actor_loss": -342.6593720703125, "actor_target_entropy": -2.0, "actor_entropy": 0.6475876789093018, "alpha_loss": 0.0021299771312624214, "alpha_value": 0.07937800142075055, "step": 70000}
{"duration": 93.84746170043945, "step": 70000}
{"episode_reward": 959.0, "episode": 281.0, "batch_reward": 2.166015625, "critic_loss": 18.523731662750244, "actor_loss": -341.639322265625, "actor_target_entropy": -2.0, "actor_entropy": 0.6543952612876892, "alpha_loss": 0.0006255194642581046, "alpha_value": 0.07921593809132914, "duration": 75.80973410606384, "step": 70250}
{"episode_reward": 300.0, "episode": 282.0, "batch_reward": 2.176828125, "critic_loss": 18.669748805999756, "actor_loss": -343.22689453125, "actor_target_entropy": -2.0, "actor_entropy": 0.7010860290527344, "alpha_loss": -0.001707475682720542, "alpha_value": 0.07929049302575955, "duration": 75.79309701919556, "step": 70500}
{"episode_reward": 970.0, "episode": 283.0, "batch_reward": 2.1785546875, "critic_loss": 18.02887339401245, "actor_loss": -342.63852563476564, "actor_target_entropy": -2.0, "actor_entropy": 0.7046770792007446, "alpha_loss": -0.0013168104765936732, "alpha_value": 0.07942149027595874, "duration": 75.81510066986084, "step": 70750}
{"episode_reward": 987.0, "episode": 284.0, "batch_reward": 2.1816484375, "critic_loss": 18.215382293701172, "actor_loss": -342.58244091796877, "actor_target_entropy": -2.0, "actor_entropy": 0.7629057807922364, "alpha_loss": -0.0035420381971634925, "alpha_value": 0.07977473008902083, "duration": 75.824782371521, "step": 71000}
{"episode_reward": 898.0, "episode": 285.0, "batch_reward": 2.19534375, "critic_loss": 18.066389587402345, "actor_loss": -344.3375510253906, "actor_target_entropy": -2.0, "actor_entropy": 0.7214912457466125, "alpha_loss": 0.00036008478607982394, "alpha_value": 0.07988517754892331, "duration": 75.75818014144897, "step": 71250}
{"episode_reward": 968.0, "episode": 286.0, "batch_reward": 2.196296875, "critic_loss": 18.340739875793457, "actor_loss": -344.2343659667969, "actor_target_entropy": -2.0, "actor_entropy": 0.7047934665679931, "alpha_loss": -0.00047210569959133864, "alpha_value": 0.0798870915908422, "duration": 75.6567792892456, "step": 71500}
{"episode_reward": 918.0, "episode": 287.0, "batch_reward": 2.20015625, "critic_loss": 17.127104679107667, "actor_loss": -343.9018981933594, "actor_target_entropy": -2.0, "actor_entropy": 0.6984189243316651, "alpha_loss": 0.0018746090419590473, "alpha_value": 0.07984078421214438, "duration": 75.75352168083191, "step": 71750}
{"episode_reward": 0.0, "episode": 288.0, "batch_reward": 2.190984375, "critic_loss": 17.74510079193115, "actor_loss": -343.51611108398436, "actor_target_entropy": -2.0, "actor_entropy": 0.7137483978271484, "alpha_loss": 0.0035158539656549694, "alpha_value": 0.07956629928817217, "duration": 75.8016209602356, "step": 72000}
{"episode_reward": 958.0, "episode": 289.0, "batch_reward": 2.2056875, "critic_loss": 17.301920455932617, "actor_loss": -344.5249868164062, "actor_target_entropy": -2.0, "actor_entropy": 0.6797984304428101, "alpha_loss": 0.0003677771585062146, "alpha_value": 0.07924999903401618, "duration": 75.73607110977173, "step": 72250}
{"episode_reward": 0.0, "episode": 290.0, "batch_reward": 2.196984375, "critic_loss": 17.87903094100952, "actor_loss": -344.83285571289065, "actor_target_entropy": -2.0, "actor_entropy": 0.6775559248924256, "alpha_loss": 0.002800602353643626, "alpha_value": 0.07913378443905962, "duration": 75.82264614105225, "step": 72500}
{"episode_reward": 973.0, "episode": 291.0, "batch_reward": 2.1894140625, "critic_loss": 18.533735317230224, "actor_loss": -344.2871669921875, "actor_target_entropy": -2.0, "actor_entropy": 0.7170508275032044, "alpha_loss": 0.0005364177683368325, "alpha_value": 0.07884939916160971, "duration": 75.8468406200409, "step": 72750}
{"episode_reward": 68.0, "episode": 292.0, "batch_reward": 2.194046875, "critic_loss": 17.938312324523928, "actor_loss": -343.8271179199219, "actor_target_entropy": -2.0, "actor_entropy": 0.7132204623222351, "alpha_loss": -0.003280033078510314, "alpha_value": 0.07903984644217454, "duration": 75.87184691429138, "step": 73000}
{"episode_reward": 0.0, "episode": 293.0, "batch_reward": 2.181453125, "critic_loss": 18.28478343963623, "actor_loss": -342.9594228515625, "actor_target_entropy": -2.0, "actor_entropy": 0.7691809120178222, "alpha_loss": -0.004437653474044055, "alpha_value": 0.07957593089787472, "duration": 75.8374514579773, "step": 73250}
{"episode_reward": 987.0, "episode": 294.0, "batch_reward": 2.196375, "critic_loss": 17.514121486663818, "actor_loss": -343.82053466796873, "actor_target_entropy": -2.0, "actor_entropy": 0.7726030793190003, "alpha_loss": -0.0004856804804876447, "alpha_value": 0.0798309306113224, "duration": 75.82066655158997, "step": 73500}
{"episode_reward": 938.0, "episode": 295.0, "batch_reward": 2.1943046875, "critic_loss": 18.536831707000733, "actor_loss": -343.68729077148436, "actor_target_entropy": -2.0, "actor_entropy": 0.7290989246368408, "alpha_loss": -0.00024946552608162166, "alpha_value": 0.07982002523200309, "duration": 75.82556128501892, "step": 73750}
{"episode_reward": 1000.0, "episode": 296.0, "batch_reward": 2.2073828125, "critic_loss": 17.289581703186034, "actor_loss": -345.3524602050781, "actor_target_entropy": -2.0, "actor_entropy": 0.7185891184806824, "alpha_loss": -0.0002188560552895069, "alpha_value": 0.0799015600151455, "duration": 75.79385948181152, "step": 74000}
{"episode_reward": 589.0, "episode": 297.0, "batch_reward": 2.205046875, "critic_loss": 17.359152294158935, "actor_loss": -344.031224609375, "actor_target_entropy": -2.0, "actor_entropy": 0.6959402651786805, "alpha_loss": 0.0005814260626211763, "alpha_value": 0.07977534009141601, "duration": 75.81696796417236, "step": 74250}
{"episode_reward": 961.0, "episode": 298.0, "batch_reward": 2.2061796875, "critic_loss": 17.924901416778564, "actor_loss": -344.328953125, "actor_target_entropy": -2.0, "actor_entropy": 0.7477388768196106, "alpha_loss": 6.675999611616135e-06, "alpha_value": 0.07982225059926977, "duration": 75.84037327766418, "step": 74500}
{"episode_reward": 935.0, "episode": 299.0, "batch_reward": 2.2156015625, "critic_loss": 18.17887991333008, "actor_loss": -344.04567626953127, "actor_target_entropy": -2.0, "actor_entropy": 0.7310724787712097, "alpha_loss": -0.0018539971178397536, "alpha_value": 0.0799330129615856, "duration": 75.88036966323853, "step": 74750}
{"episode_reward": 977.0, "episode": 300.0, "batch_reward": 2.221921875, "critic_loss": 18.458642887115477, "actor_loss": -345.24862329101563, "actor_target_entropy": -2.0, "actor_entropy": 0.7181980123519898, "alpha_loss": 0.00018578170472756029, "alpha_value": 0.07990907893980326, "step": 75000}
{"duration": 93.80152440071106, "step": 75000}
{"episode_reward": 959.0, "episode": 301.0, "batch_reward": 2.2222265625, "critic_loss": 18.641715953826903, "actor_loss": -344.6327751464844, "actor_target_entropy": -2.0, "actor_entropy": 0.7535467119216919, "alpha_loss": -0.00037563404999673366, "alpha_value": 0.08004448284796874, "duration": 75.7670967578888, "step": 75250}
{"episode_reward": 7.0, "episode": 302.0, "batch_reward": 2.2123359375, "critic_loss": 17.950848392486574, "actor_loss": -343.0120261230469, "actor_target_entropy": -2.0, "actor_entropy": 0.7261355257034302, "alpha_loss": -0.0007548025520518422, "alpha_value": 0.08008827911056282, "duration": 75.82708859443665, "step": 75500}
{"episode_reward": 975.0, "episode": 303.0, "batch_reward": 2.2188125, "critic_loss": 18.165129013061524, "actor_loss": -343.84814453125, "actor_target_entropy": -2.0, "actor_entropy": 0.7538618507385254, "alpha_loss": -0.0010697119059041142, "alpha_value": 0.08012276033500622, "duration": 75.87907648086548, "step": 75750}
{"episode_reward": 137.0, "episode": 304.0, "batch_reward": 2.2127734375, "critic_loss": 17.82050371170044, "actor_loss": -342.6419191894531, "actor_target_entropy": -2.0, "actor_entropy": 0.7451085200309754, "alpha_loss": -0.0005448878202587366, "alpha_value": 0.08031732503335717, "duration": 75.80080461502075, "step": 76000}
{"episode_reward": 996.0, "episode": 305.0, "batch_reward": 2.21696875, "critic_loss": 17.94242896270752, "actor_loss": -344.4182802734375, "actor_target_entropy": -2.0, "actor_entropy": 0.72661399269104, "alpha_loss": -5.436524143442512e-05, "alpha_value": 0.08042693416546655, "duration": 75.75935935974121, "step": 76250}
{"episode_reward": 0.0, "episode": 306.0, "batch_reward": 2.21565625, "critic_loss": 18.60331854248047, "actor_loss": -344.1757602539063, "actor_target_entropy": -2.0, "actor_entropy": 0.7262057995796204, "alpha_loss": -0.00018899781117215751, "alpha_value": 0.08034742940882014, "duration": 75.58648633956909, "step": 76500}
{"episode_reward": 968.0, "episode": 307.0, "batch_reward": 2.2040625, "critic_loss": 17.602415351867677, "actor_loss": -342.2832734375, "actor_target_entropy": -2.0, "actor_entropy": 0.7321151747703553, "alpha_loss": -0.0014876498114317655, "alpha_value": 0.08050164953701437, "duration": 75.85636973381042, "step": 76750}
{"episode_reward": 98.0, "episode": 308.0, "batch_reward": 2.21678125, "critic_loss": 18.658326705932616, "actor_loss": -342.98263061523437, "actor_target_entropy": -2.0, "actor_entropy": 0.7664847888946533, "alpha_loss": 0.0003760390197858214, "alpha_value": 0.0804491545910925, "duration": 75.83137607574463, "step": 77000}
{"episode_reward": 23.0, "episode": 309.0, "batch_reward": 2.2092890625, "critic_loss": 17.8940136756897, "actor_loss": -343.3161459960937, "actor_target_entropy": -2.0, "actor_entropy": 0.7700547652244568, "alpha_loss": -0.0007833854751661419, "alpha_value": 0.08058454451972762, "duration": 76.05089020729065, "step": 77250}
{"episode_reward": 1000.0, "episode": 310.0, "batch_reward": 2.2249140625, "critic_loss": 17.34111434173584, "actor_loss": -343.2749921875, "actor_target_entropy": -2.0, "actor_entropy": 0.7668836865425109, "alpha_loss": 0.00226066102925688, "alpha_value": 0.08038988528896696, "duration": 75.78027892112732, "step": 77500}
{"episode_reward": 1000.0, "episode": 311.0, "batch_reward": 2.2128984375, "critic_loss": 17.359465969085694, "actor_loss": -343.027787109375, "actor_target_entropy": -2.0, "actor_entropy": 0.7568406791687011, "alpha_loss": 0.0006853084461763501, "alpha_value": 0.08029856862688205, "duration": 75.8365728855133, "step": 77750}
{"episode_reward": 961.0, "episode": 312.0, "batch_reward": 2.22859375, "critic_loss": 17.264897220611573, "actor_loss": -344.0657058105469, "actor_target_entropy": -2.0, "actor_entropy": 0.7650636768341065, "alpha_loss": 0.005407924046739936, "alpha_value": 0.07984545237460254, "duration": 75.83364844322205, "step": 78000}
{"episode_reward": 997.0, "episode": 313.0, "batch_reward": 2.2248125, "critic_loss": 17.276156604766847, "actor_loss": -342.3859558105469, "actor_target_entropy": -2.0, "actor_entropy": 0.717751006603241, "alpha_loss": 0.00541084101377055, "alpha_value": 0.07936173263984932, "duration": 75.95728874206543, "step": 78250}
{"episode_reward": 934.0, "episode": 314.0, "batch_reward": 2.24421875, "critic_loss": 17.369411373138426, "actor_loss": -343.943357421875, "actor_target_entropy": -2.0, "actor_entropy": 0.7224840197563172, "alpha_loss": 0.0020654461467638613, "alpha_value": 0.0789342561783995, "duration": 75.84126400947571, "step": 78500}
{"episode_reward": 933.0, "episode": 315.0, "batch_reward": 2.2408671875, "critic_loss": 17.299866794586183, "actor_loss": -343.3685085449219, "actor_target_entropy": -2.0, "actor_entropy": 0.7575335502624512, "alpha_loss": 0.001957359899766743, "alpha_value": 0.07871657214863131, "duration": 75.88730788230896, "step": 78750}
{"episode_reward": 0.0, "episode": 316.0, "batch_reward": 2.2260625, "critic_loss": 16.602568187713622, "actor_loss": -343.57768627929687, "actor_target_entropy": -2.0, "actor_entropy": 0.702221652507782, "alpha_loss": 0.003968074692413211, "alpha_value": 0.07839311750256159, "duration": 75.87528109550476, "step": 79000}
{"episode_reward": 960.0, "episode": 317.0, "batch_reward": 2.234109375, "critic_loss": 17.084666774749756, "actor_loss": -343.83574926757814, "actor_target_entropy": -2.0, "actor_entropy": 0.7174021162986756, "alpha_loss": 0.0021010270016267895, "alpha_value": 0.07809331429805604, "duration": 75.81538152694702, "step": 79250}
{"episode_reward": 987.0, "episode": 318.0, "batch_reward": 2.23546875, "critic_loss": 16.686311931610106, "actor_loss": -343.1611962890625, "actor_target_entropy": -2.0, "actor_entropy": 0.7090641498565674, "alpha_loss": 0.0016499316450208426, "alpha_value": 0.07792532027356575, "duration": 75.85520315170288, "step": 79500}
{"episode_reward": 268.0, "episode": 319.0, "batch_reward": 2.23484375, "critic_loss": 16.460745220184325, "actor_loss": -342.35327783203127, "actor_target_entropy": -2.0, "actor_entropy": 0.7169208636283875, "alpha_loss": 0.0052413729075342416, "alpha_value": 0.0775531602173955, "duration": 75.86729550361633, "step": 79750}
{"episode_reward": 0.0, "episode": 320.0, "batch_reward": 2.234109375, "critic_loss": 16.07072538757324, "actor_loss": -341.75885620117185, "actor_target_entropy": -2.0, "actor_entropy": 0.7080809016227723, "alpha_loss": 0.005252672035247087, "alpha_value": 0.07695455495850552, "step": 80000}
{"duration": 93.9414553642273, "step": 80000}
{"episode_reward": 976.0, "episode": 321.0, "batch_reward": 2.2336328125, "critic_loss": 15.933862495422364, "actor_loss": -342.04074951171873, "actor_target_entropy": -2.0, "actor_entropy": 0.6741982169151306, "alpha_loss": 0.004313191668130457, "alpha_value": 0.07642414255168838, "duration": 75.68620157241821, "step": 80250}
{"episode_reward": 0.0, "episode": 322.0, "batch_reward": 2.2296484375, "critic_loss": 16.775518672943114, "actor_loss": -341.9873093261719, "actor_target_entropy": -2.0, "actor_entropy": 0.6806524744033814, "alpha_loss": -0.0010149923330172897, "alpha_value": 0.07631099042784124, "duration": 75.74930262565613, "step": 80500}
{"episode_reward": 334.0, "episode": 323.0, "batch_reward": 2.218703125, "critic_loss": 17.273779636383058, "actor_loss": -341.20294677734375, "actor_target_entropy": -2.0, "actor_entropy": 0.6936427297592163, "alpha_loss": -0.0015986066963523627, "alpha_value": 0.07642254296252617, "duration": 75.75575590133667, "step": 80750}
{"episode_reward": 2.0, "episode": 324.0, "batch_reward": 2.2176171875, "critic_loss": 16.8205107421875, "actor_loss": -341.26027978515623, "actor_target_entropy": -2.0, "actor_entropy": 0.729266342163086, "alpha_loss": -0.0017656954298727215, "alpha_value": 0.07658522069909034, "duration": 75.69686365127563, "step": 81000}
{"episode_reward": 421.0, "episode": 325.0, "batch_reward": 2.219015625, "critic_loss": 16.663934703826904, "actor_loss": -341.18188745117186, "actor_target_entropy": -2.0, "actor_entropy": 0.7013608717918396, "alpha_loss": -0.0004843955999240279, "alpha_value": 0.076668755667807, "duration": 75.80120158195496, "step": 81250}
{"episode_reward": 948.0, "episode": 326.0, "batch_reward": 2.2185546875, "critic_loss": 16.619331336975097, "actor_loss": -341.388771484375, "actor_target_entropy": -2.0, "actor_entropy": 0.6980389485359192, "alpha_loss": 0.0006032083155587315, "alpha_value": 0.07673797920485233, "duration": 75.7204122543335, "step": 81500}
{"episode_reward": 961.0, "episode": 327.0, "batch_reward": 2.2361328125, "critic_loss": 16.5601106300354, "actor_loss": -341.38386157226563, "actor_target_entropy": -2.0, "actor_entropy": 0.672777214050293, "alpha_loss": 0.004194931556936354, "alpha_value": 0.07635628972319865, "duration": 75.60687589645386, "step": 81750}
{"episode_reward": 973.0, "episode": 328.0, "batch_reward": 2.2382734375, "critic_loss": 17.500134891510008, "actor_loss": -341.012248046875, "actor_target_entropy": -2.0, "actor_entropy": 0.6995534043312073, "alpha_loss": -0.0010076520862057805, "alpha_value": 0.0762652324911254, "duration": 75.81424617767334, "step": 82000}
{"episode_reward": 967.0, "episode": 329.0, "batch_reward": 2.2408359375, "critic_loss": 17.074310417175294, "actor_loss": -341.7487946777344, "actor_target_entropy": -2.0, "actor_entropy": 0.7223059754371643, "alpha_loss": -0.002149785989895463, "alpha_value": 0.07647575702058039, "duration": 75.93592286109924, "step": 82250}
{"episode_reward": 992.0, "episode": 330.0, "batch_reward": 2.2459609375, "critic_loss": 16.13544989776611, "actor_loss": -340.9382629394531, "actor_target_entropy": -2.0, "actor_entropy": 0.7174845929145813, "alpha_loss": -0.0004261696734465659, "alpha_value": 0.07659826988853158, "duration": 75.8652229309082, "step": 82500}
{"episode_reward": 125.0, "episode": 331.0, "batch_reward": 2.23196875, "critic_loss": 16.23681926727295, "actor_loss": -338.90698413085937, "actor_target_entropy": -2.0, "actor_entropy": 0.6733085012435913, "alpha_loss": 0.0035033053243532777, "alpha_value": 0.07639846368940478, "duration": 75.77180123329163, "step": 82750}
{"episode_reward": 960.0, "episode": 332.0, "batch_reward": 2.247640625, "critic_loss": 16.136808414459228, "actor_loss": -340.3897009277344, "actor_target_entropy": -2.0, "actor_entropy": 0.6331316399574279, "alpha_loss": 0.0011110553764738143, "alpha_value": 0.07615601981101033, "duration": 75.80450654029846, "step": 83000}
{"episode_reward": 928.0, "episode": 333.0, "batch_reward": 2.2552109375, "critic_loss": 16.352195247650148, "actor_loss": -340.8164150390625, "actor_target_entropy": -2.0, "actor_entropy": 0.6807296614646912, "alpha_loss": -0.0018081162427552044, "alpha_value": 0.07627143254076202, "duration": 75.85486555099487, "step": 83250}
{"episode_reward": 978.0, "episode": 334.0, "batch_reward": 2.24434375, "critic_loss": 16.727914825439452, "actor_loss": -340.0457648925781, "actor_target_entropy": -2.0, "actor_entropy": 0.700859591960907, "alpha_loss": 1.2088372372090816e-05, "alpha_value": 0.07626959391798584, "duration": 75.84952402114868, "step": 83500}
{"episode_reward": 971.0, "episode": 335.0, "batch_reward": 2.2714296875, "critic_loss": 16.51212376022339, "actor_loss": -342.3023376464844, "actor_target_entropy": -2.0, "actor_entropy": 0.6691640248298645, "alpha_loss": 0.0025948405358940363, "alpha_value": 0.07619790701931474, "duration": 75.9026243686676, "step": 83750}
{"episode_reward": 998.0, "episode": 336.0, "batch_reward": 2.260046875, "critic_loss": 16.326399478912354, "actor_loss": -341.19776953125, "actor_target_entropy": -2.0, "actor_entropy": 0.6586619453430176, "alpha_loss": 0.0006567857684567571, "alpha_value": 0.07605674732347142, "duration": 75.89424753189087, "step": 84000}
{"episode_reward": 0.0, "episode": 337.0, "batch_reward": 2.258015625, "critic_loss": 16.05829860305786, "actor_loss": -340.75781396484376, "actor_target_entropy": -2.0, "actor_entropy": 0.6807643361091614, "alpha_loss": 0.0018089172346517444, "alpha_value": 0.07591946030958087, "duration": 75.95015001296997, "step": 84250}
{"episode_reward": 961.0, "episode": 338.0, "batch_reward": 2.2591015625, "critic_loss": 16.020243213653565, "actor_loss": -340.6867265625, "actor_target_entropy": -2.0, "actor_entropy": 0.6772423272132874, "alpha_loss": -0.0017399040828458964, "alpha_value": 0.07589155834590439, "duration": 75.97974729537964, "step": 84500}
{"episode_reward": 990.0, "episode": 339.0, "batch_reward": 2.263265625, "critic_loss": 16.6453819770813, "actor_loss": -340.1540556640625, "actor_target_entropy": -2.0, "actor_entropy": 0.6749945774078369, "alpha_loss": 0.00048419394856318834, "alpha_value": 0.0759821943426446, "duration": 75.81783127784729, "step": 84750}
{"episode_reward": 0.0, "episode": 340.0, "batch_reward": 2.2626484375, "critic_loss": 16.55838091659546, "actor_loss": -340.65670458984374, "actor_target_entropy": -2.0, "actor_entropy": 0.6564504592418671, "alpha_loss": 0.002038848761469126, "alpha_value": 0.07574486204956217, "step": 85000}
{"duration": 93.77795124053955, "step": 85000}
{"episode_reward": 985.0, "episode": 341.0, "batch_reward": 2.2625078125, "critic_loss": 16.156612976074218, "actor_loss": -340.30513110351563, "actor_target_entropy": -2.0, "actor_entropy": 0.662371819972992, "alpha_loss": 0.0011200939472764731, "alpha_value": 0.07556602927073733, "duration": 75.82579946517944, "step": 85250}
{"episode_reward": 957.0, "episode": 342.0, "batch_reward": 2.2806640625, "critic_loss": 15.917429145812989, "actor_loss": -340.6872446289062, "actor_target_entropy": -2.0, "actor_entropy": 0.6336944777965545, "alpha_loss": 0.0035888030109927057, "alpha_value": 0.07524138929459476, "duration": 75.90596961975098, "step": 85500}
{"episode_reward": 958.0, "episode": 343.0, "batch_reward": 2.2701171875, "critic_loss": 16.27607233428955, "actor_loss": -340.42284301757815, "actor_target_entropy": -2.0, "actor_entropy": 0.6567515993118286, "alpha_loss": -0.00039549309434369205, "alpha_value": 0.07521353674447805, "duration": 75.83395171165466, "step": 85750}
{"episode_reward": 961.0, "episode": 344.0, "batch_reward": 2.285984375, "critic_loss": 16.596103523254396, "actor_loss": -341.01692138671876, "actor_target_entropy": -2.0, "actor_entropy": 0.6390929517745971, "alpha_loss": 0.002631368794012815, "alpha_value": 0.0750897465600631, "duration": 75.86270475387573, "step": 86000}
{"episode_reward": 388.0, "episode": 345.0, "batch_reward": 2.279984375, "critic_loss": 16.454048885345458, "actor_loss": -341.37197802734374, "actor_target_entropy": -2.0, "actor_entropy": 0.6304234046936035, "alpha_loss": 0.0013464763294905424, "alpha_value": 0.07488003477675462, "duration": 75.80972743034363, "step": 86250}
{"episode_reward": 947.0, "episode": 346.0, "batch_reward": 2.292109375, "critic_loss": 16.14520548248291, "actor_loss": -340.45102783203123, "actor_target_entropy": -2.0, "actor_entropy": 0.6046059284210205, "alpha_loss": 0.005518463139422238, "alpha_value": 0.07444806767616514, "duration": 75.84875988960266, "step": 86500}
{"episode_reward": 976.0, "episode": 347.0, "batch_reward": 2.2748671875, "critic_loss": 15.897895637512207, "actor_loss": -339.98303442382814, "actor_target_entropy": -2.0, "actor_entropy": 0.5834557483196259, "alpha_loss": 0.004362966157495976, "alpha_value": 0.0739660008403775, "duration": 75.6412444114685, "step": 86750}
{"episode_reward": 0.0, "episode": 348.0, "batch_reward": 2.2843359375, "critic_loss": 15.337181388854981, "actor_loss": -339.98867529296876, "actor_target_entropy": -2.0, "actor_entropy": 0.5806036126613617, "alpha_loss": 0.006667257698252797, "alpha_value": 0.07336767098850952, "duration": 75.82449316978455, "step": 87000}
{"episode_reward": 989.0, "episode": 349.0, "batch_reward": 2.2972890625, "critic_loss": 15.685782527923584, "actor_loss": -340.63067016601565, "actor_target_entropy": -2.0, "actor_entropy": 0.5832884666919709, "alpha_loss": 0.005775879417080432, "alpha_value": 0.07271546622489874, "duration": 75.83994746208191, "step": 87250}
{"episode_reward": 954.0, "episode": 350.0, "batch_reward": 2.28078125, "critic_loss": 15.528917026519775, "actor_loss": -339.6395847167969, "actor_target_entropy": -2.0, "actor_entropy": 0.5542225687503815, "alpha_loss": 0.0029832397727295756, "alpha_value": 0.07230290637770863, "duration": 75.88093948364258, "step": 87500}
{"episode_reward": 968.0, "episode": 351.0, "batch_reward": 2.291, "critic_loss": 15.615859359741211, "actor_loss": -340.21758154296873, "actor_target_entropy": -2.0, "actor_entropy": 0.6244497616291046, "alpha_loss": 0.003322704759426415, "alpha_value": 0.07192016810141424, "duration": 75.95764589309692, "step": 87750}
{"episode_reward": 995.0, "episode": 352.0, "batch_reward": 2.2995625, "critic_loss": 15.759975666046143, "actor_loss": -340.88166381835936, "actor_target_entropy": -2.0, "actor_entropy": 0.5641463742256164, "alpha_loss": 0.0028613450936973094, "alpha_value": 0.07159066766130583, "duration": 75.9106879234314, "step": 88000}
{"episode_reward": 974.0, "episode": 353.0, "batch_reward": 2.2951953125, "critic_loss": 15.62801000213623, "actor_loss": -340.088212890625, "actor_target_entropy": -2.0, "actor_entropy": 0.5762164373397827, "alpha_loss": 0.000911530907265842, "alpha_value": 0.07139613558716237, "duration": 75.76419138908386, "step": 88250}
{"episode_reward": 947.0, "episode": 354.0, "batch_reward": 2.309, "critic_loss": 15.73659358215332, "actor_loss": -339.84151879882813, "actor_target_entropy": -2.0, "actor_entropy": 0.599116821527481, "alpha_loss": -0.0005276932748965919, "alpha_value": 0.07143907321850974, "duration": 75.81626057624817, "step": 88500}
{"episode_reward": 965.0, "episode": 355.0, "batch_reward": 2.309953125, "critic_loss": 15.451854949951171, "actor_loss": -339.485875, "actor_target_entropy": -2.0, "actor_entropy": 0.6214799685478211, "alpha_loss": 0.002517429949250072, "alpha_value": 0.07133725761567983, "duration": 75.8315978050232, "step": 88750}
{"episode_reward": 961.0, "episode": 356.0, "batch_reward": 2.31284375, "critic_loss": 15.21934508895874, "actor_loss": -340.5260849609375, "actor_target_entropy": -2.0, "actor_entropy": 0.6146352391242981, "alpha_loss": -0.0001838971092365682, "alpha_value": 0.07119188597924957, "duration": 75.89121389389038, "step": 89000}
{"episode_reward": 994.0, "episode": 357.0, "batch_reward": 2.3195625, "critic_loss": 15.870604290008545, "actor_loss": -340.38856420898435, "actor_target_entropy": -2.0, "actor_entropy": 0.6283667330741882, "alpha_loss": 0.001743938522413373, "alpha_value": 0.0711225649876437, "duration": 75.78698348999023, "step": 89250}
{"episode_reward": 969.0, "episode": 358.0, "batch_reward": 2.3233671875, "critic_loss": 15.095967643737794, "actor_loss": -340.7838369140625, "actor_target_entropy": -2.0, "actor_entropy": 0.6382881979942322, "alpha_loss": 1.2542330659925938e-05, "alpha_value": 0.07098343541546971, "duration": 75.87885189056396, "step": 89500}
{"episode_reward": 955.0, "episode": 359.0, "batch_reward": 2.330234375, "critic_loss": 14.322013694763184, "actor_loss": -340.7884731445312, "actor_target_entropy": -2.0, "actor_entropy": 0.6212803254127502, "alpha_loss": 0.001285780739504844, "alpha_value": 0.07095550520588209, "duration": 75.92050814628601, "step": 89750}
{"episode_reward": 980.0, "episode": 360.0, "batch_reward": 2.3388125, "critic_loss": 14.674480262756347, "actor_loss": -340.5986608886719, "actor_target_entropy": -2.0, "actor_entropy": 0.6168616166114808, "alpha_loss": 0.0012415628950111569, "alpha_value": 0.07073467047411884, "step": 90000}
{"duration": 93.88075423240662, "step": 90000}
{"episode_reward": 996.0, "episode": 361.0, "batch_reward": 2.3340625, "critic_loss": 14.961109951019287, "actor_loss": -341.5432001953125, "actor_target_entropy": -2.0, "actor_entropy": 0.6739238667488098, "alpha_loss": -0.0023277387768030166, "alpha_value": 0.0708185841006212, "duration": 75.7880220413208, "step": 90250}
{"episode_reward": 977.0, "episode": 362.0, "batch_reward": 2.34071875, "critic_loss": 15.088464469909669, "actor_loss": -340.8865107421875, "actor_target_entropy": -2.0, "actor_entropy": 0.665691608428955, "alpha_loss": 0.00013433129945769905, "alpha_value": 0.07097017729271267, "duration": 75.74998831748962, "step": 90500}
{"episode_reward": 0.0, "episode": 363.0, "batch_reward": 2.330671875, "critic_loss": 14.821093692779542, "actor_loss": -340.8025087890625, "actor_target_entropy": -2.0, "actor_entropy": 0.7123389673233033, "alpha_loss": -0.002320273765362799, "alpha_value": 0.07114055713615933, "duration": 75.89254331588745, "step": 90750}
{"episode_reward": 959.0, "episode": 364.0, "batch_reward": 2.331484375, "critic_loss": 14.41637755203247, "actor_loss": -340.6486762695312, "actor_target_entropy": -2.0, "actor_entropy": 0.702322169303894, "alpha_loss": -0.001633960151579231, "alpha_value": 0.07132703721616589, "duration": 75.77139163017273, "step": 91000}
{"episode_reward": 505.0, "episode": 365.0, "batch_reward": 2.339296875, "critic_loss": 15.027994804382324, "actor_loss": -340.4797746582031, "actor_target_entropy": -2.0, "actor_entropy": 0.6788100051879883, "alpha_loss": 0.003869484219234437, "alpha_value": 0.07123706521523612, "duration": 75.92257881164551, "step": 91250}
{"episode_reward": 969.0, "episode": 366.0, "batch_reward": 2.339578125, "critic_loss": 14.530459209442139, "actor_loss": -340.7296784667969, "actor_target_entropy": -2.0, "actor_entropy": 0.6422809457778931, "alpha_loss": 0.002763778912834823, "alpha_value": 0.07074491625283537, "duration": 75.8837583065033, "step": 91500}
{"episode_reward": 961.0, "episode": 367.0, "batch_reward": 2.3403203125, "critic_loss": 14.439168251037598, "actor_loss": -341.0132194824219, "actor_target_entropy": -2.0, "actor_entropy": 0.6523467712402343, "alpha_loss": 0.001765485057607293, "alpha_value": 0.07053694246877107, "duration": 75.75465559959412, "step": 91750}
{"episode_reward": 0.0, "episode": 368.0, "batch_reward": 2.33578125, "critic_loss": 14.260090965270996, "actor_loss": -339.63323583984373, "actor_target_entropy": -2.0, "actor_entropy": 0.6868299632072449, "alpha_loss": 0.0021808267813175916, "alpha_value": 0.07031199624450413, "duration": 75.72662043571472, "step": 92000}
{"episode_reward": 991.0, "episode": 369.0, "batch_reward": 2.3437578125, "critic_loss": 14.537427631378174, "actor_loss": -340.0260739746094, "actor_target_entropy": -2.0, "actor_entropy": 0.6900445387363434, "alpha_loss": -0.0019974608318880202, "alpha_value": 0.0703258324915386, "duration": 75.82876944541931, "step": 92250}
{"episode_reward": 997.0, "episode": 370.0, "batch_reward": 2.3442421875, "critic_loss": 14.284945785522462, "actor_loss": -341.8718830566406, "actor_target_entropy": -2.0, "actor_entropy": 0.6682150530815124, "alpha_loss": -0.003593518849462271, "alpha_value": 0.07063545051581058, "duration": 75.82729649543762, "step": 92500}
{"episode_reward": 981.0, "episode": 371.0, "batch_reward": 2.34953125, "critic_loss": 14.602070617675782, "actor_loss": -340.82605078125, "actor_target_entropy": -2.0, "actor_entropy": 0.7398996200561524, "alpha_loss": -0.0022579379584640263, "alpha_value": 0.07095333960922016, "duration": 75.87437605857849, "step": 92750}
{"episode_reward": 978.0, "episode": 372.0, "batch_reward": 2.353234375, "critic_loss": 14.339554859161376, "actor_loss": -340.8623903808594, "actor_target_entropy": -2.0, "actor_entropy": 0.7300612854957581, "alpha_loss": -0.000425415079575032, "alpha_value": 0.07110362289939429, "duration": 75.81005477905273, "step": 93000}
{"episode_reward": 964.0, "episode": 373.0, "batch_reward": 2.367296875, "critic_loss": 14.063380031585693, "actor_loss": -342.5356977539063, "actor_target_entropy": -2.0, "actor_entropy": 0.6948046660423279, "alpha_loss": -0.0012813997403718531, "alpha_value": 0.07116636029050896, "duration": 75.83019161224365, "step": 93250}
{"episode_reward": 957.0, "episode": 374.0, "batch_reward": 2.3700390625, "critic_loss": 13.98748938369751, "actor_loss": -341.62659326171877, "actor_target_entropy": -2.0, "actor_entropy": 0.6879245462417602, "alpha_loss": -0.0005200415076687932, "alpha_value": 0.07133548749435954, "duration": 75.88179326057434, "step": 93500}
{"episode_reward": 876.0, "episode": 375.0, "batch_reward": 2.36265625, "critic_loss": 13.9285202293396, "actor_loss": -342.19768310546874, "actor_target_entropy": -2.0, "actor_entropy": 0.684154676914215, "alpha_loss": 0.0008562242873013019, "alpha_value": 0.07128843324393323, "duration": 75.89166378974915, "step": 93750}
{"episode_reward": 947.0, "episode": 376.0, "batch_reward": 2.377609375, "critic_loss": 14.25734630203247, "actor_loss": -342.2910061035156, "actor_target_entropy": -2.0, "actor_entropy": 0.7000562953948974, "alpha_loss": 0.003749916974455118, "alpha_value": 0.07102726537861308, "duration": 75.82208776473999, "step": 94000}
{"episode_reward": 955.0, "episode": 377.0, "batch_reward": 2.3776171875, "critic_loss": 13.215686809539795, "actor_loss": -341.81994775390626, "actor_target_entropy": -2.0, "actor_entropy": 0.6612957487106323, "alpha_loss": 0.0002639478128403425, "alpha_value": 0.07081071095770564, "duration": 75.8754711151123, "step": 94250}
{"episode_reward": 959.0, "episode": 378.0, "batch_reward": 2.3727109375, "critic_loss": 14.033028076171876, "actor_loss": -341.8821818847656, "actor_target_entropy": -2.0, "actor_entropy": 0.6721961364746094, "alpha_loss": -0.002750290900468826, "alpha_value": 0.07095426396140227, "duration": 75.86304330825806, "step": 94500}
{"episode_reward": 0.0, "episode": 379.0, "batch_reward": 2.374640625, "critic_loss": 14.041760467529297, "actor_loss": -342.9084755859375, "actor_target_entropy": -2.0, "actor_entropy": 0.6927869987487792, "alpha_loss": -0.000531137048266828, "alpha_value": 0.07112581988784043, "duration": 75.96980810165405, "step": 94750}
{"episode_reward": 979.0, "episode": 380.0, "batch_reward": 2.3740234375, "critic_loss": 13.316970523834229, "actor_loss": -342.5205769042969, "actor_target_entropy": -2.0, "actor_entropy": 0.6639291563034058, "alpha_loss": -0.0004545709518715739, "alpha_value": 0.07121214209845132, "step": 95000}
{"duration": 93.82862257957458, "step": 95000}
{"episode_reward": 953.0, "episode": 381.0, "batch_reward": 2.38325, "critic_loss": 13.755429950714111, "actor_loss": -343.6155168457031, "actor_target_entropy": -2.0, "actor_entropy": 0.7110665655136108, "alpha_loss": -0.0013309617210179568, "alpha_value": 0.07127703370262205, "duration": 75.7772765159607, "step": 95250}
{"episode_reward": 984.0, "episode": 382.0, "batch_reward": 2.3771015625, "critic_loss": 13.114793197631837, "actor_loss": -342.7098623046875, "actor_target_entropy": -2.0, "actor_entropy": 0.6933930172920227, "alpha_loss": -0.0025194348488003014, "alpha_value": 0.07154967000941158, "duration": 75.73263478279114, "step": 95500}
{"episode_reward": 0.0, "episode": 383.0, "batch_reward": 2.3696015625, "critic_loss": 13.467167194366455, "actor_loss": -342.69420190429685, "actor_target_entropy": -2.0, "actor_entropy": 0.6799811892509461, "alpha_loss": 0.0004627009616233408, "alpha_value": 0.07165621965247043, "duration": 75.80927515029907, "step": 95750}
{"episode_reward": 59.0, "episode": 384.0, "batch_reward": 2.371609375, "critic_loss": 13.822133666992187, "actor_loss": -341.85684008789065, "actor_target_entropy": -2.0, "actor_entropy": 0.6948282294273377, "alpha_loss": -0.000974019284825772, "alpha_value": 0.07163885006426186, "duration": 75.74454355239868, "step": 96000}
{"episode_reward": 968.0, "episode": 385.0, "batch_reward": 2.3754296875, "critic_loss": 13.526283138275147, "actor_loss": -341.98028369140627, "actor_target_entropy": -2.0, "actor_entropy": 0.6983172888755799, "alpha_loss": 0.0005555297378450632, "alpha_value": 0.0716538974144966, "duration": 75.95157623291016, "step": 96250}
{"episode_reward": 972.0, "episode": 386.0, "batch_reward": 2.3892421875, "critic_loss": 13.519333782196044, "actor_loss": -342.8399770507813, "actor_target_entropy": -2.0, "actor_entropy": 0.6895296025276184, "alpha_loss": 0.001909296699333936, "alpha_value": 0.07148788622930309, "duration": 75.81994891166687, "step": 96500}
{"episode_reward": 995.0, "episode": 387.0, "batch_reward": 2.3943671875, "critic_loss": 14.104391201019286, "actor_loss": -342.5155817871094, "actor_target_entropy": -2.0, "actor_entropy": 0.6641086463928223, "alpha_loss": 0.001323458144441247, "alpha_value": 0.0713135430222112, "duration": 75.85794425010681, "step": 96750}
{"episode_reward": 979.0, "episode": 388.0, "batch_reward": 2.39228125, "critic_loss": 13.794331298828125, "actor_loss": -342.63944360351564, "actor_target_entropy": -2.0, "actor_entropy": 0.6851761269569397, "alpha_loss": -0.0012893953253515064, "alpha_value": 0.07134176656481857, "duration": 75.64313268661499, "step": 97000}
{"episode_reward": 977.0, "episode": 389.0, "batch_reward": 2.38459375, "critic_loss": 13.519375995635986, "actor_loss": -341.95231591796875, "actor_target_entropy": -2.0, "actor_entropy": 0.6773784604072571, "alpha_loss": 0.0006043472359888256, "alpha_value": 0.0713707624364655, "duration": 75.91790890693665, "step": 97250}
{"episode_reward": 974.0, "episode": 390.0, "batch_reward": 2.3920859375, "critic_loss": 13.579586174011231, "actor_loss": -342.1104416503906, "actor_target_entropy": -2.0, "actor_entropy": 0.6685755529403686, "alpha_loss": -3.862200537696481e-05, "alpha_value": 0.07134093456386754, "duration": 75.82944059371948, "step": 97500}
{"episode_reward": 983.0, "episode": 391.0, "batch_reward": 2.396828125, "critic_loss": 13.407278949737549, "actor_loss": -342.7305029296875, "actor_target_entropy": -2.0, "actor_entropy": 0.6664813632965088, "alpha_loss": -0.00017392789525911211, "alpha_value": 0.07138122450511437, "duration": 75.89019560813904, "step": 97750}
{"episode_reward": 975.0, "episode": 392.0, "batch_reward": 2.4071015625, "critic_loss": 13.63104048538208, "actor_loss": -342.8432192382812, "actor_target_entropy": -2.0, "actor_entropy": 0.7154922747611999, "alpha_loss": 0.0002778899702243507, "alpha_value": 0.07140484106653854, "duration": 75.82524085044861, "step": 98000}
{"episode_reward": 967.0, "episode": 393.0, "batch_reward": 2.4108046875, "critic_loss": 14.387283393859864, "actor_loss": -343.6777546386719, "actor_target_entropy": -2.0, "actor_entropy": 0.7290079412460327, "alpha_loss": -0.002173889223020524, "alpha_value": 0.07147420433855675, "duration": 75.85166358947754, "step": 98250}
{"episode_reward": 954.0, "episode": 394.0, "batch_reward": 2.413265625, "critic_loss": 13.601104991912841, "actor_loss": -342.59426831054685, "actor_target_entropy": -2.0, "actor_entropy": 0.7010109438896179, "alpha_loss": -0.0019275758918374777, "alpha_value": 0.07163513672037525, "duration": 75.86127495765686, "step": 98500}
{"episode_reward": 983.0, "episode": 395.0, "batch_reward": 2.423375, "critic_loss": 13.266474632263183, "actor_loss": -343.76948022460937, "actor_target_entropy": -2.0, "actor_entropy": 0.7159083638191223, "alpha_loss": -0.001128676506690681, "alpha_value": 0.0717956800478165, "duration": 75.89728546142578, "step": 98750}
{"episode_reward": 986.0, "episode": 396.0, "batch_reward": 2.419640625, "critic_loss": 13.686186004638673, "actor_loss": -344.3432922363281, "actor_target_entropy": -2.0, "actor_entropy": 0.6981030478477478, "alpha_loss": -0.00037836682703346015, "alpha_value": 0.07189267261887014, "duration": 75.76361393928528, "step": 99000}
{"episode_reward": 987.0, "episode": 397.0, "batch_reward": 2.42015625, "critic_loss": 13.544144863128663, "actor_loss": -344.50950732421876, "actor_target_entropy": -2.0, "actor_entropy": 0.7131537070274353, "alpha_loss": 0.0003987944219261408, "alpha_value": 0.07192932108525765, "duration": 75.80032300949097, "step": 99250}
{"episode_reward": 958.0, "episode": 398.0, "batch_reward": 2.42021875, "critic_loss": 13.529987422943115, "actor_loss": -344.3877890625, "actor_target_entropy": -2.0, "actor_entropy": 0.6978341584205627, "alpha_loss": 0.001243425568100065, "alpha_value": 0.07187324961076286, "duration": 75.8344292640686, "step": 99500}
{"episode_reward": 966.0, "episode": 399.0, "batch_reward": 2.4260234375, "critic_loss": 12.603084318161011, "actor_loss": -344.6684794921875, "actor_target_entropy": -2.0, "actor_entropy": 0.6823992309570313, "alpha_loss": 0.0016058569345623254, "alpha_value": 0.0716839764299777, "duration": 75.88522386550903, "step": 99750}
{"episode_reward": 463.0, "episode": 400.0, "batch_reward": 2.434487951807229, "critic_loss": 13.238191826755264, "actor_loss": -344.83832250976565, "actor_target_entropy": -2.0, "actor_entropy": 0.7067606964111328, "alpha_loss": -0.0012767197703942657, "alpha_value": 0.07165696126597075, "step": 99999}
