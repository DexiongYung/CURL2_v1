{"episode_reward": 0.0, "episode": 1.0, "duration": 20.775434494018555, "step": 250}
{"episode_reward": 5.0, "episode": 2.0, "duration": 0.7317824363708496, "step": 500}
{"episode_reward": 0.0, "episode": 3.0, "duration": 0.7321486473083496, "step": 750}
{"episode_reward": 0.0, "episode": 4.0, "duration": 0.7308902740478516, "step": 1000}
{"episode_reward": 201.0, "episode": 5.0, "batch_reward": 0.2528515625, "critic_loss": 0.9706124938130378, "actor_loss": -0.6708727077841758, "actor_target_entropy": -2.0, "actor_entropy": 2.469330229282379, "alpha_loss": 0.31252229410409926, "alpha_value": 0.09941512395369971, "duration": 75.35404086112976, "step": 1250}
{"episode_reward": 99.0, "episode": 6.0, "batch_reward": 0.26053125, "critic_loss": 0.4642687177658081, "actor_loss": -1.0808209805488587, "actor_target_entropy": -2.0, "actor_entropy": 2.5107942848205567, "alpha_loss": 0.30675169587135315, "alpha_value": 0.09817621185119235, "duration": 75.56740164756775, "step": 1500}
{"episode_reward": 97.0, "episode": 7.0, "batch_reward": 0.2457890625, "critic_loss": 0.4642365021705627, "actor_loss": -1.5070597200393676, "actor_target_entropy": -2.0, "actor_entropy": 2.396833812713623, "alpha_loss": 0.27655147671699526, "alpha_value": 0.09706129909348202, "duration": 75.62116837501526, "step": 1750}
{"episode_reward": 0.0, "episode": 8.0, "batch_reward": 0.21846875, "critic_loss": 0.41258998411893844, "actor_loss": -1.9679023456573486, "actor_target_entropy": -2.0, "actor_entropy": 2.357738977432251, "alpha_loss": 0.2632553173303604, "alpha_value": 0.0959752836348087, "duration": 75.77733182907104, "step": 2000}
{"episode_reward": 20.0, "episode": 9.0, "batch_reward": 0.19503125, "critic_loss": 0.7213456449508667, "actor_loss": -2.5209197187423706, "actor_target_entropy": -2.0, "actor_entropy": 2.272409119606018, "alpha_loss": 0.24462043273448944, "alpha_value": 0.09493366346980765, "duration": 75.82564854621887, "step": 2250}
{"episode_reward": 18.0, "episode": 10.0, "batch_reward": 0.186171875, "critic_loss": 0.765033635020256, "actor_loss": -3.290500110626221, "actor_target_entropy": -2.0, "actor_entropy": 2.201947410583496, "alpha_loss": 0.22381037175655366, "alpha_value": 0.09394291038311103, "duration": 75.81995487213135, "step": 2500}
{"episode_reward": 0.0, "episode": 11.0, "batch_reward": 0.291359375, "critic_loss": 1.5490844328403472, "actor_loss": -5.209106645584106, "actor_target_entropy": -2.0, "actor_entropy": 2.181012208938599, "alpha_loss": 0.1871988205909729, "alpha_value": 0.09303725794175909, "duration": 75.79772782325745, "step": 2750}
{"episode_reward": 826.0, "episode": 12.0, "batch_reward": 0.44596875, "critic_loss": 1.2376817972660066, "actor_loss": -7.822904273986817, "actor_target_entropy": -2.0, "actor_entropy": 2.1218063945770265, "alpha_loss": 0.15598572462797164, "alpha_value": 0.09226094510134833, "duration": 75.89954423904419, "step": 3000}
{"episode_reward": 0.0, "episode": 13.0, "batch_reward": 0.4097734375, "critic_loss": 1.616096339225769, "actor_loss": -9.657188999176025, "actor_target_entropy": -2.0, "actor_entropy": 1.99595920753479, "alpha_loss": 0.12238995295763015, "alpha_value": 0.0915792973172485, "duration": 75.81629657745361, "step": 3250}
{"episode_reward": 0.0, "episode": 14.0, "batch_reward": 0.4022578125, "critic_loss": 1.9279734811782836, "actor_loss": -11.519018608093262, "actor_target_entropy": -2.0, "actor_entropy": 1.8966789999008178, "alpha_loss": 0.07562092535197734, "alpha_value": 0.09107168039875588, "duration": 75.8365249633789, "step": 3500}
{"episode_reward": 347.0, "episode": 15.0, "batch_reward": 0.4840546875, "critic_loss": 2.49899658536911, "actor_loss": -13.933182456970215, "actor_target_entropy": -2.0, "actor_entropy": 1.8230782327651978, "alpha_loss": 0.06322904248535634, "alpha_value": 0.09071086280132602, "duration": 75.82113552093506, "step": 3750}
{"episode_reward": 465.0, "episode": 16.0, "batch_reward": 0.588203125, "critic_loss": 2.8707987666130066, "actor_loss": -17.196132675170897, "actor_target_entropy": -2.0, "actor_entropy": 1.6495997762680055, "alpha_loss": 0.07211288356781007, "alpha_value": 0.09031996261723892, "duration": 75.90054059028625, "step": 4000}
{"episode_reward": 422.0, "episode": 17.0, "batch_reward": 0.6078359375, "critic_loss": 2.7151844544410704, "actor_loss": -19.699091842651367, "actor_target_entropy": -2.0, "actor_entropy": 1.6096016778945923, "alpha_loss": 0.07951329490542412, "alpha_value": 0.0898428817646168, "duration": 75.8044867515564, "step": 4250}
{"episode_reward": 10.0, "episode": 18.0, "batch_reward": 0.5746796875, "critic_loss": 2.8984301505088808, "actor_loss": -21.361334930419922, "actor_target_entropy": -2.0, "actor_entropy": 1.5799956674575806, "alpha_loss": 0.07919115760922432, "alpha_value": 0.0893059917185525, "duration": 75.86836504936218, "step": 4500}
{"episode_reward": 0.0, "episode": 19.0, "batch_reward": 0.560125, "critic_loss": 2.0949264616966246, "actor_loss": -23.24029296875, "actor_target_entropy": -2.0, "actor_entropy": 1.552714940071106, "alpha_loss": 0.08385210087895394, "alpha_value": 0.08873115484279287, "duration": 75.9101951122284, "step": 4750}
{"episode_reward": 239.0, "episode": 20.0, "batch_reward": 0.58678125, "critic_loss": 2.5205092668533324, "actor_loss": -24.398202728271485, "actor_target_entropy": -2.0, "actor_entropy": 1.5938995323181153, "alpha_loss": 0.07999799713492393, "alpha_value": 0.08812832417007306, "step": 5000}
{"duration": 93.66590404510498, "step": 5000}
{"episode_reward": 213.0, "episode": 21.0, "batch_reward": 0.6723203125, "critic_loss": 2.750855916023254, "actor_loss": -27.444941650390625, "actor_target_entropy": -2.0, "actor_entropy": 1.5558533411026, "alpha_loss": 0.075099738240242, "alpha_value": 0.08753652725076949, "duration": 75.57578802108765, "step": 5250}
{"episode_reward": 952.0, "episode": 22.0, "batch_reward": 0.73759375, "critic_loss": 2.9056566848754883, "actor_loss": -30.54572280883789, "actor_target_entropy": -2.0, "actor_entropy": 1.5929963903427125, "alpha_loss": 0.06659280395507812, "alpha_value": 0.08694828676011261, "duration": 75.76518273353577, "step": 5500}
{"episode_reward": 114.0, "episode": 23.0, "batch_reward": 0.8018046875, "critic_loss": 2.7262721939086916, "actor_loss": -33.65566705322266, "actor_target_entropy": -2.0, "actor_entropy": 1.5996865787506103, "alpha_loss": 0.05295936480164528, "alpha_value": 0.08645496934235826, "duration": 75.8935182094574, "step": 5750}
{"episode_reward": 994.0, "episode": 24.0, "batch_reward": 0.861984375, "critic_loss": 3.5159933519363404, "actor_loss": -38.21033999633789, "actor_target_entropy": -2.0, "actor_entropy": 1.5454140701293946, "alpha_loss": 0.03213415551930666, "alpha_value": 0.08607168850683126, "duration": 75.83303666114807, "step": 6000}
{"episode_reward": 14.0, "episode": 25.0, "batch_reward": 0.895328125, "critic_loss": 3.1412655897140502, "actor_loss": -42.763652526855466, "actor_target_entropy": -2.0, "actor_entropy": 1.5014712200164795, "alpha_loss": 0.027062248538713904, "alpha_value": 0.08581615861404863, "duration": 75.82240343093872, "step": 6250}
{"episode_reward": 958.0, "episode": 26.0, "batch_reward": 0.9390546875, "critic_loss": 3.3184618673324584, "actor_loss": -46.578552978515624, "actor_target_entropy": -2.0, "actor_entropy": 1.4933203802108765, "alpha_loss": 0.018072663160972297, "alpha_value": 0.08557833984465744, "duration": 75.87985968589783, "step": 6500}
{"episode_reward": 4.0, "episode": 27.0, "batch_reward": 0.92271875, "critic_loss": 3.1595601043701174, "actor_loss": -48.690958129882816, "actor_target_entropy": -2.0, "actor_entropy": 1.496306987762451, "alpha_loss": 0.01696106343343854, "alpha_value": 0.085407630771064, "duration": 75.87712216377258, "step": 6750}
{"episode_reward": 183.0, "episode": 28.0, "batch_reward": 0.9004765625, "critic_loss": 3.399654035568237, "actor_loss": -50.77846878051758, "actor_target_entropy": -2.0, "actor_entropy": 1.4628198165893556, "alpha_loss": 0.012124402356334031, "alpha_value": 0.0852416269439542, "duration": 75.84323191642761, "step": 7000}
{"episode_reward": 211.0, "episode": 29.0, "batch_reward": 0.969203125, "critic_loss": 3.3740217084884643, "actor_loss": -54.75213394165039, "actor_target_entropy": -2.0, "actor_entropy": 1.3872790594100952, "alpha_loss": -0.0008889723643660545, "alpha_value": 0.08515642168250974, "duration": 75.8006739616394, "step": 7250}
{"episode_reward": 931.0, "episode": 30.0, "batch_reward": 1.0473125, "critic_loss": 3.5675063743591306, "actor_loss": -58.69975485229492, "actor_target_entropy": -2.0, "actor_entropy": 1.2666005992889404, "alpha_loss": -0.014070034044794738, "alpha_value": 0.0852690375475471, "duration": 75.93327713012695, "step": 7500}
{"episode_reward": 881.0, "episode": 31.0, "batch_reward": 1.081390625, "critic_loss": 3.7840762462615967, "actor_loss": -62.38513897705078, "actor_target_entropy": -2.0, "actor_entropy": 1.186881079673767, "alpha_loss": -0.011580851934850216, "alpha_value": 0.08543559327267393, "duration": 75.84258389472961, "step": 7750}
{"episode_reward": 49.0, "episode": 32.0, "batch_reward": 1.0794609375, "critic_loss": 3.9120139179229736, "actor_loss": -64.76770498657227, "actor_target_entropy": -2.0, "actor_entropy": 1.150724895954132, "alpha_loss": -0.015769246252253653, "alpha_value": 0.08563690274532103, "duration": 75.90032529830933, "step": 8000}
{"episode_reward": 641.0, "episode": 33.0, "batch_reward": 1.15334375, "critic_loss": 3.590568060874939, "actor_loss": -68.50315017700196, "actor_target_entropy": -2.0, "actor_entropy": 1.0662092266082763, "alpha_loss": -0.020543899235315622, "alpha_value": 0.0859169633069475, "duration": 75.88141107559204, "step": 8250}
{"episode_reward": 960.0, "episode": 34.0, "batch_reward": 1.2102890625, "critic_loss": 3.86647380065918, "actor_loss": -72.49083502197266, "actor_target_entropy": -2.0, "actor_entropy": 1.0450880246162415, "alpha_loss": -0.021397887613624333, "alpha_value": 0.08627442451911442, "duration": 75.92174410820007, "step": 8500}
{"episode_reward": 780.0, "episode": 35.0, "batch_reward": 1.283328125, "critic_loss": 4.049578994750976, "actor_loss": -76.46605065917969, "actor_target_entropy": -2.0, "actor_entropy": 1.0463119401931762, "alpha_loss": -0.021913506234064697, "alpha_value": 0.08665102722791172, "duration": 75.89640879631042, "step": 8750}
{"episode_reward": 961.0, "episode": 36.0, "batch_reward": 1.3599921875, "critic_loss": 3.963030926704407, "actor_loss": -80.18193170166016, "actor_target_entropy": -2.0, "actor_entropy": 1.0044138555526734, "alpha_loss": -0.021709675271995365, "alpha_value": 0.08703801675072599, "duration": 75.89753437042236, "step": 9000}
{"episode_reward": 975.0, "episode": 37.0, "batch_reward": 1.3641328125, "critic_loss": 3.686092674255371, "actor_loss": -83.91969201660156, "actor_target_entropy": -2.0, "actor_entropy": 1.0031657729148864, "alpha_loss": -0.026800836119800806, "alpha_value": 0.08751682943776212, "duration": 75.8954861164093, "step": 9250}
{"episode_reward": 0.0, "episode": 38.0, "batch_reward": 1.3880703125, "critic_loss": 3.627520615577698, "actor_loss": -88.17388336181641, "actor_target_entropy": -2.0, "actor_entropy": 1.0295490856170655, "alpha_loss": -0.026679175203200428, "alpha_value": 0.08807522602552045, "duration": 75.89515209197998, "step": 9500}
{"episode_reward": 976.0, "episode": 39.0, "batch_reward": 1.4545859375, "critic_loss": 3.5756762189865112, "actor_loss": -92.07064086914062, "actor_target_entropy": -2.0, "actor_entropy": 1.022881570339203, "alpha_loss": -0.02604131251387298, "alpha_value": 0.08861914862879916, "duration": 75.88215279579163, "step": 9750}
{"episode_reward": 882.0, "episode": 40.0, "batch_reward": 1.472078125, "critic_loss": 3.86440691947937, "actor_loss": -95.00727893066406, "actor_target_entropy": -2.0, "actor_entropy": 1.0174359784126281, "alpha_loss": -0.019781688719056546, "alpha_value": 0.08916784921228912, "step": 10000}
{"duration": 93.71496748924255, "step": 10000}
{"episode_reward": 464.0, "episode": 41.0, "batch_reward": 1.5210078125, "critic_loss": 3.6164276962280275, "actor_loss": -98.42686987304687, "actor_target_entropy": -2.0, "actor_entropy": 1.0173517169952393, "alpha_loss": -0.02305794064886868, "alpha_value": 0.08970285659435931, "duration": 75.52185225486755, "step": 10250}
{"episode_reward": 889.0, "episode": 42.0, "batch_reward": 1.571328125, "critic_loss": 4.095319614410401, "actor_loss": -102.36198919677734, "actor_target_entropy": -2.0, "actor_entropy": 1.0233623476028442, "alpha_loss": -0.019672399953007697, "alpha_value": 0.09019141464673233, "duration": 75.80714535713196, "step": 10500}
{"episode_reward": 987.0, "episode": 43.0, "batch_reward": 1.592140625, "critic_loss": 3.750637354850769, "actor_loss": -106.81798742675781, "actor_target_entropy": -2.0, "actor_entropy": 1.0082173867225648, "alpha_loss": -0.021177831046283246, "alpha_value": 0.09075267068635626, "duration": 75.8220272064209, "step": 10750}
{"episode_reward": 578.0, "episode": 44.0, "batch_reward": 1.5989453125, "critic_loss": 3.9962360954284666, "actor_loss": -109.3584730834961, "actor_target_entropy": -2.0, "actor_entropy": 1.0194436531066895, "alpha_loss": -0.020036417255178095, "alpha_value": 0.09133576707811364, "duration": 75.82779145240784, "step": 11000}
{"episode_reward": 12.0, "episode": 45.0, "batch_reward": 1.5898828125, "critic_loss": 4.431050579071045, "actor_loss": -111.3708267211914, "actor_target_entropy": -2.0, "actor_entropy": 1.017352740764618, "alpha_loss": -0.013061708051245659, "alpha_value": 0.09180835995328265, "duration": 75.89450788497925, "step": 11250}
{"episode_reward": 717.0, "episode": 46.0, "batch_reward": 1.6267109375, "critic_loss": 4.136743274688721, "actor_loss": -114.92631689453125, "actor_target_entropy": -2.0, "actor_entropy": 1.0021788320541383, "alpha_loss": -0.01643646314740181, "alpha_value": 0.09226462424054457, "duration": 75.86012053489685, "step": 11500}
{"episode_reward": 987.0, "episode": 47.0, "batch_reward": 1.6360390625, "critic_loss": 5.352519933700561, "actor_loss": -118.45531237792969, "actor_target_entropy": -2.0, "actor_entropy": 1.0232302227020265, "alpha_loss": -0.020034695876762272, "alpha_value": 0.0928239090492545, "duration": 75.9305191040039, "step": 11750}
{"episode_reward": 19.0, "episode": 48.0, "batch_reward": 1.6384921875, "critic_loss": 5.368594200134277, "actor_loss": -122.04390307617187, "actor_target_entropy": -2.0, "actor_entropy": 1.0258063945770264, "alpha_loss": -0.017206171847879887, "alpha_value": 0.09349071749364268, "duration": 75.90902400016785, "step": 12000}
{"episode_reward": 933.0, "episode": 49.0, "batch_reward": 1.685328125, "critic_loss": 4.947866147994995, "actor_loss": -125.67895477294923, "actor_target_entropy": -2.0, "actor_entropy": 0.9903521385192872, "alpha_loss": -0.01476501166075468, "alpha_value": 0.09406343522151209, "duration": 75.8969361782074, "step": 12250}
{"episode_reward": 896.0, "episode": 50.0, "batch_reward": 1.730640625, "critic_loss": 5.264295606613159, "actor_loss": -128.84989239501954, "actor_target_entropy": -2.0, "actor_entropy": 0.984839518070221, "alpha_loss": -0.014857352651655675, "alpha_value": 0.09460493435952234, "duration": 75.9162745475769, "step": 12500}
{"episode_reward": 944.0, "episode": 51.0, "batch_reward": 1.72784375, "critic_loss": 4.482267137527466, "actor_loss": -131.0892550048828, "actor_target_entropy": -2.0, "actor_entropy": 0.9607502040863037, "alpha_loss": -0.005825059929862619, "alpha_value": 0.09506116844297688, "duration": 75.90222382545471, "step": 12750}
{"episode_reward": 0.0, "episode": 52.0, "batch_reward": 1.71290625, "critic_loss": 5.102808712005615, "actor_loss": -133.09453845214844, "actor_target_entropy": -2.0, "actor_entropy": 0.9292503471374511, "alpha_loss": 0.0014991956520825625, "alpha_value": 0.09513166733333898, "duration": 75.85454487800598, "step": 13000}
{"episode_reward": 207.0, "episode": 53.0, "batch_reward": 1.684875, "critic_loss": 5.425241737365723, "actor_loss": -135.0343996582031, "actor_target_entropy": -2.0, "actor_entropy": 0.9348549551963806, "alpha_loss": 0.0036943813525140284, "alpha_value": 0.09497257004584497, "duration": 75.87402582168579, "step": 13250}
{"episode_reward": 0.0, "episode": 54.0, "batch_reward": 1.6577578125, "critic_loss": 6.63558286857605, "actor_loss": -135.85029724121094, "actor_target_entropy": -2.0, "actor_entropy": 0.9768678941726685, "alpha_loss": 0.0025179003514349462, "alpha_value": 0.0949139009912479, "duration": 75.87595009803772, "step": 13500}
{"episode_reward": 52.0, "episode": 55.0, "batch_reward": 1.6530078125, "critic_loss": 5.99105770111084, "actor_loss": -137.98934411621093, "actor_target_entropy": -2.0, "actor_entropy": 0.9974374585151672, "alpha_loss": 0.011229285570792854, "alpha_value": 0.09457413346844054, "duration": 75.92965292930603, "step": 13750}
{"episode_reward": 968.0, "episode": 56.0, "batch_reward": 1.67240625, "critic_loss": 5.717586417198181, "actor_loss": -141.20252429199218, "actor_target_entropy": -2.0, "actor_entropy": 1.0108803572654723, "alpha_loss": 0.010842675190418958, "alpha_value": 0.09397440476268992, "duration": 75.88350772857666, "step": 14000}
{"episode_reward": 0.0, "episode": 57.0, "batch_reward": 1.6629609375, "critic_loss": 6.652894060134888, "actor_loss": -143.89915539550782, "actor_target_entropy": -2.0, "actor_entropy": 0.9901253533363342, "alpha_loss": 0.012173481365665793, "alpha_value": 0.09336075470223003, "duration": 75.91122961044312, "step": 14250}
{"episode_reward": 982.0, "episode": 58.0, "batch_reward": 1.666515625, "critic_loss": 7.804463499069214, "actor_loss": -146.1775439453125, "actor_target_entropy": -2.0, "actor_entropy": 1.0128224897384643, "alpha_loss": 0.011343684520572423, "alpha_value": 0.09288433136632046, "duration": 75.87408661842346, "step": 14500}
{"episode_reward": 5.0, "episode": 59.0, "batch_reward": 1.6398984375, "critic_loss": 6.508846591949463, "actor_loss": -146.9902908935547, "actor_target_entropy": -2.0, "actor_entropy": 0.9577195138931275, "alpha_loss": 0.008288170848973096, "alpha_value": 0.0922289152437582, "duration": 75.88200068473816, "step": 14750}
{"episode_reward": 175.0, "episode": 60.0, "batch_reward": 1.6635546875, "critic_loss": 5.0664390230178835, "actor_loss": -149.575314453125, "actor_target_entropy": -2.0, "actor_entropy": 0.9537475557327271, "alpha_loss": 0.004575255228206516, "alpha_value": 0.09191518562245396, "step": 15000}
{"duration": 93.78905367851257, "step": 15000}
{"episode_reward": 873.0, "episode": 61.0, "batch_reward": 1.6909921875, "critic_loss": 6.791666407585144, "actor_loss": -152.3609141845703, "actor_target_entropy": -2.0, "actor_entropy": 0.9262513270378113, "alpha_loss": 0.004077888607978821, "alpha_value": 0.09165377656643216, "duration": 75.59922099113464, "step": 15250}
{"episode_reward": 980.0, "episode": 62.0, "batch_reward": 1.6948125, "critic_loss": 5.6116225099563595, "actor_loss": -154.20449096679687, "actor_target_entropy": -2.0, "actor_entropy": 0.9063576374053955, "alpha_loss": 0.0010261203981935978, "alpha_value": 0.0915339126305369, "duration": 75.53605961799622, "step": 15500}
{"episode_reward": 0.0, "episode": 63.0, "batch_reward": 1.6661328125, "critic_loss": 5.20041770362854, "actor_loss": -155.90432165527343, "actor_target_entropy": -2.0, "actor_entropy": 0.9378380308151245, "alpha_loss": 0.005034689196385443, "alpha_value": 0.09140611746369767, "duration": 75.73498249053955, "step": 15750}
{"episode_reward": 0.0, "episode": 64.0, "batch_reward": 1.671078125, "critic_loss": 7.462800631523132, "actor_loss": -157.72264147949218, "actor_target_entropy": -2.0, "actor_entropy": 0.9502888073921204, "alpha_loss": 0.0066038778629153964, "alpha_value": 0.09095165286058607, "duration": 75.84834575653076, "step": 16000}
{"episode_reward": 894.0, "episode": 65.0, "batch_reward": 1.70596875, "critic_loss": 5.100395520210266, "actor_loss": -160.23449853515626, "actor_target_entropy": -2.0, "actor_entropy": 0.8942888541221619, "alpha_loss": 0.0097021198682487, "alpha_value": 0.0903999009524687, "duration": 75.79494881629944, "step": 16250}
{"episode_reward": 976.0, "episode": 66.0, "batch_reward": 1.717859375, "critic_loss": 5.70537805557251, "actor_loss": -162.7551378173828, "actor_target_entropy": -2.0, "actor_entropy": 0.855946216583252, "alpha_loss": 0.003834274297580123, "alpha_value": 0.09002559730485378, "duration": 75.75248980522156, "step": 16500}
{"episode_reward": 0.0, "episode": 67.0, "batch_reward": 1.7047109375, "critic_loss": 6.658305054664612, "actor_loss": -163.72898474121095, "actor_target_entropy": -2.0, "actor_entropy": 0.8174089841842651, "alpha_loss": 0.005869519901461899, "alpha_value": 0.08963180874922132, "duration": 75.8077700138092, "step": 16750}
{"episode_reward": 966.0, "episode": 68.0, "batch_reward": 1.7453359375, "critic_loss": 11.536845460891724, "actor_loss": -165.93999597167968, "actor_target_entropy": -2.0, "actor_entropy": 0.9150147895812988, "alpha_loss": 0.0020267337532714007, "alpha_value": 0.0893778809345016, "duration": 75.83226799964905, "step": 17000}
{"episode_reward": 987.0, "episode": 69.0, "batch_reward": 1.7717890625, "critic_loss": 6.9712288951873775, "actor_loss": -168.97839392089844, "actor_target_entropy": -2.0, "actor_entropy": 0.894057665348053, "alpha_loss": 0.004774939482100308, "alpha_value": 0.0890861990539456, "duration": 75.7861852645874, "step": 17250}
{"episode_reward": 961.0, "episode": 70.0, "batch_reward": 1.8066484375, "critic_loss": 6.551233158111573, "actor_loss": -171.97947961425783, "actor_target_entropy": -2.0, "actor_entropy": 0.8435273170471191, "alpha_loss": 0.003973812889307737, "alpha_value": 0.08877157013388191, "duration": 75.81274485588074, "step": 17500}
{"episode_reward": 924.0, "episode": 71.0, "batch_reward": 1.8208046875, "critic_loss": 6.506885303497315, "actor_loss": -174.05602770996094, "actor_target_entropy": -2.0, "actor_entropy": 0.8307885308265686, "alpha_loss": 0.005007105896249414, "alpha_value": 0.08847508330825658, "duration": 75.83285808563232, "step": 17750}
{"episode_reward": 840.0, "episode": 72.0, "batch_reward": 1.84959375, "critic_loss": 8.434652473449708, "actor_loss": -176.06882360839845, "actor_target_entropy": -2.0, "actor_entropy": 0.8012821946144104, "alpha_loss": 0.004867832064628601, "alpha_value": 0.08811061239717644, "duration": 75.75158023834229, "step": 18000}
{"episode_reward": 929.0, "episode": 73.0, "batch_reward": 1.880671875, "critic_loss": 6.732557555198669, "actor_loss": -178.24649841308593, "actor_target_entropy": -2.0, "actor_entropy": 0.7622916083335877, "alpha_loss": 0.010509139318950474, "alpha_value": 0.08763607183102907, "duration": 75.79344725608826, "step": 18250}
{"episode_reward": 955.0, "episode": 74.0, "batch_reward": 1.8860703125, "critic_loss": 16.036659009933473, "actor_loss": -180.40454516601562, "actor_target_entropy": -2.0, "actor_entropy": 0.8364819388389587, "alpha_loss": 0.006667203127406538, "alpha_value": 0.08685941991442171, "duration": 75.74644899368286, "step": 18500}
{"episode_reward": 0.0, "episode": 75.0, "batch_reward": 1.8895859375, "critic_loss": 5.448434326171875, "actor_loss": -183.23846862792968, "actor_target_entropy": -2.0, "actor_entropy": 0.7297354898452759, "alpha_loss": 0.008837153068743647, "alpha_value": 0.08634322064978238, "duration": 75.7990608215332, "step": 18750}
{"episode_reward": 986.0, "episode": 76.0, "batch_reward": 1.90440625, "critic_loss": 5.221842804908753, "actor_loss": -185.42844738769531, "actor_target_entropy": -2.0, "actor_entropy": 0.6985720300674438, "alpha_loss": 0.0057864766288548706, "alpha_value": 0.0857319325845474, "duration": 75.85063457489014, "step": 19000}
{"episode_reward": 953.0, "episode": 77.0, "batch_reward": 1.91428125, "critic_loss": 5.143811388015747, "actor_loss": -187.87569274902344, "actor_target_entropy": -2.0, "actor_entropy": 0.678659107208252, "alpha_loss": 0.010240013011731207, "alpha_value": 0.08513960441957302, "duration": 75.81334686279297, "step": 19250}
{"episode_reward": 3.0, "episode": 78.0, "batch_reward": 1.89746875, "critic_loss": 5.32316068649292, "actor_loss": -188.99318139648437, "actor_target_entropy": -2.0, "actor_entropy": 0.6938564319610596, "alpha_loss": 0.010472157989628613, "alpha_value": 0.08435990382445657, "duration": 75.76021885871887, "step": 19500}
{"episode_reward": 848.0, "episode": 79.0, "batch_reward": 1.901171875, "critic_loss": 5.033295946121216, "actor_loss": -190.51802514648438, "actor_target_entropy": -2.0, "actor_entropy": 0.7327218866348266, "alpha_loss": 0.009052589837461709, "alpha_value": 0.08359850969465675, "duration": 75.79211139678955, "step": 19750}
{"episode_reward": 0.0, "episode": 80.0, "batch_reward": 1.8938125, "critic_loss": 5.638508981704712, "actor_loss": -191.8926661376953, "actor_target_entropy": -2.0, "actor_entropy": 0.7427598376274109, "alpha_loss": 0.004829405404627323, "alpha_value": 0.08309470639449082, "step": 20000}
{"duration": 93.80895948410034, "step": 20000}
{"episode_reward": 980.0, "episode": 81.0, "batch_reward": 1.922328125, "critic_loss": 5.237737559318543, "actor_loss": -194.36695190429688, "actor_target_entropy": -2.0, "actor_entropy": 0.7475995626449585, "alpha_loss": 0.0075647858073934916, "alpha_value": 0.08270275078558267, "duration": 75.64598631858826, "step": 20250}
{"episode_reward": 1000.0, "episode": 82.0, "batch_reward": 1.9495, "critic_loss": 5.257163077354432, "actor_loss": -196.4127490234375, "actor_target_entropy": -2.0, "actor_entropy": 0.7449794931411743, "alpha_loss": 0.007292650036979467, "alpha_value": 0.08207537086755619, "duration": 75.49714136123657, "step": 20500}
{"episode_reward": 972.0, "episode": 83.0, "batch_reward": 1.957875, "critic_loss": 6.626929493904114, "actor_loss": -198.0729821777344, "actor_target_entropy": -2.0, "actor_entropy": 0.7296727023124695, "alpha_loss": 0.011008955047931522, "alpha_value": 0.08136719840856771, "duration": 75.66841721534729, "step": 20750}
{"episode_reward": 0.0, "episode": 84.0, "batch_reward": 1.9549375, "critic_loss": 8.888805488586426, "actor_loss": -198.92091552734374, "actor_target_entropy": -2.0, "actor_entropy": 0.7317334299087525, "alpha_loss": 0.011789482741151006, "alpha_value": 0.08052152564572733, "duration": 75.73219013214111, "step": 21000}
