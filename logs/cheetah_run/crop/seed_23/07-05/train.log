{"episode_reward": 0.0, "episode": 1.0, "duration": 11.748549461364746, "step": 125}
{"episode_reward": 23.579030900784034, "episode": 2.0, "duration": 0.4824550151824951, "step": 250}
{"episode_reward": 20.747401348917606, "episode": 3.0, "duration": 0.4837019443511963, "step": 375}
{"episode_reward": 15.208494239734875, "episode": 4.0, "duration": 0.47860002517700195, "step": 500}
{"episode_reward": 22.388913929606666, "episode": 5.0, "duration": 0.4834291934967041, "step": 625}
{"episode_reward": 16.786626931975075, "episode": 6.0, "duration": 0.48256540298461914, "step": 750}
{"episode_reward": 21.279484872018013, "episode": 7.0, "duration": 0.4842197895050049, "step": 875}
{"episode_reward": 26.341675891684616, "episode": 8.0, "duration": 0.4902040958404541, "step": 1000}
{"episode_reward": 32.46511410728092, "episode": 9.0, "batch_reward": 0.18221853601932525, "critic_loss": 0.23924269008636476, "actor_loss": -0.9913102526749883, "actor_target_entropy": -6.0, "actor_entropy": 7.165710259997655, "alpha_loss": 0.9276898134322393, "alpha_value": 0.09969663867723601, "duration": 28.848352432250977, "step": 1125}
{"episode_reward": 32.06327059752095, "episode": 10.0, "batch_reward": 0.186910413980484, "critic_loss": 0.13815714591741562, "actor_loss": -1.5987535349784359, "actor_target_entropy": -6.0, "actor_entropy": 7.562983889733592, "alpha_loss": 0.9820275998884632, "alpha_value": 0.0990506432507433, "duration": 28.795578956604004, "step": 1250}
{"episode_reward": 18.661774883046537, "episode": 11.0, "batch_reward": 0.17921339631080627, "critic_loss": 0.1122234120965004, "actor_loss": -1.911583147351704, "actor_target_entropy": -6.0, "actor_entropy": 7.554104449257018, "alpha_loss": 0.9769336883983915, "alpha_value": 0.09842600894332923, "duration": 28.836392402648926, "step": 1375}
{"episode_reward": 13.197174642446933, "episode": 12.0, "batch_reward": 0.1747034422159195, "critic_loss": 0.1085124985575676, "actor_loss": -2.14201602051335, "actor_target_entropy": -6.0, "actor_entropy": 7.52936577796936, "alpha_loss": 0.969417945992562, "alpha_value": 0.09781109052586019, "duration": 28.79421877861023, "step": 1500}
{"episode_reward": 21.944480612541216, "episode": 13.0, "batch_reward": 0.17887839102745057, "critic_loss": 0.11320949244499207, "actor_loss": -2.392763554103791, "actor_target_entropy": -6.0, "actor_entropy": 7.489693248082721, "alpha_loss": 0.9550706044075981, "alpha_value": 0.09720650176341364, "duration": 28.77194571495056, "step": 1625}
{"episode_reward": 22.33824001995759, "episode": 14.0, "batch_reward": 0.17986188566684722, "critic_loss": 0.12083980679512024, "actor_loss": -2.6581978105729624, "actor_target_entropy": -6.0, "actor_entropy": 7.354078400519587, "alpha_loss": 0.9315911262266098, "alpha_value": 0.09661488271142739, "duration": 28.712467193603516, "step": 1750}
{"episode_reward": 43.551433932172905, "episode": 15.0, "batch_reward": 0.19610020709037781, "critic_loss": 0.13374251931905745, "actor_loss": -2.9245683049398754, "actor_target_entropy": -6.0, "actor_entropy": 7.230469211699471, "alpha_loss": 0.9094043128074162, "alpha_value": 0.09603797461549146, "duration": 28.86696457862854, "step": 1875}
{"episode_reward": 64.11459404535226, "episode": 16.0, "batch_reward": 0.21310270726680755, "critic_loss": 0.16252966845035552, "actor_loss": -3.244276608190229, "actor_target_entropy": -6.0, "actor_entropy": 7.23672559953505, "alpha_loss": 0.8926205683139062, "alpha_value": 0.0954722212253438, "duration": 28.79475688934326, "step": 2000}
{"episode_reward": 27.38326534667355, "episode": 17.0, "batch_reward": 0.22457773065567016, "critic_loss": 0.16174484264850617, "actor_loss": -3.5615888209570024, "actor_target_entropy": -6.0, "actor_entropy": 7.074528520069425, "alpha_loss": 0.8673697681654067, "alpha_value": 0.09491428932632419, "duration": 28.881993055343628, "step": 2125}
{"episode_reward": 79.32633171130144, "episode": 18.0, "batch_reward": 0.2404370564222336, "critic_loss": 0.16896193253993988, "actor_loss": -3.9258568363804973, "actor_target_entropy": -6.0, "actor_entropy": 6.890066862106323, "alpha_loss": 0.8282499399877363, "alpha_value": 0.09437424690082807, "duration": 28.772125720977783, "step": 2250}
{"episode_reward": 51.98453860872844, "episode": 19.0, "batch_reward": 0.26080088901519777, "critic_loss": 0.1915174422264099, "actor_loss": -4.296795519571456, "actor_target_entropy": -6.0, "actor_entropy": 6.676817243061368, "alpha_loss": 0.7923467585018703, "alpha_value": 0.09385831858496457, "duration": 28.937093019485474, "step": 2375}
{"episode_reward": 89.00877169713318, "episode": 20.0, "batch_reward": 0.2744018524885178, "critic_loss": 0.20659410285949706, "actor_loss": -4.670748387613604, "actor_target_entropy": -6.0, "actor_entropy": 6.502089300463276, "alpha_loss": 0.7421195478208603, "alpha_value": 0.09336036549684654, "duration": 28.761217832565308, "step": 2500}
{"episode_reward": 48.2944674639569, "episode": 21.0, "batch_reward": 0.296798313498497, "critic_loss": 0.2507179356813431, "actor_loss": -5.12463210877918, "actor_target_entropy": -6.0, "actor_entropy": 6.257232196747311, "alpha_loss": 0.6760231549777682, "alpha_value": 0.09289355841327387, "duration": 28.93815302848816, "step": 2625}
{"episode_reward": 126.18039856256438, "episode": 22.0, "batch_reward": 0.3141282117366791, "critic_loss": 0.28771206736564636, "actor_loss": -5.632493780505273, "actor_target_entropy": -6.0, "actor_entropy": 5.874027459852157, "alpha_loss": 0.6135560610601979, "alpha_value": 0.0924644100550538, "duration": 28.78186845779419, "step": 2750}
{"episode_reward": 41.82023237855598, "episode": 23.0, "batch_reward": 0.3218840353488922, "critic_loss": 0.3992427079677582, "actor_loss": -6.060686293102446, "actor_target_entropy": -6.0, "actor_entropy": 5.752187358008491, "alpha_loss": 0.5846358381566548, "alpha_value": 0.09205699037950392, "duration": 28.887166738510132, "step": 2875}
{"episode_reward": 87.81881637018581, "episode": 24.0, "batch_reward": 0.33256023812294006, "critic_loss": 0.30565652942657473, "actor_loss": -6.6783587394222135, "actor_target_entropy": -6.0, "actor_entropy": 5.407510565173242, "alpha_loss": 0.5525554466632104, "alpha_value": 0.09165635946425678, "duration": 28.813020706176758, "step": 3000}
{"episode_reward": 54.71888224305261, "episode": 25.0, "batch_reward": 0.33785063719749453, "critic_loss": 0.29627863979339597, "actor_loss": -7.193653288341704, "actor_target_entropy": -6.0, "actor_entropy": 5.367210804470002, "alpha_loss": 0.5336153351125263, "alpha_value": 0.09126959060040168, "duration": 28.900447845458984, "step": 3125}
{"episode_reward": 42.011008311552274, "episode": 26.0, "batch_reward": 0.349637060880661, "critic_loss": 0.31281179094314576, "actor_loss": -7.746319909249583, "actor_target_entropy": -6.0, "actor_entropy": 5.3176098331328365, "alpha_loss": 0.5255344505271604, "alpha_value": 0.09088353967742024, "duration": 28.77909755706787, "step": 3250}
{"episode_reward": 133.94867770175557, "episode": 27.0, "batch_reward": 0.37510460209846497, "critic_loss": 0.3217836275100708, "actor_loss": -8.406611533392043, "actor_target_entropy": -6.0, "actor_entropy": 5.255751473563058, "alpha_loss": 0.5241799023416307, "alpha_value": 0.09049196231181776, "duration": 28.895339488983154, "step": 3375}
{"episode_reward": 121.35612920475735, "episode": 28.0, "batch_reward": 0.3929908833503723, "critic_loss": 0.30963379883766173, "actor_loss": -9.006494199076007, "actor_target_entropy": -6.0, "actor_entropy": 5.248478481846471, "alpha_loss": 0.5279174249979758, "alpha_value": 0.09009518851004579, "duration": 28.883604049682617, "step": 3500}
{"episode_reward": 85.38618553480293, "episode": 29.0, "batch_reward": 0.40269005846977235, "critic_loss": 0.3107876350879669, "actor_loss": -9.559436041211326, "actor_target_entropy": -6.0, "actor_entropy": 5.271905641707163, "alpha_loss": 0.5484983031711881, "alpha_value": 0.08967989317136374, "duration": 28.923311233520508, "step": 3625}
{"episode_reward": 116.53715077070419, "episode": 30.0, "batch_reward": 0.42893179416656496, "critic_loss": 0.3025214993953705, "actor_loss": -10.188798181472286, "actor_target_entropy": -6.0, "actor_entropy": 5.325477692388719, "alpha_loss": 0.547818107951072, "alpha_value": 0.08924919774325214, "duration": 28.75761580467224, "step": 3750}
{"episode_reward": 140.0531842300847, "episode": 31.0, "batch_reward": 0.44693192648887636, "critic_loss": 0.2819795684814453, "actor_loss": -10.752866593618242, "actor_target_entropy": -6.0, "actor_entropy": 5.283268693893675, "alpha_loss": 0.5524643195999993, "alpha_value": 0.08881407010560614, "duration": 28.893343448638916, "step": 3875}
{"episode_reward": 117.39044169131874, "episode": 32.0, "batch_reward": 0.46408362674713133, "critic_loss": 0.28926312339305876, "actor_loss": -11.376147762421638, "actor_target_entropy": -6.0, "actor_entropy": 5.28880549246265, "alpha_loss": 0.5540787269992213, "alpha_value": 0.08837032041011815, "duration": 28.849711894989014, "step": 4000}
{"episode_reward": 125.79472718951686, "episode": 33.0, "batch_reward": 0.47096290755271913, "critic_loss": 0.2926402699947357, "actor_loss": -11.872453901502821, "actor_target_entropy": -6.0, "actor_entropy": 5.376583598908924, "alpha_loss": 0.55691630405093, "alpha_value": 0.08792159105987524, "duration": 28.896910667419434, "step": 4125}
{"episode_reward": 41.90770168675684, "episode": 34.0, "batch_reward": 0.47307630944252016, "critic_loss": 0.2951538171768188, "actor_loss": -12.351867906508907, "actor_target_entropy": -6.0, "actor_entropy": 5.301409821356496, "alpha_loss": 0.5553388182194002, "alpha_value": 0.08746706617463293, "duration": 28.80436897277832, "step": 4250}
{"episode_reward": 116.81108885217378, "episode": 35.0, "batch_reward": 0.4910794732570648, "critic_loss": 0.32051352190971377, "actor_loss": -12.900898282490079, "actor_target_entropy": -6.0, "actor_entropy": 5.296145128825354, "alpha_loss": 0.5417891438045199, "alpha_value": 0.08701858842297282, "duration": 28.97460412979126, "step": 4375}
{"episode_reward": 151.3571812856654, "episode": 36.0, "batch_reward": 0.5136841225624085, "critic_loss": 0.3080790071487427, "actor_loss": -13.489701455639254, "actor_target_entropy": -6.0, "actor_entropy": 5.1352296567732285, "alpha_loss": 0.5386878367393247, "alpha_value": 0.08657192585434086, "duration": 28.803946495056152, "step": 4500}
{"episode_reward": 127.5827935447693, "episode": 37.0, "batch_reward": 0.5194565625190735, "critic_loss": 0.3370555739402771, "actor_loss": -14.04793005141001, "actor_target_entropy": -6.0, "actor_entropy": 5.173673682742649, "alpha_loss": 0.5228419124134003, "alpha_value": 0.08612900081446112, "duration": 28.944270133972168, "step": 4625}
{"episode_reward": 80.8510528337388, "episode": 38.0, "batch_reward": 0.5312934608459473, "critic_loss": 0.3300372499227524, "actor_loss": -14.590928877553631, "actor_target_entropy": -6.0, "actor_entropy": 5.1034116360449024, "alpha_loss": 0.512245181106752, "alpha_value": 0.08569501925656603, "duration": 28.84059238433838, "step": 4750}
{"episode_reward": 172.1415084774326, "episode": 39.0, "batch_reward": 0.5516005201339722, "critic_loss": 0.3303051294088364, "actor_loss": -15.176068003215487, "actor_target_entropy": -6.0, "actor_entropy": 5.115894347902328, "alpha_loss": 0.5063739092577071, "alpha_value": 0.08526406249458862, "duration": 28.89051842689514, "step": 4875}
{"episode_reward": 141.57533759036778, "episode": 40.0, "batch_reward": 0.5669312925338745, "critic_loss": 0.35287101435661317, "actor_loss": -15.80417110073951, "actor_target_entropy": -6.0, "actor_entropy": 5.032122435108308, "alpha_loss": 0.4890948159079398, "alpha_value": 0.08483952464394226, "step": 5000}
{"duration": 39.814417600631714, "step": 5000}
{"episode_reward": 161.09907253730512, "episode": 41.0, "batch_reward": 0.5777987041473389, "critic_loss": 0.34118249440193177, "actor_loss": -16.433456572275315, "actor_target_entropy": -6.0, "actor_entropy": 4.93669471286592, "alpha_loss": 0.4923607787442586, "alpha_value": 0.08442037886912254, "duration": 28.883558750152588, "step": 5125}
{"episode_reward": 150.70972215349883, "episode": 42.0, "batch_reward": 0.6027310304641723, "critic_loss": 0.35508329939842226, "actor_loss": -17.10707999813941, "actor_target_entropy": -6.0, "actor_entropy": 4.8733062744140625, "alpha_loss": 0.4790943519723031, "alpha_value": 0.0839984375391839, "duration": 28.830475091934204, "step": 5250}
{"episode_reward": 185.96505464089338, "episode": 43.0, "batch_reward": 0.6240528354644775, "critic_loss": 0.37451970982551575, "actor_loss": -17.730296483115545, "actor_target_entropy": -6.0, "actor_entropy": 4.768685477120536, "alpha_loss": 0.4720541437466939, "alpha_value": 0.08358404071597086, "duration": 28.94357705116272, "step": 5375}
{"episode_reward": 167.17911755936126, "episode": 44.0, "batch_reward": 0.6312612891197205, "critic_loss": 0.37425817251205445, "actor_loss": -18.333877132784934, "actor_target_entropy": -6.0, "actor_entropy": 4.770287536805676, "alpha_loss": 0.4647857157453414, "alpha_value": 0.08317172472585775, "duration": 28.871821880340576, "step": 5500}
{"episode_reward": 101.11699248402914, "episode": 45.0, "batch_reward": 0.644503203868866, "critic_loss": 0.39094302916526796, "actor_loss": -18.97055180867513, "actor_target_entropy": -6.0, "actor_entropy": 4.711248624892462, "alpha_loss": 0.4518414357351878, "alpha_value": 0.08276293067457743, "duration": 29.021037101745605, "step": 5625}
{"episode_reward": 207.33177309406133, "episode": 46.0, "batch_reward": 0.6645552167892456, "critic_loss": 0.3961120111942291, "actor_loss": -19.669002902123236, "actor_target_entropy": -6.0, "actor_entropy": 4.64950470770559, "alpha_loss": 0.44291695183323276, "alpha_value": 0.08236324031831749, "duration": 28.820104360580444, "step": 5750}
{"episode_reward": 183.63715419999872, "episode": 47.0, "batch_reward": 0.6847341532707214, "critic_loss": 0.4375560145378113, "actor_loss": -20.330056599208287, "actor_target_entropy": -6.0, "actor_entropy": 4.64079277099125, "alpha_loss": 0.43459319689917186, "alpha_value": 0.08196640101842848, "duration": 28.83687734603882, "step": 5875}
{"episode_reward": 139.93784546767176, "episode": 48.0, "batch_reward": 0.6893435173034668, "critic_loss": 0.43264676475524905, "actor_loss": -20.967610297664518, "actor_target_entropy": -6.0, "actor_entropy": 4.651312351226807, "alpha_loss": 0.42774620940608366, "alpha_value": 0.08157425085811852, "duration": 28.82708501815796, "step": 6000}
{"episode_reward": 223.96679563751513, "episode": 49.0, "batch_reward": 0.708768445968628, "critic_loss": 0.46853914856910706, "actor_loss": -21.618890126546223, "actor_target_entropy": -6.0, "actor_entropy": 4.599260496714758, "alpha_loss": 0.4172818949298253, "alpha_value": 0.081186610906491, "duration": 28.955681800842285, "step": 6125}
{"episode_reward": 70.5369407428317, "episode": 50.0, "batch_reward": 0.7103952770233154, "critic_loss": 0.4310251579284668, "actor_loss": -22.169249657661684, "actor_target_entropy": -6.0, "actor_entropy": 4.577574629937449, "alpha_loss": 0.40445986197840783, "alpha_value": 0.08080164059846481, "duration": 28.931454181671143, "step": 6250}
{"episode_reward": 203.20201066066133, "episode": 51.0, "batch_reward": 0.7293248624801636, "critic_loss": 0.4490698654651642, "actor_loss": -22.948300043741863, "actor_target_entropy": -6.0, "actor_entropy": 4.433536643073673, "alpha_loss": 0.3939482796759832, "alpha_value": 0.08042792250363313, "duration": 28.892328023910522, "step": 6375}
{"episode_reward": 195.6022831091253, "episode": 52.0, "batch_reward": 0.7352687397003174, "critic_loss": 0.4933764486312866, "actor_loss": -23.550824965200118, "actor_target_entropy": -6.0, "actor_entropy": 4.4013240798827145, "alpha_loss": 0.3985017095842669, "alpha_value": 0.08005309568109505, "duration": 28.89896821975708, "step": 6500}
{"episode_reward": 46.461159403345924, "episode": 53.0, "batch_reward": 0.7441733717918396, "critic_loss": 0.5047101616859436, "actor_loss": -24.299157309153724, "actor_target_entropy": -6.0, "actor_entropy": 4.224009657663013, "alpha_loss": 0.3884470301961142, "alpha_value": 0.07967365946011694, "duration": 28.912630558013916, "step": 6625}
{"episode_reward": 204.97229912298192, "episode": 54.0, "batch_reward": 0.7594038181304932, "critic_loss": 0.5133374719619751, "actor_loss": -24.950119326191565, "actor_target_entropy": -6.0, "actor_entropy": 4.1533329679119975, "alpha_loss": 0.37709051466757254, "alpha_value": 0.07930479958045558, "duration": 28.894907236099243, "step": 6750}
{"episode_reward": 209.94959722662477, "episode": 55.0, "batch_reward": 0.7759415102005005, "critic_loss": 0.5737192311286926, "actor_loss": -25.62139202299572, "actor_target_entropy": -6.0, "actor_entropy": 4.168298225554209, "alpha_loss": 0.3644713962834979, "alpha_value": 0.07894242902197082, "duration": 28.90105676651001, "step": 6875}
{"episode_reward": 198.48498310575, "episode": 56.0, "batch_reward": 0.7887411775588989, "critic_loss": 0.5796320202350617, "actor_loss": -26.392313957214355, "actor_target_entropy": -6.0, "actor_entropy": 4.080290832827168, "alpha_loss": 0.3522263972028609, "alpha_value": 0.07858709394568932, "duration": 28.858437061309814, "step": 7000}
{"episode_reward": 134.31364493072573, "episode": 57.0, "batch_reward": 0.7909737858772278, "critic_loss": 0.6291140055656433, "actor_loss": -26.91246677580334, "actor_target_entropy": -6.0, "actor_entropy": 4.078639257521856, "alpha_loss": 0.34972430978502544, "alpha_value": 0.07823686714095786, "duration": 28.859767198562622, "step": 7125}
{"episode_reward": 192.8228496263801, "episode": 58.0, "batch_reward": 0.8054725441932679, "critic_loss": 0.6746200399398804, "actor_loss": -27.6529416730327, "actor_target_entropy": -6.0, "actor_entropy": 4.002419767841216, "alpha_loss": 0.3402609969339063, "alpha_value": 0.07788863867709925, "duration": 28.77940344810486, "step": 7250}
{"episode_reward": 105.82292265127607, "episode": 59.0, "batch_reward": 0.8105854091644287, "critic_loss": 0.6685819501876831, "actor_loss": -28.215517407371884, "actor_target_entropy": -6.0, "actor_entropy": 3.936341054855831, "alpha_loss": 0.33159316674111383, "alpha_value": 0.07754644343003343, "duration": 28.900805234909058, "step": 7375}
{"episode_reward": 262.35751345302145, "episode": 60.0, "batch_reward": 0.8294389128684998, "critic_loss": 0.7266453881263732, "actor_loss": -29.006528085277928, "actor_target_entropy": -6.0, "actor_entropy": 3.9500371640728367, "alpha_loss": 0.3248025818217185, "alpha_value": 0.0772031840150046, "duration": 28.81603503227234, "step": 7500}
{"episode_reward": 152.9322577984384, "episode": 61.0, "batch_reward": 0.8393781962394714, "critic_loss": 0.7456129341125488, "actor_loss": -29.695014317830402, "actor_target_entropy": -6.0, "actor_entropy": 3.889486036603413, "alpha_loss": 0.32575248110862004, "alpha_value": 0.0768638434783442, "duration": 28.958171367645264, "step": 7625}
{"episode_reward": 251.34215844980108, "episode": 62.0, "batch_reward": 0.8429620623588562, "critic_loss": 0.7765131530761719, "actor_loss": -30.43504681125764, "actor_target_entropy": -6.0, "actor_entropy": 3.775052624364053, "alpha_loss": 0.31354119412360654, "alpha_value": 0.07652455340234363, "duration": 28.792407989501953, "step": 7750}
{"episode_reward": 56.204193530831574, "episode": 63.0, "batch_reward": 0.8481089715957641, "critic_loss": 0.7559361591339111, "actor_loss": -30.995099627782427, "actor_target_entropy": -6.0, "actor_entropy": 3.7690014120132203, "alpha_loss": 0.30601500755264643, "alpha_value": 0.07619237464713098, "duration": 28.914888620376587, "step": 7875}
{"episode_reward": 240.33144494889626, "episode": 64.0, "batch_reward": 0.8662805557250977, "critic_loss": 0.8443060932159424, "actor_loss": -31.867813448752127, "actor_target_entropy": -6.0, "actor_entropy": 3.6972545500724547, "alpha_loss": 0.3058238589475232, "alpha_value": 0.07586167138899619, "duration": 28.794498920440674, "step": 8000}
{"episode_reward": 234.9420748678399, "episode": 65.0, "batch_reward": 0.8865959825515747, "critic_loss": 0.8407124185562134, "actor_loss": -32.729926518031526, "actor_target_entropy": -6.0, "actor_entropy": 3.6458681689368353, "alpha_loss": 0.29971874753634137, "alpha_value": 0.07552809167901424, "duration": 28.831368923187256, "step": 8125}
{"episode_reward": 219.4626007162764, "episode": 66.0, "batch_reward": 0.8950514540672302, "critic_loss": 0.8623551821708679, "actor_loss": -33.586854996219756, "actor_target_entropy": -6.0, "actor_entropy": 3.569411112416175, "alpha_loss": 0.2863386569003905, "alpha_value": 0.07520188795089215, "duration": 28.785980939865112, "step": 8250}
{"episode_reward": 208.1044744136202, "episode": 67.0, "batch_reward": 0.9110214419364929, "critic_loss": 0.9271390976905822, "actor_loss": -34.193822769891646, "actor_target_entropy": -6.0, "actor_entropy": 3.55423633257548, "alpha_loss": 0.2964394035793486, "alpha_value": 0.0748749482558385, "duration": 28.918050050735474, "step": 8375}
{"episode_reward": 259.61446941128014, "episode": 68.0, "batch_reward": 0.9268118495941162, "critic_loss": 1.0926938481330872, "actor_loss": -35.15368818467663, "actor_target_entropy": -6.0, "actor_entropy": 3.482923150062561, "alpha_loss": 0.2792358614744679, "alpha_value": 0.0745467189437335, "duration": 28.752084732055664, "step": 8500}
{"episode_reward": 191.53288441063026, "episode": 69.0, "batch_reward": 0.9355573282241821, "critic_loss": 1.0369084100723267, "actor_loss": -36.06819812835209, "actor_target_entropy": -6.0, "actor_entropy": 3.4021137214842296, "alpha_loss": 0.2745594907374609, "alpha_value": 0.07422698934923644, "duration": 28.760586261749268, "step": 8625}
{"episode_reward": 263.990798747128, "episode": 70.0, "batch_reward": 0.9435763921737671, "critic_loss": 1.2066484479904174, "actor_loss": -36.574808982110795, "actor_target_entropy": -6.0, "actor_entropy": 3.371854801331797, "alpha_loss": 0.2792872889868675, "alpha_value": 0.0739035146770919, "duration": 28.759596824645996, "step": 8750}
{"episode_reward": 64.22333745003594, "episode": 71.0, "batch_reward": 0.940358425617218, "critic_loss": 1.114975236415863, "actor_loss": -37.234131646534756, "actor_target_entropy": -6.0, "actor_entropy": 3.3731984297434487, "alpha_loss": 0.2801266078438078, "alpha_value": 0.07357312640381358, "duration": 28.81923818588257, "step": 8875}
{"episode_reward": 216.45869947226376, "episode": 72.0, "batch_reward": 0.9526125473976135, "critic_loss": 1.1465026025772094, "actor_loss": -38.04328087837465, "actor_target_entropy": -6.0, "actor_entropy": 3.356182813644409, "alpha_loss": 0.273234821134998, "alpha_value": 0.07324071361342537, "duration": 28.829792499542236, "step": 9000}
{"episode_reward": 229.51642326299276, "episode": 73.0, "batch_reward": 0.961918360710144, "critic_loss": 1.254713215827942, "actor_loss": -38.873468187120224, "actor_target_entropy": -6.0, "actor_entropy": 3.296900858954778, "alpha_loss": 0.2677029638536393, "alpha_value": 0.07291515708838828, "duration": 28.909775495529175, "step": 9125}
{"episode_reward": 174.7730370763555, "episode": 74.0, "batch_reward": 0.9655934791564942, "critic_loss": 1.3715246939659118, "actor_loss": -39.55951056941863, "actor_target_entropy": -6.0, "actor_entropy": 3.2950358467717327, "alpha_loss": 0.2790895534619208, "alpha_value": 0.07258405063561227, "duration": 28.878615140914917, "step": 9250}
{"episode_reward": 87.64613461974483, "episode": 75.0, "batch_reward": 0.9698060097694396, "critic_loss": 1.3084135146141052, "actor_loss": -40.052303193107484, "actor_target_entropy": -6.0, "actor_entropy": 3.366297763491434, "alpha_loss": 0.2682230477295225, "alpha_value": 0.07224433001700623, "duration": 28.903560876846313, "step": 9375}
{"episode_reward": 164.59906201705152, "episode": 76.0, "batch_reward": 0.9774905982017517, "critic_loss": 1.5394701080322266, "actor_loss": -40.864195977487874, "actor_target_entropy": -6.0, "actor_entropy": 3.312330388253735, "alpha_loss": 0.26628140672560663, "alpha_value": 0.07191272624064046, "duration": 28.79150700569153, "step": 9500}
{"episode_reward": 184.6611944034216, "episode": 77.0, "batch_reward": 0.9786295766830444, "critic_loss": 1.8361001062393187, "actor_loss": -41.60773243979802, "actor_target_entropy": -6.0, "actor_entropy": 3.3414399396805536, "alpha_loss": 0.26293263572549064, "alpha_value": 0.07157956297916723, "duration": 28.86009693145752, "step": 9625}
{"episode_reward": 238.08596656291172, "episode": 78.0, "batch_reward": 0.9979238600730896, "critic_loss": 1.6387792520523072, "actor_loss": -42.562964654737904, "actor_target_entropy": -6.0, "actor_entropy": 3.176364221880513, "alpha_loss": 0.25352037241381986, "alpha_value": 0.07125538701048363, "duration": 28.803444623947144, "step": 9750}
{"episode_reward": 276.65840920603335, "episode": 79.0, "batch_reward": 1.0020263895988464, "critic_loss": 1.8297668724060059, "actor_loss": -43.11218146672324, "actor_target_entropy": -6.0, "actor_entropy": 3.1609717739952936, "alpha_loss": 0.245868177167953, "alpha_value": 0.07093522728438507, "duration": 28.926108598709106, "step": 9875}
{"episode_reward": 78.96634920089348, "episode": 80.0, "batch_reward": 1.0069781608581543, "critic_loss": 1.6419549369812012, "actor_loss": -43.79361546424128, "actor_target_entropy": -6.0, "actor_entropy": 3.217159548113423, "alpha_loss": 0.2451711787331489, "alpha_value": 0.07061663581565811, "step": 10000}
{"duration": 39.64599943161011, "step": 10000}
{"episode_reward": 180.46539668851813, "episode": 81.0, "batch_reward": 1.0078132429122926, "critic_loss": 1.7241391830444337, "actor_loss": -44.41131846110026, "actor_target_entropy": -6.0, "actor_entropy": 3.0858019382234603, "alpha_loss": 0.24553736807808044, "alpha_value": 0.07029524074891215, "duration": 28.85814356803894, "step": 10125}
{"episode_reward": 256.87715711700173, "episode": 82.0, "batch_reward": 1.0171806745529175, "critic_loss": 1.7088295974731444, "actor_loss": -45.126055009903446, "actor_target_entropy": -6.0, "actor_entropy": 3.080459148653092, "alpha_loss": 0.24306353277737094, "alpha_value": 0.06997291056661449, "duration": 28.70096516609192, "step": 10250}
{"episode_reward": 98.81944500545771, "episode": 83.0, "batch_reward": 1.0164580612182617, "critic_loss": 1.7252000761032105, "actor_loss": -45.652516380188956, "actor_target_entropy": -6.0, "actor_entropy": 3.1638253605554976, "alpha_loss": 0.23647428978057133, "alpha_value": 0.06965155770291225, "duration": 28.898128747940063, "step": 10375}
{"episode_reward": 213.18196734370082, "episode": 84.0, "batch_reward": 1.0202574367523194, "critic_loss": 1.899890661239624, "actor_loss": -46.38544254918252, "actor_target_entropy": -6.0, "actor_entropy": 3.1642856213354293, "alpha_loss": 0.23616811561007653, "alpha_value": 0.06933478996233983, "duration": 28.71386742591858, "step": 10500}
{"episode_reward": 211.02038058872546, "episode": 85.0, "batch_reward": 1.033454614162445, "critic_loss": 1.9225674571990967, "actor_loss": -47.177132076687286, "actor_target_entropy": -6.0, "actor_entropy": 3.1970129656413246, "alpha_loss": 0.22933169513467758, "alpha_value": 0.06901693814670802, "duration": 26.921940565109253, "step": 10625}
{"episode_reward": 176.02866519564742, "episode": 86.0, "batch_reward": 1.042737850666046, "critic_loss": 1.8765985774993896, "actor_loss": -47.85722818682271, "actor_target_entropy": -6.0, "actor_entropy": 3.098672363065904, "alpha_loss": 0.2231140663066218, "alpha_value": 0.06870420053053698, "duration": 26.10684299468994, "step": 10750}
{"episode_reward": 316.6108437272134, "episode": 87.0, "batch_reward": 1.0578359718322754, "critic_loss": 2.0070283794403077, "actor_loss": -48.773072500077504, "actor_target_entropy": -6.0, "actor_entropy": 3.0473196506500244, "alpha_loss": 0.22040668863152701, "alpha_value": 0.06839928284505027, "duration": 25.92255926132202, "step": 10875}
{"episode_reward": 283.0772588749703, "episode": 88.0, "batch_reward": 1.0715891604423522, "critic_loss": 1.9329226999282836, "actor_loss": -49.62051410059775, "actor_target_entropy": -6.0, "actor_entropy": 2.9973128611041653, "alpha_loss": 0.21296802211192348, "alpha_value": 0.06809360520896532, "duration": 25.58487582206726, "step": 11000}
{"episode_reward": 99.17592816478184, "episode": 89.0, "batch_reward": 1.0728578281402588, "critic_loss": 1.9451484842300415, "actor_loss": -50.044622633192276, "actor_target_entropy": -6.0, "actor_entropy": 3.181736798513503, "alpha_loss": 0.21498860134964898, "alpha_value": 0.0677908547226567, "duration": 25.642234325408936, "step": 11125}
{"episode_reward": 278.8731869387994, "episode": 90.0, "batch_reward": 1.0868424191474915, "critic_loss": 1.9070114812850951, "actor_loss": -51.07941762862667, "actor_target_entropy": -6.0, "actor_entropy": 2.964134174008523, "alpha_loss": 0.20267138125435, "alpha_value": 0.06748854991840876, "duration": 25.531184434890747, "step": 11250}
{"episode_reward": 269.3221838786582, "episode": 91.0, "batch_reward": 1.094533589363098, "critic_loss": 1.9369484624862672, "actor_loss": -51.80075660584465, "actor_target_entropy": -6.0, "actor_entropy": 2.9990303327166843, "alpha_loss": 0.20472410439498842, "alpha_value": 0.06719200800366286, "duration": 25.72054624557495, "step": 11375}
{"episode_reward": 254.14579087566528, "episode": 92.0, "batch_reward": 1.1035473403930665, "critic_loss": 1.7963471612930297, "actor_loss": -52.73722654773343, "actor_target_entropy": -6.0, "actor_entropy": 3.017584889165817, "alpha_loss": 0.2006062483114581, "alpha_value": 0.06689286786326058, "duration": 25.55341911315918, "step": 11500}
{"episode_reward": 280.30504470286627, "episode": 93.0, "batch_reward": 1.1126795353889465, "critic_loss": 1.8532707147598266, "actor_loss": -53.43471630035885, "actor_target_entropy": -6.0, "actor_entropy": 2.8995699390532477, "alpha_loss": 0.1990206390619278, "alpha_value": 0.06659826587614905, "duration": 25.634700775146484, "step": 11625}
{"episode_reward": 118.28910736182482, "episode": 94.0, "batch_reward": 1.1121681537628174, "critic_loss": 1.9067725038528442, "actor_loss": -53.95659662062122, "actor_target_entropy": -6.0, "actor_entropy": 2.917765486624933, "alpha_loss": 0.1947713539965691, "alpha_value": 0.06630346687625004, "duration": 25.530924320220947, "step": 11750}
{"episode_reward": 270.14740919725756, "episode": 95.0, "batch_reward": 1.1285542688369752, "critic_loss": 1.8419699535369873, "actor_loss": -55.00932087973943, "actor_target_entropy": -6.0, "actor_entropy": 2.9060914213695224, "alpha_loss": 0.19278245549353343, "alpha_value": 0.06600773573839132, "duration": 25.55031156539917, "step": 11875}
{"episode_reward": 285.63689578089287, "episode": 96.0, "batch_reward": 1.1358984804153442, "critic_loss": 1.999605607032776, "actor_loss": -55.75606210770145, "actor_target_entropy": -6.0, "actor_entropy": 2.896702851018598, "alpha_loss": 0.18631827230415038, "alpha_value": 0.06571623864918905, "duration": 25.521530628204346, "step": 12000}
{"episode_reward": 274.310297622386, "episode": 97.0, "batch_reward": 1.1506515560150146, "critic_loss": 1.8550543842315674, "actor_loss": -56.43169839041574, "actor_target_entropy": -6.0, "actor_entropy": 2.829796722957066, "alpha_loss": 0.18827703618814076, "alpha_value": 0.06542836349434297, "duration": 25.583913564682007, "step": 12125}
{"episode_reward": 198.51907961183647, "episode": 98.0, "batch_reward": 1.1479533824920654, "critic_loss": 2.045142823219299, "actor_loss": -57.30429267883301, "actor_target_entropy": -6.0, "actor_entropy": 2.857765236208516, "alpha_loss": 0.18275836062046788, "alpha_value": 0.06513489527469601, "duration": 25.475878953933716, "step": 12250}
{"episode_reward": 242.77669203035845, "episode": 99.0, "batch_reward": 1.1667518949508666, "critic_loss": 2.081494164466858, "actor_loss": -58.17772686670697, "actor_target_entropy": -6.0, "actor_entropy": 2.8537551183549184, "alpha_loss": 0.17772342170041705, "alpha_value": 0.06485027932491501, "duration": 25.57079815864563, "step": 12375}
{"episode_reward": 282.251752381947, "episode": 100.0, "batch_reward": 1.174612377166748, "critic_loss": 1.9336077823638915, "actor_loss": -58.79611495233351, "actor_target_entropy": -6.0, "actor_entropy": 2.80796972397835, "alpha_loss": 0.17849656843370007, "alpha_value": 0.06456421957161075, "duration": 25.521791219711304, "step": 12500}
{"episode_reward": 306.273080496742, "episode": 101.0, "batch_reward": 1.1964553251266479, "critic_loss": 2.087756015777588, "actor_loss": -59.808782183934774, "actor_target_entropy": -6.0, "actor_entropy": 2.684590680258615, "alpha_loss": 0.16712897270917892, "alpha_value": 0.06428275239778268, "duration": 25.561679363250732, "step": 12625}
{"episode_reward": 274.89526850032706, "episode": 102.0, "batch_reward": 1.1944794731140136, "critic_loss": 1.7449047060012817, "actor_loss": -60.43157663652974, "actor_target_entropy": -6.0, "actor_entropy": 2.7117932842623804, "alpha_loss": 0.1728146561691838, "alpha_value": 0.06400251312022401, "duration": 25.54376792907715, "step": 12750}
{"episode_reward": 284.34902804095844, "episode": 103.0, "batch_reward": 1.2068918561935424, "critic_loss": 1.79047664642334, "actor_loss": -61.56256151956225, "actor_target_entropy": -6.0, "actor_entropy": 2.6594104009961326, "alpha_loss": 0.16180508477347239, "alpha_value": 0.06372500370262095, "duration": 25.58919930458069, "step": 12875}
{"episode_reward": 321.21100377003825, "episode": 104.0, "batch_reward": 1.2164798889160156, "critic_loss": 1.7904550275802613, "actor_loss": -62.436313321513516, "actor_target_entropy": -6.0, "actor_entropy": 2.598179551862901, "alpha_loss": 0.1621740048210467, "alpha_value": 0.06345448513347397, "duration": 25.499589920043945, "step": 13000}
{"episode_reward": 258.3465703298541, "episode": 105.0, "batch_reward": 1.225768440246582, "critic_loss": 1.8983125047683715, "actor_loss": -63.13299051920573, "actor_target_entropy": -6.0, "actor_entropy": 2.6212496984572637, "alpha_loss": 0.1523114044278387, "alpha_value": 0.06318736932458145, "duration": 25.5758957862854, "step": 13125}
{"episode_reward": 275.052829053335, "episode": 106.0, "batch_reward": 1.2324454030990601, "critic_loss": 2.1423644733428957, "actor_loss": -64.04987322899603, "actor_target_entropy": -6.0, "actor_entropy": 2.6384676848688433, "alpha_loss": 0.14702617821674194, "alpha_value": 0.06292908837950252, "duration": 25.495119094848633, "step": 13250}
{"episode_reward": 271.0987242548104, "episode": 107.0, "batch_reward": 1.2409424533843993, "critic_loss": 2.029393183708191, "actor_loss": -64.85809580485027, "actor_target_entropy": -6.0, "actor_entropy": 2.5280928119780524, "alpha_loss": 0.14019016412988541, "alpha_value": 0.06267846162230382, "duration": 25.608572721481323, "step": 13375}
{"episode_reward": 289.5142510763172, "episode": 108.0, "batch_reward": 1.2481343841552734, "critic_loss": 2.1309203147888183, "actor_loss": -65.6269019342238, "actor_target_entropy": -6.0, "actor_entropy": 2.529573017551053, "alpha_loss": 0.14421087671672145, "alpha_value": 0.06242577511766616, "duration": 25.50013494491577, "step": 13500}
{"episode_reward": 178.06385006897025, "episode": 109.0, "batch_reward": 1.2541345243453978, "critic_loss": 2.335931595802307, "actor_loss": -66.17723386249845, "actor_target_entropy": -6.0, "actor_entropy": 2.6137779780796597, "alpha_loss": 0.1405945129337765, "alpha_value": 0.06217222441031607, "duration": 25.63010334968567, "step": 13625}
{"episode_reward": 298.99738362031206, "episode": 110.0, "batch_reward": 1.2579570255279542, "critic_loss": 2.3388825073242185, "actor_loss": -66.82305194485572, "actor_target_entropy": -6.0, "actor_entropy": 2.5211834446076424, "alpha_loss": 0.1425535090027317, "alpha_value": 0.061913407361679385, "duration": 25.57199478149414, "step": 13750}
{"episode_reward": 59.098186959513065, "episode": 111.0, "batch_reward": 1.2565940084457397, "critic_loss": 2.7153028678894042, "actor_loss": -67.645995367141, "actor_target_entropy": -6.0, "actor_entropy": 2.52507950389196, "alpha_loss": 0.13651152735664732, "alpha_value": 0.06165492286226617, "duration": 25.563499927520752, "step": 13875}
{"episode_reward": 250.08068353717778, "episode": 112.0, "batch_reward": 1.2699587926864624, "critic_loss": 3.041217420578003, "actor_loss": -68.41628819127237, "actor_target_entropy": -6.0, "actor_entropy": 2.6122898440207205, "alpha_loss": 0.13445122491928838, "alpha_value": 0.061402153392421104, "duration": 25.514253616333008, "step": 14000}
{"episode_reward": 307.90189519230375, "episode": 113.0, "batch_reward": 1.276836769104004, "critic_loss": 2.931769612312317, "actor_loss": -69.13471343025329, "actor_target_entropy": -6.0, "actor_entropy": 2.579949344907488, "alpha_loss": 0.13268974518019055, "alpha_value": 0.06114881369195713, "duration": 25.615296125411987, "step": 14125}
{"episode_reward": 329.6583774320582, "episode": 114.0, "batch_reward": 1.2855247888565065, "critic_loss": 2.8384115257263183, "actor_loss": -70.05513000488281, "actor_target_entropy": -6.0, "actor_entropy": 2.5019558168226674, "alpha_loss": 0.1207837002171624, "alpha_value": 0.060899934524211816, "duration": 25.506680965423584, "step": 14250}
{"episode_reward": 280.04810377035426, "episode": 115.0, "batch_reward": 1.2977406883239746, "critic_loss": 3.01668678855896, "actor_loss": -70.80795300196088, "actor_target_entropy": -6.0, "actor_entropy": 2.454227267749726, "alpha_loss": 0.1197415619852051, "alpha_value": 0.06067110084784448, "duration": 25.603078603744507, "step": 14375}
{"episode_reward": 306.3891506735034, "episode": 116.0, "batch_reward": 1.3076882972717285, "critic_loss": 3.011011613845825, "actor_loss": -71.93174694430444, "actor_target_entropy": -6.0, "actor_entropy": 2.5200328211630545, "alpha_loss": 0.11755886902251551, "alpha_value": 0.06043142440651214, "duration": 25.53488802909851, "step": 14500}
{"episode_reward": 272.0435215704889, "episode": 117.0, "batch_reward": 1.3121208906173707, "critic_loss": 2.9143917360305784, "actor_loss": -72.59246172223773, "actor_target_entropy": -6.0, "actor_entropy": 2.512883027394613, "alpha_loss": 0.11300567856856755, "alpha_value": 0.06020489398473583, "duration": 25.680211305618286, "step": 14625}
{"episode_reward": 304.4699580183223, "episode": 118.0, "batch_reward": 1.3200212335586547, "critic_loss": 2.9091565980911254, "actor_loss": -73.73583750570974, "actor_target_entropy": -6.0, "actor_entropy": 2.446589896755834, "alpha_loss": 0.10984516528344923, "alpha_value": 0.059971637013019434, "duration": 25.541918516159058, "step": 14750}
{"episode_reward": 310.8930090841944, "episode": 119.0, "batch_reward": 1.3274149541854858, "critic_loss": 2.699573589324951, "actor_loss": -74.19502766927083, "actor_target_entropy": -6.0, "actor_entropy": 2.396169140225365, "alpha_loss": 0.10706488669864715, "alpha_value": 0.05974966576568504, "duration": 25.625428438186646, "step": 14875}
{"episode_reward": 189.8932818856297, "episode": 120.0, "batch_reward": 1.3446699295043945, "critic_loss": 3.025621584892273, "actor_loss": -75.17125726515248, "actor_target_entropy": -6.0, "actor_entropy": 2.302260035468686, "alpha_loss": 0.11374701427355889, "alpha_value": 0.059518462323015116, "step": 15000}
{"duration": 36.47485971450806, "step": 15000}
{"episode_reward": 314.64724993001414, "episode": 121.0, "batch_reward": 1.3468106880187989, "critic_loss": 3.0017836761474608, "actor_loss": -75.70386359805153, "actor_target_entropy": -6.0, "actor_entropy": 2.4182071307348827, "alpha_loss": 0.1111371966581496, "alpha_value": 0.059279372947967326, "duration": 25.568880558013916, "step": 15125}
{"episode_reward": 139.2278050119602, "episode": 122.0, "batch_reward": 1.335367561340332, "critic_loss": 3.0837646503448486, "actor_loss": -76.3503062340521, "actor_target_entropy": -6.0, "actor_entropy": 2.304793673176919, "alpha_loss": 0.10850434089379926, "alpha_value": 0.059035400046926985, "duration": 25.740249633789062, "step": 15250}
{"episode_reward": 120.90855520304599, "episode": 123.0, "batch_reward": 1.3354732265472413, "critic_loss": 3.1881232357025144, "actor_loss": -76.76397559756325, "actor_target_entropy": -6.0, "actor_entropy": 2.3677148232384333, "alpha_loss": 0.1049721378182608, "alpha_value": 0.05880075309953935, "duration": 25.57917022705078, "step": 15375}
{"episode_reward": 290.364096443384, "episode": 124.0, "batch_reward": 1.3479442434310913, "critic_loss": 3.113672695159912, "actor_loss": -77.39042848156345, "actor_target_entropy": -6.0, "actor_entropy": 2.235725389372918, "alpha_loss": 0.109998551467734, "alpha_value": 0.05856276758228755, "duration": 25.519064903259277, "step": 15500}
{"episode_reward": 107.99997707154783, "episode": 125.0, "batch_reward": 1.3417015228271485, "critic_loss": 3.436715353012085, "actor_loss": -77.74168928842695, "actor_target_entropy": -6.0, "actor_entropy": 2.325498520381867, "alpha_loss": 0.10702080362372929, "alpha_value": 0.05832117427372941, "duration": 25.56329917907715, "step": 15625}
{"episode_reward": 55.75496389787448, "episode": 126.0, "batch_reward": 1.3364085025787353, "critic_loss": 3.5876629734039307, "actor_loss": -78.40937386789629, "actor_target_entropy": -6.0, "actor_entropy": 2.437480305471728, "alpha_loss": 0.10534262957592164, "alpha_value": 0.05807673245055418, "duration": 25.56192398071289, "step": 15750}
{"episode_reward": 218.2202933215071, "episode": 127.0, "batch_reward": 1.340615240097046, "critic_loss": 3.462552547454834, "actor_loss": -79.10208856491815, "actor_target_entropy": -6.0, "actor_entropy": 2.2647511069736783, "alpha_loss": 0.10402099717231024, "alpha_value": 0.05783091373931122, "duration": 25.523022413253784, "step": 15875}
{"episode_reward": 309.8505607600769, "episode": 128.0, "batch_reward": 1.3450370874404907, "critic_loss": 3.65675563621521, "actor_loss": -80.17865334787676, "actor_target_entropy": -6.0, "actor_entropy": 2.253594369657578, "alpha_loss": 0.09826231267183058, "alpha_value": 0.05759781163343857, "duration": 25.456073999404907, "step": 16000}
{"episode_reward": 274.9107625368785, "episode": 129.0, "batch_reward": 1.357965437889099, "critic_loss": 3.4709481182098387, "actor_loss": -80.81371065170046, "actor_target_entropy": -6.0, "actor_entropy": 2.247980206731766, "alpha_loss": 0.08917033713724878, "alpha_value": 0.05736851770380887, "duration": 25.536734342575073, "step": 16125}
{"episode_reward": 346.39544609264425, "episode": 130.0, "batch_reward": 1.366626121520996, "critic_loss": 3.71967663192749, "actor_loss": -81.3294548526887, "actor_target_entropy": -6.0, "actor_entropy": 2.3185208843600367, "alpha_loss": 0.09084796160459518, "alpha_value": 0.05715376129124617, "duration": 25.467026233673096, "step": 16250}
{"episode_reward": 350.64214592272646, "episode": 131.0, "batch_reward": 1.3675173330307007, "critic_loss": 3.436322357177734, "actor_loss": -81.98207128615607, "actor_target_entropy": -6.0, "actor_entropy": 2.384245299157642, "alpha_loss": 0.08607426676012221, "alpha_value": 0.056936005052032085, "duration": 25.526245832443237, "step": 16375}
{"episode_reward": 45.416079923649825, "episode": 132.0, "batch_reward": 1.3716775035858155, "critic_loss": 3.3586588172912597, "actor_loss": -82.88387741581086, "actor_target_entropy": -6.0, "actor_entropy": 2.319032261448522, "alpha_loss": 0.08728721996228542, "alpha_value": 0.056719704272281395, "duration": 25.457008361816406, "step": 16500}
{"episode_reward": 320.37484637761236, "episode": 133.0, "batch_reward": 1.3855182285308838, "critic_loss": 3.1802947101593015, "actor_loss": -83.58038414849176, "actor_target_entropy": -6.0, "actor_entropy": 2.1698028719614424, "alpha_loss": 0.08913457050683006, "alpha_value": 0.05649936103816025, "duration": 25.5168616771698, "step": 16625}
{"episode_reward": 316.4185269897798, "episode": 134.0, "batch_reward": 1.3924931211471558, "critic_loss": 3.058039222717285, "actor_loss": -84.24208204207882, "actor_target_entropy": -6.0, "actor_entropy": 2.179594422540357, "alpha_loss": 0.08387689851224422, "alpha_value": 0.05627540838156029, "duration": 25.47780418395996, "step": 16750}
{"episode_reward": 286.92169543254755, "episode": 135.0, "batch_reward": 1.4020662631988525, "critic_loss": 3.2750250129699707, "actor_loss": -85.16944509839254, "actor_target_entropy": -6.0, "actor_entropy": 2.1257816893713817, "alpha_loss": 0.0827660635705032, "alpha_value": 0.05605967835791769, "duration": 25.516130208969116, "step": 16875}
{"episode_reward": 304.8740641027637, "episode": 136.0, "batch_reward": 1.4093099060058594, "critic_loss": 3.379517042160034, "actor_loss": -85.9427500078755, "actor_target_entropy": -6.0, "actor_entropy": 2.143979572480725, "alpha_loss": 0.07412925843269594, "alpha_value": 0.0558476118870293, "duration": 25.45708131790161, "step": 17000}
{"episode_reward": 346.7625885090963, "episode": 137.0, "batch_reward": 1.4109845447540283, "critic_loss": 3.0861267156600953, "actor_loss": -86.71246701195126, "actor_target_entropy": -6.0, "actor_entropy": 2.1588555441962347, "alpha_loss": 0.07676965128334742, "alpha_value": 0.055649908351326584, "duration": 27.054901599884033, "step": 17125}
{"episode_reward": 284.94505905743335, "episode": 138.0, "batch_reward": 1.4124812479019164, "critic_loss": 2.716409513473511, "actor_loss": -87.63267467867944, "actor_target_entropy": -6.0, "actor_entropy": 2.084819230341142, "alpha_loss": 0.07593894191086292, "alpha_value": 0.05543805298298217, "duration": 25.499701499938965, "step": 17250}
{"episode_reward": 287.2525635654258, "episode": 139.0, "batch_reward": 1.4221587009429932, "critic_loss": 3.1231430025100706, "actor_loss": -87.99115680512928, "actor_target_entropy": -6.0, "actor_entropy": 2.0502247469765797, "alpha_loss": 0.06896249139829287, "alpha_value": 0.05523789100775187, "duration": 25.524914979934692, "step": 17375}
{"episode_reward": 327.11920157881116, "episode": 140.0, "batch_reward": 1.4422985639572143, "critic_loss": 3.132004638671875, "actor_loss": -89.22023859331685, "actor_target_entropy": -6.0, "actor_entropy": 1.9509055922108312, "alpha_loss": 0.06626110463853806, "alpha_value": 0.055039791870445366, "duration": 25.459240436553955, "step": 17500}
{"episode_reward": 289.9125334803046, "episode": 141.0, "batch_reward": 1.4360707740783691, "critic_loss": 3.0580678634643554, "actor_loss": -89.59047081356957, "actor_target_entropy": -6.0, "actor_entropy": 2.0475267398925054, "alpha_loss": 0.06298939496397025, "alpha_value": 0.05485804464398066, "duration": 25.59794282913208, "step": 17625}
{"episode_reward": 331.4499972190771, "episode": 142.0, "batch_reward": 1.4530369739532472, "critic_loss": 3.223654893875122, "actor_loss": -90.53077070174679, "actor_target_entropy": -6.0, "actor_entropy": 2.0132158725492415, "alpha_loss": 0.06213714560914424, "alpha_value": 0.05466863099168095, "duration": 25.461403846740723, "step": 17750}
{"episode_reward": 323.3237689635965, "episode": 143.0, "batch_reward": 1.4606831493377685, "critic_loss": 2.963771553993225, "actor_loss": -91.2385521540566, "actor_target_entropy": -6.0, "actor_entropy": 2.037508623940604, "alpha_loss": 0.059661808083691294, "alpha_value": 0.05449556054453642, "duration": 25.464664697647095, "step": 17875}
{"episode_reward": 322.7304417967622, "episode": 144.0, "batch_reward": 1.4672058734893798, "critic_loss": 2.8004795989990234, "actor_loss": -92.14720621416646, "actor_target_entropy": -6.0, "actor_entropy": 1.843616416377406, "alpha_loss": 0.054308505818968816, "alpha_value": 0.054319361002478944, "duration": 25.4900381565094, "step": 18000}
{"episode_reward": 347.8849855469314, "episode": 145.0, "batch_reward": 1.4777957830429078, "critic_loss": 3.1522190761566162, "actor_loss": -92.95465984041729, "actor_target_entropy": -6.0, "actor_entropy": 1.896994286113315, "alpha_loss": 0.04902611211651847, "alpha_value": 0.05415708622882537, "duration": 25.564343214035034, "step": 18125}
{"episode_reward": 307.8754456117334, "episode": 146.0, "batch_reward": 1.481865740776062, "critic_loss": 3.0568086099624634, "actor_loss": -93.98449017924648, "actor_target_entropy": -6.0, "actor_entropy": 1.8650947501582484, "alpha_loss": 0.049836604825911984, "alpha_value": 0.05400190570214865, "duration": 25.50149965286255, "step": 18250}
{"episode_reward": 291.944825721348, "episode": 147.0, "batch_reward": 1.4783494882583619, "critic_loss": 3.145448143005371, "actor_loss": -94.24793098086403, "actor_target_entropy": -6.0, "actor_entropy": 1.9110799233118694, "alpha_loss": 0.05247127377088108, "alpha_value": 0.05383651720948937, "duration": 25.576136589050293, "step": 18375}
{"episode_reward": 194.27514891470747, "episode": 148.0, "batch_reward": 1.485956597328186, "critic_loss": 3.3023150711059572, "actor_loss": -95.00321997365644, "actor_target_entropy": -6.0, "actor_entropy": 1.9007581818488337, "alpha_loss": 0.04991452053429619, "alpha_value": 0.05367105316325037, "duration": 25.509960651397705, "step": 18500}
{"episode_reward": 315.16685990871633, "episode": 149.0, "batch_reward": 1.4946680927276612, "critic_loss": 3.3396034965515136, "actor_loss": -95.63953472319103, "actor_target_entropy": -6.0, "actor_entropy": 1.9494734491620744, "alpha_loss": 0.04882779248827507, "alpha_value": 0.05350480069247638, "duration": 25.599886178970337, "step": 18625}
{"episode_reward": 354.7251962504882, "episode": 150.0, "batch_reward": 1.5031690320968627, "critic_loss": 3.3233247108459474, "actor_loss": -96.80390782510081, "actor_target_entropy": -6.0, "actor_entropy": 1.826239287853241, "alpha_loss": 0.04502199713381067, "alpha_value": 0.053339593772505196, "duration": 25.51016616821289, "step": 18750}
{"episode_reward": 268.4461112263423, "episode": 151.0, "batch_reward": 1.5071819705963134, "critic_loss": 3.5677266845703124, "actor_loss": -97.23539697556268, "actor_target_entropy": -6.0, "actor_entropy": 1.9492884855421762, "alpha_loss": 0.0452573797295964, "alpha_value": 0.05318142397659902, "duration": 25.53615927696228, "step": 18875}
{"episode_reward": 353.9389905809826, "episode": 152.0, "batch_reward": 1.5107805786132813, "critic_loss": 4.091523267745972, "actor_loss": -97.98524868872857, "actor_target_entropy": -6.0, "actor_entropy": 1.8646927264428907, "alpha_loss": 0.04737610874637481, "alpha_value": 0.05301179089230795, "duration": 25.51142144203186, "step": 19000}
{"episode_reward": 331.5727490764739, "episode": 153.0, "batch_reward": 1.5205620937347413, "critic_loss": 3.784325185775757, "actor_loss": -98.85309625050378, "actor_target_entropy": -6.0, "actor_entropy": 1.7988273643312, "alpha_loss": 0.044848530568064204, "alpha_value": 0.05284900045204573, "duration": 25.625332355499268, "step": 19125}
{"episode_reward": 254.44859435662505, "episode": 154.0, "batch_reward": 1.5289904346466066, "critic_loss": 4.2292189807891845, "actor_loss": -99.48487226424679, "actor_target_entropy": -6.0, "actor_entropy": 1.7811708565681212, "alpha_loss": 0.044146542377289266, "alpha_value": 0.052679722134761846, "duration": 25.495211362838745, "step": 19250}
{"episode_reward": 345.2459200488737, "episode": 155.0, "batch_reward": 1.533615242958069, "critic_loss": 3.959358694076538, "actor_loss": -100.01708088223896, "actor_target_entropy": -6.0, "actor_entropy": 1.7929799745953272, "alpha_loss": 0.03141970346341767, "alpha_value": 0.05253970924394189, "duration": 25.593014240264893, "step": 19375}
{"episode_reward": 331.63528777234825, "episode": 156.0, "batch_reward": 1.544337776184082, "critic_loss": 3.595232088088989, "actor_loss": -100.9462430400233, "actor_target_entropy": -6.0, "actor_entropy": 1.8063386294149584, "alpha_loss": 0.026668580203887918, "alpha_value": 0.05241966187431553, "duration": 25.489119291305542, "step": 19500}
{"episode_reward": 257.895893705878, "episode": 157.0, "batch_reward": 1.557275650024414, "critic_loss": 3.6742142543792724, "actor_loss": -102.14434983995226, "actor_target_entropy": -6.0, "actor_entropy": 1.6875800310619293, "alpha_loss": 0.030857047117832635, "alpha_value": 0.05231619157851864, "duration": 25.59450674057007, "step": 19625}
{"episode_reward": 320.30540920608274, "episode": 158.0, "batch_reward": 1.5396728610992432, "critic_loss": 4.051918479919434, "actor_loss": -102.26178175403226, "actor_target_entropy": -6.0, "actor_entropy": 1.872307627431808, "alpha_loss": 0.028097099564488855, "alpha_value": 0.052189766438740584, "duration": 25.513176918029785, "step": 19750}
{"episode_reward": 327.1107313596599, "episode": 159.0, "batch_reward": 1.5587403879165649, "critic_loss": 4.01332137298584, "actor_loss": -103.47075919499473, "actor_target_entropy": -6.0, "actor_entropy": 1.7630670411246163, "alpha_loss": 0.024814463015423997, "alpha_value": 0.05207237668629338, "duration": 25.535012006759644, "step": 19875}
{"episode_reward": 195.47414271561217, "episode": 160.0, "batch_reward": 1.56039874458313, "critic_loss": 3.9429878273010255, "actor_loss": -103.7774409632529, "actor_target_entropy": -6.0, "actor_entropy": 1.7141626842560307, "alpha_loss": 0.02638938571626861, "alpha_value": 0.05197421827285048, "step": 20000}
{"duration": 36.40858793258667, "step": 20000}
{"episode_reward": 350.51935959189416, "episode": 161.0, "batch_reward": 1.5632790899276734, "critic_loss": 4.2266590137481685, "actor_loss": -104.49922349717882, "actor_target_entropy": -6.0, "actor_entropy": 1.6451268517781819, "alpha_loss": 0.02851456101791608, "alpha_value": 0.05185359778104228, "duration": 25.511982202529907, "step": 20125}
{"episode_reward": 348.2163937408668, "episode": 162.0, "batch_reward": 1.5783747653961182, "critic_loss": 4.497293352127075, "actor_loss": -105.33364437472436, "actor_target_entropy": -6.0, "actor_entropy": 1.7325335510315434, "alpha_loss": 0.0318823162346117, "alpha_value": 0.051724826266185416, "duration": 25.498549699783325, "step": 20250}
{"episode_reward": 241.79387761691942, "episode": 163.0, "batch_reward": 1.5719855489730834, "critic_loss": 5.342208839416504, "actor_loss": -105.69270772782583, "actor_target_entropy": -6.0, "actor_entropy": 1.680892200697036, "alpha_loss": 0.028064559228600017, "alpha_value": 0.051576728616606615, "duration": 25.56810235977173, "step": 20375}
{"episode_reward": 241.76174938839313, "episode": 164.0, "batch_reward": 1.583326766014099, "critic_loss": 5.915216157913208, "actor_loss": -106.28579884190714, "actor_target_entropy": -6.0, "actor_entropy": 1.6770601734038322, "alpha_loss": 0.03530743240844458, "alpha_value": 0.0514237025143012, "duration": 25.46530556678772, "step": 20500}
{"episode_reward": 168.48079827300626, "episode": 165.0, "batch_reward": 1.5743709802627563, "critic_loss": 6.180435369491577, "actor_loss": -106.77485765729632, "actor_target_entropy": -6.0, "actor_entropy": 1.7126188524185666, "alpha_loss": 0.030175325880196713, "alpha_value": 0.05126767443679136, "duration": 25.52588939666748, "step": 20625}
{"episode_reward": 310.68088192178897, "episode": 166.0, "batch_reward": 1.5846033611297607, "critic_loss": 6.430936168670654, "actor_loss": -107.72380029001543, "actor_target_entropy": -6.0, "actor_entropy": 1.605866176466788, "alpha_loss": 0.019794991632337652, "alpha_value": 0.051150042700501115, "duration": 25.48682975769043, "step": 20750}
{"episode_reward": 194.79868754553803, "episode": 167.0, "batch_reward": 1.5775262136459351, "critic_loss": 6.141456718444824, "actor_loss": -108.08123137458922, "actor_target_entropy": -6.0, "actor_entropy": 1.627265833673023, "alpha_loss": 0.025721091387187322, "alpha_value": 0.051034035885263625, "duration": 25.57838749885559, "step": 20875}
{"episode_reward": 307.8779382734629, "episode": 168.0, "batch_reward": 1.5914405517578125, "critic_loss": 6.70120267868042, "actor_loss": -109.24162169425718, "actor_target_entropy": -6.0, "actor_entropy": 1.5866489775719181, "alpha_loss": 0.022747891898747655, "alpha_value": 0.05090283481557692, "duration": 25.469067573547363, "step": 21000}
{"episode_reward": 355.2382559080706, "episode": 169.0, "batch_reward": 1.5991536960601807, "critic_loss": 7.070019020080567, "actor_loss": -109.99667721702939, "actor_target_entropy": -6.0, "actor_entropy": 1.558387273833865, "alpha_loss": 0.016196401294557346, "alpha_value": 0.050814191983006435, "duration": 25.548836946487427, "step": 21125}
{"episode_reward": 330.02804661710854, "episode": 170.0, "batch_reward": 1.6034949111938477, "critic_loss": 5.977792499542236, "actor_loss": -110.58420045914188, "actor_target_entropy": -6.0, "actor_entropy": 1.5192980593250645, "alpha_loss": 0.014911173914198673, "alpha_value": 0.05073783379523503, "duration": 25.500537633895874, "step": 21250}
{"episode_reward": 283.6147584827699, "episode": 171.0, "batch_reward": 1.5999015550613402, "critic_loss": 6.132534713745117, "actor_loss": -110.70365070161365, "actor_target_entropy": -6.0, "actor_entropy": 1.6194849165659102, "alpha_loss": 0.011458681286534383, "alpha_value": 0.0506566100218752, "duration": 25.55875253677368, "step": 21375}
{"episode_reward": 335.2829199111708, "episode": 172.0, "batch_reward": 1.6016281833648682, "critic_loss": 6.868248601913452, "actor_loss": -111.86967012959141, "actor_target_entropy": -6.0, "actor_entropy": 1.588506079489185, "alpha_loss": 0.010677370909346087, "alpha_value": 0.050584058030665804, "duration": 25.468242645263672, "step": 21500}
{"episode_reward": 140.45173147961302, "episode": 173.0, "batch_reward": 1.6196512174606323, "critic_loss": 7.5084050846099855, "actor_loss": -112.68339090498667, "actor_target_entropy": -6.0, "actor_entropy": 1.441640728049808, "alpha_loss": 0.015325672392334257, "alpha_value": 0.050518959748967446, "duration": 25.53153967857361, "step": 21625}
{"episode_reward": 224.2431747464427, "episode": 174.0, "batch_reward": 1.606424464225769, "critic_loss": 6.943782337188721, "actor_loss": -113.06004235052293, "actor_target_entropy": -6.0, "actor_entropy": 1.4507631794098885, "alpha_loss": 0.02358923422833604, "alpha_value": 0.05040155128935705, "duration": 25.464569091796875, "step": 21750}
{"episode_reward": 306.981566421809, "episode": 175.0, "batch_reward": 1.6112935466766358, "critic_loss": 7.361388633728027, "actor_loss": -113.42838033040364, "actor_target_entropy": -6.0, "actor_entropy": 1.484460128678216, "alpha_loss": 0.020068635676233543, "alpha_value": 0.050277851415776044, "duration": 25.566360235214233, "step": 21875}
{"episode_reward": 317.70973360133905, "episode": 176.0, "batch_reward": 1.6221484794616698, "critic_loss": 7.780944049835205, "actor_loss": -114.59986717470231, "actor_target_entropy": -6.0, "actor_entropy": 1.4304167532151746, "alpha_loss": 0.009042063311132933, "alpha_value": 0.050180323696972964, "duration": 25.497405529022217, "step": 22000}
{"episode_reward": 298.4335454509376, "episode": 177.0, "batch_reward": 1.627813959121704, "critic_loss": 7.927279605865478, "actor_loss": -115.52104780409071, "actor_target_entropy": -6.0, "actor_entropy": 1.392556651244088, "alpha_loss": 0.015531922716440426, "alpha_value": 0.050093099595451426, "duration": 25.631988286972046, "step": 22125}
{"episode_reward": 306.609286722532, "episode": 178.0, "batch_reward": 1.6289665641784667, "critic_loss": 7.556664026260376, "actor_loss": -115.86714603054908, "actor_target_entropy": -6.0, "actor_entropy": 1.4291241505453665, "alpha_loss": 0.012802114789073745, "alpha_value": 0.049993163218977045, "duration": 25.487114191055298, "step": 22250}
{"episode_reward": 271.4267309048959, "episode": 179.0, "batch_reward": 1.629088062286377, "critic_loss": 7.735665996551513, "actor_loss": -116.79967958964998, "actor_target_entropy": -6.0, "actor_entropy": 1.4043567360393585, "alpha_loss": 0.010128639963647676, "alpha_value": 0.04993040166323501, "duration": 25.56082034111023, "step": 22375}
{"episode_reward": 345.22483317922547, "episode": 180.0, "batch_reward": 1.6442791185379029, "critic_loss": 8.031381259918213, "actor_loss": -117.80320653607768, "actor_target_entropy": -6.0, "actor_entropy": 1.3808972172198757, "alpha_loss": 0.008300167290614016, "alpha_value": 0.04986358731489787, "duration": 25.51433777809143, "step": 22500}
{"episode_reward": 319.6434135967934, "episode": 181.0, "batch_reward": 1.6459026031494142, "critic_loss": 7.562726451873779, "actor_loss": -118.09835294693235, "actor_target_entropy": -6.0, "actor_entropy": 1.2902084570082406, "alpha_loss": 0.01298834538338558, "alpha_value": 0.049801661422121835, "duration": 25.59481120109558, "step": 22625}
{"episode_reward": 313.599968869095, "episode": 182.0, "batch_reward": 1.6438237743377686, "critic_loss": 7.613371444702149, "actor_loss": -118.87377498995873, "actor_target_entropy": -6.0, "actor_entropy": 1.3752964850394958, "alpha_loss": 0.0066372544144190125, "alpha_value": 0.049713163617573566, "duration": 25.508195877075195, "step": 22750}
{"episode_reward": 332.67647499707675, "episode": 183.0, "batch_reward": 1.6461020059585572, "critic_loss": 7.248581722259521, "actor_loss": -119.91574120899988, "actor_target_entropy": -6.0, "actor_entropy": 1.3608285983403523, "alpha_loss": 0.0064209154067886255, "alpha_value": 0.04966727792345627, "duration": 25.62959933280945, "step": 22875}
{"episode_reward": 216.15073880036348, "episode": 184.0, "batch_reward": 1.6652574815750123, "critic_loss": 6.933758916854859, "actor_loss": -120.78642703640845, "actor_target_entropy": -6.0, "actor_entropy": 1.318217949521157, "alpha_loss": 0.006053968171228564, "alpha_value": 0.049617219657936175, "duration": 25.494468688964844, "step": 23000}
{"episode_reward": 333.1403199706817, "episode": 185.0, "batch_reward": 1.662242223739624, "critic_loss": 7.683277114868164, "actor_loss": -121.47290305485801, "actor_target_entropy": -6.0, "actor_entropy": 1.4145578988014706, "alpha_loss": 0.005394273038421359, "alpha_value": 0.049580235503368465, "duration": 25.550257682800293, "step": 23125}
{"episode_reward": 220.25884535963263, "episode": 186.0, "batch_reward": 1.658218313217163, "critic_loss": 7.708776824951172, "actor_loss": -122.01563127579227, "actor_target_entropy": -6.0, "actor_entropy": 1.389163109564012, "alpha_loss": 0.002596904794054647, "alpha_value": 0.04956634870607942, "duration": 25.491947650909424, "step": 23250}
{"episode_reward": 311.07517357614086, "episode": 187.0, "batch_reward": 1.6606817150115967, "critic_loss": 8.775862457275391, "actor_loss": -122.25824422684927, "actor_target_entropy": -6.0, "actor_entropy": 1.2576622726425293, "alpha_loss": 0.009357800570479224, "alpha_value": 0.049497858463853836, "duration": 25.622626543045044, "step": 23375}
{"episode_reward": 265.7434339818308, "episode": 188.0, "batch_reward": 1.6643898973464966, "critic_loss": 8.497932197570801, "actor_loss": -122.90946505146641, "actor_target_entropy": -6.0, "actor_entropy": 1.2950751800690927, "alpha_loss": 0.0091020910899275, "alpha_value": 0.04942582786714196, "duration": 25.55748414993286, "step": 23500}
{"episode_reward": 226.726074753718, "episode": 189.0, "batch_reward": 1.6585217332839965, "critic_loss": 8.436298965454101, "actor_loss": -123.25983332073878, "actor_target_entropy": -6.0, "actor_entropy": 1.3735957779581585, "alpha_loss": -0.004192229465670174, "alpha_value": 0.049398602106745286, "duration": 25.580138444900513, "step": 23625}
{"episode_reward": 215.9476208593879, "episode": 190.0, "batch_reward": 1.6753189096450805, "critic_loss": 9.000132461547851, "actor_loss": -124.24781959287581, "actor_target_entropy": -6.0, "actor_entropy": 1.3988371549114105, "alpha_loss": -0.008319369361420432, "alpha_value": 0.049451004615862694, "duration": 25.58587884902954, "step": 23750}
{"episode_reward": 322.9245332916433, "episode": 191.0, "batch_reward": 1.6716812715530396, "critic_loss": 8.43449857711792, "actor_loss": -124.34749772813585, "actor_target_entropy": -6.0, "actor_entropy": 1.406387069868663, "alpha_loss": 0.004583384971030884, "alpha_value": 0.04948534604233242, "duration": 25.61842107772827, "step": 23875}
{"episode_reward": 324.9245596596384, "episode": 192.0, "batch_reward": 1.6782979259490967, "critic_loss": 7.943840026855469, "actor_loss": -125.49609842608052, "actor_target_entropy": -6.0, "actor_entropy": 1.4084647240177277, "alpha_loss": -0.005851258341628578, "alpha_value": 0.04946562970274909, "duration": 25.487857580184937, "step": 24000}
{"episode_reward": 360.42927229296447, "episode": 193.0, "batch_reward": 1.674267879486084, "critic_loss": 7.8919831581115725, "actor_loss": -125.99764627123636, "actor_target_entropy": -6.0, "actor_entropy": 1.3679295371449183, "alpha_loss": -0.003242183986696459, "alpha_value": 0.04950964877638968, "duration": 25.624290466308594, "step": 24125}
{"episode_reward": 67.38184706636075, "episode": 194.0, "batch_reward": 1.6758823633193969, "critic_loss": 8.28513115310669, "actor_loss": -126.8922635970577, "actor_target_entropy": -6.0, "actor_entropy": 1.410730839737, "alpha_loss": -0.0018361868682287394, "alpha_value": 0.04953916447418523, "duration": 25.567469596862793, "step": 24250}
{"episode_reward": 228.96310798473075, "episode": 195.0, "batch_reward": 1.6778408184051514, "critic_loss": 8.169486736297607, "actor_loss": -127.45977359347873, "actor_target_entropy": -6.0, "actor_entropy": 1.3817341583115714, "alpha_loss": -0.0053043286648711985, "alpha_value": 0.0495780657414171, "duration": 25.62054204940796, "step": 24375}
{"episode_reward": 283.69493964375357, "episode": 196.0, "batch_reward": 1.6894179849624633, "critic_loss": 7.758110404968262, "actor_loss": -127.44644804923765, "actor_target_entropy": -6.0, "actor_entropy": 1.5331014087123256, "alpha_loss": -0.007241299473530342, "alpha_value": 0.04965553457296082, "duration": 25.553001165390015, "step": 24500}
{"episode_reward": 101.29848341862532, "episode": 197.0, "batch_reward": 1.6808892107009887, "critic_loss": 7.486343650817871, "actor_loss": -128.13679540724982, "actor_target_entropy": -6.0, "actor_entropy": 1.3577623537608556, "alpha_loss": -0.008130878083489185, "alpha_value": 0.04973326123550453, "duration": 25.621920108795166, "step": 24625}
{"episode_reward": 361.31936591871585, "episode": 198.0, "batch_reward": 1.6867757024765015, "critic_loss": 8.111512382507325, "actor_loss": -128.56500810192478, "actor_target_entropy": -6.0, "actor_entropy": 1.4855650759512378, "alpha_loss": -0.003351105688770692, "alpha_value": 0.049801251973765365, "duration": 25.52640461921692, "step": 24750}
{"episode_reward": 266.18706179743344, "episode": 199.0, "batch_reward": 1.6883596591949463, "critic_loss": 7.66256640625, "actor_loss": -129.536501082163, "actor_target_entropy": -6.0, "actor_entropy": 1.3912409752134294, "alpha_loss": -0.005887339917188953, "alpha_value": 0.049848952477007255, "duration": 25.56393027305603, "step": 24875}
{"episode_reward": 358.3676630844881, "episode": 200.0, "batch_reward": 1.6982063665390015, "critic_loss": 7.030074352264404, "actor_loss": -130.3276717893539, "actor_target_entropy": -6.0, "actor_entropy": 1.4816563004447567, "alpha_loss": -0.003181286312023839, "alpha_value": 0.049894941326929086, "step": 25000}
{"duration": 36.29853296279907, "step": 25000}
{"episode_reward": 210.42300538645677, "episode": 201.0, "batch_reward": 1.6959714670181274, "critic_loss": 7.1730933818817135, "actor_loss": -130.43720305912078, "actor_target_entropy": -6.0, "actor_entropy": 1.4989135057207137, "alpha_loss": 0.0025826866003049033, "alpha_value": 0.04991016719440263, "duration": 25.58851408958435, "step": 25125}
{"episode_reward": 329.62144106288304, "episode": 202.0, "batch_reward": 1.6926446361541747, "critic_loss": 6.808933601379395, "actor_loss": -130.79281714654738, "actor_target_entropy": -6.0, "actor_entropy": 1.307487084980934, "alpha_loss": -0.003452587208049672, "alpha_value": 0.04989826253545711, "duration": 25.583388328552246, "step": 25250}
{"episode_reward": 340.2827652855965, "episode": 203.0, "batch_reward": 1.7071792097091676, "critic_loss": 6.744793720245362, "actor_loss": -131.7441133771624, "actor_target_entropy": -6.0, "actor_entropy": 1.226718455080002, "alpha_loss": -0.009077069377304898, "alpha_value": 0.04996380598711609, "duration": 25.593507766723633, "step": 25375}
{"episode_reward": 311.64628288912905, "episode": 204.0, "batch_reward": 1.6976500434875488, "critic_loss": 7.076247058868408, "actor_loss": -132.31109225365424, "actor_target_entropy": -6.0, "actor_entropy": 1.424033026541433, "alpha_loss": -0.004217003958464991, "alpha_value": 0.05010190911012804, "duration": 25.582083225250244, "step": 25500}
{"episode_reward": 298.92396760201945, "episode": 205.0, "batch_reward": 1.7068418951034545, "critic_loss": 6.619473804473877, "actor_loss": -133.17093016609314, "actor_target_entropy": -6.0, "actor_entropy": 1.2965040736728244, "alpha_loss": -0.0018322695793199634, "alpha_value": 0.050112192670399645, "duration": 25.67178201675415, "step": 25625}
{"episode_reward": 362.57936351615024, "episode": 206.0, "batch_reward": 1.7177300891876222, "critic_loss": 6.240777370452881, "actor_loss": -133.3074515558058, "actor_target_entropy": -6.0, "actor_entropy": 1.3698515103709312, "alpha_loss": -0.0053700760585225875, "alpha_value": 0.05013800580602975, "duration": 25.489973068237305, "step": 25750}
{"episode_reward": 337.65428023139555, "episode": 207.0, "batch_reward": 1.7303286924362182, "critic_loss": 6.517819156646729, "actor_loss": -134.54254465254527, "actor_target_entropy": -6.0, "actor_entropy": 1.3335104158946447, "alpha_loss": -0.004326060885519144, "alpha_value": 0.05021038612154783, "duration": 25.56020712852478, "step": 25875}
{"episode_reward": 341.6774067233537, "episode": 208.0, "batch_reward": 1.7243804950714112, "critic_loss": 6.133464046478272, "actor_loss": -134.70652820217995, "actor_target_entropy": -6.0, "actor_entropy": 1.3186220565149862, "alpha_loss": -0.010460378925105738, "alpha_value": 0.050326321384587265, "duration": 25.565932035446167, "step": 26000}
{"episode_reward": 301.83629772001126, "episode": 209.0, "batch_reward": 1.7335288925170897, "critic_loss": 5.686722257614136, "actor_loss": -135.4543919638982, "actor_target_entropy": -6.0, "actor_entropy": 1.2215375994879103, "alpha_loss": -0.012485979697740977, "alpha_value": 0.0504799082515952, "duration": 25.57889699935913, "step": 26125}
{"episode_reward": 334.9649661982125, "episode": 210.0, "batch_reward": 1.7337781381607056, "critic_loss": 5.610384468078613, "actor_loss": -136.4410144436744, "actor_target_entropy": -6.0, "actor_entropy": 1.278138449115138, "alpha_loss": -0.004014952046300976, "alpha_value": 0.05060749083373687, "duration": 25.541502475738525, "step": 26250}
{"episode_reward": 343.5852436833177, "episode": 211.0, "batch_reward": 1.7452626295089722, "critic_loss": 5.964247161865234, "actor_loss": -136.95020112537202, "actor_target_entropy": -6.0, "actor_entropy": 1.2354233009474618, "alpha_loss": -0.008349520882355079, "alpha_value": 0.050680348310002975, "duration": 25.596306085586548, "step": 26375}
{"episode_reward": 370.478252530378, "episode": 212.0, "batch_reward": 1.7477265787124634, "critic_loss": 6.096469652175903, "actor_loss": -137.5239021547379, "actor_target_entropy": -6.0, "actor_entropy": 1.2644133990810764, "alpha_loss": -0.005341963354317892, "alpha_value": 0.05078162006475404, "duration": 25.518454551696777, "step": 26500}
{"episode_reward": 325.34464284942095, "episode": 213.0, "batch_reward": 1.7433743057250977, "critic_loss": 5.784192527770996, "actor_loss": -137.96014743381076, "actor_target_entropy": -6.0, "actor_entropy": 1.1997738244041565, "alpha_loss": -0.005291251694813134, "alpha_value": 0.05084645817227691, "duration": 25.58924126625061, "step": 26625}
{"episode_reward": 378.9384983668963, "episode": 214.0, "batch_reward": 1.7532979726791382, "critic_loss": 5.942746063232422, "actor_loss": -138.56982077321697, "actor_target_entropy": -6.0, "actor_entropy": 1.200585683507304, "alpha_loss": -0.00699670251173478, "alpha_value": 0.05095882736666355, "duration": 25.513957262039185, "step": 26750}
{"episode_reward": 266.9641329551808, "episode": 215.0, "batch_reward": 1.7493570728302001, "critic_loss": 6.026285652160644, "actor_loss": -139.05389767601378, "actor_target_entropy": -6.0, "actor_entropy": 1.18730718559689, "alpha_loss": -0.0069712187267012065, "alpha_value": 0.05107119921040225, "duration": 25.614274263381958, "step": 26875}
{"episode_reward": 335.01986792638786, "episode": 216.0, "batch_reward": 1.760379141807556, "critic_loss": 5.671488063812256, "actor_loss": -139.33954054309476, "actor_target_entropy": -6.0, "actor_entropy": 1.168137127353299, "alpha_loss": -0.00460807898555011, "alpha_value": 0.05113243115039666, "duration": 25.516950130462646, "step": 27000}
{"episode_reward": 366.4442332021108, "episode": 217.0, "batch_reward": 1.7701667184829712, "critic_loss": 5.867410564422608, "actor_loss": -140.16890147375682, "actor_target_entropy": -6.0, "actor_entropy": 1.1705108001118614, "alpha_loss": -0.003608143322968057, "alpha_value": 0.0512277193813856, "duration": 25.469176530838013, "step": 27125}
{"episode_reward": 342.4246576010142, "episode": 218.0, "batch_reward": 1.7644485750198364, "critic_loss": 5.654610002517701, "actor_loss": -140.7224852038968, "actor_target_entropy": -6.0, "actor_entropy": 1.0691692011971627, "alpha_loss": -0.0052728807298286304, "alpha_value": 0.051265598986626505, "duration": 25.506179809570312, "step": 27250}
{"episode_reward": 384.88063691106663, "episode": 219.0, "batch_reward": 1.7777559099197389, "critic_loss": 5.415725086212158, "actor_loss": -141.74721950954861, "actor_target_entropy": -6.0, "actor_entropy": 1.1198534804677207, "alpha_loss": -0.0038872338528375306, "alpha_value": 0.05134796785817132, "duration": 25.53812313079834, "step": 27375}
{"episode_reward": 368.477372028172, "episode": 220.0, "batch_reward": 1.7806979389190674, "critic_loss": 5.769473789215088, "actor_loss": -141.78800102972215, "actor_target_entropy": -6.0, "actor_entropy": 1.2256439424330188, "alpha_loss": -0.004319775256238157, "alpha_value": 0.051426776978024016, "duration": 25.498246669769287, "step": 27500}
{"episode_reward": 304.7306715302127, "episode": 221.0, "batch_reward": 1.7881814918518066, "critic_loss": 5.507923427581787, "actor_loss": -142.79359072730654, "actor_target_entropy": -6.0, "actor_entropy": 1.1082430283228557, "alpha_loss": -0.003221870847194204, "alpha_value": 0.05149802023671036, "duration": 35.74055337905884, "step": 27625}
{"episode_reward": 335.40357167869763, "episode": 222.0, "batch_reward": 1.7867338428497315, "critic_loss": 5.493901027679444, "actor_loss": -143.09266908707158, "actor_target_entropy": -6.0, "actor_entropy": 1.1815038208038575, "alpha_loss": -0.0013817702833142493, "alpha_value": 0.05151783162145847, "duration": 39.690863609313965, "step": 27750}
{"episode_reward": 350.74766244336183, "episode": 223.0, "batch_reward": 1.7902471752166749, "critic_loss": 6.065622434616089, "actor_loss": -144.11668856181797, "actor_target_entropy": -6.0, "actor_entropy": 1.0708356395600334, "alpha_loss": -0.006682578496457566, "alpha_value": 0.05160981024603512, "duration": 37.58555865287781, "step": 27875}
{"episode_reward": 254.1007404256055, "episode": 224.0, "batch_reward": 1.7908830881118774, "critic_loss": 6.780743583679199, "actor_loss": -144.1313968781502, "actor_target_entropy": -6.0, "actor_entropy": 1.1661646443028604, "alpha_loss": -0.004042026652548943, "alpha_value": 0.051716538057597995, "duration": 50.735907793045044, "step": 28000}
{"episode_reward": 90.18058079859813, "episode": 225.0, "batch_reward": 1.796656707763672, "critic_loss": 6.763389698028565, "actor_loss": -144.45499262734066, "actor_target_entropy": -6.0, "actor_entropy": 1.1606517481425451, "alpha_loss": -0.0025262811160202893, "alpha_value": 0.051780672033695026, "duration": 31.792964458465576, "step": 28125}
{"episode_reward": 384.3794485510844, "episode": 226.0, "batch_reward": 1.7905200271606445, "critic_loss": 6.352939559936523, "actor_loss": -145.12330898161858, "actor_target_entropy": -6.0, "actor_entropy": 1.1701777356286203, "alpha_loss": -0.006175392401224423, "alpha_value": 0.05182340797558827, "duration": 77.79404425621033, "step": 28250}
{"episode_reward": 339.29316338834224, "episode": 227.0, "batch_reward": 1.8037526922225953, "critic_loss": 6.439554988861084, "actor_loss": -145.76679193405877, "actor_target_entropy": -6.0, "actor_entropy": 1.14228759209315, "alpha_loss": -0.009854108117343415, "alpha_value": 0.051984725775492395, "duration": 53.65992856025696, "step": 28375}
{"episode_reward": 363.6213230100354, "episode": 228.0, "batch_reward": 1.793425353050232, "critic_loss": 5.957713733673096, "actor_loss": -145.47406498078377, "actor_target_entropy": -6.0, "actor_entropy": 1.2670378636929296, "alpha_loss": 0.00010049334847398342, "alpha_value": 0.05208869626013552, "duration": 54.51532506942749, "step": 28500}
{"episode_reward": 360.36959048605553, "episode": 229.0, "batch_reward": 1.8031199922561645, "critic_loss": 6.040974357604981, "actor_loss": -146.59412153940352, "actor_target_entropy": -6.0, "actor_entropy": 1.2619203593995836, "alpha_loss": -0.004493770838182952, "alpha_value": 0.052096177446256, "duration": 46.582035064697266, "step": 28625}
{"episode_reward": 360.6120009626788, "episode": 230.0, "batch_reward": 1.8106217288970947, "critic_loss": 6.276418193817139, "actor_loss": -146.94183866439326, "actor_target_entropy": -6.0, "actor_entropy": 1.1327292303885184, "alpha_loss": -0.0001030263806422872, "alpha_value": 0.052175185845785524, "duration": 25.57099723815918, "step": 28750}
{"episode_reward": 303.4408721674544, "episode": 231.0, "batch_reward": 1.8112284336090088, "critic_loss": 6.782399076461792, "actor_loss": -147.51312449621776, "actor_target_entropy": -6.0, "actor_entropy": 1.2164490771672083, "alpha_loss": -0.001179869630418363, "alpha_value": 0.052172684376198035, "duration": 25.612728118896484, "step": 28875}
{"episode_reward": 313.75925695469397, "episode": 232.0, "batch_reward": 1.8213138389587402, "critic_loss": 6.827251209259034, "actor_loss": -148.39932275587512, "actor_target_entropy": -6.0, "actor_entropy": 1.2497534319277732, "alpha_loss": -0.00412081221058484, "alpha_value": 0.05220798710025115, "duration": 25.543994426727295, "step": 29000}
{"episode_reward": 347.377367469616, "episode": 233.0, "batch_reward": 1.8167613410949708, "critic_loss": 6.924474096298217, "actor_loss": -148.84430125403026, "actor_target_entropy": -6.0, "actor_entropy": 1.2728215143794106, "alpha_loss": -0.004628126779275518, "alpha_value": 0.05233392558881449, "duration": 25.66452121734619, "step": 29125}
{"episode_reward": 396.70236786673166, "episode": 234.0, "batch_reward": 1.823937171936035, "critic_loss": 6.567971061706543, "actor_loss": -149.69461256457913, "actor_target_entropy": -6.0, "actor_entropy": 1.2679765820503235, "alpha_loss": -0.0056487983017559015, "alpha_value": 0.05241891059630981, "duration": 25.583688735961914, "step": 29250}
{"episode_reward": 291.31071036701076, "episode": 235.0, "batch_reward": 1.8232389097213746, "critic_loss": 6.460092554092407, "actor_loss": -149.7484404548766, "actor_target_entropy": -6.0, "actor_entropy": 1.1970255147843134, "alpha_loss": -0.005647246086496919, "alpha_value": 0.052558609891145275, "duration": 25.63350009918213, "step": 29375}
{"episode_reward": 346.9055553395173, "episode": 236.0, "batch_reward": 1.8323687238693238, "critic_loss": 6.198368045806885, "actor_loss": -150.60349839733493, "actor_target_entropy": -6.0, "actor_entropy": 1.1332761510725944, "alpha_loss": -0.003406625878508954, "alpha_value": 0.052614785209714805, "duration": 25.602153301239014, "step": 29500}
{"episode_reward": 387.18934600897495, "episode": 237.0, "batch_reward": 1.8316926612854003, "critic_loss": 6.573087299346924, "actor_loss": -150.8577597481864, "actor_target_entropy": -6.0, "actor_entropy": 1.2883772632432362, "alpha_loss": -0.003464857005469856, "alpha_value": 0.05269989089253087, "duration": 25.657858848571777, "step": 29625}
{"episode_reward": 375.7686832464659, "episode": 238.0, "batch_reward": 1.838463791847229, "critic_loss": 6.141818855285645, "actor_loss": -151.60731727846206, "actor_target_entropy": -6.0, "actor_entropy": 1.2157571911811829, "alpha_loss": -0.005784213789851374, "alpha_value": 0.05278991150914372, "duration": 25.54625654220581, "step": 29750}
{"episode_reward": 356.609530575315, "episode": 239.0, "batch_reward": 1.8530692586898803, "critic_loss": 6.0075361366271975, "actor_loss": -152.59065924750433, "actor_target_entropy": -6.0, "actor_entropy": 1.3086325601925926, "alpha_loss": -0.007752319295254964, "alpha_value": 0.05295912006768665, "duration": 25.611490726470947, "step": 29875}
{"episode_reward": 363.2892961668284, "episode": 240.0, "batch_reward": 1.8551905841827392, "critic_loss": 5.746185098648072, "actor_loss": -152.59673875378024, "actor_target_entropy": -6.0, "actor_entropy": 1.1947013062815512, "alpha_loss": -0.0008719142436260177, "alpha_value": 0.05300915743272548, "step": 30000}
{"duration": 36.43577265739441, "step": 30000}
{"episode_reward": 361.4972679386584, "episode": 241.0, "batch_reward": 1.8576270751953126, "critic_loss": 5.896242872238159, "actor_loss": -152.9721202547588, "actor_target_entropy": -6.0, "actor_entropy": 1.2863869004779391, "alpha_loss": -0.004344962030974409, "alpha_value": 0.05310395425768327, "duration": 25.62671136856079, "step": 30125}
{"episode_reward": 364.98201135599584, "episode": 242.0, "batch_reward": 1.8587769203186035, "critic_loss": 6.329508359909058, "actor_loss": -153.4087627780053, "actor_target_entropy": -6.0, "actor_entropy": 1.1993422325580352, "alpha_loss": -0.0031071140077866375, "alpha_value": 0.053153350641236746, "duration": 25.57133936882019, "step": 30250}
{"episode_reward": 280.43560691992855, "episode": 243.0, "batch_reward": 1.8649390535354615, "critic_loss": 6.070325050354004, "actor_loss": -154.736323765346, "actor_target_entropy": -6.0, "actor_entropy": 1.2665629121992323, "alpha_loss": -0.005270217260759737, "alpha_value": 0.05325754626014293, "duration": 25.650590658187866, "step": 30375}
{"episode_reward": 350.63486229278794, "episode": 244.0, "batch_reward": 1.859770097732544, "critic_loss": 5.8052564868927, "actor_loss": -155.01995160502773, "actor_target_entropy": -6.0, "actor_entropy": 1.2202823402420166, "alpha_loss": -0.005014963318488651, "alpha_value": 0.05334654739241488, "duration": 25.549690008163452, "step": 30500}
{"episode_reward": 320.7097313754866, "episode": 245.0, "batch_reward": 1.8755527515411377, "critic_loss": 5.547456771850586, "actor_loss": -155.74100627596417, "actor_target_entropy": -6.0, "actor_entropy": 1.1696695988140409, "alpha_loss": -0.0029495287767892318, "alpha_value": 0.05343693893550935, "duration": 25.63546586036682, "step": 30625}
{"episode_reward": 390.73690214748297, "episode": 246.0, "batch_reward": 1.8738841648101807, "critic_loss": 5.576885812759399, "actor_loss": -155.87392080983807, "actor_target_entropy": -6.0, "actor_entropy": 1.1433231840210576, "alpha_loss": -0.00208406085749307, "alpha_value": 0.053522324391577475, "duration": 25.546624660491943, "step": 30750}
{"episode_reward": 369.2054834892471, "episode": 247.0, "batch_reward": 1.8752672910690307, "critic_loss": 5.202096366882325, "actor_loss": -156.70608883812315, "actor_target_entropy": -6.0, "actor_entropy": 1.0967995373029558, "alpha_loss": -0.009080713479927489, "alpha_value": 0.053624152653330634, "duration": 25.565467357635498, "step": 30875}
{"episode_reward": 384.0327707126242, "episode": 248.0, "batch_reward": 1.8966555519104005, "critic_loss": 5.316491992950439, "actor_loss": -157.3619630875126, "actor_target_entropy": -6.0, "actor_entropy": 1.1611076651080963, "alpha_loss": -0.0070634138500017506, "alpha_value": 0.05382800427198502, "duration": 25.53034257888794, "step": 31000}
{"episode_reward": 390.3104700077803, "episode": 249.0, "batch_reward": 1.8909084939956664, "critic_loss": 5.268211881637574, "actor_loss": -157.55695548890128, "actor_target_entropy": -6.0, "actor_entropy": 1.143764281083667, "alpha_loss": -0.008591848418175702, "alpha_value": 0.054007308434153176, "duration": 25.584958791732788, "step": 31125}
{"episode_reward": 341.7351085049777, "episode": 250.0, "batch_reward": 1.8895419750213622, "critic_loss": 5.171875726699829, "actor_loss": -158.1735807849515, "actor_target_entropy": -6.0, "actor_entropy": 1.2117088542830559, "alpha_loss": -0.006828370673071233, "alpha_value": 0.0541437956167299, "duration": 25.569348573684692, "step": 31250}
{"episode_reward": 375.8594340150346, "episode": 251.0, "batch_reward": 1.9041060161590577, "critic_loss": 5.30486393737793, "actor_loss": -158.64070226275732, "actor_target_entropy": -6.0, "actor_entropy": 1.2263369541319589, "alpha_loss": -0.007779644750472572, "alpha_value": 0.05435607406621437, "duration": 25.64236855506897, "step": 31375}
{"episode_reward": 399.71108079505046, "episode": 252.0, "batch_reward": 1.9055894832611084, "critic_loss": 5.705144529342651, "actor_loss": -159.28680592198526, "actor_target_entropy": -6.0, "actor_entropy": 1.1372771157372383, "alpha_loss": -0.0019184234833735372, "alpha_value": 0.054420414701625563, "duration": 25.52326464653015, "step": 31500}
{"episode_reward": 414.1241024319624, "episode": 253.0, "batch_reward": 1.9089416246414184, "critic_loss": 5.373441246032715, "actor_loss": -159.70736549014137, "actor_target_entropy": -6.0, "actor_entropy": 1.152555837517693, "alpha_loss": -0.0101720751078415, "alpha_value": 0.054530530608623146, "duration": 25.63388442993164, "step": 31625}
{"episode_reward": 319.1906673846868, "episode": 254.0, "batch_reward": 1.906969560623169, "critic_loss": 5.586752075195313, "actor_loss": -160.08457577613092, "actor_target_entropy": -6.0, "actor_entropy": 1.1406117100869455, "alpha_loss": -0.004857020191622958, "alpha_value": 0.054740830225057435, "duration": 25.558866024017334, "step": 31750}
{"episode_reward": 263.8077768789799, "episode": 255.0, "batch_reward": 1.9132794122695922, "critic_loss": 5.5644261856079105, "actor_loss": -160.39179532490078, "actor_target_entropy": -6.0, "actor_entropy": 1.1664752941282968, "alpha_loss": -0.004231439666852119, "alpha_value": 0.054868978597674645, "duration": 25.62600016593933, "step": 31875}
{"episode_reward": 400.30663129087804, "episode": 256.0, "batch_reward": 1.9169326772689819, "critic_loss": 5.467133474349976, "actor_loss": -161.33531459685295, "actor_target_entropy": -6.0, "actor_entropy": 1.089981994801952, "alpha_loss": -0.005547365376485452, "alpha_value": 0.05497219434896316, "duration": 25.576749324798584, "step": 32000}
{"episode_reward": 382.9868455978691, "episode": 257.0, "batch_reward": 1.9190371952056884, "critic_loss": 5.52476784324646, "actor_loss": -161.22144208635603, "actor_target_entropy": -6.0, "actor_entropy": 1.170647228521014, "alpha_loss": -0.008042157134262934, "alpha_value": 0.05510532305350576, "duration": 25.63084626197815, "step": 32125}
{"episode_reward": 351.7376705889721, "episode": 258.0, "batch_reward": 1.9305552377700805, "critic_loss": 5.505462949752808, "actor_loss": -161.9012180451424, "actor_target_entropy": -6.0, "actor_entropy": 1.2166784463390228, "alpha_loss": 0.0011686662234546197, "alpha_value": 0.055185500106929145, "duration": 25.659562349319458, "step": 32250}
{"episode_reward": 392.07599860523396, "episode": 259.0, "batch_reward": 1.9267884435653686, "critic_loss": 5.910258165359497, "actor_loss": -162.73509797595796, "actor_target_entropy": -6.0, "actor_entropy": 1.223921051101079, "alpha_loss": -0.002197439370248171, "alpha_value": 0.05524592074656391, "duration": 25.627670764923096, "step": 32375}
{"episode_reward": 253.0002758152706, "episode": 260.0, "batch_reward": 1.923457244873047, "critic_loss": 6.153695520401001, "actor_loss": -162.83821376677483, "actor_target_entropy": -6.0, "actor_entropy": 1.1266141168532833, "alpha_loss": 0.0029365448619148903, "alpha_value": 0.055193528472448426, "duration": 25.546584129333496, "step": 32500}
{"episode_reward": 396.2557024302902, "episode": 261.0, "batch_reward": 1.926583249092102, "critic_loss": 5.9478219089508055, "actor_loss": -163.51993597121466, "actor_target_entropy": -6.0, "actor_entropy": 1.1293356267232744, "alpha_loss": -0.005771621348454602, "alpha_value": 0.055279592630798915, "duration": 25.62579655647278, "step": 32625}
{"episode_reward": 394.7678576635313, "episode": 262.0, "batch_reward": 1.9405360097885131, "critic_loss": 5.664342046737671, "actor_loss": -164.62083705779045, "actor_target_entropy": -6.0, "actor_entropy": 1.162515708515721, "alpha_loss": -0.006021080435358829, "alpha_value": 0.05542709571208511, "duration": 25.589077711105347, "step": 32750}
{"episode_reward": 415.8749315221532, "episode": 263.0, "batch_reward": 1.9445294094085694, "critic_loss": 5.550228698730469, "actor_loss": -164.4160626123822, "actor_target_entropy": -6.0, "actor_entropy": 1.1203001226697649, "alpha_loss": -0.004295451644187172, "alpha_value": 0.05551124714433292, "duration": 25.619152307510376, "step": 32875}
{"episode_reward": 399.3306131140214, "episode": 264.0, "batch_reward": 1.9516006450653076, "critic_loss": 6.089681785583496, "actor_loss": -165.31414942587577, "actor_target_entropy": -6.0, "actor_entropy": 1.0314600092749442, "alpha_loss": -0.006837801429473104, "alpha_value": 0.05561256653039383, "duration": 25.5269877910614, "step": 33000}
{"episode_reward": 413.91300743501284, "episode": 265.0, "batch_reward": 1.9452770023345947, "critic_loss": 5.662193351745605, "actor_loss": -165.37310209728423, "actor_target_entropy": -6.0, "actor_entropy": 1.1184812878805495, "alpha_loss": -0.007573610992126521, "alpha_value": 0.05577897149530822, "duration": 25.612571239471436, "step": 33125}
{"episode_reward": 405.2107425761559, "episode": 266.0, "batch_reward": 1.9609041423797609, "critic_loss": 5.920145309448242, "actor_loss": -166.48428836945564, "actor_target_entropy": -6.0, "actor_entropy": 1.097594061205464, "alpha_loss": -0.011970416338543498, "alpha_value": 0.056036570331167955, "duration": 25.536696434020996, "step": 33250}
{"episode_reward": 332.0902677906799, "episode": 267.0, "batch_reward": 1.9548053035736084, "critic_loss": 5.8755895614624025, "actor_loss": -166.79902188740078, "actor_target_entropy": -6.0, "actor_entropy": 1.1219174625381592, "alpha_loss": -0.006702195091675672, "alpha_value": 0.056243546466206905, "duration": 25.602272510528564, "step": 33375}
{"episode_reward": 386.63286542281986, "episode": 268.0, "batch_reward": 1.9719180097579956, "critic_loss": 5.646667650222779, "actor_loss": -167.33860680364793, "actor_target_entropy": -6.0, "actor_entropy": 1.3104922559953505, "alpha_loss": -0.004152978950690838, "alpha_value": 0.056338927201549586, "duration": 25.53199315071106, "step": 33500}
{"episode_reward": 387.3735172541591, "episode": 269.0, "batch_reward": 1.9687572689056396, "critic_loss": 5.177549652099609, "actor_loss": -167.63792685856896, "actor_target_entropy": -6.0, "actor_entropy": 1.1686731397159515, "alpha_loss": -0.0060559866399252935, "alpha_value": 0.05651959844701654, "duration": 25.610945224761963, "step": 33625}
{"episode_reward": 412.5796064576019, "episode": 270.0, "batch_reward": 1.9781090269088746, "critic_loss": 5.393988733291626, "actor_loss": -168.23899816697644, "actor_target_entropy": -6.0, "actor_entropy": 1.2222367265532095, "alpha_loss": -0.00563200039511186, "alpha_value": 0.05660791665788, "duration": 25.568710327148438, "step": 33750}
{"episode_reward": 381.13658395680505, "episode": 271.0, "batch_reward": 1.9771756324768066, "critic_loss": 5.292029935836792, "actor_loss": -168.5897962782118, "actor_target_entropy": -6.0, "actor_entropy": 1.2687690324253507, "alpha_loss": -0.010294561558920477, "alpha_value": 0.05681895521057709, "duration": 25.605302333831787, "step": 33875}
{"episode_reward": 398.1567113665048, "episode": 272.0, "batch_reward": 1.9861936626434327, "critic_loss": 5.24605810546875, "actor_loss": -169.40882061373802, "actor_target_entropy": -6.0, "actor_entropy": 1.2584567435326115, "alpha_loss": -0.0046139389704612475, "alpha_value": 0.057011006245421825, "duration": 25.537113666534424, "step": 34000}
{"episode_reward": 317.4054082620054, "episode": 273.0, "batch_reward": 1.9869940357208251, "critic_loss": 5.480290508270263, "actor_loss": -169.8360823373946, "actor_target_entropy": -6.0, "actor_entropy": 1.2162589638952226, "alpha_loss": -0.004974317836708256, "alpha_value": 0.0571059660982261, "duration": 25.595541954040527, "step": 34125}
{"episode_reward": 403.26835400647747, "episode": 274.0, "batch_reward": 1.992557897567749, "critic_loss": 5.2830912876129155, "actor_loss": -170.54413383237778, "actor_target_entropy": -6.0, "actor_entropy": 1.22941808162197, "alpha_loss": -0.002519156699324207, "alpha_value": 0.057172627314207504, "duration": 25.576120615005493, "step": 34250}
{"episode_reward": 361.0437891824425, "episode": 275.0, "batch_reward": 1.9915751819610596, "critic_loss": 5.493025676727295, "actor_loss": -171.14422849624876, "actor_target_entropy": -6.0, "actor_entropy": 1.24452034821586, "alpha_loss": -0.0074504051830560445, "alpha_value": 0.05732152146928185, "duration": 25.59480595588684, "step": 34375}
{"episode_reward": 348.76035954395235, "episode": 276.0, "batch_reward": 1.9929658555984497, "critic_loss": 5.452357091903687, "actor_loss": -171.4458928262034, "actor_target_entropy": -6.0, "actor_entropy": 1.180136707521254, "alpha_loss": -0.0016119846334350446, "alpha_value": 0.05744750052244638, "duration": 25.58644723892212, "step": 34500}
{"episode_reward": 401.59232343478976, "episode": 277.0, "batch_reward": 1.9979992265701294, "critic_loss": 5.675737365722656, "actor_loss": -171.52798534574964, "actor_target_entropy": -6.0, "actor_entropy": 1.1403589863625785, "alpha_loss": -0.0027188052541561544, "alpha_value": 0.05746152524944975, "duration": 25.63750720024109, "step": 34625}
{"episode_reward": 392.3859957060737, "episode": 278.0, "batch_reward": 2.0035400228500366, "critic_loss": 5.3907301807403565, "actor_loss": -172.34157119258757, "actor_target_entropy": -6.0, "actor_entropy": 1.1527133151408164, "alpha_loss": -0.005553573116494883, "alpha_value": 0.057583204743159984, "duration": 25.558486700057983, "step": 34750}
{"episode_reward": 364.84270731342366, "episode": 279.0, "batch_reward": 2.004150272369385, "critic_loss": 5.507978986740112, "actor_loss": -172.53738790845114, "actor_target_entropy": -6.0, "actor_entropy": 1.1868925198676095, "alpha_loss": -0.004139308769640232, "alpha_value": 0.057693398230529096, "duration": 25.630407333374023, "step": 34875}
{"episode_reward": 319.12244994473883, "episode": 280.0, "batch_reward": 2.014124885559082, "critic_loss": 5.456703723907471, "actor_loss": -173.131465542701, "actor_target_entropy": -6.0, "actor_entropy": 1.2427123967678315, "alpha_loss": -0.01138797895457115, "alpha_value": 0.057878599882904315, "step": 35000}
{"duration": 36.28384304046631, "step": 35000}
{"episode_reward": 400.62575718930253, "episode": 281.0, "batch_reward": 2.0195872220993043, "critic_loss": 5.644843851089478, "actor_loss": -173.65965852283296, "actor_target_entropy": -6.0, "actor_entropy": 1.1934527101970853, "alpha_loss": -0.007813823564598957, "alpha_value": 0.058071781290447315, "duration": 25.635267972946167, "step": 35125}
{"episode_reward": 389.29339065827884, "episode": 282.0, "batch_reward": 2.0212110719680787, "critic_loss": 5.715758121490478, "actor_loss": -174.15548361501385, "actor_target_entropy": -6.0, "actor_entropy": 1.2274018747191275, "alpha_loss": -0.005957339984184551, "alpha_value": 0.0582783437212678, "duration": 25.56586241722107, "step": 35250}
{"episode_reward": 420.8676555400157, "episode": 283.0, "batch_reward": 2.023106388092041, "critic_loss": 5.813508623123169, "actor_loss": -175.22996424114893, "actor_target_entropy": -6.0, "actor_entropy": 1.280743895069001, "alpha_loss": -0.007631177869847133, "alpha_value": 0.05847998658358447, "duration": 25.655237436294556, "step": 35375}
{"episode_reward": 272.8562226357402, "episode": 284.0, "batch_reward": 2.023964838027954, "critic_loss": 5.80180027961731, "actor_loss": -175.06885971561556, "actor_target_entropy": -6.0, "actor_entropy": 1.1976468524625223, "alpha_loss": -0.0037353042993814715, "alpha_value": 0.05856735741604285, "duration": 25.62258768081665, "step": 35500}
{"episode_reward": 381.86013478471153, "episode": 285.0, "batch_reward": 2.0243672399520873, "critic_loss": 7.055214338302612, "actor_loss": -175.5779319642082, "actor_target_entropy": -6.0, "actor_entropy": 1.285065353862823, "alpha_loss": -0.008778184443520057, "alpha_value": 0.058677535745356564, "duration": 25.649817943572998, "step": 35625}
{"episode_reward": 397.4961282175678, "episode": 286.0, "batch_reward": 2.0285334625244142, "critic_loss": 6.410600713729858, "actor_loss": -176.17269282187186, "actor_target_entropy": -6.0, "actor_entropy": 1.250727355480194, "alpha_loss": -0.003901850188060874, "alpha_value": 0.05888328396943935, "duration": 25.595298767089844, "step": 35750}
{"episode_reward": 395.0797527175934, "episode": 287.0, "batch_reward": 2.030233458518982, "critic_loss": 7.494879795074463, "actor_loss": -176.90433901832216, "actor_target_entropy": -6.0, "actor_entropy": 1.1846116185188293, "alpha_loss": -0.010123216561854833, "alpha_value": 0.05906040473061718, "duration": 25.64597463607788, "step": 35875}
{"episode_reward": 384.366575372524, "episode": 288.0, "batch_reward": 2.0403038358688352, "critic_loss": 7.207377670288086, "actor_loss": -176.4358889672064, "actor_target_entropy": -6.0, "actor_entropy": 1.351947441216438, "alpha_loss": -0.0058311511548386225, "alpha_value": 0.05929358859777316, "duration": 25.561306476593018, "step": 36000}
{"episode_reward": 390.3954399036947, "episode": 289.0, "batch_reward": 2.043594304084778, "critic_loss": 7.972242809295654, "actor_loss": -177.33011784629215, "actor_target_entropy": -6.0, "actor_entropy": 1.2974506909885104, "alpha_loss": -0.012667029855831985, "alpha_value": 0.059423450388426224, "duration": 25.640925645828247, "step": 36125}
{"episode_reward": 369.26610878844554, "episode": 290.0, "batch_reward": 2.0397167205810547, "critic_loss": 7.174657669067383, "actor_loss": -177.9626184278919, "actor_target_entropy": -6.0, "actor_entropy": 1.2514184751818258, "alpha_loss": -0.01499575550007003, "alpha_value": 0.05975630791860066, "duration": 25.512855052947998, "step": 36250}
{"episode_reward": 390.0964744153208, "episode": 291.0, "batch_reward": 2.0512267417907717, "critic_loss": 6.393810335159301, "actor_loss": -178.3056890094091, "actor_target_entropy": -6.0, "actor_entropy": 1.2776421147679526, "alpha_loss": -0.013654613948708016, "alpha_value": 0.06012431114206114, "duration": 25.580387592315674, "step": 36375}
{"episode_reward": 327.9383137584104, "episode": 292.0, "batch_reward": 2.05196026802063, "critic_loss": 6.641722284317017, "actor_loss": -179.2331284553774, "actor_target_entropy": -6.0, "actor_entropy": 1.119554041854797, "alpha_loss": -0.012783504372853185, "alpha_value": 0.060395343799240386, "duration": 25.52236294746399, "step": 36500}
{"episode_reward": 387.53943427780985, "episode": 293.0, "batch_reward": 2.0590816707611084, "critic_loss": 6.5835000457763675, "actor_loss": -179.25145539783296, "actor_target_entropy": -6.0, "actor_entropy": 1.306317617022802, "alpha_loss": -0.009379134450610432, "alpha_value": 0.06067888103703268, "duration": 25.633257627487183, "step": 36625}
{"episode_reward": 298.5493237771862, "episode": 294.0, "batch_reward": 2.0587015390396117, "critic_loss": 7.077800319671631, "actor_loss": -179.6272216304656, "actor_target_entropy": -6.0, "actor_entropy": 1.338026592808385, "alpha_loss": -0.008889582597710673, "alpha_value": 0.06087435688035099, "duration": 25.5936439037323, "step": 36750}
{"episode_reward": 384.3442161622466, "episode": 295.0, "batch_reward": 2.062047904968262, "critic_loss": 6.716396858215332, "actor_loss": -180.1984405517578, "actor_target_entropy": -6.0, "actor_entropy": 1.2317125797271729, "alpha_loss": -0.0070338806318533086, "alpha_value": 0.06101627357867477, "duration": 25.62530207633972, "step": 36875}
{"episode_reward": 284.3268272107778, "episode": 296.0, "batch_reward": 2.057135475158691, "critic_loss": 6.879671800613403, "actor_loss": -180.8165809877457, "actor_target_entropy": -6.0, "actor_entropy": 1.2948880791664124, "alpha_loss": -0.010485296280333591, "alpha_value": 0.06120239976112678, "duration": 25.54179310798645, "step": 37000}
{"episode_reward": 405.6096388811327, "episode": 297.0, "batch_reward": 2.062550040245056, "critic_loss": 6.340737174987793, "actor_loss": -180.79227677602617, "actor_target_entropy": -6.0, "actor_entropy": 1.3224031083167544, "alpha_loss": -0.01134251355237904, "alpha_value": 0.06145223258269362, "duration": 25.659636735916138, "step": 37125}
{"episode_reward": 395.90533789999665, "episode": 298.0, "batch_reward": 2.0766474657058716, "critic_loss": 6.233753028869629, "actor_loss": -181.6298311295048, "actor_target_entropy": -6.0, "actor_entropy": 1.233392741410963, "alpha_loss": -0.010610858233825814, "alpha_value": 0.06175151342556439, "duration": 25.55902123451233, "step": 37250}
{"episode_reward": 348.53234608006153, "episode": 299.0, "batch_reward": 2.0761881113052367, "critic_loss": 6.2434854907989505, "actor_loss": -182.6004180908203, "actor_target_entropy": -6.0, "actor_entropy": 1.2728881429112147, "alpha_loss": -0.0065441138096272, "alpha_value": 0.06191212297195937, "duration": 25.603919982910156, "step": 37375}
{"episode_reward": 314.72829880316425, "episode": 300.0, "batch_reward": 2.069025371551514, "critic_loss": 6.9459006862640384, "actor_loss": -182.15519123692667, "actor_target_entropy": -6.0, "actor_entropy": 1.44536054518915, "alpha_loss": -0.002216518420966402, "alpha_value": 0.0620174061843118, "duration": 25.585395336151123, "step": 37500}
{"episode_reward": 385.922341340488, "episode": 301.0, "batch_reward": 2.0800187101364136, "critic_loss": 6.88638888168335, "actor_loss": -182.85789344424293, "actor_target_entropy": -6.0, "actor_entropy": 1.250264410934751, "alpha_loss": -0.010156649103876026, "alpha_value": 0.06217007743991353, "duration": 25.588892698287964, "step": 37625}
{"episode_reward": 396.4278043386056, "episode": 302.0, "batch_reward": 2.076452300071716, "critic_loss": 7.059853382110596, "actor_loss": -183.27244863202495, "actor_target_entropy": -6.0, "actor_entropy": 1.2784724975785902, "alpha_loss": -0.0008398211211897433, "alpha_value": 0.06229383069567246, "duration": 25.544132709503174, "step": 37750}
{"episode_reward": 79.39723456320844, "episode": 303.0, "batch_reward": 2.0753690147399904, "critic_loss": 6.410911825180054, "actor_loss": -183.7115979875837, "actor_target_entropy": -6.0, "actor_entropy": 1.2007424396181863, "alpha_loss": -0.0053158728110175284, "alpha_value": 0.062335086884981246, "duration": 25.63907742500305, "step": 37875}
{"episode_reward": 399.40176588734596, "episode": 304.0, "batch_reward": 2.078424584388733, "critic_loss": 6.670718576431274, "actor_loss": -184.0423076998803, "actor_target_entropy": -6.0, "actor_entropy": 1.2026507421847312, "alpha_loss": 0.0010486011282585922, "alpha_value": 0.06236049280043418, "duration": 25.53219962120056, "step": 38000}
{"episode_reward": 421.6858869434395, "episode": 305.0, "batch_reward": 2.083486922264099, "critic_loss": 6.642020973205566, "actor_loss": -184.5975535559276, "actor_target_entropy": -6.0, "actor_entropy": 1.2465316833011688, "alpha_loss": -0.01208513508373428, "alpha_value": 0.06247408999156659, "duration": 25.63494324684143, "step": 38125}
{"episode_reward": 426.71813460362927, "episode": 306.0, "batch_reward": 2.0881648359298706, "critic_loss": 6.96302991104126, "actor_loss": -184.3748779296875, "actor_target_entropy": -6.0, "actor_entropy": 1.3591005571426884, "alpha_loss": -0.008426273662236429, "alpha_value": 0.0627629607108183, "duration": 25.504711866378784, "step": 38250}
{"episode_reward": 360.91816228760536, "episode": 307.0, "batch_reward": 2.0870802145004275, "critic_loss": 6.447692947387695, "actor_loss": -185.43812149290054, "actor_target_entropy": -6.0, "actor_entropy": 1.2870244137824527, "alpha_loss": -0.010776291921040014, "alpha_value": 0.06297576055006276, "duration": 25.58160376548767, "step": 38375}
{"episode_reward": 409.5440046572711, "episode": 308.0, "batch_reward": 2.094107367515564, "critic_loss": 7.455175289154052, "actor_loss": -185.9964390416299, "actor_target_entropy": -6.0, "actor_entropy": 1.3199629120288356, "alpha_loss": -5.9791806814891674e-05, "alpha_value": 0.06305069283267557, "duration": 25.50074052810669, "step": 38500}
{"episode_reward": 409.2975758406568, "episode": 309.0, "batch_reward": 2.106030532836914, "critic_loss": 7.329572933197022, "actor_loss": -186.68406701466395, "actor_target_entropy": -6.0, "actor_entropy": 1.2205812353936454, "alpha_loss": -0.00747718575543591, "alpha_value": 0.06313151199424429, "duration": 25.578055143356323, "step": 38625}
{"episode_reward": 291.4861349687302, "episode": 310.0, "batch_reward": 2.0992787170410154, "critic_loss": 6.868023654937744, "actor_loss": -186.3334505634923, "actor_target_entropy": -6.0, "actor_entropy": 1.3447067372260555, "alpha_loss": -0.005824963321849223, "alpha_value": 0.06331281445856798, "duration": 25.507880210876465, "step": 38750}
{"episode_reward": 349.1490220964408, "episode": 311.0, "batch_reward": 2.0948473863601684, "critic_loss": 7.305544120788574, "actor_loss": -186.45856681702628, "actor_target_entropy": -6.0, "actor_entropy": 1.3134166286105202, "alpha_loss": -0.003959595348634239, "alpha_value": 0.06343146703204224, "duration": 25.582544803619385, "step": 38875}
{"episode_reward": 423.913012553939, "episode": 312.0, "batch_reward": 2.0996028747558593, "critic_loss": 7.779580181121826, "actor_loss": -186.93211832354146, "actor_target_entropy": -6.0, "actor_entropy": 1.36405120838073, "alpha_loss": -0.005336253717917228, "alpha_value": 0.06353153860954802, "duration": 25.515275955200195, "step": 39000}
{"episode_reward": 409.5536275305213, "episode": 313.0, "batch_reward": 2.1017315673828123, "critic_loss": 8.079218215942383, "actor_loss": -187.60489424448164, "actor_target_entropy": -6.0, "actor_entropy": 1.294633426363506, "alpha_loss": -0.008811981404303677, "alpha_value": 0.0637372017013613, "duration": 25.5979061126709, "step": 39125}
{"episode_reward": 351.96782570362376, "episode": 314.0, "batch_reward": 2.1154261837005617, "critic_loss": 7.909124919891357, "actor_loss": -188.0847898913968, "actor_target_entropy": -6.0, "actor_entropy": 1.2489460716324468, "alpha_loss": -0.003492335259403673, "alpha_value": 0.06381181416188941, "duration": 25.489712953567505, "step": 39250}
{"episode_reward": 410.41037663851694, "episode": 315.0, "batch_reward": 2.1112052574157714, "critic_loss": 8.057038475036622, "actor_loss": -188.35407220749627, "actor_target_entropy": -6.0, "actor_entropy": 1.3829787477614388, "alpha_loss": 0.0015504627067240932, "alpha_value": 0.06386646940173621, "duration": 25.59850311279297, "step": 39375}
{"episode_reward": 421.24992588530904, "episode": 316.0, "batch_reward": 2.1165732135772704, "critic_loss": 8.381501079559326, "actor_loss": -189.18014157202936, "actor_target_entropy": -6.0, "actor_entropy": 1.1689900332881558, "alpha_loss": -0.00968852425332091, "alpha_value": 0.0639461669169942, "duration": 25.508016347885132, "step": 39500}
{"episode_reward": 302.96606137558837, "episode": 317.0, "batch_reward": 2.122984712600708, "critic_loss": 7.655858215332032, "actor_loss": -189.4354005843874, "actor_target_entropy": -6.0, "actor_entropy": 1.1767205312138511, "alpha_loss": -0.002880265067760197, "alpha_value": 0.06409590449679411, "duration": 25.571215867996216, "step": 39625}
{"episode_reward": 389.9450504188216, "episode": 318.0, "batch_reward": 2.1336005334854127, "critic_loss": 8.011563953399659, "actor_loss": -189.90064190280052, "actor_target_entropy": -6.0, "actor_entropy": 1.1612854225020255, "alpha_loss": -0.007953862993857794, "alpha_value": 0.06424307702267322, "duration": 25.482346534729004, "step": 39750}
{"episode_reward": 401.8565728366096, "episode": 319.0, "batch_reward": 2.1183027992248533, "critic_loss": 8.006925582885742, "actor_loss": -189.68481978159102, "actor_target_entropy": -6.0, "actor_entropy": 1.3182804962945363, "alpha_loss": -0.00431928041923259, "alpha_value": 0.0643874586761077, "duration": 25.5669207572937, "step": 39875}
{"episode_reward": 368.5197287804733, "episode": 320.0, "batch_reward": 2.129796661376953, "critic_loss": 7.848696468353271, "actor_loss": -189.95013009348224, "actor_target_entropy": -6.0, "actor_entropy": 1.2561074456860941, "alpha_loss": -0.006812412734894502, "alpha_value": 0.06451013816580804, "step": 40000}
{"duration": 47.146037101745605, "step": 40000}
{"episode_reward": 383.0974793578244, "episode": 321.0, "batch_reward": 2.131326324462891, "critic_loss": 7.463489265441894, "actor_loss": -191.04066055540054, "actor_target_entropy": -6.0, "actor_entropy": 1.1704523780989269, "alpha_loss": -0.00785264644091801, "alpha_value": 0.06468218744309151, "duration": 38.5702428817749, "step": 40125}
{"episode_reward": 377.34860145904787, "episode": 322.0, "batch_reward": 2.129106304168701, "critic_loss": 8.119119243621826, "actor_loss": -191.4481737690587, "actor_target_entropy": -6.0, "actor_entropy": 1.172375911666501, "alpha_loss": -0.004204599821429339, "alpha_value": 0.06485164587690646, "duration": 26.756670236587524, "step": 40250}
{"episode_reward": 366.97488731856055, "episode": 323.0, "batch_reward": 2.1336810035705565, "critic_loss": 8.680162467956542, "actor_loss": -191.78872535342262, "actor_target_entropy": -6.0, "actor_entropy": 1.346144697968922, "alpha_loss": -0.007579462022505819, "alpha_value": 0.06494030931852027, "duration": 43.575456857681274, "step": 40375}
{"episode_reward": 365.86054488984274, "episode": 324.0, "batch_reward": 2.1262616930007936, "critic_loss": 8.057171222686767, "actor_loss": -191.83065082180886, "actor_target_entropy": -6.0, "actor_entropy": 1.242469036771405, "alpha_loss": -0.003924519439498263, "alpha_value": 0.06512752318446312, "duration": 37.74605751037598, "step": 40500}
{"episode_reward": 425.1364720964962, "episode": 325.0, "batch_reward": 2.138852607727051, "critic_loss": 8.315859436035156, "actor_loss": -192.2932351733011, "actor_target_entropy": -6.0, "actor_entropy": 1.252872213484749, "alpha_loss": -0.015768409229903704, "alpha_value": 0.06533362624175625, "duration": 49.87660098075867, "step": 40625}
{"episode_reward": 379.84945546142546, "episode": 326.0, "batch_reward": 2.1400029706954955, "critic_loss": 7.8096515045166015, "actor_loss": -193.0901572935043, "actor_target_entropy": -6.0, "actor_entropy": 1.1780725919431256, "alpha_loss": -0.01247303737627883, "alpha_value": 0.06569373529488909, "duration": 38.9029586315155, "step": 40750}
{"episode_reward": 405.1733679837885, "episode": 327.0, "batch_reward": 2.1413249216079713, "critic_loss": 7.418282005310059, "actor_loss": -192.74707975841704, "actor_target_entropy": -6.0, "actor_entropy": 1.2084431411728027, "alpha_loss": -0.005556869969171073, "alpha_value": 0.0659543477530268, "duration": 33.84554600715637, "step": 40875}
{"episode_reward": 444.71866742974356, "episode": 328.0, "batch_reward": 2.1561935024261474, "critic_loss": 8.081416324615478, "actor_loss": -193.6138660061744, "actor_target_entropy": -6.0, "actor_entropy": 1.3061202370351361, "alpha_loss": -0.004621891019445273, "alpha_value": 0.06600773372026543, "duration": 42.08839154243469, "step": 41000}
{"episode_reward": 381.0315790609913, "episode": 329.0, "batch_reward": 2.1579529695510864, "critic_loss": 7.753507164001465, "actor_loss": -194.0606912279886, "actor_target_entropy": -6.0, "actor_entropy": 1.2015591405686878, "alpha_loss": -0.0052195195079086315, "alpha_value": 0.0661497329169193, "duration": 25.578091621398926, "step": 41125}
{"episode_reward": 374.9142205893993, "episode": 330.0, "batch_reward": 2.157391586303711, "critic_loss": 7.125296176910401, "actor_loss": -194.94617782100553, "actor_target_entropy": -6.0, "actor_entropy": 1.1975002000408788, "alpha_loss": -0.005355702803259896, "alpha_value": 0.0662877056738334, "duration": 25.466579914093018, "step": 41250}
{"episode_reward": 397.30709408321513, "episode": 331.0, "batch_reward": 2.16138076877594, "critic_loss": 7.082559585571289, "actor_loss": -195.30130828373015, "actor_target_entropy": -6.0, "actor_entropy": 1.2810031440522935, "alpha_loss": -0.003901502475999887, "alpha_value": 0.06637853066804941, "duration": 25.545334100723267, "step": 41375}
{"episode_reward": 409.7214761348651, "episode": 332.0, "batch_reward": 2.1602622051239013, "critic_loss": 7.375091423034668, "actor_loss": -195.7311295540102, "actor_target_entropy": -6.0, "actor_entropy": 1.2263566255569458, "alpha_loss": -0.005282015524684421, "alpha_value": 0.06646089908997893, "duration": 25.488322496414185, "step": 41500}
{"episode_reward": 383.3437530484572, "episode": 333.0, "batch_reward": 2.161996376991272, "critic_loss": 7.708551143646241, "actor_loss": -195.76697237529453, "actor_target_entropy": -6.0, "actor_entropy": 1.2541018052706643, "alpha_loss": -0.0010209509895907508, "alpha_value": 0.06658288595962208, "duration": 25.542417526245117, "step": 41625}
{"episode_reward": 390.9922907037846, "episode": 334.0, "batch_reward": 2.165215784072876, "critic_loss": 7.518808143615723, "actor_loss": -196.4527346703314, "actor_target_entropy": -6.0, "actor_entropy": 1.2130227261973965, "alpha_loss": -0.007129838156904425, "alpha_value": 0.06668320980415111, "duration": 25.47016429901123, "step": 41750}
{"episode_reward": 405.6287819297201, "episode": 335.0, "batch_reward": 2.174925239562988, "critic_loss": 7.97233678817749, "actor_loss": -196.7436300610739, "actor_target_entropy": -6.0, "actor_entropy": 1.262569392484332, "alpha_loss": -0.01051064148279173, "alpha_value": 0.06688679836990426, "duration": 25.540807247161865, "step": 41875}
{"episode_reward": 428.8427113112312, "episode": 336.0, "batch_reward": 2.184493885040283, "critic_loss": 7.263909601211548, "actor_loss": -197.1589055215159, "actor_target_entropy": -6.0, "actor_entropy": 1.2840648062767521, "alpha_loss": -0.003962037574139333, "alpha_value": 0.06706251514791224, "duration": 25.45925521850586, "step": 42000}
{"episode_reward": 414.29734744668787, "episode": 337.0, "batch_reward": 2.181442232131958, "critic_loss": 8.08713589477539, "actor_loss": -197.67088729616196, "actor_target_entropy": -6.0, "actor_entropy": 1.3532103337938823, "alpha_loss": -0.01035387878535345, "alpha_value": 0.067259429707393, "duration": 25.565577268600464, "step": 42125}
{"episode_reward": 394.81976314002236, "episode": 338.0, "batch_reward": 2.187930721282959, "critic_loss": 7.447051124572754, "actor_loss": -198.1135007796749, "actor_target_entropy": -6.0, "actor_entropy": 1.4343978743399344, "alpha_loss": -0.005953722787390072, "alpha_value": 0.06745660346411914, "duration": 25.800923824310303, "step": 42250}
{"episode_reward": 409.7078366294086, "episode": 339.0, "batch_reward": 2.1835815925598143, "critic_loss": 7.955424369812012, "actor_loss": -198.25118945893786, "actor_target_entropy": -6.0, "actor_entropy": 1.3579173655737014, "alpha_loss": -0.006057749812801679, "alpha_value": 0.0676108751764202, "duration": 25.58085536956787, "step": 42375}
{"episode_reward": 416.2435424432771, "episode": 340.0, "batch_reward": 2.1873902797698976, "critic_loss": 7.774946170806885, "actor_loss": -198.75253812728388, "actor_target_entropy": -6.0, "actor_entropy": 1.3647709748437327, "alpha_loss": -0.0036722738539890177, "alpha_value": 0.06771640515547217, "duration": 25.51806139945984, "step": 42500}
{"episode_reward": 398.414851361216, "episode": 341.0, "batch_reward": 2.1876495265960694, "critic_loss": 7.793012920379638, "actor_loss": -198.70121692475817, "actor_target_entropy": -6.0, "actor_entropy": 1.415933162447006, "alpha_loss": -0.011071282520239789, "alpha_value": 0.06790157730022287, "duration": 25.57256317138672, "step": 42625}
{"episode_reward": 361.69102151725093, "episode": 342.0, "batch_reward": 2.191859313964844, "critic_loss": 7.187542530059814, "actor_loss": -199.50352182695943, "actor_target_entropy": -6.0, "actor_entropy": 1.3040228120742305, "alpha_loss": -0.0011571916946840862, "alpha_value": 0.0680560581074473, "duration": 25.51586413383484, "step": 42750}
{"episode_reward": 442.00902112886337, "episode": 343.0, "batch_reward": 2.2014515857696533, "critic_loss": 7.162911026000977, "actor_loss": -199.65964786590092, "actor_target_entropy": -6.0, "actor_entropy": 1.3097811142603557, "alpha_loss": -0.010340708355966306, "alpha_value": 0.06817093957334805, "duration": 25.59624934196472, "step": 42875}
{"episode_reward": 407.26214869924183, "episode": 344.0, "batch_reward": 2.1986434497833254, "critic_loss": 6.673096630096436, "actor_loss": -200.47726661928237, "actor_target_entropy": -6.0, "actor_entropy": 1.321015787701453, "alpha_loss": -0.010754130112247602, "alpha_value": 0.06844940592025271, "duration": 25.547565460205078, "step": 43000}
{"episode_reward": 437.2218741335395, "episode": 345.0, "batch_reward": 2.2109616260528564, "critic_loss": 6.8896626987457275, "actor_loss": -200.77353244357639, "actor_target_entropy": -6.0, "actor_entropy": 1.373945436780415, "alpha_loss": -0.011259223367752773, "alpha_value": 0.06877732273027694, "duration": 25.609264135360718, "step": 43125}
{"episode_reward": 400.73195235248375, "episode": 346.0, "batch_reward": 2.2117565326690674, "critic_loss": 7.286979381561279, "actor_loss": -201.21161331668978, "actor_target_entropy": -6.0, "actor_entropy": 1.4118364087996944, "alpha_loss": -0.012619870624715281, "alpha_value": 0.0690383066643738, "duration": 25.53730344772339, "step": 43250}
{"episode_reward": 401.7541751666523, "episode": 347.0, "batch_reward": 2.2101301956176758, "critic_loss": 7.270428768157959, "actor_loss": -201.90613374255952, "actor_target_entropy": -6.0, "actor_entropy": 1.4364172787893386, "alpha_loss": -0.009349469727437412, "alpha_value": 0.0693419315941903, "duration": 25.584619522094727, "step": 43375}
{"episode_reward": 400.1247176972131, "episode": 348.0, "batch_reward": 2.212319227218628, "critic_loss": 7.6644389457702635, "actor_loss": -201.8671594435169, "actor_target_entropy": -6.0, "actor_entropy": 1.4724369337481837, "alpha_loss": -0.004545564920971951, "alpha_value": 0.06947622446939575, "duration": 25.49736523628235, "step": 43500}
{"episode_reward": 322.40765590499194, "episode": 349.0, "batch_reward": 2.2181684761047364, "critic_loss": 7.686085372924805, "actor_loss": -202.21495492117745, "actor_target_entropy": -6.0, "actor_entropy": 1.4686535540081205, "alpha_loss": -0.00879384008871894, "alpha_value": 0.0696147395736989, "duration": 25.593271017074585, "step": 43625}
{"episode_reward": 376.72316856974044, "episode": 350.0, "batch_reward": 2.216949939727783, "critic_loss": 7.569353439331055, "actor_loss": -202.9053465320218, "actor_target_entropy": -6.0, "actor_entropy": 1.3868032328544124, "alpha_loss": -0.005133463591787844, "alpha_value": 0.06984012055581991, "duration": 25.594603300094604, "step": 43750}
{"episode_reward": 388.0608498035605, "episode": 351.0, "batch_reward": 2.225344192504883, "critic_loss": 6.776497386932373, "actor_loss": -203.12708464122954, "actor_target_entropy": -6.0, "actor_entropy": 1.3349300083659945, "alpha_loss": -0.002457529520763764, "alpha_value": 0.06989337747834708, "duration": 25.5959689617157, "step": 43875}
{"episode_reward": 399.7638077792771, "episode": 352.0, "batch_reward": 2.223766435623169, "critic_loss": 7.499038402557373, "actor_loss": -203.64608272429436, "actor_target_entropy": -6.0, "actor_entropy": 1.408834134378741, "alpha_loss": -0.002589910531476621, "alpha_value": 0.06997201194315975, "duration": 25.523273229599, "step": 44000}
{"episode_reward": 407.1425228807015, "episode": 353.0, "batch_reward": 2.2305604038238527, "critic_loss": 7.509800025939941, "actor_loss": -204.17918420216395, "actor_target_entropy": -6.0, "actor_entropy": 1.445277179990496, "alpha_loss": -0.0014989862868946696, "alpha_value": 0.07000661223076023, "duration": 25.576371431350708, "step": 44125}
{"episode_reward": 420.75623873213226, "episode": 354.0, "batch_reward": 2.2369561100006106, "critic_loss": 6.97283349609375, "actor_loss": -204.44531840662802, "actor_target_entropy": -6.0, "actor_entropy": 1.3894986971732108, "alpha_loss": -0.0011200558304065658, "alpha_value": 0.07005468246821771, "duration": 25.466003894805908, "step": 44250}
{"episode_reward": 379.2027729313695, "episode": 355.0, "batch_reward": 2.228641300201416, "critic_loss": 7.450128391265869, "actor_loss": -204.4901353139726, "actor_target_entropy": -6.0, "actor_entropy": 1.3855540903787764, "alpha_loss": 0.0007677442996600081, "alpha_value": 0.07001351103485508, "duration": 25.627375602722168, "step": 44375}
{"episode_reward": 437.34010291216924, "episode": 356.0, "batch_reward": 2.2279444847106933, "critic_loss": 7.028656364440918, "actor_loss": -205.04662224554247, "actor_target_entropy": -6.0, "actor_entropy": 1.4745093237969182, "alpha_loss": -0.006819973478183871, "alpha_value": 0.07014195086055687, "duration": 25.53440833091736, "step": 44500}
{"episode_reward": 416.01848367939135, "episode": 357.0, "batch_reward": 2.247021249771118, "critic_loss": 7.09049104309082, "actor_loss": -205.7074248298766, "actor_target_entropy": -6.0, "actor_entropy": 1.4147523679430523, "alpha_loss": -0.003831741791809835, "alpha_value": 0.07028206869341637, "duration": 25.598653554916382, "step": 44625}
{"episode_reward": 397.18454834532355, "episode": 358.0, "batch_reward": 2.2488626556396483, "critic_loss": 7.289635795593262, "actor_loss": -206.0254172048261, "actor_target_entropy": -6.0, "actor_entropy": 1.4089283962403574, "alpha_loss": -0.00260963213194402, "alpha_value": 0.07042035176625702, "duration": 25.58428120613098, "step": 44750}
{"episode_reward": 395.19233919740975, "episode": 359.0, "batch_reward": 2.232791313171387, "critic_loss": 7.499817180633545, "actor_loss": -206.2967727903336, "actor_target_entropy": -6.0, "actor_entropy": 1.5426639299544076, "alpha_loss": 0.0017625775968005497, "alpha_value": 0.07037186893584366, "duration": 25.59283471107483, "step": 44875}
{"episode_reward": 426.7272114720291, "episode": 360.0, "batch_reward": 2.2435089206695555, "critic_loss": 7.018931228637696, "actor_loss": -206.9295422953944, "actor_target_entropy": -6.0, "actor_entropy": 1.5010652119113552, "alpha_loss": 0.0021802749045403496, "alpha_value": 0.0702976951808357, "step": 45000}
{"duration": 36.397287368774414, "step": 45000}
{"episode_reward": 446.8772112092547, "episode": 361.0, "batch_reward": 2.250696876525879, "critic_loss": 7.6449097099304195, "actor_loss": -206.81980920216395, "actor_target_entropy": -6.0, "actor_entropy": 1.5434693779264177, "alpha_loss": -0.0016091425555743396, "alpha_value": 0.07031735712054063, "duration": 25.56959319114685, "step": 45125}
{"episode_reward": 383.51036424548, "episode": 362.0, "batch_reward": 2.2632140464782715, "critic_loss": 7.1545079193115235, "actor_loss": -207.61702309885334, "actor_target_entropy": -6.0, "actor_entropy": 1.489930239415938, "alpha_loss": -0.0020724484253855, "alpha_value": 0.07033534036701611, "duration": 25.518684148788452, "step": 45250}
{"episode_reward": 438.9439753791776, "episode": 363.0, "batch_reward": 2.2624418697357176, "critic_loss": 7.394782939910889, "actor_loss": -208.06115165589347, "actor_target_entropy": -6.0, "actor_entropy": 1.4430916233668252, "alpha_loss": -0.005248017814232125, "alpha_value": 0.07044248447019172, "duration": 25.568683862686157, "step": 45375}
{"episode_reward": 457.5518178391909, "episode": 364.0, "batch_reward": 2.2557144565582274, "critic_loss": 7.161774356842041, "actor_loss": -208.12776504024382, "actor_target_entropy": -6.0, "actor_entropy": 1.5106467277772966, "alpha_loss": -0.00020604737425944017, "alpha_value": 0.07051216786122033, "duration": 25.513561487197876, "step": 45500}
{"episode_reward": 398.22094640708093, "episode": 365.0, "batch_reward": 2.2618074436187743, "critic_loss": 6.954433149337769, "actor_loss": -208.25959995814733, "actor_target_entropy": -6.0, "actor_entropy": 1.4140934111580017, "alpha_loss": -0.005297540808983502, "alpha_value": 0.07056812919733903, "duration": 25.56706428527832, "step": 45625}
{"episode_reward": 407.94502896512347, "episode": 366.0, "batch_reward": 2.2614967441558838, "critic_loss": 6.1977063751220705, "actor_loss": -208.89283063334804, "actor_target_entropy": -6.0, "actor_entropy": 1.470650928635751, "alpha_loss": -0.003616001062665976, "alpha_value": 0.0707276012685882, "duration": 25.5514817237854, "step": 45750}
{"episode_reward": 387.0222536550518, "episode": 367.0, "batch_reward": 2.259218969345093, "critic_loss": 6.180219730377197, "actor_loss": -208.99984426347035, "actor_target_entropy": -6.0, "actor_entropy": 1.4447915856800382, "alpha_loss": 0.0019972246724166095, "alpha_value": 0.07070162417542553, "duration": 25.594327449798584, "step": 45875}
{"episode_reward": 421.98925936362957, "episode": 368.0, "batch_reward": 2.2649288406372072, "critic_loss": 6.925307945251465, "actor_loss": -209.89066757694368, "actor_target_entropy": -6.0, "actor_entropy": 1.4564684321803432, "alpha_loss": -0.005417640801639327, "alpha_value": 0.0707322472867991, "duration": 25.520121335983276, "step": 46000}
{"episode_reward": 352.85726314215333, "episode": 369.0, "batch_reward": 2.2716785717010497, "critic_loss": 6.493113082885742, "actor_loss": -210.3397955516028, "actor_target_entropy": -6.0, "actor_entropy": 1.5188052124447293, "alpha_loss": -0.004478063750346857, "alpha_value": 0.07081761772563064, "duration": 25.629835844039917, "step": 46125}
{"episode_reward": 416.5698645648474, "episode": 370.0, "batch_reward": 2.2795065269470216, "critic_loss": 6.536475549697876, "actor_loss": -210.66124454621345, "actor_target_entropy": -6.0, "actor_entropy": 1.4879453239902374, "alpha_loss": -0.0002664736351899562, "alpha_value": 0.07096481439871555, "duration": 25.57106328010559, "step": 46250}
{"episode_reward": 264.4329425463963, "episode": 371.0, "batch_reward": 2.2742758903503417, "critic_loss": 6.682577144622803, "actor_loss": -210.82113163054936, "actor_target_entropy": -6.0, "actor_entropy": 1.5489397673379808, "alpha_loss": -0.004463108740599146, "alpha_value": 0.07103864174073338, "duration": 25.58390212059021, "step": 46375}
{"episode_reward": 439.975643467528, "episode": 372.0, "batch_reward": 2.2754624347686767, "critic_loss": 6.760117612838745, "actor_loss": -210.94292942170173, "actor_target_entropy": -6.0, "actor_entropy": 1.5399996734434558, "alpha_loss": -0.002689454578719432, "alpha_value": 0.07112843026766467, "duration": 25.491870164871216, "step": 46500}
{"episode_reward": 426.8586102400116, "episode": 373.0, "batch_reward": 2.273710084915161, "critic_loss": 7.167647762298584, "actor_loss": -211.65553162589904, "actor_target_entropy": -6.0, "actor_entropy": 1.4932107471284413, "alpha_loss": 0.0036221231381955835, "alpha_value": 0.07114656832334097, "duration": 25.55532932281494, "step": 46625}
{"episode_reward": 432.2491010776314, "episode": 374.0, "batch_reward": 2.279917387008667, "critic_loss": 7.226950813293457, "actor_loss": -211.42718727357925, "actor_target_entropy": -6.0, "actor_entropy": 1.5494746315863825, "alpha_loss": -0.001338491509217889, "alpha_value": 0.07111566048461175, "duration": 25.50950288772583, "step": 46750}
{"episode_reward": 405.94224270093963, "episode": 375.0, "batch_reward": 2.294819267272949, "critic_loss": 7.410075172424317, "actor_loss": -212.17195347377233, "actor_target_entropy": -6.0, "actor_entropy": 1.4270394472848802, "alpha_loss": 0.005066465882081834, "alpha_value": 0.07103640650415055, "duration": 25.55215811729431, "step": 46875}
{"episode_reward": 415.4589956270536, "episode": 376.0, "batch_reward": 2.288067813873291, "critic_loss": 10.414937004089355, "actor_loss": -212.59135560066468, "actor_target_entropy": -6.0, "actor_entropy": 1.414942564502839, "alpha_loss": -0.007471657373131283, "alpha_value": 0.07105378757738448, "duration": 25.510915756225586, "step": 47000}
{"episode_reward": 95.65936386879106, "episode": 377.0, "batch_reward": 2.281157325744629, "critic_loss": 11.290134197235107, "actor_loss": -212.0638233971974, "actor_target_entropy": -6.0, "actor_entropy": 1.643640641182188, "alpha_loss": 0.002425165447805609, "alpha_value": 0.07105235325588516, "duration": 25.542724609375, "step": 47125}
{"episode_reward": 383.97781703606097, "episode": 378.0, "batch_reward": 2.2826744575500486, "critic_loss": 10.433360233306885, "actor_loss": -212.666751000189, "actor_target_entropy": -6.0, "actor_entropy": 1.5761605443493012, "alpha_loss": -0.0033706744584525304, "alpha_value": 0.07115945795636351, "duration": 25.48881959915161, "step": 47250}
{"episode_reward": 307.84059019988086, "episode": 379.0, "batch_reward": 2.2853593769073486, "critic_loss": 9.417078876495362, "actor_loss": -212.87604437934027, "actor_target_entropy": -6.0, "actor_entropy": 1.5737822604557825, "alpha_loss": -0.0053009595832831805, "alpha_value": 0.07127597454065199, "duration": 25.56028389930725, "step": 47375}
{"episode_reward": 341.67701590872065, "episode": 380.0, "batch_reward": 2.2948002319335936, "critic_loss": 8.433614974975585, "actor_loss": -213.54146280596333, "actor_target_entropy": -6.0, "actor_entropy": 1.5080779983151344, "alpha_loss": -0.002449586037396183, "alpha_value": 0.07137443435442543, "duration": 25.525149822235107, "step": 47500}
{"episode_reward": 427.56096338958554, "episode": 381.0, "batch_reward": 2.2869037342071534, "critic_loss": 8.134935680389404, "actor_loss": -213.5496087452722, "actor_target_entropy": -6.0, "actor_entropy": 1.5382634628386724, "alpha_loss": -0.00035430532362726, "alpha_value": 0.07136741649042885, "duration": 25.551557302474976, "step": 47625}
{"episode_reward": 301.71981549644556, "episode": 382.0, "batch_reward": 2.2925491123199464, "critic_loss": 8.222394592285156, "actor_loss": -214.0531503000567, "actor_target_entropy": -6.0, "actor_entropy": 1.5404992315077013, "alpha_loss": -0.007335745748282681, "alpha_value": 0.07144321048316256, "duration": 25.523570775985718, "step": 47750}
{"episode_reward": 424.5798340408166, "episode": 383.0, "batch_reward": 2.2906704483032225, "critic_loss": 7.738624404907227, "actor_loss": -214.50174531482514, "actor_target_entropy": -6.0, "actor_entropy": 1.5450971788830228, "alpha_loss": 0.004425703647679516, "alpha_value": 0.07157539892196917, "duration": 25.592942237854004, "step": 47875}
{"episode_reward": 441.2904293168849, "episode": 384.0, "batch_reward": 2.3000458736419676, "critic_loss": 8.30863158416748, "actor_loss": -214.16638429703252, "actor_target_entropy": -6.0, "actor_entropy": 1.4128879366382476, "alpha_loss": 0.002952892641206422, "alpha_value": 0.07140911096077633, "duration": 25.540077209472656, "step": 48000}
{"episode_reward": 416.00305656577393, "episode": 385.0, "batch_reward": 2.3009239139556885, "critic_loss": 8.537852550506592, "actor_loss": -215.00537884424602, "actor_target_entropy": -6.0, "actor_entropy": 1.4572681434570798, "alpha_loss": -0.017672009130437222, "alpha_value": 0.07161354981902829, "duration": 25.67206621170044, "step": 48125}
{"episode_reward": 400.246835628176, "episode": 386.0, "batch_reward": 2.3060897541046144, "critic_loss": 8.282033626556396, "actor_loss": -214.96461585260207, "actor_target_entropy": -6.0, "actor_entropy": 1.504697903510063, "alpha_loss": -0.0033843150407436395, "alpha_value": 0.07193957286422262, "duration": 25.53047227859497, "step": 48250}
{"episode_reward": 412.60544081982454, "episode": 387.0, "batch_reward": 2.3017841930389404, "critic_loss": 7.545500156402588, "actor_loss": -215.7075924343533, "actor_target_entropy": -6.0, "actor_entropy": 1.5072629224686396, "alpha_loss": 0.0011549134228733323, "alpha_value": 0.07194714345593514, "duration": 25.586579084396362, "step": 48375}
{"episode_reward": 363.4177288521933, "episode": 388.0, "batch_reward": 2.2994956645965576, "critic_loss": 8.362831321716309, "actor_loss": -215.40250052175213, "actor_target_entropy": -6.0, "actor_entropy": 1.3978170598706892, "alpha_loss": -0.004181280465526206, "alpha_value": 0.07200724899618319, "duration": 25.525481939315796, "step": 48500}
{"episode_reward": 438.2909250221201, "episode": 389.0, "batch_reward": 2.3109207286834716, "critic_loss": 8.326666053771973, "actor_loss": -216.59346298944382, "actor_target_entropy": -6.0, "actor_entropy": 1.5480136152297732, "alpha_loss": -0.007810492718976642, "alpha_value": 0.07209064438835386, "duration": 25.62643575668335, "step": 48625}
{"episode_reward": 322.36589685042475, "episode": 390.0, "batch_reward": 2.309160213470459, "critic_loss": 7.767823497772217, "actor_loss": -215.95292220577116, "actor_target_entropy": -6.0, "actor_entropy": 1.4668201496524196, "alpha_loss": -6.022909280633734e-05, "alpha_value": 0.07220176938188895, "duration": 25.541218519210815, "step": 48750}
{"episode_reward": 410.8950963670257, "episode": 391.0, "batch_reward": 2.3082455921173097, "critic_loss": 8.674407279968262, "actor_loss": -216.580807640439, "actor_target_entropy": -6.0, "actor_entropy": 1.4759382104116774, "alpha_loss": 0.0009140996336345635, "alpha_value": 0.07213365541130984, "duration": 25.60854482650757, "step": 48875}
{"episode_reward": 299.41898638280543, "episode": 392.0, "batch_reward": 2.3186612186431885, "critic_loss": 7.898421787261963, "actor_loss": -216.9549580235635, "actor_target_entropy": -6.0, "actor_entropy": 1.6171575323227914, "alpha_loss": -0.0005593890091404319, "alpha_value": 0.07218477934149188, "duration": 25.552592039108276, "step": 49000}
{"episode_reward": 360.19477913139764, "episode": 393.0, "batch_reward": 2.3138786010742187, "critic_loss": 7.933044055938721, "actor_loss": -217.40365091959634, "actor_target_entropy": -6.0, "actor_entropy": 1.5571698574792772, "alpha_loss": -0.003943403731913321, "alpha_value": 0.07230153524933958, "duration": 25.62970232963562, "step": 49125}
{"episode_reward": 417.42109068217076, "episode": 394.0, "batch_reward": 2.3135548324584962, "critic_loss": 8.10683108139038, "actor_loss": -217.46308972758632, "actor_target_entropy": -6.0, "actor_entropy": 1.5460644441266214, "alpha_loss": -0.006081069862815521, "alpha_value": 0.07236021094360698, "duration": 25.583573579788208, "step": 49250}
{"episode_reward": 427.8522808680855, "episode": 395.0, "batch_reward": 2.3215585422515868, "critic_loss": 8.039627876281738, "actor_loss": -217.53497823079428, "actor_target_entropy": -6.0, "actor_entropy": 1.5836474819788857, "alpha_loss": -0.0016221872102173548, "alpha_value": 0.07245741505894311, "duration": 25.58478355407715, "step": 49375}
{"episode_reward": 447.80684326806914, "episode": 396.0, "batch_reward": 2.327852104187012, "critic_loss": 7.839920738220215, "actor_loss": -218.41380063949092, "actor_target_entropy": -6.0, "actor_entropy": 1.406520003272641, "alpha_loss": -0.0070425735884195855, "alpha_value": 0.07261994486566795, "duration": 25.5458984375, "step": 49500}
{"episode_reward": 427.84863140037135, "episode": 397.0, "batch_reward": 2.3246199607849123, "critic_loss": 7.77689608001709, "actor_loss": -218.4959246923053, "actor_target_entropy": -6.0, "actor_entropy": 1.629710874860249, "alpha_loss": 0.0031181408631955347, "alpha_value": 0.07261828913476173, "duration": 25.570693731307983, "step": 49625}
{"episode_reward": 420.8307425341541, "episode": 398.0, "batch_reward": 2.3252397575378416, "critic_loss": 8.331448875427245, "actor_loss": -218.6748822119928, "actor_target_entropy": -6.0, "actor_entropy": 1.529381488600085, "alpha_loss": 0.004240827781388596, "alpha_value": 0.07256227588613266, "duration": 25.554635047912598, "step": 49750}
{"episode_reward": 278.85378504035543, "episode": 399.0, "batch_reward": 2.3262693614959717, "critic_loss": 7.56696293258667, "actor_loss": -219.14181712317088, "actor_target_entropy": -6.0, "actor_entropy": 1.4839790548597063, "alpha_loss": 0.004328869264720688, "alpha_value": 0.0724247286684903, "duration": 25.841107845306396, "step": 49875}
{"episode_reward": 431.7433912362128, "episode": 400.0, "batch_reward": 2.334921648025513, "critic_loss": 7.815047374725342, "actor_loss": -219.17936337378717, "actor_target_entropy": -6.0, "actor_entropy": 1.5463137780466387, "alpha_loss": -0.007959525634144102, "alpha_value": 0.07246824036241796, "step": 50000}
{"duration": 36.37716627120972, "step": 50000}
{"episode_reward": 420.29775259240125, "episode": 401.0, "batch_reward": 2.33282772064209, "critic_loss": 8.263732833862305, "actor_loss": -219.32990422324528, "actor_target_entropy": -6.0, "actor_entropy": 1.4780635758051797, "alpha_loss": -0.0015761620505520748, "alpha_value": 0.07262064682099482, "duration": 25.62741446495056, "step": 50125}
{"episode_reward": 408.25145006554703, "episode": 402.0, "batch_reward": 2.343513454437256, "critic_loss": 7.270048797607422, "actor_loss": -220.10471688547443, "actor_target_entropy": -6.0, "actor_entropy": 1.5192797664673097, "alpha_loss": -0.00021032825292598817, "alpha_value": 0.07262664029690562, "duration": 25.566774129867554, "step": 50250}
{"episode_reward": 413.502319212026, "episode": 403.0, "batch_reward": 2.343571912765503, "critic_loss": 8.319795959472657, "actor_loss": -220.30645751953125, "actor_target_entropy": -6.0, "actor_entropy": 1.4410534094250391, "alpha_loss": 0.0024672273550153017, "alpha_value": 0.0726218125954912, "duration": 25.605877161026, "step": 50375}
{"episode_reward": 439.2521314426704, "episode": 404.0, "batch_reward": 2.339375141143799, "critic_loss": 7.573938972473145, "actor_loss": -220.8286364155431, "actor_target_entropy": -6.0, "actor_entropy": 1.419553897073192, "alpha_loss": 0.007561951349940031, "alpha_value": 0.07246920487303202, "duration": 25.575279474258423, "step": 50500}
{"episode_reward": 433.5399150733565, "episode": 405.0, "batch_reward": 2.339627769470215, "critic_loss": 7.324499271392822, "actor_loss": -220.64163668193515, "actor_target_entropy": -6.0, "actor_entropy": 1.4422362229180714, "alpha_loss": -0.0006764722758874534, "alpha_value": 0.07234334509689475, "duration": 25.61863660812378, "step": 50625}
{"episode_reward": 411.57891310492715, "episode": 406.0, "batch_reward": 2.356895372390747, "critic_loss": 7.257146427154541, "actor_loss": -221.39739399571573, "actor_target_entropy": -6.0, "actor_entropy": 1.5142953645798467, "alpha_loss": -0.006615819184169654, "alpha_value": 0.07246876935020376, "duration": 25.569016456604004, "step": 50750}
{"episode_reward": 409.09879790174165, "episode": 407.0, "batch_reward": 2.353274501800537, "critic_loss": 7.121544628143311, "actor_loss": -222.07459949311755, "actor_target_entropy": -6.0, "actor_entropy": 1.533861862288581, "alpha_loss": -0.001018077227479172, "alpha_value": 0.07255277538448855, "duration": 25.61870551109314, "step": 50875}
{"episode_reward": 416.1318334064835, "episode": 408.0, "batch_reward": 2.346241954803467, "critic_loss": 7.307670639038086, "actor_loss": -221.81919368620842, "actor_target_entropy": -6.0, "actor_entropy": 1.5476050915256623, "alpha_loss": -0.0033258355125003764, "alpha_value": 0.07261217350101315, "duration": 25.489675998687744, "step": 51000}
{"episode_reward": 423.72128417362825, "episode": 409.0, "batch_reward": 2.3532789859771728, "critic_loss": 7.010789962768555, "actor_loss": -222.58158486986918, "actor_target_entropy": -6.0, "actor_entropy": 1.528058369954427, "alpha_loss": -0.011067158956494596, "alpha_value": 0.07277434714221517, "duration": 25.616332530975342, "step": 51125}
{"episode_reward": 427.62384917502874, "episode": 410.0, "batch_reward": 2.354859401702881, "critic_loss": 7.5224381446838375, "actor_loss": -222.55532935357863, "actor_target_entropy": -6.0, "actor_entropy": 1.5138411079683611, "alpha_loss": -0.0035396748374501665, "alpha_value": 0.07304370058628512, "duration": 25.5295672416687, "step": 51250}
{"episode_reward": 412.01421438812673, "episode": 411.0, "batch_reward": 2.3561000804901124, "critic_loss": 7.438354583740234, "actor_loss": -222.73831443181115, "actor_target_entropy": -6.0, "actor_entropy": 1.558252631671845, "alpha_loss": -0.0016844597726409871, "alpha_value": 0.07306770766787499, "duration": 25.60280203819275, "step": 51375}
{"episode_reward": 409.1916068345632, "episode": 412.0, "batch_reward": 2.3608858413696288, "critic_loss": 7.2762029838562015, "actor_loss": -222.9998072962607, "actor_target_entropy": -6.0, "actor_entropy": 1.4983130039707306, "alpha_loss": -0.001106023138779546, "alpha_value": 0.07305723903379094, "duration": 25.512454986572266, "step": 51500}
{"episode_reward": 424.31502993335647, "episode": 413.0, "batch_reward": 2.3560362091064455, "critic_loss": 7.499625392913819, "actor_loss": -223.29842776343935, "actor_target_entropy": -6.0, "actor_entropy": 1.6249486605326335, "alpha_loss": -0.007556771552781501, "alpha_value": 0.07320219297215534, "duration": 25.59977960586548, "step": 51625}
{"episode_reward": 429.58153417116415, "episode": 414.0, "batch_reward": 2.358748208999634, "critic_loss": 7.605072826385498, "actor_loss": -223.59014178860573, "actor_target_entropy": -6.0, "actor_entropy": 1.5388375097705471, "alpha_loss": 0.0001601001412998284, "alpha_value": 0.073334946862861, "duration": 25.557838678359985, "step": 51750}
{"episode_reward": 429.8523006675195, "episode": 415.0, "batch_reward": 2.371580507278442, "critic_loss": 7.256669906616211, "actor_loss": -224.04781450544084, "actor_target_entropy": -6.0, "actor_entropy": 1.5674939515098694, "alpha_loss": 0.0010937143871117207, "alpha_value": 0.0732677478723134, "duration": 25.603598594665527, "step": 51875}
{"episode_reward": 382.73853966511456, "episode": 416.0, "batch_reward": 2.3714453754425047, "critic_loss": 7.886527446746826, "actor_loss": -224.30164017215853, "actor_target_entropy": -6.0, "actor_entropy": 1.4855100877823368, "alpha_loss": 0.0014699261049709975, "alpha_value": 0.07323369914199619, "duration": 25.63368582725525, "step": 52000}
{"episode_reward": 368.47547810871424, "episode": 417.0, "batch_reward": 2.37867006111145, "critic_loss": 8.890889640808105, "actor_loss": -224.71034071180554, "actor_target_entropy": -6.0, "actor_entropy": 1.4953032164346605, "alpha_loss": -0.0024911796097599323, "alpha_value": 0.07326635504836852, "duration": 25.64346218109131, "step": 52125}
{"episode_reward": 420.6167944525871, "episode": 418.0, "batch_reward": 2.384010082244873, "critic_loss": 8.41326350402832, "actor_loss": -224.989618855138, "actor_target_entropy": -6.0, "actor_entropy": 1.5667447659277147, "alpha_loss": -0.008597969622050802, "alpha_value": 0.0734366935647637, "duration": 25.504676818847656, "step": 52250}
{"episode_reward": 460.25025666637555, "episode": 419.0, "batch_reward": 2.3839975986480715, "critic_loss": 7.830522857666016, "actor_loss": -225.6261497376457, "actor_target_entropy": -6.0, "actor_entropy": 1.5536444300696963, "alpha_loss": -0.001911757016805784, "alpha_value": 0.07353760707630812, "duration": 25.63486075401306, "step": 52375}
{"episode_reward": 444.4255228884844, "episode": 420.0, "batch_reward": 2.3759150619506837, "critic_loss": 9.040154296875, "actor_loss": -225.3791068292433, "actor_target_entropy": -6.0, "actor_entropy": 1.5846244019846762, "alpha_loss": -0.001547151049899478, "alpha_value": 0.07362167413085415, "duration": 25.578999757766724, "step": 52500}
{"episode_reward": 452.9133989646381, "episode": 421.0, "batch_reward": 2.378075010299683, "critic_loss": 8.626813144683839, "actor_loss": -225.48601568312873, "actor_target_entropy": -6.0, "actor_entropy": 1.4796598657729134, "alpha_loss": -0.0024093628365782992, "alpha_value": 0.07361194894858894, "duration": 25.640650987625122, "step": 52625}
{"episode_reward": 233.96373635930368, "episode": 422.0, "batch_reward": 2.374982433319092, "critic_loss": 9.436666744232177, "actor_loss": -225.9185050226027, "actor_target_entropy": -6.0, "actor_entropy": 1.5846203796325191, "alpha_loss": -0.012965717953780004, "alpha_value": 0.0738564031563757, "duration": 25.51858353614807, "step": 52750}
{"episode_reward": 449.53584027657786, "episode": 423.0, "batch_reward": 2.3810948581695555, "critic_loss": 9.543709243774414, "actor_loss": -225.60131957039002, "actor_target_entropy": -6.0, "actor_entropy": 1.5903880312329246, "alpha_loss": -0.006529197433135576, "alpha_value": 0.07412781761929979, "duration": 25.648223161697388, "step": 52875}
{"episode_reward": 417.0640445942978, "episode": 424.0, "batch_reward": 2.387410249710083, "critic_loss": 8.687707904815674, "actor_loss": -226.44942277477634, "actor_target_entropy": -6.0, "actor_entropy": 1.5012375443212447, "alpha_loss": -0.0005890493461441609, "alpha_value": 0.07422778985586474, "duration": 25.51179599761963, "step": 53000}
{"episode_reward": 398.1576368632218, "episode": 425.0, "batch_reward": 2.383761981964111, "critic_loss": 8.71167283630371, "actor_loss": -226.77848452613466, "actor_target_entropy": -6.0, "actor_entropy": 1.5891746415032282, "alpha_loss": 0.0005485852145486408, "alpha_value": 0.0742393260692708, "duration": 25.60282874107361, "step": 53125}
{"episode_reward": 441.9752628617641, "episode": 426.0, "batch_reward": 2.3889917888641357, "critic_loss": 8.672654518127441, "actor_loss": -227.20744348341418, "actor_target_entropy": -6.0, "actor_entropy": 1.5846097661602883, "alpha_loss": -0.0030245590662103024, "alpha_value": 0.07423359738631216, "duration": 25.569642543792725, "step": 53250}
{"episode_reward": 324.224823712132, "episode": 427.0, "batch_reward": 2.399418794631958, "critic_loss": 8.716159957885742, "actor_loss": -227.7949695889912, "actor_target_entropy": -6.0, "actor_entropy": 1.540324057851519, "alpha_loss": -0.00597085117451137, "alpha_value": 0.07436981198142247, "duration": 25.66087794303894, "step": 53375}
{"episode_reward": 416.01218778505455, "episode": 428.0, "batch_reward": 2.395275032043457, "critic_loss": 9.049370765686035, "actor_loss": -227.76944929553616, "actor_target_entropy": -6.0, "actor_entropy": 1.5958726502233935, "alpha_loss": -0.006504922200204624, "alpha_value": 0.07451566608298588, "duration": 25.60709857940674, "step": 53500}
{"episode_reward": 432.600149956796, "episode": 429.0, "batch_reward": 2.396329818725586, "critic_loss": 8.590123695373535, "actor_loss": -227.4044920906188, "actor_target_entropy": -6.0, "actor_entropy": 1.6420538065925476, "alpha_loss": -0.007192975547652514, "alpha_value": 0.07476305766084267, "duration": 25.707024335861206, "step": 53625}
{"episode_reward": 425.7974206694615, "episode": 430.0, "batch_reward": 2.398259410858154, "critic_loss": 8.944107559204102, "actor_loss": -228.3062973022461, "actor_target_entropy": -6.0, "actor_entropy": 1.6324303938496498, "alpha_loss": -0.0008860182377599901, "alpha_value": 0.07485143978239904, "duration": 25.565643787384033, "step": 53750}
{"episode_reward": 345.90138627811535, "episode": 431.0, "batch_reward": 2.3971339893341064, "critic_loss": 8.570129505157471, "actor_loss": -228.74967472136967, "actor_target_entropy": -6.0, "actor_entropy": 1.531944515213134, "alpha_loss": -0.0030576331090063805, "alpha_value": 0.0749401497632746, "duration": 25.61328101158142, "step": 53875}
{"episode_reward": 444.06356129045116, "episode": 432.0, "batch_reward": 2.4008525619506838, "critic_loss": 8.560222015380859, "actor_loss": -228.7960687452747, "actor_target_entropy": -6.0, "actor_entropy": 1.5987325522207445, "alpha_loss": -0.006148457420133655, "alpha_value": 0.07502396212854484, "duration": 25.579572439193726, "step": 54000}
{"episode_reward": 440.9721080473509, "episode": 433.0, "batch_reward": 2.4042950477600096, "critic_loss": 8.641826740264893, "actor_loss": -228.86512368822855, "actor_target_entropy": -6.0, "actor_entropy": 1.5818347817375547, "alpha_loss": -0.000847943119763855, "alpha_value": 0.07509148616953867, "duration": 25.595098972320557, "step": 54125}
{"episode_reward": 403.2595441256728, "episode": 434.0, "batch_reward": 2.410362148284912, "critic_loss": 8.311381107330321, "actor_loss": -229.11184569328063, "actor_target_entropy": -6.0, "actor_entropy": 1.587629508587622, "alpha_loss": 0.002500030891819587, "alpha_value": 0.07510058426259554, "duration": 25.51467990875244, "step": 54250}
{"episode_reward": 334.6970745826078, "episode": 435.0, "batch_reward": 2.411678197860718, "critic_loss": 9.10534740447998, "actor_loss": -229.56464155893477, "actor_target_entropy": -6.0, "actor_entropy": 1.5964966955639066, "alpha_loss": 0.0018462472196136201, "alpha_value": 0.07505257374448407, "duration": 25.625067710876465, "step": 54375}
{"episode_reward": 407.6988940637494, "episode": 436.0, "batch_reward": 2.404366439819336, "critic_loss": 8.962003570556641, "actor_loss": -229.8484878540039, "actor_target_entropy": -6.0, "actor_entropy": 1.5697064149764277, "alpha_loss": -0.0007881955356307087, "alpha_value": 0.0750157401634606, "duration": 25.550238132476807, "step": 54500}
{"episode_reward": 329.7196527982142, "episode": 437.0, "batch_reward": 2.4092228240966795, "critic_loss": 8.049491573333741, "actor_loss": -230.00877089727493, "actor_target_entropy": -6.0, "actor_entropy": 1.5772133630419534, "alpha_loss": 0.0023655014312160866, "alpha_value": 0.07504019273491727, "duration": 25.588971614837646, "step": 54625}
{"episode_reward": 436.59353020115174, "episode": 438.0, "batch_reward": 2.413796516418457, "critic_loss": 8.378181522369385, "actor_loss": -230.33924275059854, "actor_target_entropy": -6.0, "actor_entropy": 1.6093279796261941, "alpha_loss": -0.008657858019784814, "alpha_value": 0.07510570956416404, "duration": 25.508527278900146, "step": 54750}
{"episode_reward": 434.4564686899962, "episode": 439.0, "batch_reward": 2.411341905593872, "critic_loss": 8.133796726226807, "actor_loss": -230.97974383641804, "actor_target_entropy": -6.0, "actor_entropy": 1.6345020154165844, "alpha_loss": -0.00933720635634566, "alpha_value": 0.07528624791442597, "duration": 25.591453313827515, "step": 54875}
{"episode_reward": 441.7694180557549, "episode": 440.0, "batch_reward": 2.414594306945801, "critic_loss": 8.39352763748169, "actor_loss": -230.36796594435168, "actor_target_entropy": -6.0, "actor_entropy": 1.551571286493732, "alpha_loss": 0.00012816013693208657, "alpha_value": 0.07548101982821702, "step": 55000}
{"duration": 36.450597286224365, "step": 55000}
{"episode_reward": 404.2512011818184, "episode": 441.0, "batch_reward": 2.4179265480041505, "critic_loss": 8.489003944396973, "actor_loss": -230.8875967358786, "actor_target_entropy": -6.0, "actor_entropy": 1.5851887029314797, "alpha_loss": 0.006060579477528494, "alpha_value": 0.07539339576818012, "duration": 25.63870644569397, "step": 55125}
{"episode_reward": 411.6437046441529, "episode": 442.0, "batch_reward": 2.4258983612060545, "critic_loss": 8.198252994537354, "actor_loss": -231.52305455361642, "actor_target_entropy": -6.0, "actor_entropy": 1.5334739204375976, "alpha_loss": 0.005488429207264656, "alpha_value": 0.07524212041309052, "duration": 25.547674894332886, "step": 55250}
{"episode_reward": 441.8637349211605, "episode": 443.0, "batch_reward": 2.4257914028167726, "critic_loss": 7.4225546875, "actor_loss": -231.84361557733445, "actor_target_entropy": -6.0, "actor_entropy": 1.5382428263861037, "alpha_loss": -0.00033270674831573923, "alpha_value": 0.07519604137277676, "duration": 25.555927991867065, "step": 55375}
{"episode_reward": 448.9575765158366, "episode": 444.0, "batch_reward": 2.428436288833618, "critic_loss": 8.16588422012329, "actor_loss": -232.27872516262917, "actor_target_entropy": -6.0, "actor_entropy": 1.5539796140886122, "alpha_loss": 0.00031693005228355047, "alpha_value": 0.07517083381889773, "duration": 25.62136960029602, "step": 55500}
{"episode_reward": 442.8078551967792, "episode": 445.0, "batch_reward": 2.418292470932007, "critic_loss": 7.69590998840332, "actor_loss": -232.33236476353235, "actor_target_entropy": -6.0, "actor_entropy": 1.591401906240554, "alpha_loss": -0.0007609483667664112, "alpha_value": 0.0752100881977676, "duration": 25.592461347579956, "step": 55625}
{"episode_reward": 436.0331534219152, "episode": 446.0, "batch_reward": 2.4312752151489256, "critic_loss": 7.569495059967041, "actor_loss": -232.8845650457567, "actor_target_entropy": -6.0, "actor_entropy": 1.523829133279862, "alpha_loss": -0.002203218505582622, "alpha_value": 0.07518217815321805, "duration": 25.528223514556885, "step": 55750}
{"episode_reward": 409.6265762136237, "episode": 447.0, "batch_reward": 2.4329715995788574, "critic_loss": 7.649225353240967, "actor_loss": -233.0140664236886, "actor_target_entropy": -6.0, "actor_entropy": 1.5635947216124761, "alpha_loss": 0.004951424109527753, "alpha_value": 0.07519178322485258, "duration": 25.624932050704956, "step": 55875}
{"episode_reward": 461.46768945110335, "episode": 448.0, "batch_reward": 2.431354480743408, "critic_loss": 8.117197048187256, "actor_loss": -233.3323684200164, "actor_target_entropy": -6.0, "actor_entropy": 1.5653349103466156, "alpha_loss": -0.003567643332174949, "alpha_value": 0.07512005183604653, "duration": 25.516167879104614, "step": 56000}
{"episode_reward": 420.5388940672374, "episode": 449.0, "batch_reward": 2.4452941455841066, "critic_loss": 8.011407440185547, "actor_loss": -233.6533966064453, "actor_target_entropy": -6.0, "actor_entropy": 1.4744034400061956, "alpha_loss": 0.005512477094603199, "alpha_value": 0.0750642804272165, "duration": 25.60794472694397, "step": 56125}
{"episode_reward": 403.66283389452764, "episode": 450.0, "batch_reward": 2.441266166687012, "critic_loss": 8.146686454772949, "actor_loss": -233.28491678545552, "actor_target_entropy": -6.0, "actor_entropy": 1.6312650384441498, "alpha_loss": -0.004961842182843435, "alpha_value": 0.0750549917224601, "duration": 25.563138246536255, "step": 56250}
{"episode_reward": 459.6751122783488, "episode": 451.0, "batch_reward": 2.44180327796936, "critic_loss": 7.474418834686279, "actor_loss": -234.08690776522198, "actor_target_entropy": -6.0, "actor_entropy": 1.4872161566265045, "alpha_loss": -0.006116828082927636, "alpha_value": 0.0752698270231349, "duration": 25.683330535888672, "step": 56375}
{"episode_reward": 447.9670020927514, "episode": 452.0, "batch_reward": 2.4410907821655274, "critic_loss": 7.592734226226806, "actor_loss": -234.05279221073275, "actor_target_entropy": -6.0, "actor_entropy": 1.4690657911762115, "alpha_loss": 0.0039812792918734975, "alpha_value": 0.0752751385088488, "duration": 25.51121234893799, "step": 56500}
{"episode_reward": 436.20299537224173, "episode": 453.0, "batch_reward": 2.4575979137420654, "critic_loss": 7.726947082519532, "actor_loss": -234.48187473842077, "actor_target_entropy": -6.0, "actor_entropy": 1.5597194735966031, "alpha_loss": -0.0008741340466908046, "alpha_value": 0.07522081974142966, "duration": 25.60047435760498, "step": 56625}
{"episode_reward": 407.4956268713208, "episode": 454.0, "batch_reward": 2.447177635192871, "critic_loss": 8.349998901367188, "actor_loss": -235.19195162865424, "actor_target_entropy": -6.0, "actor_entropy": 1.5933031843554588, "alpha_loss": -0.0042839715399989675, "alpha_value": 0.07524266810417972, "duration": 25.595552682876587, "step": 56750}
{"episode_reward": 436.0068004640481, "episode": 455.0, "batch_reward": 2.4573115100860594, "critic_loss": 7.536559574127197, "actor_loss": -234.9018082391648, "actor_target_entropy": -6.0, "actor_entropy": 1.545866852714902, "alpha_loss": -0.005040009960620886, "alpha_value": 0.07547237535113722, "duration": 25.66524577140808, "step": 56875}
{"episode_reward": 444.38228784436825, "episode": 456.0, "batch_reward": 2.460267686843872, "critic_loss": 7.339518806457519, "actor_loss": -235.14773534959363, "actor_target_entropy": -6.0, "actor_entropy": 1.6026772722121208, "alpha_loss": 0.002616343366342687, "alpha_value": 0.0754847134162168, "duration": 25.544951677322388, "step": 57000}
{"episode_reward": 435.8517432222756, "episode": 457.0, "batch_reward": 2.4561418762207032, "critic_loss": 7.430617446899414, "actor_loss": -235.34166003030444, "actor_target_entropy": -6.0, "actor_entropy": 1.5001152337543548, "alpha_loss": -0.0015399816542095135, "alpha_value": 0.07538609332169892, "duration": 25.645565032958984, "step": 57125}
{"episode_reward": 445.11624849930723, "episode": 458.0, "batch_reward": 2.4600144119262697, "critic_loss": 7.649172214508057, "actor_loss": -235.98067745085686, "actor_target_entropy": -6.0, "actor_entropy": 1.52961072421843, "alpha_loss": -0.008018324775020442, "alpha_value": 0.07558630727624857, "duration": 25.53072738647461, "step": 57250}
{"episode_reward": 360.50956000435616, "episode": 459.0, "batch_reward": 2.459758617401123, "critic_loss": 7.813779273986817, "actor_loss": -236.41701374356708, "actor_target_entropy": -6.0, "actor_entropy": 1.5724965087951175, "alpha_loss": -0.005081637089865075, "alpha_value": 0.07574345314751367, "duration": 25.609074115753174, "step": 57375}
{"episode_reward": 434.7808206084183, "episode": 460.0, "batch_reward": 2.462666151046753, "critic_loss": 7.800415573120117, "actor_loss": -236.02035153296686, "actor_target_entropy": -6.0, "actor_entropy": 1.6299050085006221, "alpha_loss": -0.011077180887842852, "alpha_value": 0.07594620215742999, "duration": 25.54409670829773, "step": 57500}
{"episode_reward": 277.6494892421084, "episode": 461.0, "batch_reward": 2.4598908462524416, "critic_loss": 9.102649173736573, "actor_loss": -236.2928263346354, "actor_target_entropy": -6.0, "actor_entropy": 1.6708646123371427, "alpha_loss": 0.004665786175922092, "alpha_value": 0.07607296949603702, "duration": 25.600783824920654, "step": 57625}
{"episode_reward": 400.4099940383699, "episode": 462.0, "batch_reward": 2.462961103439331, "critic_loss": 11.172854724884033, "actor_loss": -236.61289707306892, "actor_target_entropy": -6.0, "actor_entropy": 1.7588992503381544, "alpha_loss": -0.013377270449118147, "alpha_value": 0.07614469978443676, "duration": 25.582773208618164, "step": 57750}
{"episode_reward": 458.92470492937673, "episode": 463.0, "batch_reward": 2.464812942504883, "critic_loss": 9.599713317871094, "actor_loss": -236.72569953070746, "actor_target_entropy": -6.0, "actor_entropy": 1.6110388381140572, "alpha_loss": -0.0010107698118580239, "alpha_value": 0.07641496949622058, "duration": 25.64186978340149, "step": 57875}
{"episode_reward": 197.96676884258324, "episode": 464.0, "batch_reward": 2.474289310455322, "critic_loss": 9.351031616210937, "actor_loss": -236.97237100908833, "actor_target_entropy": -6.0, "actor_entropy": 1.6122606877357728, "alpha_loss": 4.57661752138407e-05, "alpha_value": 0.07634506603760385, "duration": 25.56799864768982, "step": 58000}
{"episode_reward": 463.52441735231116, "episode": 465.0, "batch_reward": 2.469792722702026, "critic_loss": 9.753799102783203, "actor_loss": -237.58917817615327, "actor_target_entropy": -6.0, "actor_entropy": 1.704614351666163, "alpha_loss": -0.004927990233732594, "alpha_value": 0.07645848552758984, "duration": 25.61597228050232, "step": 58125}
{"episode_reward": 328.3338498877583, "episode": 466.0, "batch_reward": 2.4677327117919923, "critic_loss": 8.437015403747559, "actor_loss": -237.1406729913527, "actor_target_entropy": -6.0, "actor_entropy": 1.5939696027386574, "alpha_loss": 0.003826265704006918, "alpha_value": 0.07649196147192787, "duration": 25.566961526870728, "step": 58250}
{"episode_reward": 428.01208862194613, "episode": 467.0, "batch_reward": 2.4664479961395265, "critic_loss": 8.995505870819091, "actor_loss": -237.60523502410405, "actor_target_entropy": -6.0, "actor_entropy": 1.58890548206511, "alpha_loss": -0.005274457982667382, "alpha_value": 0.07652218919791462, "duration": 25.64790105819702, "step": 58375}
{"episode_reward": 431.05719942406756, "episode": 468.0, "batch_reward": 2.4714799480438234, "critic_loss": 9.032799530029298, "actor_loss": -238.8953136321037, "actor_target_entropy": -6.0, "actor_entropy": 1.5832757123054997, "alpha_loss": 0.00023582190906088198, "alpha_value": 0.076568661457993, "duration": 25.589860200881958, "step": 58500}
{"episode_reward": 449.44352347272934, "episode": 469.0, "batch_reward": 2.478486680984497, "critic_loss": 8.752950046539306, "actor_loss": -238.45050097268725, "actor_target_entropy": -6.0, "actor_entropy": 1.5382246933286152, "alpha_loss": 0.0003237608591065047, "alpha_value": 0.07652444478073724, "duration": 25.628715753555298, "step": 58625}
{"episode_reward": 421.14352671243773, "episode": 470.0, "batch_reward": 2.4785781383514403, "critic_loss": 8.530738410949708, "actor_loss": -238.74670656265752, "actor_target_entropy": -6.0, "actor_entropy": 1.515073968518165, "alpha_loss": -0.0007558013406401921, "alpha_value": 0.07659079647682711, "duration": 25.54235553741455, "step": 58750}
{"episode_reward": 408.25403671988295, "episode": 471.0, "batch_reward": 2.485957508087158, "critic_loss": 8.113486476898194, "actor_loss": -239.19864036923363, "actor_target_entropy": -6.0, "actor_entropy": 1.4969790435972667, "alpha_loss": -0.005693118235776349, "alpha_value": 0.07663172055107646, "duration": 25.675015926361084, "step": 58875}
{"episode_reward": 463.53901330958666, "episode": 472.0, "batch_reward": 2.48328515625, "critic_loss": 8.906103420257569, "actor_loss": -239.16300767467868, "actor_target_entropy": -6.0, "actor_entropy": 1.5599637992920414, "alpha_loss": -0.003830848152809326, "alpha_value": 0.07675174408725498, "duration": 25.568353176116943, "step": 59000}
{"episode_reward": 421.70310404972463, "episode": 473.0, "batch_reward": 2.4808311653137207, "critic_loss": 9.009667514801025, "actor_loss": -238.7737104627821, "actor_target_entropy": -6.0, "actor_entropy": 1.6450446314281888, "alpha_loss": 0.0038424511366183796, "alpha_value": 0.07676008445314604, "duration": 25.64540433883667, "step": 59125}
{"episode_reward": 440.19598715999086, "episode": 474.0, "batch_reward": 2.4932322254180908, "critic_loss": 8.46202649307251, "actor_loss": -239.9397181849326, "actor_target_entropy": -6.0, "actor_entropy": 1.5407104280687147, "alpha_loss": -0.006000960784618773, "alpha_value": 0.07677680537655579, "duration": 25.578706979751587, "step": 59250}
{"episode_reward": 456.80244152478207, "episode": 475.0, "batch_reward": 2.4955334396362305, "critic_loss": 8.782259929656982, "actor_loss": -240.45158022925966, "actor_target_entropy": -6.0, "actor_entropy": 1.6165425720668973, "alpha_loss": -0.007466545169581733, "alpha_value": 0.07693168411506106, "duration": 25.656065225601196, "step": 59375}
{"episode_reward": 374.7907154701785, "episode": 476.0, "batch_reward": 2.482735664367676, "critic_loss": 9.094580051422119, "actor_loss": -239.6918699202999, "actor_target_entropy": -6.0, "actor_entropy": 1.6199796468980852, "alpha_loss": 2.3164673738421932e-05, "alpha_value": 0.07706510123747891, "duration": 25.56652855873108, "step": 59500}
{"episode_reward": 425.87257096598967, "episode": 477.0, "batch_reward": 2.497940715789795, "critic_loss": 9.2565524559021, "actor_loss": -240.21556406172496, "actor_target_entropy": -6.0, "actor_entropy": 1.6359614947485546, "alpha_loss": -0.0001478622600968395, "alpha_value": 0.07706279485755942, "duration": 25.63797616958618, "step": 59625}
{"episode_reward": 410.1800944634072, "episode": 478.0, "batch_reward": 2.4945788326263427, "critic_loss": 8.855896968841552, "actor_loss": -240.4492655108052, "actor_target_entropy": -6.0, "actor_entropy": 1.5939527403923772, "alpha_loss": -0.004475353612384248, "alpha_value": 0.07715690522258732, "duration": 25.50846815109253, "step": 59750}
{"episode_reward": 305.5671563937437, "episode": 479.0, "batch_reward": 2.4807310733795167, "critic_loss": 8.864143184661865, "actor_loss": -240.53106834774925, "actor_target_entropy": -6.0, "actor_entropy": 1.5788521615285722, "alpha_loss": -0.009114082244830944, "alpha_value": 0.07737167771482023, "duration": 25.65176796913147, "step": 59875}
{"episode_reward": 415.41200707936906, "episode": 480.0, "batch_reward": 2.502711296081543, "critic_loss": 8.884767360687256, "actor_loss": -241.09760062925278, "actor_target_entropy": -6.0, "actor_entropy": 1.5879897648288357, "alpha_loss": -0.0010707456385716796, "alpha_value": 0.07742108636401063, "step": 60000}
{"duration": 36.42201519012451, "step": 60000}
{"episode_reward": 443.97306891674464, "episode": 481.0, "batch_reward": 2.495748123168945, "critic_loss": 9.519182178497314, "actor_loss": -241.29265945676772, "actor_target_entropy": -6.0, "actor_entropy": 1.705347594760713, "alpha_loss": -0.006991730104865772, "alpha_value": 0.07758154071557727, "duration": 25.65143370628357, "step": 60125}
{"episode_reward": 412.8004100337148, "episode": 482.0, "batch_reward": 2.494481782913208, "critic_loss": 9.007115264892578, "actor_loss": -241.5999029836347, "actor_target_entropy": -6.0, "actor_entropy": 1.627781162338872, "alpha_loss": -0.004931680719187904, "alpha_value": 0.07771194718279538, "duration": 25.56082010269165, "step": 60250}
{"episode_reward": 443.71592027201103, "episode": 483.0, "batch_reward": 2.49274773979187, "critic_loss": 8.990065437316895, "actor_loss": -241.8090057373047, "actor_target_entropy": -6.0, "actor_entropy": 1.6477526880445934, "alpha_loss": -0.0008465119282759371, "alpha_value": 0.07777135953356455, "duration": 25.609395265579224, "step": 60375}
{"episode_reward": 412.34520533286656, "episode": 484.0, "batch_reward": 2.501152118682861, "critic_loss": 8.669685386657715, "actor_loss": -241.73452783400012, "actor_target_entropy": -6.0, "actor_entropy": 1.6165479921525525, "alpha_loss": 0.004776444015724044, "alpha_value": 0.07775306512678115, "duration": 25.522093772888184, "step": 60500}
{"episode_reward": 438.7188033781863, "episode": 485.0, "batch_reward": 2.4993608264923095, "critic_loss": 8.679735027313232, "actor_loss": -242.1465296669612, "actor_target_entropy": -6.0, "actor_entropy": 1.4517271594395713, "alpha_loss": -0.00198284072047543, "alpha_value": 0.07776583823847433, "duration": 25.639654397964478, "step": 60625}
{"episode_reward": 422.94755861959544, "episode": 486.0, "batch_reward": 2.5111604824066163, "critic_loss": 8.968647026062012, "actor_loss": -242.87577179939515, "actor_target_entropy": -6.0, "actor_entropy": 1.6082922277912017, "alpha_loss": -0.0065272674227373735, "alpha_value": 0.07784837872889352, "duration": 25.538638591766357, "step": 60750}
{"episode_reward": 451.705311633254, "episode": 487.0, "batch_reward": 2.4943656044006346, "critic_loss": 8.265768630981444, "actor_loss": -242.4575958251953, "actor_target_entropy": -6.0, "actor_entropy": 1.5800868253859262, "alpha_loss": -0.005741876550018787, "alpha_value": 0.07796885194448515, "duration": 25.61666226387024, "step": 60875}
{"episode_reward": 436.18711121583516, "episode": 488.0, "batch_reward": 2.500421049118042, "critic_loss": 8.228820739746094, "actor_loss": -242.47816418063255, "actor_target_entropy": -6.0, "actor_entropy": 1.5647575336117898, "alpha_loss": -0.002334684869574924, "alpha_value": 0.07808693732643734, "duration": 25.541626691818237, "step": 61000}
{"episode_reward": 458.20456704736745, "episode": 489.0, "batch_reward": 2.5083311367034913, "critic_loss": 8.107051990509033, "actor_loss": -243.1096452985491, "actor_target_entropy": -6.0, "actor_entropy": 1.6433207364309401, "alpha_loss": 0.004606467801042729, "alpha_value": 0.07811592322230324, "duration": 25.618155241012573, "step": 61125}
{"episode_reward": 449.85512699030335, "episode": 490.0, "batch_reward": 2.5123808765411377, "critic_loss": 8.657783416748046, "actor_loss": -243.7050719722625, "actor_target_entropy": -6.0, "actor_entropy": 1.5821800635706993, "alpha_loss": -0.0028443163065540213, "alpha_value": 0.07801947388193337, "duration": 25.52523970603943, "step": 61250}
{"episode_reward": 469.8391463289948, "episode": 491.0, "batch_reward": 2.5099563541412353, "critic_loss": 8.368083492279053, "actor_loss": -243.4362039717417, "actor_target_entropy": -6.0, "actor_entropy": 1.6442212169132535, "alpha_loss": 0.0018441352830638016, "alpha_value": 0.07807260830342211, "duration": 25.607696533203125, "step": 61375}
{"episode_reward": 460.901245720833, "episode": 492.0, "batch_reward": 2.5172346305847166, "critic_loss": 9.263204433441162, "actor_loss": -243.9694309849893, "actor_target_entropy": -6.0, "actor_entropy": 1.5922620661797062, "alpha_loss": -0.0028935861867672255, "alpha_value": 0.07802316273373043, "duration": 25.574540853500366, "step": 61500}
{"episode_reward": 430.4988709649558, "episode": 493.0, "batch_reward": 2.5263887100219726, "critic_loss": 8.869137790679932, "actor_loss": -244.90538218664744, "actor_target_entropy": -6.0, "actor_entropy": 1.6629855292184013, "alpha_loss": 0.006211341122194888, "alpha_value": 0.07799939806402886, "duration": 25.667792320251465, "step": 61625}
{"episode_reward": 368.46083905365117, "episode": 494.0, "batch_reward": 2.526279893875122, "critic_loss": 9.405466777801514, "actor_loss": -244.499757828251, "actor_target_entropy": -6.0, "actor_entropy": 1.6337029414792215, "alpha_loss": -0.0006675232509751954, "alpha_value": 0.07798558817823081, "duration": 25.505269765853882, "step": 61750}
{"episode_reward": 353.6325657927026, "episode": 495.0, "batch_reward": 2.532171751022339, "critic_loss": 9.293614131927491, "actor_loss": -245.48169478159102, "actor_target_entropy": -6.0, "actor_entropy": 1.5954956932673379, "alpha_loss": -0.0003425720376923444, "alpha_value": 0.07796481629704556, "duration": 25.598387002944946, "step": 61875}
{"episode_reward": 411.91171572363277, "episode": 496.0, "batch_reward": 2.5216577796936037, "critic_loss": 9.413142665863036, "actor_loss": -245.26950885403542, "actor_target_entropy": -6.0, "actor_entropy": 1.5436759610329904, "alpha_loss": 0.010738388458717494, "alpha_value": 0.07781789030458805, "duration": 25.591145277023315, "step": 62000}
{"episode_reward": 391.79727559869195, "episode": 497.0, "batch_reward": 2.5281993255615234, "critic_loss": 9.113343372344971, "actor_loss": -245.38425820971293, "actor_target_entropy": -6.0, "actor_entropy": 1.67909422374907, "alpha_loss": 0.0025898644382814093, "alpha_value": 0.0776407030407172, "duration": 25.62423872947693, "step": 62125}
{"episode_reward": 456.7401164350233, "episode": 498.0, "batch_reward": 2.527692552566528, "critic_loss": 8.719658111572265, "actor_loss": -246.12023433562248, "actor_target_entropy": -6.0, "actor_entropy": 1.6264692910255925, "alpha_loss": -0.0033971662407801034, "alpha_value": 0.0776067465436532, "duration": 25.57269024848938, "step": 62250}
{"episode_reward": 442.5219058139271, "episode": 499.0, "batch_reward": 2.5257364807128906, "critic_loss": 8.384117038726806, "actor_loss": -245.6898425874256, "actor_target_entropy": -6.0, "actor_entropy": 1.6624401202277532, "alpha_loss": -0.005820595821927464, "alpha_value": 0.07775936292855752, "duration": 25.644863605499268, "step": 62375}
{"episode_reward": 445.55110876426835, "episode": 500.0, "batch_reward": 2.53949627494812, "critic_loss": 8.522313674926759, "actor_loss": -245.9578616234564, "actor_target_entropy": -6.0, "actor_entropy": 1.624000370502472, "alpha_loss": -0.004459440005913137, "alpha_value": 0.07792778280218157, "duration": 25.60317873954773, "step": 62500}
{"episode_reward": 384.70945348856515, "episode": 501.0, "batch_reward": 2.5267096328735352, "critic_loss": 8.659898990631104, "actor_loss": -245.96850125751797, "actor_target_entropy": -6.0, "actor_entropy": 1.6302736959760151, "alpha_loss": -0.00245474857307734, "alpha_value": 0.07800661562517891, "duration": 25.63231873512268, "step": 62625}
{"episode_reward": 427.70976851600983, "episode": 502.0, "batch_reward": 2.5361027755737306, "critic_loss": 8.52781895828247, "actor_loss": -246.17594835835118, "actor_target_entropy": -6.0, "actor_entropy": 1.607561961297066, "alpha_loss": -0.0022824593752081837, "alpha_value": 0.0780566913798942, "duration": 25.620100259780884, "step": 62750}
{"episode_reward": 460.1194086081443, "episode": 503.0, "batch_reward": 2.531203632354736, "critic_loss": 7.864937641143799, "actor_loss": -246.46156698559957, "actor_target_entropy": -6.0, "actor_entropy": 1.6831097829909551, "alpha_loss": 0.0022285988107175816, "alpha_value": 0.078094075395516, "duration": 25.63955283164978, "step": 62875}
{"episode_reward": 409.2874362241043, "episode": 504.0, "batch_reward": 2.541861810684204, "critic_loss": 8.857043170928955, "actor_loss": -246.92313483453566, "actor_target_entropy": -6.0, "actor_entropy": 1.6528551078611804, "alpha_loss": 0.0005145133022339114, "alpha_value": 0.07797071466166836, "duration": 25.57990860939026, "step": 63000}
{"episode_reward": 449.0692702202015, "episode": 505.0, "batch_reward": 2.546292879104614, "critic_loss": 8.70568968963623, "actor_loss": -247.4997335766989, "actor_target_entropy": -6.0, "actor_entropy": 1.6239360570907593, "alpha_loss": -0.0076220827103252444, "alpha_value": 0.07812804206438896, "duration": 25.669347524642944, "step": 63125}
{"episode_reward": 413.6704953329872, "episode": 506.0, "batch_reward": 2.543519546508789, "critic_loss": 8.716304634094238, "actor_loss": -247.64829721758443, "actor_target_entropy": -6.0, "actor_entropy": 1.6744276861990652, "alpha_loss": -0.004541112019890739, "alpha_value": 0.07829373411397818, "duration": 25.63775086402893, "step": 63250}
{"episode_reward": 446.9146645584591, "episode": 507.0, "batch_reward": 2.5459627838134766, "critic_loss": 8.792800605773925, "actor_loss": -247.48033142089844, "actor_target_entropy": -6.0, "actor_entropy": 1.6441855127849276, "alpha_loss": -0.01575764545076896, "alpha_value": 0.07860215262230959, "duration": 25.689889430999756, "step": 63375}
{"episode_reward": 362.25437154743327, "episode": 508.0, "batch_reward": 2.538382177352905, "critic_loss": 9.581921794891358, "actor_loss": -247.85511262955205, "actor_target_entropy": -6.0, "actor_entropy": 1.6013793426175271, "alpha_loss": 0.003152224595748609, "alpha_value": 0.07873304631204558, "duration": 25.625568389892578, "step": 63500}
{"episode_reward": 459.1880775031141, "episode": 509.0, "batch_reward": 2.539035827636719, "critic_loss": 9.225882740020753, "actor_loss": -248.02391342889695, "actor_target_entropy": -6.0, "actor_entropy": 1.7179150448905096, "alpha_loss": -0.003722138421994353, "alpha_value": 0.07874833929311824, "duration": 25.672080755233765, "step": 63625}
{"episode_reward": 437.83912865316324, "episode": 510.0, "batch_reward": 2.5553011474609373, "critic_loss": 8.929365684509277, "actor_loss": -248.15870026619203, "actor_target_entropy": -6.0, "actor_entropy": 1.676125976347154, "alpha_loss": -0.0015527241668033024, "alpha_value": 0.07880863324304756, "duration": 25.614734411239624, "step": 63750}
{"episode_reward": 431.02468546236236, "episode": 511.0, "batch_reward": 2.5556348056793214, "critic_loss": 8.356822639465332, "actor_loss": -248.32000441778274, "actor_target_entropy": -6.0, "actor_entropy": 1.7321990766222515, "alpha_loss": -0.002283408587414121, "alpha_value": 0.07892860548989306, "duration": 25.64229702949524, "step": 63875}
{"episode_reward": 456.2227949548297, "episode": 512.0, "batch_reward": 2.5435963363647462, "critic_loss": 9.111116710662841, "actor_loss": -248.43246213851435, "actor_target_entropy": -6.0, "actor_entropy": 1.563809544809403, "alpha_loss": 0.002641290140848967, "alpha_value": 0.07888375394311026, "duration": 25.569257736206055, "step": 64000}
{"episode_reward": 425.33886106505486, "episode": 513.0, "batch_reward": 2.5589172496795656, "critic_loss": 8.9511771774292, "actor_loss": -249.278318859282, "actor_target_entropy": -6.0, "actor_entropy": 1.6914349888998366, "alpha_loss": -0.0029195275837703358, "alpha_value": 0.07888938949474043, "duration": 25.595578908920288, "step": 64125}
{"episode_reward": 450.0450339436491, "episode": 514.0, "batch_reward": 2.5520859317779543, "critic_loss": 8.902905773162841, "actor_loss": -249.05845642089844, "actor_target_entropy": -6.0, "actor_entropy": 1.6760494651332978, "alpha_loss": 0.0002244893506529831, "alpha_value": 0.07887416140384305, "duration": 25.539652824401855, "step": 64250}
{"episode_reward": 451.14943697781297, "episode": 515.0, "batch_reward": 2.5557825469970705, "critic_loss": 9.22245881652832, "actor_loss": -249.39508541046627, "actor_target_entropy": -6.0, "actor_entropy": 1.6847989634862022, "alpha_loss": -0.002663419803693181, "alpha_value": 0.0788957122469981, "duration": 25.631839752197266, "step": 64375}
{"episode_reward": 452.0427937468597, "episode": 516.0, "batch_reward": 2.5656230354309084, "critic_loss": 8.510422916412354, "actor_loss": -249.95243466284967, "actor_target_entropy": -6.0, "actor_entropy": 1.683077908331348, "alpha_loss": -0.005504795406464367, "alpha_value": 0.07906549226055697, "duration": 25.57772731781006, "step": 64500}
{"episode_reward": 437.1674376984986, "episode": 517.0, "batch_reward": 2.556769676208496, "critic_loss": 8.516006637573243, "actor_loss": -249.51390051463292, "actor_target_entropy": -6.0, "actor_entropy": 1.6522014216771201, "alpha_loss": 0.0005863137092323057, "alpha_value": 0.07911203803015639, "duration": 25.65710711479187, "step": 64625}
{"episode_reward": 425.5025711683461, "episode": 518.0, "batch_reward": 2.5588786849975587, "critic_loss": 8.474108634948731, "actor_loss": -250.23004913330078, "actor_target_entropy": -6.0, "actor_entropy": 1.5019906624670951, "alpha_loss": 0.0020405975744999466, "alpha_value": 0.07911875180742957, "duration": 25.61289119720459, "step": 64750}
{"episode_reward": 465.74645999387826, "episode": 519.0, "batch_reward": 2.5647135219573975, "critic_loss": 9.240648300170898, "actor_loss": -250.18462965223523, "actor_target_entropy": -6.0, "actor_entropy": 1.6295638595308577, "alpha_loss": 0.0017044557025656104, "alpha_value": 0.07905624121325132, "duration": 25.662752628326416, "step": 64875}
{"episode_reward": 455.4473272218072, "episode": 520.0, "batch_reward": 2.566854890823364, "critic_loss": 9.67603018951416, "actor_loss": -250.1306090816375, "actor_target_entropy": -6.0, "actor_entropy": 1.6902488662350563, "alpha_loss": -0.0008588036702525231, "alpha_value": 0.07897192497431768, "step": 65000}
{"duration": 36.45523548126221, "step": 65000}
{"episode_reward": 438.1734849254792, "episode": 521.0, "batch_reward": 2.5756045207977296, "critic_loss": 9.063823638916016, "actor_loss": -250.80724225725447, "actor_target_entropy": -6.0, "actor_entropy": 1.6094214935151359, "alpha_loss": 0.0027143034348559992, "alpha_value": 0.07900888896304561, "duration": 25.672796487808228, "step": 65125}
{"episode_reward": 420.07214636232214, "episode": 522.0, "batch_reward": 2.5678107776641848, "critic_loss": 9.226367183685303, "actor_loss": -250.36685992825417, "actor_target_entropy": -6.0, "actor_entropy": 1.621987565871208, "alpha_loss": 0.0022585723199881613, "alpha_value": 0.07892184716230588, "duration": 25.635799884796143, "step": 65250}
{"episode_reward": 430.17223730531714, "episode": 523.0, "batch_reward": 2.5725368194580076, "critic_loss": 8.930263107299805, "actor_loss": -251.04829794263082, "actor_target_entropy": -6.0, "actor_entropy": 1.6425743008416795, "alpha_loss": 0.004301170352846384, "alpha_value": 0.07891942922839307, "duration": 25.64875888824463, "step": 65375}
{"episode_reward": 430.9088457701632, "episode": 524.0, "batch_reward": 2.565650390625, "critic_loss": 10.031669952392578, "actor_loss": -250.8051295126638, "actor_target_entropy": -6.0, "actor_entropy": 1.7054281407786953, "alpha_loss": -0.00169030235021285, "alpha_value": 0.0787666241112075, "duration": 25.601805210113525, "step": 65500}
{"episode_reward": 436.1619020506748, "episode": 525.0, "batch_reward": 2.5686631717681885, "critic_loss": 9.762783809661865, "actor_loss": -251.49530562143477, "actor_target_entropy": -6.0, "actor_entropy": 1.8320279083554707, "alpha_loss": -0.006167992354474134, "alpha_value": 0.07886142691029847, "duration": 25.681284189224243, "step": 65625}
{"episode_reward": 321.66961245487465, "episode": 526.0, "batch_reward": 2.566742277145386, "critic_loss": 8.999548877716064, "actor_loss": -251.78086951471144, "actor_target_entropy": -6.0, "actor_entropy": 1.6634016402306095, "alpha_loss": 0.0016220663899495717, "alpha_value": 0.07893233860031115, "duration": 25.62204337120056, "step": 65750}
{"episode_reward": 424.6261438971102, "episode": 527.0, "batch_reward": 2.5726734390258787, "critic_loss": 9.912860012054443, "actor_loss": -251.17742774600075, "actor_target_entropy": -6.0, "actor_entropy": 1.7702946662902832, "alpha_loss": -0.010804686662075775, "alpha_value": 0.07916920541645799, "duration": 25.684186458587646, "step": 65875}
{"episode_reward": 408.81044309431564, "episode": 528.0, "batch_reward": 2.579632026672363, "critic_loss": 9.939219932556153, "actor_loss": -252.19445333173198, "actor_target_entropy": -6.0, "actor_entropy": 1.7259283931024614, "alpha_loss": 0.006332365991247277, "alpha_value": 0.07922840184461176, "duration": 25.63321304321289, "step": 66000}
{"episode_reward": 473.56832633474056, "episode": 529.0, "batch_reward": 2.5785982456207277, "critic_loss": 9.916672954559326, "actor_loss": -252.51472715347532, "actor_target_entropy": -6.0, "actor_entropy": 1.6541919613641405, "alpha_loss": 0.0019260970247347677, "alpha_value": 0.07905767258305844, "duration": 25.650853633880615, "step": 66125}
{"episode_reward": 445.778605470127, "episode": 530.0, "batch_reward": 2.576290241241455, "critic_loss": 8.318561428070069, "actor_loss": -252.21338604342552, "actor_target_entropy": -6.0, "actor_entropy": 1.7020748584501204, "alpha_loss": -0.005894084609368996, "alpha_value": 0.0791639103520661, "duration": 25.697286128997803, "step": 66250}
{"episode_reward": 427.6026427396647, "episode": 531.0, "batch_reward": 2.59252773475647, "critic_loss": 8.406906867980958, "actor_loss": -252.70288667224702, "actor_target_entropy": -6.0, "actor_entropy": 1.6657653271205841, "alpha_loss": 0.0015479523747686356, "alpha_value": 0.07919857879566768, "duration": 25.708340167999268, "step": 66375}
{"episode_reward": 445.5221691981901, "episode": 532.0, "batch_reward": 2.5856944046020507, "critic_loss": 8.98419889831543, "actor_loss": -253.04315948486328, "actor_target_entropy": -6.0, "actor_entropy": 1.5802634473769896, "alpha_loss": 0.003930343900837244, "alpha_value": 0.0791176429678072, "duration": 25.67073106765747, "step": 66500}
{"episode_reward": 434.77499034175634, "episode": 533.0, "batch_reward": 2.5852804374694824, "critic_loss": 9.177337211608886, "actor_loss": -253.02869378952752, "actor_target_entropy": -6.0, "actor_entropy": 1.5596455960046678, "alpha_loss": 0.0038248952552084885, "alpha_value": 0.078960437790576, "duration": 25.671987533569336, "step": 66625}
{"episode_reward": 447.10292876955305, "episode": 534.0, "batch_reward": 2.583420946121216, "critic_loss": 9.19854002380371, "actor_loss": -253.3395220848822, "actor_target_entropy": -6.0, "actor_entropy": 1.6815111060296335, "alpha_loss": -0.00512476333401977, "alpha_value": 0.07897532051640953, "duration": 25.582491159439087, "step": 66750}
{"episode_reward": 413.74148535691864, "episode": 535.0, "batch_reward": 2.5902112312316894, "critic_loss": 8.042896072387695, "actor_loss": -253.75406561957465, "actor_target_entropy": -6.0, "actor_entropy": 1.6004565008102902, "alpha_loss": 0.01139150366061441, "alpha_value": 0.07894908541220781, "duration": 25.719417333602905, "step": 66875}
{"episode_reward": 413.17492492695425, "episode": 536.0, "batch_reward": 2.5825232696533202, "critic_loss": 8.33615711593628, "actor_loss": -254.0903517200101, "actor_target_entropy": -6.0, "actor_entropy": 1.595196097127853, "alpha_loss": 0.005706915139941679, "alpha_value": 0.07871221826907408, "duration": 25.580045223236084, "step": 67000}
{"episode_reward": 465.8149175977433, "episode": 537.0, "batch_reward": 2.59523268699646, "critic_loss": 8.28895394897461, "actor_loss": -254.32029772561694, "actor_target_entropy": -6.0, "actor_entropy": 1.6547462277942233, "alpha_loss": 0.004645449068722507, "alpha_value": 0.07852003374722619, "duration": 25.701221704483032, "step": 67125}
{"episode_reward": 445.8507410560703, "episode": 538.0, "batch_reward": 2.5946840209960937, "critic_loss": 8.238431121826173, "actor_loss": -253.98217921103202, "actor_target_entropy": -6.0, "actor_entropy": 1.5543628565726741, "alpha_loss": 0.0021234441120477933, "alpha_value": 0.07849755261738071, "duration": 25.66098928451538, "step": 67250}
{"episode_reward": 430.9351888966831, "episode": 539.0, "batch_reward": 2.5990977725982667, "critic_loss": 8.444316104888916, "actor_loss": -254.82669164264013, "actor_target_entropy": -6.0, "actor_entropy": 1.725032787474375, "alpha_loss": 0.0021661828652704282, "alpha_value": 0.07835293934130606, "duration": 25.851482629776, "step": 67375}
{"episode_reward": 425.41979447687277, "episode": 540.0, "batch_reward": 2.60558233833313, "critic_loss": 8.70389457321167, "actor_loss": -255.1940915507655, "actor_target_entropy": -6.0, "actor_entropy": 1.586894191080524, "alpha_loss": -0.0006559082408315472, "alpha_value": 0.0784105935368779, "duration": 25.65278959274292, "step": 67500}
{"episode_reward": 457.88699815558533, "episode": 541.0, "batch_reward": 2.6052688388824463, "critic_loss": 8.856484375, "actor_loss": -255.05523294115824, "actor_target_entropy": -6.0, "actor_entropy": 1.6556640901262798, "alpha_loss": -0.004782133968546987, "alpha_value": 0.07846709696762753, "duration": 25.720479726791382, "step": 67625}
{"episode_reward": 396.6201097137486, "episode": 542.0, "batch_reward": 2.6033087215423585, "critic_loss": 8.071401508331299, "actor_loss": -255.28392471805697, "actor_target_entropy": -6.0, "actor_entropy": 1.7047725608271938, "alpha_loss": 0.0007369039568959945, "alpha_value": 0.07851520044838146, "duration": 25.627034187316895, "step": 67750}
{"episode_reward": 449.8337837082949, "episode": 543.0, "batch_reward": 2.6136603088378907, "critic_loss": 8.725034484863281, "actor_loss": -255.58609856499567, "actor_target_entropy": -6.0, "actor_entropy": 1.5365914976786053, "alpha_loss": -0.001315293946332993, "alpha_value": 0.07853519766479446, "duration": 25.684343338012695, "step": 67875}
{"episode_reward": 443.4107027635232, "episode": 544.0, "batch_reward": 2.6125882148742674, "critic_loss": 8.231055213928222, "actor_loss": -256.3014171969506, "actor_target_entropy": -6.0, "actor_entropy": 1.5928087734406995, "alpha_loss": -0.003237151289208522, "alpha_value": 0.0786545457065057, "duration": 25.621418952941895, "step": 68000}
{"episode_reward": 461.47237829962086, "episode": 545.0, "batch_reward": 2.6052200088500976, "critic_loss": 8.623126403808595, "actor_loss": -255.51200479174418, "actor_target_entropy": -6.0, "actor_entropy": 1.7784663476641216, "alpha_loss": -0.005228077394089529, "alpha_value": 0.07871907334091614, "duration": 25.69426441192627, "step": 68125}
{"episode_reward": 398.3158734665118, "episode": 546.0, "batch_reward": 2.595428743362427, "critic_loss": 8.316283042907715, "actor_loss": -255.55389822683026, "actor_target_entropy": -6.0, "actor_entropy": 1.601987571485581, "alpha_loss": -0.004359273055958892, "alpha_value": 0.07879845483611284, "duration": 25.583404064178467, "step": 68250}
{"episode_reward": 329.35081483705346, "episode": 547.0, "batch_reward": 2.6144981575012207, "critic_loss": 8.401995056152344, "actor_loss": -256.31593128991506, "actor_target_entropy": -6.0, "actor_entropy": 1.5667237024458627, "alpha_loss": 0.003207532892240182, "alpha_value": 0.07883614799066199, "duration": 25.68968105316162, "step": 68375}
{"episode_reward": 454.87360359507477, "episode": 548.0, "batch_reward": 2.613160146713257, "critic_loss": 8.396271621704102, "actor_loss": -256.2115274244739, "actor_target_entropy": -6.0, "actor_entropy": 1.6678345837900717, "alpha_loss": 0.0013746639747442978, "alpha_value": 0.07875059535333111, "duration": 25.593644618988037, "step": 68500}
{"episode_reward": 464.83158455369403, "episode": 549.0, "batch_reward": 2.616413896560669, "critic_loss": 8.830432949066163, "actor_loss": -256.39448910667784, "actor_target_entropy": -6.0, "actor_entropy": 1.6514387944388011, "alpha_loss": -0.0012720357663633804, "alpha_value": 0.07883687514726145, "duration": 25.65010905265808, "step": 68625}
{"episode_reward": 445.50044875415045, "episode": 550.0, "batch_reward": 2.6204572219848634, "critic_loss": 9.11754386138916, "actor_loss": -256.7594966273154, "actor_target_entropy": -6.0, "actor_entropy": 1.6014297969879643, "alpha_loss": -0.007057951838378945, "alpha_value": 0.07893453752523628, "duration": 25.57882595062256, "step": 68750}
{"episode_reward": 422.1044673023981, "episode": 551.0, "batch_reward": 2.6240135288238524, "critic_loss": 8.929869750976563, "actor_loss": -256.5559726291233, "actor_target_entropy": -6.0, "actor_entropy": 1.7561481320668781, "alpha_loss": -0.0027703257159344733, "alpha_value": 0.07900791067223097, "duration": 25.655139207839966, "step": 68875}
{"episode_reward": 435.2867969842708, "episode": 552.0, "batch_reward": 2.6176377334594725, "critic_loss": 8.442165050506592, "actor_loss": -257.25612148161855, "actor_target_entropy": -6.0, "actor_entropy": 1.6854055639236205, "alpha_loss": -0.0017319830893088252, "alpha_value": 0.0790661982008292, "duration": 25.56609606742859, "step": 69000}
{"episode_reward": 404.4501213924943, "episode": 553.0, "batch_reward": 2.6199902687072756, "critic_loss": 7.719463813781738, "actor_loss": -257.457276117234, "actor_target_entropy": -6.0, "actor_entropy": 1.696595065177433, "alpha_loss": -0.002914856971492843, "alpha_value": 0.07914109411701044, "duration": 25.64043164253235, "step": 69125}
{"episode_reward": 450.66960448163326, "episode": 554.0, "batch_reward": 2.6167224960327147, "critic_loss": 7.919530784606933, "actor_loss": -257.67916943950036, "actor_target_entropy": -6.0, "actor_entropy": 1.7219481160563808, "alpha_loss": -0.007846548683911322, "alpha_value": 0.07928588488736135, "duration": 25.566996335983276, "step": 69250}
{"episode_reward": 430.3578794709002, "episode": 555.0, "batch_reward": 2.6189072494506838, "critic_loss": 8.078563728332519, "actor_loss": -257.4093986390129, "actor_target_entropy": -6.0, "actor_entropy": 1.8058348818430825, "alpha_loss": -0.007119977467929915, "alpha_value": 0.07946883952471681, "duration": 25.658588886260986, "step": 69375}
{"episode_reward": 439.42509482747414, "episode": 556.0, "batch_reward": 2.6246753234863283, "critic_loss": 8.499595500946045, "actor_loss": -257.46197928151776, "actor_target_entropy": -6.0, "actor_entropy": 1.6708226723055686, "alpha_loss": 0.002176127593678933, "alpha_value": 0.07964066112698868, "duration": 25.58117961883545, "step": 69500}
{"episode_reward": 429.1344189655703, "episode": 557.0, "batch_reward": 2.6286523895263674, "critic_loss": 8.824150802612305, "actor_loss": -258.64076426672557, "actor_target_entropy": -6.0, "actor_entropy": 1.6097585303442818, "alpha_loss": -0.0037080193130624673, "alpha_value": 0.07957881600787234, "duration": 25.634154796600342, "step": 69625}
{"episode_reward": 474.66474180971545, "episode": 558.0, "batch_reward": 2.6210709247589112, "critic_loss": 8.191736282348632, "actor_loss": -258.2321075931672, "actor_target_entropy": -6.0, "actor_entropy": 1.6721010977222073, "alpha_loss": -0.0026474841645047547, "alpha_value": 0.07970333513455584, "duration": 25.58855414390564, "step": 69750}
{"episode_reward": 362.7054774978228, "episode": 559.0, "batch_reward": 2.6284123725891115, "critic_loss": 8.615440368652344, "actor_loss": -258.5410512288411, "actor_target_entropy": -6.0, "actor_entropy": 1.6021976735856798, "alpha_loss": 0.007599300047057489, "alpha_value": 0.07964484571481617, "duration": 25.61906361579895, "step": 69875}
{"episode_reward": 449.33163220004553, "episode": 560.0, "batch_reward": 2.638901212692261, "critic_loss": 8.554407958984376, "actor_loss": -258.89053320115613, "actor_target_entropy": -6.0, "actor_entropy": 1.6502597197409599, "alpha_loss": -3.81583550704583e-05, "alpha_value": 0.0795528585386149, "step": 70000}
{"duration": 36.33030343055725, "step": 70000}
{"episode_reward": 464.50010625764185, "episode": 561.0, "batch_reward": 2.625135223388672, "critic_loss": 7.96184243774414, "actor_loss": -259.143554445297, "actor_target_entropy": -6.0, "actor_entropy": 1.5905748416507055, "alpha_loss": 0.00027906152951930253, "alpha_value": 0.07951437378515018, "duration": 25.69007658958435, "step": 70125}
{"episode_reward": 446.4021310921624, "episode": 562.0, "batch_reward": 2.630495922088623, "critic_loss": 7.862927478790283, "actor_loss": -258.75067803167525, "actor_target_entropy": -6.0, "actor_entropy": 1.6234597794471248, "alpha_loss": 0.006066053275830082, "alpha_value": 0.07942920502921975, "duration": 25.633302450180054, "step": 70250}
{"episode_reward": 426.2806861947643, "episode": 563.0, "batch_reward": 2.6401045932769773, "critic_loss": 7.860901504516602, "actor_loss": -259.1486499120319, "actor_target_entropy": -6.0, "actor_entropy": 1.5634737544589572, "alpha_loss": 0.0010756344408802097, "alpha_value": 0.07934817115791908, "duration": 25.681966066360474, "step": 70375}
{"episode_reward": 455.96591669900823, "episode": 564.0, "batch_reward": 2.6340458641052247, "critic_loss": 9.477176887512208, "actor_loss": -259.6429258777249, "actor_target_entropy": -6.0, "actor_entropy": 1.6679591978749921, "alpha_loss": -0.008825057967295569, "alpha_value": 0.07939387330684974, "duration": 25.553076028823853, "step": 70500}
{"episode_reward": 454.68957917942834, "episode": 565.0, "batch_reward": 2.6330631103515625, "critic_loss": 9.205686748504638, "actor_loss": -259.690906100803, "actor_target_entropy": -6.0, "actor_entropy": 1.6277635835465931, "alpha_loss": 0.0004195791284834582, "alpha_value": 0.0795839113455771, "duration": 26.06580138206482, "step": 70625}
{"episode_reward": 415.0148495231792, "episode": 566.0, "batch_reward": 2.6366606788635254, "critic_loss": 9.031988208770752, "actor_loss": -260.037468940981, "actor_target_entropy": -6.0, "actor_entropy": 1.6708340914018693, "alpha_loss": 0.0027449804962792943, "alpha_value": 0.07952327406998635, "duration": 26.081573247909546, "step": 70750}
{"episode_reward": 320.4938777192659, "episode": 567.0, "batch_reward": 2.644707187652588, "critic_loss": 8.362300132751464, "actor_loss": -260.4661884610615, "actor_target_entropy": -6.0, "actor_entropy": 1.773774126219371, "alpha_loss": -0.0047015504826540275, "alpha_value": 0.07950279528722726, "duration": 25.916179418563843, "step": 70875}
{"episode_reward": 478.3055651598217, "episode": 568.0, "batch_reward": 2.642514451980591, "critic_loss": 8.210061252593993, "actor_loss": -260.502935594128, "actor_target_entropy": -6.0, "actor_entropy": 1.7140778476192104, "alpha_loss": 0.006137258974054168, "alpha_value": 0.07946675082376939, "duration": 25.780129194259644, "step": 71000}
{"episode_reward": 448.1593817806704, "episode": 569.0, "batch_reward": 2.6445729751586913, "critic_loss": 8.015304611206055, "actor_loss": -260.71290709480405, "actor_target_entropy": -6.0, "actor_entropy": 1.7082566401315114, "alpha_loss": -0.009701460374460097, "alpha_value": 0.07952538267000152, "duration": 25.840245962142944, "step": 71125}
{"episode_reward": 460.6642834332978, "episode": 570.0, "batch_reward": 2.639256299972534, "critic_loss": 8.182430164337159, "actor_loss": -261.029537077873, "actor_target_entropy": -6.0, "actor_entropy": 1.7088320966689818, "alpha_loss": -0.004871517170085421, "alpha_value": 0.07981914717104131, "duration": 26.019952297210693, "step": 71250}
{"episode_reward": 306.3249992039302, "episode": 571.0, "batch_reward": 2.640769762039185, "critic_loss": 10.558200775146485, "actor_loss": -260.4553418840681, "actor_target_entropy": -6.0, "actor_entropy": 1.5574056856215945, "alpha_loss": -0.0020778017739454904, "alpha_value": 0.07985447001973817, "duration": 25.91649293899536, "step": 71375}
{"episode_reward": 230.04025303091817, "episode": 572.0, "batch_reward": 2.6409194755554197, "critic_loss": 11.484103397369385, "actor_loss": -260.89678512081025, "actor_target_entropy": -6.0, "actor_entropy": 1.745762417393346, "alpha_loss": -0.010242659944079576, "alpha_value": 0.0799975596359955, "duration": 25.7471764087677, "step": 71500}
{"episode_reward": 490.78571737669796, "episode": 573.0, "batch_reward": 2.6430392608642577, "critic_loss": 11.58662890625, "actor_loss": -260.5199686686198, "actor_target_entropy": -6.0, "actor_entropy": 1.7161023068049597, "alpha_loss": -0.0005674230356124186, "alpha_value": 0.08013639941305033, "duration": 25.858640670776367, "step": 71625}
{"episode_reward": 474.4327580388318, "episode": 574.0, "batch_reward": 2.6405043487548827, "critic_loss": 10.668032627105713, "actor_loss": -260.51272533785914, "actor_target_entropy": -6.0, "actor_entropy": 1.7033799444475481, "alpha_loss": 0.0001806169898519593, "alpha_value": 0.08020071985500048, "duration": 25.83945631980896, "step": 71750}
{"episode_reward": 428.2942946804413, "episode": 575.0, "batch_reward": 2.637989128112793, "critic_loss": 11.154364803314209, "actor_loss": -260.7494095090836, "actor_target_entropy": -6.0, "actor_entropy": 1.7778656747606065, "alpha_loss": 0.0058000703593568195, "alpha_value": 0.08016825699531988, "duration": 25.70676875114441, "step": 71875}
{"episode_reward": 444.09347483123804, "episode": 576.0, "batch_reward": 2.656852039337158, "critic_loss": 11.88518134689331, "actor_loss": -261.71883859942034, "actor_target_entropy": -6.0, "actor_entropy": 1.8045788849553754, "alpha_loss": -0.005997746700285783, "alpha_value": 0.08008076142793037, "duration": 25.867428302764893, "step": 72000}
{"episode_reward": 441.41979194113276, "episode": 577.0, "batch_reward": 2.6547701930999756, "critic_loss": 12.181840751647949, "actor_loss": -261.4306936112661, "actor_target_entropy": -6.0, "actor_entropy": 1.7636876598237052, "alpha_loss": -0.0028825835990054266, "alpha_value": 0.08014951852580716, "duration": 25.96843147277832, "step": 72125}
{"episode_reward": 421.17425575610855, "episode": 578.0, "batch_reward": 2.6530854206085204, "critic_loss": 10.494302978515625, "actor_loss": -262.02498995873236, "actor_target_entropy": -6.0, "actor_entropy": 1.7956640585776298, "alpha_loss": -0.00458616778186913, "alpha_value": 0.08033608170307321, "duration": 25.769387006759644, "step": 72250}
{"episode_reward": 395.86728788349063, "episode": 579.0, "batch_reward": 2.657498586654663, "critic_loss": 9.353827098846436, "actor_loss": -262.0662120031932, "actor_target_entropy": -6.0, "actor_entropy": 1.7645456544936649, "alpha_loss": -0.0071216463111341, "alpha_value": 0.08052189730924095, "duration": 25.78435182571411, "step": 72375}
{"episode_reward": 456.7611013479172, "episode": 580.0, "batch_reward": 2.6567840919494627, "critic_loss": 10.185196701049804, "actor_loss": -262.2193893924836, "actor_target_entropy": -6.0, "actor_entropy": 1.768121588614679, "alpha_loss": -0.0010154641631449903, "alpha_value": 0.08065918920498127, "duration": 25.728629112243652, "step": 72500}
{"episode_reward": 486.0970191589147, "episode": 581.0, "batch_reward": 2.662842544555664, "critic_loss": 11.01304069519043, "actor_loss": -262.5294218517485, "actor_target_entropy": -6.0, "actor_entropy": 1.6543676493659851, "alpha_loss": -0.0028313487428166563, "alpha_value": 0.08066201861270408, "duration": 25.76636576652527, "step": 72625}
{"episode_reward": 452.17612633612697, "episode": 582.0, "batch_reward": 2.655704586029053, "critic_loss": 10.411773429870605, "actor_loss": -262.18412190098917, "actor_target_entropy": -6.0, "actor_entropy": 1.7009880177436336, "alpha_loss": -0.004081109050481069, "alpha_value": 0.08077226446716831, "duration": 25.699089288711548, "step": 72750}
{"episode_reward": 443.9179008843174, "episode": 583.0, "batch_reward": 2.6649008846282958, "critic_loss": 10.402353923797607, "actor_loss": -262.9891870892237, "actor_target_entropy": -6.0, "actor_entropy": 1.7017641313492307, "alpha_loss": -0.004542180614191152, "alpha_value": 0.08084993300944078, "duration": 25.767292976379395, "step": 72875}
{"episode_reward": 456.0331575562329, "episode": 584.0, "batch_reward": 2.670415283203125, "critic_loss": 9.752756790161133, "actor_loss": -263.3892074092742, "actor_target_entropy": -6.0, "actor_entropy": 1.676044064183389, "alpha_loss": -0.0005283003575318764, "alpha_value": 0.08094518226765246, "duration": 25.66748070716858, "step": 73000}
{"episode_reward": 483.1191795000245, "episode": 585.0, "batch_reward": 2.6664038887023924, "critic_loss": 10.044476142883301, "actor_loss": -263.7494395422557, "actor_target_entropy": -6.0, "actor_entropy": 1.7071347482620725, "alpha_loss": -0.0019440138934268838, "alpha_value": 0.080930256352737, "duration": 25.852972984313965, "step": 73125}
{"episode_reward": 454.320541923607, "episode": 586.0, "batch_reward": 2.670935377120972, "critic_loss": 9.685893558502197, "actor_loss": -263.2451747771232, "actor_target_entropy": -6.0, "actor_entropy": 1.7092209612169573, "alpha_loss": -0.002705132506126838, "alpha_value": 0.08095906130078405, "duration": 25.655316591262817, "step": 73250}
{"episode_reward": 444.4825204322882, "episode": 587.0, "batch_reward": 2.6675470581054688, "critic_loss": 9.936614086151122, "actor_loss": -263.6914556594122, "actor_target_entropy": -6.0, "actor_entropy": 1.8338661818277269, "alpha_loss": -0.003940667365751569, "alpha_value": 0.08108483693508291, "duration": 25.734395027160645, "step": 73375}
{"episode_reward": 493.0189852896958, "episode": 588.0, "batch_reward": 2.670664451599121, "critic_loss": 9.743845191955566, "actor_loss": -263.73050468198716, "actor_target_entropy": -6.0, "actor_entropy": 1.7493061000300991, "alpha_loss": 0.001201041542264002, "alpha_value": 0.08119381065076992, "duration": 25.65582299232483, "step": 73500}
{"episode_reward": 458.8490101270893, "episode": 589.0, "batch_reward": 2.6628140411376955, "critic_loss": 10.015682411193847, "actor_loss": -264.0990518236917, "actor_target_entropy": -6.0, "actor_entropy": 1.6786085953788152, "alpha_loss": -0.0003909963582243238, "alpha_value": 0.08116146646427796, "duration": 25.68376326560974, "step": 73625}
{"episode_reward": 455.41886172153295, "episode": 590.0, "batch_reward": 2.6766050415039064, "critic_loss": 9.643541458129883, "actor_loss": -263.5287775839529, "actor_target_entropy": -6.0, "actor_entropy": 1.6409449308149275, "alpha_loss": 0.008734838751655432, "alpha_value": 0.08104916616060832, "duration": 25.788790702819824, "step": 73750}
{"episode_reward": 461.29878736837145, "episode": 591.0, "batch_reward": 2.6691439323425294, "critic_loss": 9.501772834777832, "actor_loss": -263.90433804951016, "actor_target_entropy": -6.0, "actor_entropy": 1.718881056422279, "alpha_loss": -0.0005092367433780242, "alpha_value": 0.08088525371768022, "duration": 25.754148244857788, "step": 73875}
{"episode_reward": 455.92527563107046, "episode": 592.0, "batch_reward": 2.6841106243133543, "critic_loss": 9.7042052154541, "actor_loss": -264.28723242975053, "actor_target_entropy": -6.0, "actor_entropy": 1.805027848289859, "alpha_loss": -0.01010079506123739, "alpha_value": 0.08101734803712421, "duration": 25.772260904312134, "step": 74000}
{"episode_reward": 439.75184809127, "episode": 593.0, "batch_reward": 2.677533103942871, "critic_loss": 10.023120105743407, "actor_loss": -264.9758082798549, "actor_target_entropy": -6.0, "actor_entropy": 1.7241162951030429, "alpha_loss": 0.002046548391854952, "alpha_value": 0.0811757034923335, "duration": 25.736660957336426, "step": 74125}
{"episode_reward": 470.91027714640023, "episode": 594.0, "batch_reward": 2.68725657081604, "critic_loss": 9.799970985412598, "actor_loss": -264.937742663968, "actor_target_entropy": -6.0, "actor_entropy": 1.749244209258787, "alpha_loss": 0.004149154654794162, "alpha_value": 0.081112026605636, "duration": 25.63397526741028, "step": 74250}
{"episode_reward": 429.78295787696203, "episode": 595.0, "batch_reward": 2.6780857791900634, "critic_loss": 10.569706199645996, "actor_loss": -264.80591062515504, "actor_target_entropy": -6.0, "actor_entropy": 1.7900047661766174, "alpha_loss": -0.004485982011944529, "alpha_value": 0.08112173463967313, "duration": 25.75315499305725, "step": 74375}
{"episode_reward": 454.4075943662085, "episode": 596.0, "batch_reward": 2.6783836879730223, "critic_loss": 10.054533897399903, "actor_loss": -264.95882834157635, "actor_target_entropy": -6.0, "actor_entropy": 1.8144845212659528, "alpha_loss": 0.001991912084180982, "alpha_value": 0.08111003230066359, "duration": 25.865278959274292, "step": 74500}
{"episode_reward": 441.69459859257296, "episode": 597.0, "batch_reward": 2.689036289215088, "critic_loss": 10.675874477386474, "actor_loss": -265.4269530281188, "actor_target_entropy": -6.0, "actor_entropy": 1.7761982944276598, "alpha_loss": -0.004255260529351376, "alpha_value": 0.08119643407291416, "duration": 25.82381796836853, "step": 74625}
{"episode_reward": 467.8527567393027, "episode": 598.0, "batch_reward": 2.6837296047210693, "critic_loss": 9.867483448028564, "actor_loss": -265.499268070344, "actor_target_entropy": -6.0, "actor_entropy": 1.899518528292256, "alpha_loss": 0.004027663209971281, "alpha_value": 0.08120320403013044, "duration": 25.700178384780884, "step": 74750}
{"episode_reward": 431.1563324505757, "episode": 599.0, "batch_reward": 2.6790273780822753, "critic_loss": 10.39160391998291, "actor_loss": -265.3656466045077, "actor_target_entropy": -6.0, "actor_entropy": 1.8268238533110845, "alpha_loss": 0.005213102044922019, "alpha_value": 0.08099756115867629, "duration": 25.757338762283325, "step": 74875}
{"episode_reward": 478.96545028521894, "episode": 600.0, "batch_reward": 2.6954171352386473, "critic_loss": 9.510218852996827, "actor_loss": -265.90792895901586, "actor_target_entropy": -6.0, "actor_entropy": 1.9197953324164114, "alpha_loss": -0.0012168819272530176, "alpha_value": 0.08098540723505471, "step": 75000}
{"duration": 36.46377396583557, "step": 75000}
{"episode_reward": 453.4451902390906, "episode": 601.0, "batch_reward": 2.699932191848755, "critic_loss": 9.503086910247802, "actor_loss": -265.7705712696863, "actor_target_entropy": -6.0, "actor_entropy": 1.818777846911597, "alpha_loss": -0.0022079364270977085, "alpha_value": 0.08104360147712643, "duration": 25.824496507644653, "step": 75125}
{"episode_reward": 452.3703953536577, "episode": 602.0, "batch_reward": 2.6927693119049074, "critic_loss": 9.677476081848145, "actor_loss": -266.33208982406126, "actor_target_entropy": -6.0, "actor_entropy": 1.8598496337090769, "alpha_loss": -0.013759418841331236, "alpha_value": 0.08126006297904982, "duration": 25.68405771255493, "step": 75250}
{"episode_reward": 483.96655645747484, "episode": 603.0, "batch_reward": 2.690909954071045, "critic_loss": 9.341742603302002, "actor_loss": -266.6434854174417, "actor_target_entropy": -6.0, "actor_entropy": 1.7991708119710286, "alpha_loss": -0.007416888443191373, "alpha_value": 0.08148063240094576, "duration": 25.74248719215393, "step": 75375}
{"episode_reward": 461.04999734666853, "episode": 604.0, "batch_reward": 2.7110692462921144, "critic_loss": 8.792414016723633, "actor_loss": -267.3346400107107, "actor_target_entropy": -6.0, "actor_entropy": 1.7399738123339992, "alpha_loss": 0.0012786674253161877, "alpha_value": 0.08163892977072525, "duration": 25.638143062591553, "step": 75500}
{"episode_reward": 471.44876163300387, "episode": 605.0, "batch_reward": 2.690933988571167, "critic_loss": 8.785136993408203, "actor_loss": -266.44520350864957, "actor_target_entropy": -6.0, "actor_entropy": 1.8062235854920887, "alpha_loss": -0.0027698258654997934, "alpha_value": 0.0816246470825107, "duration": 25.779592275619507, "step": 75625}
{"episode_reward": 450.3047086984909, "episode": 606.0, "batch_reward": 2.693216272354126, "critic_loss": 8.929630405426025, "actor_loss": -267.2153851909022, "actor_target_entropy": -6.0, "actor_entropy": 1.6964073104243125, "alpha_loss": -0.0013385892849445582, "alpha_value": 0.08172780585387167, "duration": 25.678287506103516, "step": 75750}
{"episode_reward": 451.734300400315, "episode": 607.0, "batch_reward": 2.7009168014526366, "critic_loss": 8.459886154174805, "actor_loss": -267.35792081318203, "actor_target_entropy": -6.0, "actor_entropy": 1.734515731296842, "alpha_loss": -6.339818771396364e-05, "alpha_value": 0.08170095816313189, "duration": 25.692322254180908, "step": 75875}
{"episode_reward": 441.5622871279049, "episode": 608.0, "batch_reward": 2.690137128829956, "critic_loss": 9.027687118530274, "actor_loss": -267.41488352129534, "actor_target_entropy": -6.0, "actor_entropy": 1.7458583212667895, "alpha_loss": 0.001583904215705491, "alpha_value": 0.08166942040099691, "duration": 25.669273376464844, "step": 76000}
{"episode_reward": 488.03225391353135, "episode": 609.0, "batch_reward": 2.71012947845459, "critic_loss": 8.369883937835693, "actor_loss": -267.75194198366194, "actor_target_entropy": -6.0, "actor_entropy": 1.8051936020926824, "alpha_loss": 0.001064169630851774, "alpha_value": 0.08166388131634719, "duration": 25.89053201675415, "step": 76125}
{"episode_reward": 475.766039917553, "episode": 610.0, "batch_reward": 2.7033780841827393, "critic_loss": 8.370054908752442, "actor_loss": -267.8517032746346, "actor_target_entropy": -6.0, "actor_entropy": 1.7874085191757447, "alpha_loss": -0.0032198391291463086, "alpha_value": 0.08170363761877587, "duration": 25.638194799423218, "step": 76250}
{"episode_reward": 480.56111763845513, "episode": 611.0, "batch_reward": 2.7056615467071534, "critic_loss": 8.262009635925294, "actor_loss": -268.06412808857266, "actor_target_entropy": -6.0, "actor_entropy": 1.774391215945047, "alpha_loss": 0.011558630710674657, "alpha_value": 0.08164433467936585, "duration": 25.737772941589355, "step": 76375}
{"episode_reward": 473.1695364170522, "episode": 612.0, "batch_reward": 2.713024070739746, "critic_loss": 8.753617153167724, "actor_loss": -268.0813731531943, "actor_target_entropy": -6.0, "actor_entropy": 1.8286680463821656, "alpha_loss": 0.0034852879227048926, "alpha_value": 0.08135293026797288, "duration": 25.64140772819519, "step": 76500}
{"episode_reward": 424.5850733557443, "episode": 613.0, "batch_reward": 2.7150345993041993, "critic_loss": 8.278702335357666, "actor_loss": -268.4177822536892, "actor_target_entropy": -6.0, "actor_entropy": 1.7721370685668218, "alpha_loss": -0.0029439975189725085, "alpha_value": 0.08135746979844848, "duration": 25.711879014968872, "step": 76625}
{"episode_reward": 444.12993130058106, "episode": 614.0, "batch_reward": 2.713165559768677, "critic_loss": 8.3270439453125, "actor_loss": -268.33333513813636, "actor_target_entropy": -6.0, "actor_entropy": 1.7329540810277384, "alpha_loss": 0.004719271519852262, "alpha_value": 0.08132080014294771, "duration": 25.610528469085693, "step": 76750}
{"episode_reward": 469.6288490338413, "episode": 615.0, "batch_reward": 2.709574062347412, "critic_loss": 9.122190643310548, "actor_loss": -268.67325894794766, "actor_target_entropy": -6.0, "actor_entropy": 1.8388793998294406, "alpha_loss": 0.0014464302516971079, "alpha_value": 0.0812473677295533, "duration": 25.758622646331787, "step": 76875}
{"episode_reward": 482.94390868740203, "episode": 616.0, "batch_reward": 2.7163052139282224, "critic_loss": 8.681956127166748, "actor_loss": -268.78714924473917, "actor_target_entropy": -6.0, "actor_entropy": 1.8243941010967377, "alpha_loss": 0.006980757623340094, "alpha_value": 0.08122425780407078, "duration": 25.667768239974976, "step": 77000}
{"episode_reward": 454.32040198886295, "episode": 617.0, "batch_reward": 2.7178178691864012, "critic_loss": 8.414064624786377, "actor_loss": -269.1628703768291, "actor_target_entropy": -6.0, "actor_entropy": 1.8313509774586512, "alpha_loss": 0.007256277666855899, "alpha_value": 0.08098959683576976, "duration": 25.751879930496216, "step": 77125}
{"episode_reward": 447.18308742022896, "episode": 618.0, "batch_reward": 2.711406436920166, "critic_loss": 9.401603492736816, "actor_loss": -269.10331381520916, "actor_target_entropy": -6.0, "actor_entropy": 1.692033287017576, "alpha_loss": -0.0003396286629140377, "alpha_value": 0.0807954821794109, "duration": 26.017677783966064, "step": 77250}
{"episode_reward": 469.1825588437354, "episode": 619.0, "batch_reward": 2.7220545024871825, "critic_loss": 9.373983066558838, "actor_loss": -269.33453175378224, "actor_target_entropy": -6.0, "actor_entropy": 1.72964808865199, "alpha_loss": 0.0018011556221320041, "alpha_value": 0.08084440840532785, "duration": 25.755938053131104, "step": 77375}
{"episode_reward": 472.869568793262, "episode": 620.0, "batch_reward": 2.719322195053101, "critic_loss": 8.272277046203614, "actor_loss": -270.0316536195817, "actor_target_entropy": -6.0, "actor_entropy": 1.75602352042352, "alpha_loss": -0.001254814138050161, "alpha_value": 0.08083494443447595, "duration": 25.67333173751831, "step": 77500}
{"episode_reward": 440.78545656106166, "episode": 621.0, "batch_reward": 2.7228587818145753, "critic_loss": 8.392101192474366, "actor_loss": -270.06275867280505, "actor_target_entropy": -6.0, "actor_entropy": 1.877000617602515, "alpha_loss": -0.002973887749711081, "alpha_value": 0.0808593272850575, "duration": 25.741957187652588, "step": 77625}
{"episode_reward": 423.0448623595323, "episode": 622.0, "batch_reward": 2.7254579639434815, "critic_loss": 10.514349494934082, "actor_loss": -270.1364475373299, "actor_target_entropy": -6.0, "actor_entropy": 1.8865967777467543, "alpha_loss": -0.00702925743309841, "alpha_value": 0.08097316807212364, "duration": 25.646708488464355, "step": 77750}
{"episode_reward": 458.81279613557666, "episode": 623.0, "batch_reward": 2.723383047103882, "critic_loss": 10.324778755187989, "actor_loss": -270.1481507316468, "actor_target_entropy": -6.0, "actor_entropy": 1.9454351436524164, "alpha_loss": -0.008285544990074067, "alpha_value": 0.08116173250458127, "duration": 25.68116807937622, "step": 77875}
{"episode_reward": 484.4520110812177, "episode": 624.0, "batch_reward": 2.7193341407775877, "critic_loss": 8.451403240203858, "actor_loss": -269.7922865344632, "actor_target_entropy": -6.0, "actor_entropy": 1.8790978116373862, "alpha_loss": -0.0012068027900832316, "alpha_value": 0.08132292158813045, "duration": 25.970078229904175, "step": 78000}
{"episode_reward": 472.6186109965907, "episode": 625.0, "batch_reward": 2.7298574829101563, "critic_loss": 8.926192989349365, "actor_loss": -270.64764113653274, "actor_target_entropy": -6.0, "actor_entropy": 1.853734739243038, "alpha_loss": 0.003269400776526521, "alpha_value": 0.0813296300867637, "duration": 25.730066776275635, "step": 78125}
{"episode_reward": 479.78691774959896, "episode": 626.0, "batch_reward": 2.724310359954834, "critic_loss": 8.951186298370361, "actor_loss": -270.73277528824343, "actor_target_entropy": -6.0, "actor_entropy": 1.9121218362162191, "alpha_loss": -0.0026659483705917674, "alpha_value": 0.08128250612545695, "duration": 25.67652940750122, "step": 78250}
{"episode_reward": 480.55305097016486, "episode": 627.0, "batch_reward": 2.7332591724395754, "critic_loss": 8.259418506622314, "actor_loss": -270.71558925083707, "actor_target_entropy": -6.0, "actor_entropy": 1.8616366745933655, "alpha_loss": 0.0064045194211223766, "alpha_value": 0.08118601041412118, "duration": 25.693127870559692, "step": 78375}
{"episode_reward": 468.1251697385195, "episode": 628.0, "batch_reward": 2.7349013023376463, "critic_loss": 8.065665523529052, "actor_loss": -270.8412569107548, "actor_target_entropy": -6.0, "actor_entropy": 1.7965813836743754, "alpha_loss": 0.0029500919251492425, "alpha_value": 0.08114820613064506, "duration": 25.76649761199951, "step": 78500}
{"episode_reward": 466.0747435924536, "episode": 629.0, "batch_reward": 2.7319083499908445, "critic_loss": 8.86032011795044, "actor_loss": -271.16268775576634, "actor_target_entropy": -6.0, "actor_entropy": 1.8356556230121188, "alpha_loss": -0.003843134871521403, "alpha_value": 0.08114186229119127, "duration": 25.815826416015625, "step": 78625}
{"episode_reward": 498.49272606155034, "episode": 630.0, "batch_reward": 2.7386640129089357, "critic_loss": 8.309026901245117, "actor_loss": -271.37689651981475, "actor_target_entropy": -6.0, "actor_entropy": 1.9071533756871377, "alpha_loss": -0.0003264932968323269, "alpha_value": 0.08118063747255513, "duration": 25.65571165084839, "step": 78750}
{"episode_reward": 425.94207548543017, "episode": 631.0, "batch_reward": 2.744209312438965, "critic_loss": 8.646689754486085, "actor_loss": -271.797860281808, "actor_target_entropy": -6.0, "actor_entropy": 1.7950275814722454, "alpha_loss": -0.00028749433020868945, "alpha_value": 0.08112261536665433, "duration": 25.779796600341797, "step": 78875}
{"episode_reward": 465.0040419761934, "episode": 632.0, "batch_reward": 2.747931406021118, "critic_loss": 8.743756839752198, "actor_loss": -272.1363525390625, "actor_target_entropy": -6.0, "actor_entropy": 1.7055243926663552, "alpha_loss": -0.00607594431588246, "alpha_value": 0.08123900632659478, "duration": 25.567025423049927, "step": 79000}
{"episode_reward": 478.93239390359497, "episode": 633.0, "batch_reward": 2.7455255661010742, "critic_loss": 8.507655296325684, "actor_loss": -271.739991203187, "actor_target_entropy": -6.0, "actor_entropy": 1.7912069634785728, "alpha_loss": 0.00028314485791183655, "alpha_value": 0.08140375271646019, "duration": 25.79400658607483, "step": 79125}
{"episode_reward": 488.30601695478947, "episode": 634.0, "batch_reward": 2.7483035774230955, "critic_loss": 9.492844589233398, "actor_loss": -272.1670502693422, "actor_target_entropy": -6.0, "actor_entropy": 1.8073012155871238, "alpha_loss": 0.0015232340853300788, "alpha_value": 0.08132145679647722, "duration": 25.55678415298462, "step": 79250}
{"episode_reward": 256.2230934643467, "episode": 635.0, "batch_reward": 2.745859525680542, "critic_loss": 9.116119632720947, "actor_loss": -272.58001805865575, "actor_target_entropy": -6.0, "actor_entropy": 1.7162537007104783, "alpha_loss": -0.0014269982154170673, "alpha_value": 0.08132987063636493, "duration": 25.797397136688232, "step": 79375}
{"episode_reward": 481.1472869111966, "episode": 636.0, "batch_reward": 2.7425401973724366, "critic_loss": 8.5915065574646, "actor_loss": -272.78453014742945, "actor_target_entropy": -6.0, "actor_entropy": 1.7466024487249312, "alpha_loss": -0.00456023107718436, "alpha_value": 0.08143857379383959, "duration": 25.618987321853638, "step": 79500}
{"episode_reward": 485.258580523409, "episode": 637.0, "batch_reward": 2.752940315246582, "critic_loss": 9.259904293060302, "actor_loss": -273.07776896158856, "actor_target_entropy": -6.0, "actor_entropy": 1.8103859613812159, "alpha_loss": 0.0004377990983249176, "alpha_value": 0.08146016586537859, "duration": 25.785992860794067, "step": 79625}
{"episode_reward": 459.835090409535, "episode": 638.0, "batch_reward": 2.747493181228638, "critic_loss": 8.64667511367798, "actor_loss": -273.0983404344128, "actor_target_entropy": -6.0, "actor_entropy": 1.8920945852033553, "alpha_loss": -0.00899213116856352, "alpha_value": 0.08165587198987814, "duration": 25.6819326877594, "step": 79750}
{"episode_reward": 482.2720307039231, "episode": 639.0, "batch_reward": 2.7496741275787353, "critic_loss": 9.143311038970948, "actor_loss": -273.4236828031994, "actor_target_entropy": -6.0, "actor_entropy": 1.8275511397255793, "alpha_loss": -0.005275955176099189, "alpha_value": 0.08176033531658555, "duration": 25.767037868499756, "step": 79875}
{"episode_reward": 468.5853873538983, "episode": 640.0, "batch_reward": 2.753243709564209, "critic_loss": 9.487747283935548, "actor_loss": -273.08541673229587, "actor_target_entropy": -6.0, "actor_entropy": 1.827046726980517, "alpha_loss": 4.016297433765665e-05, "alpha_value": 0.08191955504696075, "step": 80000}
{"duration": 36.43075132369995, "step": 80000}
{"episode_reward": 461.2643744085441, "episode": 641.0, "batch_reward": 2.750827838897705, "critic_loss": 8.884845153808595, "actor_loss": -273.5941113668775, "actor_target_entropy": -6.0, "actor_entropy": 1.7999508570110987, "alpha_loss": -0.006441834696849424, "alpha_value": 0.08190506609773712, "duration": 25.771077871322632, "step": 80125}
{"episode_reward": 423.659371044629, "episode": 642.0, "batch_reward": 2.7557324142456054, "critic_loss": 8.5383397064209, "actor_loss": -273.90524144326486, "actor_target_entropy": -6.0, "actor_entropy": 1.7504118777090503, "alpha_loss": -0.006035059266122839, "alpha_value": 0.08214307800798969, "duration": 25.593010187149048, "step": 80250}
{"episode_reward": 494.8925561525064, "episode": 643.0, "batch_reward": 2.7559949741363527, "critic_loss": 9.301799724578858, "actor_loss": -274.0973874046689, "actor_target_entropy": -6.0, "actor_entropy": 1.9010683052123538, "alpha_loss": -0.009901462887812938, "alpha_value": 0.0823060071998535, "duration": 25.69644331932068, "step": 80375}
{"episode_reward": 362.9637590881823, "episode": 644.0, "batch_reward": 2.7637690544128417, "critic_loss": 8.717757705688477, "actor_loss": -274.3294451313634, "actor_target_entropy": -6.0, "actor_entropy": 1.808613334932635, "alpha_loss": -0.001496825836628916, "alpha_value": 0.08249251430279407, "duration": 25.65249252319336, "step": 80500}
{"episode_reward": 483.28980087749864, "episode": 645.0, "batch_reward": 2.7667253494262694, "critic_loss": 9.018034713745116, "actor_loss": -274.89396304175966, "actor_target_entropy": -6.0, "actor_entropy": 1.6837470512541513, "alpha_loss": -0.007516748124053554, "alpha_value": 0.08263978168404251, "duration": 25.710443258285522, "step": 80625}
{"episode_reward": 466.88149401083973, "episode": 646.0, "batch_reward": 2.75548429107666, "critic_loss": 8.735329906463623, "actor_loss": -274.73975347703504, "actor_target_entropy": -6.0, "actor_entropy": 1.8306013076536116, "alpha_loss": -0.004184604870275625, "alpha_value": 0.08275201912878544, "duration": 25.76339340209961, "step": 80750}
{"episode_reward": 492.76827739256987, "episode": 647.0, "batch_reward": 2.76777095413208, "critic_loss": 8.6832283782959, "actor_loss": -274.9795139857701, "actor_target_entropy": -6.0, "actor_entropy": 1.8120216907016815, "alpha_loss": -0.0014277150566201833, "alpha_value": 0.08280413928049885, "duration": 25.674565315246582, "step": 80875}
{"episode_reward": 485.4949664118847, "episode": 648.0, "batch_reward": 2.760449911117554, "critic_loss": 8.675104122161866, "actor_loss": -274.7353274437689, "actor_target_entropy": -6.0, "actor_entropy": 1.8017492255856913, "alpha_loss": -0.004087504889485577, "alpha_value": 0.08298227942194483, "duration": 25.72648811340332, "step": 81000}
{"episode_reward": 487.8021597141115, "episode": 649.0, "batch_reward": 2.7746996994018556, "critic_loss": 8.441966995239257, "actor_loss": -275.4930211627294, "actor_target_entropy": -6.0, "actor_entropy": 1.85833530009739, "alpha_loss": -0.014502853968195499, "alpha_value": 0.08321176383103783, "duration": 25.674638986587524, "step": 81125}
{"episode_reward": 478.69575823579663, "episode": 650.0, "batch_reward": 2.7565997276306153, "critic_loss": 8.341825309753418, "actor_loss": -274.8751215780935, "actor_target_entropy": -6.0, "actor_entropy": 1.8544597068140585, "alpha_loss": -0.0007475438647933545, "alpha_value": 0.08340786375623609, "duration": 25.65516757965088, "step": 81250}
{"episode_reward": 463.6709409891371, "episode": 651.0, "batch_reward": 2.771009798049927, "critic_loss": 8.433355587005614, "actor_loss": -275.9559393988715, "actor_target_entropy": -6.0, "actor_entropy": 1.836385168726482, "alpha_loss": 0.0030561184754506463, "alpha_value": 0.08338376025541402, "duration": 25.76959204673767, "step": 81375}
{"episode_reward": 496.9391968066439, "episode": 652.0, "batch_reward": 2.76694517326355, "critic_loss": 9.002148769378662, "actor_loss": -275.43334271830895, "actor_target_entropy": -6.0, "actor_entropy": 1.7443452015999825, "alpha_loss": -2.9984253248380077e-05, "alpha_value": 0.08327787675504986, "duration": 25.571032524108887, "step": 81500}
{"episode_reward": 454.9040823585148, "episode": 653.0, "batch_reward": 2.764088191986084, "critic_loss": 9.877707454681396, "actor_loss": -275.71522739955356, "actor_target_entropy": -6.0, "actor_entropy": 1.7673033759707497, "alpha_loss": -0.001917520770803094, "alpha_value": 0.08337901801067782, "duration": 25.68971037864685, "step": 81625}
{"episode_reward": 462.4644020492272, "episode": 654.0, "batch_reward": 2.7728378047943116, "critic_loss": 9.194486324310303, "actor_loss": -276.02278727869833, "actor_target_entropy": -6.0, "actor_entropy": 1.7792672553370077, "alpha_loss": -0.003651861428102899, "alpha_value": 0.08342818782536274, "duration": 25.63895893096924, "step": 81750}
{"episode_reward": 459.4570119045931, "episode": 655.0, "batch_reward": 2.7654371242523195, "critic_loss": 8.314166477203369, "actor_loss": -276.15286933051215, "actor_target_entropy": -6.0, "actor_entropy": 1.830833075538514, "alpha_loss": -0.007785141833924821, "alpha_value": 0.08361809043564129, "duration": 25.676130533218384, "step": 81875}
{"episode_reward": 463.8711619725642, "episode": 656.0, "batch_reward": 2.762373624801636, "critic_loss": 8.714337238311767, "actor_loss": -276.3128863919166, "actor_target_entropy": -6.0, "actor_entropy": 1.8813056311299723, "alpha_loss": 0.005830162073365382, "alpha_value": 0.08366354896709297, "duration": 25.792646884918213, "step": 82000}
{"episode_reward": 468.1434912083261, "episode": 657.0, "batch_reward": 2.7814950332641604, "critic_loss": 7.7488537063598635, "actor_loss": -276.39697217184397, "actor_target_entropy": -6.0, "actor_entropy": 1.8071948762923953, "alpha_loss": 0.001499304658777657, "alpha_value": 0.08354234192234662, "duration": 25.70459246635437, "step": 82125}
{"episode_reward": 481.47346231321717, "episode": 658.0, "batch_reward": 2.783903326034546, "critic_loss": 7.19032897567749, "actor_loss": -276.2953919441469, "actor_target_entropy": -6.0, "actor_entropy": 1.667583446348867, "alpha_loss": -0.0006194072869426061, "alpha_value": 0.08354333595888275, "duration": 25.69226336479187, "step": 82250}
{"episode_reward": 465.13083967149805, "episode": 659.0, "batch_reward": 2.779897855758667, "critic_loss": 8.463125095367431, "actor_loss": -276.80946664961556, "actor_target_entropy": -6.0, "actor_entropy": 1.7273468687420799, "alpha_loss": -0.0018401248177276953, "alpha_value": 0.08360777573800197, "duration": 25.814812421798706, "step": 82375}
{"episode_reward": 491.41628209632836, "episode": 660.0, "batch_reward": 2.781340019226074, "critic_loss": 8.9848162651062, "actor_loss": -277.3380786526588, "actor_target_entropy": -6.0, "actor_entropy": 1.6528434714963358, "alpha_loss": -0.0016534898745556993, "alpha_value": 0.08361019531094638, "duration": 25.656211376190186, "step": 82500}
{"episode_reward": 432.50089996995297, "episode": 661.0, "batch_reward": 2.7834014472961424, "critic_loss": 8.021363235473633, "actor_loss": -277.4065755208333, "actor_target_entropy": -6.0, "actor_entropy": 1.7332165165553017, "alpha_loss": -0.001191827453791149, "alpha_value": 0.08360081269037248, "duration": 25.764520406723022, "step": 82625}
{"episode_reward": 508.0453040299684, "episode": 662.0, "batch_reward": 2.781205587387085, "critic_loss": 7.9993995094299315, "actor_loss": -277.23219003985, "actor_target_entropy": -6.0, "actor_entropy": 1.7911032130641322, "alpha_loss": -0.01108902476112088, "alpha_value": 0.08378977294181028, "duration": 25.763173580169678, "step": 82750}
{"episode_reward": 453.2790406338521, "episode": 663.0, "batch_reward": 2.7826357421875, "critic_loss": 7.692316886901856, "actor_loss": -277.17611500573537, "actor_target_entropy": -6.0, "actor_entropy": 1.7610073941094535, "alpha_loss": -0.0033154907850696455, "alpha_value": 0.08402818349440343, "duration": 25.860110998153687, "step": 82875}
{"episode_reward": 461.8828243177047, "episode": 664.0, "batch_reward": 2.7898528499603272, "critic_loss": 7.6504802284240725, "actor_loss": -277.7355292535597, "actor_target_entropy": -6.0, "actor_entropy": 1.7836805562819205, "alpha_loss": 0.001059819245710969, "alpha_value": 0.08404316324563232, "duration": 25.755294799804688, "step": 83000}
{"episode_reward": 436.61638113029124, "episode": 665.0, "batch_reward": 2.791780275344849, "critic_loss": 8.294679916381837, "actor_loss": -277.86310008215526, "actor_target_entropy": -6.0, "actor_entropy": 1.7621227067614358, "alpha_loss": -0.0022156761316139075, "alpha_value": 0.08396987714647862, "duration": 25.8207368850708, "step": 83125}
{"episode_reward": 461.0138209567815, "episode": 666.0, "batch_reward": 2.7907534217834473, "critic_loss": 8.304919845581054, "actor_loss": -278.10335516160535, "actor_target_entropy": -6.0, "actor_entropy": 1.790526638107915, "alpha_loss": -0.005043246888465459, "alpha_value": 0.08415741462452195, "duration": 25.791062116622925, "step": 83250}
{"episode_reward": 466.9538502011338, "episode": 667.0, "batch_reward": 2.788139106750488, "critic_loss": 8.810693313598632, "actor_loss": -277.6671985444568, "actor_target_entropy": -6.0, "actor_entropy": 1.820750429516747, "alpha_loss": -0.005899545086163377, "alpha_value": 0.08429769675547129, "duration": 25.782780170440674, "step": 83375}
{"episode_reward": 475.1446611025876, "episode": 668.0, "batch_reward": 2.7942874240875244, "critic_loss": 8.026950134277344, "actor_loss": -278.2906750094506, "actor_target_entropy": -6.0, "actor_entropy": 1.8341659653571345, "alpha_loss": -0.001050252970608492, "alpha_value": 0.08431407197500156, "duration": 25.798580646514893, "step": 83500}
{"episode_reward": 482.0330261805242, "episode": 669.0, "batch_reward": 2.794011121749878, "critic_loss": 8.30177156829834, "actor_loss": -278.53234233553445, "actor_target_entropy": -6.0, "actor_entropy": 1.7863767639039054, "alpha_loss": -0.003170193226579281, "alpha_value": 0.08447740774883514, "duration": 25.78827476501465, "step": 83625}
{"episode_reward": 456.90579878784945, "episode": 670.0, "batch_reward": 2.7857968273162843, "critic_loss": 9.443425533294677, "actor_loss": -278.5446585378339, "actor_target_entropy": -6.0, "actor_entropy": 1.8235585362680498, "alpha_loss": 0.004394863206412523, "alpha_value": 0.08446218381189072, "duration": 25.836055040359497, "step": 83750}
{"episode_reward": 207.04355605242597, "episode": 671.0, "batch_reward": 2.7997177753448486, "critic_loss": 10.14084769821167, "actor_loss": -278.8852044968378, "actor_target_entropy": -6.0, "actor_entropy": 1.794842693540785, "alpha_loss": -0.004646750381364236, "alpha_value": 0.08446065395433602, "duration": 25.809301376342773, "step": 83875}
{"episode_reward": 267.91897757751167, "episode": 672.0, "batch_reward": 2.7913482189178467, "critic_loss": 11.52663782119751, "actor_loss": -278.61202363044987, "actor_target_entropy": -6.0, "actor_entropy": 1.9027445431678527, "alpha_loss": 0.001291625190436119, "alpha_value": 0.08440352133766059, "duration": 25.731630325317383, "step": 84000}
{"episode_reward": 474.23253061532506, "episode": 673.0, "batch_reward": 2.7975261116027834, "critic_loss": 9.89301335144043, "actor_loss": -278.7561689104353, "actor_target_entropy": -6.0, "actor_entropy": 1.760319223479619, "alpha_loss": 0.003946239926985332, "alpha_value": 0.08438051169206509, "duration": 25.81282639503479, "step": 84125}
{"episode_reward": 492.36810738852233, "episode": 674.0, "batch_reward": 2.7853316688537597, "critic_loss": 10.63420516204834, "actor_loss": -278.298585953251, "actor_target_entropy": -6.0, "actor_entropy": 1.8501871939628356, "alpha_loss": 0.008972714816580617, "alpha_value": 0.08429063437922009, "duration": 25.746644020080566, "step": 84250}
{"episode_reward": 441.80683558948544, "episode": 675.0, "batch_reward": 2.7947640056610106, "critic_loss": 13.546595600128175, "actor_loss": -279.34415351019965, "actor_target_entropy": -6.0, "actor_entropy": 1.7971338866248963, "alpha_loss": -0.006686625558705557, "alpha_value": 0.08418360862256488, "duration": 25.852607488632202, "step": 84375}
{"episode_reward": 327.4402300693087, "episode": 676.0, "batch_reward": 2.7987896575927733, "critic_loss": 10.394214065551758, "actor_loss": -279.6260454731603, "actor_target_entropy": -6.0, "actor_entropy": 1.8155296021892178, "alpha_loss": -0.00616132338989466, "alpha_value": 0.08434225922009111, "duration": 25.73377299308777, "step": 84500}
{"episode_reward": 450.30664233279344, "episode": 677.0, "batch_reward": 2.7960910301208495, "critic_loss": 10.011356624603271, "actor_loss": -279.6945524669829, "actor_target_entropy": -6.0, "actor_entropy": 1.7232002038804313, "alpha_loss": -0.0021427994102446567, "alpha_value": 0.08446949857173777, "duration": 25.821999549865723, "step": 84625}
{"episode_reward": 493.63151260689864, "episode": 678.0, "batch_reward": 2.7963064308166503, "critic_loss": 9.950730167388915, "actor_loss": -279.8548687350365, "actor_target_entropy": -6.0, "actor_entropy": 1.8212243876149576, "alpha_loss": -0.00034345822754285987, "alpha_value": 0.08441060529716105, "duration": 25.779704570770264, "step": 84750}
{"episode_reward": 491.735050799034, "episode": 679.0, "batch_reward": 2.8005043964385985, "critic_loss": 10.192666252136231, "actor_loss": -280.1710214766245, "actor_target_entropy": -6.0, "actor_entropy": 1.88444769760919, "alpha_loss": -0.011329144686608323, "alpha_value": 0.08469945794044208, "duration": 25.794395685195923, "step": 84875}
{"episode_reward": 513.1614599435562, "episode": 680.0, "batch_reward": 2.8121261348724365, "critic_loss": 10.304530963897705, "actor_loss": -280.47083503969253, "actor_target_entropy": -6.0, "actor_entropy": 1.777385373269358, "alpha_loss": 0.0039428670612734655, "alpha_value": 0.08480439232294938, "step": 85000}
{"duration": 36.63515782356262, "step": 85000}
{"episode_reward": 501.349591490036, "episode": 681.0, "batch_reward": 2.80737007522583, "critic_loss": 9.743946834564209, "actor_loss": -280.44066220238096, "actor_target_entropy": -6.0, "actor_entropy": 1.765984160559518, "alpha_loss": 0.0010562965910630448, "alpha_value": 0.08472771395714794, "duration": 25.901662588119507, "step": 85125}
{"episode_reward": 485.75797099040426, "episode": 682.0, "batch_reward": 2.8078653774261473, "critic_loss": 11.161117942810058, "actor_loss": -280.03821735997354, "actor_target_entropy": -6.0, "actor_entropy": 1.8024943874728294, "alpha_loss": -0.0053000155528406465, "alpha_value": 0.08471664882681552, "duration": 25.789740324020386, "step": 85250}
{"episode_reward": 456.2138280675123, "episode": 683.0, "batch_reward": 2.8009411544799803, "critic_loss": 10.016698913574219, "actor_loss": -280.6099122062562, "actor_target_entropy": -6.0, "actor_entropy": 1.7837445187190222, "alpha_loss": 5.1984160635916016e-05, "alpha_value": 0.08483657108237931, "duration": 25.832717418670654, "step": 85375}
{"episode_reward": 479.6610624686655, "episode": 684.0, "batch_reward": 2.8069101696014402, "critic_loss": 11.49579153060913, "actor_loss": -280.58160646500124, "actor_target_entropy": -6.0, "actor_entropy": 1.7262069044574615, "alpha_loss": -0.00991948280153015, "alpha_value": 0.08494408349338994, "duration": 25.740345239639282, "step": 85500}
{"episode_reward": 455.19461070984295, "episode": 685.0, "batch_reward": 2.809257390975952, "critic_loss": 11.20076052093506, "actor_loss": -280.9052196684338, "actor_target_entropy": -6.0, "actor_entropy": 1.9041113758844042, "alpha_loss": -0.012861866322863433, "alpha_value": 0.08534352942757194, "duration": 25.81169843673706, "step": 85625}
{"episode_reward": 515.8731448696905, "episode": 686.0, "batch_reward": 2.8102716121673583, "critic_loss": 11.104365627288818, "actor_loss": -281.1841937649635, "actor_target_entropy": -6.0, "actor_entropy": 1.8619354540301907, "alpha_loss": -0.004829128708450064, "alpha_value": 0.085491657178758, "duration": 25.77458667755127, "step": 85750}
{"episode_reward": 422.2028386357434, "episode": 687.0, "batch_reward": 2.8162438278198243, "critic_loss": 9.97663536453247, "actor_loss": -281.44819907536584, "actor_target_entropy": -6.0, "actor_entropy": 1.8579860263400607, "alpha_loss": -0.0016086603152669137, "alpha_value": 0.08561402340876581, "duration": 25.822232484817505, "step": 85875}
{"episode_reward": 439.6321051740658, "episode": 688.0, "batch_reward": 2.8265143814086913, "critic_loss": 9.960878219604492, "actor_loss": -281.84953012774065, "actor_target_entropy": -6.0, "actor_entropy": 1.8659163944182857, "alpha_loss": -0.004940231892115046, "alpha_value": 0.08572754688255035, "duration": 25.73458170890808, "step": 86000}
{"episode_reward": 445.7678564597113, "episode": 689.0, "batch_reward": 2.814022678375244, "critic_loss": 10.454043956756593, "actor_loss": -281.6296091231089, "actor_target_entropy": -6.0, "actor_entropy": 1.9257377518547907, "alpha_loss": -0.0020000961653533437, "alpha_value": 0.08580974539037729, "duration": 25.848047733306885, "step": 86125}
{"episode_reward": 68.34623914966842, "episode": 690.0, "batch_reward": 2.8128570041656493, "critic_loss": 9.628934562683105, "actor_loss": -281.6024475097656, "actor_target_entropy": -6.0, "actor_entropy": 1.8952328447372682, "alpha_loss": 0.001183430149760698, "alpha_value": 0.08580255345890223, "duration": 25.829092264175415, "step": 86250}
{"episode_reward": 488.57578288774147, "episode": 691.0, "batch_reward": 2.8133744049072265, "critic_loss": 12.007148975372315, "actor_loss": -281.5369902111235, "actor_target_entropy": -6.0, "actor_entropy": 1.8146221107906766, "alpha_loss": -0.0033342131221341708, "alpha_value": 0.08580940528966531, "duration": 25.791103839874268, "step": 86375}
{"episode_reward": 499.80859026373315, "episode": 692.0, "batch_reward": 2.8100970191955565, "critic_loss": 10.415813514709473, "actor_loss": -281.64906163369454, "actor_target_entropy": -6.0, "actor_entropy": 1.8906420603875191, "alpha_loss": -0.004494457475600704, "alpha_value": 0.08597565996999465, "duration": 25.765891313552856, "step": 86500}
{"episode_reward": 446.7869228527633, "episode": 693.0, "batch_reward": 2.8235844802856445, "critic_loss": 10.763654460906983, "actor_loss": -282.13731553819446, "actor_target_entropy": -6.0, "actor_entropy": 1.8312536004989866, "alpha_loss": 0.00021223308858535591, "alpha_value": 0.0859721853751301, "duration": 25.774926900863647, "step": 86625}
{"episode_reward": 430.8133686292228, "episode": 694.0, "batch_reward": 2.8202244873046873, "critic_loss": 9.464733699798584, "actor_loss": -282.2061792189075, "actor_target_entropy": -6.0, "actor_entropy": 1.943143625413218, "alpha_loss": 0.0042754108341591015, "alpha_value": 0.08597221877990707, "duration": 25.744871854782104, "step": 86750}
{"episode_reward": 458.2170160488576, "episode": 695.0, "batch_reward": 2.8155513648986816, "critic_loss": 10.533691947937012, "actor_loss": -282.66234188988096, "actor_target_entropy": -6.0, "actor_entropy": 1.8904945982827082, "alpha_loss": 0.0019427469916759976, "alpha_value": 0.08585323664949994, "duration": 25.771268367767334, "step": 86875}
{"episode_reward": 380.55225037142225, "episode": 696.0, "batch_reward": 2.826512029647827, "critic_loss": 10.220107643127442, "actor_loss": -282.69085939468874, "actor_target_entropy": -6.0, "actor_entropy": 1.961735700407336, "alpha_loss": -0.0099848723377011, "alpha_value": 0.08593584710382501, "duration": 25.79043936729431, "step": 87000}
{"episode_reward": 482.0994247008878, "episode": 697.0, "batch_reward": 2.8180384407043455, "critic_loss": 10.594352073669434, "actor_loss": -282.6693401033916, "actor_target_entropy": -6.0, "actor_entropy": 1.8943079274798196, "alpha_loss": 0.0013111394031771592, "alpha_value": 0.08611209970522843, "duration": 25.88822102546692, "step": 87125}
{"episode_reward": 495.83211182591316, "episode": 698.0, "batch_reward": 2.819837827682495, "critic_loss": 10.567325504302978, "actor_loss": -282.6136533675655, "actor_target_entropy": -6.0, "actor_entropy": 1.9564744368676217, "alpha_loss": -0.01265128830357665, "alpha_value": 0.08621554791548876, "duration": 25.774457931518555, "step": 87250}
{"episode_reward": 498.01078647888426, "episode": 699.0, "batch_reward": 2.8190388107299804, "critic_loss": 10.440728046417236, "actor_loss": -282.54491364009795, "actor_target_entropy": -6.0, "actor_entropy": 2.0333256229521735, "alpha_loss": -0.008716923214258656, "alpha_value": 0.08648620653221699, "duration": 25.825927257537842, "step": 87375}
{"episode_reward": 476.281478709018, "episode": 700.0, "batch_reward": 2.829235807418823, "critic_loss": 9.766571403503418, "actor_loss": -283.56668681483114, "actor_target_entropy": -6.0, "actor_entropy": 1.9895834499789822, "alpha_loss": -0.013920983799072284, "alpha_value": 0.08685166468717902, "duration": 25.812020301818848, "step": 87500}
{"episode_reward": 469.1900037900604, "episode": 701.0, "batch_reward": 2.8254751110076906, "critic_loss": 10.84139658355713, "actor_loss": -283.2513514927455, "actor_target_entropy": -6.0, "actor_entropy": 1.9668496184878879, "alpha_loss": -0.0056757323761721925, "alpha_value": 0.08707455387224086, "duration": 25.826059818267822, "step": 87625}
{"episode_reward": 460.12338311195185, "episode": 702.0, "batch_reward": 2.833577283859253, "critic_loss": 11.09683772277832, "actor_loss": -283.33936678978705, "actor_target_entropy": -6.0, "actor_entropy": 1.9467981419255656, "alpha_loss": -2.1834559212889402e-05, "alpha_value": 0.08714395997564646, "duration": 25.79951548576355, "step": 87750}
{"episode_reward": 307.72845262198007, "episode": 703.0, "batch_reward": 2.8226058464050294, "critic_loss": 13.095463848114013, "actor_loss": -283.5127795991443, "actor_target_entropy": -6.0, "actor_entropy": 1.912402586331443, "alpha_loss": 0.0010135658454918672, "alpha_value": 0.08709783148123028, "duration": 25.818559646606445, "step": 87875}
{"episode_reward": 446.4356300040264, "episode": 704.0, "batch_reward": 2.8347046813964845, "critic_loss": 12.012885791778565, "actor_loss": -283.34440268239666, "actor_target_entropy": -6.0, "actor_entropy": 1.9100115895271301, "alpha_loss": -0.0025792759542744006, "alpha_value": 0.08717542866994078, "duration": 25.797623872756958, "step": 88000}
{"episode_reward": 473.18378187088183, "episode": 705.0, "batch_reward": 2.8370300731658937, "critic_loss": 11.117116653442382, "actor_loss": -284.35886540488593, "actor_target_entropy": -6.0, "actor_entropy": 1.8104056214529372, "alpha_loss": -0.00780169036985922, "alpha_value": 0.0872525881603806, "duration": 25.860525369644165, "step": 88125}
{"episode_reward": 472.5555299119341, "episode": 706.0, "batch_reward": 2.830560522079468, "critic_loss": 11.06167977142334, "actor_loss": -283.7105737501575, "actor_target_entropy": -6.0, "actor_entropy": 1.8631726080371487, "alpha_loss": -0.003109863489836214, "alpha_value": 0.08740611715690397, "duration": 25.78968119621277, "step": 88250}
{"episode_reward": 447.442041080148, "episode": 707.0, "batch_reward": 2.838260534286499, "critic_loss": 10.861234390258788, "actor_loss": -284.31044321211556, "actor_target_entropy": -6.0, "actor_entropy": 1.931457449519445, "alpha_loss": -0.009247423116383808, "alpha_value": 0.08766667793537622, "duration": 25.784562587738037, "step": 88375}
{"episode_reward": 487.6884512925652, "episode": 708.0, "batch_reward": 2.827015398025513, "critic_loss": 11.192736400604248, "actor_loss": -283.7306676064768, "actor_target_entropy": -6.0, "actor_entropy": 1.9149745106697083, "alpha_loss": -0.0019656208967189152, "alpha_value": 0.08776100784303822, "duration": 25.73473882675171, "step": 88500}
{"episode_reward": 489.1438775257139, "episode": 709.0, "batch_reward": 2.8445451469421386, "critic_loss": 10.372051250457764, "actor_loss": -284.5398666139633, "actor_target_entropy": -6.0, "actor_entropy": 1.9323265912040832, "alpha_loss": -0.0026436587352128256, "alpha_value": 0.08787762018878525, "duration": 25.806777238845825, "step": 88625}
{"episode_reward": 460.8435599250772, "episode": 710.0, "batch_reward": 2.8419486770629883, "critic_loss": 11.254471511840821, "actor_loss": -284.5872182538432, "actor_target_entropy": -6.0, "actor_entropy": 1.9718888190484816, "alpha_loss": 0.0029693751055146415, "alpha_value": 0.08786063889450052, "duration": 25.79301166534424, "step": 88750}
{"episode_reward": 472.59651856997596, "episode": 711.0, "batch_reward": 2.8433510303497314, "critic_loss": 13.566390705108642, "actor_loss": -284.7505338154142, "actor_target_entropy": -6.0, "actor_entropy": 1.99085695781405, "alpha_loss": -0.0076777456875240045, "alpha_value": 0.08787920555378177, "duration": 25.81234884262085, "step": 88875}
{"episode_reward": 462.31022564407743, "episode": 712.0, "batch_reward": 2.82713169670105, "critic_loss": 13.508131450653076, "actor_loss": -284.81095197123864, "actor_target_entropy": -6.0, "actor_entropy": 1.8043513336489279, "alpha_loss": -0.001539006401153822, "alpha_value": 0.08799919916507054, "duration": 25.855543613433838, "step": 89000}
{"episode_reward": 437.4827150936734, "episode": 713.0, "batch_reward": 2.8365991611480714, "critic_loss": 11.289680309295655, "actor_loss": -284.8342682369172, "actor_target_entropy": -6.0, "actor_entropy": 1.9214395871238104, "alpha_loss": -0.00765092488718293, "alpha_value": 0.08817435927579367, "duration": 25.94110608100891, "step": 89125}
{"episode_reward": 484.2693742383455, "episode": 714.0, "batch_reward": 2.8377459411621095, "critic_loss": 11.995119384765625, "actor_loss": -284.6095940374559, "actor_target_entropy": -6.0, "actor_entropy": 1.9113097671539552, "alpha_loss": 0.007787302662167818, "alpha_value": 0.08812466625392942, "duration": 25.829951286315918, "step": 89250}
{"episode_reward": 480.6981737140505, "episode": 715.0, "batch_reward": 2.836101163864136, "critic_loss": 11.862976924896241, "actor_loss": -284.85690162295384, "actor_target_entropy": -6.0, "actor_entropy": 1.9306408583171784, "alpha_loss": -0.007785435668044975, "alpha_value": 0.08819484791861128, "duration": 25.893374919891357, "step": 89375}
{"episode_reward": 487.2117535274054, "episode": 716.0, "batch_reward": 2.847426839828491, "critic_loss": 12.205712600708008, "actor_loss": -285.4143214071951, "actor_target_entropy": -6.0, "actor_entropy": 2.0930547022050425, "alpha_loss": -0.005912771651280984, "alpha_value": 0.08839577492543312, "duration": 25.81316041946411, "step": 89500}
{"episode_reward": 412.6264244000169, "episode": 717.0, "batch_reward": 2.8515567359924314, "critic_loss": 10.401139575958252, "actor_loss": -285.8172893221416, "actor_target_entropy": -6.0, "actor_entropy": 1.9404139140295604, "alpha_loss": -0.0008777586377358862, "alpha_value": 0.08848892974290581, "duration": 25.91715097427368, "step": 89625}
{"episode_reward": 464.44713647624604, "episode": 718.0, "batch_reward": 2.850807294845581, "critic_loss": 9.764019371032715, "actor_loss": -285.792242726972, "actor_target_entropy": -6.0, "actor_entropy": 1.890943136907393, "alpha_loss": 0.0051794294756086125, "alpha_value": 0.08843171545873375, "duration": 25.84145951271057, "step": 89750}
{"episode_reward": 477.2411984768794, "episode": 719.0, "batch_reward": 2.842416446685791, "critic_loss": 9.410669216156005, "actor_loss": -285.9538792201451, "actor_target_entropy": -6.0, "actor_entropy": 1.816091123081389, "alpha_loss": 0.0024551647227434885, "alpha_value": 0.08824152226503854, "duration": 25.90779209136963, "step": 89875}
{"episode_reward": 418.53223114219, "episode": 720.0, "batch_reward": 2.850594980239868, "critic_loss": 10.289016483306884, "actor_loss": -285.7362518310547, "actor_target_entropy": -6.0, "actor_entropy": 1.7480131368483267, "alpha_loss": 0.007022438679761704, "alpha_value": 0.08812826199755991, "step": 90000}
{"duration": 36.62928485870361, "step": 90000}
{"episode_reward": 506.0013490408649, "episode": 721.0, "batch_reward": 2.8512535915374757, "critic_loss": 10.306217639923096, "actor_loss": -286.43040732731896, "actor_target_entropy": -6.0, "actor_entropy": 1.9640015912434412, "alpha_loss": -0.004478453397972598, "alpha_value": 0.088109587666444, "duration": 25.88566756248474, "step": 90125}
{"episode_reward": 494.78834564483486, "episode": 722.0, "batch_reward": 2.8565746269226073, "critic_loss": 9.943981536865234, "actor_loss": -286.5512242471018, "actor_target_entropy": -6.0, "actor_entropy": 1.8612795202962813, "alpha_loss": -0.0008610168794891046, "alpha_value": 0.08814582018290383, "duration": 25.871245861053467, "step": 90250}
{"episode_reward": 471.1173662795788, "episode": 723.0, "batch_reward": 2.8444448432922362, "critic_loss": 10.416227474212647, "actor_loss": -286.3622514028398, "actor_target_entropy": -6.0, "actor_entropy": 1.9082193052957928, "alpha_loss": -0.0023340205661952496, "alpha_value": 0.08817714822090279, "duration": 25.876044034957886, "step": 90375}
{"episode_reward": 491.28803362785567, "episode": 724.0, "batch_reward": 2.8547438583374025, "critic_loss": 10.152370323181152, "actor_loss": -286.17676765688003, "actor_target_entropy": -6.0, "actor_entropy": 1.9422030910368888, "alpha_loss": -0.0013679317987313675, "alpha_value": 0.08828938232412491, "duration": 25.827207326889038, "step": 90500}
{"episode_reward": 502.6553921381165, "episode": 725.0, "batch_reward": 2.8516948337554933, "critic_loss": 9.680836612701416, "actor_loss": -286.65362839471726, "actor_target_entropy": -6.0, "actor_entropy": 1.848960902955797, "alpha_loss": -0.003285275768518211, "alpha_value": 0.08832650790182436, "duration": 25.870395183563232, "step": 90625}
{"episode_reward": 483.2722625273463, "episode": 726.0, "batch_reward": 2.8564924602508546, "critic_loss": 10.202324787139892, "actor_loss": -286.7752124417213, "actor_target_entropy": -6.0, "actor_entropy": 1.84462288694997, "alpha_loss": -0.0034456110499318567, "alpha_value": 0.08846867643231203, "duration": 25.83234667778015, "step": 90750}
{"episode_reward": 502.81298963300793, "episode": 727.0, "batch_reward": 2.8568773593902588, "critic_loss": 9.458523197174072, "actor_loss": -286.04766458178324, "actor_target_entropy": -6.0, "actor_entropy": 1.9848737773441134, "alpha_loss": -0.00014794313733185093, "alpha_value": 0.08851564470950542, "duration": 25.93161416053772, "step": 90875}
{"episode_reward": 450.67741998073, "episode": 728.0, "batch_reward": 2.8609085845947266, "critic_loss": 9.283664085388184, "actor_loss": -287.64055559712074, "actor_target_entropy": -6.0, "actor_entropy": 1.900956186556047, "alpha_loss": -0.007450254915672685, "alpha_value": 0.08850620743787989, "duration": 25.82086205482483, "step": 91000}
{"episode_reward": 489.51245501669246, "episode": 729.0, "batch_reward": 2.8558110637664793, "critic_loss": 10.196740104675293, "actor_loss": -287.1651364281064, "actor_target_entropy": -6.0, "actor_entropy": 1.8539320381860884, "alpha_loss": -0.0019694818590309414, "alpha_value": 0.08873819602219285, "duration": 25.928027391433716, "step": 91125}
{"episode_reward": 497.4232764874225, "episode": 730.0, "batch_reward": 2.8691189498901366, "critic_loss": 9.188079193115234, "actor_loss": -287.52125303206907, "actor_target_entropy": -6.0, "actor_entropy": 1.9192442470981228, "alpha_loss": 0.0045395800205428275, "alpha_value": 0.08869579100193035, "duration": 25.882742404937744, "step": 91250}
{"episode_reward": 432.2616028665734, "episode": 731.0, "batch_reward": 2.870550380706787, "critic_loss": 9.778911041259766, "actor_loss": -286.9370940677703, "actor_target_entropy": -6.0, "actor_entropy": 1.9920957977809604, "alpha_loss": -0.004690924230667334, "alpha_value": 0.08870422436413894, "duration": 25.897050380706787, "step": 91375}
{"episode_reward": 471.0522411933278, "episode": 732.0, "batch_reward": 2.873816955566406, "critic_loss": 9.70563126373291, "actor_loss": -287.2886815224924, "actor_target_entropy": -6.0, "actor_entropy": 1.860525982995187, "alpha_loss": 0.004618362238210055, "alpha_value": 0.08869284831818117, "duration": 25.861751556396484, "step": 91500}
{"episode_reward": 487.8375457357072, "episode": 733.0, "batch_reward": 2.8695750427246094, "critic_loss": 9.909814102172852, "actor_loss": -287.191890656002, "actor_target_entropy": -6.0, "actor_entropy": 1.8365006257617285, "alpha_loss": -0.006365962681316194, "alpha_value": 0.08873110483488625, "duration": 25.79970407485962, "step": 91625}
{"episode_reward": 475.0784957134259, "episode": 734.0, "batch_reward": 2.8696538143157957, "critic_loss": 10.199930164337157, "actor_loss": -287.6974630048198, "actor_target_entropy": -6.0, "actor_entropy": 1.86189825688639, "alpha_loss": -0.0021831972652205057, "alpha_value": 0.08871956862877552, "duration": 25.833887815475464, "step": 91750}
{"episode_reward": 467.6615934608989, "episode": 735.0, "batch_reward": 2.8742854537963867, "critic_loss": 10.20478980255127, "actor_loss": -288.06248546781995, "actor_target_entropy": -6.0, "actor_entropy": 1.9399604683830625, "alpha_loss": 0.00010046600881550048, "alpha_value": 0.08889050272003442, "duration": 25.888593196868896, "step": 91875}
{"episode_reward": 478.66608411310546, "episode": 736.0, "batch_reward": 2.876349515914917, "critic_loss": 9.081350936889649, "actor_loss": -288.02897053380167, "actor_target_entropy": -6.0, "actor_entropy": 1.883918700679656, "alpha_loss": -0.0022304741808423594, "alpha_value": 0.08889450745992003, "duration": 25.790138721466064, "step": 92000}
{"episode_reward": 488.1354720619079, "episode": 737.0, "batch_reward": 2.8768556404113768, "critic_loss": 10.36199564743042, "actor_loss": -288.24511670309397, "actor_target_entropy": -6.0, "actor_entropy": 1.8604346608358717, "alpha_loss": 0.0013914298763247354, "alpha_value": 0.08888309369358979, "duration": 25.865151166915894, "step": 92125}
{"episode_reward": 496.6015408279725, "episode": 738.0, "batch_reward": 2.8783522472381593, "critic_loss": 10.075875999450684, "actor_loss": -287.99616118400326, "actor_target_entropy": -6.0, "actor_entropy": 1.8998122830544748, "alpha_loss": -0.0030029520782972534, "alpha_value": 0.08891548160573222, "duration": 25.81431818008423, "step": 92250}
{"episode_reward": 504.4976946405086, "episode": 739.0, "batch_reward": 2.8747053718566895, "critic_loss": 9.540584911346436, "actor_loss": -288.24453783792165, "actor_target_entropy": -6.0, "actor_entropy": 1.797002667472476, "alpha_loss": 0.009265717107891328, "alpha_value": 0.08885487776414966, "duration": 25.905613660812378, "step": 92375}
{"episode_reward": 513.1943901207226, "episode": 740.0, "batch_reward": 2.868744525909424, "critic_loss": 10.059980430603026, "actor_loss": -288.440423288653, "actor_target_entropy": -6.0, "actor_entropy": 1.8083958568111542, "alpha_loss": -0.0013497786919376062, "alpha_value": 0.08870768187038681, "duration": 25.80123496055603, "step": 92500}
{"episode_reward": 108.0980094875638, "episode": 741.0, "batch_reward": 2.875331651687622, "critic_loss": 11.604807064056397, "actor_loss": -288.34594387478296, "actor_target_entropy": -6.0, "actor_entropy": 1.827710197085426, "alpha_loss": -0.0012129278639183632, "alpha_value": 0.08879124589461473, "duration": 25.90814971923828, "step": 92625}
{"episode_reward": 478.54910321039125, "episode": 742.0, "batch_reward": 2.874364782333374, "critic_loss": 10.70752177810669, "actor_loss": -288.50759001701107, "actor_target_entropy": -6.0, "actor_entropy": 1.9271628837431631, "alpha_loss": -0.007566705424969475, "alpha_value": 0.08890003391663677, "duration": 25.79079818725586, "step": 92750}
{"episode_reward": 516.1086889848598, "episode": 743.0, "batch_reward": 2.8852328357696533, "critic_loss": 10.418536331176758, "actor_loss": -289.11140708317834, "actor_target_entropy": -6.0, "actor_entropy": 1.9370023258148679, "alpha_loss": -0.0055609464179724455, "alpha_value": 0.0890526630482401, "duration": 25.88170599937439, "step": 92875}
{"episode_reward": 512.8614278897296, "episode": 744.0, "batch_reward": 2.8729042530059816, "critic_loss": 12.281965263366699, "actor_loss": -288.7974292385963, "actor_target_entropy": -6.0, "actor_entropy": 1.9650781173859873, "alpha_loss": 0.003837617215580277, "alpha_value": 0.08905558108645886, "duration": 25.8441801071167, "step": 93000}
{"episode_reward": 498.00637541396907, "episode": 745.0, "batch_reward": 2.880411329269409, "critic_loss": 11.720049324035644, "actor_loss": -289.25076439267116, "actor_target_entropy": -6.0, "actor_entropy": 2.0483811242239818, "alpha_loss": -0.01222280856399309, "alpha_value": 0.08918245273949801, "duration": 25.8736515045166, "step": 93125}
{"episode_reward": 495.6601654027322, "episode": 746.0, "batch_reward": 2.8746900424957276, "critic_loss": 13.466927906036377, "actor_loss": -288.8816976239604, "actor_target_entropy": -6.0, "actor_entropy": 2.0199707015868156, "alpha_loss": 0.004218235255158957, "alpha_value": 0.08937388994015347, "duration": 25.80994939804077, "step": 93250}
{"episode_reward": 436.22354480780416, "episode": 747.0, "batch_reward": 2.886629274368286, "critic_loss": 11.975122570037842, "actor_loss": -289.2744319855221, "actor_target_entropy": -6.0, "actor_entropy": 1.9644772817218115, "alpha_loss": -0.007913166738396126, "alpha_value": 0.08938368551851109, "duration": 25.89000701904297, "step": 93375}
{"episode_reward": 461.2517107709489, "episode": 748.0, "batch_reward": 2.890216375350952, "critic_loss": 11.923723743438721, "actor_loss": -289.75125269736014, "actor_target_entropy": -6.0, "actor_entropy": 1.9663472906235726, "alpha_loss": -0.0023526947930335037, "alpha_value": 0.08951148364859847, "duration": 25.86710810661316, "step": 93500}
{"episode_reward": 494.3107485773825, "episode": 749.0, "batch_reward": 2.886686815261841, "critic_loss": 10.94457080078125, "actor_loss": -289.4745677160838, "actor_target_entropy": -6.0, "actor_entropy": 2.0635797523316883, "alpha_loss": -0.01109006920725935, "alpha_value": 0.08964693772630794, "duration": 25.935605764389038, "step": 93625}
{"episode_reward": 466.2177703504854, "episode": 750.0, "batch_reward": 2.8880945358276366, "critic_loss": 10.587984031677246, "actor_loss": -290.0653839111328, "actor_target_entropy": -6.0, "actor_entropy": 1.9918564154255776, "alpha_loss": -0.00044378136555033346, "alpha_value": 0.08984130785334489, "duration": 25.864847660064697, "step": 93750}
{"episode_reward": 484.5190048530153, "episode": 751.0, "batch_reward": 2.8817955513000486, "critic_loss": 11.231565013885499, "actor_loss": -289.92161342075894, "actor_target_entropy": -6.0, "actor_entropy": 1.9250561112449283, "alpha_loss": -0.005017129349566642, "alpha_value": 0.0898456606060732, "duration": 25.922260522842407, "step": 93875}
{"episode_reward": 510.733986549581, "episode": 752.0, "batch_reward": 2.8870140342712403, "critic_loss": 10.119451305389404, "actor_loss": -289.6407741423576, "actor_target_entropy": -6.0, "actor_entropy": 1.9780281801377573, "alpha_loss": -0.012478491764575723, "alpha_value": 0.09014886998526661, "duration": 25.874274253845215, "step": 94000}
{"episode_reward": 479.25389563935676, "episode": 753.0, "batch_reward": 2.8904469718933106, "critic_loss": 10.19658359146118, "actor_loss": -290.0408199249752, "actor_target_entropy": -6.0, "actor_entropy": 1.9001167899086362, "alpha_loss": 0.002069983949204759, "alpha_value": 0.09029160116318048, "duration": 25.97913956642151, "step": 94125}
{"episode_reward": 512.4852965595119, "episode": 754.0, "batch_reward": 2.8910673503875732, "critic_loss": 10.803166412353516, "actor_loss": -290.35298845844886, "actor_target_entropy": -6.0, "actor_entropy": 2.001144805262166, "alpha_loss": 0.000953646523186997, "alpha_value": 0.0902377360805242, "duration": 25.891560077667236, "step": 94250}
{"episode_reward": 492.36392758345835, "episode": 755.0, "batch_reward": 2.8997496070861817, "critic_loss": 10.820090549468993, "actor_loss": -291.42635672433033, "actor_target_entropy": -6.0, "actor_entropy": 1.9055421655140226, "alpha_loss": -0.007121680537238717, "alpha_value": 0.09024933046051925, "duration": 25.886844873428345, "step": 94375}
{"episode_reward": 481.0550899704198, "episode": 756.0, "batch_reward": 2.894867900848389, "critic_loss": 10.695958290100098, "actor_loss": -290.6936502764302, "actor_target_entropy": -6.0, "actor_entropy": 1.9231684630916965, "alpha_loss": 0.0004570775650321476, "alpha_value": 0.09047849510754995, "duration": 25.83302927017212, "step": 94500}
{"episode_reward": 508.1864537333117, "episode": 757.0, "batch_reward": 2.887943117141724, "critic_loss": 11.4287158203125, "actor_loss": -290.37284778413317, "actor_target_entropy": -6.0, "actor_entropy": 1.9227673628973583, "alpha_loss": 0.00034666435408686833, "alpha_value": 0.09034595976123665, "duration": 25.889927864074707, "step": 94625}
{"episode_reward": 509.06162957345634, "episode": 758.0, "batch_reward": 2.89347310256958, "critic_loss": 11.53229343032837, "actor_loss": -290.84688346616684, "actor_target_entropy": -6.0, "actor_entropy": 2.023763458574972, "alpha_loss": -0.0077927786323632444, "alpha_value": 0.09057007714086493, "duration": 25.840633869171143, "step": 94750}
{"episode_reward": 502.29936999879027, "episode": 759.0, "batch_reward": 2.8953324851989746, "critic_loss": 10.267219829559327, "actor_loss": -291.1039850144159, "actor_target_entropy": -6.0, "actor_entropy": 1.9847001045469255, "alpha_loss": 0.006176502225802295, "alpha_value": 0.09049461423691811, "duration": 25.86407780647278, "step": 94875}
{"episode_reward": 518.5828024713647, "episode": 760.0, "batch_reward": 2.9036720027923586, "critic_loss": 11.244417270660401, "actor_loss": -291.1654815673828, "actor_target_entropy": -6.0, "actor_entropy": 1.9831493977577455, "alpha_loss": -0.0018272416275595465, "alpha_value": 0.09039238200249884, "step": 95000}
{"duration": 36.621187925338745, "step": 95000}
{"episode_reward": 405.9364723421933, "episode": 761.0, "batch_reward": 2.902989088058472, "critic_loss": 11.44284729385376, "actor_loss": -291.99000573536705, "actor_target_entropy": -6.0, "actor_entropy": 1.9920058723479983, "alpha_loss": 0.0013151912698670038, "alpha_value": 0.09049903586534694, "duration": 25.891722917556763, "step": 95125}
{"episode_reward": 470.3990237538467, "episode": 762.0, "batch_reward": 2.9037860679626464, "critic_loss": 9.429132236480713, "actor_loss": -291.7201488864037, "actor_target_entropy": -6.0, "actor_entropy": 1.9838236801085933, "alpha_loss": 0.0020438937673104866, "alpha_value": 0.09046059308096589, "duration": 25.802833318710327, "step": 95250}
{"episode_reward": 497.34773679046907, "episode": 763.0, "batch_reward": 2.902456268310547, "critic_loss": 11.73522248840332, "actor_loss": -291.75463721865697, "actor_target_entropy": -6.0, "actor_entropy": 2.0226942130497525, "alpha_loss": 0.004771842994535017, "alpha_value": 0.09031305543654261, "duration": 25.863859176635742, "step": 95375}
{"episode_reward": 468.53430816650416, "episode": 764.0, "batch_reward": 2.9120346794128418, "critic_loss": 9.851478988647461, "actor_loss": -291.8583265735257, "actor_target_entropy": -6.0, "actor_entropy": 2.0835658407980397, "alpha_loss": 0.008438914465988356, "alpha_value": 0.09021182468580376, "duration": 25.681716918945312, "step": 95500}
{"episode_reward": 498.62549355118995, "episode": 765.0, "batch_reward": 2.9102772808074953, "critic_loss": 8.96763544845581, "actor_loss": -292.3451843261719, "actor_target_entropy": -6.0, "actor_entropy": 1.9695736945621551, "alpha_loss": -0.002881930139477527, "alpha_value": 0.09005513021286514, "duration": 25.831634283065796, "step": 95625}
{"episode_reward": 502.0527079953385, "episode": 766.0, "batch_reward": 2.8997685871124266, "critic_loss": 9.564351146697998, "actor_loss": -292.16218862225935, "actor_target_entropy": -6.0, "actor_entropy": 1.9518230788169368, "alpha_loss": -0.007117616917727695, "alpha_value": 0.09020212976399715, "duration": 25.771975994110107, "step": 95750}
{"episode_reward": 525.1667269259074, "episode": 767.0, "batch_reward": 2.901524147033691, "critic_loss": 10.056798305511474, "actor_loss": -291.78653147863963, "actor_target_entropy": -6.0, "actor_entropy": 2.0387140985519165, "alpha_loss": -0.0043308777838117546, "alpha_value": 0.09035225074553928, "duration": 25.873444318771362, "step": 95875}
{"episode_reward": 494.89175913865967, "episode": 768.0, "batch_reward": 2.9155391788482667, "critic_loss": 9.646769897460938, "actor_loss": -292.4433967836442, "actor_target_entropy": -6.0, "actor_entropy": 1.9872437600166566, "alpha_loss": 6.20829842744335e-05, "alpha_value": 0.0903785215758907, "duration": 25.720382690429688, "step": 96000}
{"episode_reward": 455.05329547327574, "episode": 769.0, "batch_reward": 2.9102594470977783, "critic_loss": 11.055045295715333, "actor_loss": -292.2823873852927, "actor_target_entropy": -6.0, "actor_entropy": 1.988690111372206, "alpha_loss": 0.003507783381445777, "alpha_value": 0.09035007122732758, "duration": 25.827064752578735, "step": 96125}
{"episode_reward": 446.2572940857663, "episode": 770.0, "batch_reward": 2.9132840404510496, "critic_loss": 10.35603394317627, "actor_loss": -292.54745286510837, "actor_target_entropy": -6.0, "actor_entropy": 1.9863902099670903, "alpha_loss": -0.01896795408514839, "alpha_value": 0.09058345291698663, "duration": 25.789401054382324, "step": 96250}
{"episode_reward": 472.9834520297291, "episode": 771.0, "batch_reward": 2.924572582244873, "critic_loss": 10.53770146560669, "actor_loss": -293.06148516942585, "actor_target_entropy": -6.0, "actor_entropy": 1.9931425934746152, "alpha_loss": 0.0015104818730688994, "alpha_value": 0.09084098065020325, "duration": 25.921976566314697, "step": 96375}
{"episode_reward": 334.65072964718576, "episode": 772.0, "batch_reward": 2.915996700286865, "critic_loss": 9.036059032440185, "actor_loss": -293.2076726113596, "actor_target_entropy": -6.0, "actor_entropy": 1.9907938818777762, "alpha_loss": -0.0007374614417072266, "alpha_value": 0.09089094689525004, "duration": 25.713163137435913, "step": 96500}
{"episode_reward": 515.0878384621763, "episode": 773.0, "batch_reward": 2.9161984214782715, "critic_loss": 9.571590309143067, "actor_loss": -293.4338146391369, "actor_target_entropy": -6.0, "actor_entropy": 1.99396846975599, "alpha_loss": 0.000376803870682442, "alpha_value": 0.09090375830182425, "duration": 25.594170570373535, "step": 96625}
{"episode_reward": 537.3309815641248, "episode": 774.0, "batch_reward": 2.91491548538208, "critic_loss": 9.129698783874511, "actor_loss": -293.11720472766507, "actor_target_entropy": -6.0, "actor_entropy": 1.9951829198868043, "alpha_loss": 0.0068305349428086515, "alpha_value": 0.09075593686104222, "duration": 25.621360778808594, "step": 96750}
{"episode_reward": 470.78018774836823, "episode": 775.0, "batch_reward": 2.923717674255371, "critic_loss": 9.530746898651124, "actor_loss": -293.9307623969184, "actor_target_entropy": -6.0, "actor_entropy": 1.9239429897732205, "alpha_loss": 0.007839857888895841, "alpha_value": 0.09054066809601297, "duration": 25.64182758331299, "step": 96875}
{"episode_reward": 253.1129609418726, "episode": 776.0, "batch_reward": 2.907456579208374, "critic_loss": 11.896178157806396, "actor_loss": -293.231943930349, "actor_target_entropy": -6.0, "actor_entropy": 2.034108586849705, "alpha_loss": -0.002938857771486284, "alpha_value": 0.0904746230644193, "duration": 25.53060269355774, "step": 97000}
{"episode_reward": 491.0379891522388, "episode": 777.0, "batch_reward": 2.919921579360962, "critic_loss": 12.004472465515137, "actor_loss": -293.14292786613345, "actor_target_entropy": -6.0, "actor_entropy": 2.0203351936643084, "alpha_loss": 0.005119940107096992, "alpha_value": 0.09049025104802956, "duration": 25.69253373146057, "step": 97125}
{"episode_reward": 499.4436564369786, "episode": 778.0, "batch_reward": 2.9121743831634523, "critic_loss": 13.00670524597168, "actor_loss": -293.40182199785784, "actor_target_entropy": -6.0, "actor_entropy": 2.0574559723177264, "alpha_loss": -0.009748733962976163, "alpha_value": 0.09043284066577566, "duration": 25.54481077194214, "step": 97250}
{"episode_reward": 491.9340745817896, "episode": 779.0, "batch_reward": 2.9186166343688966, "critic_loss": 14.046203128814698, "actor_loss": -293.5071028452071, "actor_target_entropy": -6.0, "actor_entropy": 2.1725397999324496, "alpha_loss": -0.008442543195708403, "alpha_value": 0.09075816643282289, "duration": 25.681212186813354, "step": 97375}
{"episode_reward": 483.28745563166717, "episode": 780.0, "batch_reward": 2.9239328346252442, "critic_loss": 12.004095832824706, "actor_loss": -294.1580584126134, "actor_target_entropy": -6.0, "actor_entropy": 2.0586275823654665, "alpha_loss": 0.003546825595079891, "alpha_value": 0.09088189191619113, "duration": 25.55042266845703, "step": 97500}
{"episode_reward": 488.15747589009493, "episode": 781.0, "batch_reward": 2.9276142044067384, "critic_loss": 11.677141315460204, "actor_loss": -294.14178563678075, "actor_target_entropy": -6.0, "actor_entropy": 1.9361549521249437, "alpha_loss": 0.007312161097716954, "alpha_value": 0.09067939656379792, "duration": 25.68113350868225, "step": 97625}
{"episode_reward": 496.93179630602407, "episode": 782.0, "batch_reward": 2.9217483825683592, "critic_loss": 12.024691791534424, "actor_loss": -294.14774740895916, "actor_target_entropy": -6.0, "actor_entropy": 2.002835883248237, "alpha_loss": 0.0023252741290977403, "alpha_value": 0.09045706518396004, "duration": 25.585938692092896, "step": 97750}
{"episode_reward": 475.30857512060135, "episode": 783.0, "batch_reward": 2.927467580795288, "critic_loss": 10.125495906829833, "actor_loss": -294.4233165922619, "actor_target_entropy": -6.0, "actor_entropy": 2.0369990685629467, "alpha_loss": -0.001462666206948814, "alpha_value": 0.09058384060213523, "duration": 25.658937454223633, "step": 97875}
{"episode_reward": 485.39555523364686, "episode": 784.0, "batch_reward": 2.9244961738586426, "critic_loss": 9.609099632263183, "actor_loss": -294.6043912826046, "actor_target_entropy": -6.0, "actor_entropy": 1.9623609646674125, "alpha_loss": -0.007574969497058661, "alpha_value": 0.09066615087625286, "duration": 25.618120431900024, "step": 98000}
{"episode_reward": 510.92578095974915, "episode": 785.0, "batch_reward": 2.9287677726745605, "critic_loss": 10.131030925750732, "actor_loss": -294.68150596013146, "actor_target_entropy": -6.0, "actor_entropy": 1.9544929209209623, "alpha_loss": -0.002397403775137805, "alpha_value": 0.09076631135663324, "duration": 25.77671980857849, "step": 98125}
{"episode_reward": 474.50762507180957, "episode": 786.0, "batch_reward": 2.9262206916809084, "critic_loss": 9.335657814025879, "actor_loss": -294.82043161699846, "actor_target_entropy": -6.0, "actor_entropy": 1.9814561182452786, "alpha_loss": -0.011624462594608627, "alpha_value": 0.09101002512582143, "duration": 25.64553689956665, "step": 98250}
{"episode_reward": 519.1911562191838, "episode": 787.0, "batch_reward": 2.922032440185547, "critic_loss": 10.873696834564209, "actor_loss": -294.57140192909844, "actor_target_entropy": -6.0, "actor_entropy": 1.9891599643798101, "alpha_loss": 0.0017010068376770331, "alpha_value": 0.0910996290624511, "duration": 25.728359699249268, "step": 98375}
{"episode_reward": 479.05935472013664, "episode": 788.0, "batch_reward": 2.9258298988342286, "critic_loss": 9.597204746246337, "actor_loss": -294.96632828251006, "actor_target_entropy": -6.0, "actor_entropy": 1.982143880859498, "alpha_loss": -0.00012524881880850562, "alpha_value": 0.09114967276617202, "duration": 25.589761972427368, "step": 98500}
{"episode_reward": 482.3000701920249, "episode": 789.0, "batch_reward": 2.9312472515106203, "critic_loss": 10.118364288330078, "actor_loss": -295.2482178703187, "actor_target_entropy": -6.0, "actor_entropy": 1.9797785660577198, "alpha_loss": -0.002141727467200586, "alpha_value": 0.09110666138482257, "duration": 25.762845277786255, "step": 98625}
{"episode_reward": 497.78009879483625, "episode": 790.0, "batch_reward": 2.928964635848999, "critic_loss": 10.571173034667968, "actor_loss": -295.0649645405431, "actor_target_entropy": -6.0, "actor_entropy": 1.9668236240263908, "alpha_loss": -0.003784938178385698, "alpha_value": 0.09118855734867452, "duration": 25.682966232299805, "step": 98750}
{"episode_reward": 477.68440839565505, "episode": 791.0, "batch_reward": 2.937003744125366, "critic_loss": 9.745781745910644, "actor_loss": -296.12669154575894, "actor_target_entropy": -6.0, "actor_entropy": 1.9691333581530859, "alpha_loss": -0.001576621543675188, "alpha_value": 0.0912885771718042, "duration": 25.71707010269165, "step": 98875}
{"episode_reward": 462.19956380445973, "episode": 792.0, "batch_reward": 2.936309192657471, "critic_loss": 10.091528743743897, "actor_loss": -295.50330574281753, "actor_target_entropy": -6.0, "actor_entropy": 1.9557994142655404, "alpha_loss": -0.0011071459007179064, "alpha_value": 0.09129827193906641, "duration": 25.69159960746765, "step": 99000}
{"episode_reward": 470.94002305449357, "episode": 793.0, "batch_reward": 2.9379487533569337, "critic_loss": 9.095737159729003, "actor_loss": -295.9435579814608, "actor_target_entropy": -6.0, "actor_entropy": 1.9089007926365686, "alpha_loss": 0.0049079049541245374, "alpha_value": 0.09126356911044119, "duration": 25.694786548614502, "step": 99125}
{"episode_reward": 514.387226302748, "episode": 794.0, "batch_reward": 2.9424627990722656, "critic_loss": 10.878562313079835, "actor_loss": -296.02029714276716, "actor_target_entropy": -6.0, "actor_entropy": 2.0722380472767736, "alpha_loss": -0.0026058385246283105, "alpha_value": 0.09117298621641327, "duration": 25.664239406585693, "step": 99250}
{"episode_reward": 450.86269002493526, "episode": 795.0, "batch_reward": 2.941009147644043, "critic_loss": 10.75778204345703, "actor_loss": -295.86946372380334, "actor_target_entropy": -6.0, "actor_entropy": 2.0780806749586076, "alpha_loss": -0.013038915593088382, "alpha_value": 0.0914926506866837, "duration": 25.72822666168213, "step": 99375}
{"episode_reward": 409.43965487464607, "episode": 796.0, "batch_reward": 2.943661809921265, "critic_loss": 12.26357746887207, "actor_loss": -296.2408117478894, "actor_target_entropy": -6.0, "actor_entropy": 2.0738700109143413, "alpha_loss": -0.013126517593440029, "alpha_value": 0.09175064454811306, "duration": 25.57261037826538, "step": 99500}
{"episode_reward": 477.01255824378876, "episode": 797.0, "batch_reward": 2.9415393257141114, "critic_loss": 12.443498447418213, "actor_loss": -296.1785234723772, "actor_target_entropy": -6.0, "actor_entropy": 2.1330425455456687, "alpha_loss": -0.015311151717065109, "alpha_value": 0.09229094157019001, "duration": 25.684624671936035, "step": 99625}
{"episode_reward": 496.83328796754216, "episode": 798.0, "batch_reward": 2.9348893947601318, "critic_loss": 12.801363567352295, "actor_loss": -295.73109485257055, "actor_target_entropy": -6.0, "actor_entropy": 2.1493983172601268, "alpha_loss": -0.011857647666587465, "alpha_value": 0.09263806857531223, "duration": 25.60369086265564, "step": 99750}
{"episode_reward": 516.0700200194759, "episode": 799.0, "batch_reward": 2.943013833999634, "critic_loss": 12.864405685424805, "actor_loss": -295.80589706178694, "actor_target_entropy": -6.0, "actor_entropy": 2.034610434183999, "alpha_loss": 0.0006764487452095463, "alpha_value": 0.09275461094960591, "duration": 25.687630653381348, "step": 99875}
{"episode_reward": 475.4131091495905, "episode": 800.0, "batch_reward": 2.9399892764706768, "critic_loss": 11.28289415759425, "actor_loss": -296.45311417118194, "actor_target_entropy": -6.0, "actor_entropy": 2.095464969834974, "alpha_loss": -0.010947635611369005, "alpha_value": 0.0928686131211805, "step": 99999}
