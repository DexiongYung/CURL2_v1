{"episode_reward": 0.0, "episode": 1.0, "duration": 27.56848692893982, "step": 125}
{"episode_reward": 23.579030900784034, "episode": 2.0, "duration": 0.4942936897277832, "step": 250}
{"episode_reward": 20.747401348917606, "episode": 3.0, "duration": 0.4916379451751709, "step": 375}
{"episode_reward": 15.208494239734875, "episode": 4.0, "duration": 0.49030590057373047, "step": 500}
{"episode_reward": 22.388913929606666, "episode": 5.0, "duration": 0.4931471347808838, "step": 625}
{"episode_reward": 16.786626931975075, "episode": 6.0, "duration": 0.4945542812347412, "step": 750}
{"episode_reward": 21.279484872018013, "episode": 7.0, "duration": 0.4945495128631592, "step": 875}
{"episode_reward": 26.341675891684616, "episode": 8.0, "duration": 0.49171876907348633, "step": 1000}
{"episode_reward": 32.46511410728092, "episode": 9.0, "Q1 loss": 0.10266472232341767, "Q2 loss": 0.10981446155905723, "Mean Target Q": 0.574164964646101, "Mean Q1": 0.5781304625570775, "Mean Q2": 0.5798098920397461, "critic_loss": 0.2124791818857193, "batch_reward": 0.17776903796195984, "actor_loss": -0.9052645222298683, "actor_target_entropy": -6.0, "actor_entropy": 7.087212274471919, "alpha_loss": 0.9321241000341991, "alpha_value": 0.09971526905510006, "duration": 250.77348041534424, "step": 1125}
{"episode_reward": 25.21109642772242, "episode": 10.0, "Q1 loss": 0.06040869498252869, "Q2 loss": 0.06025623777508736, "Mean Target Q": 1.1308906474113465, "Mean Q1": 1.1295581884384156, "Mean Q2": 1.1293028240203857, "critic_loss": 0.12066493272781371, "batch_reward": 0.18130953443050385, "actor_loss": -1.5330066084861755, "actor_target_entropy": -6.0, "actor_entropy": 7.540648314260667, "alpha_loss": 0.987135709293427, "alpha_value": 0.09907916629260731, "duration": 245.44455528259277, "step": 1250}
{"episode_reward": 17.723865435398864, "episode": 11.0, "Q1 loss": 0.050647600710391996, "Q2 loss": 0.049788030326366424, "Mean Target Q": 1.4218286638259887, "Mean Q1": 1.4215549831390382, "Mean Q2": 1.421726138114929, "critic_loss": 0.10043563121557236, "batch_reward": 0.17869734144210817, "actor_loss": -1.8250136432193576, "actor_target_entropy": -6.0, "actor_entropy": 7.497285116286505, "alpha_loss": 0.9764378950709388, "alpha_value": 0.09845942941544959, "duration": 242.57951974868774, "step": 1375}
{"episode_reward": 26.590165920795403, "episode": 12.0, "Q1 loss": 0.05112673595547676, "Q2 loss": 0.049523131400346754, "Mean Target Q": 1.7015085554122924, "Mean Q1": 1.7009241285324097, "Mean Q2": 1.70061349773407, "critic_loss": 0.1006498670578003, "batch_reward": 0.1778451052904129, "actor_loss": -2.1053424746759477, "actor_target_entropy": -6.0, "actor_entropy": 7.426849219106859, "alpha_loss": 0.9552351169047817, "alpha_value": 0.09785307804529476, "duration": 232.66264462471008, "step": 1500}
{"episode_reward": 20.180510273920913, "episode": 13.0, "Q1 loss": 0.0534973067343235, "Q2 loss": 0.051430664747953415, "Mean Target Q": 1.9532801971435547, "Mean Q1": 1.9525578861236572, "Mean Q2": 1.9528305368423462, "critic_loss": 0.10492797142267227, "batch_reward": 0.18564278745651244, "actor_loss": -2.3568799836294994, "actor_target_entropy": -6.0, "actor_entropy": 7.250044149065775, "alpha_loss": 0.9290845138686044, "alpha_value": 0.09726103695095782, "duration": 257.2193064689636, "step": 1625}
{"episode_reward": 39.22600480811117, "episode": 14.0, "Q1 loss": 0.052784427464008334, "Q2 loss": 0.05091699400544167, "Mean Target Q": 2.1981061553955077, "Mean Q1": 2.1974569492340086, "Mean Q2": 2.1972488708496094, "critic_loss": 0.1037014217376709, "batch_reward": 0.1987074842453003, "actor_loss": -2.6216251081035984, "actor_target_entropy": -6.0, "actor_entropy": 7.0073675417131, "alpha_loss": 0.8834953433082949, "alpha_value": 0.09668813006263033, "duration": 241.92952227592468, "step": 1750}
{"episode_reward": 64.8297610804732, "episode": 15.0, "Q1 loss": 0.11002486351132393, "Q2 loss": 0.11113866958022117, "Mean Target Q": 2.453344331741333, "Mean Q1": 2.4501793365478517, "Mean Q2": 2.4489531717300417, "critic_loss": 0.22116353315114975, "batch_reward": 0.22173311591148376, "actor_loss": -2.893997801674737, "actor_target_entropy": -6.0, "actor_entropy": 6.8287530777946355, "alpha_loss": 0.8307889945923336, "alpha_value": 0.09614394448003619, "duration": 251.57511568069458, "step": 1875}
{"episode_reward": 55.21951763303467, "episode": 16.0, "Q1 loss": 0.1106667783856392, "Q2 loss": 0.11071887743473054, "Mean Target Q": 3.1679065399169923, "Mean Q1": 3.1647312850952147, "Mean Q2": 3.16650612449646, "critic_loss": 0.22138565587997436, "batch_reward": 0.23188253951072693, "actor_loss": -3.535699894351344, "actor_target_entropy": -6.0, "actor_entropy": 7.9652695040549, "alpha_loss": 0.9295157319115054, "alpha_value": 0.09558165801231137, "duration": 246.78832006454468, "step": 2000}
{"episode_reward": 49.49007916614022, "episode": 17.0, "Q1 loss": 0.08036551955342293, "Q2 loss": 0.07954343780875206, "Mean Target Q": 3.2598979263305665, "Mean Q1": 3.2602509117126464, "Mean Q2": 3.259344051361084, "critic_loss": 0.15990895718336107, "batch_reward": 0.2427654300928116, "actor_loss": -3.637498041940114, "actor_target_entropy": -6.0, "actor_entropy": 7.599693532974001, "alpha_loss": 0.8727916384500171, "alpha_value": 0.09500038565255692, "duration": 250.59069895744324, "step": 2125}
{"episode_reward": 57.13897482517025, "episode": 18.0, "Q1 loss": 0.09069979500770568, "Q2 loss": 0.08944191443920135, "Mean Target Q": 3.5646581153869628, "Mean Q1": 3.563121105194092, "Mean Q2": 3.563575855255127, "critic_loss": 0.18014170980453492, "batch_reward": 0.25554140031337735, "actor_loss": -3.9796166842983616, "actor_target_entropy": -6.0, "actor_entropy": 7.262738989245507, "alpha_loss": 0.8176518303732718, "alpha_value": 0.09445400391803511, "duration": 254.10594630241394, "step": 2250}
{"episode_reward": 71.8073214657291, "episode": 19.0, "Q1 loss": 0.16297180080413817, "Q2 loss": 0.16181708490848543, "Mean Target Q": 3.996247407913208, "Mean Q1": 3.9932764358520507, "Mean Q2": 3.9937301177978517, "critic_loss": 0.32478888642787934, "batch_reward": 0.2750998898744583, "actor_loss": -4.39056244350615, "actor_target_entropy": -6.0, "actor_entropy": 7.212251943255228, "alpha_loss": 0.811497257815467, "alpha_value": 0.0939332354413671, "duration": 223.5999150276184, "step": 2375}
{"episode_reward": 59.05076514916052, "episode": 20.0, "Q1 loss": 0.11673949944972992, "Q2 loss": 0.11544650381803513, "Mean Target Q": 4.4108162651062015, "Mean Q1": 4.409055248260498, "Mean Q2": 4.408692939758301, "critic_loss": 0.2321860032081604, "batch_reward": 0.2878737493753433, "actor_loss": -4.828393613138506, "actor_target_entropy": -6.0, "actor_entropy": 7.000774914218534, "alpha_loss": 0.7706288022379721, "alpha_value": 0.09340707597880613, "duration": 222.8468828201294, "step": 2500}
{"episode_reward": 89.65814058466732, "episode": 21.0, "Q1 loss": 0.1579927276968956, "Q2 loss": 0.15718328392505646, "Mean Target Q": 4.58358950805664, "Mean Q1": 4.584175922393799, "Mean Q2": 4.584610919952393, "critic_loss": 0.3151760132312775, "batch_reward": 0.3068174510002136, "actor_loss": -5.091672715686617, "actor_target_entropy": -6.0, "actor_entropy": 6.820034034668454, "alpha_loss": 0.6520387596554227, "alpha_value": 0.09293787578306224, "duration": 231.0717511177063, "step": 2625}
{"episode_reward": 32.917449173863254, "episode": 22.0, "Q1 loss": 0.16524067491292954, "Q2 loss": 0.16482282674312593, "Mean Target Q": 4.887628196716308, "Mean Q1": 4.886441223144531, "Mean Q2": 4.886350547790527, "critic_loss": 0.33006350135803225, "batch_reward": 0.314581449508667, "actor_loss": -5.54443790835719, "actor_target_entropy": -6.0, "actor_entropy": 6.40838506144862, "alpha_loss": 0.5675487354878457, "alpha_value": 0.09252650664114812, "duration": 222.0388205051422, "step": 2750}
{"episode_reward": 107.04401247803038, "episode": 23.0, "Q1 loss": 0.16873328334093093, "Q2 loss": 0.1705567603111267, "Mean Target Q": 5.397940280914306, "Mean Q1": 5.396363426208496, "Mean Q2": 5.396018230438233, "critic_loss": 0.3392900426387787, "batch_reward": 0.32859472298622133, "actor_loss": -6.192043788849362, "actor_target_entropy": -6.0, "actor_entropy": 6.028716564178467, "alpha_loss": 0.49871337981451125, "alpha_value": 0.09215914443771375, "duration": 238.42596435546875, "step": 2875}
{"episode_reward": 37.24135823768352, "episode": 24.0, "Q1 loss": 0.16460186564922333, "Q2 loss": 0.16578193891048432, "Mean Target Q": 5.971270179748535, "Mean Q1": 5.970052852630615, "Mean Q2": 5.970258010864258, "critic_loss": 0.33038380384445193, "batch_reward": 0.3301688184738159, "actor_loss": -6.840588008203814, "actor_target_entropy": -6.0, "actor_entropy": 5.941619311609576, "alpha_loss": 0.47007451086275037, "alpha_value": 0.09181623644815935, "duration": 235.53338265419006, "step": 3000}
{"episode_reward": 54.06305755291679, "episode": 25.0, "Q1 loss": 0.1564627023935318, "Q2 loss": 0.15739624387025833, "Mean Target Q": 6.6512103958129885, "Mean Q1": 6.650526264190674, "Mean Q2": 6.650544120788574, "critic_loss": 0.31385894560813904, "batch_reward": 0.3450070114135742, "actor_loss": -7.501029317341153, "actor_target_entropy": -6.0, "actor_entropy": 5.834474124605694, "alpha_loss": 0.4765487762670668, "alpha_value": 0.09147076621022623, "duration": 235.6879367828369, "step": 3125}
{"episode_reward": 122.71627332776852, "episode": 26.0, "Q1 loss": 0.16181465834379197, "Q2 loss": 0.16437755215167998, "Mean Target Q": 7.371044261932373, "Mean Q1": 7.369898063659668, "Mean Q2": 7.370006298065186, "critic_loss": 0.3261922097206116, "batch_reward": 0.36332200407981874, "actor_loss": -8.186494488869943, "actor_target_entropy": -6.0, "actor_entropy": 5.764889863229567, "alpha_loss": 0.4790378260997034, "alpha_value": 0.09111352487773386, "duration": 239.8804051876068, "step": 3250}
{"episode_reward": 58.8805497617584, "episode": 27.0, "Q1 loss": 0.1453316926956177, "Q2 loss": 0.14661368644237519, "Mean Target Q": 7.953760002136231, "Mean Q1": 7.951968238830567, "Mean Q2": 7.951974468231201, "critic_loss": 0.2919453779459, "batch_reward": 0.36833230781555176, "actor_loss": -8.686741238548642, "actor_target_entropy": -6.0, "actor_entropy": 5.874379097469269, "alpha_loss": 0.5095449529943012, "alpha_value": 0.0907352641261126, "duration": 224.79416704177856, "step": 3375}
{"episode_reward": 71.50044755290283, "episode": 28.0, "Q1 loss": 0.13164617770910264, "Q2 loss": 0.13307865917682649, "Mean Target Q": 8.470851600646972, "Mean Q1": 8.46874111175537, "Mean Q2": 8.4684310836792, "critic_loss": 0.26472483670711516, "batch_reward": 0.36725869369506836, "actor_loss": -9.147180464959913, "actor_target_entropy": -6.0, "actor_entropy": 5.879732031976023, "alpha_loss": 0.5403968264018336, "alpha_value": 0.0903217401087305, "duration": 230.43839240074158, "step": 3500}
{"episode_reward": 22.25934851407051, "episode": 29.0, "Q1 loss": 0.1214151782989502, "Q2 loss": 0.1226998586654663, "Mean Target Q": 8.883517150878907, "Mean Q1": 8.883757537841797, "Mean Q2": 8.883912063598633, "critic_loss": 0.24411503553390504, "batch_reward": 0.3606096086502075, "actor_loss": -9.51468581245059, "actor_target_entropy": -6.0, "actor_entropy": 5.957883047679114, "alpha_loss": 0.5590090354283651, "alpha_value": 0.0898865724608162, "duration": 223.80835270881653, "step": 3625}
{"episode_reward": 42.23686652975207, "episode": 30.0, "Q1 loss": 0.11474754720926285, "Q2 loss": 0.11628443348407745, "Mean Target Q": 9.366358192443847, "Mean Q1": 9.36538436126709, "Mean Q2": 9.36463208770752, "critic_loss": 0.23103198099136352, "batch_reward": 0.36595605993270874, "actor_loss": -9.974068180207283, "actor_target_entropy": -6.0, "actor_entropy": 5.949345604065926, "alpha_loss": 0.5659599842563752, "alpha_value": 0.08943312542094187, "duration": 243.11767101287842, "step": 3750}
{"episode_reward": 67.04322618181625, "episode": 31.0, "Q1 loss": 0.11596979409456253, "Q2 loss": 0.11925642865896224, "Mean Target Q": 9.914699279785156, "Mean Q1": 9.91359538269043, "Mean Q2": 9.914378883361817, "critic_loss": 0.23522622227668763, "batch_reward": 0.38020241069793703, "actor_loss": -10.492670498197041, "actor_target_entropy": -6.0, "actor_entropy": 5.973744838956803, "alpha_loss": 0.5654256353302608, "alpha_value": 0.08897371434246089, "duration": 233.0229835510254, "step": 3875}
{"episode_reward": 128.00126590741016, "episode": 32.0, "Q1 loss": 0.12677028107643126, "Q2 loss": 0.1270493949651718, "Mean Target Q": 10.475387908935547, "Mean Q1": 10.474408226013184, "Mean Q2": 10.473948783874512, "critic_loss": 0.25381967675685885, "batch_reward": 0.3889746739864349, "actor_loss": -11.059698227913149, "actor_target_entropy": -6.0, "actor_entropy": 5.961956254897579, "alpha_loss": 0.5681737209520032, "alpha_value": 0.08850962889749864, "duration": 212.90201830863953, "step": 4000}
{"episode_reward": 63.193253913777426, "episode": 33.0, "Q1 loss": 0.1336458733677864, "Q2 loss": 0.13632017016410827, "Mean Target Q": 11.05176123046875, "Mean Q1": 11.049862747192384, "Mean Q2": 11.04983561706543, "critic_loss": 0.26996604347229003, "batch_reward": 0.4051692707538605, "actor_loss": -11.587595606607104, "actor_target_entropy": -6.0, "actor_entropy": 5.900217071412102, "alpha_loss": 0.5628525179529947, "alpha_value": 0.08804443855219937, "duration": 223.26426458358765, "step": 4125}
{"episode_reward": 164.6670885781546, "episode": 34.0, "Q1 loss": 0.12500518387556075, "Q2 loss": 0.12422547447681427, "Mean Target Q": 11.69724127960205, "Mean Q1": 11.69725764465332, "Mean Q2": 11.69680731201172, "critic_loss": 0.24923065900802613, "batch_reward": 0.43220500230789183, "actor_loss": -12.255413193856516, "actor_target_entropy": -6.0, "actor_entropy": 5.807073054775115, "alpha_loss": 0.5530975528301731, "alpha_value": 0.08758137426502687, "duration": 231.26198601722717, "step": 4250}
{"episode_reward": 144.44253906115713, "episode": 35.0, "Q1 loss": 0.13115176874399184, "Q2 loss": 0.13260257452726365, "Mean Target Q": 12.297145011901856, "Mean Q1": 12.296615127563477, "Mean Q2": 12.297302841186523, "critic_loss": 0.26375434231758116, "batch_reward": 0.454221577167511, "actor_loss": -12.822496505010696, "actor_target_entropy": -6.0, "actor_entropy": 5.777093652694944, "alpha_loss": 0.5474466757168845, "alpha_value": 0.08712308061375888, "duration": 236.2157838344574, "step": 4375}
{"episode_reward": 157.7436779726518, "episode": 36.0, "Q1 loss": 0.1379085328578949, "Q2 loss": 0.13937305587530135, "Mean Target Q": 12.898134117126466, "Mean Q1": 12.89718074798584, "Mean Q2": 12.89705982208252, "critic_loss": 0.27728158795833585, "batch_reward": 0.47146181321144104, "actor_loss": -13.441993897961032, "actor_target_entropy": -6.0, "actor_entropy": 5.64421949848052, "alpha_loss": 0.5337930014056544, "alpha_value": 0.08667024215943343, "duration": 229.58482456207275, "step": 4500}
{"episode_reward": 151.26251618048124, "episode": 37.0, "Q1 loss": 0.13930644631385802, "Q2 loss": 0.13924250841140748, "Mean Target Q": 13.57522688293457, "Mean Q1": 13.573522628784179, "Mean Q2": 13.57408381652832, "critic_loss": 0.2785489536523819, "batch_reward": 0.496338383436203, "actor_loss": -14.143594968886603, "actor_target_entropy": -6.0, "actor_entropy": 5.52640962600708, "alpha_loss": 0.5127281655394842, "alpha_value": 0.08622809908171582, "duration": 231.66084361076355, "step": 4625}
{"episode_reward": 173.92666560206257, "episode": 38.0, "Q1 loss": 0.1424956836104393, "Q2 loss": 0.14792130440473555, "Mean Target Q": 14.13359848022461, "Mean Q1": 14.133222518920899, "Mean Q2": 14.13268091583252, "critic_loss": 0.2904169887304306, "batch_reward": 0.5128086261749267, "actor_loss": -14.707066459040488, "actor_target_entropy": -6.0, "actor_entropy": 5.458587600338843, "alpha_loss": 0.505298973091187, "alpha_value": 0.08579466836744312, "duration": 233.29918789863586, "step": 4750}
{"episode_reward": 51.04294544351171, "episode": 39.0, "Q1 loss": 0.1501855878829956, "Q2 loss": 0.15028578931093217, "Mean Target Q": 14.664336402893067, "Mean Q1": 14.66299600982666, "Mean Q2": 14.663401741027831, "critic_loss": 0.3004713762998581, "batch_reward": 0.5144133095741272, "actor_loss": -15.24819172753228, "actor_target_entropy": -6.0, "actor_entropy": 5.495627577342685, "alpha_loss": 0.4976162290762341, "alpha_value": 0.08536419124031791, "duration": 234.0127716064453, "step": 4875}
{"episode_reward": 168.4194288150708, "episode": 40.0, "Q1 loss": 0.1592436019182205, "Q2 loss": 0.16368813985586167, "Mean Target Q": 15.215274948120117, "Mean Q1": 15.214222633361816, "Mean Q2": 15.213387382507324, "critic_loss": 0.32293174147605896, "batch_reward": 0.5299905889034271, "actor_loss": -15.793950050107894, "actor_target_entropy": -6.0, "actor_entropy": 5.460968786670316, "alpha_loss": 0.4863287840158709, "alpha_value": 0.0849403099264207, "step": 5000}
{"duration": 245.3214852809906, "step": 5000}
{"episode_reward": 53.442790821703454, "episode": 41.0, "Q1 loss": 0.15548050510883332, "Q2 loss": 0.15571143454313277, "Mean Target Q": 15.761021881103515, "Mean Q1": 15.75961215209961, "Mean Q2": 15.75992576599121, "critic_loss": 0.31119194042682646, "batch_reward": 0.5380226151943207, "actor_loss": -16.359050114949543, "actor_target_entropy": -6.0, "actor_entropy": 5.4325766487727085, "alpha_loss": 0.47862940317108515, "alpha_value": 0.08451953566284089, "duration": 241.05587315559387, "step": 5125}
{"episode_reward": 150.49819097932954, "episode": 42.0, "Q1 loss": 0.16558950406312942, "Q2 loss": 0.16735535180568695, "Mean Target Q": 16.403916435241698, "Mean Q1": 16.403351486206056, "Mean Q2": 16.403463150024415, "critic_loss": 0.33294485545158387, "batch_reward": 0.5565867242813111, "actor_loss": -17.018870169116603, "actor_target_entropy": -6.0, "actor_entropy": 5.317289567762805, "alpha_loss": 0.473755931661975, "alpha_value": 0.08409995828062179, "duration": 236.0314393043518, "step": 5250}
{"episode_reward": 241.79918260260402, "episode": 43.0, "Q1 loss": 0.1596310080885887, "Q2 loss": 0.1625268074274063, "Mean Target Q": 17.16168753051758, "Mean Q1": 17.160229049682616, "Mean Q2": 17.159933212280272, "critic_loss": 0.32215781593322756, "batch_reward": 0.5868749380111694, "actor_loss": -17.745540830824112, "actor_target_entropy": -6.0, "actor_entropy": 5.296531351785811, "alpha_loss": 0.46343582679354955, "alpha_value": 0.08368507676127117, "duration": 239.06941390037537, "step": 5375}
{"episode_reward": 198.46623543065837, "episode": 44.0, "Q1 loss": 0.1832039624452591, "Q2 loss": 0.18558115780353546, "Mean Target Q": 17.835379196166993, "Mean Q1": 17.834727478027343, "Mean Q2": 17.834632934570312, "critic_loss": 0.3687851197719574, "batch_reward": 0.6031999559402466, "actor_loss": -18.447887574472734, "actor_target_entropy": -6.0, "actor_entropy": 5.256765773219447, "alpha_loss": 0.45027641711696503, "alpha_value": 0.08327638198286783, "duration": 226.47946190834045, "step": 5500}
{"episode_reward": 104.4063058052845, "episode": 45.0, "Q1 loss": 0.19878055334091185, "Q2 loss": 0.20018161725997924, "Mean Target Q": 18.413872055053712, "Mean Q1": 18.41362774658203, "Mean Q2": 18.413660385131838, "critic_loss": 0.3989621715545654, "batch_reward": 0.6161221294403076, "actor_loss": -19.030217700534397, "actor_target_entropy": -6.0, "actor_entropy": 5.2231171320355125, "alpha_loss": 0.44146702261198134, "alpha_value": 0.08287387631953634, "duration": 240.56304740905762, "step": 5625}
{"episode_reward": 126.6302460414992, "episode": 46.0, "Q1 loss": 0.19362983870506287, "Q2 loss": 0.19957226049900054, "Mean Target Q": 19.06642578125, "Mean Q1": 19.064531295776366, "Mean Q2": 19.064352432250978, "critic_loss": 0.39320210003852846, "batch_reward": 0.6246240239143371, "actor_loss": -19.71973496098672, "actor_target_entropy": -6.0, "actor_entropy": 5.19285007446043, "alpha_loss": 0.43308095393642304, "alpha_value": 0.08247414230268411, "duration": 236.50051307678223, "step": 5750}
{"episode_reward": 198.122262880529, "episode": 47.0, "Q1 loss": 0.22155546295642853, "Q2 loss": 0.22392847418785095, "Mean Target Q": 19.797895980834962, "Mean Q1": 19.79661309814453, "Mean Q2": 19.797121551513673, "critic_loss": 0.4454839353561401, "batch_reward": 0.6438600354194641, "actor_loss": -20.469405340769935, "actor_target_entropy": -6.0, "actor_entropy": 5.013110395461794, "alpha_loss": 0.42545838961525567, "alpha_value": 0.08207995402106259, "duration": 231.98423075675964, "step": 5875}
{"episode_reward": 167.0455370017969, "episode": 48.0, "Q1 loss": 0.24483343517780304, "Q2 loss": 0.24749977672100068, "Mean Target Q": 20.335193908691405, "Mean Q1": 20.334947799682617, "Mean Q2": 20.335150497436523, "critic_loss": 0.49233321285247805, "batch_reward": 0.6505738840103149, "actor_loss": -20.94653372610769, "actor_target_entropy": -6.0, "actor_entropy": 5.064276764469762, "alpha_loss": 0.4212247359175836, "alpha_value": 0.08168930727824866, "duration": 242.6250512599945, "step": 6000}
{"episode_reward": 63.675623775969015, "episode": 49.0, "Q1 loss": 0.24089573287963867, "Q2 loss": 0.24431391942501068, "Mean Target Q": 20.954488510131835, "Mean Q1": 20.953463821411134, "Mean Q2": 20.95239094543457, "critic_loss": 0.48520965218544004, "batch_reward": 0.6545136332511902, "actor_loss": -21.638241359165736, "actor_target_entropy": -6.0, "actor_entropy": 4.972026385958233, "alpha_loss": 0.4147536016645886, "alpha_value": 0.0812992032077827, "duration": 237.51732468605042, "step": 6125}
{"episode_reward": 151.148650594881, "episode": 50.0, "Q1 loss": 0.26952995550632475, "Q2 loss": 0.269218220114708, "Mean Target Q": 21.62483529663086, "Mean Q1": 21.62443193054199, "Mean Q2": 21.624433151245118, "critic_loss": 0.5387481789588928, "batch_reward": 0.6695883402824402, "actor_loss": -22.368822805343136, "actor_target_entropy": -6.0, "actor_entropy": 4.930378421660392, "alpha_loss": 0.4055822337827375, "alpha_value": 0.08090901008029447, "duration": 229.3954005241394, "step": 6250}
{"episode_reward": 204.4064898568227, "episode": 51.0, "Q1 loss": 0.28171811532974245, "Q2 loss": 0.28141364645957945, "Mean Target Q": 22.335143493652343, "Mean Q1": 22.333113082885742, "Mean Q2": 22.333500366210938, "critic_loss": 0.5631317627429963, "batch_reward": 0.688122314453125, "actor_loss": -22.967759874131943, "actor_target_entropy": -6.0, "actor_entropy": 4.892892852662102, "alpha_loss": 0.3996494242123195, "alpha_value": 0.08052353755489583, "duration": 231.752783536911, "step": 6375}
{"episode_reward": 207.99482563162115, "episode": 52.0, "Q1 loss": 0.2915059492588043, "Q2 loss": 0.29727980065345766, "Mean Target Q": 23.19582795715332, "Mean Q1": 23.194394638061524, "Mean Q2": 23.194652557373047, "critic_loss": 0.5887857496738433, "batch_reward": 0.7093060603141784, "actor_loss": -23.91292098260695, "actor_target_entropy": -6.0, "actor_entropy": 4.818789112952448, "alpha_loss": 0.38646104018534383, "alpha_value": 0.08014606996017985, "duration": 229.7506833076477, "step": 6500}
{"episode_reward": 233.01364097604193, "episode": 53.0, "Q1 loss": 0.3003656302690506, "Q2 loss": 0.30599788546562195, "Mean Target Q": 23.936582183837892, "Mean Q1": 23.9354638671875, "Mean Q2": 23.93488397216797, "critic_loss": 0.6063635153770447, "batch_reward": 0.7186890993118286, "actor_loss": -24.634241861010356, "actor_target_entropy": -6.0, "actor_entropy": 4.819488305894155, "alpha_loss": 0.3801523385539887, "alpha_value": 0.07977540487914558, "duration": 244.1871087551117, "step": 6625}
{"episode_reward": 49.397116516244346, "episode": 54.0, "Q1 loss": 0.29151731038093565, "Q2 loss": 0.2889513012170792, "Mean Target Q": 24.476472396850586, "Mean Q1": 24.475216812133787, "Mean Q2": 24.47551091003418, "critic_loss": 0.5804686098098755, "batch_reward": 0.7226183295249939, "actor_loss": -25.17425158716017, "actor_target_entropy": -6.0, "actor_entropy": 4.728395562018117, "alpha_loss": 0.38144449793523355, "alpha_value": 0.07940169825343169, "duration": 243.98322677612305, "step": 6750}
{"episode_reward": 244.98890481152839, "episode": 55.0, "Q1 loss": 0.3095171666145325, "Q2 loss": 0.31006078243255614, "Mean Target Q": 25.374678665161134, "Mean Q1": 25.37414205932617, "Mean Q2": 25.374791748046874, "critic_loss": 0.6195779449939728, "batch_reward": 0.7472113094329834, "actor_loss": -26.043688425942072, "actor_target_entropy": -6.0, "actor_entropy": 4.690664124867273, "alpha_loss": 0.370855717904984, "alpha_value": 0.07902713484709253, "duration": 253.5276288986206, "step": 6875}
{"episode_reward": 158.40317916982167, "episode": 56.0, "Q1 loss": 0.3345848740339279, "Q2 loss": 0.33247119617462156, "Mean Target Q": 26.09794886779785, "Mean Q1": 26.096326538085936, "Mean Q2": 26.0959755859375, "critic_loss": 0.6670560698509216, "batch_reward": 0.7556911935806274, "actor_loss": -26.75785267737604, "actor_target_entropy": -6.0, "actor_entropy": 4.708321309858753, "alpha_loss": 0.36706753603873715, "alpha_value": 0.07865862925786488, "duration": 254.6587016582489, "step": 7000}
{"episode_reward": 228.5828433335488, "episode": 57.0, "Q1 loss": 0.32467515182495116, "Q2 loss": 0.3296611473560333, "Mean Target Q": 26.905268676757814, "Mean Q1": 26.903969116210938, "Mean Q2": 26.903761276245117, "critic_loss": 0.6543363020420074, "batch_reward": 0.7712792582511901, "actor_loss": -27.527761459350586, "actor_target_entropy": -6.0, "actor_entropy": 4.686980239928714, "alpha_loss": 0.3647137691104223, "alpha_value": 0.07828874998421849, "duration": 244.7834508419037, "step": 7125}
{"episode_reward": 260.0484838557945, "episode": 58.0, "Q1 loss": 0.3476064703464508, "Q2 loss": 0.35041308522224424, "Mean Target Q": 27.846114013671876, "Mean Q1": 27.8460810546875, "Mean Q2": 27.845227127075194, "critic_loss": 0.6980195546150207, "batch_reward": 0.8016610236167908, "actor_loss": -28.511571391936272, "actor_target_entropy": -6.0, "actor_entropy": 4.62923276808954, "alpha_loss": 0.3549266183568585, "alpha_value": 0.07792182392311327, "duration": 232.5088756084442, "step": 7250}
{"episode_reward": 265.81758098542895, "episode": 59.0, "Q1 loss": 0.3265947415828705, "Q2 loss": 0.32498688852787017, "Mean Target Q": 28.73046076965332, "Mean Q1": 28.727684799194336, "Mean Q2": 28.72872166442871, "critic_loss": 0.6515816316604615, "batch_reward": 0.8204593648910522, "actor_loss": -29.403320403326127, "actor_target_entropy": -6.0, "actor_entropy": 4.51309533346267, "alpha_loss": 0.3464655417298514, "alpha_value": 0.077560827432333, "duration": 236.21821308135986, "step": 7375}
{"episode_reward": 231.73102238960803, "episode": 60.0, "Q1 loss": 0.3275777430534363, "Q2 loss": 0.34076310992240905, "Mean Target Q": 29.636850967407227, "Mean Q1": 29.63706350708008, "Mean Q2": 29.635832763671875, "critic_loss": 0.6683408541679382, "batch_reward": 0.84441619348526, "actor_loss": -30.352072961868778, "actor_target_entropy": -6.0, "actor_entropy": 4.384243272965954, "alpha_loss": 0.33831645692548445, "alpha_value": 0.07720352070423446, "duration": 222.77240014076233, "step": 7500}
{"episode_reward": 273.2269654855509, "episode": 61.0, "Q1 loss": 0.40548657488822937, "Q2 loss": 0.4064311187267303, "Mean Target Q": 30.391397842407226, "Mean Q1": 30.389392990112306, "Mean Q2": 30.39000584411621, "critic_loss": 0.8119176921844482, "batch_reward": 0.8513741512298584, "actor_loss": -31.10302882724338, "actor_target_entropy": -6.0, "actor_entropy": 4.3898464687286864, "alpha_loss": 0.33298833502663505, "alpha_value": 0.07685064644486696, "duration": 243.5520350933075, "step": 7625}
{"episode_reward": 146.33807279637603, "episode": 62.0, "Q1 loss": 0.40148786616325377, "Q2 loss": 0.4076386890411377, "Mean Target Q": 31.156527725219725, "Mean Q1": 31.155011199951172, "Mean Q2": 31.154781173706056, "critic_loss": 0.8091265559196472, "batch_reward": 0.8743220500946045, "actor_loss": -31.776556353415213, "actor_target_entropy": -6.0, "actor_entropy": 4.327702180031808, "alpha_loss": 0.3310936838388443, "alpha_value": 0.07649833552102471, "duration": 238.432377576828, "step": 7750}
{"episode_reward": 294.14275962842396, "episode": 63.0, "Q1 loss": 0.44014093017578126, "Q2 loss": 0.4439161722660065, "Mean Target Q": 31.98565756225586, "Mean Q1": 31.98569647216797, "Mean Q2": 31.9849793548584, "critic_loss": 0.8840571012496948, "batch_reward": 0.8950968222618103, "actor_loss": -32.54658529493544, "actor_target_entropy": -6.0, "actor_entropy": 4.213352233644516, "alpha_loss": 0.32446404818504576, "alpha_value": 0.07614520582840824, "duration": 234.1222198009491, "step": 7875}
{"episode_reward": 187.2203624636735, "episode": 64.0, "Q1 loss": 0.4560579631328583, "Q2 loss": 0.4627698588371277, "Mean Target Q": 32.66611410522461, "Mean Q1": 32.66437446594238, "Mean Q2": 32.66522354125976, "critic_loss": 0.9188278231620789, "batch_reward": 0.8969417200088501, "actor_loss": -33.28656375023626, "actor_target_entropy": -6.0, "actor_entropy": 4.195072300972477, "alpha_loss": 0.31989052843663, "alpha_value": 0.07579529371834332, "duration": 246.93124270439148, "step": 8000}
{"episode_reward": 245.21983718850763, "episode": 65.0, "Q1 loss": 0.530622618675232, "Q2 loss": 0.5288166794776916, "Mean Target Q": 33.42691799926758, "Mean Q1": 33.42358990478515, "Mean Q2": 33.42318798828125, "critic_loss": 1.0594392986297607, "batch_reward": 0.9089974293708801, "actor_loss": -34.154823061019655, "actor_target_entropy": -6.0, "actor_entropy": 4.157631983832707, "alpha_loss": 0.3028107862623911, "alpha_value": 0.0754549771272718, "duration": 240.83377933502197, "step": 8125}
{"episode_reward": 125.00960988432266, "episode": 66.0, "Q1 loss": 0.5284904100894928, "Q2 loss": 0.5343211183547973, "Mean Target Q": 34.13367138671875, "Mean Q1": 34.135086730957035, "Mean Q2": 34.13475039672851, "critic_loss": 1.0628115329742431, "batch_reward": 0.9157135362625122, "actor_loss": -34.834007509293095, "actor_target_entropy": -6.0, "actor_entropy": 4.132237668960325, "alpha_loss": 0.3050962994175573, "alpha_value": 0.07511863168921012, "duration": 243.10799717903137, "step": 8250}
{"episode_reward": 278.3381007261717, "episode": 67.0, "Q1 loss": 0.5171869564056396, "Q2 loss": 0.5189414627552033, "Mean Target Q": 35.127450714111326, "Mean Q1": 35.12638778686524, "Mean Q2": 35.12658377075196, "critic_loss": 1.0361284174919128, "batch_reward": 0.9420736608505249, "actor_loss": -35.77935003855872, "actor_target_entropy": -6.0, "actor_entropy": 4.047915787923904, "alpha_loss": 0.29050324526098037, "alpha_value": 0.07478388443727967, "duration": 235.83087968826294, "step": 8375}
{"episode_reward": 302.7235078496228, "episode": 68.0, "Q1 loss": 0.5160721108913422, "Q2 loss": 0.5148430998325348, "Mean Target Q": 36.08975369262696, "Mean Q1": 36.08669485473633, "Mean Q2": 36.086572631835935, "critic_loss": 1.0309152116775513, "batch_reward": 0.960775104045868, "actor_loss": -36.768574622369584, "actor_target_entropy": -6.0, "actor_entropy": 4.024277802436583, "alpha_loss": 0.2767406194921463, "alpha_value": 0.07446249717492573, "duration": 250.28267121315002, "step": 8500}
{"episode_reward": 272.2525109318923, "episode": 69.0, "Q1 loss": 0.5839033150672912, "Q2 loss": 0.5824866135120392, "Mean Target Q": 37.06386175537109, "Mean Q1": 37.06187417602539, "Mean Q2": 37.06196807861328, "critic_loss": 1.1663899269104003, "batch_reward": 0.984495825767517, "actor_loss": -37.76537329053122, "actor_target_entropy": -6.0, "actor_entropy": 4.019534020196824, "alpha_loss": 0.2613803153000181, "alpha_value": 0.07415369832682955, "duration": 244.36893153190613, "step": 8625}
{"episode_reward": 326.0331931717134, "episode": 70.0, "Q1 loss": 0.5239532532691955, "Q2 loss": 0.5342416162490845, "Mean Target Q": 38.011622650146485, "Mean Q1": 38.010730407714846, "Mean Q2": 38.01127194213867, "critic_loss": 1.0581948709487916, "batch_reward": 0.9991226229667663, "actor_loss": -38.75043069162676, "actor_target_entropy": -6.0, "actor_entropy": 3.941487016216401, "alpha_loss": 0.24964588303719798, "alpha_value": 0.07385590597241395, "duration": 232.26859402656555, "step": 8750}
{"episode_reward": 230.21235256136194, "episode": 71.0, "Q1 loss": 0.5475198101997375, "Q2 loss": 0.5559440250396729, "Mean Target Q": 38.77263098144531, "Mean Q1": 38.77411767578125, "Mean Q2": 38.773741943359376, "critic_loss": 1.1034638333320617, "batch_reward": 1.014256378173828, "actor_loss": -39.466243743896484, "actor_target_entropy": -6.0, "actor_entropy": 4.013526231523544, "alpha_loss": 0.24529529729532817, "alpha_value": 0.07356150287682958, "duration": 244.50341296195984, "step": 8875}
{"episode_reward": 324.12273233485513, "episode": 72.0, "Q1 loss": 0.6014344916343689, "Q2 loss": 0.6050314064025879, "Mean Target Q": 39.803757293701175, "Mean Q1": 39.80082971191406, "Mean Q2": 39.8002841796875, "critic_loss": 1.2064659032821656, "batch_reward": 1.033870391845703, "actor_loss": -40.53408241271973, "actor_target_entropy": -6.0, "actor_entropy": 4.0095294137154855, "alpha_loss": 0.23311873140834993, "alpha_value": 0.07327578969683304, "duration": 242.07879066467285, "step": 9000}
{"episode_reward": 312.83924008063224, "episode": 73.0, "Q1 loss": 5.6409361729621885, "Q2 loss": 5.517748742580414, "Mean Target Q": 40.24881860351562, "Mean Q1": 40.21803454589844, "Mean Q2": 40.21540063476562, "critic_loss": 11.158684882640838, "batch_reward": 1.053376899242401, "actor_loss": -41.088753715394034, "actor_target_entropy": -6.0, "actor_entropy": 5.807292764149015, "alpha_loss": 0.02642911028981741, "alpha_value": 0.07308792222753735, "duration": 235.6530635356903, "step": 9125}
{"episode_reward": 114.51515302891603, "episode": 74.0, "Q1 loss": 1.38866738986969, "Q2 loss": 1.3525081968307495, "Mean Target Q": 41.66549844360352, "Mean Q1": 41.66265182495117, "Mean Q2": 41.660879486083985, "critic_loss": 2.741175579071045, "batch_reward": 1.0372574863433839, "actor_loss": -42.65045559790827, "actor_target_entropy": -6.0, "actor_entropy": 6.2509516131493355, "alpha_loss": 0.10355343296748376, "alpha_value": 0.07305906148718627, "duration": 242.44999933242798, "step": 9250}
{"episode_reward": 44.569748504364306, "episode": 75.0, "Q1 loss": 1.3756621236801148, "Q2 loss": 1.3341033811569214, "Mean Target Q": 42.54140399169922, "Mean Q1": 42.538907135009765, "Mean Q2": 42.538592742919924, "critic_loss": 2.709765507698059, "batch_reward": 1.0380775127410888, "actor_loss": -43.18672519259982, "actor_target_entropy": -6.0, "actor_entropy": 5.9583957687256826, "alpha_loss": 0.23007497498913418, "alpha_value": 0.07282548541381223, "duration": 249.5797474384308, "step": 9375}
{"episode_reward": 129.21811301149222, "episode": 76.0, "Q1 loss": 1.384108976840973, "Q2 loss": 1.3728046970367431, "Mean Target Q": 43.21477420043945, "Mean Q1": 43.21564611816406, "Mean Q2": 43.21532382202148, "critic_loss": 2.7569136610031126, "batch_reward": 1.0357477464675904, "actor_loss": -43.89632157356508, "actor_target_entropy": -6.0, "actor_entropy": 5.458598129210934, "alpha_loss": 0.22707809820290534, "alpha_value": 0.07252663289580118, "duration": 231.17980217933655, "step": 9500}
{"episode_reward": 67.71604418892699, "episode": 77.0, "Q1 loss": 1.3068187861442566, "Q2 loss": 1.2934095706939697, "Mean Target Q": 43.78113973999024, "Mean Q1": 43.77851791381836, "Mean Q2": 43.77872088623047, "critic_loss": 2.6002283582687378, "batch_reward": 1.0430284252166748, "actor_loss": -44.39496648879278, "actor_target_entropy": -6.0, "actor_entropy": 5.042421462043883, "alpha_loss": 0.23595455430802845, "alpha_value": 0.07222504319890669, "duration": 238.09581351280212, "step": 9625}
{"episode_reward": 272.9132800495432, "episode": 78.0, "Q1 loss": 1.21858008146286, "Q2 loss": 1.1949988865852357, "Mean Target Q": 44.62627963256836, "Mean Q1": 44.62537991333008, "Mean Q2": 44.62450106811524, "critic_loss": 2.413578974723816, "batch_reward": 1.0534312262535095, "actor_loss": -45.35202783153903, "actor_target_entropy": -6.0, "actor_entropy": 4.656240394038539, "alpha_loss": 0.2282222374793022, "alpha_value": 0.07191546420270815, "duration": 243.12977075576782, "step": 9750}
{"episode_reward": 232.4840915057476, "episode": 79.0, "Q1 loss": 1.23896493434906, "Q2 loss": 1.2186963872909546, "Mean Target Q": 45.42765524291992, "Mean Q1": 45.42774572753906, "Mean Q2": 45.427501373291015, "critic_loss": 2.4576613216400145, "batch_reward": 1.062737944126129, "actor_loss": -46.13520928034707, "actor_target_entropy": -6.0, "actor_entropy": 4.5846636181785945, "alpha_loss": 0.22316896986393703, "alpha_value": 0.07161196735049778, "duration": 244.1622154712677, "step": 9875}
{"episode_reward": 265.99213433217176, "episode": 80.0, "Q1 loss": 1.1612616171836854, "Q2 loss": 1.1558845748901367, "Mean Target Q": 46.382572174072266, "Mean Q1": 46.37964666748047, "Mean Q2": 46.37963180541992, "critic_loss": 2.317146186828613, "batch_reward": 1.0714704751968385, "actor_loss": -47.20197646848617, "actor_target_entropy": -6.0, "actor_entropy": 4.456686931271707, "alpha_loss": 0.22139944977337314, "alpha_value": 0.07130586883110446, "step": 10000}
{"duration": 260.1554093360901, "step": 10000}
{"episode_reward": 278.69219873533825, "episode": 81.0, "Q1 loss": 1.0863889684677124, "Q2 loss": 1.082920687198639, "Mean Target Q": 47.326158081054686, "Mean Q1": 47.326435363769534, "Mean Q2": 47.327549255371096, "critic_loss": 2.169309648513794, "batch_reward": 1.0864659209251404, "actor_loss": -48.09045155843099, "actor_target_entropy": -6.0, "actor_entropy": 4.372244706229558, "alpha_loss": 0.2175309598918945, "alpha_value": 0.0710044532915079, "duration": 285.83602356910706, "step": 10125}
{"episode_reward": 194.22289566727295, "episode": 82.0, "Q1 loss": 1.164245129108429, "Q2 loss": 1.1723496947288514, "Mean Target Q": 48.094350036621094, "Mean Q1": 48.09100347900391, "Mean Q2": 48.092091278076175, "critic_loss": 2.3365948276519775, "batch_reward": 1.09764093208313, "actor_loss": -48.76033684515184, "actor_target_entropy": -6.0, "actor_entropy": 4.304499818432715, "alpha_loss": 0.2134222335392429, "alpha_value": 0.07070133350679164, "duration": 247.73290586471558, "step": 10250}
{"episode_reward": 231.41685701330601, "episode": 83.0, "Q1 loss": 1.1145384497642516, "Q2 loss": 1.0942324872016906, "Mean Target Q": 49.213276062011715, "Mean Q1": 49.21390768432617, "Mean Q2": 49.21229559326172, "critic_loss": 2.2087709455490114, "batch_reward": 1.1127905578613282, "actor_loss": -50.013454013400604, "actor_target_entropy": -6.0, "actor_entropy": 4.159767771524097, "alpha_loss": 0.21187323497401345, "alpha_value": 0.07040437662139354, "duration": 247.9933421611786, "step": 10375}
{"episode_reward": 306.85603272334174, "episode": 84.0, "Q1 loss": 1.0087082629203796, "Q2 loss": 0.995017635345459, "Mean Target Q": 50.03433508300781, "Mean Q1": 50.031860900878904, "Mean Q2": 50.0316911315918, "critic_loss": 2.003725888252258, "batch_reward": 1.12098433303833, "actor_loss": -50.785032456920995, "actor_target_entropy": -6.0, "actor_entropy": 4.09237741270373, "alpha_loss": 0.20918454013524518, "alpha_value": 0.07010226242407562, "duration": 248.52772903442383, "step": 10500}
{"episode_reward": 275.04251613888505, "episode": 85.0, "Q1 loss": 1.0552676515579225, "Q2 loss": 1.0591511754989624, "Mean Target Q": 50.9434303894043, "Mean Q1": 50.943697784423826, "Mean Q2": 50.94370834350586, "critic_loss": 2.1144188232421874, "batch_reward": 1.1393077373504639, "actor_loss": -51.652130005851625, "actor_target_entropy": -6.0, "actor_entropy": 4.041282082360889, "alpha_loss": 0.209658734382145, "alpha_value": 0.06979342658560987, "duration": 246.03113460540771, "step": 10625}
{"episode_reward": 310.3423246984441, "episode": 86.0, "Q1 loss": 0.9905693564414978, "Q2 loss": 0.9942912788391113, "Mean Target Q": 52.07882739257813, "Mean Q1": 52.07688079833984, "Mean Q2": 52.076532684326175, "critic_loss": 1.9848606386184693, "batch_reward": 1.156849274635315, "actor_loss": -52.718300788633286, "actor_target_entropy": -6.0, "actor_entropy": 4.009802649098058, "alpha_loss": 0.20183468297604593, "alpha_value": 0.06949237203216338, "duration": 239.50392770767212, "step": 10750}
{"episode_reward": 286.72478985145165, "episode": 87.0, "Q1 loss": 1.002309977531433, "Q2 loss": 1.019305944442749, "Mean Target Q": 52.81688754272461, "Mean Q1": 52.813122680664065, "Mean Q2": 52.814019348144534, "critic_loss": 2.021615924835205, "batch_reward": 1.164661060333252, "actor_loss": -53.505030011373854, "actor_target_entropy": -6.0, "actor_entropy": 3.904087683511159, "alpha_loss": 0.19792147855910044, "alpha_value": 0.06919623760471794, "duration": 252.35551238059998, "step": 10875}
{"episode_reward": 236.63230288499696, "episode": 88.0, "Q1 loss": 1.0301312561035156, "Q2 loss": 1.022319371700287, "Mean Target Q": 53.657442199707035, "Mean Q1": 53.65649722290039, "Mean Q2": 53.655451080322266, "critic_loss": 2.052450632095337, "batch_reward": 1.1725183687210083, "actor_loss": -54.359170790641535, "actor_target_entropy": -6.0, "actor_entropy": 3.9364213674299178, "alpha_loss": 0.19573333691204747, "alpha_value": 0.0688976031731572, "duration": 237.94008493423462, "step": 11000}
{"episode_reward": 300.3102696283122, "episode": 89.0, "Q1 loss": 1.1558699197769164, "Q2 loss": 1.148148675918579, "Mean Target Q": 54.453392517089846, "Mean Q1": 54.45382800292969, "Mean Q2": 54.45466091918945, "critic_loss": 2.3040185909271242, "batch_reward": 1.1748704233169556, "actor_loss": -55.12811255076575, "actor_target_entropy": -6.0, "actor_entropy": 3.945558203591241, "alpha_loss": 0.1899307372551116, "alpha_value": 0.06860738428378683, "duration": 229.07003784179688, "step": 11125}
{"episode_reward": 57.52641322006363, "episode": 90.0, "Q1 loss": 1.2956325068473815, "Q2 loss": 1.2844579763412476, "Mean Target Q": 55.03302822875977, "Mean Q1": 55.02947100830078, "Mean Q2": 55.02962875366211, "critic_loss": 2.580090476989746, "batch_reward": 1.1781786088943482, "actor_loss": -55.90482828694005, "actor_target_entropy": -6.0, "actor_entropy": 3.9700219785013506, "alpha_loss": 0.18068156078938516, "alpha_value": 0.06831962494081158, "duration": 242.02128958702087, "step": 11250}
{"episode_reward": 322.80387797794117, "episode": 91.0, "Q1 loss": 1.1177997508049011, "Q2 loss": 1.1245714559555053, "Mean Target Q": 56.1057448425293, "Mean Q1": 56.10546813964844, "Mean Q2": 56.10558285522461, "critic_loss": 2.2423712062835692, "batch_reward": 1.203280237197876, "actor_loss": -56.814000265938894, "actor_target_entropy": -6.0, "actor_entropy": 3.908931471052624, "alpha_loss": 0.17856003107532623, "alpha_value": 0.06803868607189185, "duration": 242.5803096294403, "step": 11375}
{"episode_reward": 334.20757396242783, "episode": 92.0, "Q1 loss": 1.055306818962097, "Q2 loss": 1.0502017550468445, "Mean Target Q": 56.962239166259764, "Mean Q1": 56.95973440551758, "Mean Q2": 56.960878509521486, "critic_loss": 2.1055085763931274, "batch_reward": 1.20753484916687, "actor_loss": -57.63348960876465, "actor_target_entropy": -6.0, "actor_entropy": 3.901505054966096, "alpha_loss": 0.16994689717408148, "alpha_value": 0.0677620459083109, "duration": 248.05298805236816, "step": 11500}
{"episode_reward": 292.43720149545675, "episode": 93.0, "Q1 loss": 1.1488380889892578, "Q2 loss": 1.1457940363883972, "Mean Target Q": 57.93606015014648, "Mean Q1": 57.93588122558594, "Mean Q2": 57.935477600097656, "critic_loss": 2.294632116317749, "batch_reward": 1.223703164100647, "actor_loss": -58.766601804703, "actor_target_entropy": -6.0, "actor_entropy": 3.856527339844477, "alpha_loss": 0.16590732619875953, "alpha_value": 0.06749246194158183, "duration": 249.34076595306396, "step": 11625}
{"episode_reward": 316.8676714747088, "episode": 94.0, "Q1 loss": 1.0807235774993897, "Q2 loss": 1.0778591804504394, "Mean Target Q": 58.86585925292969, "Mean Q1": 58.86376837158203, "Mean Q2": 58.8633137512207, "critic_loss": 2.1585827531814576, "batch_reward": 1.230917350769043, "actor_loss": -59.55003842999858, "actor_target_entropy": -6.0, "actor_entropy": 3.842375812991973, "alpha_loss": 0.16128018474386585, "alpha_value": 0.06722341580399009, "duration": 238.79984641075134, "step": 11750}
{"episode_reward": 325.5528544115979, "episode": 95.0, "Q1 loss": 1.1014432463645936, "Q2 loss": 1.1208614320755006, "Mean Target Q": 59.861943359375, "Mean Q1": 59.860350524902344, "Mean Q2": 59.86071600341797, "critic_loss": 2.222304675102234, "batch_reward": 1.2419786806106567, "actor_loss": -60.676649487207804, "actor_target_entropy": -6.0, "actor_entropy": 3.8251599432930115, "alpha_loss": 0.1564965767283288, "alpha_value": 0.06696216808970076, "duration": 239.68971490859985, "step": 11875}
{"episode_reward": 338.4948100629631, "episode": 96.0, "Q1 loss": 1.0435781435966491, "Q2 loss": 1.045242314338684, "Mean Target Q": 60.72844354248047, "Mean Q1": 60.72632846069336, "Mean Q2": 60.72692422485351, "critic_loss": 2.0888204593658446, "batch_reward": 1.2660069274902344, "actor_loss": -61.54873571088237, "actor_target_entropy": -6.0, "actor_entropy": 3.8311451212052376, "alpha_loss": 0.15395723667836958, "alpha_value": 0.06669760447013962, "duration": 239.3423638343811, "step": 12000}
{"episode_reward": 362.27303135700885, "episode": 97.0, "Q1 loss": 1.0114676246643066, "Q2 loss": 1.0008493719100953, "Mean Target Q": 61.71971322631836, "Mean Q1": 61.716592712402345, "Mean Q2": 61.71786819458008, "critic_loss": 2.0123170013427734, "batch_reward": 1.2732733659744262, "actor_loss": -62.46711730957031, "actor_target_entropy": -6.0, "actor_entropy": 3.738232907794771, "alpha_loss": 0.14711381968051668, "alpha_value": 0.06644370568790271, "duration": 235.98408365249634, "step": 12125}
{"episode_reward": 346.23599625193833, "episode": 98.0, "Q1 loss": 1.159887448310852, "Q2 loss": 1.1621895251274108, "Mean Target Q": 62.807233276367185, "Mean Q1": 62.80795864868164, "Mean Q2": 62.8060719909668, "critic_loss": 2.3220769662857057, "batch_reward": 1.2929653329849242, "actor_loss": -63.591697938980595, "actor_target_entropy": -6.0, "actor_entropy": 3.746001716583006, "alpha_loss": 0.139829266696207, "alpha_value": 0.06619158359010541, "duration": 257.8313772678375, "step": 12250}
{"episode_reward": 140.93906027440386, "episode": 99.0, "Q1 loss": 1.2808691840171813, "Q2 loss": 1.3007210178375244, "Mean Target Q": 63.55459295654297, "Mean Q1": 63.551654846191404, "Mean Q2": 63.552067260742184, "critic_loss": 2.5815902004241944, "batch_reward": 1.2970965013504028, "actor_loss": -64.26519351535373, "actor_target_entropy": -6.0, "actor_entropy": 3.824697354483226, "alpha_loss": 0.13417951005791862, "alpha_value": 0.0659524627753111, "duration": 251.1657953262329, "step": 12375}
{"episode_reward": 179.37731832656817, "episode": 100.0, "Q1 loss": 1.4177676010131837, "Q2 loss": 1.3631408944129944, "Mean Target Q": 64.3320848083496, "Mean Q1": 64.32947900390624, "Mean Q2": 64.32955834960937, "critic_loss": 2.7809084968566893, "batch_reward": 1.3026829824447632, "actor_loss": -65.14340043837025, "actor_target_entropy": -6.0, "actor_entropy": 3.776222332831352, "alpha_loss": 0.1348878696801201, "alpha_value": 0.06571268417178713, "duration": 238.40294861793518, "step": 12500}
{"episode_reward": 311.0556816948834, "episode": 101.0, "Q1 loss": 1.317162055492401, "Q2 loss": 1.320837194442749, "Mean Target Q": 65.38511080932618, "Mean Q1": 65.38281640625, "Mean Q2": 65.38264712524413, "critic_loss": 2.637999252319336, "batch_reward": 1.3112673444747924, "actor_loss": -66.19789159865607, "actor_target_entropy": -6.0, "actor_entropy": 3.623358438885401, "alpha_loss": 0.1311413591343259, "alpha_value": 0.06546846627000513, "duration": 240.64694738388062, "step": 12625}
{"episode_reward": 346.1919292424929, "episode": 102.0, "Q1 loss": 1.2384836230278016, "Q2 loss": 1.2523793811798096, "Mean Target Q": 66.31730194091797, "Mean Q1": 66.31385122680663, "Mean Q2": 66.31458331298828, "critic_loss": 2.4908630018234255, "batch_reward": 1.319364623069763, "actor_loss": -67.0007525413267, "actor_target_entropy": -6.0, "actor_entropy": 3.632995601623289, "alpha_loss": 0.12348741232868164, "alpha_value": 0.06523252604682997, "duration": 232.1925232410431, "step": 12750}
{"episode_reward": 358.9571933924926, "episode": 103.0, "Q1 loss": 1.4390104656219482, "Q2 loss": 1.4084294033050537, "Mean Target Q": 67.50508874511719, "Mean Q1": 67.50613598632812, "Mean Q2": 67.50669506835938, "critic_loss": 2.847439866065979, "batch_reward": 1.3412632293701172, "actor_loss": -68.21092672196646, "actor_target_entropy": -6.0, "actor_entropy": 3.6070256573813304, "alpha_loss": 0.12580850010826475, "alpha_value": 0.06499557527139843, "duration": 261.17075514793396, "step": 12875}
{"episode_reward": 246.2918923392162, "episode": 104.0, "Q1 loss": 1.3708588676452638, "Q2 loss": 1.3733738317489623, "Mean Target Q": 68.44610931396484, "Mean Q1": 68.44466613769531, "Mean Q2": 68.44299389648438, "critic_loss": 2.7442326850891114, "batch_reward": 1.342087191581726, "actor_loss": -69.19523312968593, "actor_target_entropy": -6.0, "actor_entropy": 3.5335864213205155, "alpha_loss": 0.11862084173387097, "alpha_value": 0.06476216472908403, "duration": 240.89542698860168, "step": 13000}
{"episode_reward": 339.5528156747, "episode": 105.0, "Q1 loss": 1.501038341999054, "Q2 loss": 1.4984740843772888, "Mean Target Q": 69.38870031738281, "Mean Q1": 69.38297436523438, "Mean Q2": 69.38391247558594, "critic_loss": 2.999512429237366, "batch_reward": 1.3515641269683838, "actor_loss": -70.14610460069444, "actor_target_entropy": -6.0, "actor_entropy": 3.544813250738477, "alpha_loss": 0.11712952265663752, "alpha_value": 0.06453647473370838, "duration": 241.3342022895813, "step": 13125}
{"episode_reward": 134.67074107209604, "episode": 106.0, "Q1 loss": 1.3324231433868408, "Q2 loss": 1.3168262739181518, "Mean Target Q": 70.24225817871094, "Mean Q1": 70.24389343261718, "Mean Q2": 70.24412908935547, "critic_loss": 2.6492494220733644, "batch_reward": 1.3710722322463988, "actor_loss": -70.9605981149981, "actor_target_entropy": -6.0, "actor_entropy": 3.5273385817004788, "alpha_loss": 0.12245098249085488, "alpha_value": 0.06429739722364317, "duration": 226.50259113311768, "step": 13250}
{"episode_reward": 346.575356051029, "episode": 107.0, "Q1 loss": 1.4656815056800843, "Q2 loss": 1.4250746474266052, "Mean Target Q": 71.16845404052734, "Mean Q1": 71.16764611816406, "Mean Q2": 71.16824798583984, "critic_loss": 2.8907561511993407, "batch_reward": 1.3731910486221313, "actor_loss": -71.89129662892175, "actor_target_entropy": -6.0, "actor_entropy": 3.565701931241959, "alpha_loss": 0.11312645827493971, "alpha_value": 0.06405505438194324, "duration": 238.82928895950317, "step": 13375}
{"episode_reward": 318.94474231054636, "episode": 108.0, "Q1 loss": 1.3705451197624205, "Q2 loss": 1.353381591796875, "Mean Target Q": 72.168771484375, "Mean Q1": 72.16682971191406, "Mean Q2": 72.16646643066406, "critic_loss": 2.723926700592041, "batch_reward": 1.3838865661621094, "actor_loss": -72.94663607689643, "actor_target_entropy": -6.0, "actor_entropy": 3.5368509754057853, "alpha_loss": 0.1171294846121342, "alpha_value": 0.06382125333124661, "duration": 241.44402146339417, "step": 13500}
{"episode_reward": 361.9261740302923, "episode": 109.0, "Q1 loss": 1.1825688037872315, "Q2 loss": 1.1881806979179381, "Mean Target Q": 73.23422058105469, "Mean Q1": 73.23143212890625, "Mean Q2": 73.23310778808593, "critic_loss": 2.3707495098114015, "batch_reward": 1.3942956705093383, "actor_loss": -73.9048833695669, "actor_target_entropy": -6.0, "actor_entropy": 3.5737151342724998, "alpha_loss": 0.11208631240186237, "alpha_value": 0.06358390279516765, "duration": 256.646831035614, "step": 13625}
{"episode_reward": 354.85928739170777, "episode": 110.0, "Q1 loss": 1.202490626335144, "Q2 loss": 1.1826872582435608, "Mean Target Q": 74.1657314453125, "Mean Q1": 74.16278021240234, "Mean Q2": 74.1612533569336, "critic_loss": 2.3851778993606567, "batch_reward": 1.412238507270813, "actor_loss": -75.08395311909337, "actor_target_entropy": -6.0, "actor_entropy": 3.356343984603882, "alpha_loss": 0.10997898383967337, "alpha_value": 0.06335009656874743, "duration": 245.50670194625854, "step": 13750}
{"episode_reward": 355.79816704096356, "episode": 111.0, "Q1 loss": 1.1825001397132873, "Q2 loss": 1.1580703296661377, "Mean Target Q": 75.25661480712891, "Mean Q1": 75.25825177001953, "Mean Q2": 75.25917803955078, "critic_loss": 2.3405704698562624, "batch_reward": 1.4232972822189331, "actor_loss": -76.14085230751643, "actor_target_entropy": -6.0, "actor_entropy": 3.4493966178288535, "alpha_loss": 0.10875911987017071, "alpha_value": 0.06311024492911685, "duration": 227.23476028442383, "step": 13875}
{"episode_reward": 379.35615170188515, "episode": 112.0, "Q1 loss": 1.1906847276687622, "Q2 loss": 1.195350245475769, "Mean Target Q": 76.29892645263672, "Mean Q1": 76.29621911621093, "Mean Q2": 76.29474053955079, "critic_loss": 2.386034967422485, "batch_reward": 1.4344956912994384, "actor_loss": -77.2255364694903, "actor_target_entropy": -6.0, "actor_entropy": 3.415020415859838, "alpha_loss": 0.10289767642896022, "alpha_value": 0.06288023421160287, "duration": 234.98307991027832, "step": 14000}
{"episode_reward": 329.69455867334057, "episode": 113.0, "Q1 loss": 1.2420307989120483, "Q2 loss": 1.229486337184906, "Mean Target Q": 77.36439831542968, "Mean Q1": 77.360869140625, "Mean Q2": 77.36138806152344, "critic_loss": 2.471517128944397, "batch_reward": 1.4531978616714478, "actor_loss": -78.10241263253349, "actor_target_entropy": -6.0, "actor_entropy": 3.347274655387515, "alpha_loss": 0.10025723337654084, "alpha_value": 0.06265391239071046, "duration": 222.55590391159058, "step": 14125}
{"episode_reward": 300.2386565842858, "episode": 114.0, "Q1 loss": 1.3022781405448913, "Q2 loss": 1.2983313875198363, "Mean Target Q": 78.30152911376953, "Mean Q1": 78.30261785888672, "Mean Q2": 78.30132415771484, "critic_loss": 2.6006095275878907, "batch_reward": 1.459800313949585, "actor_loss": -78.92623938283613, "actor_target_entropy": -6.0, "actor_entropy": 3.435452749652247, "alpha_loss": 0.10401008097875503, "alpha_value": 0.06242285596294056, "duration": 232.16302680969238, "step": 14250}
{"episode_reward": 381.6466958049203, "episode": 115.0, "Q1 loss": 1.3678290686607362, "Q2 loss": 1.35023064994812, "Mean Target Q": 79.1238695678711, "Mean Q1": 79.12049694824219, "Mean Q2": 79.12144720458984, "critic_loss": 2.7180597105026245, "batch_reward": 1.4649897441864013, "actor_loss": -79.82096656920417, "actor_target_entropy": -6.0, "actor_entropy": 3.3337313674745106, "alpha_loss": 0.0999065377409496, "alpha_value": 0.06218565924981799, "duration": 239.1647629737854, "step": 14375}
{"episode_reward": 361.2381560054716, "episode": 116.0, "Q1 loss": 1.3061660976409912, "Q2 loss": 1.3001001152992249, "Mean Target Q": 80.12776501464843, "Mean Q1": 80.12411065673828, "Mean Q2": 80.12463854980469, "critic_loss": 2.606266201972961, "batch_reward": 1.481816339492798, "actor_loss": -80.833494617093, "actor_target_entropy": -6.0, "actor_entropy": 3.327928054717279, "alpha_loss": 0.09793683610135509, "alpha_value": 0.06195332569440676, "duration": 241.87930822372437, "step": 14500}
{"episode_reward": 355.98810846927273, "episode": 117.0, "Q1 loss": 1.2613469562530517, "Q2 loss": 1.2629415392875671, "Mean Target Q": 81.28250665283203, "Mean Q1": 81.28046606445312, "Mean Q2": 81.2788413696289, "critic_loss": 2.524288495063782, "batch_reward": 1.4992181053161622, "actor_loss": -81.98830353267608, "actor_target_entropy": -6.0, "actor_entropy": 3.3141116868881952, "alpha_loss": 0.09749399101923382, "alpha_value": 0.06172454154539647, "duration": 232.98353171348572, "step": 14625}
{"episode_reward": 387.2182367345394, "episode": 118.0, "Q1 loss": 1.1739413504600524, "Q2 loss": 1.1739349417686462, "Mean Target Q": 82.17552667236328, "Mean Q1": 82.17687188720703, "Mean Q2": 82.1782783203125, "critic_loss": 2.347876298904419, "batch_reward": 1.498203049659729, "actor_loss": -83.08244262203094, "actor_target_entropy": -6.0, "actor_entropy": 3.30918348604633, "alpha_loss": 0.09240490618732668, "alpha_value": 0.06149844685045779, "duration": 234.66356110572815, "step": 14750}
{"episode_reward": 305.3584499349073, "episode": 119.0, "Q1 loss": 1.3374892406463623, "Q2 loss": 1.3327816395759582, "Mean Target Q": 83.31638677978516, "Mean Q1": 83.31333685302734, "Mean Q2": 83.31243969726563, "critic_loss": 2.6702708778381345, "batch_reward": 1.5170648822784423, "actor_loss": -83.95191337948754, "actor_target_entropy": -6.0, "actor_entropy": 3.2684409315623935, "alpha_loss": 0.09085849418290078, "alpha_value": 0.061267587910064716, "duration": 228.23133516311646, "step": 14875}
{"episode_reward": 344.7182758406816, "episode": 120.0, "Q1 loss": 1.4184128856658935, "Q2 loss": 1.4095590085983276, "Mean Target Q": 84.07817199707031, "Mean Q1": 84.07798376464844, "Mean Q2": 84.07954663085937, "critic_loss": 2.827971888542175, "batch_reward": 1.5300010166168212, "actor_loss": -84.7928844574959, "actor_target_entropy": -6.0, "actor_entropy": 3.2754450190451836, "alpha_loss": 0.0888326019649544, "alpha_value": 0.06104770759202293, "step": 15000}
{"duration": 255.51869297027588, "step": 15000}
{"episode_reward": 341.23457949731375, "episode": 121.0, "Q1 loss": 1.3722139267921447, "Q2 loss": 1.3380791940689087, "Mean Target Q": 84.95282196044921, "Mean Q1": 84.95040960693359, "Mean Q2": 84.94978955078125, "critic_loss": 2.7102931118011475, "batch_reward": 1.5299798755645753, "actor_loss": -85.74800267295232, "actor_target_entropy": -6.0, "actor_entropy": 3.204927694229853, "alpha_loss": 0.08451845603329795, "alpha_value": 0.06082391479849985, "duration": 240.07650327682495, "step": 15125}
{"episode_reward": 371.0931642758409, "episode": 122.0, "Q1 loss": 1.407892825603485, "Q2 loss": 1.3954622507095338, "Mean Target Q": 86.14522058105469, "Mean Q1": 86.14552038574219, "Mean Q2": 86.14581182861328, "critic_loss": 2.803355080604553, "batch_reward": 1.5437314376831055, "actor_loss": -86.75949896535566, "actor_target_entropy": -6.0, "actor_entropy": 3.1996462691214775, "alpha_loss": 0.0875690838982982, "alpha_value": 0.060604228504736, "duration": 221.72714281082153, "step": 15250}
{"episode_reward": 125.41272884038686, "episode": 123.0, "Q1 loss": 1.4744790959358216, "Q2 loss": 1.466433376789093, "Mean Target Q": 86.7644506225586, "Mean Q1": 86.76175665283203, "Mean Q2": 86.76120916748047, "critic_loss": 2.9409124689102173, "batch_reward": 1.5457944355010986, "actor_loss": -87.54168119884673, "actor_target_entropy": -6.0, "actor_entropy": 3.223187147624909, "alpha_loss": 0.08378727609912555, "alpha_value": 0.060380459615757116, "duration": 226.72952342033386, "step": 15375}
{"episode_reward": 354.8749518351504, "episode": 124.0, "Q1 loss": 1.5075983600616456, "Q2 loss": 1.5318183937072753, "Mean Target Q": 87.54831915283204, "Mean Q1": 87.54424505615235, "Mean Q2": 87.54463433837891, "critic_loss": 3.0394167404174803, "batch_reward": 1.5509814825057984, "actor_loss": -88.2597305543961, "actor_target_entropy": -6.0, "actor_entropy": 3.130130160239435, "alpha_loss": 0.07873591954909986, "alpha_value": 0.0601606870790665, "duration": 213.77785634994507, "step": 15500}
{"episode_reward": 323.7372085261211, "episode": 125.0, "Q1 loss": 1.539853355407715, "Q2 loss": 1.5221513357162475, "Mean Target Q": 88.50984271240235, "Mean Q1": 88.51001489257813, "Mean Q2": 88.50927679443359, "critic_loss": 3.0620046997070314, "batch_reward": 1.560322829246521, "actor_loss": -89.2609111240932, "actor_target_entropy": -6.0, "actor_entropy": 3.157595153838869, "alpha_loss": 0.07344266784096522, "alpha_value": 0.05995433213155357, "duration": 233.76501083374023, "step": 15625}
{"episode_reward": 414.10644229997087, "episode": 126.0, "Q1 loss": 1.6212296934127808, "Q2 loss": 1.6223658399581908, "Mean Target Q": 89.61258099365234, "Mean Q1": 89.61039874267578, "Mean Q2": 89.61179473876953, "critic_loss": 3.243595533370972, "batch_reward": 1.5740138158798218, "actor_loss": -90.29057176651493, "actor_target_entropy": -6.0, "actor_entropy": 3.1215689951373684, "alpha_loss": 0.07021322161439926, "alpha_value": 0.05975349142070052, "duration": 235.0505120754242, "step": 15750}
{"episode_reward": 355.6669214431656, "episode": 127.0, "Q1 loss": 1.5236953973770142, "Q2 loss": 1.5409226837158203, "Mean Target Q": 90.53534045410156, "Mean Q1": 90.53300653076172, "Mean Q2": 90.53360247802735, "critic_loss": 3.064618103027344, "batch_reward": 1.5935091047286987, "actor_loss": -91.10322837224082, "actor_target_entropy": -6.0, "actor_entropy": 3.111907610817561, "alpha_loss": 0.07166336600979169, "alpha_value": 0.05955812657719469, "duration": 236.14138770103455, "step": 15875}
{"episode_reward": 330.4114198674861, "episode": 128.0, "Q1 loss": 1.5473535394668578, "Q2 loss": 1.563385069847107, "Mean Target Q": 91.40898992919922, "Mean Q1": 91.40943389892578, "Mean Q2": 91.40747631835937, "critic_loss": 3.1107385997772217, "batch_reward": 1.5936995487213135, "actor_loss": -92.26967547016758, "actor_target_entropy": -6.0, "actor_entropy": 3.0046221671565885, "alpha_loss": 0.06901632919306716, "alpha_value": 0.059353284541127094, "duration": 248.29263257980347, "step": 16000}
{"episode_reward": 373.56553579856916, "episode": 129.0, "Q1 loss": 1.5712906351089477, "Q2 loss": 1.6040602207183838, "Mean Target Q": 92.19198071289063, "Mean Q1": 92.18974200439453, "Mean Q2": 92.1905620727539, "critic_loss": 3.175350854873657, "batch_reward": 1.5974728260040283, "actor_loss": -92.9180161006867, "actor_target_entropy": -6.0, "actor_entropy": 3.0633993754311213, "alpha_loss": 0.06199506634757632, "alpha_value": 0.05916269951800172, "duration": 256.2252354621887, "step": 16125}
{"episode_reward": 368.7870030713364, "episode": 130.0, "Q1 loss": 1.5927635087966918, "Q2 loss": 1.612118353843689, "Mean Target Q": 93.44092901611329, "Mean Q1": 93.43776177978516, "Mean Q2": 93.43753326416015, "critic_loss": 3.2048818607330323, "batch_reward": 1.619623122215271, "actor_loss": -94.02968609717584, "actor_target_entropy": -6.0, "actor_entropy": 3.0346504065298263, "alpha_loss": 0.06460546753219058, "alpha_value": 0.05897579632754252, "duration": 276.4176321029663, "step": 16250}
{"episode_reward": 207.41561219367816, "episode": 131.0, "Q1 loss": 1.7527758626937866, "Q2 loss": 1.7530270338058471, "Mean Target Q": 93.67310888671875, "Mean Q1": 93.67430133056641, "Mean Q2": 93.67431719970703, "critic_loss": 3.5058028964996337, "batch_reward": 1.6174885759353637, "actor_loss": -94.48215545169892, "actor_target_entropy": -6.0, "actor_entropy": 3.0709790313054643, "alpha_loss": 0.06545756124551334, "alpha_value": 0.05877480928362029, "duration": 251.23388695716858, "step": 16375}
{"episode_reward": 372.4256680692231, "episode": 132.0, "Q1 loss": 1.7726083555221557, "Q2 loss": 1.7781453924179078, "Mean Target Q": 94.77978308105469, "Mean Q1": 94.77560266113281, "Mean Q2": 94.77626220703125, "critic_loss": 3.550753734588623, "batch_reward": 1.6204868354797364, "actor_loss": -95.49917122625536, "actor_target_entropy": -6.0, "actor_entropy": 2.969363785559131, "alpha_loss": 0.06995716270419859, "alpha_value": 0.05857411710262396, "duration": 242.43271660804749, "step": 16500}
{"episode_reward": 90.81247656589704, "episode": 133.0, "Q1 loss": 2.1462934017181396, "Q2 loss": 2.146065242767334, "Mean Target Q": 95.42475280761718, "Mean Q1": 95.42109808349609, "Mean Q2": 95.42145526123046, "critic_loss": 4.29235863494873, "batch_reward": 1.618537790298462, "actor_loss": -96.11218625023251, "actor_target_entropy": -6.0, "actor_entropy": 3.060526090954977, "alpha_loss": 0.06084633149975349, "alpha_value": 0.05836614640960311, "duration": 246.75881481170654, "step": 16625}
{"episode_reward": 156.26378991647326, "episode": 134.0, "Q1 loss": 2.1948557729721068, "Q2 loss": 2.197296305656433, "Mean Target Q": 96.31997485351563, "Mean Q1": 96.32081134033203, "Mean Q2": 96.32126055908203, "critic_loss": 4.3921520767211915, "batch_reward": 1.6256227254867555, "actor_loss": -96.89698422339654, "actor_target_entropy": -6.0, "actor_entropy": 3.1490898324597265, "alpha_loss": 0.06473832065239549, "alpha_value": 0.05816639679013164, "duration": 263.94356298446655, "step": 16750}
{"episode_reward": 356.8083144994762, "episode": 135.0, "Q1 loss": 2.767978600502014, "Q2 loss": 2.767688097000122, "Mean Target Q": 96.98720043945312, "Mean Q1": 96.98588171386719, "Mean Q2": 96.98527825927735, "critic_loss": 5.535666669845581, "batch_reward": 1.6314820022583008, "actor_loss": -97.65385267469618, "actor_target_entropy": -6.0, "actor_entropy": 3.11010231668987, "alpha_loss": 0.0641322313320069, "alpha_value": 0.05795391686030856, "duration": 249.67689490318298, "step": 16875}
{"episode_reward": 359.2594977999336, "episode": 136.0, "Q1 loss": 11.276088674545289, "Q2 loss": 11.422588673591614, "Mean Target Q": 97.3107158203125, "Mean Q1": 97.28390014648437, "Mean Q2": 97.28391717529297, "critic_loss": 22.69867752838135, "batch_reward": 1.6449273719787598, "actor_loss": -98.5642321186681, "actor_target_entropy": -6.0, "actor_entropy": 4.083217336285498, "alpha_loss": -0.056096635818962126, "alpha_value": 0.057810364274252415, "duration": 261.33838152885437, "step": 17000}
{"episode_reward": 227.10914237314466, "episode": 137.0, "Q1 loss": 3.7550174713134767, "Q2 loss": 3.839194692611694, "Mean Target Q": 97.17747552490235, "Mean Q1": 97.17572534179688, "Mean Q2": 97.1751069946289, "critic_loss": 7.594212146759033, "batch_reward": 1.6277113304138184, "actor_loss": -97.55901348780073, "actor_target_entropy": -6.0, "actor_entropy": 5.004189037141346, "alpha_loss": 0.005922213026751128, "alpha_value": 0.05802973968505211, "duration": 265.2169051170349, "step": 17125}
{"episode_reward": 159.14472150873982, "episode": 138.0, "Q1 loss": 3.2516921977996827, "Q2 loss": 3.2866349287033083, "Mean Target Q": 98.85805590820313, "Mean Q1": 98.85594958496094, "Mean Q2": 98.85317895507812, "critic_loss": 6.538327144622802, "batch_reward": 1.623816637992859, "actor_loss": -99.38458079676474, "actor_target_entropy": -6.0, "actor_entropy": 4.371143483346509, "alpha_loss": 0.030801448565457138, "alpha_value": 0.05794797810121888, "duration": 249.0490198135376, "step": 17250}
{"episode_reward": 59.43677736354292, "episode": 139.0, "Q1 loss": 2.967513607978821, "Q2 loss": 3.0580035667419434, "Mean Target Q": 99.23152368164062, "Mean Q1": 99.23298358154297, "Mean Q2": 99.23520623779297, "critic_loss": 6.025517135620118, "batch_reward": 1.6240402994155885, "actor_loss": -99.85018157958984, "actor_target_entropy": -6.0, "actor_entropy": 4.021982007556492, "alpha_loss": 0.04697564232444006, "alpha_value": 0.05781722886011011, "duration": 264.375613451004, "step": 17375}
{"episode_reward": 341.21127819976283, "episode": 140.0, "Q1 loss": 2.8601103372573853, "Q2 loss": 2.849516272544861, "Mean Target Q": 100.28088568115234, "Mean Q1": 100.27650762939453, "Mean Q2": 100.27651690673828, "critic_loss": 5.709626611709595, "batch_reward": 1.6349747257232665, "actor_loss": -100.93460279895413, "actor_target_entropy": -6.0, "actor_entropy": 3.7355897426605225, "alpha_loss": 0.05241318365498897, "alpha_value": 0.05765701706028549, "duration": 241.19053435325623, "step": 17500}
{"episode_reward": 344.55169575099814, "episode": 141.0, "Q1 loss": 2.6465215177536012, "Q2 loss": 2.656672512054443, "Mean Target Q": 100.86618145751953, "Mean Q1": 100.86657238769531, "Mean Q2": 100.86700988769532, "critic_loss": 5.303194047927857, "batch_reward": 1.6318337965011596, "actor_loss": -101.73797377329024, "actor_target_entropy": -6.0, "actor_entropy": 3.6140999869694785, "alpha_loss": 0.05438960046463069, "alpha_value": 0.05748327563476681, "duration": 220.37921142578125, "step": 17625}
{"episode_reward": 175.39270871044286, "episode": 142.0, "Q1 loss": 2.5717910261154175, "Q2 loss": 2.55028636264801, "Mean Target Q": 101.76924084472657, "Mean Q1": 101.7674213256836, "Mean Q2": 101.76522845458985, "critic_loss": 5.122077386856079, "batch_reward": 1.6389971504211425, "actor_loss": -102.71664477932838, "actor_target_entropy": -6.0, "actor_entropy": 3.413812948811439, "alpha_loss": 0.061144651394457586, "alpha_value": 0.05728626518355212, "duration": 209.57235431671143, "step": 17750}
{"episode_reward": 169.06844500278805, "episode": 143.0, "Q1 loss": 2.9115992193222047, "Q2 loss": 2.9087928276062014, "Mean Target Q": 102.167501953125, "Mean Q1": 102.16729418945313, "Mean Q2": 102.1695131225586, "critic_loss": 5.820392030715943, "batch_reward": 1.6293498487472535, "actor_loss": -102.73646702842107, "actor_target_entropy": -6.0, "actor_entropy": 3.416790655681065, "alpha_loss": 0.06451634429986515, "alpha_value": 0.0570664390493283, "duration": 244.0658552646637, "step": 17875}
{"episode_reward": 312.94907918652234, "episode": 144.0, "Q1 loss": 2.996405198097229, "Q2 loss": 2.993600561141968, "Mean Target Q": 102.80693377685547, "Mean Q1": 102.8055390625, "Mean Q2": 102.80368591308594, "critic_loss": 5.9900057392120365, "batch_reward": 1.633795467376709, "actor_loss": -103.5730099831858, "actor_target_entropy": -6.0, "actor_entropy": 3.333733104890393, "alpha_loss": 0.06466461913359742, "alpha_value": 0.05684582908984282, "duration": 242.34711456298828, "step": 18000}
{"episode_reward": 324.81075413479994, "episode": 145.0, "Q1 loss": 2.766308046340942, "Q2 loss": 2.713979835510254, "Mean Target Q": 103.74252941894531, "Mean Q1": 103.73930920410156, "Mean Q2": 103.73916168212891, "critic_loss": 5.48028787612915, "batch_reward": 1.6498780794143677, "actor_loss": -104.33834415011935, "actor_target_entropy": -6.0, "actor_entropy": 3.15220834716918, "alpha_loss": 0.06911357929782262, "alpha_value": 0.05660340553079594, "duration": 233.45509099960327, "step": 18125}
{"episode_reward": 325.6447697270394, "episode": 146.0, "Q1 loss": 2.9064603176116943, "Q2 loss": 2.9228163728713987, "Mean Target Q": 104.52415887451171, "Mean Q1": 104.52425787353516, "Mean Q2": 104.52496557617188, "critic_loss": 5.829276659011841, "batch_reward": 1.659797601699829, "actor_loss": -105.2370108327558, "actor_target_entropy": -6.0, "actor_entropy": 3.1126420920894993, "alpha_loss": 0.06061036881780432, "alpha_value": 0.056371923019658175, "duration": 223.2187147140503, "step": 18250}
{"episode_reward": 208.24615949260007, "episode": 147.0, "Q1 loss": 3.1271855335235594, "Q2 loss": 3.124017179489136, "Mean Target Q": 105.30839117431641, "Mean Q1": 105.30397320556641, "Mean Q2": 105.30362451171875, "critic_loss": 6.251202697753906, "batch_reward": 1.6567468061447144, "actor_loss": -105.98253001863995, "actor_target_entropy": -6.0, "actor_entropy": 3.036588952654884, "alpha_loss": 0.06569953423939527, "alpha_value": 0.056143322962112115, "duration": 238.86061334609985, "step": 18375}
{"episode_reward": 350.5893169710695, "episode": 148.0, "Q1 loss": 2.989078974723816, "Q2 loss": 2.9044809017181397, "Mean Target Q": 106.16349713134765, "Mean Q1": 106.1629359741211, "Mean Q2": 106.16188372802735, "critic_loss": 5.893559858322144, "batch_reward": 1.6688029956817627, "actor_loss": -106.94089532667591, "actor_target_entropy": -6.0, "actor_entropy": 3.0162077488437777, "alpha_loss": 0.059146370588531415, "alpha_value": 0.05591406476812207, "duration": 247.9413857460022, "step": 18500}
{"episode_reward": 367.50136749410734, "episode": 149.0, "Q1 loss": 2.755914611816406, "Q2 loss": 2.7873605117797853, "Mean Target Q": 106.8253956298828, "Mean Q1": 106.82526617431641, "Mean Q2": 106.82702453613281, "critic_loss": 5.543275106430054, "batch_reward": 1.6754519681930542, "actor_loss": -107.59483422173395, "actor_target_entropy": -6.0, "actor_entropy": 3.0510526876600963, "alpha_loss": 0.05582493041006346, "alpha_value": 0.05570258577745249, "duration": 236.49435424804688, "step": 18625}
{"episode_reward": 231.34808447734548, "episode": 150.0, "Q1 loss": 2.5752215671539305, "Q2 loss": 2.5572734479904176, "Mean Target Q": 107.44485412597656, "Mean Q1": 107.44158673095703, "Mean Q2": 107.44156475830079, "critic_loss": 5.132495038986206, "batch_reward": 1.672667757987976, "actor_loss": -108.2446050336284, "actor_target_entropy": -6.0, "actor_entropy": 2.992980953185789, "alpha_loss": 0.05886311501625084, "alpha_value": 0.05548481787441978, "duration": 252.55562901496887, "step": 18750}
{"episode_reward": 372.28733388096225, "episode": 151.0, "Q1 loss": 2.5479522714614866, "Q2 loss": 2.47693957901001, "Mean Target Q": 108.28230908203125, "Mean Q1": 108.28257977294922, "Mean Q2": 108.28146984863281, "critic_loss": 5.024891843795777, "batch_reward": 1.6842762937545777, "actor_loss": -108.92970191107855, "actor_target_entropy": -6.0, "actor_entropy": 2.993738159300789, "alpha_loss": 0.051183328919467475, "alpha_value": 0.05527138636835192, "duration": 257.4998924732208, "step": 18875}
{"episode_reward": 358.8603976695663, "episode": 152.0, "Q1 loss": 2.5383741283416748, "Q2 loss": 2.561040328025818, "Mean Target Q": 109.29542218017578, "Mean Q1": 109.29555865478515, "Mean Q2": 109.29628479003907, "critic_loss": 5.099414463043213, "batch_reward": 1.6869647159576415, "actor_loss": -110.06689428514049, "actor_target_entropy": -6.0, "actor_entropy": 2.9465849707203526, "alpha_loss": 0.049993608747759176, "alpha_value": 0.05508399450789162, "duration": 258.37398886680603, "step": 19000}
{"episode_reward": 334.64469392725067, "episode": 153.0, "Q1 loss": 2.703043807029724, "Q2 loss": 2.6590530910491945, "Mean Target Q": 110.10628210449218, "Mean Q1": 110.10395166015626, "Mean Q2": 110.1044617919922, "critic_loss": 5.362096899032593, "batch_reward": 1.7042607669830323, "actor_loss": -110.74718099927145, "actor_target_entropy": -6.0, "actor_entropy": 2.8964308821965776, "alpha_loss": 0.05246306095449697, "alpha_value": 0.054874824533632016, "duration": 257.9287130832672, "step": 19125}
{"episode_reward": 255.78561094538853, "episode": 154.0, "Q1 loss": 2.74200625705719, "Q2 loss": 2.6896439170837403, "Mean Target Q": 110.83467999267579, "Mean Q1": 110.83288696289063, "Mean Q2": 110.83060003662109, "critic_loss": 5.431650144577026, "batch_reward": 1.7016229696273804, "actor_loss": -111.47494137671686, "actor_target_entropy": -6.0, "actor_entropy": 2.8978758781186995, "alpha_loss": 0.050610648317923466, "alpha_value": 0.05466649858200299, "duration": 241.32733702659607, "step": 19250}
{"episode_reward": 365.6834439567204, "episode": 155.0, "Q1 loss": 3.1118603982925417, "Q2 loss": 3.105288989067078, "Mean Target Q": 111.42297399902344, "Mean Q1": 111.41946893310546, "Mean Q2": 111.42112292480469, "critic_loss": 6.217149393081665, "batch_reward": 1.7073262453079223, "actor_loss": -112.30725376189702, "actor_target_entropy": -6.0, "actor_entropy": 2.9236479638114807, "alpha_loss": 0.048101764408841965, "alpha_value": 0.054468392065437646, "duration": 249.96712017059326, "step": 19375}
{"episode_reward": 62.86975710908811, "episode": 156.0, "Q1 loss": 2.961735233306885, "Q2 loss": 2.862432990074158, "Mean Target Q": 112.24289819335938, "Mean Q1": 112.24586303710937, "Mean Q2": 112.24419274902344, "critic_loss": 5.824168251037598, "batch_reward": 1.698375864982605, "actor_loss": -112.72729467576549, "actor_target_entropy": -6.0, "actor_entropy": 2.9179147635736773, "alpha_loss": 0.04386340096713074, "alpha_value": 0.054273795389254614, "duration": 256.33474946022034, "step": 19500}
{"episode_reward": 294.51115222303156, "episode": 157.0, "Q1 loss": 3.2559214458465577, "Q2 loss": 3.199056568145752, "Mean Target Q": 112.65894415283204, "Mean Q1": 112.65374060058593, "Mean Q2": 112.65525567626953, "critic_loss": 6.45497799873352, "batch_reward": 1.702199270248413, "actor_loss": -113.20990547301277, "actor_target_entropy": -6.0, "actor_entropy": 2.960196896204873, "alpha_loss": 0.04477268352454144, "alpha_value": 0.05409308545117628, "duration": 249.17122101783752, "step": 19625}
{"episode_reward": 256.56536659335154, "episode": 158.0, "Q1 loss": 3.2459331645965577, "Q2 loss": 3.2242000045776367, "Mean Target Q": 113.67007342529297, "Mean Q1": 113.66993188476563, "Mean Q2": 113.66873309326172, "critic_loss": 6.470133190155029, "batch_reward": 1.7139941921234132, "actor_loss": -114.34940805742818, "actor_target_entropy": -6.0, "actor_entropy": 2.922671260372285, "alpha_loss": 0.04231942955201732, "alpha_value": 0.05390725503583708, "duration": 262.8452305793762, "step": 19750}
{"episode_reward": 390.5074469553033, "episode": 159.0, "Q1 loss": 3.531235659599304, "Q2 loss": 3.5112038383483886, "Mean Target Q": 114.33170928955079, "Mean Q1": 114.32891241455079, "Mean Q2": 114.32992419433593, "critic_loss": 7.042439468383789, "batch_reward": 1.7150707111358643, "actor_loss": -114.75692749023438, "actor_target_entropy": -6.0, "actor_entropy": 3.1201961343250577, "alpha_loss": 0.03890883153866208, "alpha_value": 0.0537156074975078, "duration": 259.5457284450531, "step": 19875}
{"episode_reward": 421.39970209644287, "episode": 160.0, "Q1 loss": 3.3082859497070314, "Q2 loss": 3.269682399749756, "Mean Target Q": 115.23080139160156, "Mean Q1": 115.22627423095703, "Mean Q2": 115.22686627197265, "critic_loss": 6.577968360900879, "batch_reward": 1.7307946872711182, "actor_loss": -116.06534970191217, "actor_target_entropy": -6.0, "actor_entropy": 2.921134102729059, "alpha_loss": 0.03705722997866331, "alpha_value": 0.053558741717870714, "step": 20000}
{"duration": 274.89225792884827, "step": 20000}
{"episode_reward": 409.6435799526045, "episode": 161.0, "Q1 loss": 3.0875948848724364, "Q2 loss": 3.0481927556991577, "Mean Target Q": 116.06757458496094, "Mean Q1": 116.06670257568359, "Mean Q2": 116.06765771484375, "critic_loss": 6.135787624359131, "batch_reward": 1.7465270738601684, "actor_loss": -116.78770749531095, "actor_target_entropy": -6.0, "actor_entropy": 2.8714280544765414, "alpha_loss": 0.03039641752617345, "alpha_value": 0.05339815205988652, "duration": 273.9413402080536, "step": 20125}
{"episode_reward": 279.4628602002191, "episode": 162.0, "Q1 loss": 3.5062431888580323, "Q2 loss": 3.447174299240112, "Mean Target Q": 116.55788958740234, "Mean Q1": 116.55938879394532, "Mean Q2": 116.55788439941406, "critic_loss": 6.953417476654053, "batch_reward": 1.7344024639129638, "actor_loss": -117.34527341781124, "actor_target_entropy": -6.0, "actor_entropy": 2.961177775936742, "alpha_loss": 0.030375383831861037, "alpha_value": 0.05325494847918431, "duration": 259.45149874687195, "step": 20250}
{"episode_reward": 390.55136792894007, "episode": 163.0, "Q1 loss": 3.335009117126465, "Q2 loss": 3.2977798328399657, "Mean Target Q": 117.85968194580079, "Mean Q1": 117.85402459716796, "Mean Q2": 117.8547944946289, "critic_loss": 6.632788940429688, "batch_reward": 1.7451398391723634, "actor_loss": -118.89552500891307, "actor_target_entropy": -6.0, "actor_entropy": 2.9459341934749057, "alpha_loss": 0.019173449478186076, "alpha_value": 0.05313358491618438, "duration": 246.53695011138916, "step": 20375}
{"episode_reward": 381.28011493213637, "episode": 164.0, "Q1 loss": 3.2947913942337035, "Q2 loss": 3.29496205329895, "Mean Target Q": 118.38206610107422, "Mean Q1": 118.38201544189454, "Mean Q2": 118.38163006591797, "critic_loss": 6.589753438949585, "batch_reward": 1.7543232612609863, "actor_loss": -119.12865251110446, "actor_target_entropy": -6.0, "actor_entropy": 3.047956843529978, "alpha_loss": 0.01742779516855315, "alpha_value": 0.05304391848999708, "duration": 261.293377161026, "step": 20500}
{"episode_reward": 390.8525368263748, "episode": 165.0, "Q1 loss": 3.678789981842041, "Q2 loss": 3.6499215049743654, "Mean Target Q": 119.22587823486329, "Mean Q1": 119.21974548339844, "Mean Q2": 119.21971887207032, "critic_loss": 7.328711473464966, "batch_reward": 1.762553689956665, "actor_loss": -120.12709432934957, "actor_target_entropy": -6.0, "actor_entropy": 3.034797221895248, "alpha_loss": 0.017205277099348014, "alpha_value": 0.05295684163381977, "duration": 247.20071172714233, "step": 20625}
{"episode_reward": 223.43030844101366, "episode": 166.0, "Q1 loss": 3.8231858558654785, "Q2 loss": 3.7669383697509766, "Mean Target Q": 120.17585632324219, "Mean Q1": 120.17351000976562, "Mean Q2": 120.17513391113282, "critic_loss": 7.590124195098877, "batch_reward": 1.7755034074783325, "actor_loss": -120.94265291767735, "actor_target_entropy": -6.0, "actor_entropy": 3.1171413352412563, "alpha_loss": 0.012143501647627883, "alpha_value": 0.05288889358437281, "duration": 265.93884658813477, "step": 20750}
{"episode_reward": 389.31947307179, "episode": 167.0, "Q1 loss": 3.4951768341064455, "Q2 loss": 3.3920516452789307, "Mean Target Q": 120.67998956298828, "Mean Q1": 120.67878448486329, "Mean Q2": 120.67737219238282, "critic_loss": 6.887228496551514, "batch_reward": 1.767515365600586, "actor_loss": -121.4001704624721, "actor_target_entropy": -6.0, "actor_entropy": 3.0004097734178816, "alpha_loss": 0.016911117230645485, "alpha_value": 0.052818259417345026, "duration": 261.3444483280182, "step": 20875}
{"episode_reward": 296.48008898999416, "episode": 168.0, "Q1 loss": 4.141457872390747, "Q2 loss": 4.140409059524536, "Mean Target Q": 121.85966284179688, "Mean Q1": 121.85839965820313, "Mean Q2": 121.85771984863281, "critic_loss": 8.281866897583008, "batch_reward": 1.7817844181060791, "actor_loss": -122.59737162436208, "actor_target_entropy": -6.0, "actor_entropy": 2.981907002387508, "alpha_loss": 0.017089719183727977, "alpha_value": 0.05272028644002939, "duration": 250.6461842060089, "step": 21000}
{"episode_reward": 405.3936348473135, "episode": 169.0, "Q1 loss": 3.5712023220062257, "Q2 loss": 3.5199196701049806, "Mean Target Q": 122.48483172607422, "Mean Q1": 122.48374475097657, "Mean Q2": 122.48417102050782, "critic_loss": 7.091121967315674, "batch_reward": 1.7819386749267578, "actor_loss": -122.94549197242374, "actor_target_entropy": -6.0, "actor_entropy": 2.9922452389247836, "alpha_loss": 0.017117689633446318, "alpha_value": 0.05262235107613092, "duration": 258.68261528015137, "step": 21125}
{"episode_reward": 446.65893279254846, "episode": 170.0, "Q1 loss": 3.5238593263626097, "Q2 loss": 3.5197900772094726, "Mean Target Q": 123.0445609741211, "Mean Q1": 123.04226513671875, "Mean Q2": 123.04248638916016, "critic_loss": 7.043649410247803, "batch_reward": 1.7901461782455443, "actor_loss": -123.95079606579196, "actor_target_entropy": -6.0, "actor_entropy": 2.9845849660135086, "alpha_loss": 0.009745689533320405, "alpha_value": 0.05256209924717197, "duration": 252.36772465705872, "step": 21250}
{"episode_reward": 157.73827603945344, "episode": 171.0, "Q1 loss": 3.2771838092803955, "Q2 loss": 3.2328444490432737, "Mean Target Q": 123.65692761230468, "Mean Q1": 123.65298303222656, "Mean Q2": 123.65215618896484, "critic_loss": 6.5100282821655275, "batch_reward": 1.7889242353439332, "actor_loss": -124.30080111064608, "actor_target_entropy": -6.0, "actor_entropy": 3.00139524066259, "alpha_loss": 0.016414990977546763, "alpha_value": 0.05247485514200848, "duration": 250.9895794391632, "step": 21375}
{"episode_reward": 395.0867540159224, "episode": 172.0, "Q1 loss": 4.0521026115417484, "Q2 loss": 4.021991836547851, "Mean Target Q": 124.39775500488281, "Mean Q1": 124.39532159423828, "Mean Q2": 124.39381072998047, "critic_loss": 8.07409446334839, "batch_reward": 1.8022869215011597, "actor_loss": -124.98032219179215, "actor_target_entropy": -6.0, "actor_entropy": 3.064294834290781, "alpha_loss": 0.013484754517013508, "alpha_value": 0.052386007035163835, "duration": 256.8802270889282, "step": 21500}
{"episode_reward": 429.0250158199672, "episode": 173.0, "Q1 loss": 3.453428749084473, "Q2 loss": 3.423177879333496, "Mean Target Q": 125.34478308105469, "Mean Q1": 125.34374682617188, "Mean Q2": 125.3439144897461, "critic_loss": 6.876606590270996, "batch_reward": 1.806223229408264, "actor_loss": -125.90361749558221, "actor_target_entropy": -6.0, "actor_entropy": 2.983116252081735, "alpha_loss": 0.011720861670457654, "alpha_value": 0.05230641142458208, "duration": 260.87150859832764, "step": 21625}
{"episode_reward": 343.67166834448255, "episode": 174.0, "Q1 loss": 4.251562633514404, "Q2 loss": 4.187444187164306, "Mean Target Q": 126.27935565185547, "Mean Q1": 126.27219244384766, "Mean Q2": 126.27433770751954, "critic_loss": 8.439006828308106, "batch_reward": 1.8133623666763306, "actor_loss": -127.25126401839718, "actor_target_entropy": -6.0, "actor_entropy": 2.901860414012786, "alpha_loss": 0.006811461591672513, "alpha_value": 0.05224959726909893, "duration": 254.98788928985596, "step": 21750}
{"episode_reward": 349.6984830367276, "episode": 175.0, "Q1 loss": 4.00721494102478, "Q2 loss": 3.942227466583252, "Mean Target Q": 127.05270880126953, "Mean Q1": 127.05748120117188, "Mean Q2": 127.05636010742188, "critic_loss": 7.949442405700683, "batch_reward": 1.8235204401016236, "actor_loss": -127.72718702043805, "actor_target_entropy": -6.0, "actor_entropy": 2.943419657056294, "alpha_loss": 0.011647851228536595, "alpha_value": 0.0521820528811283, "duration": 257.52700686454773, "step": 21875}
{"episode_reward": 429.2537015899239, "episode": 176.0, "Q1 loss": 3.8812637519836426, "Q2 loss": 3.872864442825317, "Mean Target Q": 127.60162585449218, "Mean Q1": 127.59551837158203, "Mean Q2": 127.59636462402344, "critic_loss": 7.754128211975098, "batch_reward": 1.8179814748764038, "actor_loss": -128.10961274177797, "actor_target_entropy": -6.0, "actor_entropy": 2.9965842462355092, "alpha_loss": 0.00936286754515623, "alpha_value": 0.05212810405785788, "duration": 254.8612678050995, "step": 22000}
{"episode_reward": 378.01617644043824, "episode": 177.0, "Q1 loss": 3.506513954162598, "Q2 loss": 3.56145951461792, "Mean Target Q": 128.6039037475586, "Mean Q1": 128.60462023925783, "Mean Q2": 128.60381231689453, "critic_loss": 7.067973426818847, "batch_reward": 1.8352013988494873, "actor_loss": -129.51920500255767, "actor_target_entropy": -6.0, "actor_entropy": 3.024396563333178, "alpha_loss": 0.001221085207477685, "alpha_value": 0.052089178008369624, "duration": 260.4014675617218, "step": 22125}
{"episode_reward": 363.5471849503922, "episode": 178.0, "Q1 loss": 3.636046339035034, "Q2 loss": 3.641470500946045, "Mean Target Q": 129.5434040527344, "Mean Q1": 129.5394630126953, "Mean Q2": 129.54072192382813, "critic_loss": 7.277516830444336, "batch_reward": 1.8445513753890992, "actor_loss": -130.44964156612272, "actor_target_entropy": -6.0, "actor_entropy": 2.989872505587916, "alpha_loss": 0.0028717876937721046, "alpha_value": 0.05208203152968257, "duration": 249.33681559562683, "step": 22250}
{"episode_reward": 403.9998528180484, "episode": 179.0, "Q1 loss": 3.236410526275635, "Q2 loss": 3.253997133255005, "Mean Target Q": 130.50362908935546, "Mean Q1": 130.500400390625, "Mean Q2": 130.4992797241211, "critic_loss": 6.490407653808594, "batch_reward": 1.8564043035507203, "actor_loss": -131.36646367633153, "actor_target_entropy": -6.0, "actor_entropy": 2.908401091893514, "alpha_loss": -0.002334727792971073, "alpha_value": 0.05207516993834166, "duration": 248.05690622329712, "step": 22375}
{"episode_reward": 423.43551630497257, "episode": 180.0, "Q1 loss": 3.0911449699401854, "Q2 loss": 3.15379340839386, "Mean Target Q": 131.10120288085938, "Mean Q1": 131.0997142944336, "Mean Q2": 131.10058154296874, "critic_loss": 6.244938388824463, "batch_reward": 1.8537730083465576, "actor_loss": -132.13014418079007, "actor_target_entropy": -6.0, "actor_entropy": 2.899349924056761, "alpha_loss": 0.007714825928316361, "alpha_value": 0.05205342391187272, "duration": 255.11456775665283, "step": 22500}
{"episode_reward": 435.72140111772876, "episode": 181.0, "Q1 loss": 3.600722646713257, "Q2 loss": 3.624617467880249, "Mean Target Q": 131.61350939941406, "Mean Q1": 131.61064184570313, "Mean Q2": 131.6089736328125, "critic_loss": 7.2253401222229, "batch_reward": 1.8619246149063111, "actor_loss": -132.28344266376797, "actor_target_entropy": -6.0, "actor_entropy": 2.915893770399548, "alpha_loss": 0.0017351996234899003, "alpha_value": 0.05200616928151099, "duration": 256.2920069694519, "step": 22625}
{"episode_reward": 118.84261116882907, "episode": 182.0, "Q1 loss": 4.308479644775391, "Q2 loss": 4.23376411819458, "Mean Target Q": 132.0879526977539, "Mean Q1": 132.09265661621095, "Mean Q2": 132.09372100830078, "critic_loss": 8.542243740081787, "batch_reward": 1.853588119506836, "actor_loss": -132.90518336142264, "actor_target_entropy": -6.0, "actor_entropy": 3.120923084597434, "alpha_loss": -0.0001465905224904418, "alpha_value": 0.05199707828893294, "duration": 252.46840238571167, "step": 22750}
{"episode_reward": 116.81636279594646, "episode": 183.0, "Q1 loss": 3.9960075454711914, "Q2 loss": 4.095524271011352, "Mean Target Q": 132.68542755126953, "Mean Q1": 132.67625067138673, "Mean Q2": 132.67408361816408, "critic_loss": 8.091531774520874, "batch_reward": 1.8617755613327027, "actor_loss": -133.33799828423395, "actor_target_entropy": -6.0, "actor_entropy": 3.191510287542192, "alpha_loss": 0.0009435426170331618, "alpha_value": 0.05201768594839891, "duration": 252.4292516708374, "step": 22875}
{"episode_reward": 415.16010645609185, "episode": 184.0, "Q1 loss": 4.2646110706329345, "Q2 loss": 4.321274765014649, "Mean Target Q": 133.5439775390625, "Mean Q1": 133.54203833007813, "Mean Q2": 133.54502307128905, "critic_loss": 8.585885852813721, "batch_reward": 1.8704014081954956, "actor_loss": -134.03785804010207, "actor_target_entropy": -6.0, "actor_entropy": 3.0248686382847447, "alpha_loss": 0.0025276788397722186, "alpha_value": 0.05198205200688332, "duration": 272.0887567996979, "step": 23000}
{"episode_reward": 382.20862820816535, "episode": 185.0, "Q1 loss": 3.5989623374938966, "Q2 loss": 3.5450754051208495, "Mean Target Q": 134.30084155273437, "Mean Q1": 134.30126599121093, "Mean Q2": 134.30020202636717, "critic_loss": 7.144037734985352, "batch_reward": 1.8708332223892212, "actor_loss": -134.99980817522322, "actor_target_entropy": -6.0, "actor_entropy": 2.9926970837608216, "alpha_loss": -0.001378618956853946, "alpha_value": 0.05199256447273524, "duration": 255.2520980834961, "step": 23125}
{"episode_reward": 361.2966965309932, "episode": 186.0, "Q1 loss": 3.7110046939849854, "Q2 loss": 3.7566273174285887, "Mean Target Q": 135.20619360351563, "Mean Q1": 135.20223400878905, "Mean Q2": 135.20283239746092, "critic_loss": 7.46763200378418, "batch_reward": 1.8791127882003784, "actor_loss": -136.38233553978705, "actor_target_entropy": -6.0, "actor_entropy": 2.9978439192618094, "alpha_loss": -0.002119548374696845, "alpha_value": 0.05199923931923706, "duration": 260.6780722141266, "step": 23250}
{"episode_reward": 403.5337320242231, "episode": 187.0, "Q1 loss": 3.721871702194214, "Q2 loss": 3.722024543762207, "Mean Target Q": 135.91891284179687, "Mean Q1": 135.92033251953126, "Mean Q2": 135.91893212890625, "critic_loss": 7.443896236419678, "batch_reward": 1.8824600858688354, "actor_loss": -136.83031160869297, "actor_target_entropy": -6.0, "actor_entropy": 3.0273974320245167, "alpha_loss": 0.0002973802324887069, "alpha_value": 0.05202094064795851, "duration": 265.27841424942017, "step": 23375}
{"episode_reward": 381.61972452834175, "episode": 188.0, "Q1 loss": 3.5807660531997683, "Q2 loss": 3.5644041137695313, "Mean Target Q": 137.2847606201172, "Mean Q1": 137.27786486816407, "Mean Q2": 137.27878601074218, "critic_loss": 7.145170188903808, "batch_reward": 1.8996927165985107, "actor_loss": -138.04239851428616, "actor_target_entropy": -6.0, "actor_entropy": 3.099713748501193, "alpha_loss": -0.010911985073283675, "alpha_value": 0.05206750579500125, "duration": 241.58588004112244, "step": 23500}
{"episode_reward": 284.4221491589866, "episode": 189.0, "Q1 loss": 3.7513850688934327, "Q2 loss": 3.6881427154541018, "Mean Target Q": 137.18903552246093, "Mean Q1": 137.18921301269532, "Mean Q2": 137.18928771972656, "critic_loss": 7.4395277824401855, "batch_reward": 1.8902231874465942, "actor_loss": -138.05058797200522, "actor_target_entropy": -6.0, "actor_entropy": 3.0282717697204107, "alpha_loss": -0.0036196848469978522, "alpha_value": 0.052129934802303546, "duration": 246.93888640403748, "step": 23625}
{"episode_reward": 396.6000689205422, "episode": 190.0, "Q1 loss": 3.6617720546722414, "Q2 loss": 3.582085287094116, "Mean Target Q": 137.6523868408203, "Mean Q1": 137.65406799316406, "Mean Q2": 137.65168688964843, "critic_loss": 7.243857406616211, "batch_reward": 1.8956065034866334, "actor_loss": -138.32137347805886, "actor_target_entropy": -6.0, "actor_entropy": 2.8847171106646137, "alpha_loss": 0.005313758158140005, "alpha_value": 0.05211452159283855, "duration": 254.60074019432068, "step": 23750}
{"episode_reward": 368.39541445192634, "episode": 191.0, "Q1 loss": 3.899566864013672, "Q2 loss": 3.8781037464141845, "Mean Target Q": 138.51294104003907, "Mean Q1": 138.5078828125, "Mean Q2": 138.50812414550782, "critic_loss": 7.777670623779297, "batch_reward": 1.9006292533874511, "actor_loss": -139.5993899390811, "actor_target_entropy": -6.0, "actor_entropy": 3.0377389817010787, "alpha_loss": -0.0033628081196978216, "alpha_value": 0.05210296703677228, "duration": 261.0211510658264, "step": 23875}
{"episode_reward": 398.80201037756905, "episode": 192.0, "Q1 loss": 3.6596837673187257, "Q2 loss": 3.6675318603515623, "Mean Target Q": 139.62203430175782, "Mean Q1": 139.6205782470703, "Mean Q2": 139.62000463867187, "critic_loss": 7.327215621948242, "batch_reward": 1.9063604669570924, "actor_loss": -140.42408038723855, "actor_target_entropy": -6.0, "actor_entropy": 3.0431903293055873, "alpha_loss": -0.0026062113334304623, "alpha_value": 0.052147705172188565, "duration": 253.8422474861145, "step": 24000}
{"episode_reward": 343.8591328138688, "episode": 193.0, "Q1 loss": 3.153307004928589, "Q2 loss": 3.109758958816528, "Mean Target Q": 140.77421960449217, "Mean Q1": 140.7708581542969, "Mean Q2": 140.7720224609375, "critic_loss": 6.263065929412842, "batch_reward": 1.9207351570129394, "actor_loss": -141.6239950997489, "actor_target_entropy": -6.0, "actor_entropy": 3.047710619275532, "alpha_loss": -0.0031516128367493077, "alpha_value": 0.052177983627119916, "duration": 246.15446066856384, "step": 24125}
{"episode_reward": 436.2348550485299, "episode": 194.0, "Q1 loss": 3.37611474609375, "Q2 loss": 3.404977264404297, "Mean Target Q": 141.56360046386717, "Mean Q1": 141.56497021484375, "Mean Q2": 141.566048828125, "critic_loss": 6.781092037200928, "batch_reward": 1.922015682220459, "actor_loss": -142.49757065311556, "actor_target_entropy": -6.0, "actor_entropy": 2.9287528414880075, "alpha_loss": -0.005588021519924363, "alpha_value": 0.05220720785206195, "duration": 265.71896147727966, "step": 24250}
{"episode_reward": 430.6867251154502, "episode": 195.0, "Q1 loss": 3.5348102264404297, "Q2 loss": 3.5329225177764894, "Mean Target Q": 141.90200073242187, "Mean Q1": 141.89969140625, "Mean Q2": 141.89796411132812, "critic_loss": 7.0677327537536625, "batch_reward": 1.9271511602401734, "actor_loss": -142.4610297793434, "actor_target_entropy": -6.0, "actor_entropy": 3.0452087568858315, "alpha_loss": -0.004345871012894407, "alpha_value": 0.05225224897732687, "duration": 242.9920938014984, "step": 24375}
{"episode_reward": 449.43378721757244, "episode": 196.0, "Q1 loss": 3.8904728078842163, "Q2 loss": 3.881682424545288, "Mean Target Q": 142.9272879638672, "Mean Q1": 142.92499694824218, "Mean Q2": 142.92662670898437, "critic_loss": 7.772155239105224, "batch_reward": 1.93205904006958, "actor_loss": -143.55790562783517, "actor_target_entropy": -6.0, "actor_entropy": 3.0008300965832126, "alpha_loss": -0.004949174582913158, "alpha_value": 0.052307578032974006, "duration": 255.46833729743958, "step": 24500}
{"episode_reward": 317.4538166758865, "episode": 197.0, "Q1 loss": 3.7541683826446532, "Q2 loss": 3.774698884963989, "Mean Target Q": 144.0627421875, "Mean Q1": 144.0565400390625, "Mean Q2": 144.05620446777343, "critic_loss": 7.52886727142334, "batch_reward": 1.9573644342422485, "actor_loss": -144.76681252131385, "actor_target_entropy": -6.0, "actor_entropy": 2.9960378805796304, "alpha_loss": 0.0009175255850312256, "alpha_value": 0.05234117501246536, "duration": 259.92764019966125, "step": 24625}
{"episode_reward": 405.03505067567994, "episode": 198.0, "Q1 loss": 3.7134832916259763, "Q2 loss": 3.726379978179932, "Mean Target Q": 144.55866870117188, "Mean Q1": 144.56071520996093, "Mean Q2": 144.55912573242188, "critic_loss": 7.4398632354736325, "batch_reward": 1.9539803352355958, "actor_loss": -145.33923093734248, "actor_target_entropy": -6.0, "actor_entropy": 2.972611342706988, "alpha_loss": -0.0015590422985804898, "alpha_value": 0.0523291348655124, "duration": 241.254700422287, "step": 24750}
{"episode_reward": 395.4722112779822, "episode": 199.0, "Q1 loss": 4.113403772354126, "Q2 loss": 4.011441997528076, "Mean Target Q": 145.11139099121092, "Mean Q1": 145.10866198730469, "Mean Q2": 145.11047985839843, "critic_loss": 8.124845718383789, "batch_reward": 1.9475109462738036, "actor_loss": -145.86573476640004, "actor_target_entropy": -6.0, "actor_entropy": 2.926550547281901, "alpha_loss": -0.0039306492821889975, "alpha_value": 0.052372403301076016, "duration": 241.36550164222717, "step": 24875}
{"episode_reward": 158.40704695554058, "episode": 200.0, "Q1 loss": 4.542089851379394, "Q2 loss": 4.631118478775025, "Mean Target Q": 145.89378442382812, "Mean Q1": 145.89214782714845, "Mean Q2": 145.89080908203124, "critic_loss": 9.173208282470704, "batch_reward": 1.9521354160308837, "actor_loss": -146.62808842812814, "actor_target_entropy": -6.0, "actor_entropy": 3.0359676691793624, "alpha_loss": -0.0033490860181289816, "alpha_value": 0.05243269167579232, "step": 25000}
{"duration": 270.87780690193176, "step": 25000}
{"episode_reward": 403.3018023296364, "episode": 201.0, "Q1 loss": 5.1581438331604, "Q2 loss": 5.077968637466431, "Mean Target Q": 146.5117255859375, "Mean Q1": 146.50508911132812, "Mean Q2": 146.5077224121094, "critic_loss": 10.236112461090087, "batch_reward": 1.9618999557495118, "actor_loss": -147.42406548394098, "actor_target_entropy": -6.0, "actor_entropy": 2.9896009195418585, "alpha_loss": -0.00048610781289873617, "alpha_value": 0.05245768730220528, "duration": 251.34083437919617, "step": 25125}
{"episode_reward": 269.13073842387263, "episode": 202.0, "Q1 loss": 5.091591957092285, "Q2 loss": 5.064677257537841, "Mean Target Q": 147.18367163085938, "Mean Q1": 147.18341479492187, "Mean Q2": 147.18095202636718, "critic_loss": 10.156269180297851, "batch_reward": 1.9546057319641112, "actor_loss": -147.97782258064515, "actor_target_entropy": -6.0, "actor_entropy": 2.9977674176616054, "alpha_loss": -0.010231637452248364, "alpha_value": 0.05249964170660318, "duration": 255.47729420661926, "step": 25250}
{"episode_reward": 446.3545013322212, "episode": 203.0, "Q1 loss": 7.381662845611572, "Q2 loss": 7.266720890045166, "Mean Target Q": 148.193583984375, "Mean Q1": 148.1879670410156, "Mean Q2": 148.1887716064453, "critic_loss": 14.648383754730224, "batch_reward": 1.9759230337142943, "actor_loss": -148.7439238533141, "actor_target_entropy": -6.0, "actor_entropy": 3.0875496561565097, "alpha_loss": -0.024193716590248403, "alpha_value": 0.05267809745382616, "duration": 252.7868950366974, "step": 25375}
{"episode_reward": 406.4129356507934, "episode": 204.0, "Q1 loss": 6.355501148223877, "Q2 loss": 6.269027143478394, "Mean Target Q": 148.7208309326172, "Mean Q1": 148.7218918457031, "Mean Q2": 148.72109399414063, "critic_loss": 12.624528282165528, "batch_reward": 1.9793990602493285, "actor_loss": -149.39041433026713, "actor_target_entropy": -6.0, "actor_entropy": 3.255398073504048, "alpha_loss": -0.02656839204005777, "alpha_value": 0.05306926743419188, "duration": 249.8532841205597, "step": 25500}
{"episode_reward": 401.7298351238078, "episode": 205.0, "Q1 loss": 4.82386618232727, "Q2 loss": 4.941959671020507, "Mean Target Q": 149.40404614257812, "Mean Q1": 149.39937072753906, "Mean Q2": 149.40267834472655, "critic_loss": 9.765825813293457, "batch_reward": 1.9773570051193237, "actor_loss": -150.02840023949034, "actor_target_entropy": -6.0, "actor_entropy": 2.971650702612741, "alpha_loss": -0.008543515677696891, "alpha_value": 0.053292894516403296, "duration": 246.9593164920807, "step": 25625}
{"episode_reward": 414.65764153437, "episode": 206.0, "Q1 loss": 4.151011058807373, "Q2 loss": 4.112144176483154, "Mean Target Q": 150.50354956054687, "Mean Q1": 150.5025362548828, "Mean Q2": 150.5003828125, "critic_loss": 8.263155250549316, "batch_reward": 1.9867313346862794, "actor_loss": -151.27527889128655, "actor_target_entropy": -6.0, "actor_entropy": 3.013243725222926, "alpha_loss": -0.00832213886878303, "alpha_value": 0.05339066875562259, "duration": 259.49517941474915, "step": 25750}
{"episode_reward": 348.3165407582683, "episode": 207.0, "Q1 loss": 4.200799989700317, "Q2 loss": 4.294942026138306, "Mean Target Q": 150.27646533203125, "Mean Q1": 150.27659802246095, "Mean Q2": 150.27660241699218, "critic_loss": 8.495741992950439, "batch_reward": 1.987241075515747, "actor_loss": -150.93174598330543, "actor_target_entropy": -6.0, "actor_entropy": 3.02663226733132, "alpha_loss": -0.007182375635094349, "alpha_value": 0.053482281650302776, "duration": 238.9332399368286, "step": 25875}
{"episode_reward": 187.75562310354601, "episode": 208.0, "Q1 loss": 4.33989536857605, "Q2 loss": 4.393305658340454, "Mean Target Q": 151.1080584716797, "Mean Q1": 151.10519860839844, "Mean Q2": 151.10545910644532, "critic_loss": 8.73320101928711, "batch_reward": 1.981695146560669, "actor_loss": -151.7930155108052, "actor_target_entropy": -6.0, "actor_entropy": 3.014210331824518, "alpha_loss": -0.00995110709130043, "alpha_value": 0.053589816586344076, "duration": 247.5751609802246, "step": 26000}
{"episode_reward": 442.80910090705015, "episode": 209.0, "Q1 loss": 4.507710416793823, "Q2 loss": 4.45162287902832, "Mean Target Q": 151.80930651855468, "Mean Q1": 151.80637365722657, "Mean Q2": 151.8049715576172, "critic_loss": 8.959333267211914, "batch_reward": 1.992933521270752, "actor_loss": -152.80042811802454, "actor_target_entropy": -6.0, "actor_entropy": 2.9852001742711143, "alpha_loss": -0.003974872469414203, "alpha_value": 0.053691866315080584, "duration": 256.102872133255, "step": 26125}
{"episode_reward": 271.3959506841868, "episode": 210.0, "Q1 loss": 4.8576368236541745, "Q2 loss": 4.909983814239502, "Mean Target Q": 152.47881970214843, "Mean Q1": 152.47569653320312, "Mean Q2": 152.47527783203125, "critic_loss": 9.767620651245117, "batch_reward": 1.9977123584747314, "actor_loss": -153.2321489395634, "actor_target_entropy": -6.0, "actor_entropy": 2.975403908760317, "alpha_loss": -0.0031887322791942186, "alpha_value": 0.05371960409558613, "duration": 246.72386193275452, "step": 26250}
{"episode_reward": 110.33724126079723, "episode": 211.0, "Q1 loss": 5.800727077484131, "Q2 loss": 5.9427117862701415, "Mean Target Q": 151.7879880371094, "Mean Q1": 151.7852781982422, "Mean Q2": 151.7862976074219, "critic_loss": 11.743438888549806, "batch_reward": 1.982500012397766, "actor_loss": -152.4993150499132, "actor_target_entropy": -6.0, "actor_entropy": 3.110685117661007, "alpha_loss": 0.0023520448289456822, "alpha_value": 0.05375663843565405, "duration": 249.89601945877075, "step": 26375}
{"episode_reward": 80.10677806223731, "episode": 212.0, "Q1 loss": 6.593661863327027, "Q2 loss": 6.610349296569824, "Mean Target Q": 152.49696728515624, "Mean Q1": 152.49398474121094, "Mean Q2": 152.49340734863281, "critic_loss": 13.204011177062988, "batch_reward": 1.9821069030761718, "actor_loss": -153.1724612328314, "actor_target_entropy": -6.0, "actor_entropy": 3.0588121221911524, "alpha_loss": -0.005583672391836562, "alpha_value": 0.05377408461373657, "duration": 260.643426656723, "step": 26500}
{"episode_reward": 467.2705084022918, "episode": 213.0, "Q1 loss": 5.84102187538147, "Q2 loss": 6.0208934135437016, "Mean Target Q": 153.19951098632814, "Mean Q1": 153.20113452148436, "Mean Q2": 153.20141174316407, "critic_loss": 11.861915298461915, "batch_reward": 1.9980252923965454, "actor_loss": -153.91431172688803, "actor_target_entropy": -6.0, "actor_entropy": 3.0734039412604437, "alpha_loss": -0.0003607689609958066, "alpha_value": 0.053852286346029066, "duration": 271.4624056816101, "step": 26625}
{"episode_reward": 399.4003122371187, "episode": 214.0, "Q1 loss": 6.5608277435302735, "Q2 loss": 6.537556062698364, "Mean Target Q": 154.01613842773438, "Mean Q1": 154.006771484375, "Mean Q2": 154.00751635742188, "critic_loss": 13.098383811950683, "batch_reward": 2.0029436960220335, "actor_loss": -154.77143121534777, "actor_target_entropy": -6.0, "actor_entropy": 3.0554327464872792, "alpha_loss": -0.005446481790709039, "alpha_value": 0.05384900368147338, "duration": 240.3918857574463, "step": 26750}
{"episode_reward": 377.5379926747216, "episode": 215.0, "Q1 loss": 5.583197149276733, "Q2 loss": 5.660188022613525, "Mean Target Q": 154.50392541503905, "Mean Q1": 154.5068349609375, "Mean Q2": 154.50620385742187, "critic_loss": 11.243385173797607, "batch_reward": 2.0053797149658203, "actor_loss": -155.35010734437003, "actor_target_entropy": -6.0, "actor_entropy": 3.0136562718285456, "alpha_loss": -0.003483483734141503, "alpha_value": 0.05391127266560669, "duration": 258.751722574234, "step": 26875}
{"episode_reward": 379.1144828782168, "episode": 216.0, "Q1 loss": 4.539972654342652, "Q2 loss": 4.523056930541992, "Mean Target Q": 155.24232409667968, "Mean Q1": 155.23920178222656, "Mean Q2": 155.2403115234375, "critic_loss": 9.063029651641846, "batch_reward": 2.008044535636902, "actor_loss": -155.92659587244833, "actor_target_entropy": -6.0, "actor_entropy": 2.9115481415102558, "alpha_loss": -0.002836439754783867, "alpha_value": 0.053989890193120706, "duration": 244.0905246734619, "step": 27000}
{"episode_reward": 418.51739845217594, "episode": 217.0, "Q1 loss": 4.610823356628418, "Q2 loss": 4.662692579269409, "Mean Target Q": 156.12338671875, "Mean Q1": 156.1196475830078, "Mean Q2": 156.11732116699218, "critic_loss": 9.273515892028808, "batch_reward": 2.0112198753356934, "actor_loss": -156.8562253921751, "actor_target_entropy": -6.0, "actor_entropy": 2.912395359977843, "alpha_loss": -0.003128325052943731, "alpha_value": 0.05403123327594992, "duration": 249.85728359222412, "step": 27125}
{"episode_reward": 421.70944890619404, "episode": 218.0, "Q1 loss": 4.919294595718384, "Q2 loss": 4.981229293823242, "Mean Target Q": 157.13330798339842, "Mean Q1": 157.1316711425781, "Mean Q2": 157.13321130371094, "critic_loss": 9.900523891448975, "batch_reward": 2.0278799648284913, "actor_loss": -157.6081769389491, "actor_target_entropy": -6.0, "actor_entropy": 2.976262096435793, "alpha_loss": -0.0028211950106666454, "alpha_value": 0.05406814189866644, "duration": 243.08894872665405, "step": 27250}
{"episode_reward": 428.8727769322373, "episode": 219.0, "Q1 loss": 4.4825008106231685, "Q2 loss": 4.638600400924682, "Mean Target Q": 157.50673083496093, "Mean Q1": 157.5101044921875, "Mean Q2": 157.50896936035156, "critic_loss": 9.121101230621338, "batch_reward": 2.031266881942749, "actor_loss": -158.14442032102554, "actor_target_entropy": -6.0, "actor_entropy": 2.949974707194737, "alpha_loss": -0.002836166803414623, "alpha_value": 0.05414057405763035, "duration": 238.2900116443634, "step": 27375}
{"episode_reward": 405.5497880371672, "episode": 220.0, "Q1 loss": 4.2181964740753175, "Q2 loss": 4.265942752838135, "Mean Target Q": 158.5358566894531, "Mean Q1": 158.53280529785155, "Mean Q2": 158.53094763183594, "critic_loss": 8.484139225006103, "batch_reward": 2.0356400690078735, "actor_loss": -159.12487325360698, "actor_target_entropy": -6.0, "actor_entropy": 3.019287132447766, "alpha_loss": -0.0055704954147879635, "alpha_value": 0.05417162263118338, "duration": 232.48206329345703, "step": 27500}
{"episode_reward": 427.5604184944961, "episode": 221.0, "Q1 loss": 4.766978029251098, "Q2 loss": 4.938127382278442, "Mean Target Q": 159.01220947265625, "Mean Q1": 159.0088504638672, "Mean Q2": 159.01040185546876, "critic_loss": 9.705105392456055, "batch_reward": 2.0344069213867186, "actor_loss": -159.3516378251333, "actor_target_entropy": -6.0, "actor_entropy": 2.9437435468037925, "alpha_loss": -0.011471906240792975, "alpha_value": 0.05432623153677493, "duration": 242.49652433395386, "step": 27625}
{"episode_reward": 396.92325676214045, "episode": 222.0, "Q1 loss": 5.007104541778564, "Q2 loss": 4.9752354946136474, "Mean Target Q": 159.95471740722655, "Mean Q1": 159.95290551757813, "Mean Q2": 159.9521864013672, "critic_loss": 9.982340045928956, "batch_reward": 2.042083406448364, "actor_loss": -160.80529539046748, "actor_target_entropy": -6.0, "actor_entropy": 2.880892845892137, "alpha_loss": -0.012363883696736829, "alpha_value": 0.054503164236950466, "duration": 218.91785097122192, "step": 27750}
{"episode_reward": 371.13061223937433, "episode": 223.0, "Q1 loss": 4.959329988479614, "Q2 loss": 4.95002853012085, "Mean Target Q": 160.6957392578125, "Mean Q1": 160.69600622558593, "Mean Q2": 160.69705700683593, "critic_loss": 9.909358501434326, "batch_reward": 2.0562818584442137, "actor_loss": -161.4123789469401, "actor_target_entropy": -6.0, "actor_entropy": 2.8746387504395985, "alpha_loss": -0.01448510680347681, "alpha_value": 0.05471480574919543, "duration": 232.87582302093506, "step": 27875}
{"episode_reward": 402.1843144402055, "episode": 224.0, "Q1 loss": 4.907962350845337, "Q2 loss": 4.969302295684814, "Mean Target Q": 161.07493579101563, "Mean Q1": 161.07021154785156, "Mean Q2": 161.06853076171876, "critic_loss": 9.877264640808106, "batch_reward": 2.0549037771224974, "actor_loss": -161.79577513664, "actor_target_entropy": -6.0, "actor_entropy": 2.931523461495676, "alpha_loss": -0.00907799818988649, "alpha_value": 0.054925276938152814, "duration": 228.3570477962494, "step": 28000}
{"episode_reward": 454.0216857703291, "episode": 225.0, "Q1 loss": 4.971288572311401, "Q2 loss": 5.003560527801514, "Mean Target Q": 161.82320764160156, "Mean Q1": 161.82367346191407, "Mean Q2": 161.8231923828125, "critic_loss": 9.974849113464355, "batch_reward": 2.066623553276062, "actor_loss": -162.66087849934897, "actor_target_entropy": -6.0, "actor_entropy": 2.9485436091347346, "alpha_loss": 0.00031261059773405865, "alpha_value": 0.0550213923965678, "duration": 224.82576489448547, "step": 28125}
{"episode_reward": 416.1509334198553, "episode": 226.0, "Q1 loss": 4.536787347793579, "Q2 loss": 4.643538146972657, "Mean Target Q": 162.66445678710937, "Mean Q1": 162.66383508300783, "Mean Q2": 162.66586047363282, "critic_loss": 9.180325485229492, "batch_reward": 2.06903537273407, "actor_loss": -163.53824935420866, "actor_target_entropy": -6.0, "actor_entropy": 2.888296631074721, "alpha_loss": -0.006825926386931491, "alpha_value": 0.055055499598220294, "duration": 235.80054354667664, "step": 28250}
{"episode_reward": 434.8002001492881, "episode": 227.0, "Q1 loss": 4.442777565002442, "Q2 loss": 4.482434047698975, "Mean Target Q": 163.14635388183595, "Mean Q1": 163.1422149658203, "Mean Q2": 163.1396057128906, "critic_loss": 8.9252116355896, "batch_reward": 2.0705367660522462, "actor_loss": -164.05431232755146, "actor_target_entropy": -6.0, "actor_entropy": 2.926658134611826, "alpha_loss": -0.008030380528893263, "alpha_value": 0.05519626274862453, "duration": 223.3020145893097, "step": 28375}
{"episode_reward": 137.9633965835848, "episode": 228.0, "Q1 loss": 5.779956886291504, "Q2 loss": 5.826217060089111, "Mean Target Q": 163.4430137939453, "Mean Q1": 163.43552856445314, "Mean Q2": 163.43585827636718, "critic_loss": 11.606173915863037, "batch_reward": 2.0648556909561155, "actor_loss": -164.17888518302672, "actor_target_entropy": -6.0, "actor_entropy": 2.87717055889868, "alpha_loss": -0.0020950348905077383, "alpha_value": 0.05529757863176146, "duration": 168.24161458015442, "step": 28500}
{"episode_reward": 415.08324199730606, "episode": 229.0, "Q1 loss": 6.048595489501953, "Q2 loss": 6.069687602996826, "Mean Target Q": 164.31362475585937, "Mean Q1": 164.31472839355467, "Mean Q2": 164.31672094726562, "critic_loss": 12.118283081054688, "batch_reward": 2.080085114479065, "actor_loss": -164.9564729720827, "actor_target_entropy": -6.0, "actor_entropy": 3.029036907922654, "alpha_loss": -0.009227769181413192, "alpha_value": 0.05539343497029061, "duration": 74.02377986907959, "step": 28625}
{"episode_reward": 465.882884562151, "episode": 230.0, "Q1 loss": 5.174549139022827, "Q2 loss": 5.410162677764893, "Mean Target Q": 165.04274182128907, "Mean Q1": 165.04188269042967, "Mean Q2": 165.0401954345703, "critic_loss": 10.584711799621582, "batch_reward": 2.086761079788208, "actor_loss": -165.94804283880418, "actor_target_entropy": -6.0, "actor_entropy": 2.8157447845705095, "alpha_loss": -0.009364211898026687, "alpha_value": 0.055545528851488675, "duration": 76.2450749874115, "step": 28750}
{"episode_reward": 444.21197643417725, "episode": 231.0, "Q1 loss": 4.811420713424683, "Q2 loss": 4.894089559555054, "Mean Target Q": 165.49510473632813, "Mean Q1": 165.495994140625, "Mean Q2": 165.4973056640625, "critic_loss": 9.705510234832763, "batch_reward": 2.0825297632217405, "actor_loss": -166.4294954330202, "actor_target_entropy": -6.0, "actor_entropy": 2.884235522103688, "alpha_loss": -0.01101537138253214, "alpha_value": 0.055716480531417666, "duration": 80.21241998672485, "step": 28875}
{"episode_reward": 440.0043145687159, "episode": 232.0, "Q1 loss": 4.7992462768554685, "Q2 loss": 4.677735084533691, "Mean Target Q": 165.99855212402343, "Mean Q1": 165.9951779785156, "Mean Q2": 165.99401770019531, "critic_loss": 9.476981353759765, "batch_reward": 2.0916673774719237, "actor_loss": -166.8662389939831, "actor_target_entropy": -6.0, "actor_entropy": 2.9178975705177552, "alpha_loss": -0.01045798129897805, "alpha_value": 0.05587654999083621, "duration": 122.49925422668457, "step": 29000}
{"episode_reward": 290.6543992395156, "episode": 233.0, "Q1 loss": 4.975368391036987, "Q2 loss": 4.990937568664551, "Mean Target Q": 166.94894592285155, "Mean Q1": 166.94475244140625, "Mean Q2": 166.94592236328126, "critic_loss": 9.966305927276611, "batch_reward": 2.095059946060181, "actor_loss": -167.44727289109002, "actor_target_entropy": -6.0, "actor_entropy": 2.811992853406876, "alpha_loss": -0.0038749343264729732, "alpha_value": 0.05606209053795886, "duration": 123.30338072776794, "step": 29125}
{"episode_reward": 417.7813058383392, "episode": 234.0, "Q1 loss": 5.008201293945312, "Q2 loss": 5.07075975227356, "Mean Target Q": 167.73899865722657, "Mean Q1": 167.73399243164062, "Mean Q2": 167.73364404296876, "critic_loss": 10.078961006164551, "batch_reward": 2.1014526290893554, "actor_loss": -168.45884015483242, "actor_target_entropy": -6.0, "actor_entropy": 2.930870921381058, "alpha_loss": -0.0033860160901601757, "alpha_value": 0.056090716608347614, "duration": 145.840646982193, "step": 29250}
{"episode_reward": 392.4558907073004, "episode": 235.0, "Q1 loss": 5.321284692764282, "Q2 loss": 5.304293445587158, "Mean Target Q": 168.7410330810547, "Mean Q1": 168.74060009765626, "Mean Q2": 168.7390830078125, "critic_loss": 10.625578144073486, "batch_reward": 2.110126428604126, "actor_loss": -169.17773921906002, "actor_target_entropy": -6.0, "actor_entropy": 2.9111996302528986, "alpha_loss": -0.004696998745203018, "alpha_value": 0.05618286239296386, "duration": 132.22945952415466, "step": 29375}
{"episode_reward": 282.06813699915966, "episode": 236.0, "Q1 loss": 5.586408218383789, "Q2 loss": 5.692553014755249, "Mean Target Q": 168.80500354003905, "Mean Q1": 168.80111145019532, "Mean Q2": 168.80410205078124, "critic_loss": 11.278961223602295, "batch_reward": 2.0995353088378907, "actor_loss": -169.4530317244991, "actor_target_entropy": -6.0, "actor_entropy": 2.8542684201271302, "alpha_loss": -0.006659974329053394, "alpha_value": 0.056300711783062264, "duration": 81.10677099227905, "step": 29500}
{"episode_reward": 78.72142181973557, "episode": 237.0, "Q1 loss": 5.850099992752075, "Q2 loss": 5.5351270236969, "Mean Target Q": 169.3018825683594, "Mean Q1": 169.29601916503907, "Mean Q2": 169.2958798828125, "critic_loss": 11.385227012634278, "batch_reward": 2.1055553550720214, "actor_loss": -169.71990845695373, "actor_target_entropy": -6.0, "actor_entropy": 3.0895837337251693, "alpha_loss": -0.011813446373072646, "alpha_value": 0.056459458213195084, "duration": 98.68063735961914, "step": 29625}
{"episode_reward": 460.45165790256294, "episode": 238.0, "Q1 loss": 6.079852230072022, "Q2 loss": 6.221105781555176, "Mean Target Q": 169.53495922851562, "Mean Q1": 169.53438781738282, "Mean Q2": 169.53547790527344, "critic_loss": 12.300957939147949, "batch_reward": 2.1127654933929443, "actor_loss": -170.33313431278353, "actor_target_entropy": -6.0, "actor_entropy": 2.842369041135234, "alpha_loss": -0.0017682851307214268, "alpha_value": 0.05658932613385135, "duration": 130.5419144630432, "step": 29750}
{"episode_reward": 424.10601815530725, "episode": 239.0, "Q1 loss": 7.710392894744873, "Q2 loss": 7.633281051635742, "Mean Target Q": 169.8945302734375, "Mean Q1": 169.89100842285157, "Mean Q2": 169.8912775878906, "critic_loss": 15.343674026489257, "batch_reward": 2.1030016984939577, "actor_loss": -170.38004048665366, "actor_target_entropy": -6.0, "actor_entropy": 2.9087580234285384, "alpha_loss": -0.003778373822569847, "alpha_value": 0.056676462361596125, "duration": 133.21210622787476, "step": 29875}
{"episode_reward": 110.6881478049126, "episode": 240.0, "Q1 loss": 6.045317991256714, "Q2 loss": 6.016583610534668, "Mean Target Q": 170.81280651855468, "Mean Q1": 170.81462976074218, "Mean Q2": 170.813486328125, "critic_loss": 12.06190163040161, "batch_reward": 2.1059755516052245, "actor_loss": -171.85594349522745, "actor_target_entropy": -6.0, "actor_entropy": 3.0254939717631184, "alpha_loss": -0.006646830945335809, "alpha_value": 0.05673832171027956, "step": 30000}
{"duration": 121.66687941551208, "step": 30000}
{"episode_reward": 430.7196537749212, "episode": 241.0, "Q1 loss": 5.26913730430603, "Q2 loss": 5.302853387832641, "Mean Target Q": 170.75371240234375, "Mean Q1": 170.74830334472657, "Mean Q2": 170.74777221679688, "critic_loss": 10.571990699768067, "batch_reward": 2.099405225753784, "actor_loss": -171.71593051486545, "actor_target_entropy": -6.0, "actor_entropy": 2.996662317760407, "alpha_loss": -0.006955165170236594, "alpha_value": 0.056903106880324475, "duration": 79.7872633934021, "step": 30125}
{"episode_reward": 412.1751167769797, "episode": 242.0, "Q1 loss": 5.712918848037719, "Q2 loss": 5.67903621673584, "Mean Target Q": 171.5664580078125, "Mean Q1": 171.5652998046875, "Mean Q2": 171.5625565185547, "critic_loss": 11.391955055236817, "batch_reward": 2.1130276174545286, "actor_loss": -172.28975677490234, "actor_target_entropy": -6.0, "actor_entropy": 2.9873401580318326, "alpha_loss": -0.0029082992189233344, "alpha_value": 0.056971896999651155, "duration": 65.33768320083618, "step": 30250}
{"episode_reward": 439.4802657357729, "episode": 243.0, "Q1 loss": 5.21008563041687, "Q2 loss": 5.164911893844605, "Mean Target Q": 172.56380493164062, "Mean Q1": 172.56265661621094, "Mean Q2": 172.56504638671876, "critic_loss": 10.374997512817384, "batch_reward": 2.1241476068496703, "actor_loss": -173.04496474493118, "actor_target_entropy": -6.0, "actor_entropy": 2.9169014711228627, "alpha_loss": 0.0018048494396406033, "alpha_value": 0.05701290454008187, "duration": 105.50440835952759, "step": 30375}
{"episode_reward": 240.82513338679283, "episode": 244.0, "Q1 loss": 6.239100028991699, "Q2 loss": 6.336976747512818, "Mean Target Q": 172.7289168701172, "Mean Q1": 172.7237342529297, "Mean Q2": 172.72342028808595, "critic_loss": 12.576076808929443, "batch_reward": 2.1105442667007446, "actor_loss": -173.25411248976184, "actor_target_entropy": -6.0, "actor_entropy": 2.835326252445098, "alpha_loss": -0.00013435102488485075, "alpha_value": 0.056983024065028184, "duration": 125.92082262039185, "step": 30500}
{"episode_reward": 122.9313914922585, "episode": 245.0, "Q1 loss": 6.212222494125366, "Q2 loss": 6.336098354339599, "Mean Target Q": 173.24861474609375, "Mean Q1": 173.2438603515625, "Mean Q2": 173.24468603515626, "critic_loss": 12.54832085800171, "batch_reward": 2.1106250915527345, "actor_loss": -174.02428133525547, "actor_target_entropy": -6.0, "actor_entropy": 2.939253795714605, "alpha_loss": -0.00611685092989651, "alpha_value": 0.057032138288638186, "duration": 117.826833486557, "step": 30625}
{"episode_reward": 289.6949242028054, "episode": 246.0, "Q1 loss": 7.500922334671021, "Q2 loss": 7.381736232757568, "Mean Target Q": 173.58158264160156, "Mean Q1": 173.57962963867186, "Mean Q2": 173.57897131347656, "critic_loss": 14.882658557891846, "batch_reward": 2.117826648712158, "actor_loss": -174.63610347624748, "actor_target_entropy": -6.0, "actor_entropy": 2.9180143494759836, "alpha_loss": -0.0027884650569889816, "alpha_value": 0.057121386543770115, "duration": 118.45027709007263, "step": 30750}
{"episode_reward": 399.61994518111237, "episode": 247.0, "Q1 loss": 6.8472636108398435, "Q2 loss": 6.990756900787353, "Mean Target Q": 174.56266674804687, "Mean Q1": 174.5607147216797, "Mean Q2": 174.55778540039063, "critic_loss": 13.838020542144776, "batch_reward": 2.1282497110366823, "actor_loss": -175.0802760048518, "actor_target_entropy": -6.0, "actor_entropy": 2.9731869205595953, "alpha_loss": -0.005361293146889361, "alpha_value": 0.057208956099193985, "duration": 91.26846814155579, "step": 30875}
{"episode_reward": 448.4956875505141, "episode": 248.0, "Q1 loss": 6.7622028293609615, "Q2 loss": 6.85013680267334, "Mean Target Q": 175.004091796875, "Mean Q1": 175.00252563476562, "Mean Q2": 175.00522094726563, "critic_loss": 13.612339614868164, "batch_reward": 2.132803147315979, "actor_loss": -175.7406485772902, "actor_target_entropy": -6.0, "actor_entropy": 2.9895402308433288, "alpha_loss": 4.5157416964009884e-05, "alpha_value": 0.05727157483963134, "duration": 64.93376159667969, "step": 31000}
{"episode_reward": 325.4249808466822, "episode": 249.0, "Q1 loss": 6.587387887954712, "Q2 loss": 6.579610488891602, "Mean Target Q": 175.19986999511718, "Mean Q1": 175.1985673828125, "Mean Q2": 175.20060278320312, "critic_loss": 13.166998371124267, "batch_reward": 2.131163166999817, "actor_loss": -176.0826449924045, "actor_target_entropy": -6.0, "actor_entropy": 2.8954837284390886, "alpha_loss": 0.0012259181101052534, "alpha_value": 0.05727965779032649, "duration": 62.32512307167053, "step": 31125}
{"episode_reward": 444.3605370975111, "episode": 250.0, "Q1 loss": 6.696426736831665, "Q2 loss": 6.864333366394043, "Mean Target Q": 176.2903634033203, "Mean Q1": 176.2872275390625, "Mean Q2": 176.28421459960938, "critic_loss": 13.56076012802124, "batch_reward": 2.1380733165740966, "actor_loss": -177.0028814500378, "actor_target_entropy": -6.0, "actor_entropy": 2.9138311532235917, "alpha_loss": -0.008049836968101801, "alpha_value": 0.05729621540008471, "duration": 82.92692351341248, "step": 31250}
{"episode_reward": 339.08810348324334, "episode": 251.0, "Q1 loss": 6.777898069381714, "Q2 loss": 6.712022779464721, "Mean Target Q": 176.62976696777343, "Mean Q1": 176.62623669433594, "Mean Q2": 176.6276746826172, "critic_loss": 13.489920875549316, "batch_reward": 2.1409312467575075, "actor_loss": -177.00657678028895, "actor_target_entropy": -6.0, "actor_entropy": 2.950533912295387, "alpha_loss": -0.006917650822461361, "alpha_value": 0.05748065527806663, "duration": 97.6753945350647, "step": 31375}
{"episode_reward": 348.14886551100955, "episode": 252.0, "Q1 loss": 7.592119312286377, "Q2 loss": 7.359294567108154, "Mean Target Q": 177.12222314453126, "Mean Q1": 177.125208984375, "Mean Q2": 177.1243787841797, "critic_loss": 14.951413837432861, "batch_reward": 2.1368378133773804, "actor_loss": -177.8820074758222, "actor_target_entropy": -6.0, "actor_entropy": 3.032863732307188, "alpha_loss": -0.0050172942104719336, "alpha_value": 0.057643959918561805, "duration": 114.03776812553406, "step": 31500}
{"episode_reward": 306.2346555769502, "episode": 253.0, "Q1 loss": 6.793144855499268, "Q2 loss": 6.796384630203247, "Mean Target Q": 177.565900390625, "Mean Q1": 177.5547305908203, "Mean Q2": 177.5534354248047, "critic_loss": 13.589529521942138, "batch_reward": 2.1446412687301635, "actor_loss": -178.34993804447234, "actor_target_entropy": -6.0, "actor_entropy": 3.0771453948248, "alpha_loss": -0.006017459338412635, "alpha_value": 0.05770777597426398, "duration": 113.72883987426758, "step": 31625}
{"episode_reward": 350.9686675536652, "episode": 254.0, "Q1 loss": 7.192469619750977, "Q2 loss": 7.183250883102417, "Mean Target Q": 178.03474975585937, "Mean Q1": 178.03634655761718, "Mean Q2": 178.03771911621095, "critic_loss": 14.375720428466797, "batch_reward": 2.1417216472625733, "actor_loss": -178.48444268011278, "actor_target_entropy": -6.0, "actor_entropy": 3.046494949248529, "alpha_loss": -0.006144608489252747, "alpha_value": 0.05782751164090485, "duration": 107.36543464660645, "step": 31750}
{"episode_reward": 423.298744524022, "episode": 255.0, "Q1 loss": 7.57228671836853, "Q2 loss": 7.525457654953003, "Mean Target Q": 179.0579490966797, "Mean Q1": 179.05746350097655, "Mean Q2": 179.05913146972657, "critic_loss": 15.097744411468506, "batch_reward": 2.1549090480804445, "actor_loss": -179.55975971524677, "actor_target_entropy": -6.0, "actor_entropy": 2.972144376663935, "alpha_loss": -0.007444211073027599, "alpha_value": 0.05799486689942704, "duration": 103.53509521484375, "step": 31875}
{"episode_reward": 483.08000807988, "episode": 256.0, "Q1 loss": 7.213157543182373, "Q2 loss": 7.276957111358643, "Mean Target Q": 179.47589599609375, "Mean Q1": 179.47302661132812, "Mean Q2": 179.47130456542968, "critic_loss": 14.490114723205567, "batch_reward": 2.1635658054351805, "actor_loss": -180.19485498243762, "actor_target_entropy": -6.0, "actor_entropy": 3.0143410851878505, "alpha_loss": -0.008193179003653987, "alpha_value": 0.058098675602296604, "duration": 110.12427163124084, "step": 32000}
{"episode_reward": 428.840573504561, "episode": 257.0, "Q1 loss": 6.984303647994995, "Q2 loss": 7.195414854049683, "Mean Target Q": 179.70459411621093, "Mean Q1": 179.69650500488282, "Mean Q2": 179.69519567871095, "critic_loss": 14.179718513488769, "batch_reward": 2.161974507331848, "actor_loss": -180.20071677556115, "actor_target_entropy": -6.0, "actor_entropy": 2.9682116962614513, "alpha_loss": -0.021633849275993215, "alpha_value": 0.05846976519198728, "duration": 92.81476211547852, "step": 32125}
{"episode_reward": 442.47392994406897, "episode": 258.0, "Q1 loss": 7.484492763519287, "Q2 loss": 7.7049293766021725, "Mean Target Q": 180.53243334960936, "Mean Q1": 180.5324287109375, "Mean Q2": 180.5319005126953, "critic_loss": 15.189422187805176, "batch_reward": 2.158951410293579, "actor_loss": -181.13800467214276, "actor_target_entropy": -6.0, "actor_entropy": 3.062496304512024, "alpha_loss": -0.010652171271372466, "alpha_value": 0.05879368876913649, "duration": 67.7243173122406, "step": 32250}
{"episode_reward": 216.62358165034826, "episode": 259.0, "Q1 loss": 9.10461067199707, "Q2 loss": 9.247491413116455, "Mean Target Q": 180.40083728027344, "Mean Q1": 180.3940270996094, "Mean Q2": 180.39813635253907, "critic_loss": 18.352102005004884, "batch_reward": 2.1586023626327515, "actor_loss": -181.33351086813306, "actor_target_entropy": -6.0, "actor_entropy": 3.2701883845859103, "alpha_loss": -0.0408281832046452, "alpha_value": 0.059163873169872865, "duration": 62.011587142944336, "step": 32375}
{"episode_reward": 377.2033350354194, "episode": 260.0, "Q1 loss": 8.242802227020263, "Q2 loss": 8.347139007568359, "Mean Target Q": 181.34004736328126, "Mean Q1": 181.33835302734374, "Mean Q2": 181.3379755859375, "critic_loss": 16.589941207885744, "batch_reward": 2.1634628534317017, "actor_loss": -181.57176134663243, "actor_target_entropy": -6.0, "actor_entropy": 3.2378173105178343, "alpha_loss": -0.011070997891722308, "alpha_value": 0.059718921787273956, "duration": 78.90769791603088, "step": 32500}
{"episode_reward": 426.04094097819603, "episode": 261.0, "Q1 loss": 7.3204494495391845, "Q2 loss": 7.191336420059204, "Mean Target Q": 182.29650512695312, "Mean Q1": 182.2908565673828, "Mean Q2": 182.29184020996092, "critic_loss": 14.511785846710206, "batch_reward": 2.179962589263916, "actor_loss": -183.00970628526477, "actor_target_entropy": -6.0, "actor_entropy": 3.128613369805472, "alpha_loss": -0.03059882488072155, "alpha_value": 0.060094823900723814, "duration": 88.99992156028748, "step": 32625}
{"episode_reward": 433.0154972134609, "episode": 262.0, "Q1 loss": 6.784142288208008, "Q2 loss": 6.84782876586914, "Mean Target Q": 182.91460546875, "Mean Q1": 182.91384606933593, "Mean Q2": 182.91443237304688, "critic_loss": 13.63197106552124, "batch_reward": 2.184900400161743, "actor_loss": -183.17956001527847, "actor_target_entropy": -6.0, "actor_entropy": 3.1519639991944834, "alpha_loss": -0.02965244747540583, "alpha_value": 0.060606365336974694, "duration": 112.04312348365784, "step": 32750}
{"episode_reward": 403.53845874436263, "episode": 263.0, "Q1 loss": 6.867672096252441, "Q2 loss": 6.861024101257324, "Mean Target Q": 183.03064025878905, "Mean Q1": 183.03311975097657, "Mean Q2": 183.0301328125, "critic_loss": 13.728696193695068, "batch_reward": 2.1754265823364256, "actor_loss": -183.84539891803075, "actor_target_entropy": -6.0, "actor_entropy": 2.974992067094833, "alpha_loss": -0.04422271464552198, "alpha_value": 0.061190970855661775, "duration": 80.27926087379456, "step": 32875}
{"episode_reward": 437.7161087901654, "episode": 264.0, "Q1 loss": 6.968484928131104, "Q2 loss": 6.979619798660278, "Mean Target Q": 183.88163293457032, "Mean Q1": 183.87402502441407, "Mean Q2": 183.8738017578125, "critic_loss": 13.948104667663575, "batch_reward": 2.178779294967651, "actor_loss": -184.71020655478202, "actor_target_entropy": -6.0, "actor_entropy": 3.023126140717537, "alpha_loss": -0.03139771526724461, "alpha_value": 0.061707260271060396, "duration": 58.71701717376709, "step": 33000}
{"episode_reward": 453.5875433276982, "episode": 265.0, "Q1 loss": 7.561380889892578, "Q2 loss": 7.5927702445983885, "Mean Target Q": 184.1601589355469, "Mean Q1": 184.15610510253907, "Mean Q2": 184.15956213378905, "critic_loss": 15.154151119232179, "batch_reward": 2.1814083576202394, "actor_loss": -184.51429942297557, "actor_target_entropy": -6.0, "actor_entropy": 3.0307212443578813, "alpha_loss": -0.049084386906571804, "alpha_value": 0.062236577053756695, "duration": 66.41066908836365, "step": 33125}
{"episode_reward": 439.6170850432965, "episode": 266.0, "Q1 loss": 6.7818158321380615, "Q2 loss": 6.834376235961914, "Mean Target Q": 185.1949306640625, "Mean Q1": 185.19415124511718, "Mean Q2": 185.19146118164062, "critic_loss": 13.616191978454589, "batch_reward": 2.1973199710845948, "actor_loss": -185.9006345195155, "actor_target_entropy": -6.0, "actor_entropy": 3.07780945685602, "alpha_loss": -0.02970634618653886, "alpha_value": 0.06281640011390226, "duration": 65.53983283042908, "step": 33250}
{"episode_reward": 314.1116832319462, "episode": 267.0, "Q1 loss": 6.593266363143921, "Q2 loss": 6.574787647247314, "Mean Target Q": 185.62567932128906, "Mean Q1": 185.6256689453125, "Mean Q2": 185.62724536132814, "critic_loss": 13.16805403137207, "batch_reward": 2.191598087310791, "actor_loss": -186.27375987219432, "actor_target_entropy": -6.0, "actor_entropy": 3.036133959179833, "alpha_loss": -0.030793363671927226, "alpha_value": 0.0632160365533308, "duration": 70.45409440994263, "step": 33375}
{"episode_reward": 466.2684716661947, "episode": 268.0, "Q1 loss": 6.580284887313843, "Q2 loss": 6.627095140457153, "Mean Target Q": 186.85392639160156, "Mean Q1": 186.84975366210938, "Mean Q2": 186.8488907470703, "critic_loss": 13.207380031585693, "batch_reward": 2.212775297164917, "actor_loss": -187.44483849310106, "actor_target_entropy": -6.0, "actor_entropy": 3.083053554258039, "alpha_loss": -0.030109127611672927, "alpha_value": 0.06362232437623919, "duration": 67.94696235656738, "step": 33500}
{"episode_reward": 380.6378384485323, "episode": 269.0, "Q1 loss": 6.00963247680664, "Q2 loss": 6.0176554241180416, "Mean Target Q": 186.77924951171875, "Mean Q1": 186.77672375488282, "Mean Q2": 186.77713610839845, "critic_loss": 12.027287799835205, "batch_reward": 2.2073761444091797, "actor_loss": -187.4233633374411, "actor_target_entropy": -6.0, "actor_entropy": 3.0374505746932257, "alpha_loss": -0.028042073444729403, "alpha_value": 0.06404476554819517, "duration": 78.94986248016357, "step": 33625}
{"episode_reward": 454.18884777841043, "episode": 270.0, "Q1 loss": 5.986017526626587, "Q2 loss": 5.904422121047974, "Mean Target Q": 187.20144262695314, "Mean Q1": 187.19553747558595, "Mean Q2": 187.1964533691406, "critic_loss": 11.890439708709717, "batch_reward": 2.212247219085693, "actor_loss": -188.1534886513987, "actor_target_entropy": -6.0, "actor_entropy": 3.0415769315535024, "alpha_loss": -0.013558253444986599, "alpha_value": 0.06428609874807388, "duration": 77.06348466873169, "step": 33750}
{"episode_reward": 380.7414526626024, "episode": 271.0, "Q1 loss": 5.872404973983764, "Q2 loss": 5.744267587661743, "Mean Target Q": 188.36501635742187, "Mean Q1": 188.36651623535155, "Mean Q2": 188.36544555664062, "critic_loss": 11.616672512054443, "batch_reward": 2.2216236381530763, "actor_loss": -188.7613491482205, "actor_target_entropy": -6.0, "actor_entropy": 2.9649910094246033, "alpha_loss": -0.014774317949241588, "alpha_value": 0.06447993794138152, "duration": 87.80372524261475, "step": 33875}
{"episode_reward": 436.9218765711848, "episode": 272.0, "Q1 loss": 6.264208263397217, "Q2 loss": 6.101169540405273, "Mean Target Q": 188.6272255859375, "Mean Q1": 188.6222431640625, "Mean Q2": 188.6208065185547, "critic_loss": 12.365377880096435, "batch_reward": 2.2204244747161863, "actor_loss": -189.30182253929877, "actor_target_entropy": -6.0, "actor_entropy": 3.0716134463587115, "alpha_loss": -0.009968504227036911, "alpha_value": 0.06459939954805752, "duration": 77.06468343734741, "step": 34000}
{"episode_reward": 306.93803830740706, "episode": 273.0, "Q1 loss": 5.753091588973999, "Q2 loss": 5.895534900665283, "Mean Target Q": 188.71818505859375, "Mean Q1": 188.71832397460938, "Mean Q2": 188.72000598144533, "critic_loss": 11.648626461029053, "batch_reward": 2.2209404487609863, "actor_loss": -189.15684606158544, "actor_target_entropy": -6.0, "actor_entropy": 3.1082952514527338, "alpha_loss": -0.005595970895170929, "alpha_value": 0.06476046835730222, "duration": 79.343088388443, "step": 34125}
{"episode_reward": 410.187789071787, "episode": 274.0, "Q1 loss": 5.855472511291504, "Q2 loss": 5.6906864528656005, "Mean Target Q": 189.19722705078124, "Mean Q1": 189.1921533203125, "Mean Q2": 189.191083984375, "critic_loss": 11.546158889770508, "batch_reward": 2.223046106338501, "actor_loss": -189.959718765751, "actor_target_entropy": -6.0, "actor_entropy": 3.011800727536601, "alpha_loss": -0.005493945092894137, "alpha_value": 0.06484106757538555, "duration": 84.4391872882843, "step": 34250}
{"episode_reward": 446.8769320001497, "episode": 275.0, "Q1 loss": 5.662509567260742, "Q2 loss": 5.638944198608399, "Mean Target Q": 189.85479577636718, "Mean Q1": 189.85234997558592, "Mean Q2": 189.85277502441406, "critic_loss": 11.301453777313233, "batch_reward": 2.2312701110839845, "actor_loss": -190.20929778568328, "actor_target_entropy": -6.0, "actor_entropy": 3.126043066145882, "alpha_loss": -0.00747003143150655, "alpha_value": 0.06494060012103733, "duration": 78.37141919136047, "step": 34375}
{"episode_reward": 434.80164318036014, "episode": 276.0, "Q1 loss": 6.137081523895263, "Q2 loss": 6.100916353225708, "Mean Target Q": 190.7900556640625, "Mean Q1": 190.7855565185547, "Mean Q2": 190.78731958007813, "critic_loss": 12.237997844696045, "batch_reward": 2.2388235149383546, "actor_loss": -191.77298687350364, "actor_target_entropy": -6.0, "actor_entropy": 3.0452331996733144, "alpha_loss": -0.013378087836768358, "alpha_value": 0.06508283975978986, "duration": 88.99812722206116, "step": 34500}
{"episode_reward": 441.5539562343191, "episode": 277.0, "Q1 loss": 5.437514215469361, "Q2 loss": 5.344472345352173, "Mean Target Q": 190.99724719238282, "Mean Q1": 191.0023740234375, "Mean Q2": 190.99997729492188, "critic_loss": 10.781986568450927, "batch_reward": 2.240149517059326, "actor_loss": -191.29948352632067, "actor_target_entropy": -6.0, "actor_entropy": 3.1293053551325722, "alpha_loss": -0.007466871563034753, "alpha_value": 0.06523486691136747, "duration": 104.54920387268066, "step": 34625}
{"episode_reward": 422.7855576261003, "episode": 278.0, "Q1 loss": 6.032835948944092, "Q2 loss": 5.992189226150512, "Mean Target Q": 191.3925352783203, "Mean Q1": 191.38458056640624, "Mean Q2": 191.38440942382812, "critic_loss": 12.025025177001954, "batch_reward": 2.2418558254241945, "actor_loss": -192.0469724593624, "actor_target_entropy": -6.0, "actor_entropy": 3.0817692510543333, "alpha_loss": -0.0008102934131579053, "alpha_value": 0.06530019617314395, "duration": 114.93104076385498, "step": 34750}
{"episode_reward": 451.29047190984625, "episode": 279.0, "Q1 loss": 5.6157227115631105, "Q2 loss": 5.66507042312622, "Mean Target Q": 192.41140576171875, "Mean Q1": 192.40748266601562, "Mean Q2": 192.40823425292967, "critic_loss": 11.280793186187744, "batch_reward": 2.2516968784332274, "actor_loss": -192.64359707302518, "actor_target_entropy": -6.0, "actor_entropy": 2.9676963677482, "alpha_loss": -0.0029727108185253447, "alpha_value": 0.06534773782047179, "duration": 121.04720783233643, "step": 34875}
{"episode_reward": 282.1261961093062, "episode": 280.0, "Q1 loss": 5.810843015670776, "Q2 loss": 5.650410766601563, "Mean Target Q": 192.866384765625, "Mean Q1": 192.8667520751953, "Mean Q2": 192.86393798828124, "critic_loss": 11.461253772735596, "batch_reward": 2.2538320503234863, "actor_loss": -193.46092888616747, "actor_target_entropy": -6.0, "actor_entropy": 3.029348031167061, "alpha_loss": 0.005598318759321926, "alpha_value": 0.06532079712754864, "step": 35000}
{"duration": 98.12495493888855, "step": 35000}
{"episode_reward": 396.3267638296167, "episode": 281.0, "Q1 loss": 5.4232439479827885, "Q2 loss": 5.418861206054688, "Mean Target Q": 193.5665302734375, "Mean Q1": 193.566041015625, "Mean Q2": 193.56725708007812, "critic_loss": 10.842105125427246, "batch_reward": 2.2601852626800536, "actor_loss": -194.07714044480096, "actor_target_entropy": -6.0, "actor_entropy": 2.996593403437781, "alpha_loss": 0.011641363609611752, "alpha_value": 0.06515367090096823, "duration": 81.44661378860474, "step": 35125}
{"episode_reward": 436.3615440300219, "episode": 282.0, "Q1 loss": 5.559209350585937, "Q2 loss": 5.475729625701904, "Mean Target Q": 193.41803601074218, "Mean Q1": 193.41824255371094, "Mean Q2": 193.41661767578125, "critic_loss": 11.034938957214356, "batch_reward": 2.257560203552246, "actor_loss": -194.20822955716042, "actor_target_entropy": -6.0, "actor_entropy": 3.0266071327271, "alpha_loss": 0.00456570180493497, "alpha_value": 0.06501836921053022, "duration": 75.79152631759644, "step": 35250}
{"episode_reward": 473.846477188584, "episode": 283.0, "Q1 loss": 5.862406764984131, "Q2 loss": 5.800005443572998, "Mean Target Q": 194.2275078125, "Mean Q1": 194.21968591308593, "Mean Q2": 194.2188194580078, "critic_loss": 11.66241222000122, "batch_reward": 2.2659893970489504, "actor_loss": -194.9991687593006, "actor_target_entropy": -6.0, "actor_entropy": 3.1311714914109974, "alpha_loss": -0.0023135256044389237, "alpha_value": 0.06500296019626643, "duration": 91.51713800430298, "step": 35375}
{"episode_reward": 411.3380754082918, "episode": 284.0, "Q1 loss": 5.156867748260498, "Q2 loss": 5.029260005950928, "Mean Target Q": 194.58568090820313, "Mean Q1": 194.58360900878907, "Mean Q2": 194.58552026367187, "critic_loss": 10.186127777099609, "batch_reward": 2.2621891841888426, "actor_loss": -194.98876485516948, "actor_target_entropy": -6.0, "actor_entropy": 3.0021664404099986, "alpha_loss": 0.009487621730283623, "alpha_value": 0.06493674137964338, "duration": 111.73980331420898, "step": 35500}
{"episode_reward": 454.89061296085146, "episode": 285.0, "Q1 loss": 5.38385033416748, "Q2 loss": 5.299720169067383, "Mean Target Q": 195.13969750976563, "Mean Q1": 195.13873046875, "Mean Q2": 195.13761157226563, "critic_loss": 10.683570514678955, "batch_reward": 2.2612504501342774, "actor_loss": -196.16169278583828, "actor_target_entropy": -6.0, "actor_entropy": 3.156912614428808, "alpha_loss": -0.0029207563973845, "alpha_value": 0.06488697884043229, "duration": 93.64072370529175, "step": 35625}
{"episode_reward": 389.2319527053252, "episode": 286.0, "Q1 loss": 5.79623024559021, "Q2 loss": 5.9302452907562255, "Mean Target Q": 196.00970178222656, "Mean Q1": 196.00836376953126, "Mean Q2": 196.01065844726563, "critic_loss": 11.726475524902344, "batch_reward": 2.281242033004761, "actor_loss": -196.5239060924899, "actor_target_entropy": -6.0, "actor_entropy": 3.1727801407537153, "alpha_loss": -0.001405392718997093, "alpha_value": 0.06490967707860268, "duration": 76.01339626312256, "step": 35750}
{"episode_reward": 459.1845545800331, "episode": 287.0, "Q1 loss": 5.490008621215821, "Q2 loss": 5.503329103469849, "Mean Target Q": 196.0989324951172, "Mean Q1": 196.09186791992187, "Mean Q2": 196.0915604248047, "critic_loss": 10.993337734222411, "batch_reward": 2.2828071994781496, "actor_loss": -196.58959016345796, "actor_target_entropy": -6.0, "actor_entropy": 3.1665854567573186, "alpha_loss": 0.005563198296826274, "alpha_value": 0.06485425449794659, "duration": 79.32669591903687, "step": 35875}
{"episode_reward": 402.2965106538033, "episode": 288.0, "Q1 loss": 6.186116884231567, "Q2 loss": 6.131987174987793, "Mean Target Q": 196.5715389404297, "Mean Q1": 196.572552734375, "Mean Q2": 196.5722940673828, "critic_loss": 12.318104030609131, "batch_reward": 2.2780465412139894, "actor_loss": -197.27317096341042, "actor_target_entropy": -6.0, "actor_entropy": 3.1549363636201426, "alpha_loss": -0.0031110086598463596, "alpha_value": 0.06485051784653041, "duration": 78.3691565990448, "step": 36000}
{"episode_reward": 358.1692042896189, "episode": 289.0, "Q1 loss": 6.007780086517334, "Q2 loss": 6.063630838394165, "Mean Target Q": 197.1729151611328, "Mean Q1": 197.1681309814453, "Mean Q2": 197.16777307128908, "critic_loss": 12.071410900115966, "batch_reward": 2.279428310394287, "actor_loss": -198.04923236180866, "actor_target_entropy": -6.0, "actor_entropy": 3.145846821012951, "alpha_loss": -0.009762677234700985, "alpha_value": 0.06496535912773278, "duration": 78.27093696594238, "step": 36125}
{"episode_reward": 256.15810099260875, "episode": 290.0, "Q1 loss": 5.609325662612915, "Q2 loss": 5.578254102706909, "Mean Target Q": 197.53031872558594, "Mean Q1": 197.53240881347656, "Mean Q2": 197.53242932128907, "critic_loss": 11.187579776763917, "batch_reward": 2.290674205780029, "actor_loss": -197.95909512427545, "actor_target_entropy": -6.0, "actor_entropy": 3.1824176619129796, "alpha_loss": -0.01137058139072671, "alpha_value": 0.06521383147233342, "duration": 82.29492282867432, "step": 36250}
{"episode_reward": 468.855065163993, "episode": 291.0, "Q1 loss": 6.320987457275391, "Q2 loss": 6.311194568634034, "Mean Target Q": 197.99166662597656, "Mean Q1": 197.98748657226562, "Mean Q2": 197.98556994628908, "critic_loss": 12.632182037353516, "batch_reward": 2.2928669300079347, "actor_loss": -198.57270062158977, "actor_target_entropy": -6.0, "actor_entropy": 3.0724404236627003, "alpha_loss": -0.004402275533518857, "alpha_value": 0.0653164821708353, "duration": 78.38039207458496, "step": 36375}
{"episode_reward": 458.96046197189713, "episode": 292.0, "Q1 loss": 5.8900885181427, "Q2 loss": 5.882108335494995, "Mean Target Q": 198.45175354003905, "Mean Q1": 198.44803759765625, "Mean Q2": 198.44868029785155, "critic_loss": 11.772196865081787, "batch_reward": 2.297364103317261, "actor_loss": -198.68359941051853, "actor_target_entropy": -6.0, "actor_entropy": 3.190740704536438, "alpha_loss": 0.006129809437439807, "alpha_value": 0.06527525611838636, "duration": 74.03448438644409, "step": 36500}
{"episode_reward": 352.82433927152863, "episode": 293.0, "Q1 loss": 6.0640912456512455, "Q2 loss": 6.15311054611206, "Mean Target Q": 198.97627770996093, "Mean Q1": 198.97622778320311, "Mean Q2": 198.97548864746093, "critic_loss": 12.21720177078247, "batch_reward": 2.302378231048584, "actor_loss": -199.5952400328621, "actor_target_entropy": -6.0, "actor_entropy": 3.050672561403305, "alpha_loss": -0.003420529683815345, "alpha_value": 0.06525906494220036, "duration": 76.03657293319702, "step": 36625}
{"episode_reward": 436.4258396170848, "episode": 294.0, "Q1 loss": 7.168342512130737, "Q2 loss": 6.9825303192138675, "Mean Target Q": 199.1882880859375, "Mean Q1": 199.18658581542968, "Mean Q2": 199.18432666015624, "critic_loss": 14.150872871398926, "batch_reward": 2.3061974601745607, "actor_loss": -199.4943106866652, "actor_target_entropy": -6.0, "actor_entropy": 3.1837486643945017, "alpha_loss": -0.0016082597130368794, "alpha_value": 0.06536286191991164, "duration": 101.2929584980011, "step": 36750}
{"episode_reward": 446.808516727995, "episode": 295.0, "Q1 loss": 6.57539287185669, "Q2 loss": 6.553435108184814, "Mean Target Q": 199.5521209716797, "Mean Q1": 199.54877673339843, "Mean Q2": 199.54853588867186, "critic_loss": 13.128828033447265, "batch_reward": 2.299934658050537, "actor_loss": -199.8212159171937, "actor_target_entropy": -6.0, "actor_entropy": 3.214811203971742, "alpha_loss": 0.0022916140197406687, "alpha_value": 0.06527838222913815, "duration": 101.81795477867126, "step": 36875}
{"episode_reward": 458.84589413796215, "episode": 296.0, "Q1 loss": 7.351552198410034, "Q2 loss": 7.407995277404785, "Mean Target Q": 200.24673181152343, "Mean Q1": 200.241658203125, "Mean Q2": 200.24595336914064, "critic_loss": 14.759547428131103, "batch_reward": 2.30393229675293, "actor_loss": -201.01887856760334, "actor_target_entropy": -6.0, "actor_entropy": 3.1844643239052064, "alpha_loss": -0.0012876997972207686, "alpha_value": 0.06532507635697538, "duration": 85.11549806594849, "step": 37000}
{"episode_reward": 474.6024281732864, "episode": 297.0, "Q1 loss": 7.042802812576294, "Q2 loss": 6.985888452529907, "Mean Target Q": 200.40587658691408, "Mean Q1": 200.40682153320313, "Mean Q2": 200.4050421142578, "critic_loss": 14.02869123840332, "batch_reward": 2.3105546417236327, "actor_loss": -200.99582102942088, "actor_target_entropy": -6.0, "actor_entropy": 3.1373648227207243, "alpha_loss": 0.0004991298164462759, "alpha_value": 0.06528604011070169, "duration": 94.75009489059448, "step": 37125}
{"episode_reward": 464.03697413605363, "episode": 298.0, "Q1 loss": 5.977014581680298, "Q2 loss": 6.175380390167236, "Mean Target Q": 200.76842126464842, "Mean Q1": 200.76708435058595, "Mean Q2": 200.7683826904297, "critic_loss": 12.152394924163819, "batch_reward": 2.2964739151000977, "actor_loss": -201.20123364848476, "actor_target_entropy": -6.0, "actor_entropy": 3.1373162384956115, "alpha_loss": -0.00209520393682103, "alpha_value": 0.0653428910580142, "duration": 97.65397763252258, "step": 37250}
{"episode_reward": 377.2743507612338, "episode": 299.0, "Q1 loss": 5.995229204177856, "Q2 loss": 6.052715459823609, "Mean Target Q": 202.07067907714844, "Mean Q1": 202.06776586914063, "Mean Q2": 202.06476184082032, "critic_loss": 12.04794471359253, "batch_reward": 2.3229175853729247, "actor_loss": -202.27212185329861, "actor_target_entropy": -6.0, "actor_entropy": 3.1674920377277194, "alpha_loss": -0.0043400572834625135, "alpha_value": 0.06536659352290196, "duration": 106.02288460731506, "step": 37375}
{"episode_reward": 449.58579786577116, "episode": 300.0, "Q1 loss": 6.652791252136231, "Q2 loss": 6.711144157409668, "Mean Target Q": 202.04328491210939, "Mean Q1": 202.04273474121095, "Mean Q2": 202.0404931640625, "critic_loss": 13.36393536758423, "batch_reward": 2.318020725250244, "actor_loss": -203.19067875031502, "actor_target_entropy": -6.0, "actor_entropy": 3.1261020398909047, "alpha_loss": -0.01053822074355858, "alpha_value": 0.0655354614322204, "duration": 98.37208223342896, "step": 37500}
{"episode_reward": 452.10067190382176, "episode": 301.0, "Q1 loss": 5.8670941295623775, "Q2 loss": 6.002582927703857, "Mean Target Q": 202.1601708984375, "Mean Q1": 202.15607751464844, "Mean Q2": 202.15824670410157, "critic_loss": 11.869677066802979, "batch_reward": 2.316090087890625, "actor_loss": -203.0244377983941, "actor_target_entropy": -6.0, "actor_entropy": 3.1639382990579756, "alpha_loss": -0.005863402729913119, "alpha_value": 0.06571791257291142, "duration": 108.89987778663635, "step": 37625}
{"episode_reward": 465.8450314215862, "episode": 302.0, "Q1 loss": 5.933850101470947, "Q2 loss": 5.887842872619629, "Mean Target Q": 203.38293029785157, "Mean Q1": 203.3823399658203, "Mean Q2": 203.38386645507813, "critic_loss": 11.821692985534668, "batch_reward": 2.342735523223877, "actor_loss": -203.9253163491526, "actor_target_entropy": -6.0, "actor_entropy": 3.262537875483113, "alpha_loss": -0.005984246651942451, "alpha_value": 0.06578960942209187, "duration": 94.89577126502991, "step": 37750}
{"episode_reward": 451.92381298050145, "episode": 303.0, "Q1 loss": 5.9799182472229, "Q2 loss": 6.052054466247559, "Mean Target Q": 203.69081225585938, "Mean Q1": 203.69252160644533, "Mean Q2": 203.69215002441408, "critic_loss": 12.031972785949707, "batch_reward": 2.3345937385559083, "actor_loss": -204.4611319890098, "actor_target_entropy": -6.0, "actor_entropy": 3.232594584661817, "alpha_loss": -0.006301600571041779, "alpha_value": 0.06593291658293043, "duration": 74.06376051902771, "step": 37875}
{"episode_reward": 439.3995785464855, "episode": 304.0, "Q1 loss": 5.881785097122193, "Q2 loss": 5.9298498115539555, "Mean Target Q": 203.703140625, "Mean Q1": 203.69789831542968, "Mean Q2": 203.69524755859376, "critic_loss": 11.811634910583496, "batch_reward": 2.3336635837554933, "actor_loss": -204.4768750590663, "actor_target_entropy": -6.0, "actor_entropy": 3.1831071607528196, "alpha_loss": -0.0015198900251679362, "alpha_value": 0.06598271339970986, "duration": 113.19854211807251, "step": 38000}
{"episode_reward": 407.334519227944, "episode": 305.0, "Q1 loss": 5.796707225799561, "Q2 loss": 5.776044723510743, "Mean Target Q": 204.54399719238282, "Mean Q1": 204.54321997070312, "Mean Q2": 204.54311352539062, "critic_loss": 11.572751976013183, "batch_reward": 2.346608034133911, "actor_loss": -205.04942297557042, "actor_target_entropy": -6.0, "actor_entropy": 3.1322098724425786, "alpha_loss": -0.0015653163482922884, "alpha_value": 0.06606885540018266, "duration": 142.70748233795166, "step": 38125}
{"episode_reward": 404.7837329059446, "episode": 306.0, "Q1 loss": 5.815325473785401, "Q2 loss": 5.865271530151367, "Mean Target Q": 204.97930773925782, "Mean Q1": 204.97330590820312, "Mean Q2": 204.97680529785157, "critic_loss": 11.680597011566162, "batch_reward": 2.3484526252746583, "actor_loss": -205.66197179978894, "actor_target_entropy": -6.0, "actor_entropy": 3.134410415926287, "alpha_loss": -0.008421639662100784, "alpha_value": 0.06613583961508371, "duration": 126.48440289497375, "step": 38250}
{"episode_reward": 409.0730506020665, "episode": 307.0, "Q1 loss": 6.645867273330689, "Q2 loss": 6.644640336990356, "Mean Target Q": 205.21861499023439, "Mean Q1": 205.21900244140625, "Mean Q2": 205.21625329589844, "critic_loss": 13.290507667541505, "batch_reward": 2.340309532165527, "actor_loss": -205.75000072660902, "actor_target_entropy": -6.0, "actor_entropy": 3.1150664602007185, "alpha_loss": -0.0025172586005831523, "alpha_value": 0.06630660103140114, "duration": 104.00852656364441, "step": 38375}
{"episode_reward": 361.1908531879248, "episode": 308.0, "Q1 loss": 7.627956192016602, "Q2 loss": 7.577690357208252, "Mean Target Q": 206.1608507080078, "Mean Q1": 206.16325964355468, "Mean Q2": 206.16212817382814, "critic_loss": 15.205646560668946, "batch_reward": 2.355360870361328, "actor_loss": -206.3097120715726, "actor_target_entropy": -6.0, "actor_entropy": 3.1905732885483773, "alpha_loss": 0.0014207570798574916, "alpha_value": 0.06630951386723126, "duration": 133.06001710891724, "step": 38500}
{"episode_reward": 436.7094573603406, "episode": 309.0, "Q1 loss": 8.560122493743897, "Q2 loss": 8.482772384643555, "Mean Target Q": 206.21377404785156, "Mean Q1": 206.2112979736328, "Mean Q2": 206.21190197753907, "critic_loss": 17.042894805908205, "batch_reward": 2.3477818813323976, "actor_loss": -206.61556377108136, "actor_target_entropy": -6.0, "actor_entropy": 3.1264517610035245, "alpha_loss": -0.012826889405943571, "alpha_value": 0.06641708063044112, "duration": 109.50543165206909, "step": 38625}
{"episode_reward": 434.68598635357665, "episode": 310.0, "Q1 loss": 6.659394344329834, "Q2 loss": 6.70345061302185, "Mean Target Q": 207.27871264648437, "Mean Q1": 207.27209240722655, "Mean Q2": 207.27255261230468, "critic_loss": 13.362844970703126, "batch_reward": 2.361966485977173, "actor_loss": -207.46253548899006, "actor_target_entropy": -6.0, "actor_entropy": 3.2045079661953833, "alpha_loss": -0.010676176557617803, "alpha_value": 0.06662063817754414, "duration": 94.07215285301208, "step": 38750}
{"episode_reward": 492.98069001537505, "episode": 311.0, "Q1 loss": 7.69502579498291, "Q2 loss": 7.782738506317139, "Mean Target Q": 206.96217553710937, "Mean Q1": 206.9591893310547, "Mean Q2": 206.9593555908203, "critic_loss": 15.477764289855957, "batch_reward": 2.355243995666504, "actor_loss": -207.4587605794271, "actor_target_entropy": -6.0, "actor_entropy": 3.283252367897639, "alpha_loss": -0.009244645640830555, "alpha_value": 0.066882697764472, "duration": 117.8241765499115, "step": 38875}
{"episode_reward": 491.07315920346093, "episode": 312.0, "Q1 loss": 6.923365976333618, "Q2 loss": 7.011351072311402, "Mean Target Q": 207.8685811767578, "Mean Q1": 207.86828234863282, "Mean Q2": 207.870056640625, "critic_loss": 13.934717056274414, "batch_reward": 2.365830263137817, "actor_loss": -207.9213805660125, "actor_target_entropy": -6.0, "actor_entropy": 3.331503987312317, "alpha_loss": -0.013885239443381226, "alpha_value": 0.06703597605372245, "duration": 137.62115454673767, "step": 39000}
{"episode_reward": 472.00412417266665, "episode": 313.0, "Q1 loss": 6.13410445022583, "Q2 loss": 6.106532361984253, "Mean Target Q": 207.97356958007813, "Mean Q1": 207.970177734375, "Mean Q2": 207.96689990234376, "critic_loss": 12.240636741638184, "batch_reward": 2.368073070526123, "actor_loss": -208.4718773251488, "actor_target_entropy": -6.0, "actor_entropy": 3.2795466960422575, "alpha_loss": -0.0029442349064444737, "alpha_value": 0.06726054377532707, "duration": 139.29436802864075, "step": 39125}
{"episode_reward": 450.18079129181484, "episode": 314.0, "Q1 loss": 5.643601800918579, "Q2 loss": 5.619153966903687, "Mean Target Q": 208.94637744140624, "Mean Q1": 208.94333166503907, "Mean Q2": 208.94507958984374, "critic_loss": 11.262755786895752, "batch_reward": 2.3777007884979247, "actor_loss": -209.2701881162582, "actor_target_entropy": -6.0, "actor_entropy": 3.39290387399735, "alpha_loss": -0.009258730930366343, "alpha_value": 0.06737386345820368, "duration": 135.23944640159607, "step": 39250}
{"episode_reward": 387.72850990950224, "episode": 315.0, "Q1 loss": 5.3566302299499515, "Q2 loss": 5.351045602798462, "Mean Target Q": 209.41985144042968, "Mean Q1": 209.41682983398437, "Mean Q2": 209.4146220703125, "critic_loss": 10.707675868988037, "batch_reward": 2.3777049102783203, "actor_loss": -210.24377901591953, "actor_target_entropy": -6.0, "actor_entropy": 3.2397746282910544, "alpha_loss": -0.009506938387713736, "alpha_value": 0.06757610360552882, "duration": 99.99931287765503, "step": 39375}
{"episode_reward": 460.43648760658857, "episode": 316.0, "Q1 loss": 5.486278383255005, "Q2 loss": 5.453261211395263, "Mean Target Q": 210.05654370117188, "Mean Q1": 210.0569598388672, "Mean Q2": 210.06122607421875, "critic_loss": 10.939539623260497, "batch_reward": 2.3886598072052, "actor_loss": -210.7021939677577, "actor_target_entropy": -6.0, "actor_entropy": 3.3309289793814383, "alpha_loss": -0.009860118486798339, "alpha_value": 0.06774838803110327, "duration": 89.61723613739014, "step": 39500}
{"episode_reward": 415.13533834764974, "episode": 317.0, "Q1 loss": 5.315686616897583, "Q2 loss": 5.436233186721802, "Mean Target Q": 210.56084643554686, "Mean Q1": 210.5564676513672, "Mean Q2": 210.5549102783203, "critic_loss": 10.751919883728027, "batch_reward": 2.386042890548706, "actor_loss": -211.20304119776165, "actor_target_entropy": -6.0, "actor_entropy": 3.1291593597048806, "alpha_loss": -0.004152479374574291, "alpha_value": 0.06796649948204327, "duration": 94.73642206192017, "step": 39625}
{"episode_reward": 409.1327589848816, "episode": 318.0, "Q1 loss": 5.299160068511963, "Q2 loss": 5.348017255783081, "Mean Target Q": 211.14147424316405, "Mean Q1": 211.13995727539063, "Mean Q2": 211.1403946533203, "critic_loss": 10.6471773147583, "batch_reward": 2.393946699142456, "actor_loss": -211.9428422989384, "actor_target_entropy": -6.0, "actor_entropy": 3.168125564052213, "alpha_loss": -0.00013470303102005874, "alpha_value": 0.06796486128077144, "duration": 93.56382513046265, "step": 39750}
{"episode_reward": 437.1584655523287, "episode": 319.0, "Q1 loss": 6.0324676284790035, "Q2 loss": 6.099393356323242, "Mean Target Q": 211.48092993164062, "Mean Q1": 211.48105310058594, "Mean Q2": 211.4792978515625, "critic_loss": 12.131861000061035, "batch_reward": 2.398782962799072, "actor_loss": -211.99334741017176, "actor_target_entropy": -6.0, "actor_entropy": 3.1770747918931264, "alpha_loss": 0.005562233191633981, "alpha_value": 0.06791857774694918, "duration": 89.73967790603638, "step": 39875}
{"episode_reward": 477.59521831595407, "episode": 320.0, "Q1 loss": 5.795808721542358, "Q2 loss": 5.717050384521484, "Mean Target Q": 211.66450341796875, "Mean Q1": 211.66292761230468, "Mean Q2": 211.66357263183593, "critic_loss": 11.512859046936034, "batch_reward": 2.3921954917907713, "actor_loss": -212.2787084271831, "actor_target_entropy": -6.0, "actor_entropy": 3.1775021976040256, "alpha_loss": -0.007848782652628518, "alpha_value": 0.06789371838359254, "step": 40000}
{"duration": 110.3898332118988, "step": 40000}
{"episode_reward": 447.09316984808925, "episode": 321.0, "Q1 loss": 5.771211427688598, "Q2 loss": 5.921641996383667, "Mean Target Q": 212.28209057617187, "Mean Q1": 212.2766143798828, "Mean Q2": 212.27505395507814, "critic_loss": 11.692853340148925, "batch_reward": 2.39138889503479, "actor_loss": -212.77193923223587, "actor_target_entropy": -6.0, "actor_entropy": 3.2074766915941995, "alpha_loss": 0.00034800833386797755, "alpha_value": 0.06801198997589224, "duration": 156.37511014938354, "step": 40125}
{"episode_reward": 496.61678552479333, "episode": 322.0, "Q1 loss": 5.099248743057251, "Q2 loss": 5.150561452865601, "Mean Target Q": 212.84608447265626, "Mean Q1": 212.845083984375, "Mean Q2": 212.84528479003907, "critic_loss": 10.249810173034668, "batch_reward": 2.405491142272949, "actor_loss": -213.550655980264, "actor_target_entropy": -6.0, "actor_entropy": 3.188310123259021, "alpha_loss": -0.00987085772137488, "alpha_value": 0.06810548540821541, "duration": 148.91149067878723, "step": 40250}
{"episode_reward": 459.72349618634223, "episode": 323.0, "Q1 loss": 4.922462518692017, "Q2 loss": 4.989725589752197, "Mean Target Q": 213.30401416015624, "Mean Q1": 213.30202795410156, "Mean Q2": 213.3022755126953, "critic_loss": 9.912188125610351, "batch_reward": 2.409437538146973, "actor_loss": -213.82478598942834, "actor_target_entropy": -6.0, "actor_entropy": 3.2177763212294805, "alpha_loss": -0.0007816738308599544, "alpha_value": 0.06821688148436496, "duration": 142.08961057662964, "step": 40375}
{"episode_reward": 407.02734277033034, "episode": 324.0, "Q1 loss": 5.692451091766357, "Q2 loss": 5.536871648788452, "Mean Target Q": 213.64040307617188, "Mean Q1": 213.64105700683595, "Mean Q2": 213.63953857421876, "critic_loss": 11.229322772979737, "batch_reward": 2.4121314849853515, "actor_loss": -213.9925778296686, "actor_target_entropy": -6.0, "actor_entropy": 3.22039916053895, "alpha_loss": -0.0025251486278589693, "alpha_value": 0.06827986140987267, "duration": 155.72819089889526, "step": 40500}
{"episode_reward": 475.8993663404241, "episode": 325.0, "Q1 loss": 5.454167642593384, "Q2 loss": 5.489801639556885, "Mean Target Q": 214.43641552734374, "Mean Q1": 214.43158276367188, "Mean Q2": 214.43423559570311, "critic_loss": 10.943969314575195, "batch_reward": 2.412339630126953, "actor_loss": -214.7031434074281, "actor_target_entropy": -6.0, "actor_entropy": 3.2310802179669578, "alpha_loss": -0.00020378967377519797, "alpha_value": 0.06832001052527659, "duration": 153.99545884132385, "step": 40625}
{"episode_reward": 451.25691179042514, "episode": 326.0, "Q1 loss": 5.297681470870971, "Q2 loss": 5.402096923828125, "Mean Target Q": 214.56572302246093, "Mean Q1": 214.5652384033203, "Mean Q2": 214.56530358886718, "critic_loss": 10.699778430938721, "batch_reward": 2.419298084259033, "actor_loss": -215.1689950266192, "actor_target_entropy": -6.0, "actor_entropy": 3.2159734426006192, "alpha_loss": -0.0017009688984422433, "alpha_value": 0.06832553830176384, "duration": 89.53598618507385, "step": 40750}
{"episode_reward": 246.9493095259918, "episode": 327.0, "Q1 loss": 6.30981852722168, "Q2 loss": 6.332620639801025, "Mean Target Q": 214.50364892578125, "Mean Q1": 214.50552136230468, "Mean Q2": 214.5037899169922, "critic_loss": 12.642439140319825, "batch_reward": 2.40483518409729, "actor_loss": -214.54863484700522, "actor_target_entropy": -6.0, "actor_entropy": 3.22826221632579, "alpha_loss": 0.0027167988102143954, "alpha_value": 0.0682878892948718, "duration": 86.28399777412415, "step": 40875}
{"episode_reward": 330.57583231149994, "episode": 328.0, "Q1 loss": 7.059584091186523, "Q2 loss": 7.04439497756958, "Mean Target Q": 215.20333984375, "Mean Q1": 215.19738745117186, "Mean Q2": 215.19812658691407, "critic_loss": 14.10397914505005, "batch_reward": 2.4197309513092042, "actor_loss": -215.69663952242942, "actor_target_entropy": -6.0, "actor_entropy": 3.369189993027718, "alpha_loss": -0.0008558863773941994, "alpha_value": 0.06826993484889037, "duration": 104.56286883354187, "step": 41000}
{"episode_reward": 434.12118185619806, "episode": 329.0, "Q1 loss": 6.784807325363159, "Q2 loss": 6.842980079650879, "Mean Target Q": 216.24507189941406, "Mean Q1": 216.24562072753906, "Mean Q2": 216.2449366455078, "critic_loss": 13.62778742980957, "batch_reward": 2.435821199417114, "actor_loss": -216.6491965642051, "actor_target_entropy": -6.0, "actor_entropy": 3.3271802493504117, "alpha_loss": -0.003189600198455746, "alpha_value": 0.06839749423374403, "duration": 136.57660508155823, "step": 41125}
{"episode_reward": 495.037745866381, "episode": 330.0, "Q1 loss": 6.028123399734497, "Q2 loss": 6.02107328414917, "Mean Target Q": 215.9806083984375, "Mean Q1": 215.97960192871093, "Mean Q2": 215.9783046875, "critic_loss": 12.049196632385254, "batch_reward": 2.420689514160156, "actor_loss": -216.4446763069399, "actor_target_entropy": -6.0, "actor_entropy": 3.3307518036134782, "alpha_loss": 0.007227855546760463, "alpha_value": 0.06824687783268371, "duration": 156.85058546066284, "step": 41250}
{"episode_reward": 476.35574775966535, "episode": 331.0, "Q1 loss": 7.047030353546143, "Q2 loss": 7.0173572807312015, "Mean Target Q": 216.528447265625, "Mean Q1": 216.52564575195314, "Mean Q2": 216.52624609375, "critic_loss": 14.06438762664795, "batch_reward": 2.4391563339233397, "actor_loss": -217.20612032451328, "actor_target_entropy": -6.0, "actor_entropy": 3.156085078678434, "alpha_loss": 0.00521848038105028, "alpha_value": 0.068110124669829, "duration": 143.09743404388428, "step": 41375}
{"episode_reward": 438.7415088011547, "episode": 332.0, "Q1 loss": 6.602092990875244, "Q2 loss": 6.683370908737182, "Mean Target Q": 216.93870385742187, "Mean Q1": 216.93339868164063, "Mean Q2": 216.9328957519531, "critic_loss": 13.285463844299317, "batch_reward": 2.438036518096924, "actor_loss": -217.48579480571132, "actor_target_entropy": -6.0, "actor_entropy": 3.318903996098426, "alpha_loss": -0.003222319815728453, "alpha_value": 0.06810262093860608, "duration": 131.75545954704285, "step": 41500}
{"episode_reward": 442.70264977221456, "episode": 333.0, "Q1 loss": 6.738807538986206, "Q2 loss": 6.6720889282226565, "Mean Target Q": 217.2254208984375, "Mean Q1": 217.22411437988282, "Mean Q2": 217.2271982421875, "critic_loss": 13.410896476745606, "batch_reward": 2.4412714805603026, "actor_loss": -218.18169560508122, "actor_target_entropy": -6.0, "actor_entropy": 3.262515363239107, "alpha_loss": -0.00036967658190174943, "alpha_value": 0.06815481354510945, "duration": 133.94052839279175, "step": 41625}
{"episode_reward": 429.81314973807406, "episode": 334.0, "Q1 loss": 6.201188575744629, "Q2 loss": 6.311099285125732, "Mean Target Q": 217.84488806152345, "Mean Q1": 217.84138220214842, "Mean Q2": 217.83759167480468, "critic_loss": 12.512287879943848, "batch_reward": 2.450082862854004, "actor_loss": -218.42847344183153, "actor_target_entropy": -6.0, "actor_entropy": 3.2195615922251055, "alpha_loss": -0.004034359383607103, "alpha_value": 0.06813290554700319, "duration": 141.59191918373108, "step": 41750}
{"episode_reward": 487.49775123552047, "episode": 335.0, "Q1 loss": 6.700558990478515, "Q2 loss": 6.796063787460327, "Mean Target Q": 217.9121162109375, "Mean Q1": 217.91240979003905, "Mean Q2": 217.9127442626953, "critic_loss": 13.496622745513916, "batch_reward": 2.4473972663879393, "actor_loss": -218.38647194514198, "actor_target_entropy": -6.0, "actor_entropy": 3.200765810315571, "alpha_loss": -0.008461208707312979, "alpha_value": 0.06827915282998917, "duration": 87.2127013206482, "step": 41875}
{"episode_reward": 425.38626123904413, "episode": 336.0, "Q1 loss": 6.037814781188965, "Q2 loss": 6.091987785339356, "Mean Target Q": 218.65814685058595, "Mean Q1": 218.65701306152343, "Mean Q2": 218.65731115722656, "critic_loss": 12.129802585601807, "batch_reward": 2.451516664505005, "actor_loss": -219.07753212221206, "actor_target_entropy": -6.0, "actor_entropy": 3.255871634329519, "alpha_loss": -0.008092793403193355, "alpha_value": 0.06851460552513428, "duration": 94.90287518501282, "step": 42000}
{"episode_reward": 446.01085957437937, "episode": 337.0, "Q1 loss": 6.767554260253906, "Q2 loss": 6.8559254379272465, "Mean Target Q": 218.73598205566407, "Mean Q1": 218.73207958984375, "Mean Q2": 218.73277185058595, "critic_loss": 13.623479667663574, "batch_reward": 2.4505619888305663, "actor_loss": -219.14189656575522, "actor_target_entropy": -6.0, "actor_entropy": 3.2477877442798917, "alpha_loss": -0.0008581891722444977, "alpha_value": 0.06861549895356198, "duration": 105.93637800216675, "step": 42125}
{"episode_reward": 80.53881916312919, "episode": 338.0, "Q1 loss": 6.797883092880249, "Q2 loss": 7.0273794784545895, "Mean Target Q": 218.45136291503906, "Mean Q1": 218.45228002929687, "Mean Q2": 218.45145349121094, "critic_loss": 13.825262634277344, "batch_reward": 2.4400852336883543, "actor_loss": -219.2224822505828, "actor_target_entropy": -6.0, "actor_entropy": 3.339411093342689, "alpha_loss": -0.004741398762205556, "alpha_value": 0.06873052498096859, "duration": 134.74418377876282, "step": 42250}
{"episode_reward": 410.9993948397291, "episode": 339.0, "Q1 loss": 7.188148902893066, "Q2 loss": 7.23819686126709, "Mean Target Q": 219.28221228027343, "Mean Q1": 219.2772274169922, "Mean Q2": 219.27850073242186, "critic_loss": 14.426345817565918, "batch_reward": 2.4499593391418455, "actor_loss": -219.51824466765873, "actor_target_entropy": -6.0, "actor_entropy": 3.110283809994894, "alpha_loss": 0.001371040992024872, "alpha_value": 0.0686884335760962, "duration": 139.16178131103516, "step": 42375}
{"episode_reward": 489.563590463549, "episode": 340.0, "Q1 loss": 6.366931591033936, "Q2 loss": 6.394882467269897, "Mean Target Q": 219.49595959472657, "Mean Q1": 219.49656799316406, "Mean Q2": 219.49372277832032, "critic_loss": 12.761814090728759, "batch_reward": 2.45852360534668, "actor_loss": -219.86248607020224, "actor_target_entropy": -6.0, "actor_entropy": 3.2001585075932164, "alpha_loss": -0.0030418910638188882, "alpha_value": 0.06871500204461471, "duration": 115.67895460128784, "step": 42500}
{"episode_reward": 486.521153381862, "episode": 341.0, "Q1 loss": 7.5603728828430175, "Q2 loss": 7.626163898468017, "Mean Target Q": 219.65255749511718, "Mean Q1": 219.64924572753907, "Mean Q2": 219.65102294921874, "critic_loss": 15.18653677368164, "batch_reward": 2.445828899383545, "actor_loss": -220.32489304315476, "actor_target_entropy": -6.0, "actor_entropy": 3.196009533745902, "alpha_loss": -0.0028023834724629684, "alpha_value": 0.06880334135199206, "duration": 123.0248601436615, "step": 42625}
{"episode_reward": 460.9690588387711, "episode": 342.0, "Q1 loss": 6.980803060531616, "Q2 loss": 6.956298950195312, "Mean Target Q": 220.4453233642578, "Mean Q1": 220.44538781738282, "Mean Q2": 220.4421484375, "critic_loss": 13.937101997375489, "batch_reward": 2.454529098510742, "actor_loss": -220.9259975802514, "actor_target_entropy": -6.0, "actor_entropy": 3.2553311086470083, "alpha_loss": -0.01612477884778092, "alpha_value": 0.06903672387762717, "duration": 90.61764669418335, "step": 42750}
{"episode_reward": 397.4173633674998, "episode": 343.0, "Q1 loss": 6.5665346622467045, "Q2 loss": 6.450367862701416, "Mean Target Q": 220.7285185546875, "Mean Q1": 220.72481274414062, "Mean Q2": 220.72495031738282, "critic_loss": 13.016902503967286, "batch_reward": 2.4595534992218018, "actor_loss": -221.04612150646392, "actor_target_entropy": -6.0, "actor_entropy": 3.2732013937026734, "alpha_loss": 0.006115973738598682, "alpha_value": 0.06914938032504633, "duration": 69.66089797019958, "step": 42875}
{"episode_reward": 467.9669935471698, "episode": 344.0, "Q1 loss": 6.644439952850342, "Q2 loss": 6.5643017253875735, "Mean Target Q": 221.0759519042969, "Mean Q1": 221.07105859375, "Mean Q2": 221.07315795898438, "critic_loss": 13.208741668701173, "batch_reward": 2.4635739765167237, "actor_loss": -221.86065772271925, "actor_target_entropy": -6.0, "actor_entropy": 3.212499495475523, "alpha_loss": 0.004634377811359422, "alpha_value": 0.0690167806136243, "duration": 70.75040674209595, "step": 43000}
{"episode_reward": 443.3417526884304, "episode": 345.0, "Q1 loss": 6.592701961517334, "Q2 loss": 6.585155952453613, "Mean Target Q": 221.84980517578126, "Mean Q1": 221.85083435058593, "Mean Q2": 221.85058483886718, "critic_loss": 13.17785789489746, "batch_reward": 2.473107614517212, "actor_loss": -222.10118417891246, "actor_target_entropy": -6.0, "actor_entropy": 3.3185027970208063, "alpha_loss": -0.0009729048451556573, "alpha_value": 0.06900865050822605, "duration": 69.2652359008789, "step": 43125}
{"episode_reward": 492.8279813595578, "episode": 346.0, "Q1 loss": 6.693081979751587, "Q2 loss": 6.782901433944702, "Mean Target Q": 222.24958544921876, "Mean Q1": 222.24585095214843, "Mean Q2": 222.2454111328125, "critic_loss": 13.4759833984375, "batch_reward": 2.4663318271636965, "actor_loss": -222.8368675478043, "actor_target_entropy": -6.0, "actor_entropy": 3.2107869963492117, "alpha_loss": -0.00548441877828971, "alpha_value": 0.06907039007105703, "duration": 106.9410891532898, "step": 43250}
{"episode_reward": 466.8566318232179, "episode": 347.0, "Q1 loss": 6.99358462524414, "Q2 loss": 7.067611854553222, "Mean Target Q": 222.56359216308593, "Mean Q1": 222.5650322265625, "Mean Q2": 222.565900390625, "critic_loss": 14.061196445465088, "batch_reward": 2.485234140396118, "actor_loss": -222.8769041999938, "actor_target_entropy": -6.0, "actor_entropy": 3.1588505866035583, "alpha_loss": -0.015192606689644948, "alpha_value": 0.06928688110515475, "duration": 134.79990601539612, "step": 43375}
{"episode_reward": 327.10605008323756, "episode": 348.0, "Q1 loss": 6.643098192214966, "Q2 loss": 6.668233724594116, "Mean Target Q": 222.67334057617188, "Mean Q1": 222.6718779296875, "Mean Q2": 222.6738415527344, "critic_loss": 13.311331897735595, "batch_reward": 2.4800863571166993, "actor_loss": -223.41796038227696, "actor_target_entropy": -6.0, "actor_entropy": 3.195301559663588, "alpha_loss": -0.0003055170095796066, "alpha_value": 0.06947148426239755, "duration": 104.90576696395874, "step": 43500}
{"episode_reward": 488.96262126475244, "episode": 349.0, "Q1 loss": 7.801376909255981, "Q2 loss": 7.87187876701355, "Mean Target Q": 223.0923487548828, "Mean Q1": 223.08995825195314, "Mean Q2": 223.0895280761719, "critic_loss": 15.673255722045898, "batch_reward": 2.4857652492523195, "actor_loss": -223.9129905095176, "actor_target_entropy": -6.0, "actor_entropy": 3.168837687325856, "alpha_loss": 0.0014978115084684556, "alpha_value": 0.06948668146385441, "duration": 83.29651618003845, "step": 43625}
{"episode_reward": 468.71382669408615, "episode": 350.0, "Q1 loss": 7.895767059326172, "Q2 loss": 7.822118907928467, "Mean Target Q": 223.96597338867187, "Mean Q1": 223.96196752929689, "Mean Q2": 223.96030822753906, "critic_loss": 15.717885971069336, "batch_reward": 2.4939508476257326, "actor_loss": -224.406735327936, "actor_target_entropy": -6.0, "actor_entropy": 3.281515944388605, "alpha_loss": -0.0030542570391609786, "alpha_value": 0.06947602472546502, "duration": 82.15132808685303, "step": 43750}
{"episode_reward": 420.67763400858473, "episode": 351.0, "Q1 loss": 6.93374645614624, "Q2 loss": 7.016396377563477, "Mean Target Q": 224.54527172851562, "Mean Q1": 224.5450655517578, "Mean Q2": 224.5464207763672, "critic_loss": 13.95014278793335, "batch_reward": 2.496956953048706, "actor_loss": -224.8437737358941, "actor_target_entropy": -6.0, "actor_entropy": 3.33660114000714, "alpha_loss": -0.00928970072085836, "alpha_value": 0.06962010570767761, "duration": 91.95947980880737, "step": 43875}
{"episode_reward": 466.7747380149856, "episode": 352.0, "Q1 loss": 8.179164688110351, "Q2 loss": 8.151054355621337, "Mean Target Q": 224.5099168701172, "Mean Q1": 224.50961499023438, "Mean Q2": 224.50855212402342, "critic_loss": 16.330219039916994, "batch_reward": 2.496930700302124, "actor_loss": -224.9187270133726, "actor_target_entropy": -6.0, "actor_entropy": 3.32961905002594, "alpha_loss": -0.0003322091914953724, "alpha_value": 0.06970446042502744, "duration": 128.30935096740723, "step": 44000}
{"episode_reward": 473.71488195903305, "episode": 353.0, "Q1 loss": 7.6109786796569825, "Q2 loss": 7.617862529754639, "Mean Target Q": 224.515357421875, "Mean Q1": 224.51281848144532, "Mean Q2": 224.5112890625, "critic_loss": 15.228841232299805, "batch_reward": 2.4814138126373293, "actor_loss": -224.87586611793154, "actor_target_entropy": -6.0, "actor_entropy": 3.3006331088050964, "alpha_loss": 0.0023346636518244705, "alpha_value": 0.06968348637967245, "duration": 100.11978197097778, "step": 44125}
{"episode_reward": 483.8493592924422, "episode": 354.0, "Q1 loss": 6.93994845199585, "Q2 loss": 6.865676080703735, "Mean Target Q": 225.02258544921875, "Mean Q1": 225.01471166992187, "Mean Q2": 225.01634411621095, "critic_loss": 13.805624504089355, "batch_reward": 2.5042876567840575, "actor_loss": -224.9046146023658, "actor_target_entropy": -6.0, "actor_entropy": 3.2454822024991437, "alpha_loss": -0.004008928768246645, "alpha_value": 0.06973638711178494, "duration": 74.69094443321228, "step": 44250}
{"episode_reward": 254.8332669044568, "episode": 355.0, "Q1 loss": 7.395206453323365, "Q2 loss": 7.438314186096191, "Mean Target Q": 225.22774780273437, "Mean Q1": 225.23218176269532, "Mean Q2": 225.23205017089845, "critic_loss": 14.83352066040039, "batch_reward": 2.4936734771728517, "actor_loss": -226.15244523305742, "actor_target_entropy": -6.0, "actor_entropy": 3.339594761530558, "alpha_loss": 0.000739506431042202, "alpha_value": 0.06980949025166037, "duration": 70.99414610862732, "step": 44375}
{"episode_reward": 127.1784485867889, "episode": 356.0, "Q1 loss": 7.983958450317383, "Q2 loss": 8.084971256256104, "Mean Target Q": 225.58997766113282, "Mean Q1": 225.5866912841797, "Mean Q2": 225.586060546875, "critic_loss": 16.0689296836853, "batch_reward": 2.4943005237579348, "actor_loss": -226.24031411447834, "actor_target_entropy": -6.0, "actor_entropy": 3.257505243824374, "alpha_loss": -0.01216820896332783, "alpha_value": 0.06990510930299389, "duration": 70.16666269302368, "step": 44500}
{"episode_reward": 525.7763400935091, "episode": 357.0, "Q1 loss": 7.1295572681427, "Q2 loss": 7.312943948745728, "Mean Target Q": 226.03319104003907, "Mean Q1": 226.02377856445312, "Mean Q2": 226.0251573486328, "critic_loss": 14.442501152038574, "batch_reward": 2.4973665599822996, "actor_loss": -226.20739116365948, "actor_target_entropy": -6.0, "actor_entropy": 3.276908371183607, "alpha_loss": -0.008348398708871432, "alpha_value": 0.0701433091584561, "duration": 78.61261343955994, "step": 44625}
{"episode_reward": 478.6630440427551, "episode": 358.0, "Q1 loss": 7.562332452774048, "Q2 loss": 7.438703615188599, "Mean Target Q": 226.6283464355469, "Mean Q1": 226.63030151367187, "Mean Q2": 226.62893359375, "critic_loss": 15.001036113739014, "batch_reward": 2.5050428829193114, "actor_loss": -227.33750669417842, "actor_target_entropy": -6.0, "actor_entropy": 3.293148740645378, "alpha_loss": -0.001855558708250042, "alpha_value": 0.07021400574887367, "duration": 79.98819708824158, "step": 44750}
{"episode_reward": 433.3742485349708, "episode": 359.0, "Q1 loss": 8.763636631011963, "Q2 loss": 8.774307189941407, "Mean Target Q": 226.87430517578125, "Mean Q1": 226.87471447753907, "Mean Q2": 226.87405969238282, "critic_loss": 17.537943878173827, "batch_reward": 2.5057565727233886, "actor_loss": -227.48898024786087, "actor_target_entropy": -6.0, "actor_entropy": 3.270579292660668, "alpha_loss": -0.00645096593033818, "alpha_value": 0.0703070753907273, "duration": 85.3913996219635, "step": 44875}
{"episode_reward": 416.92349786218756, "episode": 360.0, "Q1 loss": 9.988593078613281, "Q2 loss": 10.085833824157715, "Mean Target Q": 227.24928735351563, "Mean Q1": 227.24533935546876, "Mean Q2": 227.24471557617187, "critic_loss": 20.074426979064942, "batch_reward": 2.513383930206299, "actor_loss": -227.66773445375503, "actor_target_entropy": -6.0, "actor_entropy": 3.3680730212119316, "alpha_loss": -0.010131334228771589, "alpha_value": 0.07050174278332474, "step": 45000}
{"duration": 95.06438302993774, "step": 45000}
{"episode_reward": 390.1489739954118, "episode": 361.0, "Q1 loss": 9.60340954208374, "Q2 loss": 9.55264747619629, "Mean Target Q": 227.560146484375, "Mean Q1": 227.55654052734374, "Mean Q2": 227.5596680908203, "critic_loss": 19.15605697631836, "batch_reward": 2.511463731765747, "actor_loss": -228.0724061027406, "actor_target_entropy": -6.0, "actor_entropy": 3.262915229040479, "alpha_loss": -0.006026030226152331, "alpha_value": 0.07060232410765481, "duration": 74.83237648010254, "step": 45125}
{"episode_reward": 531.6128643481474, "episode": 362.0, "Q1 loss": 7.911998336791992, "Q2 loss": 7.936538036346436, "Mean Target Q": 228.09491564941408, "Mean Q1": 228.09581494140625, "Mean Q2": 228.09531616210938, "critic_loss": 15.848536392211914, "batch_reward": 2.5183054485321046, "actor_loss": -228.8317169681672, "actor_target_entropy": -6.0, "actor_entropy": 3.2568739191178353, "alpha_loss": -0.011666625779452584, "alpha_value": 0.07089332549735398, "duration": 75.8763599395752, "step": 45250}
{"episode_reward": 444.9476735996971, "episode": 363.0, "Q1 loss": 8.36114245223999, "Q2 loss": 8.41342455291748, "Mean Target Q": 227.98437548828124, "Mean Q1": 227.97868884277344, "Mean Q2": 227.97843017578126, "critic_loss": 16.774566925048827, "batch_reward": 2.507449035644531, "actor_loss": -228.7994886125837, "actor_target_entropy": -6.0, "actor_entropy": 3.324501915583535, "alpha_loss": 0.0019299934159905192, "alpha_value": 0.07105332688023139, "duration": 92.97536277770996, "step": 45375}
{"episode_reward": 485.16477499553815, "episode": 364.0, "Q1 loss": 7.195152851104736, "Q2 loss": 7.34358489227295, "Mean Target Q": 228.9798820800781, "Mean Q1": 228.97760363769532, "Mean Q2": 228.97780102539062, "critic_loss": 14.538737758636474, "batch_reward": 2.517459337234497, "actor_loss": -229.25519561767578, "actor_target_entropy": -6.0, "actor_entropy": 3.3653646399897914, "alpha_loss": -0.007652251864783466, "alpha_value": 0.07106994647574034, "duration": 95.79881358146667, "step": 45500}
{"episode_reward": 429.99958414618453, "episode": 365.0, "Q1 loss": 7.466351026535034, "Q2 loss": 7.293312578201294, "Mean Target Q": 229.28318920898437, "Mean Q1": 229.28605480957032, "Mean Q2": 229.28340075683593, "critic_loss": 14.759663597106934, "batch_reward": 2.53502223777771, "actor_loss": -229.50133671836247, "actor_target_entropy": -6.0, "actor_entropy": 3.294128830470736, "alpha_loss": -0.004477979327064185, "alpha_value": 0.07120867927497274, "duration": 116.41682052612305, "step": 45625}
{"episode_reward": 467.8266015999749, "episode": 366.0, "Q1 loss": 8.545608600616456, "Q2 loss": 8.754585926055908, "Mean Target Q": 229.49402709960938, "Mean Q1": 229.49322314453124, "Mean Q2": 229.49531030273437, "critic_loss": 17.300194480895996, "batch_reward": 2.530284200668335, "actor_loss": -230.30260418307395, "actor_target_entropy": -6.0, "actor_entropy": 3.3656903928326023, "alpha_loss": -0.0005135617684572935, "alpha_value": 0.07124770215341206, "duration": 129.85779690742493, "step": 45750}
{"episode_reward": 397.93399536057376, "episode": 367.0, "Q1 loss": 8.092752960205079, "Q2 loss": 8.146816471099854, "Mean Target Q": 229.50144799804687, "Mean Q1": 229.49564892578124, "Mean Q2": 229.49412145996095, "critic_loss": 16.23956955718994, "batch_reward": 2.5276151390075685, "actor_loss": -229.93061852833583, "actor_target_entropy": -6.0, "actor_entropy": 3.4221293055821977, "alpha_loss": -0.014636083269521358, "alpha_value": 0.07147038614110293, "duration": 98.20697236061096, "step": 45875}
{"episode_reward": 407.64267771763446, "episode": 368.0, "Q1 loss": 8.038848747253418, "Q2 loss": 8.294020626068114, "Mean Target Q": 229.95759802246093, "Mean Q1": 229.95685437011718, "Mean Q2": 229.95441833496093, "critic_loss": 16.332869403839112, "batch_reward": 2.5384420032501223, "actor_loss": -230.5329840875441, "actor_target_entropy": -6.0, "actor_entropy": 3.231605972013166, "alpha_loss": 0.0012277276386627027, "alpha_value": 0.0715689386737123, "duration": 93.42456793785095, "step": 46000}
{"episode_reward": 457.6938445094871, "episode": 369.0, "Q1 loss": 7.803337963104248, "Q2 loss": 7.909538753509522, "Mean Target Q": 230.38720727539064, "Mean Q1": 230.3873359375, "Mean Q2": 230.38767895507812, "critic_loss": 15.712876640319823, "batch_reward": 2.5276547508239746, "actor_loss": -230.59108407156808, "actor_target_entropy": -6.0, "actor_entropy": 3.285634203562661, "alpha_loss": -0.006176149897602579, "alpha_value": 0.07164156040594205, "duration": 89.76315450668335, "step": 46125}
{"episode_reward": 428.36810148898894, "episode": 370.0, "Q1 loss": 8.055030630111695, "Q2 loss": 8.077759490966796, "Mean Target Q": 230.95711938476563, "Mean Q1": 230.9498399658203, "Mean Q2": 230.95251501464844, "critic_loss": 16.132790153503418, "batch_reward": 2.531030515670776, "actor_loss": -231.44627847979146, "actor_target_entropy": -6.0, "actor_entropy": 3.3423176734678206, "alpha_loss": -0.0068283265028449315, "alpha_value": 0.07174750478794972, "duration": 85.6183454990387, "step": 46250}
{"episode_reward": 486.84540033969853, "episode": 371.0, "Q1 loss": 9.5168763961792, "Q2 loss": 9.39320553970337, "Mean Target Q": 231.66209167480469, "Mean Q1": 231.66862829589843, "Mean Q2": 231.66531286621094, "critic_loss": 18.910082000732423, "batch_reward": 2.543320062637329, "actor_loss": -232.16542150103857, "actor_target_entropy": -6.0, "actor_entropy": 3.337048814410255, "alpha_loss": -0.009931244388488787, "alpha_value": 0.0719753937977117, "duration": 92.82590341567993, "step": 46375}
{"episode_reward": 438.7892806317407, "episode": 372.0, "Q1 loss": 7.362490905761719, "Q2 loss": 7.285739171981811, "Mean Target Q": 231.87366259765625, "Mean Q1": 231.86460083007813, "Mean Q2": 231.86551708984376, "critic_loss": 14.64823012161255, "batch_reward": 2.5439437046051023, "actor_loss": -231.93794816540134, "actor_target_entropy": -6.0, "actor_entropy": 3.4085616988520466, "alpha_loss": -0.003992661852539788, "alpha_value": 0.07211483090890025, "duration": 108.44914245605469, "step": 46500}
{"episode_reward": 480.5361951053349, "episode": 373.0, "Q1 loss": 7.767345516204834, "Q2 loss": 7.790202415466308, "Mean Target Q": 232.07004260253908, "Mean Q1": 232.0697794189453, "Mean Q2": 232.0703681640625, "critic_loss": 15.55754783630371, "batch_reward": 2.537921977996826, "actor_loss": -232.1024203830295, "actor_target_entropy": -6.0, "actor_entropy": 3.305195445106143, "alpha_loss": -0.002676288187060328, "alpha_value": 0.0722238115292114, "duration": 115.26683712005615, "step": 46625}
{"episode_reward": 243.36891578369423, "episode": 374.0, "Q1 loss": 7.583779224395752, "Q2 loss": 7.661565784454345, "Mean Target Q": 232.23342163085937, "Mean Q1": 232.22876342773438, "Mean Q2": 232.228138671875, "critic_loss": 15.245345024108886, "batch_reward": 2.542387783050537, "actor_loss": -232.43179345900012, "actor_target_entropy": -6.0, "actor_entropy": 3.369730914792707, "alpha_loss": -0.0024775349076897385, "alpha_value": 0.07228106156342592, "duration": 98.35877895355225, "step": 46750}
{"episode_reward": 511.52416050904964, "episode": 375.0, "Q1 loss": 7.756863735198975, "Q2 loss": 7.61982741355896, "Mean Target Q": 233.13525317382812, "Mean Q1": 233.13425549316406, "Mean Q2": 233.13649206542968, "critic_loss": 15.376691200256348, "batch_reward": 2.5526992778778075, "actor_loss": -233.70946732778398, "actor_target_entropy": -6.0, "actor_entropy": 3.3686722611624096, "alpha_loss": -0.011205342561302204, "alpha_value": 0.0724759616397434, "duration": 89.53270196914673, "step": 46875}
{"episode_reward": 524.5614278192633, "episode": 376.0, "Q1 loss": 7.333078569412232, "Q2 loss": 7.274508487701416, "Mean Target Q": 233.31800549316407, "Mean Q1": 233.31409606933593, "Mean Q2": 233.31312976074219, "critic_loss": 14.607587036132813, "batch_reward": 2.5554056816101074, "actor_loss": -233.78479668401903, "actor_target_entropy": -6.0, "actor_entropy": 3.2765725428058254, "alpha_loss": 0.001981213305806441, "alpha_value": 0.07252909254542982, "duration": 134.66283249855042, "step": 47000}
{"episode_reward": 333.00114934530654, "episode": 377.0, "Q1 loss": 8.703679836273194, "Q2 loss": 8.425993991851806, "Mean Target Q": 233.082796875, "Mean Q1": 233.0868739013672, "Mean Q2": 233.08661071777342, "critic_loss": 17.129673881530763, "batch_reward": 2.5502731437683104, "actor_loss": -232.99449254596044, "actor_target_entropy": -6.0, "actor_entropy": 3.355508490214272, "alpha_loss": -0.0079466862537499, "alpha_value": 0.07254802975400869, "duration": 119.19243693351746, "step": 47125}
{"episode_reward": 474.8762779762321, "episode": 378.0, "Q1 loss": 7.887458679199219, "Q2 loss": 7.9472636756896975, "Mean Target Q": 233.91667504882813, "Mean Q1": 233.9104744873047, "Mean Q2": 233.91042529296874, "critic_loss": 15.834722389221191, "batch_reward": 2.5532581024169922, "actor_loss": -234.307011019799, "actor_target_entropy": -6.0, "actor_entropy": 3.3480130472490863, "alpha_loss": -0.005361147562883074, "alpha_value": 0.0728326065620832, "duration": 100.59663414955139, "step": 47250}
{"episode_reward": 449.79440758321397, "episode": 379.0, "Q1 loss": 8.896280582427979, "Q2 loss": 8.72263049697876, "Mean Target Q": 234.36278442382812, "Mean Q1": 234.36338732910156, "Mean Q2": 234.362466796875, "critic_loss": 17.61891107940674, "batch_reward": 2.563925537109375, "actor_loss": -234.75196789938306, "actor_target_entropy": -6.0, "actor_entropy": 3.2569240729014077, "alpha_loss": 0.0015937774608443891, "alpha_value": 0.07278863677713265, "duration": 141.15729594230652, "step": 47375}
{"episode_reward": 505.88285324250296, "episode": 380.0, "Q1 loss": 8.419805130004884, "Q2 loss": 8.349131378173828, "Mean Target Q": 234.3362108154297, "Mean Q1": 234.33952783203125, "Mean Q2": 234.3392235107422, "critic_loss": 16.768936424255372, "batch_reward": 2.559218194961548, "actor_loss": -234.905028312437, "actor_target_entropy": -6.0, "actor_entropy": 3.336128680936752, "alpha_loss": -0.008662947652591091, "alpha_value": 0.07287607371408632, "duration": 126.37152147293091, "step": 47500}
{"episode_reward": 553.61941557317, "episode": 381.0, "Q1 loss": 8.153197534561157, "Q2 loss": 8.28705460357666, "Mean Target Q": 234.69764477539061, "Mean Q1": 234.69063745117188, "Mean Q2": 234.68969799804688, "critic_loss": 16.440252143859862, "batch_reward": 2.5636942558288576, "actor_loss": -234.9292200482081, "actor_target_entropy": -6.0, "actor_entropy": 3.293604513955495, "alpha_loss": -0.004008468665507814, "alpha_value": 0.07306401533087108, "duration": 140.00913405418396, "step": 47625}
{"episode_reward": 465.0750094893982, "episode": 382.0, "Q1 loss": 8.244411594390868, "Q2 loss": 8.273671876907349, "Mean Target Q": 235.39884350585936, "Mean Q1": 235.40299182128905, "Mean Q2": 235.4019033203125, "critic_loss": 16.518083473205568, "batch_reward": 2.572964147567749, "actor_loss": -235.8139680431735, "actor_target_entropy": -6.0, "actor_entropy": 3.334403864799007, "alpha_loss": -0.002312380475022139, "alpha_value": 0.07316751585875239, "duration": 128.76007914543152, "step": 47750}
{"episode_reward": 476.1183302766023, "episode": 383.0, "Q1 loss": 8.341894439697265, "Q2 loss": 8.405942012786864, "Mean Target Q": 236.33427880859375, "Mean Q1": 236.32582336425781, "Mean Q2": 236.32755578613282, "critic_loss": 16.747836448669435, "batch_reward": 2.5867601070404054, "actor_loss": -236.88504318963913, "actor_target_entropy": -6.0, "actor_entropy": 3.195819536844889, "alpha_loss": -0.004493474932609215, "alpha_value": 0.07317469151425132, "duration": 111.22346782684326, "step": 47875}
{"episode_reward": 452.5377891001903, "episode": 384.0, "Q1 loss": 8.0565104637146, "Q2 loss": 7.950762351989746, "Mean Target Q": 235.9619903564453, "Mean Q1": 235.96066467285155, "Mean Q2": 235.96115673828126, "critic_loss": 16.007272789001465, "batch_reward": 2.584820478439331, "actor_loss": -236.60711792976625, "actor_target_entropy": -6.0, "actor_entropy": 3.3307848668867543, "alpha_loss": 0.0037481520332456114, "alpha_value": 0.07315577155291761, "duration": 94.85310626029968, "step": 48000}
{"episode_reward": 455.7285084770744, "episode": 385.0, "Q1 loss": 8.985825790405274, "Q2 loss": 9.133135829925537, "Mean Target Q": 236.24258715820312, "Mean Q1": 236.23830834960938, "Mean Q2": 236.2383934326172, "critic_loss": 18.118961654663085, "batch_reward": 2.580478189468384, "actor_loss": -236.75214204334077, "actor_target_entropy": -6.0, "actor_entropy": 3.2153346879141673, "alpha_loss": -0.0067917831456436525, "alpha_value": 0.0731617835240171, "duration": 118.59766602516174, "step": 48125}
{"episode_reward": 519.6308606660526, "episode": 386.0, "Q1 loss": 7.634906677246094, "Q2 loss": 7.515224639892578, "Mean Target Q": 236.6189755859375, "Mean Q1": 236.61833959960939, "Mean Q2": 236.6157196044922, "critic_loss": 15.150131240844727, "batch_reward": 2.5918821659088134, "actor_loss": -237.36025902532762, "actor_target_entropy": -6.0, "actor_entropy": 3.3135226003585325, "alpha_loss": -0.009440603252920893, "alpha_value": 0.0733977807684704, "duration": 123.98850321769714, "step": 48250}
{"episode_reward": 472.9992411200125, "episode": 387.0, "Q1 loss": 7.790341560363769, "Q2 loss": 7.768278156280518, "Mean Target Q": 237.08163842773436, "Mean Q1": 237.0861864013672, "Mean Q2": 237.08509045410156, "critic_loss": 15.558619682312012, "batch_reward": 2.5902553234100343, "actor_loss": -237.8684786841983, "actor_target_entropy": -6.0, "actor_entropy": 3.2896971702575684, "alpha_loss": -0.0008195647193739811, "alpha_value": 0.07350437851038666, "duration": 131.53518223762512, "step": 48375}
{"episode_reward": 441.4143967813235, "episode": 388.0, "Q1 loss": 8.767051612854004, "Q2 loss": 9.02526016998291, "Mean Target Q": 237.59341015625, "Mean Q1": 237.5871241455078, "Mean Q2": 237.58932934570313, "critic_loss": 17.792311866760254, "batch_reward": 2.595286672592163, "actor_loss": -238.2735834429341, "actor_target_entropy": -6.0, "actor_entropy": 3.3451157500666957, "alpha_loss": -0.0025821227276126946, "alpha_value": 0.07355126544948348, "duration": 128.4037971496582, "step": 48500}
{"episode_reward": 397.00836926421124, "episode": 389.0, "Q1 loss": 11.567660133361816, "Q2 loss": 11.320787662506104, "Mean Target Q": 237.50955017089845, "Mean Q1": 237.50512915039062, "Mean Q2": 237.5045535888672, "critic_loss": 22.88844775390625, "batch_reward": 2.5875636196136473, "actor_loss": -237.64673868815103, "actor_target_entropy": -6.0, "actor_entropy": 3.294576607053242, "alpha_loss": -0.012930228870125517, "alpha_value": 0.0737072017346155, "duration": 115.37291407585144, "step": 48625}
{"episode_reward": 449.65657331527456, "episode": 390.0, "Q1 loss": 7.780675140380859, "Q2 loss": 7.800060989379883, "Mean Target Q": 237.8474326171875, "Mean Q1": 237.84391748046875, "Mean Q2": 237.8433839111328, "critic_loss": 15.58073611831665, "batch_reward": 2.5870361919403075, "actor_loss": -238.38520985264933, "actor_target_entropy": -6.0, "actor_entropy": 3.3299062482772337, "alpha_loss": -0.006165315870255712, "alpha_value": 0.07396789707475057, "duration": 65.37166428565979, "step": 48750}
{"episode_reward": 467.84226564786246, "episode": 391.0, "Q1 loss": 8.270559413909911, "Q2 loss": 8.472458766937256, "Mean Target Q": 237.9950322265625, "Mean Q1": 237.99905419921876, "Mean Q2": 237.99655017089844, "critic_loss": 16.743018310546876, "batch_reward": 2.590913785934448, "actor_loss": -238.78642006525916, "actor_target_entropy": -6.0, "actor_entropy": 3.198185988834926, "alpha_loss": 0.0002897508139352477, "alpha_value": 0.07400985789447691, "duration": 73.50114488601685, "step": 48875}
{"episode_reward": 503.0143181308546, "episode": 392.0, "Q1 loss": 8.718404251098633, "Q2 loss": 8.488853298187255, "Mean Target Q": 238.72014904785155, "Mean Q1": 238.71257397460937, "Mean Q2": 238.71418774414062, "critic_loss": 17.207257469177247, "batch_reward": 2.5979301204681398, "actor_loss": -239.19141757103705, "actor_target_entropy": -6.0, "actor_entropy": 3.382890820503235, "alpha_loss": -0.002353327153551002, "alpha_value": 0.07405211142366686, "duration": 123.86443543434143, "step": 49000}
{"episode_reward": 455.29774650837146, "episode": 393.0, "Q1 loss": 8.146867897033692, "Q2 loss": 8.111991680145264, "Mean Target Q": 239.20395690917968, "Mean Q1": 239.20470874023437, "Mean Q2": 239.20359252929688, "critic_loss": 16.25885961151123, "batch_reward": 2.606688024520874, "actor_loss": -239.78060719323537, "actor_target_entropy": -6.0, "actor_entropy": 3.2835210959116616, "alpha_loss": -0.007973192211624885, "alpha_value": 0.07416355773088469, "duration": 104.15448141098022, "step": 49125}
{"episode_reward": 489.7869044284848, "episode": 394.0, "Q1 loss": 7.86761294555664, "Q2 loss": 7.954095481872558, "Mean Target Q": 239.1049298095703, "Mean Q1": 239.10256201171876, "Mean Q2": 239.10046020507812, "critic_loss": 15.82170835876465, "batch_reward": 2.607065160751343, "actor_loss": -239.16188344647807, "actor_target_entropy": -6.0, "actor_entropy": 3.3040042461887484, "alpha_loss": -0.006822088117440862, "alpha_value": 0.07438304917628333, "duration": 79.49097275733948, "step": 49250}
{"episode_reward": 572.6604333973936, "episode": 395.0, "Q1 loss": 7.953965881347656, "Q2 loss": 7.852406314849853, "Mean Target Q": 239.7351951904297, "Mean Q1": 239.7297596435547, "Mean Q2": 239.730607421875, "critic_loss": 15.806372253417969, "batch_reward": 2.607545530319214, "actor_loss": -240.10032266283793, "actor_target_entropy": -6.0, "actor_entropy": 3.3906639417012534, "alpha_loss": -0.004196663749300771, "alpha_value": 0.07444062104022457, "duration": 82.75018310546875, "step": 49375}
{"episode_reward": 451.6140773434127, "episode": 396.0, "Q1 loss": 8.586064990997315, "Q2 loss": 8.632095722198486, "Mean Target Q": 240.28006237792968, "Mean Q1": 240.28025256347655, "Mean Q2": 240.2793173828125, "critic_loss": 17.21816078186035, "batch_reward": 2.612898633956909, "actor_loss": -241.20425464260964, "actor_target_entropy": -6.0, "actor_entropy": 3.2982424997514292, "alpha_loss": -0.008980868219007407, "alpha_value": 0.07465113579600721, "duration": 113.6769871711731, "step": 49500}
{"episode_reward": 477.0159118467754, "episode": 397.0, "Q1 loss": 8.268314136505127, "Q2 loss": 8.143945510864258, "Mean Target Q": 240.61022827148437, "Mean Q1": 240.60746594238282, "Mean Q2": 240.6098262939453, "critic_loss": 16.412259651184083, "batch_reward": 2.614370510101318, "actor_loss": -240.7490026080419, "actor_target_entropy": -6.0, "actor_entropy": 3.346553855472141, "alpha_loss": -0.0037142597951941073, "alpha_value": 0.07473669129635122, "duration": 129.05302834510803, "step": 49625}
{"episode_reward": 491.36057393719113, "episode": 398.0, "Q1 loss": 8.349495670318603, "Q2 loss": 8.214469667434692, "Mean Target Q": 240.6949842529297, "Mean Q1": 240.69183251953126, "Mean Q2": 240.69318322753907, "critic_loss": 16.563965362548828, "batch_reward": 2.619737030029297, "actor_loss": -240.8206486855784, "actor_target_entropy": -6.0, "actor_entropy": 3.4416271371226155, "alpha_loss": -0.006452709308735306, "alpha_value": 0.07490840737191101, "duration": 84.53235745429993, "step": 49750}
{"episode_reward": 494.4756764689495, "episode": 399.0, "Q1 loss": 9.802508808135986, "Q2 loss": 9.890308826446534, "Mean Target Q": 241.5491971435547, "Mean Q1": 241.54961889648436, "Mean Q2": 241.54583154296876, "critic_loss": 19.692817695617677, "batch_reward": 2.6227039012908935, "actor_loss": -241.73878115699404, "actor_target_entropy": -6.0, "actor_entropy": 3.3606867222558883, "alpha_loss": -0.010591197818044632, "alpha_value": 0.07499703315891491, "duration": 89.22817611694336, "step": 49875}
{"episode_reward": 511.7753111344728, "episode": 400.0, "Q1 loss": 7.56184429359436, "Q2 loss": 7.560316181182861, "Mean Target Q": 241.51380871582032, "Mean Q1": 241.5127829589844, "Mean Q2": 241.51425732421876, "critic_loss": 15.122160484313964, "batch_reward": 2.621201374053955, "actor_loss": -241.92284245644845, "actor_target_entropy": -6.0, "actor_entropy": 3.4551191099228395, "alpha_loss": -0.020166143823805594, "alpha_value": 0.07546966736572182, "step": 50000}
{"duration": 95.6342511177063, "step": 50000}
{"episode_reward": 507.1648231506661, "episode": 401.0, "Q1 loss": 7.4620736236572265, "Q2 loss": 7.362637056350708, "Mean Target Q": 241.63925170898438, "Mean Q1": 241.63485107421874, "Mean Q2": 241.63525476074219, "critic_loss": 14.82471063232422, "batch_reward": 2.6209021911621093, "actor_loss": -241.87084791395398, "actor_target_entropy": -6.0, "actor_entropy": 3.395995787211827, "alpha_loss": -0.006560681446913689, "alpha_value": 0.07570230491258015, "duration": 126.32103967666626, "step": 50125}
{"episode_reward": 108.39473312625351, "episode": 402.0, "Q1 loss": 7.1402372550964355, "Q2 loss": 7.2919990348815915, "Mean Target Q": 241.8427265625, "Mean Q1": 241.84580419921875, "Mean Q2": 241.84472827148437, "critic_loss": 14.432236320495605, "batch_reward": 2.618014865875244, "actor_loss": -242.3821258544922, "actor_target_entropy": -6.0, "actor_entropy": 3.357217046522325, "alpha_loss": 0.008000017117498624, "alpha_value": 0.07571541556857316, "duration": 119.47928071022034, "step": 50250}
{"episode_reward": 428.682088654506, "episode": 403.0, "Q1 loss": 6.922717739105225, "Q2 loss": 6.844628761291504, "Mean Target Q": 242.52494116210937, "Mean Q1": 242.5193330078125, "Mean Q2": 242.52130749511718, "critic_loss": 13.767346504211426, "batch_reward": 2.628747049331665, "actor_loss": -242.98881119016616, "actor_target_entropy": -6.0, "actor_entropy": 3.3669748722560824, "alpha_loss": -0.0027244672038784575, "alpha_value": 0.07566989328748351, "duration": 106.34277701377869, "step": 50375}
{"episode_reward": 485.31640286615067, "episode": 404.0, "Q1 loss": 7.035888618469238, "Q2 loss": 6.854201240539551, "Mean Target Q": 242.7061004638672, "Mean Q1": 242.70693518066406, "Mean Q2": 242.7036160888672, "critic_loss": 13.890089878082275, "batch_reward": 2.62529150390625, "actor_loss": -243.14763862855972, "actor_target_entropy": -6.0, "actor_entropy": 3.362850481464017, "alpha_loss": -0.004367768464069213, "alpha_value": 0.07578111927526716, "duration": 83.03810358047485, "step": 50500}
{"episode_reward": 522.0696196542282, "episode": 405.0, "Q1 loss": 7.240199855804443, "Q2 loss": 7.26053185081482, "Mean Target Q": 243.0037996826172, "Mean Q1": 243.00046655273437, "Mean Q2": 243.00484814453125, "critic_loss": 14.500731678009034, "batch_reward": 2.6364265365600588, "actor_loss": -243.45292130727617, "actor_target_entropy": -6.0, "actor_entropy": 3.299995471560766, "alpha_loss": -0.0044218317923387365, "alpha_value": 0.07581748245929934, "duration": 87.06982684135437, "step": 50625}
{"episode_reward": 507.4272106149135, "episode": 406.0, "Q1 loss": 7.064095706939697, "Q2 loss": 7.230982410430908, "Mean Target Q": 243.1228583984375, "Mean Q1": 243.12303088378906, "Mean Q2": 243.12259594726564, "critic_loss": 14.29507810974121, "batch_reward": 2.6330619735717775, "actor_loss": -243.684449472735, "actor_target_entropy": -6.0, "actor_entropy": 3.338504268277076, "alpha_loss": -0.00868716653466465, "alpha_value": 0.07596871081944506, "duration": 85.59610867500305, "step": 50750}
{"episode_reward": 437.42748150969766, "episode": 407.0, "Q1 loss": 7.116488887786865, "Q2 loss": 7.365234653472901, "Mean Target Q": 243.52367492675782, "Mean Q1": 243.52021032714845, "Mean Q2": 243.5188592529297, "critic_loss": 14.481723564147948, "batch_reward": 2.636249101638794, "actor_loss": -244.27572147429936, "actor_target_entropy": -6.0, "actor_entropy": 3.273941013548109, "alpha_loss": -0.0026387226590443226, "alpha_value": 0.0761359106805041, "duration": 93.71754050254822, "step": 50875}
{"episode_reward": 516.524669539053, "episode": 408.0, "Q1 loss": 8.90051810836792, "Q2 loss": 8.939721759796143, "Mean Target Q": 244.38084338378906, "Mean Q1": 244.37924645996094, "Mean Q2": 244.3801290283203, "critic_loss": 17.840239837646486, "batch_reward": 2.6479694213867186, "actor_loss": -244.76090929585118, "actor_target_entropy": -6.0, "actor_entropy": 3.309941610982341, "alpha_loss": -0.004639233563906483, "alpha_value": 0.07619177944106732, "duration": 78.06410932540894, "step": 51000}
{"episode_reward": 448.8595565529202, "episode": 409.0, "Q1 loss": 8.046277835845947, "Q2 loss": 7.855932647705078, "Mean Target Q": 243.97002099609375, "Mean Q1": 243.96982592773438, "Mean Q2": 243.96764477539062, "critic_loss": 15.902210556030273, "batch_reward": 2.6422259769439695, "actor_loss": -244.77979581318203, "actor_target_entropy": -6.0, "actor_entropy": 3.310638397459, "alpha_loss": -0.015447532152017903, "alpha_value": 0.07641742341837111, "duration": 82.56694149971008, "step": 51125}
{"episode_reward": 475.3642489758189, "episode": 410.0, "Q1 loss": 7.402353412628174, "Q2 loss": 7.395641948699951, "Mean Target Q": 244.6386506347656, "Mean Q1": 244.63248376464844, "Mean Q2": 244.63426550292968, "critic_loss": 14.797995346069335, "batch_reward": 2.6428418312072752, "actor_loss": -244.70142462945753, "actor_target_entropy": -6.0, "actor_entropy": 3.447984979998681, "alpha_loss": -0.005291850711669653, "alpha_value": 0.07665412575150851, "duration": 83.84415817260742, "step": 51250}
{"episode_reward": 493.1977236264668, "episode": 411.0, "Q1 loss": 7.244626644134521, "Q2 loss": 7.335996524810791, "Mean Target Q": 245.24006665039062, "Mean Q1": 245.23512890625, "Mean Q2": 245.23300134277343, "critic_loss": 14.580623161315918, "batch_reward": 2.6477102451324463, "actor_loss": -245.41385832287017, "actor_target_entropy": -6.0, "actor_entropy": 3.4111519200461253, "alpha_loss": -0.015402783846689595, "alpha_value": 0.07687588192555535, "duration": 86.09463763237, "step": 51375}
{"episode_reward": 421.8748581414913, "episode": 412.0, "Q1 loss": 7.2265542831420895, "Q2 loss": 7.28534037399292, "Mean Target Q": 245.4822354736328, "Mean Q1": 245.48298266601563, "Mean Q2": 245.48572790527345, "critic_loss": 14.511894645690917, "batch_reward": 2.6537488708496095, "actor_loss": -245.6835162255072, "actor_target_entropy": -6.0, "actor_entropy": 3.4123409640404487, "alpha_loss": -0.019497411873852535, "alpha_value": 0.07725286965591222, "duration": 124.14359521865845, "step": 51500}
{"episode_reward": 443.65969115513855, "episode": 413.0, "Q1 loss": 7.0390888175964355, "Q2 loss": 7.04245804977417, "Mean Target Q": 245.47122680664063, "Mean Q1": 245.46850671386719, "Mean Q2": 245.4678048095703, "critic_loss": 14.081546867370605, "batch_reward": 2.64272872543335, "actor_loss": -246.1253369043744, "actor_target_entropy": -6.0, "actor_entropy": 3.3925364055330793, "alpha_loss": -0.006182237077386133, "alpha_value": 0.07756021528205731, "duration": 135.06096816062927, "step": 51625}
{"episode_reward": 323.8170787329674, "episode": 414.0, "Q1 loss": 6.666489028930664, "Q2 loss": 6.676698841094971, "Mean Target Q": 246.2777657470703, "Mean Q1": 246.27594885253907, "Mean Q2": 246.2786387939453, "critic_loss": 13.34318784713745, "batch_reward": 2.6597540855407713, "actor_loss": -247.10158391152657, "actor_target_entropy": -6.0, "actor_entropy": 3.3791957478369437, "alpha_loss": -0.0027824983999673878, "alpha_value": 0.07770314762737603, "duration": 125.90318942070007, "step": 51750}
{"episode_reward": 526.3030738489626, "episode": 415.0, "Q1 loss": 6.806649013519287, "Q2 loss": 6.879893070220947, "Mean Target Q": 246.97300561523437, "Mean Q1": 246.97043786621094, "Mean Q2": 246.97162561035157, "critic_loss": 13.686542022705078, "batch_reward": 2.670306621551514, "actor_loss": -247.60918850368924, "actor_target_entropy": -6.0, "actor_entropy": 3.357144317929707, "alpha_loss": -0.005730329421422784, "alpha_value": 0.07774929542822911, "duration": 135.96618509292603, "step": 51875}
{"episode_reward": 392.91419805542205, "episode": 416.0, "Q1 loss": 6.452133121490479, "Q2 loss": 6.655404899597168, "Mean Target Q": 247.1469246826172, "Mean Q1": 247.14306713867188, "Mean Q2": 247.1395897216797, "critic_loss": 13.107538040161133, "batch_reward": 2.66451330947876, "actor_loss": -247.36990602554815, "actor_target_entropy": -6.0, "actor_entropy": 3.3916154869141115, "alpha_loss": -0.0071534827546847445, "alpha_value": 0.0779953651746672, "duration": 131.09703993797302, "step": 52000}
{"episode_reward": 465.58044760966766, "episode": 417.0, "Q1 loss": 7.737484252929687, "Q2 loss": 7.687008148193359, "Mean Target Q": 247.21546105957032, "Mean Q1": 247.20963562011718, "Mean Q2": 247.21005407714844, "critic_loss": 15.424492309570313, "batch_reward": 2.659680830001831, "actor_loss": -247.62344360351562, "actor_target_entropy": -6.0, "actor_entropy": 3.3474108680846197, "alpha_loss": -0.00013071709194235385, "alpha_value": 0.07801996648548888, "duration": 87.80699515342712, "step": 52125}
{"episode_reward": 417.8454716303574, "episode": 418.0, "Q1 loss": 7.34103694152832, "Q2 loss": 7.38923588180542, "Mean Target Q": 247.71429846191407, "Mean Q1": 247.71747521972657, "Mean Q2": 247.71733898925783, "critic_loss": 14.730272842407226, "batch_reward": 2.6682140083312986, "actor_loss": -248.07261829991495, "actor_target_entropy": -6.0, "actor_entropy": 3.3962591732701948, "alpha_loss": -0.0010054567453241156, "alpha_value": 0.078044801552432, "duration": 114.52745699882507, "step": 52250}
{"episode_reward": 500.03523953101126, "episode": 419.0, "Q1 loss": 7.293878868103027, "Q2 loss": 7.375032997131347, "Mean Target Q": 248.26139013671875, "Mean Q1": 248.25862280273438, "Mean Q2": 248.26038305664062, "critic_loss": 14.668911865234374, "batch_reward": 2.6750325393676757, "actor_loss": -248.56430102151538, "actor_target_entropy": -6.0, "actor_entropy": 3.334793034053984, "alpha_loss": -0.0064630456387050565, "alpha_value": 0.07812205471099162, "duration": 113.86277294158936, "step": 52375}
{"episode_reward": 533.6867068457077, "episode": 420.0, "Q1 loss": 7.129261024475098, "Q2 loss": 7.128431007385254, "Mean Target Q": 248.49801647949218, "Mean Q1": 248.49725, "Mean Q2": 248.49820922851563, "critic_loss": 14.257692001342773, "batch_reward": 2.67063073348999, "actor_loss": -249.52282591789, "actor_target_entropy": -6.0, "actor_entropy": 3.39858159711284, "alpha_loss": -0.0069498619357604655, "alpha_value": 0.07828246366342985, "duration": 110.44086027145386, "step": 52500}
{"episode_reward": 452.8385679530574, "episode": 421.0, "Q1 loss": 7.425724590301514, "Q2 loss": 7.446047035217285, "Mean Target Q": 248.42692248535155, "Mean Q1": 248.42147827148438, "Mean Q2": 248.41827685546875, "critic_loss": 14.871771705627442, "batch_reward": 2.67860587310791, "actor_loss": -248.8223411923363, "actor_target_entropy": -6.0, "actor_entropy": 3.3032544075496615, "alpha_loss": 0.006588030750641511, "alpha_value": 0.0782526062877693, "duration": 91.18319773674011, "step": 52625}
{"episode_reward": 461.2544300609089, "episode": 422.0, "Q1 loss": 7.014208911895752, "Q2 loss": 7.071867046356201, "Mean Target Q": 249.11085144042968, "Mean Q1": 249.10827746582032, "Mean Q2": 249.1113601074219, "critic_loss": 14.086075942993164, "batch_reward": 2.684576196670532, "actor_loss": -249.76359213552166, "actor_target_entropy": -6.0, "actor_entropy": 3.336946245162718, "alpha_loss": -0.0004953433038486589, "alpha_value": 0.07821604407372551, "duration": 89.85450291633606, "step": 52750}
{"episode_reward": 416.1115142255464, "episode": 423.0, "Q1 loss": 7.595263206481934, "Q2 loss": 7.71932067489624, "Mean Target Q": 249.20047314453126, "Mean Q1": 249.20098559570312, "Mean Q2": 249.20057922363281, "critic_loss": 15.314583930969238, "batch_reward": 2.6805649394989013, "actor_loss": -249.27915833488342, "actor_target_entropy": -6.0, "actor_entropy": 3.3392026235186862, "alpha_loss": 0.0018127424354177145, "alpha_value": 0.0781864008015603, "duration": 84.56499743461609, "step": 52875}
{"episode_reward": 505.138879769747, "episode": 424.0, "Q1 loss": 8.608788852691651, "Q2 loss": 8.55889554977417, "Mean Target Q": 249.238451171875, "Mean Q1": 249.2375515136719, "Mean Q2": 249.2335682373047, "critic_loss": 17.1676844329834, "batch_reward": 2.6759783058166504, "actor_loss": -249.99761076896422, "actor_target_entropy": -6.0, "actor_entropy": 3.3946258060393797, "alpha_loss": -0.0071558656937052165, "alpha_value": 0.07820479962919112, "duration": 89.97975182533264, "step": 53000}
{"episode_reward": 360.42887632988476, "episode": 425.0, "Q1 loss": 8.272046977996826, "Q2 loss": 7.983975090026855, "Mean Target Q": 249.71890600585937, "Mean Q1": 249.71651159667968, "Mean Q2": 249.7186143798828, "critic_loss": 16.256022109985352, "batch_reward": 2.677114978790283, "actor_loss": -250.10174003479972, "actor_target_entropy": -6.0, "actor_entropy": 3.400841720520504, "alpha_loss": -0.007385400090632694, "alpha_value": 0.07840980152319646, "duration": 96.75337171554565, "step": 53125}
{"episode_reward": 489.69503057972827, "episode": 426.0, "Q1 loss": 7.969637439727784, "Q2 loss": 7.775586441040039, "Mean Target Q": 250.2577841796875, "Mean Q1": 250.2552489013672, "Mean Q2": 250.2571120605469, "critic_loss": 15.745223823547363, "batch_reward": 2.685081018447876, "actor_loss": -250.4290709957, "actor_target_entropy": -6.0, "actor_entropy": 3.4506680734695925, "alpha_loss": -0.007524502918034071, "alpha_value": 0.07854587281943841, "duration": 83.4827241897583, "step": 53250}
{"episode_reward": 484.43640542133414, "episode": 427.0, "Q1 loss": 7.808282518386841, "Q2 loss": 7.919290809631348, "Mean Target Q": 250.96971252441406, "Mean Q1": 250.9686522216797, "Mean Q2": 250.9672744140625, "critic_loss": 15.727573318481445, "batch_reward": 2.6880165309906006, "actor_loss": -251.81165132068452, "actor_target_entropy": -6.0, "actor_entropy": 3.411150814994933, "alpha_loss": -0.0004526397826830073, "alpha_value": 0.07868170992753282, "duration": 106.40990877151489, "step": 53375}
{"episode_reward": 522.9055627335173, "episode": 428.0, "Q1 loss": 7.48321195602417, "Q2 loss": 7.593510734558105, "Mean Target Q": 251.43073461914062, "Mean Q1": 251.42371728515624, "Mean Q2": 251.42461987304688, "critic_loss": 15.076722732543946, "batch_reward": 2.6991833305358885, "actor_loss": -251.20635617163873, "actor_target_entropy": -6.0, "actor_entropy": 3.4631426026744228, "alpha_loss": -0.005489507825264047, "alpha_value": 0.07877528024623942, "duration": 142.93870425224304, "step": 53500}
{"episode_reward": 541.049321984514, "episode": 429.0, "Q1 loss": 7.286349983215332, "Q2 loss": 7.198843139648438, "Mean Target Q": 251.77087353515626, "Mean Q1": 251.77239379882812, "Mean Q2": 251.770490234375, "critic_loss": 14.485193161010741, "batch_reward": 2.695122968673706, "actor_loss": -252.23855542379712, "actor_target_entropy": -6.0, "actor_entropy": 3.2397264147561695, "alpha_loss": 0.004059514256253365, "alpha_value": 0.0787970068709953, "duration": 132.77752947807312, "step": 53625}
{"episode_reward": 446.23265246198736, "episode": 430.0, "Q1 loss": 7.576673639297486, "Q2 loss": 7.551610305786133, "Mean Target Q": 251.62945043945314, "Mean Q1": 251.62364721679688, "Mean Q2": 251.6238134765625, "critic_loss": 15.12828394317627, "batch_reward": 2.695930746078491, "actor_loss": -251.7345467844317, "actor_target_entropy": -6.0, "actor_entropy": 3.322546955077879, "alpha_loss": -0.002797967656665752, "alpha_value": 0.07872307636150432, "duration": 101.05826187133789, "step": 53750}
{"episode_reward": 520.6743881326146, "episode": 431.0, "Q1 loss": 7.821091636657715, "Q2 loss": 7.94732621383667, "Mean Target Q": 252.33125549316406, "Mean Q1": 252.33653784179688, "Mean Q2": 252.3364119873047, "critic_loss": 15.768417877197265, "batch_reward": 2.7049206104278563, "actor_loss": -252.9537823389447, "actor_target_entropy": -6.0, "actor_entropy": 3.35265090352013, "alpha_loss": -0.006948103111917301, "alpha_value": 0.07886282567828667, "duration": 131.64494824409485, "step": 53875}
{"episode_reward": 436.6243060847152, "episode": 432.0, "Q1 loss": 7.728245883941651, "Q2 loss": 7.8730330009460445, "Mean Target Q": 252.48008251953124, "Mean Q1": 252.4760106201172, "Mean Q2": 252.47547412109375, "critic_loss": 15.601278839111329, "batch_reward": 2.7052524547576904, "actor_loss": -252.87651800340223, "actor_target_entropy": -6.0, "actor_entropy": 3.3644509776946037, "alpha_loss": 0.003002292412753788, "alpha_value": 0.0789199720437373, "duration": 133.23413705825806, "step": 54000}
{"episode_reward": 69.45293513538653, "episode": 433.0, "Q1 loss": 8.117372505187989, "Q2 loss": 8.113081798553466, "Mean Target Q": 252.43370043945313, "Mean Q1": 252.43274670410156, "Mean Q2": 252.43346569824217, "critic_loss": 16.230454345703127, "batch_reward": 2.7054170932769774, "actor_loss": -252.85662454272074, "actor_target_entropy": -6.0, "actor_entropy": 3.3916463473486522, "alpha_loss": -0.0012250703293830156, "alpha_value": 0.07888731161835735, "duration": 155.44496631622314, "step": 54125}
{"episode_reward": 501.3492400312908, "episode": 434.0, "Q1 loss": 8.471285968780517, "Q2 loss": 8.642980430603027, "Mean Target Q": 252.51258251953124, "Mean Q1": 252.5096815185547, "Mean Q2": 252.5099139404297, "critic_loss": 17.11426634979248, "batch_reward": 2.699441467285156, "actor_loss": -252.5849796418221, "actor_target_entropy": -6.0, "actor_entropy": 3.3231491965632283, "alpha_loss": -0.0027831632873013376, "alpha_value": 0.07892517790486392, "duration": 151.54059743881226, "step": 54250}
{"episode_reward": 478.45352481915353, "episode": 435.0, "Q1 loss": 8.097261726379395, "Q2 loss": 8.009673782348633, "Mean Target Q": 252.52298010253907, "Mean Q1": 252.51802087402345, "Mean Q2": 252.51687744140625, "critic_loss": 16.106935485839845, "batch_reward": 2.698943134307861, "actor_loss": -252.635011703249, "actor_target_entropy": -6.0, "actor_entropy": 3.29315371740432, "alpha_loss": -0.0017688863518987856, "alpha_value": 0.07902728221126325, "duration": 125.7819275856018, "step": 54375}
{"episode_reward": 522.4117958075865, "episode": 436.0, "Q1 loss": 7.414317020416259, "Q2 loss": 7.415200428009033, "Mean Target Q": 252.80127478027345, "Mean Q1": 252.8021348876953, "Mean Q2": 252.80227404785157, "critic_loss": 14.829517486572266, "batch_reward": 2.7081556453704834, "actor_loss": -253.26631312216483, "actor_target_entropy": -6.0, "actor_entropy": 3.311765697694594, "alpha_loss": 0.004673065189572592, "alpha_value": 0.07903784370987663, "duration": 147.01879382133484, "step": 54500}
{"episode_reward": 211.11274012707128, "episode": 437.0, "Q1 loss": 10.001821830749511, "Q2 loss": 9.932905841827393, "Mean Target Q": 252.941673828125, "Mean Q1": 252.9435947265625, "Mean Q2": 252.94260803222656, "critic_loss": 19.93472779083252, "batch_reward": 2.706649108886719, "actor_loss": -253.65900021507628, "actor_target_entropy": -6.0, "actor_entropy": 3.3003790757012745, "alpha_loss": -0.001623392737071429, "alpha_value": 0.07890106550734938, "duration": 140.88569355010986, "step": 54625}
{"episode_reward": 542.1367275518515, "episode": 438.0, "Q1 loss": 9.778592697143555, "Q2 loss": 9.577139904022216, "Mean Target Q": 253.5694052734375, "Mean Q1": 253.5624287109375, "Mean Q2": 253.5654952392578, "critic_loss": 19.35573262023926, "batch_reward": 2.7160875968933107, "actor_loss": -253.5995389876827, "actor_target_entropy": -6.0, "actor_entropy": 3.3359377691822667, "alpha_loss": 0.010120673901251247, "alpha_value": 0.07882220540072768, "duration": 155.68006229400635, "step": 54750}
{"episode_reward": 533.4546995386892, "episode": 439.0, "Q1 loss": 8.294588592529298, "Q2 loss": 8.15533720779419, "Mean Target Q": 253.3898017578125, "Mean Q1": 253.3912332763672, "Mean Q2": 253.38995788574218, "critic_loss": 16.44992576599121, "batch_reward": 2.706755922317505, "actor_loss": -253.80657765221974, "actor_target_entropy": -6.0, "actor_entropy": 3.2802972263760037, "alpha_loss": 0.008291730697872856, "alpha_value": 0.07852004777119505, "duration": 128.59509921073914, "step": 54875}
{"episode_reward": 508.9737629686058, "episode": 440.0, "Q1 loss": 8.568689769744873, "Q2 loss": 8.508551929473876, "Mean Target Q": 253.98866931152344, "Mean Q1": 253.98336865234376, "Mean Q2": 253.98641674804688, "critic_loss": 17.077241691589357, "batch_reward": 2.7179542121887206, "actor_loss": -254.19288143034905, "actor_target_entropy": -6.0, "actor_entropy": 3.2549790951513473, "alpha_loss": -0.0025439501003993135, "alpha_value": 0.07852225040668054, "step": 55000}
{"duration": 113.93907189369202, "step": 55000}
{"episode_reward": 491.14147305912655, "episode": 441.0, "Q1 loss": 7.609138317108155, "Q2 loss": 7.8182562141418455, "Mean Target Q": 254.85472106933594, "Mean Q1": 254.85455493164062, "Mean Q2": 254.85209619140625, "critic_loss": 15.427394569396972, "batch_reward": 2.723692762374878, "actor_loss": -254.73334127759176, "actor_target_entropy": -6.0, "actor_entropy": 3.291355257942563, "alpha_loss": -0.005730062183584013, "alpha_value": 0.07859800791100413, "duration": 98.31268334388733, "step": 55125}
{"episode_reward": 486.4997727769367, "episode": 442.0, "Q1 loss": 8.636732406616211, "Q2 loss": 8.686457832336426, "Mean Target Q": 254.99452453613281, "Mean Q1": 254.99411083984376, "Mean Q2": 254.99345361328125, "critic_loss": 17.323190238952638, "batch_reward": 2.7227558574676514, "actor_loss": -255.3740027643019, "actor_target_entropy": -6.0, "actor_entropy": 3.3686845687127884, "alpha_loss": -0.014948834068021707, "alpha_value": 0.07886410812901123, "duration": 92.61477994918823, "step": 55250}
{"episode_reward": 447.65043164028975, "episode": 443.0, "Q1 loss": 8.261342861175537, "Q2 loss": 8.342558055877685, "Mean Target Q": 255.158541015625, "Mean Q1": 255.15156384277344, "Mean Q2": 255.15054602050782, "critic_loss": 16.603900924682616, "batch_reward": 2.7211732234954833, "actor_loss": -255.61966838533917, "actor_target_entropy": -6.0, "actor_entropy": 3.3519605871230835, "alpha_loss": -0.011051391037033191, "alpha_value": 0.07924381702467785, "duration": 103.59947562217712, "step": 55375}
{"episode_reward": 490.87816310469464, "episode": 444.0, "Q1 loss": 8.625118740081787, "Q2 loss": 8.700803749084473, "Mean Target Q": 256.2463283691406, "Mean Q1": 256.2435438232422, "Mean Q2": 256.2453779296875, "critic_loss": 17.325922554016113, "batch_reward": 2.730070646286011, "actor_loss": -256.66300816689767, "actor_target_entropy": -6.0, "actor_entropy": 3.283865963259051, "alpha_loss": -0.009211629989647096, "alpha_value": 0.07937599633942924, "duration": 94.22958445549011, "step": 55500}
{"episode_reward": 453.9220804054792, "episode": 445.0, "Q1 loss": 8.770989738464355, "Q2 loss": 8.627730350494385, "Mean Target Q": 255.90816064453125, "Mean Q1": 255.90554650878906, "Mean Q2": 255.90583935546874, "critic_loss": 17.39872004699707, "batch_reward": 2.733214282989502, "actor_loss": -256.78518749418714, "actor_target_entropy": -6.0, "actor_entropy": 3.2663001370808433, "alpha_loss": -0.004346661247490417, "alpha_value": 0.07963159157015871, "duration": 107.45837306976318, "step": 55625}
{"episode_reward": 511.1237378432195, "episode": 446.0, "Q1 loss": 7.336274597167969, "Q2 loss": 7.320803016662597, "Mean Target Q": 256.4191691894531, "Mean Q1": 256.41577307128904, "Mean Q2": 256.4155703125, "critic_loss": 14.657077598571778, "batch_reward": 2.73119987487793, "actor_loss": -257.03629278367566, "actor_target_entropy": -6.0, "actor_entropy": 3.3154746294021606, "alpha_loss": -0.0032220755989152577, "alpha_value": 0.07972445196699535, "duration": 89.6858720779419, "step": 55750}
{"episode_reward": 529.5815055498741, "episode": 447.0, "Q1 loss": 8.610537475585938, "Q2 loss": 8.41416588973999, "Mean Target Q": 256.5255318603516, "Mean Q1": 256.5205717773438, "Mean Q2": 256.5205860595703, "critic_loss": 17.024703254699705, "batch_reward": 2.73119246673584, "actor_loss": -256.82356625511534, "actor_target_entropy": -6.0, "actor_entropy": 3.2805575378357417, "alpha_loss": -0.0016004449081799342, "alpha_value": 0.07967608449914443, "duration": 98.33010268211365, "step": 55875}
{"episode_reward": 504.4379966014848, "episode": 448.0, "Q1 loss": 7.902892078399658, "Q2 loss": 7.840110046386719, "Mean Target Q": 256.95694567871095, "Mean Q1": 256.95797436523435, "Mean Q2": 256.9591197509766, "critic_loss": 15.743002143859863, "batch_reward": 2.74345751953125, "actor_loss": -257.12602726105723, "actor_target_entropy": -6.0, "actor_entropy": 3.300283901153072, "alpha_loss": -0.011800905445500488, "alpha_value": 0.07989079962803611, "duration": 98.82585763931274, "step": 56000}
{"episode_reward": 499.60358368484236, "episode": 449.0, "Q1 loss": 8.18519856262207, "Q2 loss": 8.206233730316162, "Mean Target Q": 257.4274968261719, "Mean Q1": 257.4271923828125, "Mean Q2": 257.42406372070315, "critic_loss": 16.39143222808838, "batch_reward": 2.739391956329346, "actor_loss": -257.84059070405505, "actor_target_entropy": -6.0, "actor_entropy": 3.30244419309828, "alpha_loss": -0.006616887403652072, "alpha_value": 0.08009065350001157, "duration": 98.6699788570404, "step": 56125}
{"episode_reward": 512.6867959624841, "episode": 450.0, "Q1 loss": 9.421367824554443, "Q2 loss": 9.406328323364258, "Mean Target Q": 257.7221240234375, "Mean Q1": 257.7201475830078, "Mean Q2": 257.71968395996095, "critic_loss": 18.827696144104003, "batch_reward": 2.7503051776885985, "actor_loss": -258.48272483579575, "actor_target_entropy": -6.0, "actor_entropy": 3.30417533843748, "alpha_loss": -0.013293825762136089, "alpha_value": 0.08035083413510959, "duration": 102.05702233314514, "step": 56250}
{"episode_reward": 473.16290645650577, "episode": 451.0, "Q1 loss": 7.637065647125244, "Q2 loss": 7.575942581176758, "Mean Target Q": 258.1845391845703, "Mean Q1": 258.18419702148435, "Mean Q2": 258.18503271484377, "critic_loss": 15.213008171081542, "batch_reward": 2.752895700454712, "actor_loss": -259.0338195316375, "actor_target_entropy": -6.0, "actor_entropy": 3.2544619204506042, "alpha_loss": -0.0007292870875625383, "alpha_value": 0.08051818199261591, "duration": 105.64338731765747, "step": 56375}
{"episode_reward": 532.6855405366357, "episode": 452.0, "Q1 loss": 7.702990879058838, "Q2 loss": 7.618598815917969, "Mean Target Q": 258.0399177246094, "Mean Q1": 258.0399903564453, "Mean Q2": 258.0389616699219, "critic_loss": 15.321589668273926, "batch_reward": 2.742106517791748, "actor_loss": -258.36724385907576, "actor_target_entropy": -6.0, "actor_entropy": 3.2043981359850977, "alpha_loss": 0.002046317793428898, "alpha_value": 0.08053064227267921, "duration": 112.44513320922852, "step": 56500}
{"episode_reward": 326.08453041033965, "episode": 453.0, "Q1 loss": 8.357086116790772, "Q2 loss": 8.247439838409424, "Mean Target Q": 258.7247426757813, "Mean Q1": 258.7176872558594, "Mean Q2": 258.72132385253906, "critic_loss": 16.6045259475708, "batch_reward": 2.7420268993377688, "actor_loss": -258.71877228267607, "actor_target_entropy": -6.0, "actor_entropy": 3.288522107260568, "alpha_loss": 0.00644271324078242, "alpha_value": 0.08038582899243339, "duration": 135.52745127677917, "step": 56625}
{"episode_reward": 471.46305648556506, "episode": 454.0, "Q1 loss": 7.980952972412109, "Q2 loss": 7.820583843231201, "Mean Target Q": 258.96750561523436, "Mean Q1": 258.9672321777344, "Mean Q2": 258.9636300048828, "critic_loss": 15.801536827087402, "batch_reward": 2.7521753005981444, "actor_loss": -259.4747083110194, "actor_target_entropy": -6.0, "actor_entropy": 3.2240917644193097, "alpha_loss": -0.0016788402084080922, "alpha_value": 0.08027931682204244, "duration": 135.54874801635742, "step": 56750}
{"episode_reward": 459.3289310080795, "episode": 455.0, "Q1 loss": 8.140001068115234, "Q2 loss": 8.189583209991454, "Mean Target Q": 258.61866552734375, "Mean Q1": 258.61182556152346, "Mean Q2": 258.6162071533203, "critic_loss": 16.329584266662597, "batch_reward": 2.745086545944214, "actor_loss": -258.95401243179566, "actor_target_entropy": -6.0, "actor_entropy": 3.4113248075757707, "alpha_loss": -0.0012087972635137184, "alpha_value": 0.08036013048742485, "duration": 128.95855689048767, "step": 56875}
{"episode_reward": 515.5854618712523, "episode": 456.0, "Q1 loss": 8.016111743927002, "Q2 loss": 7.95479280090332, "Mean Target Q": 259.55781640625, "Mean Q1": 259.5641560058594, "Mean Q2": 259.5578823242187, "critic_loss": 15.970904556274414, "batch_reward": 2.761422590255737, "actor_loss": -259.61898656045236, "actor_target_entropy": -6.0, "actor_entropy": 3.3192477803076468, "alpha_loss": -0.003266563774236748, "alpha_value": 0.08049569210054444, "duration": 130.5669686794281, "step": 57000}
{"episode_reward": 508.6007806319292, "episode": 457.0, "Q1 loss": 7.51057201385498, "Q2 loss": 7.555233909606933, "Mean Target Q": 259.52967016601565, "Mean Q1": 259.5243865966797, "Mean Q2": 259.5268687744141, "critic_loss": 15.06580591583252, "batch_reward": 2.7567303047180176, "actor_loss": -259.86674160427515, "actor_target_entropy": -6.0, "actor_entropy": 3.196862534871177, "alpha_loss": 0.0019906958794250846, "alpha_value": 0.08046017558762768, "duration": 127.59179091453552, "step": 57125}
{"episode_reward": 462.9435619809574, "episode": 458.0, "Q1 loss": 7.894312606811523, "Q2 loss": 7.858350894927979, "Mean Target Q": 260.31238134765624, "Mean Q1": 260.30706457519534, "Mean Q2": 260.3057791748047, "critic_loss": 15.752663520812987, "batch_reward": 2.764837028503418, "actor_loss": -260.978143753544, "actor_target_entropy": -6.0, "actor_entropy": 3.21568771331541, "alpha_loss": 0.00023107504427072502, "alpha_value": 0.08039441136203078, "duration": 142.43422412872314, "step": 57250}
{"episode_reward": 467.29983141373407, "episode": 459.0, "Q1 loss": 7.864845878601074, "Q2 loss": 7.900988456726075, "Mean Target Q": 260.06544494628906, "Mean Q1": 260.05835021972655, "Mean Q2": 260.06231433105467, "critic_loss": 15.76583432006836, "batch_reward": 2.7575271129608154, "actor_loss": -260.7719140431238, "actor_target_entropy": -6.0, "actor_entropy": 3.2880003868587435, "alpha_loss": -0.004751149768246308, "alpha_value": 0.08044223702391817, "duration": 144.17909955978394, "step": 57375}
{"episode_reward": 489.15110208903377, "episode": 460.0, "Q1 loss": 7.276504112243653, "Q2 loss": 7.444150867462159, "Mean Target Q": 260.9419733886719, "Mean Q1": 260.9512227783203, "Mean Q2": 260.9502398681641, "critic_loss": 14.72065496826172, "batch_reward": 2.765216390609741, "actor_loss": -261.29991346789944, "actor_target_entropy": -6.0, "actor_entropy": 3.3073374379065728, "alpha_loss": -0.004097109934645554, "alpha_value": 0.08058381342753916, "duration": 119.60323119163513, "step": 57500}
{"episode_reward": 564.5148820721427, "episode": 461.0, "Q1 loss": 8.630785385131835, "Q2 loss": 8.788854454040527, "Mean Target Q": 260.75049865722656, "Mean Q1": 260.7473291015625, "Mean Q2": 260.7462984619141, "critic_loss": 17.41963988494873, "batch_reward": 2.7692033977508546, "actor_loss": -261.5902332124256, "actor_target_entropy": -6.0, "actor_entropy": 3.3206257479531422, "alpha_loss": -0.012011860866868307, "alpha_value": 0.08071359108767277, "duration": 85.30184721946716, "step": 57625}
{"episode_reward": 273.0990463824584, "episode": 462.0, "Q1 loss": 8.67563359451294, "Q2 loss": 8.749578662872315, "Mean Target Q": 261.40328845214844, "Mean Q1": 261.3946895751953, "Mean Q2": 261.39467700195314, "critic_loss": 17.425212211608887, "batch_reward": 2.773531063079834, "actor_loss": -262.2777262041646, "actor_target_entropy": -6.0, "actor_entropy": 3.3372845034445486, "alpha_loss": -0.01858387412428255, "alpha_value": 0.08115441857849008, "duration": 89.97874665260315, "step": 57750}
{"episode_reward": 467.188765454522, "episode": 463.0, "Q1 loss": 7.167636352539063, "Q2 loss": 7.109883758544922, "Mean Target Q": 261.46221313476565, "Mean Q1": 261.4669289550781, "Mean Q2": 261.4663660888672, "critic_loss": 14.27752001953125, "batch_reward": 2.760368427276611, "actor_loss": -262.3167625306145, "actor_target_entropy": -6.0, "actor_entropy": 3.361452102661133, "alpha_loss": -0.003081478296764313, "alpha_value": 0.0814411016249402, "duration": 89.75263476371765, "step": 57875}
{"episode_reward": 522.4944243543093, "episode": 464.0, "Q1 loss": 7.517831726074219, "Q2 loss": 7.718681896209717, "Mean Target Q": 262.58718395996095, "Mean Q1": 262.5860477294922, "Mean Q2": 262.5880124511719, "critic_loss": 15.236513679504395, "batch_reward": 2.7843853397369385, "actor_loss": -262.81651084653794, "actor_target_entropy": -6.0, "actor_entropy": 3.2003100341366184, "alpha_loss": -0.0024472234485250328, "alpha_value": 0.08148167768982215, "duration": 100.05690550804138, "step": 58000}
{"episode_reward": 525.1563136800398, "episode": 465.0, "Q1 loss": 8.714924726486206, "Q2 loss": 8.740402862548828, "Mean Target Q": 261.8647512207031, "Mean Q1": 261.8598742675781, "Mean Q2": 261.8592895507812, "critic_loss": 17.45532758331299, "batch_reward": 2.7631642684936524, "actor_loss": -262.47303505549354, "actor_target_entropy": -6.0, "actor_entropy": 3.211600867528764, "alpha_loss": 0.004164946162038379, "alpha_value": 0.08141237340301537, "duration": 104.09012866020203, "step": 58125}
{"episode_reward": 538.6178145922604, "episode": 466.0, "Q1 loss": 9.853159294128417, "Q2 loss": 9.80710428237915, "Mean Target Q": 262.7261389160156, "Mean Q1": 262.7221997070312, "Mean Q2": 262.72126928710935, "critic_loss": 19.660263549804686, "batch_reward": 2.792680700302124, "actor_loss": -263.02461734894786, "actor_target_entropy": -6.0, "actor_entropy": 3.3666797760994203, "alpha_loss": -0.018810516677706713, "alpha_value": 0.08154260029216014, "duration": 122.16542458534241, "step": 58250}
{"episode_reward": 373.2161193090384, "episode": 467.0, "Q1 loss": 9.055884456634521, "Q2 loss": 8.922816394805908, "Mean Target Q": 262.6522329101563, "Mean Q1": 262.647439453125, "Mean Q2": 262.6491530761719, "critic_loss": 17.9787008895874, "batch_reward": 2.7729786319732668, "actor_loss": -263.25386895073785, "actor_target_entropy": -6.0, "actor_entropy": 3.284141729748438, "alpha_loss": 0.0012445365529625662, "alpha_value": 0.08179206129718745, "duration": 129.79405975341797, "step": 58375}
{"episode_reward": 484.29149669477385, "episode": 468.0, "Q1 loss": 8.794824619293212, "Q2 loss": 8.704940185546874, "Mean Target Q": 262.5588591308594, "Mean Q1": 262.56131005859373, "Mean Q2": 262.5599864501953, "critic_loss": 17.499764762878417, "batch_reward": 2.7792610454559328, "actor_loss": -263.1513570970105, "actor_target_entropy": -6.0, "actor_entropy": 3.252910421740624, "alpha_loss": -0.0005853410937913484, "alpha_value": 0.08178749409342091, "duration": 151.71517658233643, "step": 58500}
{"episode_reward": 464.085407771521, "episode": 469.0, "Q1 loss": 10.11352632522583, "Q2 loss": 9.936899532318115, "Mean Target Q": 262.5672712402344, "Mean Q1": 262.56221240234373, "Mean Q2": 262.56423107910155, "critic_loss": 20.050425941467285, "batch_reward": 2.7802318897247313, "actor_loss": -263.2392042856368, "actor_target_entropy": -6.0, "actor_entropy": 3.2580873814840166, "alpha_loss": 0.004992152634446347, "alpha_value": 0.08170123231821443, "duration": 115.37135314941406, "step": 58625}
{"episode_reward": 546.362781038621, "episode": 470.0, "Q1 loss": 8.468394050598144, "Q2 loss": 8.481893920898438, "Mean Target Q": 263.41380615234374, "Mean Q1": 263.4105, "Mean Q2": 263.41113671875, "critic_loss": 16.950287956237794, "batch_reward": 2.7913195133209228, "actor_loss": -263.5089652769027, "actor_target_entropy": -6.0, "actor_entropy": 3.3402019316150295, "alpha_loss": 0.0010832365219210906, "alpha_value": 0.08164726284712434, "duration": 126.35807228088379, "step": 58750}
{"episode_reward": 527.0768434636865, "episode": 471.0, "Q1 loss": 8.631294513702393, "Q2 loss": 8.269085193634034, "Mean Target Q": 263.88436865234377, "Mean Q1": 263.88308459472654, "Mean Q2": 263.88062939453124, "critic_loss": 16.900379692077635, "batch_reward": 2.792015354156494, "actor_loss": -264.7246345641121, "actor_target_entropy": -6.0, "actor_entropy": 3.2348119834112743, "alpha_loss": -0.0036782941093579644, "alpha_value": 0.08170986377936044, "duration": 145.30854153633118, "step": 58875}
{"episode_reward": 533.5163505971582, "episode": 472.0, "Q1 loss": 8.062966999053955, "Q2 loss": 7.891928249359131, "Mean Target Q": 264.4101945800781, "Mean Q1": 264.40973901367187, "Mean Q2": 264.40987109375, "critic_loss": 15.954895195007325, "batch_reward": 2.802093296051025, "actor_loss": -264.3336619715537, "actor_target_entropy": -6.0, "actor_entropy": 3.296560537430548, "alpha_loss": -0.0026472227219792623, "alpha_value": 0.08177026641988275, "duration": 148.47372269630432, "step": 59000}
{"episode_reward": 434.7369761053449, "episode": 473.0, "Q1 loss": 8.55788480758667, "Q2 loss": 8.56734767150879, "Mean Target Q": 263.8579306640625, "Mean Q1": 263.863251953125, "Mean Q2": 263.8623566894531, "critic_loss": 17.125232498168945, "batch_reward": 2.7823425731658937, "actor_loss": -264.5216679648748, "actor_target_entropy": -6.0, "actor_entropy": 3.262322838344271, "alpha_loss": -0.006415933326241516, "alpha_value": 0.08183428050511327, "duration": 154.43661546707153, "step": 59125}
{"episode_reward": 559.6782276910697, "episode": 474.0, "Q1 loss": 8.980851718902588, "Q2 loss": 8.863064685821533, "Mean Target Q": 264.395775390625, "Mean Q1": 264.3883494873047, "Mean Q2": 264.3878349609375, "critic_loss": 17.843916374206543, "batch_reward": 2.7966660594940187, "actor_loss": -265.0300770421182, "actor_target_entropy": -6.0, "actor_entropy": 3.344797815046003, "alpha_loss": -0.0067561388188492385, "alpha_value": 0.08197441222157414, "duration": 112.76071786880493, "step": 59250}
{"episode_reward": 541.2835682127725, "episode": 475.0, "Q1 loss": 8.825126838684081, "Q2 loss": 8.681227054595947, "Mean Target Q": 264.7975649414062, "Mean Q1": 264.7944013671875, "Mean Q2": 264.7983188476563, "critic_loss": 17.506353996276854, "batch_reward": 2.8024392166137697, "actor_loss": -265.25992111932663, "actor_target_entropy": -6.0, "actor_entropy": 3.314611302481757, "alpha_loss": -0.0033677765205206854, "alpha_value": 0.08215239011992101, "duration": 99.87693238258362, "step": 59375}
{"episode_reward": 474.99047989028725, "episode": 476.0, "Q1 loss": 9.206377101898193, "Q2 loss": 9.238911472320556, "Mean Target Q": 265.40088159179686, "Mean Q1": 265.3980700683594, "Mean Q2": 265.3960915527344, "critic_loss": 18.445288597106934, "batch_reward": 2.815807647705078, "actor_loss": -265.4514425954511, "actor_target_entropy": -6.0, "actor_entropy": 3.324236427584002, "alpha_loss": -0.01102569991452319, "alpha_value": 0.08230490368329876, "duration": 139.22473406791687, "step": 59500}
{"episode_reward": 560.2254118185939, "episode": 477.0, "Q1 loss": 8.519720478057861, "Q2 loss": 8.562590755462647, "Mean Target Q": 265.4128151855469, "Mean Q1": 265.4140090332031, "Mean Q2": 265.41330102539064, "critic_loss": 17.082311264038086, "batch_reward": 2.8051066226959227, "actor_loss": -265.8453994024368, "actor_target_entropy": -6.0, "actor_entropy": 3.267025289081392, "alpha_loss": -0.007785284559109381, "alpha_value": 0.08256417391102001, "duration": 141.21140027046204, "step": 59625}
{"episode_reward": 469.8557043986261, "episode": 478.0, "Q1 loss": 8.668574974060059, "Q2 loss": 8.51737095451355, "Mean Target Q": 265.82238940429687, "Mean Q1": 265.8243408203125, "Mean Q2": 265.82348852539064, "critic_loss": 17.185945953369142, "batch_reward": 2.8099016971588133, "actor_loss": -265.87571716308594, "actor_target_entropy": -6.0, "actor_entropy": 3.381114967407719, "alpha_loss": 2.1649269206869987e-05, "alpha_value": 0.08268582066334755, "duration": 142.2900788784027, "step": 59750}
{"episode_reward": 554.4560966886805, "episode": 479.0, "Q1 loss": 8.940666473388672, "Q2 loss": 9.016157688140868, "Mean Target Q": 265.81367041015625, "Mean Q1": 265.7972033691406, "Mean Q2": 265.80166015625, "critic_loss": 17.95682418060303, "batch_reward": 2.8132305641174318, "actor_loss": -266.35898844401044, "actor_target_entropy": -6.0, "actor_entropy": 3.275706317689684, "alpha_loss": 0.0009488612339491882, "alpha_value": 0.08266279149458317, "duration": 148.13891172409058, "step": 59875}
{"episode_reward": 462.186571229395, "episode": 480.0, "Q1 loss": 9.265839923858643, "Q2 loss": 9.326092510223388, "Mean Target Q": 266.24253442382815, "Mean Q1": 266.253404296875, "Mean Q2": 266.24895776367185, "critic_loss": 18.59193241882324, "batch_reward": 2.8140925998687742, "actor_loss": -266.5363577565839, "actor_target_entropy": -6.0, "actor_entropy": 3.263276219367981, "alpha_loss": -0.003932114780670212, "alpha_value": 0.08269090807545294, "step": 60000}
{"duration": 131.67506575584412, "step": 60000}
{"episode_reward": 58.72736085992089, "episode": 481.0, "Q1 loss": 11.024642623901368, "Q2 loss": 10.748375492095947, "Mean Target Q": 266.38957080078126, "Mean Q1": 266.3806633300781, "Mean Q2": 266.3835183105469, "critic_loss": 21.773018096923828, "batch_reward": 2.80435626411438, "actor_loss": -266.9618152436756, "actor_target_entropy": -6.0, "actor_entropy": 3.239898685425047, "alpha_loss": -0.004888339297077249, "alpha_value": 0.08280431052723783, "duration": 168.05793523788452, "step": 60125}
{"episode_reward": 505.2621166188979, "episode": 482.0, "Q1 loss": 9.98171726989746, "Q2 loss": 10.081945373535156, "Mean Target Q": 267.31299584960936, "Mean Q1": 267.3119536132813, "Mean Q2": 267.31209423828125, "critic_loss": 20.063662704467774, "batch_reward": 2.8208767070770264, "actor_loss": -267.76935011340726, "actor_target_entropy": -6.0, "actor_entropy": 3.2711923045496785, "alpha_loss": -0.008898293640795014, "alpha_value": 0.08299359835757644, "duration": 97.95152306556702, "step": 60250}
{"episode_reward": 517.5558829985124, "episode": 483.0, "Q1 loss": 9.736894680023193, "Q2 loss": 9.617927433013916, "Mean Target Q": 266.81798046875, "Mean Q1": 266.823083984375, "Mean Q2": 266.8165808105469, "critic_loss": 19.35482206726074, "batch_reward": 2.817450855255127, "actor_loss": -267.4808984181238, "actor_target_entropy": -6.0, "actor_entropy": 3.391068170941065, "alpha_loss": -0.012998451160947009, "alpha_value": 0.08321625450537223, "duration": 94.23224687576294, "step": 60375}
{"episode_reward": 489.25870945597086, "episode": 484.0, "Q1 loss": 10.578216388702392, "Q2 loss": 10.171830360412597, "Mean Target Q": 267.001703125, "Mean Q1": 266.9940190429688, "Mean Q2": 266.9984567871094, "critic_loss": 20.750046745300292, "batch_reward": 2.8194090480804443, "actor_loss": -266.95590259182836, "actor_target_entropy": -6.0, "actor_entropy": 3.294862974074579, "alpha_loss": -0.0027110196514836243, "alpha_value": 0.08339522200816173, "duration": 94.9840521812439, "step": 60500}
{"episode_reward": 462.877617782218, "episode": 485.0, "Q1 loss": 11.142551868438721, "Q2 loss": 10.73371816253662, "Mean Target Q": 267.27679370117187, "Mean Q1": 267.27635302734376, "Mean Q2": 267.2773078613281, "critic_loss": 21.87627003479004, "batch_reward": 2.8099071083068847, "actor_loss": -267.8219628712488, "actor_target_entropy": -6.0, "actor_entropy": 3.307087603069487, "alpha_loss": -0.02101672055672795, "alpha_value": 0.08369674372204823, "duration": 131.11716318130493, "step": 60625}
{"episode_reward": 513.0686050360056, "episode": 486.0, "Q1 loss": 11.221802062988282, "Q2 loss": 11.042686325073243, "Mean Target Q": 267.608234375, "Mean Q1": 267.60231372070314, "Mean Q2": 267.60519018554686, "critic_loss": 22.264488418579102, "batch_reward": 2.824212854385376, "actor_loss": -268.0907701061618, "actor_target_entropy": -6.0, "actor_entropy": 3.3589574483133133, "alpha_loss": -0.005046551637802153, "alpha_value": 0.08395928707338046, "duration": 123.21228003501892, "step": 60750}
{"episode_reward": 463.36499874337596, "episode": 487.0, "Q1 loss": 10.893446998596191, "Q2 loss": 10.94941514968872, "Mean Target Q": 267.5642622070313, "Mean Q1": 267.56070239257815, "Mean Q2": 267.5575520019531, "critic_loss": 21.842862129211426, "batch_reward": 2.824306894302368, "actor_loss": -268.1194385346912, "actor_target_entropy": -6.0, "actor_entropy": 3.2821738417186435, "alpha_loss": -0.009907979163385573, "alpha_value": 0.08424951960383424, "duration": 86.56557631492615, "step": 60875}
{"episode_reward": 475.95226106208133, "episode": 488.0, "Q1 loss": 10.807605121612548, "Q2 loss": 10.63625832748413, "Mean Target Q": 268.641103515625, "Mean Q1": 268.6440905761719, "Mean Q2": 268.64369995117187, "critic_loss": 21.44386346435547, "batch_reward": 2.8336005573272707, "actor_loss": -269.137942898658, "actor_target_entropy": -6.0, "actor_entropy": 3.3169998391982047, "alpha_loss": -0.006964929600907189, "alpha_value": 0.08437140850706744, "duration": 84.33557558059692, "step": 61000}
{"episode_reward": 536.6231562339859, "episode": 489.0, "Q1 loss": 11.296644721984864, "Q2 loss": 11.024188835144043, "Mean Target Q": 268.0200832519531, "Mean Q1": 268.0136787109375, "Mean Q2": 268.0095771484375, "critic_loss": 22.320833450317384, "batch_reward": 2.8185105609893797, "actor_loss": -267.8339068700397, "actor_target_entropy": -6.0, "actor_entropy": 3.3198356174287342, "alpha_loss": -0.026287984376448015, "alpha_value": 0.08470954750645351, "duration": 101.02382898330688, "step": 61125}
{"episode_reward": 354.3131919987304, "episode": 490.0, "Q1 loss": 10.32310099029541, "Q2 loss": 10.389899299621582, "Mean Target Q": 268.577197265625, "Mean Q1": 268.57790380859376, "Mean Q2": 268.58095629882814, "critic_loss": 20.71300033569336, "batch_reward": 2.8269051399230958, "actor_loss": -269.00613157210813, "actor_target_entropy": -6.0, "actor_entropy": 3.4128023578274633, "alpha_loss": -0.011580872075301745, "alpha_value": 0.08519017525490408, "duration": 89.82996654510498, "step": 61250}
{"episode_reward": 546.7855520056603, "episode": 491.0, "Q1 loss": 10.186434814453126, "Q2 loss": 10.497449920654297, "Mean Target Q": 268.4565383300781, "Mean Q1": 268.4534775390625, "Mean Q2": 268.45270825195314, "critic_loss": 20.683884765625, "batch_reward": 2.8162850723266604, "actor_loss": -268.93518599252855, "actor_target_entropy": -6.0, "actor_entropy": 3.3335022812797908, "alpha_loss": -0.00868162229686739, "alpha_value": 0.08538889653635927, "duration": 87.47666501998901, "step": 61375}
{"episode_reward": 452.3566680056634, "episode": 492.0, "Q1 loss": 11.617655841827393, "Q2 loss": 11.550982864379883, "Mean Target Q": 269.588109375, "Mean Q1": 269.5829382324219, "Mean Q2": 269.58403442382814, "critic_loss": 23.16863877105713, "batch_reward": 2.831753053665161, "actor_loss": -269.4936897523942, "actor_target_entropy": -6.0, "actor_entropy": 3.2936990684078586, "alpha_loss": -0.023487746970908295, "alpha_value": 0.08575401373202331, "duration": 122.9114203453064, "step": 61500}
{"episode_reward": 548.6377256218792, "episode": 493.0, "Q1 loss": 10.273780242919923, "Q2 loss": 10.158104263305663, "Mean Target Q": 269.73812841796877, "Mean Q1": 269.73529565429686, "Mean Q2": 269.7346511230469, "critic_loss": 20.43188452911377, "batch_reward": 2.84301188659668, "actor_loss": -269.9015406048487, "actor_target_entropy": -6.0, "actor_entropy": 3.4576019862341503, "alpha_loss": -0.0029969356680614135, "alpha_value": 0.0860484264186384, "duration": 131.1373417377472, "step": 61625}
{"episode_reward": 569.9760511262725, "episode": 494.0, "Q1 loss": 10.749875865936279, "Q2 loss": 11.087877532958984, "Mean Target Q": 270.25190771484375, "Mean Q1": 270.2486884765625, "Mean Q2": 270.24961987304687, "critic_loss": 21.83775344848633, "batch_reward": 2.8421828289031983, "actor_loss": -270.78951189594886, "actor_target_entropy": -6.0, "actor_entropy": 3.250984222658219, "alpha_loss": -0.01365365357618899, "alpha_value": 0.08623934163017115, "duration": 145.84226489067078, "step": 61750}
{"episode_reward": 561.4664898573168, "episode": 495.0, "Q1 loss": 9.781550651550292, "Q2 loss": 9.957710693359376, "Mean Target Q": 270.9881652832031, "Mean Q1": 270.9888063964844, "Mean Q2": 270.98652270507813, "critic_loss": 19.739261322021484, "batch_reward": 2.855466655731201, "actor_loss": -271.45568508572046, "actor_target_entropy": -6.0, "actor_entropy": 3.2818578122154114, "alpha_loss": -0.014796821285955726, "alpha_value": 0.0864604635465333, "duration": 142.68884181976318, "step": 61875}
{"episode_reward": 438.08617665827524, "episode": 496.0, "Q1 loss": 10.085866230010986, "Q2 loss": 10.197465282440186, "Mean Target Q": 271.060154296875, "Mean Q1": 271.057521484375, "Mean Q2": 271.0583601074219, "critic_loss": 20.283331588745117, "batch_reward": 2.85508406829834, "actor_loss": -271.75487296811997, "actor_target_entropy": -6.0, "actor_entropy": 3.294261767018226, "alpha_loss": -0.01779741188135719, "alpha_value": 0.08688646697773925, "duration": 124.96778798103333, "step": 62000}
{"episode_reward": 537.1158576140538, "episode": 497.0, "Q1 loss": 8.782417671203614, "Q2 loss": 8.97632795715332, "Mean Target Q": 270.936609375, "Mean Q1": 270.92979174804685, "Mean Q2": 270.931443359375, "critic_loss": 17.758745681762694, "batch_reward": 2.846990322113037, "actor_loss": -271.6388215564546, "actor_target_entropy": -6.0, "actor_entropy": 3.250525538883512, "alpha_loss": -0.013663905088804544, "alpha_value": 0.08728041104975875, "duration": 100.90248823165894, "step": 62125}
{"episode_reward": 552.7096827002422, "episode": 498.0, "Q1 loss": 9.10232751083374, "Q2 loss": 9.070153678894043, "Mean Target Q": 271.1300473632813, "Mean Q1": 271.1292990722656, "Mean Q2": 271.1285549316406, "critic_loss": 18.172481178283693, "batch_reward": 2.8416833515167235, "actor_loss": -271.58727485902847, "actor_target_entropy": -6.0, "actor_entropy": 3.3330103120496197, "alpha_loss": -0.01108651295784981, "alpha_value": 0.08749688348829136, "duration": 87.38515019416809, "step": 62250}
{"episode_reward": 530.2395941932526, "episode": 499.0, "Q1 loss": 8.914426368713379, "Q2 loss": 8.930610916137695, "Mean Target Q": 271.1869118652344, "Mean Q1": 271.1873981933594, "Mean Q2": 271.1851125488281, "critic_loss": 17.845037277221678, "batch_reward": 2.843298635482788, "actor_loss": -271.66819157676093, "actor_target_entropy": -6.0, "actor_entropy": 3.3104287972525945, "alpha_loss": 0.0012879255042958354, "alpha_value": 0.08763016330872822, "duration": 103.3941695690155, "step": 62375}
{"episode_reward": 549.5040595241211, "episode": 500.0, "Q1 loss": 9.795681499481201, "Q2 loss": 9.51440143585205, "Mean Target Q": 271.6590244140625, "Mean Q1": 271.6554709472656, "Mean Q2": 271.6516594238281, "critic_loss": 19.310082916259766, "batch_reward": 2.8574329376220704, "actor_loss": -271.7633755591608, "actor_target_entropy": -6.0, "actor_entropy": 3.3435347080230713, "alpha_loss": -0.002141688785125171, "alpha_value": 0.08758463251531316, "duration": 97.17312026023865, "step": 62500}
{"episode_reward": 492.1781617561087, "episode": 501.0, "Q1 loss": 8.129289821624756, "Q2 loss": 8.32715223312378, "Mean Target Q": 272.22928173828126, "Mean Q1": 272.2299755859375, "Mean Q2": 272.2362375488281, "critic_loss": 16.456442138671875, "batch_reward": 2.857699659347534, "actor_loss": -272.8271988157242, "actor_target_entropy": -6.0, "actor_entropy": 3.264496576218378, "alpha_loss": -0.011559241163056521, "alpha_value": 0.08782066837104151, "duration": 90.4170434474945, "step": 62625}
{"episode_reward": 541.3357762260296, "episode": 502.0, "Q1 loss": 8.434232223510742, "Q2 loss": 8.520109935760498, "Mean Target Q": 272.557658203125, "Mean Q1": 272.5454091796875, "Mean Q2": 272.5461730957031, "critic_loss": 16.954342140197753, "batch_reward": 2.8655986137390137, "actor_loss": -272.7709798505229, "actor_target_entropy": -6.0, "actor_entropy": 3.3367391440176193, "alpha_loss": -0.0046590149192319765, "alpha_value": 0.08796296042603571, "duration": 90.93037152290344, "step": 62750}
{"episode_reward": 506.2604722738087, "episode": 503.0, "Q1 loss": 8.510328773498536, "Q2 loss": 8.449210201263428, "Mean Target Q": 272.8058825683594, "Mean Q1": 272.80672387695313, "Mean Q2": 272.80494946289065, "critic_loss": 16.959539031982423, "batch_reward": 2.8589285945892335, "actor_loss": -273.41400049603175, "actor_target_entropy": -6.0, "actor_entropy": 3.3514617284139, "alpha_loss": -0.016701954283884594, "alpha_value": 0.08823091891118741, "duration": 96.41380739212036, "step": 62875}
{"episode_reward": 565.4139676607621, "episode": 504.0, "Q1 loss": 8.189219699859619, "Q2 loss": 8.194234745025636, "Mean Target Q": 273.20391235351565, "Mean Q1": 273.1992934570313, "Mean Q2": 273.19797412109375, "critic_loss": 16.383454429626465, "batch_reward": 2.880935098648071, "actor_loss": -273.3239056987147, "actor_target_entropy": -6.0, "actor_entropy": 3.282372501588637, "alpha_loss": -0.012243389384821057, "alpha_value": 0.08848068383957826, "duration": 93.62490558624268, "step": 63000}
{"episode_reward": 544.3133409408779, "episode": 505.0, "Q1 loss": 8.282423385620117, "Q2 loss": 8.256313137054443, "Mean Target Q": 272.97831176757813, "Mean Q1": 272.97839672851563, "Mean Q2": 272.9772392578125, "critic_loss": 16.538736488342284, "batch_reward": 2.8710031852722167, "actor_loss": -273.51241871667287, "actor_target_entropy": -6.0, "actor_entropy": 3.335136602795313, "alpha_loss": -0.003972491460098397, "alpha_value": 0.08870463312975971, "duration": 102.99176716804504, "step": 63125}
{"episode_reward": 545.9774932718158, "episode": 506.0, "Q1 loss": 8.54812424468994, "Q2 loss": 8.545097328186035, "Mean Target Q": 274.10000512695314, "Mean Q1": 274.0967180175781, "Mean Q2": 274.0974504394531, "critic_loss": 17.093221488952636, "batch_reward": 2.872183441162109, "actor_loss": -274.47061304892264, "actor_target_entropy": -6.0, "actor_entropy": 3.311794869361385, "alpha_loss": -0.008289906883522147, "alpha_value": 0.08879591827957842, "duration": 97.47134518623352, "step": 63250}
{"episode_reward": 433.04343088801807, "episode": 507.0, "Q1 loss": 8.6104362449646, "Q2 loss": 8.546335010528564, "Mean Target Q": 273.6865185546875, "Mean Q1": 273.68470434570315, "Mean Q2": 273.6873369140625, "critic_loss": 17.156771240234374, "batch_reward": 2.865924585342407, "actor_loss": -274.4542526971726, "actor_target_entropy": -6.0, "actor_entropy": 3.335125684738159, "alpha_loss": -0.011461375964923746, "alpha_value": 0.08907554531961746, "duration": 101.50410580635071, "step": 63375}
{"episode_reward": 437.3384571061295, "episode": 508.0, "Q1 loss": 8.717925121307372, "Q2 loss": 8.619766231536865, "Mean Target Q": 274.37994873046875, "Mean Q1": 274.37688671875, "Mean Q2": 274.37654638671876, "critic_loss": 17.337691329956055, "batch_reward": 2.8761300830841066, "actor_loss": -274.65687610257055, "actor_target_entropy": -6.0, "actor_entropy": 3.4095887176452147, "alpha_loss": -0.01904074029035626, "alpha_value": 0.0894215013803034, "duration": 127.65262007713318, "step": 63500}
{"episode_reward": 553.7583390303416, "episode": 509.0, "Q1 loss": 9.283575366973876, "Q2 loss": 9.344388065338135, "Mean Target Q": 274.92231787109375, "Mean Q1": 274.91893359375, "Mean Q2": 274.9181884765625, "critic_loss": 18.627963500976563, "batch_reward": 2.888351999282837, "actor_loss": -275.1995185973152, "actor_target_entropy": -6.0, "actor_entropy": 3.362506071726481, "alpha_loss": -0.007931311862424963, "alpha_value": 0.08971851869812399, "duration": 115.89607238769531, "step": 63625}
{"episode_reward": 399.89085314311615, "episode": 510.0, "Q1 loss": 10.565632961273193, "Q2 loss": 10.293840766906738, "Mean Target Q": 274.67726977539064, "Mean Q1": 274.67449462890625, "Mean Q2": 274.67732275390625, "critic_loss": 20.85947370147705, "batch_reward": 2.876529317855835, "actor_loss": -274.8783411825857, "actor_target_entropy": -6.0, "actor_entropy": 3.499892246338629, "alpha_loss": -0.019151597554164547, "alpha_value": 0.09007906112578917, "duration": 92.6326630115509, "step": 63750}
{"episode_reward": 517.1612805777803, "episode": 511.0, "Q1 loss": 9.530431419372558, "Q2 loss": 9.280158416748048, "Mean Target Q": 274.3460432128906, "Mean Q1": 274.34409741210936, "Mean Q2": 274.343263671875, "critic_loss": 18.810589836120606, "batch_reward": 2.8762950019836424, "actor_loss": -274.6260477701823, "actor_target_entropy": -6.0, "actor_entropy": 3.412021462879484, "alpha_loss": -0.011207021048499478, "alpha_value": 0.0903868444252506, "duration": 92.88345289230347, "step": 63875}
{"episode_reward": 494.62194232556703, "episode": 512.0, "Q1 loss": 9.962747619628907, "Q2 loss": 9.942339462280273, "Mean Target Q": 275.2799326171875, "Mean Q1": 275.2821159667969, "Mean Q2": 275.2827355957031, "critic_loss": 19.905087089538576, "batch_reward": 2.886082983016968, "actor_loss": -275.90804561491933, "actor_target_entropy": -6.0, "actor_entropy": 3.437785760048897, "alpha_loss": -0.004567720694467425, "alpha_value": 0.09050769009314136, "duration": 87.55378413200378, "step": 64000}
{"episode_reward": 514.7341825565875, "episode": 513.0, "Q1 loss": 9.182725894927978, "Q2 loss": 9.24407417678833, "Mean Target Q": 275.401380859375, "Mean Q1": 275.39335595703125, "Mean Q2": 275.39014892578126, "critic_loss": 18.426800010681152, "batch_reward": 2.8869331569671632, "actor_loss": -275.7259245372954, "actor_target_entropy": -6.0, "actor_entropy": 3.3286313783554804, "alpha_loss": -0.018260956039681794, "alpha_value": 0.09083307497699182, "duration": 125.21649265289307, "step": 64125}
{"episode_reward": 519.9665101305583, "episode": 514.0, "Q1 loss": 8.487032344818115, "Q2 loss": 8.500212482452392, "Mean Target Q": 275.67237060546876, "Mean Q1": 275.668923828125, "Mean Q2": 275.67069506835935, "critic_loss": 16.987244773864745, "batch_reward": 2.889477373123169, "actor_loss": -276.06751029722153, "actor_target_entropy": -6.0, "actor_entropy": 3.3005037730739963, "alpha_loss": 0.006202868490119374, "alpha_value": 0.09090410388328118, "duration": 131.1194303035736, "step": 64250}
{"episode_reward": 459.8600702163869, "episode": 515.0, "Q1 loss": 8.803881996154786, "Q2 loss": 8.671776084899902, "Mean Target Q": 275.841681640625, "Mean Q1": 275.84504858398435, "Mean Q2": 275.84368896484375, "critic_loss": 17.47565821838379, "batch_reward": 2.899181463241577, "actor_loss": -276.1686207604787, "actor_target_entropy": -6.0, "actor_entropy": 3.357064163874066, "alpha_loss": 0.003198484683202373, "alpha_value": 0.09090860848512428, "duration": 135.58337497711182, "step": 64375}
{"episode_reward": 520.1179438357367, "episode": 516.0, "Q1 loss": 8.611126762390137, "Q2 loss": 8.656651004791259, "Mean Target Q": 276.11783862304685, "Mean Q1": 276.1131166992187, "Mean Q2": 276.1090354003906, "critic_loss": 17.267777770996094, "batch_reward": 2.8845217208862306, "actor_loss": -276.2843819895098, "actor_target_entropy": -6.0, "actor_entropy": 3.3235024021517847, "alpha_loss": -0.0017653009328510493, "alpha_value": 0.09085712045740701, "duration": 122.67780756950378, "step": 64500}
{"episode_reward": 529.1222755480969, "episode": 517.0, "Q1 loss": 7.357652179718017, "Q2 loss": 7.369899520874023, "Mean Target Q": 276.49172509765623, "Mean Q1": 276.4896228027344, "Mean Q2": 276.492765625, "critic_loss": 14.727551727294921, "batch_reward": 2.885693542480469, "actor_loss": -276.6505422440786, "actor_target_entropy": -6.0, "actor_entropy": 3.336786429087321, "alpha_loss": 0.0021898491485487846, "alpha_value": 0.09087870983992005, "duration": 103.87866425514221, "step": 64625}
{"episode_reward": 511.9290094421187, "episode": 518.0, "Q1 loss": 7.9206125411987305, "Q2 loss": 7.8708932495117185, "Mean Target Q": 277.47668725585936, "Mean Q1": 277.47567797851565, "Mean Q2": 277.47360961914063, "critic_loss": 15.791505798339843, "batch_reward": 2.9111656436920166, "actor_loss": -278.08753327400456, "actor_target_entropy": -6.0, "actor_entropy": 3.212305288161001, "alpha_loss": 0.007617445846628998, "alpha_value": 0.0907186948434947, "duration": 115.45745277404785, "step": 64750}
{"episode_reward": 513.1819642847664, "episode": 519.0, "Q1 loss": 7.742416313171387, "Q2 loss": 7.513402030944825, "Mean Target Q": 277.3297712402344, "Mean Q1": 277.33127368164065, "Mean Q2": 277.33126904296876, "critic_loss": 15.255818367004395, "batch_reward": 2.898688024520874, "actor_loss": -277.6983913845486, "actor_target_entropy": -6.0, "actor_entropy": 3.306935541213505, "alpha_loss": 0.003862842248516187, "alpha_value": 0.09054509386420138, "duration": 139.8938136100769, "step": 64875}
{"episode_reward": 506.9982231430557, "episode": 520.0, "Q1 loss": 8.543213062286377, "Q2 loss": 8.51748017501831, "Mean Target Q": 277.6998193359375, "Mean Q1": 277.6921120605469, "Mean Q2": 277.6936828613281, "critic_loss": 17.06069319152832, "batch_reward": 2.9048568077087404, "actor_loss": -277.91024829495336, "actor_target_entropy": -6.0, "actor_entropy": 3.3150925597836896, "alpha_loss": 0.012348187561597555, "alpha_value": 0.09045464489573975, "step": 65000}
{"duration": 118.14319276809692, "step": 65000}
{"episode_reward": 439.27096326005136, "episode": 521.0, "Q1 loss": 8.415822092056274, "Q2 loss": 8.483179960250855, "Mean Target Q": 278.08620629882813, "Mean Q1": 278.0856928710937, "Mean Q2": 278.0831042480469, "critic_loss": 16.899002044677733, "batch_reward": 2.9034152698516844, "actor_loss": -278.6513933454241, "actor_target_entropy": -6.0, "actor_entropy": 3.287656515363663, "alpha_loss": 0.0032029113665755305, "alpha_value": 0.09024675158639787, "duration": 122.8214967250824, "step": 65125}
{"episode_reward": 528.383391015799, "episode": 522.0, "Q1 loss": 7.973472610473633, "Q2 loss": 7.996423324584961, "Mean Target Q": 277.99130786132815, "Mean Q1": 277.99167724609373, "Mean Q2": 277.99533251953125, "critic_loss": 15.969895965576171, "batch_reward": 2.9068720321655275, "actor_loss": -278.2858719364289, "actor_target_entropy": -6.0, "actor_entropy": 3.2697728257025442, "alpha_loss": -0.00169058253372749, "alpha_value": 0.09017993026223377, "duration": 72.45562744140625, "step": 65250}
{"episode_reward": 516.1628270740598, "episode": 523.0, "Q1 loss": 8.187034324645996, "Q2 loss": 8.252373832702636, "Mean Target Q": 278.7015107421875, "Mean Q1": 278.69593603515625, "Mean Q2": 278.6921860351562, "critic_loss": 16.439408210754394, "batch_reward": 2.917727849960327, "actor_loss": -278.8507593548487, "actor_target_entropy": -6.0, "actor_entropy": 3.2525446150037975, "alpha_loss": -0.002313092469222962, "alpha_value": 0.09025117926433697, "duration": 69.45447754859924, "step": 65375}
{"episode_reward": 516.4370510642797, "episode": 524.0, "Q1 loss": 7.941384189605713, "Q2 loss": 7.906135131835938, "Mean Target Q": 278.78171557617185, "Mean Q1": 278.7778759765625, "Mean Q2": 278.77995654296876, "critic_loss": 15.847519317626952, "batch_reward": 2.915927724838257, "actor_loss": -279.03583600444176, "actor_target_entropy": -6.0, "actor_entropy": 3.35022844037702, "alpha_loss": 0.009121676884411324, "alpha_value": 0.0901203276169692, "duration": 76.7659502029419, "step": 65500}
{"episode_reward": 499.24112418095973, "episode": 525.0, "Q1 loss": 8.382098785400391, "Q2 loss": 8.421501220703124, "Mean Target Q": 279.107048828125, "Mean Q1": 279.10649682617185, "Mean Q2": 279.1087763671875, "critic_loss": 16.80359999847412, "batch_reward": 2.911644878387451, "actor_loss": -279.3511434888083, "actor_target_entropy": -6.0, "actor_entropy": 3.346107872705611, "alpha_loss": -0.0034340362079323286, "alpha_value": 0.09006674606488735, "duration": 76.88501191139221, "step": 65625}
{"episode_reward": 494.2183617978411, "episode": 526.0, "Q1 loss": 7.710260711669922, "Q2 loss": 7.555229679107666, "Mean Target Q": 279.3724792480469, "Mean Q1": 279.36808618164065, "Mean Q2": 279.36587329101565, "critic_loss": 15.26549040222168, "batch_reward": 2.918403594970703, "actor_loss": -279.7103497905116, "actor_target_entropy": -6.0, "actor_entropy": 3.374046333374516, "alpha_loss": -0.015153162046185425, "alpha_value": 0.09031135745505739, "duration": 107.13126516342163, "step": 65750}
{"episode_reward": 510.5532856353255, "episode": 527.0, "Q1 loss": 7.527554218292236, "Q2 loss": 7.5455320396423335, "Mean Target Q": 279.81077758789064, "Mean Q1": 279.81167456054686, "Mean Q2": 279.8100529785156, "critic_loss": 15.073086242675782, "batch_reward": 2.91452799987793, "actor_loss": -280.26148671952507, "actor_target_entropy": -6.0, "actor_entropy": 3.341397009198628, "alpha_loss": 0.002687141280769119, "alpha_value": 0.09043197805173307, "duration": 134.57353019714355, "step": 65875}
{"episode_reward": 495.32797634946985, "episode": 528.0, "Q1 loss": 7.833295764923096, "Q2 loss": 7.983064846038818, "Mean Target Q": 279.8761469726563, "Mean Q1": 279.87140625, "Mean Q2": 279.87550268554685, "critic_loss": 15.816360656738281, "batch_reward": 2.9154703254699705, "actor_loss": -280.51234879032256, "actor_target_entropy": -6.0, "actor_entropy": 3.249253584492591, "alpha_loss": 0.0008953442804575447, "alpha_value": 0.09038857112559422, "duration": 133.52844643592834, "step": 66000}
{"episode_reward": 494.4095057923104, "episode": 529.0, "Q1 loss": 8.269909870147705, "Q2 loss": 8.124276695251465, "Mean Target Q": 279.76278125, "Mean Q1": 279.76277319335935, "Mean Q2": 279.7617141113281, "critic_loss": 16.394186553955077, "batch_reward": 2.9115750370025633, "actor_loss": -280.5034794883123, "actor_target_entropy": -6.0, "actor_entropy": 3.307236565483941, "alpha_loss": -0.00381233773401214, "alpha_value": 0.09042781060199716, "duration": 113.898934841156, "step": 66125}
{"episode_reward": 523.0324731942997, "episode": 530.0, "Q1 loss": 8.22254670715332, "Q2 loss": 7.9986575355529785, "Mean Target Q": 280.1654443359375, "Mean Q1": 280.1607661132812, "Mean Q2": 280.1616467285156, "critic_loss": 16.221204223632814, "batch_reward": 2.917820999145508, "actor_loss": -280.742421304026, "actor_target_entropy": -6.0, "actor_entropy": 3.305473869846713, "alpha_loss": -0.01338712321293931, "alpha_value": 0.09068387058015742, "duration": 112.30100703239441, "step": 66250}
{"episode_reward": 537.7067258481645, "episode": 531.0, "Q1 loss": 7.7410684509277345, "Q2 loss": 7.794294746398926, "Mean Target Q": 280.1923771972656, "Mean Q1": 280.19401513671875, "Mean Q2": 280.1886350097656, "critic_loss": 15.53536321258545, "batch_reward": 2.9174276866912843, "actor_loss": -280.4230211046007, "actor_target_entropy": -6.0, "actor_entropy": 3.3446633626544284, "alpha_loss": -0.012785749247534171, "alpha_value": 0.09098913703008142, "duration": 100.65968251228333, "step": 66375}
{"episode_reward": 526.8536925276875, "episode": 532.0, "Q1 loss": 7.816814613342285, "Q2 loss": 8.133063796997071, "Mean Target Q": 281.10138330078127, "Mean Q1": 281.09610791015626, "Mean Q2": 281.1003688964844, "critic_loss": 15.949878410339355, "batch_reward": 2.92824112701416, "actor_loss": -281.7177586709299, "actor_target_entropy": -6.0, "actor_entropy": 3.274721837812854, "alpha_loss": -0.007140160297914859, "alpha_value": 0.09125958932372717, "duration": 75.67540240287781, "step": 66500}
{"episode_reward": 474.68388385339125, "episode": 533.0, "Q1 loss": 7.595672706604004, "Q2 loss": 7.671781337738037, "Mean Target Q": 280.8085412597656, "Mean Q1": 280.8066096191406, "Mean Q2": 280.80724658203127, "critic_loss": 15.267453994750976, "batch_reward": 2.9214428482055665, "actor_loss": -280.8982655358693, "actor_target_entropy": -6.0, "actor_entropy": 3.3339005046420627, "alpha_loss": -0.00843225459065584, "alpha_value": 0.09136195574617861, "duration": 94.68824124336243, "step": 66625}
{"episode_reward": 514.7424160275035, "episode": 534.0, "Q1 loss": 8.11251011276245, "Q2 loss": 8.146615818023681, "Mean Target Q": 281.0580744628906, "Mean Q1": 281.05694775390623, "Mean Q2": 281.05649267578127, "critic_loss": 16.259125968933105, "batch_reward": 2.9200769805908204, "actor_loss": -281.4214895925214, "actor_target_entropy": -6.0, "actor_entropy": 3.307247369520126, "alpha_loss": -0.0037339055617790547, "alpha_value": 0.09151609113125267, "duration": 116.5088791847229, "step": 66750}
{"episode_reward": 528.3466488992643, "episode": 535.0, "Q1 loss": 7.323981231689453, "Q2 loss": 7.278307037353516, "Mean Target Q": 281.68102685546876, "Mean Q1": 281.68092065429687, "Mean Q2": 281.68000927734374, "critic_loss": 14.602288299560547, "batch_reward": 2.9416010341644285, "actor_loss": -281.8262474423363, "actor_target_entropy": -6.0, "actor_entropy": 3.3454215375203935, "alpha_loss": 0.0004185202221075694, "alpha_value": 0.09158232631436841, "duration": 122.22206687927246, "step": 66875}
{"episode_reward": 503.00939661194275, "episode": 536.0, "Q1 loss": 7.1806333580017085, "Q2 loss": 7.133728034973145, "Mean Target Q": 281.9487944335938, "Mean Q1": 281.9449182128906, "Mean Q2": 281.9449724121094, "critic_loss": 14.314361434936524, "batch_reward": 2.9290599822998047, "actor_loss": -282.40074994487145, "actor_target_entropy": -6.0, "actor_entropy": 3.369341919499059, "alpha_loss": -0.007067451336150689, "alpha_value": 0.09161889187175777, "duration": 119.37920618057251, "step": 67000}
{"episode_reward": 556.541967466349, "episode": 537.0, "Q1 loss": 7.116512889862061, "Q2 loss": 7.226210983276367, "Mean Target Q": 282.444482421875, "Mean Q1": 282.4482800292969, "Mean Q2": 282.4463161621094, "critic_loss": 14.342723899841308, "batch_reward": 2.9464603633880615, "actor_loss": -282.7371109250992, "actor_target_entropy": -6.0, "actor_entropy": 3.343986908594767, "alpha_loss": -0.0079584346810681, "alpha_value": 0.091794604022595, "duration": 132.38689255714417, "step": 67125}
{"episode_reward": 514.847569115657, "episode": 538.0, "Q1 loss": 7.913604290008545, "Q2 loss": 7.81416947555542, "Mean Target Q": 282.1081071777344, "Mean Q1": 282.100240234375, "Mean Q2": 282.10192114257814, "critic_loss": 15.727773811340333, "batch_reward": 2.938381996154785, "actor_loss": -281.9756046418221, "actor_target_entropy": -6.0, "actor_entropy": 3.349842629125041, "alpha_loss": -0.00401083528319554, "alpha_value": 0.09198211879239174, "duration": 132.23883724212646, "step": 67250}
{"episode_reward": 537.057914259044, "episode": 539.0, "Q1 loss": 7.342828411102295, "Q2 loss": 7.516415496826172, "Mean Target Q": 283.133392578125, "Mean Q1": 283.13136694335935, "Mean Q2": 283.13166845703125, "critic_loss": 14.859243843078612, "batch_reward": 2.950353406906128, "actor_loss": -283.49780709402904, "actor_target_entropy": -6.0, "actor_entropy": 3.377365138795641, "alpha_loss": -0.00755061563991365, "alpha_value": 0.09212544147582237, "duration": 141.91736030578613, "step": 67375}
{"episode_reward": 515.2972120606631, "episode": 540.0, "Q1 loss": 7.883332504272461, "Q2 loss": 7.895621421813964, "Mean Target Q": 282.79565649414064, "Mean Q1": 282.78767504882813, "Mean Q2": 282.78863549804686, "critic_loss": 15.778953956604004, "batch_reward": 2.9452710266113282, "actor_loss": -282.9213685066469, "actor_target_entropy": -6.0, "actor_entropy": 3.306394857745017, "alpha_loss": -0.00665121432018256, "alpha_value": 0.09231398643165842, "duration": 127.85363054275513, "step": 67500}
{"episode_reward": 487.67372118739644, "episode": 541.0, "Q1 loss": 8.165701755523681, "Q2 loss": 8.170092208862304, "Mean Target Q": 283.1311708984375, "Mean Q1": 283.1311950683594, "Mean Q2": 283.1315241699219, "critic_loss": 16.33579396057129, "batch_reward": 2.939533250808716, "actor_loss": -283.1224607437376, "actor_target_entropy": -6.0, "actor_entropy": 3.34391028540475, "alpha_loss": 0.000909505777859262, "alpha_value": 0.09239452791911383, "duration": 72.11801528930664, "step": 67625}
{"episode_reward": 487.4479417630346, "episode": 542.0, "Q1 loss": 6.891223567962647, "Q2 loss": 6.913065628051758, "Mean Target Q": 283.7705322265625, "Mean Q1": 283.7714453125, "Mean Q2": 283.77180590820313, "critic_loss": 13.804289260864257, "batch_reward": 2.947298173904419, "actor_loss": -284.07415574596774, "actor_target_entropy": -6.0, "actor_entropy": 3.395604310497161, "alpha_loss": 0.005723077514689536, "alpha_value": 0.0922697222126151, "duration": 65.76123666763306, "step": 67750}
{"episode_reward": 512.8738945247991, "episode": 543.0, "Q1 loss": 8.28981105041504, "Q2 loss": 8.268404258728028, "Mean Target Q": 283.3238952636719, "Mean Q1": 283.32087646484376, "Mean Q2": 283.32071142578127, "critic_loss": 16.558215301513673, "batch_reward": 2.9458802394866943, "actor_loss": -283.6804795038132, "actor_target_entropy": -6.0, "actor_entropy": 3.3729186966305686, "alpha_loss": 0.013280867059375085, "alpha_value": 0.09206145171748883, "duration": 72.99827647209167, "step": 67875}
{"episode_reward": 533.4925445915329, "episode": 544.0, "Q1 loss": 8.534167335510254, "Q2 loss": 8.395982223510742, "Mean Target Q": 283.9313742675781, "Mean Q1": 283.9325158691406, "Mean Q2": 283.9342521972656, "critic_loss": 16.93014959716797, "batch_reward": 2.9566172409057616, "actor_loss": -284.46743725192164, "actor_target_entropy": -6.0, "actor_entropy": 3.309942772311549, "alpha_loss": -0.005536781999492838, "alpha_value": 0.09195856320020689, "duration": 75.60215067863464, "step": 68000}
{"episode_reward": 524.9212703411965, "episode": 545.0, "Q1 loss": 9.064001289367676, "Q2 loss": 8.898064739227294, "Mean Target Q": 284.362994140625, "Mean Q1": 284.359009765625, "Mean Q2": 284.35572998046877, "critic_loss": 17.96206600189209, "batch_reward": 2.9562850856781004, "actor_loss": -284.3842308407738, "actor_target_entropy": -6.0, "actor_entropy": 3.3296376561361645, "alpha_loss": -0.0005580556157621599, "alpha_value": 0.09199220629549282, "duration": 70.67047882080078, "step": 68125}
{"episode_reward": 61.65244984626109, "episode": 546.0, "Q1 loss": 7.93676095199585, "Q2 loss": 8.061910625457763, "Mean Target Q": 283.94321801757815, "Mean Q1": 283.93704052734375, "Mean Q2": 283.938830078125, "critic_loss": 15.998671562194824, "batch_reward": 2.9455158023834227, "actor_loss": -283.8376927529612, "actor_target_entropy": -6.0, "actor_entropy": 3.3276290432099374, "alpha_loss": 0.009606256393805867, "alpha_value": 0.0918928577504716, "duration": 96.59899687767029, "step": 68250}
{"episode_reward": 108.13457010748066, "episode": 547.0, "Q1 loss": 8.776809707641602, "Q2 loss": 8.734871784210204, "Mean Target Q": 283.8151240234375, "Mean Q1": 283.8176162109375, "Mean Q2": 283.8173461914063, "critic_loss": 17.511681495666505, "batch_reward": 2.9417033882141115, "actor_loss": -284.0081864614335, "actor_target_entropy": -6.0, "actor_entropy": 3.3955674814799477, "alpha_loss": -0.009124370683575906, "alpha_value": 0.09188895624770138, "duration": 118.74735879898071, "step": 68375}
{"episode_reward": 526.9164992753838, "episode": 548.0, "Q1 loss": 9.928590003967285, "Q2 loss": 10.101711406707764, "Mean Target Q": 284.4215087890625, "Mean Q1": 284.4248000488281, "Mean Q2": 284.4253388671875, "critic_loss": 20.030301429748537, "batch_reward": 2.947345371246338, "actor_loss": -284.4062706731981, "actor_target_entropy": -6.0, "actor_entropy": 3.396000296838822, "alpha_loss": -0.010355541377418464, "alpha_value": 0.0921650628968201, "duration": 81.95611214637756, "step": 68500}
{"episode_reward": 536.0383347516338, "episode": 549.0, "Q1 loss": 10.475643054962159, "Q2 loss": 10.311483600616455, "Mean Target Q": 284.75389331054686, "Mean Q1": 284.7448684082031, "Mean Q2": 284.7456330566406, "critic_loss": 20.787126678466798, "batch_reward": 2.9512198371887206, "actor_loss": -284.82190086728053, "actor_target_entropy": -6.0, "actor_entropy": 3.3479564341287764, "alpha_loss": -0.0006920850599214198, "alpha_value": 0.09224574178145596, "duration": 75.1585762500763, "step": 68625}
{"episode_reward": 454.1538032368817, "episode": 550.0, "Q1 loss": 9.496686897277833, "Q2 loss": 9.424255439758301, "Mean Target Q": 284.42615380859377, "Mean Q1": 284.42478173828124, "Mean Q2": 284.4226511230469, "critic_loss": 18.920942337036134, "batch_reward": 2.9575168724060057, "actor_loss": -284.9429178545552, "actor_target_entropy": -6.0, "actor_entropy": 3.3264543356433993, "alpha_loss": 0.0001309173549675653, "alpha_value": 0.09227891052781628, "duration": 104.57336449623108, "step": 68750}
{"episode_reward": 503.80648757981055, "episode": 551.0, "Q1 loss": 8.886768657684327, "Q2 loss": 8.822878704071044, "Mean Target Q": 284.7343017578125, "Mean Q1": 284.7258093261719, "Mean Q2": 284.72760595703124, "critic_loss": 17.709647415161132, "batch_reward": 2.9465294857025146, "actor_loss": -285.06463332403274, "actor_target_entropy": -6.0, "actor_entropy": 3.4030665140303356, "alpha_loss": 0.007722069176712206, "alpha_value": 0.092238598576262, "duration": 122.15013933181763, "step": 68875}
{"episode_reward": 470.4545018761739, "episode": 552.0, "Q1 loss": 8.51724382019043, "Q2 loss": 8.57710012435913, "Mean Target Q": 284.843111328125, "Mean Q1": 284.8484104003906, "Mean Q2": 284.84797265625, "critic_loss": 17.09434393310547, "batch_reward": 2.959967025756836, "actor_loss": -284.69698456794987, "actor_target_entropy": -6.0, "actor_entropy": 3.2803086003949566, "alpha_loss": 0.015907203080132604, "alpha_value": 0.0918626719871514, "duration": 89.76462721824646, "step": 69000}
{"episode_reward": 557.6166732034933, "episode": 553.0, "Q1 loss": 8.82412978363037, "Q2 loss": 8.899618034362794, "Mean Target Q": 285.24116943359377, "Mean Q1": 285.2416879882812, "Mean Q2": 285.2412797851562, "critic_loss": 17.723747779846192, "batch_reward": 2.960270299911499, "actor_loss": -285.39261736188615, "actor_target_entropy": -6.0, "actor_entropy": 3.2774831453959146, "alpha_loss": 0.0043710895207902745, "alpha_value": 0.09164493057891063, "duration": 67.57911515235901, "step": 69125}
{"episode_reward": 502.0130859020197, "episode": 554.0, "Q1 loss": 8.643015628814696, "Q2 loss": 8.603097785949707, "Mean Target Q": 285.8539794921875, "Mean Q1": 285.8525769042969, "Mean Q2": 285.85024291992187, "critic_loss": 17.246113441467283, "batch_reward": 2.9628586082458495, "actor_loss": -285.9981694375315, "actor_target_entropy": -6.0, "actor_entropy": 3.3116027078320904, "alpha_loss": 0.004245284024716144, "alpha_value": 0.09154389683469405, "duration": 74.07199287414551, "step": 69250}
{"episode_reward": 523.1703934810396, "episode": 555.0, "Q1 loss": 9.003100917816163, "Q2 loss": 9.11132964706421, "Mean Target Q": 285.8192778320313, "Mean Q1": 285.8120852050781, "Mean Q2": 285.81259423828124, "critic_loss": 18.114430564880372, "batch_reward": 2.9558521728515625, "actor_loss": -286.2593059237041, "actor_target_entropy": -6.0, "actor_entropy": 3.295750629334223, "alpha_loss": 0.003201025811630109, "alpha_value": 0.09142273341101502, "duration": 71.65869760513306, "step": 69375}
{"episode_reward": 499.6711752986149, "episode": 556.0, "Q1 loss": 9.545025115966796, "Q2 loss": 9.471629734039306, "Mean Target Q": 286.1155087890625, "Mean Q1": 286.1158173828125, "Mean Q2": 286.1175012207031, "critic_loss": 19.01665496826172, "batch_reward": 2.96632204246521, "actor_loss": -286.3224787558279, "actor_target_entropy": -6.0, "actor_entropy": 3.353695211871978, "alpha_loss": -0.0003549911367196229, "alpha_value": 0.09141337535805817, "duration": 69.36527061462402, "step": 69500}
{"episode_reward": 502.17992704937467, "episode": 557.0, "Q1 loss": 9.246329658508301, "Q2 loss": 9.32708433151245, "Mean Target Q": 285.96302465820315, "Mean Q1": 285.9621748046875, "Mean Q2": 285.96044116210936, "critic_loss": 18.573413993835448, "batch_reward": 2.9669064502716065, "actor_loss": -286.2350308857267, "actor_target_entropy": -6.0, "actor_entropy": 3.2819408386472673, "alpha_loss": 0.012384754291454714, "alpha_value": 0.0912472238047231, "duration": 103.16283941268921, "step": 69625}
{"episode_reward": 510.27763366045605, "episode": 558.0, "Q1 loss": 9.207549388885498, "Q2 loss": 9.248451602935791, "Mean Target Q": 286.24420068359376, "Mean Q1": 286.2423562011719, "Mean Q2": 286.2432375488281, "critic_loss": 18.456001083374023, "batch_reward": 2.9617061004638674, "actor_loss": -286.4636732532132, "actor_target_entropy": -6.0, "actor_entropy": 3.3331092249962593, "alpha_loss": 0.012305481385649932, "alpha_value": 0.09100501273772207, "duration": 124.76899409294128, "step": 69750}
{"episode_reward": 552.9216849143779, "episode": 559.0, "Q1 loss": 8.697269157409668, "Q2 loss": 8.794044406890869, "Mean Target Q": 286.3800949707031, "Mean Q1": 286.3798659667969, "Mean Q2": 286.37696118164064, "critic_loss": 17.491313484191895, "batch_reward": 2.968015392303467, "actor_loss": -286.6211702861483, "actor_target_entropy": -6.0, "actor_entropy": 3.3448059029049344, "alpha_loss": 0.009995017318971573, "alpha_value": 0.09064696949176615, "duration": 92.26692867279053, "step": 69875}
{"episode_reward": 552.5149073908984, "episode": 560.0, "Q1 loss": 8.148732563018799, "Q2 loss": 8.216046867370606, "Mean Target Q": 287.3082587890625, "Mean Q1": 287.31012475585936, "Mean Q2": 287.30886743164064, "critic_loss": 16.36477941131592, "batch_reward": 2.9785282096862793, "actor_loss": -287.5248176820817, "actor_target_entropy": -6.0, "actor_entropy": 3.278638908939977, "alpha_loss": 0.0068996986599578975, "alpha_value": 0.09052024225489488, "step": 70000}
{"duration": 123.7701895236969, "step": 70000}
{"episode_reward": 558.4355027024059, "episode": 561.0, "Q1 loss": 9.379499622344971, "Q2 loss": 9.203115226745606, "Mean Target Q": 287.5390786132813, "Mean Q1": 287.53178833007814, "Mean Q2": 287.5348681640625, "critic_loss": 18.582614944458008, "batch_reward": 2.984723690032959, "actor_loss": -287.57323879665796, "actor_target_entropy": -6.0, "actor_entropy": 3.346968541069636, "alpha_loss": 0.001760948903947359, "alpha_value": 0.09047651374230334, "duration": 150.64352464675903, "step": 70125}
{"episode_reward": 524.2523652765094, "episode": 562.0, "Q1 loss": 8.871956859588623, "Q2 loss": 8.954928810119629, "Mean Target Q": 287.43508056640627, "Mean Q1": 287.43367602539064, "Mean Q2": 287.434908203125, "critic_loss": 17.826885597229005, "batch_reward": 2.9846451988220215, "actor_loss": -287.4825675718246, "actor_target_entropy": -6.0, "actor_entropy": 3.3114881169411445, "alpha_loss": -0.010618707420484673, "alpha_value": 0.09050678342541454, "duration": 88.3141348361969, "step": 70250}
{"episode_reward": 548.141111929049, "episode": 563.0, "Q1 loss": 8.404790542602539, "Q2 loss": 8.570576755523682, "Mean Target Q": 287.8939897460937, "Mean Q1": 287.89278076171877, "Mean Q2": 287.89113842773435, "critic_loss": 16.975367248535157, "batch_reward": 2.989741106033325, "actor_loss": -288.0260305253286, "actor_target_entropy": -6.0, "actor_entropy": 3.348600913607885, "alpha_loss": 0.0037913784857780213, "alpha_value": 0.09060823447841986, "duration": 117.11470413208008, "step": 70375}
{"episode_reward": 524.7153517234873, "episode": 564.0, "Q1 loss": 8.049100452423096, "Q2 loss": 8.143360866546631, "Mean Target Q": 288.09406079101564, "Mean Q1": 288.09268481445315, "Mean Q2": 288.08798901367186, "critic_loss": 16.192461288452147, "batch_reward": 2.979499029159546, "actor_loss": -288.5746061263546, "actor_target_entropy": -6.0, "actor_entropy": 3.3595045343522103, "alpha_loss": -0.009516530016797685, "alpha_value": 0.09064977623269818, "duration": 115.9581983089447, "step": 70500}
{"episode_reward": 532.2353927503673, "episode": 565.0, "Q1 loss": 8.105128196716308, "Q2 loss": 8.337621284484863, "Mean Target Q": 287.80587426757813, "Mean Q1": 287.8004047851563, "Mean Q2": 287.8065456542969, "critic_loss": 16.44274952697754, "batch_reward": 2.984338241577148, "actor_loss": -288.5972415984623, "actor_target_entropy": -6.0, "actor_entropy": 3.34309811062283, "alpha_loss": -0.00020880657913429395, "alpha_value": 0.0908127029168442, "duration": 68.42188167572021, "step": 70625}
{"episode_reward": 497.12816977453105, "episode": 566.0, "Q1 loss": 9.271148796081542, "Q2 loss": 9.151538803100586, "Mean Target Q": 288.43767138671876, "Mean Q1": 288.4357919921875, "Mean Q2": 288.4371760253906, "critic_loss": 18.422687698364257, "batch_reward": 2.9922495346069335, "actor_loss": -289.10437750047254, "actor_target_entropy": -6.0, "actor_entropy": 3.275494590882332, "alpha_loss": 0.0016756581683312693, "alpha_value": 0.09081727829787836, "duration": 69.55531120300293, "step": 70750}
{"episode_reward": 515.03953921702, "episode": 567.0, "Q1 loss": 8.624689182281495, "Q2 loss": 8.621520252227784, "Mean Target Q": 288.9882717285156, "Mean Q1": 288.9880173339844, "Mean Q2": 288.9857985839844, "critic_loss": 17.24620948791504, "batch_reward": 3.001101385116577, "actor_loss": -289.35755411783856, "actor_target_entropy": -6.0, "actor_entropy": 3.347809015758454, "alpha_loss": -0.009435680391828693, "alpha_value": 0.09091836252755217, "duration": 104.72490215301514, "step": 70875}
{"episode_reward": 523.1698215422879, "episode": 568.0, "Q1 loss": 7.964920246124268, "Q2 loss": 7.7967686882019045, "Mean Target Q": 289.401076171875, "Mean Q1": 289.4020141601562, "Mean Q2": 289.4030114746094, "critic_loss": 15.761688972473145, "batch_reward": 2.9883024997711183, "actor_loss": -289.2659926875945, "actor_target_entropy": -6.0, "actor_entropy": 3.3239625461639895, "alpha_loss": 0.0015051725410646008, "alpha_value": 0.09102900249678512, "duration": 116.61150646209717, "step": 71000}
{"episode_reward": 469.55708093551243, "episode": 569.0, "Q1 loss": 7.83377751159668, "Q2 loss": 7.837311218261719, "Mean Target Q": 289.37140502929685, "Mean Q1": 289.36778979492186, "Mean Q2": 289.3640563964844, "critic_loss": 15.671088790893554, "batch_reward": 2.9912485065460204, "actor_loss": -289.4046877906436, "actor_target_entropy": -6.0, "actor_entropy": 3.337160515406775, "alpha_loss": 0.001733882145749198, "alpha_value": 0.09092722887233312, "duration": 79.0416898727417, "step": 71125}
{"episode_reward": 540.4035231169034, "episode": 570.0, "Q1 loss": 8.49279146194458, "Q2 loss": 8.14372589111328, "Mean Target Q": 289.30917041015624, "Mean Q1": 289.30426586914064, "Mean Q2": 289.30881372070314, "critic_loss": 16.63651741027832, "batch_reward": 2.990546899795532, "actor_loss": -289.40294327274444, "actor_target_entropy": -6.0, "actor_entropy": 3.299036183664876, "alpha_loss": 0.0027296754621690318, "alpha_value": 0.09084038443286775, "duration": 80.66177558898926, "step": 71250}
{"episode_reward": 490.24305608876546, "episode": 571.0, "Q1 loss": 7.734811782836914, "Q2 loss": 7.750676338195801, "Mean Target Q": 289.3860598144531, "Mean Q1": 289.3900041503906, "Mean Q2": 289.3871896972656, "critic_loss": 15.485488128662109, "batch_reward": 2.9916263847351074, "actor_loss": -289.7210039411272, "actor_target_entropy": -6.0, "actor_entropy": 3.2916725249517533, "alpha_loss": 0.003008756779193405, "alpha_value": 0.0908186162960991, "duration": 70.02376937866211, "step": 71375}
{"episode_reward": 566.618586451793, "episode": 572.0, "Q1 loss": 8.17461382675171, "Q2 loss": 8.134284217834473, "Mean Target Q": 289.8457353515625, "Mean Q1": 289.84271875, "Mean Q2": 289.84310522460936, "critic_loss": 16.30889803314209, "batch_reward": 3.0015161685943603, "actor_loss": -289.95043649981096, "actor_target_entropy": -6.0, "actor_entropy": 3.3180433434824788, "alpha_loss": 0.005191767543193794, "alpha_value": 0.09070864586869586, "duration": 71.24471259117126, "step": 71500}
{"episode_reward": 566.7208515308173, "episode": 573.0, "Q1 loss": 8.207587963104247, "Q2 loss": 8.003024394989014, "Mean Target Q": 289.9123640136719, "Mean Q1": 289.9101179199219, "Mean Q2": 289.90947802734377, "critic_loss": 16.210612396240233, "batch_reward": 2.998715919494629, "actor_loss": -290.8734566824777, "actor_target_entropy": -6.0, "actor_entropy": 3.256326187224615, "alpha_loss": 0.004203458264884021, "alpha_value": 0.09063058306729421, "duration": 88.85278654098511, "step": 71625}
{"episode_reward": 550.7086188571222, "episode": 574.0, "Q1 loss": 7.899224868774414, "Q2 loss": 7.72496367263794, "Mean Target Q": 290.52455419921876, "Mean Q1": 290.5277780761719, "Mean Q2": 290.52866650390627, "critic_loss": 15.624188575744629, "batch_reward": 3.014681526184082, "actor_loss": -290.7747093939012, "actor_target_entropy": -6.0, "actor_entropy": 3.267964924535444, "alpha_loss": 0.004810441454361764, "alpha_value": 0.0905275955898352, "duration": 128.34090757369995, "step": 71750}
{"episode_reward": 516.901327961654, "episode": 575.0, "Q1 loss": 8.18832233428955, "Q2 loss": 8.192065223693847, "Mean Target Q": 290.82324560546874, "Mean Q1": 290.8176064453125, "Mean Q2": 290.81993408203124, "critic_loss": 16.380387634277344, "batch_reward": 3.002647493362427, "actor_loss": -291.0276823497954, "actor_target_entropy": -6.0, "actor_entropy": 3.3661195437113443, "alpha_loss": -0.004040793678353703, "alpha_value": 0.09043500935433248, "duration": 154.7144591808319, "step": 71875}
{"episode_reward": 461.7401851433497, "episode": 576.0, "Q1 loss": 7.68303829574585, "Q2 loss": 7.57393765258789, "Mean Target Q": 291.22370556640624, "Mean Q1": 291.22691650390624, "Mean Q2": 291.2242844238281, "critic_loss": 15.256975967407227, "batch_reward": 3.0054225444793703, "actor_loss": -292.1821564705141, "actor_target_entropy": -6.0, "actor_entropy": 3.3267679252932147, "alpha_loss": 0.00041610693498965234, "alpha_value": 0.09052463927056703, "duration": 149.4941554069519, "step": 72000}
{"episode_reward": 463.6023449041526, "episode": 577.0, "Q1 loss": 7.078384281158447, "Q2 loss": 7.189529914855957, "Mean Target Q": 291.29556201171874, "Mean Q1": 291.28900830078123, "Mean Q2": 291.28999609375, "critic_loss": 14.267914161682128, "batch_reward": 3.0065358161926268, "actor_loss": -291.7059733072917, "actor_target_entropy": -6.0, "actor_entropy": 3.3682011536189487, "alpha_loss": 0.0012446197215467691, "alpha_value": 0.09045964019101776, "duration": 95.84492945671082, "step": 72125}
{"episode_reward": 529.4258976901207, "episode": 578.0, "Q1 loss": 7.874800266265869, "Q2 loss": 7.9371579246521, "Mean Target Q": 291.518771484375, "Mean Q1": 291.52009008789065, "Mean Q2": 291.5205549316406, "critic_loss": 15.81195816040039, "batch_reward": 3.0129040279388426, "actor_loss": -291.73558044433594, "actor_target_entropy": -6.0, "actor_entropy": 3.308493818006208, "alpha_loss": 0.004877091663318777, "alpha_value": 0.09046946079960226, "duration": 89.89195537567139, "step": 72250}
{"episode_reward": 170.4788489228919, "episode": 579.0, "Q1 loss": 8.117166828155517, "Q2 loss": 8.057630634307861, "Mean Target Q": 291.51454443359376, "Mean Q1": 291.50721655273435, "Mean Q2": 291.50769750976565, "critic_loss": 16.174797424316406, "batch_reward": 3.0068002395629883, "actor_loss": -291.85692535884795, "actor_target_entropy": -6.0, "actor_entropy": 3.3481326368119984, "alpha_loss": 0.014626812540911256, "alpha_value": 0.09023788353624541, "duration": 91.33451104164124, "step": 72375}
{"episode_reward": 536.3005048843485, "episode": 580.0, "Q1 loss": 9.038976108551026, "Q2 loss": 9.065916538238525, "Mean Target Q": 291.77857373046874, "Mean Q1": 291.78175756835935, "Mean Q2": 291.7816083984375, "critic_loss": 18.10489260864258, "batch_reward": 3.0118870029449463, "actor_loss": -292.27401979507937, "actor_target_entropy": -6.0, "actor_entropy": 3.2751947833645727, "alpha_loss": 0.0009591104237422828, "alpha_value": 0.09000152529005939, "duration": 119.1586377620697, "step": 72500}
{"episode_reward": 586.271453044042, "episode": 581.0, "Q1 loss": 10.191292922973632, "Q2 loss": 9.986952686309815, "Mean Target Q": 291.45434887695313, "Mean Q1": 291.45019873046874, "Mean Q2": 291.44917993164063, "critic_loss": 20.178245582580566, "batch_reward": 3.0029448051452636, "actor_loss": -292.0423283652654, "actor_target_entropy": -6.0, "actor_entropy": 3.293222151105366, "alpha_loss": -0.00427356291384924, "alpha_value": 0.09004010379986015, "duration": 131.62238574028015, "step": 72625}
{"episode_reward": 437.95565555683305, "episode": 582.0, "Q1 loss": 9.24120206451416, "Q2 loss": 9.144975044250488, "Mean Target Q": 292.18255517578126, "Mean Q1": 292.1835461425781, "Mean Q2": 292.1856223144531, "critic_loss": 18.386177139282225, "batch_reward": 3.0243558292388917, "actor_loss": -292.5042970718876, "actor_target_entropy": -6.0, "actor_entropy": 3.301606055228941, "alpha_loss": -0.007506439484836113, "alpha_value": 0.09017586620441251, "duration": 92.9863212108612, "step": 72750}
{"episode_reward": 571.6011769554804, "episode": 583.0, "Q1 loss": 9.190065635681153, "Q2 loss": 8.957675659179687, "Mean Target Q": 292.5593564453125, "Mean Q1": 292.5542829589844, "Mean Q2": 292.5545070800781, "critic_loss": 18.147741355895995, "batch_reward": 3.0243970527648925, "actor_loss": -293.3463502914187, "actor_target_entropy": -6.0, "actor_entropy": 3.3259381831638395, "alpha_loss": -0.01407807702863855, "alpha_value": 0.09040544057846535, "duration": 91.3728015422821, "step": 72875}
{"episode_reward": 557.2533822424799, "episode": 584.0, "Q1 loss": 7.80965266418457, "Q2 loss": 8.029084251403809, "Mean Target Q": 292.6628623046875, "Mean Q1": 292.6591279296875, "Mean Q2": 292.65974487304686, "critic_loss": 15.838736999511719, "batch_reward": 3.0232319984436034, "actor_loss": -293.0196282171434, "actor_target_entropy": -6.0, "actor_entropy": 3.309029056179908, "alpha_loss": -0.009372650502970623, "alpha_value": 0.09070567500539457, "duration": 93.36140823364258, "step": 73000}
{"episode_reward": 562.6784297608639, "episode": 585.0, "Q1 loss": 8.434712863922119, "Q2 loss": 8.352096885681153, "Mean Target Q": 292.6889797363281, "Mean Q1": 292.6858391113281, "Mean Q2": 292.6881862792969, "critic_loss": 16.786809776306153, "batch_reward": 3.0231383972167967, "actor_loss": -292.9320383223276, "actor_target_entropy": -6.0, "actor_entropy": 3.282980797782777, "alpha_loss": -0.010674114734496153, "alpha_value": 0.09096110711383507, "duration": 95.07033491134644, "step": 73125}
{"episode_reward": 544.43445674926, "episode": 586.0, "Q1 loss": 9.014592948913574, "Q2 loss": 9.15380937576294, "Mean Target Q": 293.3717512207031, "Mean Q1": 293.372474609375, "Mean Q2": 293.36795874023437, "critic_loss": 18.168402267456056, "batch_reward": 3.027724323272705, "actor_loss": -293.6632094844695, "actor_target_entropy": -6.0, "actor_entropy": 3.341538260059972, "alpha_loss": -0.005154498950428059, "alpha_value": 0.0911417159785108, "duration": 88.54005265235901, "step": 73250}
{"episode_reward": 499.52266790091056, "episode": 587.0, "Q1 loss": 9.15772904586792, "Q2 loss": 9.012451656341552, "Mean Target Q": 293.35135278320314, "Mean Q1": 293.35019018554686, "Mean Q2": 293.3519025878906, "critic_loss": 18.170180709838867, "batch_reward": 3.030222677230835, "actor_loss": -294.2158043271019, "actor_target_entropy": -6.0, "actor_entropy": 3.315720145664518, "alpha_loss": -0.018627286493216478, "alpha_value": 0.09144277866429287, "duration": 119.90881776809692, "step": 73375}
{"episode_reward": 547.9574423325664, "episode": 588.0, "Q1 loss": 8.484824306488036, "Q2 loss": 8.550509490966796, "Mean Target Q": 293.41699584960935, "Mean Q1": 293.40730224609376, "Mean Q2": 293.40843359375, "critic_loss": 17.035333671569823, "batch_reward": 3.0298618183135986, "actor_loss": -293.77143958307084, "actor_target_entropy": -6.0, "actor_entropy": 3.3957084225070093, "alpha_loss": -0.005227803879777991, "alpha_value": 0.09168679413790974, "duration": 135.36521768569946, "step": 73500}
{"episode_reward": 559.5563908280253, "episode": 589.0, "Q1 loss": 8.283996795654296, "Q2 loss": 8.115163200378419, "Mean Target Q": 293.835822265625, "Mean Q1": 293.84367236328126, "Mean Q2": 293.83878662109373, "critic_loss": 16.399160079956054, "batch_reward": 3.038641935348511, "actor_loss": -294.0864989265563, "actor_target_entropy": -6.0, "actor_entropy": 3.3273845513661704, "alpha_loss": -0.001738793005989421, "alpha_value": 0.09178470809960362, "duration": 116.56097078323364, "step": 73625}
{"episode_reward": 519.423034836963, "episode": 590.0, "Q1 loss": 8.755330738067627, "Q2 loss": 8.56168798828125, "Mean Target Q": 293.4746196289062, "Mean Q1": 293.4718955078125, "Mean Q2": 293.4727998046875, "critic_loss": 17.317018775939943, "batch_reward": 3.0270544567108155, "actor_loss": -293.43831462244833, "actor_target_entropy": -6.0, "actor_entropy": 3.4212032633443035, "alpha_loss": -0.005695409592120878, "alpha_value": 0.0918770481618775, "duration": 110.68738603591919, "step": 73750}
{"episode_reward": 516.6574426398079, "episode": 591.0, "Q1 loss": 8.522006927490235, "Q2 loss": 8.471849685668944, "Mean Target Q": 294.0438430175781, "Mean Q1": 294.0319765625, "Mean Q2": 294.0353376464844, "critic_loss": 16.993856590270997, "batch_reward": 3.0329435482025144, "actor_loss": -294.67945353190106, "actor_target_entropy": -6.0, "actor_entropy": 3.3364616651383656, "alpha_loss": 0.0027313706989858357, "alpha_value": 0.09193874148177691, "duration": 113.9406259059906, "step": 73875}
{"episode_reward": 544.0602002535246, "episode": 592.0, "Q1 loss": 8.467134510040284, "Q2 loss": 8.44169515991211, "Mean Target Q": 295.0740434570312, "Mean Q1": 295.0844501953125, "Mean Q2": 295.0827912597656, "critic_loss": 16.908829696655275, "batch_reward": 3.0527772235870363, "actor_loss": -295.1845461937689, "actor_target_entropy": -6.0, "actor_entropy": 3.2775362960753904, "alpha_loss": -0.0012537336217299585, "alpha_value": 0.09181667431394688, "duration": 93.19640302658081, "step": 74000}
{"episode_reward": 513.1818356134514, "episode": 593.0, "Q1 loss": 8.510001468658448, "Q2 loss": 8.433996368408204, "Mean Target Q": 295.00790576171875, "Mean Q1": 295.0003515625, "Mean Q2": 295.0049995117187, "critic_loss": 16.943997833251952, "batch_reward": 3.0411858901977538, "actor_loss": -295.6598394484747, "actor_target_entropy": -6.0, "actor_entropy": 3.3685538920145186, "alpha_loss": -0.016242883216205335, "alpha_value": 0.09212725537977821, "duration": 119.6435136795044, "step": 74125}
{"episode_reward": 566.5478013511273, "episode": 594.0, "Q1 loss": 8.509808086395264, "Q2 loss": 8.492251914978027, "Mean Target Q": 295.19225634765627, "Mean Q1": 295.188484375, "Mean Q2": 295.1819345703125, "critic_loss": 17.00206001281738, "batch_reward": 3.0450674953460695, "actor_loss": -295.9474541448778, "actor_target_entropy": -6.0, "actor_entropy": 3.3226572082888697, "alpha_loss": -0.004834799118520272, "alpha_value": 0.09234743184843705, "duration": 114.26640510559082, "step": 74250}
{"episode_reward": 548.1291745666792, "episode": 595.0, "Q1 loss": 8.128036865234375, "Q2 loss": 8.266295650482178, "Mean Target Q": 295.63458374023435, "Mean Q1": 295.6327844238281, "Mean Q2": 295.63408251953126, "critic_loss": 16.394332550048826, "batch_reward": 3.0460424575805662, "actor_loss": -296.39705355205234, "actor_target_entropy": -6.0, "actor_entropy": 3.2722308408646357, "alpha_loss": 0.001274375355846825, "alpha_value": 0.09241824208319475, "duration": 149.14733481407166, "step": 74375}
{"episode_reward": 577.3960981423041, "episode": 596.0, "Q1 loss": 8.37295475769043, "Q2 loss": 8.262969745635987, "Mean Target Q": 295.51341479492186, "Mean Q1": 295.51943334960936, "Mean Q2": 295.5192180175781, "critic_loss": 16.635924446105957, "batch_reward": 3.0401027603149413, "actor_loss": -295.99608489005794, "actor_target_entropy": -6.0, "actor_entropy": 3.2714710812414847, "alpha_loss": -0.005618706446952156, "alpha_value": 0.09241331711227833, "duration": 101.55399489402771, "step": 74500}
{"episode_reward": 594.5756176580585, "episode": 597.0, "Q1 loss": 8.880300632476807, "Q2 loss": 8.905520816802978, "Mean Target Q": 295.4020202636719, "Mean Q1": 295.39193896484375, "Mean Q2": 295.3919875488281, "critic_loss": 17.785821434020995, "batch_reward": 3.050860288619995, "actor_loss": -295.82937912713913, "actor_target_entropy": -6.0, "actor_entropy": 3.334164199374971, "alpha_loss": -0.003443040471110079, "alpha_value": 0.09249424890804267, "duration": 83.99314451217651, "step": 74625}
{"episode_reward": 534.6548588646377, "episode": 598.0, "Q1 loss": 8.490070987701417, "Q2 loss": 8.665637439727783, "Mean Target Q": 296.2015419921875, "Mean Q1": 296.1969836425781, "Mean Q2": 296.1985439453125, "critic_loss": 17.1557084274292, "batch_reward": 3.0628545360565185, "actor_loss": -296.45134858162174, "actor_target_entropy": -6.0, "actor_entropy": 3.2988327895441363, "alpha_loss": -0.009417365267572383, "alpha_value": 0.09269447651037177, "duration": 91.55219411849976, "step": 74750}
{"episode_reward": 543.9578659965774, "episode": 599.0, "Q1 loss": 9.016740169525146, "Q2 loss": 8.512056289672852, "Mean Target Q": 295.5186828613281, "Mean Q1": 295.52043603515625, "Mean Q2": 295.52068090820313, "critic_loss": 17.528796478271484, "batch_reward": 3.0501178035736083, "actor_loss": -295.54427519298736, "actor_target_entropy": -6.0, "actor_entropy": 3.373423424978105, "alpha_loss": -0.005097036360807362, "alpha_value": 0.09288310715545516, "duration": 127.28504157066345, "step": 74875}
{"episode_reward": 533.8624271807897, "episode": 600.0, "Q1 loss": 8.254116004943848, "Q2 loss": 8.2184344291687, "Mean Target Q": 296.77890112304686, "Mean Q1": 296.7760805664062, "Mean Q2": 296.7748132324219, "critic_loss": 16.472550384521483, "batch_reward": 3.066633729934692, "actor_loss": -297.0909527194115, "actor_target_entropy": -6.0, "actor_entropy": 3.344015129150883, "alpha_loss": -0.016305321962722847, "alpha_value": 0.09315077210869446, "step": 75000}
{"duration": 129.89318370819092, "step": 75000}
{"episode_reward": 566.804163164014, "episode": 601.0, "Q1 loss": 7.882849304199219, "Q2 loss": 8.062544822692871, "Mean Target Q": 296.6001281738281, "Mean Q1": 296.60639453125, "Mean Q2": 296.60601708984376, "critic_loss": 15.945394096374512, "batch_reward": 3.061975685119629, "actor_loss": -296.9228229825459, "actor_target_entropy": -6.0, "actor_entropy": 3.3544289535946317, "alpha_loss": -0.0064575589624130065, "alpha_value": 0.0934761899790651, "duration": 83.93034958839417, "step": 75125}
{"episode_reward": 538.9783480758612, "episode": 602.0, "Q1 loss": 7.868293197631836, "Q2 loss": 7.9449316635131835, "Mean Target Q": 296.49018920898436, "Mean Q1": 296.48247778320314, "Mean Q2": 296.4835573730469, "critic_loss": 15.813224891662598, "batch_reward": 3.0543716468811035, "actor_loss": -296.8055198423324, "actor_target_entropy": -6.0, "actor_entropy": 3.3116535140622045, "alpha_loss": -0.0007683092225042562, "alpha_value": 0.09354087558008832, "duration": 81.43512988090515, "step": 75250}
{"episode_reward": 560.8469039988165, "episode": 603.0, "Q1 loss": 7.721511650085449, "Q2 loss": 7.771331039428711, "Mean Target Q": 297.02619140625, "Mean Q1": 297.02452172851565, "Mean Q2": 297.0247116699219, "critic_loss": 15.492842720031739, "batch_reward": 3.07156022644043, "actor_loss": -297.3250005812872, "actor_target_entropy": -6.0, "actor_entropy": 3.2780699616386775, "alpha_loss": 0.006150456673894373, "alpha_value": 0.09344575812856802, "duration": 78.41059613227844, "step": 75375}
{"episode_reward": 499.5150699919977, "episode": 604.0, "Q1 loss": 8.403120128631592, "Q2 loss": 8.319950523376464, "Mean Target Q": 297.12437573242187, "Mean Q1": 297.1255832519531, "Mean Q2": 297.12163818359375, "critic_loss": 16.72307061767578, "batch_reward": 3.0602374935150145, "actor_loss": -297.39349955897177, "actor_target_entropy": -6.0, "actor_entropy": 3.298572870992845, "alpha_loss": -0.008999986423840445, "alpha_value": 0.09350262487789589, "duration": 78.32616353034973, "step": 75500}
{"episode_reward": 470.3974935057767, "episode": 605.0, "Q1 loss": 8.647854015350342, "Q2 loss": 8.650274391174316, "Mean Target Q": 297.1519294433594, "Mean Q1": 297.147306640625, "Mean Q2": 297.14824829101565, "critic_loss": 17.298128364562988, "batch_reward": 3.0668259620666505, "actor_loss": -297.71504865373885, "actor_target_entropy": -6.0, "actor_entropy": 3.3452905813852944, "alpha_loss": -0.012340881555001177, "alpha_value": 0.0937807972444188, "duration": 78.48784899711609, "step": 75625}
{"episode_reward": 571.3642016121287, "episode": 606.0, "Q1 loss": 8.083062660217285, "Q2 loss": 7.95043860244751, "Mean Target Q": 297.58162573242186, "Mean Q1": 297.57485986328123, "Mean Q2": 297.580580078125, "critic_loss": 16.03350133514404, "batch_reward": 3.059330255508423, "actor_loss": -297.37101647161666, "actor_target_entropy": -6.0, "actor_entropy": 3.301102638244629, "alpha_loss": -0.005045369560379655, "alpha_value": 0.0939860233825054, "duration": 85.46096706390381, "step": 75750}
{"episode_reward": 536.6578335630794, "episode": 607.0, "Q1 loss": 7.5520514984130855, "Q2 loss": 7.467802234649659, "Mean Target Q": 297.9985263671875, "Mean Q1": 297.99674389648436, "Mean Q2": 297.9950546875, "critic_loss": 15.01985376739502, "batch_reward": 3.067639554977417, "actor_loss": -298.3201725066654, "actor_target_entropy": -6.0, "actor_entropy": 3.32577863950578, "alpha_loss": -0.000923963984297145, "alpha_value": 0.09399672883127384, "duration": 80.22544288635254, "step": 75875}
{"episode_reward": 520.3137075398905, "episode": 608.0, "Q1 loss": 8.0021100730896, "Q2 loss": 7.994512882232666, "Mean Target Q": 298.2998781738281, "Mean Q1": 298.29936328125, "Mean Q2": 298.2960671386719, "critic_loss": 15.99662297821045, "batch_reward": 3.077233438491821, "actor_loss": -298.66620119156374, "actor_target_entropy": -6.0, "actor_entropy": 3.3047993452318254, "alpha_loss": 0.0003252201488301639, "alpha_value": 0.09404294805247163, "duration": 101.77297568321228, "step": 76000}
{"episode_reward": 513.6936641070465, "episode": 609.0, "Q1 loss": 7.835664222717285, "Q2 loss": 7.819159160614014, "Mean Target Q": 298.52540380859375, "Mean Q1": 298.5209677734375, "Mean Q2": 298.5240202636719, "critic_loss": 15.654823356628418, "batch_reward": 3.067360761642456, "actor_loss": -298.65096270848835, "actor_target_entropy": -6.0, "actor_entropy": 3.4203530531080943, "alpha_loss": -0.013017425428159417, "alpha_value": 0.09423334791786045, "duration": 117.81768751144409, "step": 76125}
{"episode_reward": 465.2989169364062, "episode": 610.0, "Q1 loss": 8.196946544647217, "Q2 loss": 8.007295070648194, "Mean Target Q": 298.27839233398436, "Mean Q1": 298.2802890625, "Mean Q2": 298.28071826171873, "critic_loss": 16.20424164581299, "batch_reward": 3.0657715854644776, "actor_loss": -299.0123546969506, "actor_target_entropy": -6.0, "actor_entropy": 3.413601198504048, "alpha_loss": -0.006780741863974159, "alpha_value": 0.09447333165137323, "duration": 91.4684407711029, "step": 76250}
{"episode_reward": 524.711678674348, "episode": 611.0, "Q1 loss": 7.578848253250122, "Q2 loss": 7.634809322357178, "Mean Target Q": 298.51606274414064, "Mean Q1": 298.5114858398438, "Mean Q2": 298.50994921875, "critic_loss": 15.213657554626465, "batch_reward": 3.084929609298706, "actor_loss": -298.6410745287698, "actor_target_entropy": -6.0, "actor_entropy": 3.416253581879631, "alpha_loss": -0.004823903774931317, "alpha_value": 0.09455425650475814, "duration": 80.27692103385925, "step": 76375}
{"episode_reward": 488.4983938229515, "episode": 612.0, "Q1 loss": 7.778070861816406, "Q2 loss": 7.702161205291748, "Mean Target Q": 299.24312060546873, "Mean Q1": 299.24800390625, "Mean Q2": 299.25151513671875, "critic_loss": 15.480232124328614, "batch_reward": 3.0809786071777343, "actor_loss": -299.4385764829574, "actor_target_entropy": -6.0, "actor_entropy": 3.4118675224242674, "alpha_loss": -0.0016245591611931882, "alpha_value": 0.0946509462451234, "duration": 78.86915040016174, "step": 76500}
{"episode_reward": 539.1717345036215, "episode": 613.0, "Q1 loss": 7.625159038543702, "Q2 loss": 7.8082790184021, "Mean Target Q": 299.206669921875, "Mean Q1": 299.20094018554687, "Mean Q2": 299.19706005859376, "critic_loss": 15.433437980651856, "batch_reward": 3.079037656784058, "actor_loss": -298.98838394407244, "actor_target_entropy": -6.0, "actor_entropy": 3.3955330848693848, "alpha_loss": 9.350578433700971e-05, "alpha_value": 0.09464637289198771, "duration": 106.43939447402954, "step": 76625}
{"episode_reward": 508.75452407546356, "episode": 614.0, "Q1 loss": 7.410421653747559, "Q2 loss": 7.409949718475342, "Mean Target Q": 299.5402456054687, "Mean Q1": 299.538306640625, "Mean Q2": 299.54071240234373, "critic_loss": 14.820371391296387, "batch_reward": 3.0755085945129395, "actor_loss": -299.5311471262286, "actor_target_entropy": -6.0, "actor_entropy": 3.330978266654476, "alpha_loss": 0.00491272073779856, "alpha_value": 0.0946019682843169, "duration": 112.110360622406, "step": 76750}
{"episode_reward": 526.0474392862795, "episode": 615.0, "Q1 loss": 8.281504096984863, "Q2 loss": 8.055432376861573, "Mean Target Q": 300.09800537109373, "Mean Q1": 300.0930234375, "Mean Q2": 300.09187866210937, "critic_loss": 16.33693653869629, "batch_reward": 3.093709476470947, "actor_loss": -300.2267785450769, "actor_target_entropy": -6.0, "actor_entropy": 3.330557721001761, "alpha_loss": 0.000731635033079083, "alpha_value": 0.09450234143583991, "duration": 78.5747766494751, "step": 76875}
{"episode_reward": 524.0887713063476, "episode": 616.0, "Q1 loss": 7.331431705474854, "Q2 loss": 7.224300712585449, "Mean Target Q": 299.9128698730469, "Mean Q1": 299.91404736328127, "Mean Q2": 299.9134958496094, "critic_loss": 14.555732429504394, "batch_reward": 3.077069025039673, "actor_loss": -300.12383836315524, "actor_target_entropy": -6.0, "actor_entropy": 3.297940973312624, "alpha_loss": 0.009853092645625434, "alpha_value": 0.09445044470858178, "duration": 95.85038042068481, "step": 77000}
{"episode_reward": 503.4345675205941, "episode": 617.0, "Q1 loss": 7.819187488555908, "Q2 loss": 7.862412887573242, "Mean Target Q": 299.85839575195314, "Mean Q1": 299.8581865234375, "Mean Q2": 299.8580400390625, "critic_loss": 15.681600311279297, "batch_reward": 3.0773237266540527, "actor_loss": -300.53997221447173, "actor_target_entropy": -6.0, "actor_entropy": 3.4147055716741654, "alpha_loss": 0.005000281064505023, "alpha_value": 0.09417249311659139, "duration": 110.6766049861908, "step": 77125}
{"episode_reward": 541.4410941546686, "episode": 618.0, "Q1 loss": 7.34409289932251, "Q2 loss": 7.288034160614013, "Mean Target Q": 300.42664379882814, "Mean Q1": 300.421759765625, "Mean Q2": 300.4218059082031, "critic_loss": 14.632127067565918, "batch_reward": 3.0965394420623777, "actor_loss": -300.43345002205143, "actor_target_entropy": -6.0, "actor_entropy": 3.2963874455421203, "alpha_loss": -0.008337979419006696, "alpha_value": 0.09425535409020633, "duration": 95.10553312301636, "step": 77250}
{"episode_reward": 538.3060876407737, "episode": 619.0, "Q1 loss": 7.4316875305175785, "Q2 loss": 7.517440776824952, "Mean Target Q": 300.6545241699219, "Mean Q1": 300.6529487304687, "Mean Q2": 300.6532109375, "critic_loss": 14.949128303527832, "batch_reward": 3.0962892417907715, "actor_loss": -300.91063290550596, "actor_target_entropy": -6.0, "actor_entropy": 3.3665682815370106, "alpha_loss": 0.0022864755656984118, "alpha_value": 0.09433497733392943, "duration": 76.38472008705139, "step": 77375}
{"episode_reward": 548.4098272658645, "episode": 620.0, "Q1 loss": 7.923046985626221, "Q2 loss": 7.819663398742676, "Mean Target Q": 301.51739038085935, "Mean Q1": 301.51784521484376, "Mean Q2": 301.5172917480469, "critic_loss": 15.742710403442382, "batch_reward": 3.096648292541504, "actor_loss": -301.66892365486393, "actor_target_entropy": -6.0, "actor_entropy": 3.3534594658882386, "alpha_loss": -0.001118986596984248, "alpha_value": 0.09431214234463753, "duration": 75.30794191360474, "step": 77500}
{"episode_reward": 569.7565930912925, "episode": 621.0, "Q1 loss": 7.879594745635987, "Q2 loss": 7.836013324737549, "Mean Target Q": 300.97857470703127, "Mean Q1": 300.97449975585937, "Mean Q2": 300.97083911132813, "critic_loss": 15.71560807800293, "batch_reward": 3.0900927352905274, "actor_loss": -301.28028312562003, "actor_target_entropy": -6.0, "actor_entropy": 3.361661702867538, "alpha_loss": -0.010036941152065992, "alpha_value": 0.09442035212493644, "duration": 72.68899416923523, "step": 77625}
{"episode_reward": 501.1065935487944, "episode": 622.0, "Q1 loss": 7.68112841796875, "Q2 loss": 7.607002510070801, "Mean Target Q": 301.6067058105469, "Mean Q1": 301.60429321289064, "Mean Q2": 301.6095393066406, "critic_loss": 15.288130912780762, "batch_reward": 3.099358142852783, "actor_loss": -301.92292884088334, "actor_target_entropy": -6.0, "actor_entropy": 3.366392481711603, "alpha_loss": -0.007053633573495092, "alpha_value": 0.09467842215878378, "duration": 77.35810780525208, "step": 77750}
{"episode_reward": 541.0046280531678, "episode": 623.0, "Q1 loss": 7.323896083831787, "Q2 loss": 7.287309886932373, "Mean Target Q": 301.83889794921873, "Mean Q1": 301.84122534179687, "Mean Q2": 301.8403112792969, "critic_loss": 14.611205940246583, "batch_reward": 3.1034700088500977, "actor_loss": -301.4410322885665, "actor_target_entropy": -6.0, "actor_entropy": 3.32569894714961, "alpha_loss": 0.007870149266506945, "alpha_value": 0.09463047852174981, "duration": 88.77620887756348, "step": 77875}
{"episode_reward": 458.1814803295747, "episode": 624.0, "Q1 loss": 7.544689949035645, "Q2 loss": 7.350690093994141, "Mean Target Q": 301.6651936035156, "Mean Q1": 301.66031323242186, "Mean Q2": 301.66348706054686, "critic_loss": 14.895380043029785, "batch_reward": 3.0963389072418215, "actor_loss": -302.40284482894407, "actor_target_entropy": -6.0, "actor_entropy": 3.3408969486913374, "alpha_loss": -0.0005143769122960587, "alpha_value": 0.0945293716059715, "duration": 93.63839340209961, "step": 78000}
{"episode_reward": 589.8859531242111, "episode": 625.0, "Q1 loss": 8.721126449584961, "Q2 loss": 8.519217868804931, "Mean Target Q": 301.9490183105469, "Mean Q1": 301.9475319824219, "Mean Q2": 301.94601025390625, "critic_loss": 17.24034427642822, "batch_reward": 3.098066955566406, "actor_loss": -302.27909100244915, "actor_target_entropy": -6.0, "actor_entropy": 3.356098617826189, "alpha_loss": -0.0007901266198753128, "alpha_value": 0.09455053017997204, "duration": 91.51870536804199, "step": 78125}
{"episode_reward": 574.0299133688025, "episode": 626.0, "Q1 loss": 7.823482574462891, "Q2 loss": 7.778034744262695, "Mean Target Q": 302.0781455078125, "Mean Q1": 302.0754279785156, "Mean Q2": 302.0742390136719, "critic_loss": 15.60151732635498, "batch_reward": 3.109060134887695, "actor_loss": -302.65657831007434, "actor_target_entropy": -6.0, "actor_entropy": 3.343708065248305, "alpha_loss": 1.3632249207265915e-05, "alpha_value": 0.09458045386821515, "duration": 79.6449556350708, "step": 78250}
{"episode_reward": 555.5191828503681, "episode": 627.0, "Q1 loss": 8.205805206298828, "Q2 loss": 8.078696254730225, "Mean Target Q": 301.94995458984374, "Mean Q1": 301.94711083984373, "Mean Q2": 301.9503083496094, "critic_loss": 16.284501441955566, "batch_reward": 3.092811243057251, "actor_loss": -302.3180479019407, "actor_target_entropy": -6.0, "actor_entropy": 3.3791136060442244, "alpha_loss": -5.528586177480599e-05, "alpha_value": 0.09466122544654772, "duration": 73.5188376903534, "step": 78375}
{"episode_reward": 532.7175279805922, "episode": 628.0, "Q1 loss": 8.077698387145997, "Q2 loss": 8.118157444000245, "Mean Target Q": 302.41286059570314, "Mean Q1": 302.414197265625, "Mean Q2": 302.41305078125, "critic_loss": 16.19585585784912, "batch_reward": 3.112556282043457, "actor_loss": -302.19805662093626, "actor_target_entropy": -6.0, "actor_entropy": 3.3380042737530125, "alpha_loss": 0.000841143871507337, "alpha_value": 0.09457661610077242, "duration": 81.63009309768677, "step": 78500}
{"episode_reward": 550.540482419165, "episode": 629.0, "Q1 loss": 12.263510639190674, "Q2 loss": 12.235486339569091, "Mean Target Q": 302.26074072265624, "Mean Q1": 302.2550319824219, "Mean Q2": 302.25753442382813, "critic_loss": 24.498996910095215, "batch_reward": 3.1140384788513185, "actor_loss": -302.87122696165056, "actor_target_entropy": -6.0, "actor_entropy": 3.4144064585367837, "alpha_loss": -0.01858675309885589, "alpha_value": 0.09473963056648557, "duration": 100.50157737731934, "step": 78625}
{"episode_reward": 557.2391939580527, "episode": 630.0, "Q1 loss": 7.891923797607422, "Q2 loss": 7.964465984344482, "Mean Target Q": 303.5195568847656, "Mean Q1": 303.5169626464844, "Mean Q2": 303.5137470703125, "critic_loss": 15.856389747619628, "batch_reward": 3.1154168090820313, "actor_loss": -303.8011203888924, "actor_target_entropy": -6.0, "actor_entropy": 3.407418550983552, "alpha_loss": -0.016356279191020274, "alpha_value": 0.09527143624556388, "duration": 100.5541090965271, "step": 78750}
{"episode_reward": 559.5194260889874, "episode": 631.0, "Q1 loss": 7.665768478393555, "Q2 loss": 7.754004993438721, "Mean Target Q": 303.03744580078126, "Mean Q1": 303.0358571777344, "Mean Q2": 303.03616064453126, "critic_loss": 15.419773445129394, "batch_reward": 3.1191816234588625, "actor_loss": -303.4771588037884, "actor_target_entropy": -6.0, "actor_entropy": 3.2949269839695523, "alpha_loss": -0.001600608155722656, "alpha_value": 0.09540856483495162, "duration": 84.79549026489258, "step": 78875}
{"episode_reward": 564.5619344816504, "episode": 632.0, "Q1 loss": 7.14888724899292, "Q2 loss": 7.109917007446289, "Mean Target Q": 303.6918039550781, "Mean Q1": 303.6899729003906, "Mean Q2": 303.6899245605469, "critic_loss": 14.258804267883301, "batch_reward": 3.124908708572388, "actor_loss": -304.0251838930192, "actor_target_entropy": -6.0, "actor_entropy": 3.2509168771005448, "alpha_loss": 0.0048896771697928346, "alpha_value": 0.0954158581485179, "duration": 75.21371579170227, "step": 79000}
{"episode_reward": 488.881316513784, "episode": 633.0, "Q1 loss": 7.229073429107666, "Q2 loss": 7.432022651672363, "Mean Target Q": 303.33007641601563, "Mean Q1": 303.3340107421875, "Mean Q2": 303.33364184570314, "critic_loss": 14.66109602355957, "batch_reward": 3.1110027198791506, "actor_loss": -303.21463448660717, "actor_target_entropy": -6.0, "actor_entropy": 3.3746036688486734, "alpha_loss": 0.007522351869810668, "alpha_value": 0.09523229395333309, "duration": 76.25299620628357, "step": 79125}
{"episode_reward": 556.44025162265, "episode": 634.0, "Q1 loss": 7.632339942932129, "Q2 loss": 7.591829200744629, "Mean Target Q": 303.88098583984373, "Mean Q1": 303.86758740234376, "Mean Q2": 303.8712041015625, "critic_loss": 15.224169105529786, "batch_reward": 3.1181459674835206, "actor_loss": -304.0852695588143, "actor_target_entropy": -6.0, "actor_entropy": 3.342251989149278, "alpha_loss": 0.0028701362710806633, "alpha_value": 0.09511772062040251, "duration": 71.65122151374817, "step": 79250}
{"episode_reward": 559.5711453903072, "episode": 635.0, "Q1 loss": 7.05043448638916, "Q2 loss": 6.897087017059326, "Mean Target Q": 304.047056640625, "Mean Q1": 304.05509448242185, "Mean Q2": 304.0534396972656, "critic_loss": 13.94752155303955, "batch_reward": 3.121747808456421, "actor_loss": -304.4951661125062, "actor_target_entropy": -6.0, "actor_entropy": 3.226204512611268, "alpha_loss": 0.0016510495952966194, "alpha_value": 0.09507467333897208, "duration": 89.67004084587097, "step": 79375}
{"episode_reward": 545.0757272215739, "episode": 636.0, "Q1 loss": 7.03411270904541, "Q2 loss": 7.001928039550782, "Mean Target Q": 304.1145712890625, "Mean Q1": 304.107310546875, "Mean Q2": 304.10574145507815, "critic_loss": 14.036040763854981, "batch_reward": 3.127719585418701, "actor_loss": -304.7482181672127, "actor_target_entropy": -6.0, "actor_entropy": 3.2810188262693343, "alpha_loss": 0.003939535701647401, "alpha_value": 0.0950065099439049, "duration": 105.45494103431702, "step": 79500}
{"episode_reward": 561.9481943240168, "episode": 637.0, "Q1 loss": 6.9264570922851565, "Q2 loss": 7.066028526306153, "Mean Target Q": 304.13763037109373, "Mean Q1": 304.14046484375, "Mean Q2": 304.14276684570314, "critic_loss": 13.99248558807373, "batch_reward": 3.1176633586883544, "actor_loss": -304.27227880084325, "actor_target_entropy": -6.0, "actor_entropy": 3.2126651302216547, "alpha_loss": 0.0011214935442521458, "alpha_value": 0.09499747746037436, "duration": 101.85866093635559, "step": 79625}
{"episode_reward": 558.1593235885999, "episode": 638.0, "Q1 loss": 7.265203933715821, "Q2 loss": 7.254500671386719, "Mean Target Q": 304.97100927734374, "Mean Q1": 304.9719111328125, "Mean Q2": 304.969763671875, "critic_loss": 14.519704582214356, "batch_reward": 3.134666450500488, "actor_loss": -304.8879744006741, "actor_target_entropy": -6.0, "actor_entropy": 3.2763213880600466, "alpha_loss": -0.007860010208171462, "alpha_value": 0.09501622782465509, "duration": 106.68905329704285, "step": 79750}
{"episode_reward": 523.7309337779908, "episode": 639.0, "Q1 loss": 7.515920288085938, "Q2 loss": 7.520810123443604, "Mean Target Q": 304.8543278808594, "Mean Q1": 304.8493698730469, "Mean Q2": 304.84906689453123, "critic_loss": 15.036730506896973, "batch_reward": 3.130220277786255, "actor_loss": -305.10084461030505, "actor_target_entropy": -6.0, "actor_entropy": 3.302265700839815, "alpha_loss": -0.0026931531084257933, "alpha_value": 0.09516142040194016, "duration": 104.63409924507141, "step": 79875}
{"episode_reward": 585.7176602237482, "episode": 640.0, "Q1 loss": 6.9343126678466795, "Q2 loss": 7.03637455368042, "Mean Target Q": 305.0097294921875, "Mean Q1": 305.0129865722656, "Mean Q2": 305.01075463867187, "critic_loss": 13.97068726348877, "batch_reward": 3.1290172843933104, "actor_loss": -305.4625249062815, "actor_target_entropy": -6.0, "actor_entropy": 3.3155500004368443, "alpha_loss": -0.003363410033465874, "alpha_value": 0.0952896119420897, "step": 80000}
{"duration": 86.27044367790222, "step": 80000}
{"episode_reward": 516.2948413560426, "episode": 641.0, "Q1 loss": 7.402772022247315, "Q2 loss": 7.271943798065186, "Mean Target Q": 305.1103955078125, "Mean Q1": 305.10550830078125, "Mean Q2": 305.107955078125, "critic_loss": 14.674715888977051, "batch_reward": 3.1326058826446532, "actor_loss": -305.17688714890255, "actor_target_entropy": -6.0, "actor_entropy": 3.3536870025453114, "alpha_loss": -0.003415443531666247, "alpha_value": 0.0953170533132241, "duration": 112.15454483032227, "step": 80125}
{"episode_reward": 541.081416956559, "episode": 642.0, "Q1 loss": 7.259197805404663, "Q2 loss": 7.296266445159912, "Mean Target Q": 305.17743408203125, "Mean Q1": 305.1725065917969, "Mean Q2": 305.1707578125, "critic_loss": 14.555464279174805, "batch_reward": 3.1256717929840088, "actor_loss": -305.46802643806706, "actor_target_entropy": -6.0, "actor_entropy": 3.3518327551503337, "alpha_loss": -0.0007786910019574627, "alpha_value": 0.09536887509692249, "duration": 112.30575633049011, "step": 80250}
{"episode_reward": 566.1904383140638, "episode": 643.0, "Q1 loss": 7.237431262969971, "Q2 loss": 7.062991306304932, "Mean Target Q": 305.640740234375, "Mean Q1": 305.64414599609376, "Mean Q2": 305.64475219726563, "critic_loss": 14.300422607421876, "batch_reward": 3.141888542175293, "actor_loss": -306.2444520980593, "actor_target_entropy": -6.0, "actor_entropy": 3.282247263287741, "alpha_loss": -0.0031103504163819172, "alpha_value": 0.09537556422459154, "duration": 90.42403960227966, "step": 80375}
{"episode_reward": 573.3207897923851, "episode": 644.0, "Q1 loss": 7.310323757171631, "Q2 loss": 7.33124955368042, "Mean Target Q": 306.2672800292969, "Mean Q1": 306.26476293945314, "Mean Q2": 306.2649697265625, "critic_loss": 14.64157332611084, "batch_reward": 3.138473690032959, "actor_loss": -306.5382847939768, "actor_target_entropy": -6.0, "actor_entropy": 3.355082873375185, "alpha_loss": 0.005016142885471063, "alpha_value": 0.09535167170714676, "duration": 71.26736402511597, "step": 80500}
{"episode_reward": 570.0317382353619, "episode": 645.0, "Q1 loss": 7.2987649040222164, "Q2 loss": 7.371031711578369, "Mean Target Q": 306.25161547851565, "Mean Q1": 306.24822924804687, "Mean Q2": 306.2501059570312, "critic_loss": 14.669796577453614, "batch_reward": 3.1394081325531005, "actor_loss": -306.32557169596356, "actor_target_entropy": -6.0, "actor_entropy": 3.321236701238723, "alpha_loss": -0.0028361379065447384, "alpha_value": 0.09532631733555781, "duration": 85.27100777626038, "step": 80625}
{"episode_reward": 511.2776081269241, "episode": 646.0, "Q1 loss": 8.152607891082763, "Q2 loss": 7.895007755279541, "Mean Target Q": 306.4164978027344, "Mean Q1": 306.4137966308594, "Mean Q2": 306.41322607421876, "critic_loss": 16.04761569213867, "batch_reward": 3.1477977771759034, "actor_loss": -306.38638502551663, "actor_target_entropy": -6.0, "actor_entropy": 3.38897523572368, "alpha_loss": -0.007963758423894404, "alpha_value": 0.0954558257643221, "duration": 108.25400185585022, "step": 80750}
{"episode_reward": 363.90529136687644, "episode": 647.0, "Q1 loss": 7.653364723205566, "Q2 loss": 7.6998122062683105, "Mean Target Q": 306.901890625, "Mean Q1": 306.89984814453123, "Mean Q2": 306.89781958007814, "critic_loss": 15.353176895141601, "batch_reward": 3.1544786357879637, "actor_loss": -307.49817863343253, "actor_target_entropy": -6.0, "actor_entropy": 3.3146643827831936, "alpha_loss": -0.00733721768853092, "alpha_value": 0.09570140481367778, "duration": 99.73550391197205, "step": 80875}
{"episode_reward": 593.611510211717, "episode": 648.0, "Q1 loss": 7.3661936721801755, "Q2 loss": 7.516618804931641, "Mean Target Q": 306.14523388671876, "Mean Q1": 306.14653466796875, "Mean Q2": 306.1484587402344, "critic_loss": 14.88281251525879, "batch_reward": 3.140017831802368, "actor_loss": -306.13414838237145, "actor_target_entropy": -6.0, "actor_entropy": 3.406182800569842, "alpha_loss": -0.0017399117237918318, "alpha_value": 0.09580104344420705, "duration": 70.65070366859436, "step": 81000}
{"episode_reward": 550.0945845926752, "episode": 649.0, "Q1 loss": 7.963782844543457, "Q2 loss": 7.915264400482178, "Mean Target Q": 306.83665234375, "Mean Q1": 306.8332470703125, "Mean Q2": 306.832119140625, "critic_loss": 15.879047325134277, "batch_reward": 3.1378466339111326, "actor_loss": -306.6405644492498, "actor_target_entropy": -6.0, "actor_entropy": 3.4433535810500855, "alpha_loss": -0.0013468012006746398, "alpha_value": 0.09578586401726795, "duration": 75.8657751083374, "step": 81125}
{"episode_reward": 534.1264379004903, "episode": 650.0, "Q1 loss": 7.034900764465332, "Q2 loss": 7.155833431243897, "Mean Target Q": 306.9610327148437, "Mean Q1": 306.9556291503906, "Mean Q2": 306.9583835449219, "critic_loss": 14.190734230041503, "batch_reward": 3.1500855293273924, "actor_loss": -306.9632317327684, "actor_target_entropy": -6.0, "actor_entropy": 3.4272510736219344, "alpha_loss": 0.003898444754492131, "alpha_value": 0.09583702134365209, "duration": 73.93842482566833, "step": 81250}
{"episode_reward": 482.7688658892738, "episode": 651.0, "Q1 loss": 7.116489826202392, "Q2 loss": 6.992858631134033, "Mean Target Q": 307.44039038085936, "Mean Q1": 307.4459052734375, "Mean Q2": 307.4444992675781, "critic_loss": 14.109348403930664, "batch_reward": 3.151721538543701, "actor_loss": -307.8783564491877, "actor_target_entropy": -6.0, "actor_entropy": 3.2592087359655473, "alpha_loss": -0.007352715228787727, "alpha_value": 0.09579614163849506, "duration": 79.94462060928345, "step": 81375}
{"episode_reward": 576.0537083204086, "episode": 652.0, "Q1 loss": 7.245834209442139, "Q2 loss": 7.101525447845459, "Mean Target Q": 307.1000871582031, "Mean Q1": 307.0958791503906, "Mean Q2": 307.09335009765624, "critic_loss": 14.347359580993652, "batch_reward": 3.145932788848877, "actor_loss": -307.3750999204574, "actor_target_entropy": -6.0, "actor_entropy": 3.3028205402435793, "alpha_loss": 0.00016471366548249797, "alpha_value": 0.09597591744543328, "duration": 97.25999546051025, "step": 81500}
{"episode_reward": 566.7556222688235, "episode": 653.0, "Q1 loss": 7.377874351501465, "Q2 loss": 7.4756298294067385, "Mean Target Q": 307.9057822265625, "Mean Q1": 307.9017321777344, "Mean Q2": 307.90252783203124, "critic_loss": 14.853504203796387, "batch_reward": 3.1582653160095213, "actor_loss": -308.3538847423735, "actor_target_entropy": -6.0, "actor_entropy": 3.2804904665265764, "alpha_loss": -0.005153513705683133, "alpha_value": 0.09605700278608555, "duration": 107.76892733573914, "step": 81625}
{"episode_reward": 517.4966241038613, "episode": 654.0, "Q1 loss": 7.624559120178223, "Q2 loss": 7.66638159942627, "Mean Target Q": 308.36419555664065, "Mean Q1": 308.36250903320314, "Mean Q2": 308.3629353027344, "critic_loss": 15.290940757751464, "batch_reward": 3.1618682136535643, "actor_loss": -308.78122194351687, "actor_target_entropy": -6.0, "actor_entropy": 3.2824759367973573, "alpha_loss": -0.0026558959826586707, "alpha_value": 0.09608497435232788, "duration": 124.94552850723267, "step": 81750}
{"episode_reward": 565.8552211809925, "episode": 655.0, "Q1 loss": 6.808878028869629, "Q2 loss": 6.821872657775879, "Mean Target Q": 307.9634958496094, "Mean Q1": 307.96160009765623, "Mean Q2": 307.96291845703126, "critic_loss": 13.630750785827637, "batch_reward": 3.1560725803375242, "actor_loss": -308.5503433469742, "actor_target_entropy": -6.0, "actor_entropy": 3.3191032371823748, "alpha_loss": 0.0039026333529147365, "alpha_value": 0.0960869801340178, "duration": 101.79527878761292, "step": 81875}
{"episode_reward": 547.076230845593, "episode": 656.0, "Q1 loss": 7.373354446411133, "Q2 loss": 7.242807510375976, "Mean Target Q": 308.48094384765625, "Mean Q1": 308.4802927246094, "Mean Q2": 308.4782841796875, "critic_loss": 14.616161994934082, "batch_reward": 3.1644492778778077, "actor_loss": -308.0599138813634, "actor_target_entropy": -6.0, "actor_entropy": 3.2571890200338056, "alpha_loss": 0.002145781936574607, "alpha_value": 0.09602714375188727, "duration": 106.78276801109314, "step": 82000}
{"episode_reward": 539.7835589838388, "episode": 657.0, "Q1 loss": 7.236221153259278, "Q2 loss": 7.148820865631103, "Mean Target Q": 309.1189033203125, "Mean Q1": 309.11769580078123, "Mean Q2": 309.12043408203124, "critic_loss": 14.385041976928711, "batch_reward": 3.169306545257568, "actor_loss": -309.5642622690352, "actor_target_entropy": -6.0, "actor_entropy": 3.2844025823805065, "alpha_loss": -0.0157862948438537, "alpha_value": 0.09611614506523661, "duration": 124.72168517112732, "step": 82125}
{"episode_reward": 537.7570563169317, "episode": 658.0, "Q1 loss": 7.628020484924316, "Q2 loss": 7.606745639801026, "Mean Target Q": 308.7734907226563, "Mean Q1": 308.771384765625, "Mean Q2": 308.7727841796875, "critic_loss": 15.234766143798828, "batch_reward": 3.1602044773101805, "actor_loss": -309.2405843427104, "actor_target_entropy": -6.0, "actor_entropy": 3.248264531935415, "alpha_loss": -0.008543848995149376, "alpha_value": 0.09646869083736842, "duration": 98.8241012096405, "step": 82250}
{"episode_reward": 572.0957432390188, "episode": 659.0, "Q1 loss": 7.498654422760009, "Q2 loss": 7.6680195503234865, "Mean Target Q": 308.80931274414064, "Mean Q1": 308.8082551269531, "Mean Q2": 308.80634545898437, "critic_loss": 15.166673942565918, "batch_reward": 3.15788179397583, "actor_loss": -309.0379871186756, "actor_target_entropy": -6.0, "actor_entropy": 3.2898176435440307, "alpha_loss": -0.0008691232097113417, "alpha_value": 0.09654974428833911, "duration": 104.20630979537964, "step": 82375}
{"episode_reward": 575.5755509578189, "episode": 660.0, "Q1 loss": 7.154559303283691, "Q2 loss": 7.3085131950378415, "Mean Target Q": 309.5862802734375, "Mean Q1": 309.5865588378906, "Mean Q2": 309.58723461914065, "critic_loss": 14.463072479248046, "batch_reward": 3.1742839698791503, "actor_loss": -309.6845452093309, "actor_target_entropy": -6.0, "actor_entropy": 3.31051847627086, "alpha_loss": 0.0005183249576798369, "alpha_value": 0.09656797595371384, "duration": 117.49812006950378, "step": 82500}
{"episode_reward": 510.56944904868686, "episode": 661.0, "Q1 loss": 7.1206482238769535, "Q2 loss": 7.125935405731201, "Mean Target Q": 309.5769680175781, "Mean Q1": 309.57746508789063, "Mean Q2": 309.5750368652344, "critic_loss": 14.246583694458009, "batch_reward": 3.1681145343780517, "actor_loss": -309.41539800734745, "actor_target_entropy": -6.0, "actor_entropy": 3.3380304783109636, "alpha_loss": -0.009100024425794207, "alpha_value": 0.09670750946512702, "duration": 111.05409002304077, "step": 82625}
{"episode_reward": 547.8456481561306, "episode": 662.0, "Q1 loss": 7.48016822052002, "Q2 loss": 7.290316307067871, "Mean Target Q": 310.10514453125, "Mean Q1": 310.10229345703124, "Mean Q2": 310.1027001953125, "critic_loss": 14.770484550476073, "batch_reward": 3.1720823516845704, "actor_loss": -309.87103025374876, "actor_target_entropy": -6.0, "actor_entropy": 3.366107709946171, "alpha_loss": -0.004842448562774207, "alpha_value": 0.09684906030264401, "duration": 139.44236278533936, "step": 82750}
{"episode_reward": 500.96208878643716, "episode": 663.0, "Q1 loss": 6.9060462379455565, "Q2 loss": 6.906182083129883, "Mean Target Q": 309.947490234375, "Mean Q1": 309.94683740234376, "Mean Q2": 309.9482214355469, "critic_loss": 13.812228324890137, "batch_reward": 3.173104866027832, "actor_loss": -310.22227260044644, "actor_target_entropy": -6.0, "actor_entropy": 3.269866496797592, "alpha_loss": 0.007730435805454377, "alpha_value": 0.09683730787765527, "duration": 130.29568815231323, "step": 82875}
{"episode_reward": 466.0334450701463, "episode": 664.0, "Q1 loss": 10.564086406707764, "Q2 loss": 10.491021564483642, "Mean Target Q": 309.64055419921874, "Mean Q1": 309.6323715820312, "Mean Q2": 309.6336005859375, "critic_loss": 21.055108070373535, "batch_reward": 3.170402681350708, "actor_loss": -309.67741098711565, "actor_target_entropy": -6.0, "actor_entropy": 3.28306979902329, "alpha_loss": -0.0042673984632617045, "alpha_value": 0.09675199680269234, "duration": 108.20495128631592, "step": 83000}
{"episode_reward": 508.2355622269154, "episode": 665.0, "Q1 loss": 9.973424457550049, "Q2 loss": 9.941023414611816, "Mean Target Q": 310.3219777832031, "Mean Q1": 310.319568359375, "Mean Q2": 310.31762475585936, "critic_loss": 19.914447868347168, "batch_reward": 3.1691554832458495, "actor_loss": -310.6262376573351, "actor_target_entropy": -6.0, "actor_entropy": 3.3492743817586748, "alpha_loss": -0.01842380114757116, "alpha_value": 0.09709567517632549, "duration": 127.31253910064697, "step": 83125}
{"episode_reward": 571.8553772704918, "episode": 666.0, "Q1 loss": 8.341944435119629, "Q2 loss": 8.27775690460205, "Mean Target Q": 310.59997192382815, "Mean Q1": 310.602984375, "Mean Q2": 310.60118237304687, "critic_loss": 16.619701316833495, "batch_reward": 3.1781667156219484, "actor_loss": -310.73677161432084, "actor_target_entropy": -6.0, "actor_entropy": 3.404001574362478, "alpha_loss": -0.005906556594005275, "alpha_value": 0.09730648022073293, "duration": 134.5568745136261, "step": 83250}
{"episode_reward": 506.88252420814956, "episode": 667.0, "Q1 loss": 9.991360904693604, "Q2 loss": 9.641518562316895, "Mean Target Q": 310.7556960449219, "Mean Q1": 310.7565114746094, "Mean Q2": 310.75781420898437, "critic_loss": 19.632879501342774, "batch_reward": 3.18192195892334, "actor_loss": -310.95711117699034, "actor_target_entropy": -6.0, "actor_entropy": 3.3373512654077437, "alpha_loss": -0.013189522919082453, "alpha_value": 0.09755903692757499, "duration": 157.03837275505066, "step": 83375}
{"episode_reward": 568.5034746999436, "episode": 668.0, "Q1 loss": 8.191493381500244, "Q2 loss": 8.077230556488036, "Mean Target Q": 310.84380004882814, "Mean Q1": 310.83781640625, "Mean Q2": 310.8389636230469, "critic_loss": 16.268723991394044, "batch_reward": 3.1754220962524413, "actor_loss": -311.1731375417402, "actor_target_entropy": -6.0, "actor_entropy": 3.352229445211349, "alpha_loss": -0.0020447257350409225, "alpha_value": 0.09781972799829636, "duration": 139.17782878875732, "step": 83500}
{"episode_reward": 566.0089082709256, "episode": 669.0, "Q1 loss": 9.792717906951903, "Q2 loss": 9.868414623260499, "Mean Target Q": 311.0871789550781, "Mean Q1": 311.0839091796875, "Mean Q2": 311.08418920898436, "critic_loss": 19.661132797241212, "batch_reward": 3.184490085601807, "actor_loss": -311.5778401692708, "actor_target_entropy": -6.0, "actor_entropy": 3.290986640112741, "alpha_loss": -0.007286017657154136, "alpha_value": 0.09789477767032069, "duration": 162.61516666412354, "step": 83625}
{"episode_reward": 476.2551853293129, "episode": 670.0, "Q1 loss": 9.503747081756591, "Q2 loss": 9.290971416473388, "Mean Target Q": 311.4539645996094, "Mean Q1": 311.45115234375, "Mean Q2": 311.4514919433594, "critic_loss": 18.794718505859375, "batch_reward": 3.181273983001709, "actor_loss": -311.90971866730723, "actor_target_entropy": -6.0, "actor_entropy": 3.4119454391541018, "alpha_loss": -0.013472856202673527, "alpha_value": 0.09822598490612813, "duration": 127.59467124938965, "step": 83750}
{"episode_reward": 528.5638865492874, "episode": 671.0, "Q1 loss": 8.329017822265625, "Q2 loss": 8.377743343353272, "Mean Target Q": 311.59587109375, "Mean Q1": 311.5951806640625, "Mean Q2": 311.59025024414063, "critic_loss": 16.706761184692382, "batch_reward": 3.181348659515381, "actor_loss": -311.809823172433, "actor_target_entropy": -6.0, "actor_entropy": 3.355696231599838, "alpha_loss": -0.009809722554766469, "alpha_value": 0.09841408857959863, "duration": 129.96461749076843, "step": 83875}
{"episode_reward": 595.4569559432289, "episode": 672.0, "Q1 loss": 8.033630882263184, "Q2 loss": 8.217467723846436, "Mean Target Q": 311.7693759765625, "Mean Q1": 311.7669611816406, "Mean Q2": 311.77113012695315, "critic_loss": 16.251098571777344, "batch_reward": 3.1887131462097167, "actor_loss": -311.9687017625378, "actor_target_entropy": -6.0, "actor_entropy": 3.373826842154226, "alpha_loss": -0.0054949297937714765, "alpha_value": 0.09872933978849018, "duration": 117.91150116920471, "step": 84000}
{"episode_reward": 536.2434835907997, "episode": 673.0, "Q1 loss": 7.454959281921386, "Q2 loss": 7.608785572052002, "Mean Target Q": 311.974599609375, "Mean Q1": 311.9739130859375, "Mean Q2": 311.974458984375, "critic_loss": 15.063744758605957, "batch_reward": 3.191165365219116, "actor_loss": -312.11891295417905, "actor_target_entropy": -6.0, "actor_entropy": 3.3342840974293058, "alpha_loss": -0.0008167424017474765, "alpha_value": 0.09874171863573188, "duration": 108.35554075241089, "step": 84125}
{"episode_reward": 305.25535048437047, "episode": 674.0, "Q1 loss": 8.502374523162842, "Q2 loss": 8.254736610412598, "Mean Target Q": 312.1320588378906, "Mean Q1": 312.13494799804687, "Mean Q2": 312.135373046875, "critic_loss": 16.757111167907716, "batch_reward": 3.183988067626953, "actor_loss": -311.9584685294859, "actor_target_entropy": -6.0, "actor_entropy": 3.4388757213469474, "alpha_loss": 0.009720692959343713, "alpha_value": 0.09860868478152571, "duration": 111.98357272148132, "step": 84250}
{"episode_reward": 511.0188686538993, "episode": 675.0, "Q1 loss": 7.629748531341553, "Q2 loss": 7.681501014709473, "Mean Target Q": 312.7220305175781, "Mean Q1": 312.7167604980469, "Mean Q2": 312.71514990234374, "critic_loss": 15.311249557495117, "batch_reward": 3.1981620826721193, "actor_loss": -313.2806672595796, "actor_target_entropy": -6.0, "actor_entropy": 3.329380743087284, "alpha_loss": -0.005724610372756918, "alpha_value": 0.09854947258560433, "duration": 143.7229664325714, "step": 84375}
{"episode_reward": 547.3938706851545, "episode": 676.0, "Q1 loss": 8.132515018463135, "Q2 loss": 8.069293190002442, "Mean Target Q": 312.75740747070313, "Mean Q1": 312.75183471679685, "Mean Q2": 312.753142578125, "critic_loss": 16.201808265686036, "batch_reward": 3.1938564777374268, "actor_loss": -313.2359146610383, "actor_target_entropy": -6.0, "actor_entropy": 3.349850220064963, "alpha_loss": 0.0014732133112697592, "alpha_value": 0.09862990117191464, "duration": 120.63612484931946, "step": 84500}
{"episode_reward": 601.0023874963429, "episode": 677.0, "Q1 loss": 7.659812744140625, "Q2 loss": 7.653960052490234, "Mean Target Q": 312.3477041015625, "Mean Q1": 312.34453515625, "Mean Q2": 312.3457744140625, "critic_loss": 15.31377286529541, "batch_reward": 3.1898135414123536, "actor_loss": -312.6447206527468, "actor_target_entropy": -6.0, "actor_entropy": 3.3192575356316945, "alpha_loss": -0.002820800228547009, "alpha_value": 0.09864653428099561, "duration": 116.07989859580994, "step": 84625}
{"episode_reward": 545.0455380756538, "episode": 678.0, "Q1 loss": 7.8486705513000485, "Q2 loss": 7.9153007125854495, "Mean Target Q": 312.9787536621094, "Mean Q1": 312.97860229492187, "Mean Q2": 312.97629516601563, "critic_loss": 15.763971229553222, "batch_reward": 3.2002336254119874, "actor_loss": -313.08638295819685, "actor_target_entropy": -6.0, "actor_entropy": 3.2733666550728584, "alpha_loss": 0.00020297506688943793, "alpha_value": 0.09861798246468592, "duration": 122.72385835647583, "step": 84750}
{"episode_reward": 545.6466057641088, "episode": 679.0, "Q1 loss": 7.307544315338135, "Q2 loss": 7.159275051116944, "Mean Target Q": 312.8800341796875, "Mean Q1": 312.8783649902344, "Mean Q2": 312.87954296875, "critic_loss": 14.466819435119628, "batch_reward": 3.195701333999634, "actor_loss": -313.0450933547247, "actor_target_entropy": -6.0, "actor_entropy": 3.3571561480325367, "alpha_loss": 0.0003640710021413508, "alpha_value": 0.09861773016088429, "duration": 126.22089958190918, "step": 84875}
{"episode_reward": 614.0801790981391, "episode": 680.0, "Q1 loss": 7.822768009185791, "Q2 loss": 7.936554576873779, "Mean Target Q": 313.4023012695312, "Mean Q1": 313.3976682128906, "Mean Q2": 313.3987971191406, "critic_loss": 15.759322563171386, "batch_reward": 3.2018555526733397, "actor_loss": -314.13078012774065, "actor_target_entropy": -6.0, "actor_entropy": 3.3725468650940926, "alpha_loss": 0.004055212976621284, "alpha_value": 0.09852360563029447, "step": 85000}
{"duration": 173.66510009765625, "step": 85000}
{"episode_reward": 504.37620803219454, "episode": 681.0, "Q1 loss": 7.379608821868897, "Q2 loss": 7.45677452468872, "Mean Target Q": 313.83852734375, "Mean Q1": 313.8386591796875, "Mean Q2": 313.8379055175781, "critic_loss": 14.836383407592773, "batch_reward": 3.2058806018829347, "actor_loss": -314.2031012641059, "actor_target_entropy": -6.0, "actor_entropy": 3.416314302928864, "alpha_loss": -0.008246117737144232, "alpha_value": 0.09864613469445226, "duration": 167.33078527450562, "step": 85125}
{"episode_reward": 523.1043808589401, "episode": 682.0, "Q1 loss": 7.367147556304932, "Q2 loss": 7.274057865142822, "Mean Target Q": 313.7826018066406, "Mean Q1": 313.7790556640625, "Mean Q2": 313.7813674316406, "critic_loss": 14.641205413818358, "batch_reward": 3.1963458614349367, "actor_loss": -313.64395535376764, "actor_target_entropy": -6.0, "actor_entropy": 3.3664553626891105, "alpha_loss": -0.00031525581969969697, "alpha_value": 0.0987100137139503, "duration": 152.40770077705383, "step": 85250}
{"episode_reward": 587.3127826960871, "episode": 683.0, "Q1 loss": 7.052886798858642, "Q2 loss": 7.061574851989746, "Mean Target Q": 313.95728369140625, "Mean Q1": 313.95842358398437, "Mean Q2": 313.9560534667969, "critic_loss": 14.114461647033691, "batch_reward": 3.2120509223937987, "actor_loss": -314.0581345331101, "actor_target_entropy": -6.0, "actor_entropy": 3.2897857560051813, "alpha_loss": 0.003842620352756173, "alpha_value": 0.09869027287718025, "duration": 156.93914556503296, "step": 85375}
{"episode_reward": 538.060466922823, "episode": 684.0, "Q1 loss": 7.689677913665771, "Q2 loss": 7.396553524017334, "Mean Target Q": 314.9526154785156, "Mean Q1": 314.9579753417969, "Mean Q2": 314.95657666015626, "critic_loss": 15.08623146057129, "batch_reward": 3.219693609237671, "actor_loss": -314.8846888388357, "actor_target_entropy": -6.0, "actor_entropy": 3.364708158277696, "alpha_loss": 0.0013762328308075666, "alpha_value": 0.09861104256273096, "duration": 144.4402174949646, "step": 85500}
{"episode_reward": 561.9022937779039, "episode": 685.0, "Q1 loss": 7.542595676422119, "Q2 loss": 7.596450538635254, "Mean Target Q": 314.44206787109374, "Mean Q1": 314.43606396484375, "Mean Q2": 314.4397814941406, "critic_loss": 15.139046218872071, "batch_reward": 3.2145712451934814, "actor_loss": -314.92955235072543, "actor_target_entropy": -6.0, "actor_entropy": 3.3180720579056513, "alpha_loss": -0.0019293413497507572, "alpha_value": 0.09863871752652936, "duration": 147.53340363502502, "step": 85625}
{"episode_reward": 579.5633965546862, "episode": 686.0, "Q1 loss": 6.985587287902832, "Q2 loss": 7.169774112701416, "Mean Target Q": 314.5420144042969, "Mean Q1": 314.54022729492186, "Mean Q2": 314.535349609375, "critic_loss": 14.15536142730713, "batch_reward": 3.2192518920898436, "actor_loss": -314.4452819824219, "actor_target_entropy": -6.0, "actor_entropy": 3.359062983143714, "alpha_loss": 0.002557386407598613, "alpha_value": 0.09855597521599886, "duration": 95.2009482383728, "step": 85750}
{"episode_reward": 566.0691435988837, "episode": 687.0, "Q1 loss": 7.764708965301514, "Q2 loss": 7.697889575958252, "Mean Target Q": 314.5555622558594, "Mean Q1": 314.5572143554688, "Mean Q2": 314.5592785644531, "critic_loss": 15.462598541259766, "batch_reward": 3.209250072479248, "actor_loss": -314.99000186011904, "actor_target_entropy": -6.0, "actor_entropy": 3.232398309404888, "alpha_loss": 8.711875379381198e-05, "alpha_value": 0.09860807787186442, "duration": 91.88587427139282, "step": 85875}
{"episode_reward": 560.9921910208914, "episode": 688.0, "Q1 loss": 8.594128650665283, "Q2 loss": 8.711159317016602, "Mean Target Q": 314.69638647460937, "Mean Q1": 314.6865810546875, "Mean Q2": 314.6893161621094, "critic_loss": 17.30528798675537, "batch_reward": 3.214803192138672, "actor_loss": -314.59289058562246, "actor_target_entropy": -6.0, "actor_entropy": 3.2444868856860745, "alpha_loss": 0.005531302469241764, "alpha_value": 0.0984849756553206, "duration": 97.46509170532227, "step": 86000}
{"episode_reward": 568.9933043216082, "episode": 689.0, "Q1 loss": 8.740895156860352, "Q2 loss": 8.494526725769044, "Mean Target Q": 315.24093334960935, "Mean Q1": 315.24344360351563, "Mean Q2": 315.2391203613281, "critic_loss": 17.235421875, "batch_reward": 3.2224086513519286, "actor_loss": -315.283453078497, "actor_target_entropy": -6.0, "actor_entropy": 3.32454002092755, "alpha_loss": -0.0025595712941139936, "alpha_value": 0.09855521411860521, "duration": 98.47618579864502, "step": 86125}
{"episode_reward": 538.7324473038345, "episode": 690.0, "Q1 loss": 7.63920639038086, "Q2 loss": 7.5081781501770015, "Mean Target Q": 315.65223046875, "Mean Q1": 315.64719921875, "Mean Q2": 315.6473649902344, "critic_loss": 15.147384521484375, "batch_reward": 3.228042060852051, "actor_loss": -315.1270294189453, "actor_target_entropy": -6.0, "actor_entropy": 3.2975205259938396, "alpha_loss": 0.002272741076716733, "alpha_value": 0.09850765370679788, "duration": 113.80105495452881, "step": 86250}
{"episode_reward": 554.2312172697046, "episode": 691.0, "Q1 loss": 8.35367946624756, "Q2 loss": 8.284458564758301, "Mean Target Q": 315.75004467773437, "Mean Q1": 315.75086328125, "Mean Q2": 315.7500412597656, "critic_loss": 16.63813801574707, "batch_reward": 3.219843194961548, "actor_loss": -316.3453577435206, "actor_target_entropy": -6.0, "actor_entropy": 3.2825585395570784, "alpha_loss": -0.008035298614274888, "alpha_value": 0.098571720676741, "duration": 117.96045422554016, "step": 86375}
{"episode_reward": 610.5009672037908, "episode": 692.0, "Q1 loss": 7.433548515319824, "Q2 loss": 7.485680587768555, "Mean Target Q": 315.18747680664063, "Mean Q1": 315.18798608398436, "Mean Q2": 315.1874943847656, "critic_loss": 14.919229202270508, "batch_reward": 3.218696054458618, "actor_loss": -315.1791416291268, "actor_target_entropy": -6.0, "actor_entropy": 3.386514832896571, "alpha_loss": 0.010412617676681089, "alpha_value": 0.09859654927883407, "duration": 137.7164487838745, "step": 86500}
{"episode_reward": 579.895257093352, "episode": 693.0, "Q1 loss": 7.5266268272399905, "Q2 loss": 7.364616706848144, "Mean Target Q": 315.56546240234377, "Mean Q1": 315.55755712890624, "Mean Q2": 315.5645419921875, "critic_loss": 14.891243507385253, "batch_reward": 3.226564300537109, "actor_loss": -315.81724717881946, "actor_target_entropy": -6.0, "actor_entropy": 3.3112346255590044, "alpha_loss": -0.00023632489943078587, "alpha_value": 0.09841594663204081, "duration": 129.3689877986908, "step": 86625}
{"episode_reward": 546.5848345826007, "episode": 694.0, "Q1 loss": 7.864199634552002, "Q2 loss": 7.859478183746338, "Mean Target Q": 315.83648803710935, "Mean Q1": 315.8375788574219, "Mean Q2": 315.83583862304687, "critic_loss": 15.723677810668946, "batch_reward": 3.217487775802612, "actor_loss": -316.22584533691406, "actor_target_entropy": -6.0, "actor_entropy": 3.324730646225714, "alpha_loss": 0.004471756807047754, "alpha_value": 0.09835369124501171, "duration": 157.07479906082153, "step": 86750}
{"episode_reward": 588.1446696904571, "episode": 695.0, "Q1 loss": 7.58536580657959, "Q2 loss": 7.544189666748047, "Mean Target Q": 315.82353784179685, "Mean Q1": 315.82121044921877, "Mean Q2": 315.82071337890625, "critic_loss": 15.129555427551269, "batch_reward": 3.2211015853881837, "actor_loss": -316.0710250612289, "actor_target_entropy": -6.0, "actor_entropy": 3.302075563915192, "alpha_loss": 0.00400949234793347, "alpha_value": 0.09811934256914286, "duration": 164.4180052280426, "step": 86875}
{"episode_reward": 447.03378226698334, "episode": 696.0, "Q1 loss": 7.460248573303223, "Q2 loss": 7.376968917846679, "Mean Target Q": 316.30822119140623, "Mean Q1": 316.308759765625, "Mean Q2": 316.30714892578123, "critic_loss": 14.837217498779298, "batch_reward": 3.226559600830078, "actor_loss": -316.1229769799017, "actor_target_entropy": -6.0, "actor_entropy": 3.375465746848814, "alpha_loss": -0.005763341207057238, "alpha_value": 0.0982863396545354, "duration": 185.61636900901794, "step": 87000}
{"episode_reward": 504.9760381801011, "episode": 697.0, "Q1 loss": 7.58532169342041, "Q2 loss": 7.546702068328857, "Mean Target Q": 316.91593872070314, "Mean Q1": 316.9123625488281, "Mean Q2": 316.9143583984375, "critic_loss": 15.132023735046387, "batch_reward": 3.2370700073242187, "actor_loss": -317.30870952303445, "actor_target_entropy": -6.0, "actor_entropy": 3.328378681152586, "alpha_loss": -0.0014035745656916074, "alpha_value": 0.09826738378494759, "duration": 196.31518816947937, "step": 87125}
{"episode_reward": 557.301536764697, "episode": 698.0, "Q1 loss": 8.481348167419434, "Q2 loss": 8.526640033721923, "Mean Target Q": 316.7624924316406, "Mean Q1": 316.76461865234376, "Mean Q2": 316.7623500976562, "critic_loss": 17.007988174438477, "batch_reward": 3.2337885265350343, "actor_loss": -316.3257338000882, "actor_target_entropy": -6.0, "actor_entropy": 3.401269312827818, "alpha_loss": -0.00869761511773592, "alpha_value": 0.0984407017289927, "duration": 183.0558624267578, "step": 87250}
{"episode_reward": 579.9124378720542, "episode": 699.0, "Q1 loss": 7.547752433776855, "Q2 loss": 7.798126441955566, "Mean Target Q": 316.206638671875, "Mean Q1": 316.19964526367187, "Mean Q2": 316.20386572265625, "critic_loss": 15.345878982543946, "batch_reward": 3.2320063915252684, "actor_loss": -316.6700289287264, "actor_target_entropy": -6.0, "actor_entropy": 3.379408488197932, "alpha_loss": -0.0049823507710936524, "alpha_value": 0.09862985713781945, "duration": 155.37565183639526, "step": 87375}
{"episode_reward": 579.6589997321031, "episode": 700.0, "Q1 loss": 8.271205825805664, "Q2 loss": 8.20096197128296, "Mean Target Q": 317.16148608398436, "Mean Q1": 317.1649853515625, "Mean Q2": 317.1613154296875, "critic_loss": 16.472167747497558, "batch_reward": 3.2470264511108398, "actor_loss": -317.1476839127079, "actor_target_entropy": -6.0, "actor_entropy": 3.411063140438449, "alpha_loss": -0.0034344181823994843, "alpha_value": 0.09868014418473749, "duration": 156.6579670906067, "step": 87500}
{"episode_reward": 525.5249307861136, "episode": 701.0, "Q1 loss": 8.410688941955566, "Q2 loss": 8.235037471771241, "Mean Target Q": 317.60781225585936, "Mean Q1": 317.601615234375, "Mean Q2": 317.6060166015625, "critic_loss": 16.645726470947267, "batch_reward": 3.2458813095092776, "actor_loss": -317.43736727275547, "actor_target_entropy": -6.0, "actor_entropy": 3.390972338025532, "alpha_loss": 0.003117680549621582, "alpha_value": 0.09874319877323214, "duration": 148.06693291664124, "step": 87625}
{"episode_reward": 526.6103401304912, "episode": 702.0, "Q1 loss": 7.530682010650635, "Q2 loss": 7.486860969543457, "Mean Target Q": 317.74349658203124, "Mean Q1": 317.74226391601565, "Mean Q2": 317.74181201171876, "critic_loss": 15.017542961120606, "batch_reward": 3.236615156173706, "actor_loss": -318.29133950510334, "actor_target_entropy": -6.0, "actor_entropy": 3.3790198833711687, "alpha_loss": 0.009073771393647598, "alpha_value": 0.09863939690376286, "duration": 128.95211958885193, "step": 87750}
{"episode_reward": 569.3445052115737, "episode": 703.0, "Q1 loss": 6.539118747711182, "Q2 loss": 6.592106353759766, "Mean Target Q": 317.2613051757813, "Mean Q1": 317.26047412109375, "Mean Q2": 317.25855346679685, "critic_loss": 13.131225032806396, "batch_reward": 3.2297806186676024, "actor_loss": -317.4738352942088, "actor_target_entropy": -6.0, "actor_entropy": 3.2840787607526023, "alpha_loss": 0.00020619370191106722, "alpha_value": 0.0984662767309289, "duration": 134.8196620941162, "step": 87875}
{"episode_reward": 537.7637842920584, "episode": 704.0, "Q1 loss": 6.816334053039551, "Q2 loss": 6.808528617858887, "Mean Target Q": 317.4420705566406, "Mean Q1": 317.44004418945315, "Mean Q2": 317.4417551269531, "critic_loss": 13.624862678527832, "batch_reward": 3.2481783199310303, "actor_loss": -317.48173030730214, "actor_target_entropy": -6.0, "actor_entropy": 3.2533688160680954, "alpha_loss": 0.007951646900525498, "alpha_value": 0.09837811768333832, "duration": 158.8397581577301, "step": 88000}
{"episode_reward": 527.600768813941, "episode": 705.0, "Q1 loss": 6.858788078308105, "Q2 loss": 6.846838756561279, "Mean Target Q": 317.2813498535156, "Mean Q1": 317.27831689453126, "Mean Q2": 317.27748974609375, "critic_loss": 13.705626838684083, "batch_reward": 3.2348355560302733, "actor_loss": -317.44593253968253, "actor_target_entropy": -6.0, "actor_entropy": 3.2632565649728926, "alpha_loss": 0.0046155839005396476, "alpha_value": 0.09819287142157888, "duration": 162.16562008857727, "step": 88125}
{"episode_reward": 591.6908014055409, "episode": 706.0, "Q1 loss": 6.699009117126465, "Q2 loss": 6.6261102447509765, "Mean Target Q": 318.1904658203125, "Mean Q1": 318.1908479003906, "Mean Q2": 318.1898090820313, "critic_loss": 13.325119388580323, "batch_reward": 3.241797149658203, "actor_loss": -318.2899932861328, "actor_target_entropy": -6.0, "actor_entropy": 3.286324004973135, "alpha_loss": 0.00013117120420980837, "alpha_value": 0.09822605826059391, "duration": 153.19695019721985, "step": 88250}
{"episode_reward": 584.2471230607587, "episode": 707.0, "Q1 loss": 7.208814300537109, "Q2 loss": 7.235604064941406, "Mean Target Q": 317.899994140625, "Mean Q1": 317.89854125976564, "Mean Q2": 317.89931127929685, "critic_loss": 14.44441837310791, "batch_reward": 3.2496856937408447, "actor_loss": -318.26342918759303, "actor_target_entropy": -6.0, "actor_entropy": 3.252624401970515, "alpha_loss": -0.00677792264872955, "alpha_value": 0.09825140883272333, "duration": 149.38417267799377, "step": 88375}
{"episode_reward": 583.2604762458302, "episode": 708.0, "Q1 loss": 7.067514675140381, "Q2 loss": 6.998374027252197, "Mean Target Q": 318.09820532226564, "Mean Q1": 318.09766455078125, "Mean Q2": 318.1004592285156, "critic_loss": 14.065888694763183, "batch_reward": 3.241962577819824, "actor_loss": -318.49866460984754, "actor_target_entropy": -6.0, "actor_entropy": 3.3305358694445704, "alpha_loss": -0.002460141748850865, "alpha_value": 0.0983724433768057, "duration": 145.90232944488525, "step": 88500}
{"episode_reward": 497.9915300746388, "episode": 709.0, "Q1 loss": 6.891416740417481, "Q2 loss": 6.892446048736573, "Mean Target Q": 318.782494140625, "Mean Q1": 318.78121044921875, "Mean Q2": 318.7821337890625, "critic_loss": 13.783862823486329, "batch_reward": 3.2446376991271975, "actor_loss": -318.8368307446677, "actor_target_entropy": -6.0, "actor_entropy": 3.2837191195715043, "alpha_loss": -0.005257291353440711, "alpha_value": 0.09847990196560107, "duration": 140.11526560783386, "step": 88625}
{"episode_reward": 541.2957645624019, "episode": 710.0, "Q1 loss": 6.677448997497558, "Q2 loss": 6.464261627197265, "Mean Target Q": 318.94041650390625, "Mean Q1": 318.94052807617186, "Mean Q2": 318.94032055664064, "critic_loss": 13.141710700988769, "batch_reward": 3.254987943649292, "actor_loss": -319.1992724018712, "actor_target_entropy": -6.0, "actor_entropy": 3.2558817017462944, "alpha_loss": -0.005573075163298317, "alpha_value": 0.09859308362384608, "duration": 159.80741381645203, "step": 88750}
{"episode_reward": 549.8711740865643, "episode": 711.0, "Q1 loss": 7.49174861907959, "Q2 loss": 7.448344009399414, "Mean Target Q": 318.86331567382814, "Mean Q1": 318.86302368164064, "Mean Q2": 318.8619482421875, "critic_loss": 14.94009260559082, "batch_reward": 3.253993968963623, "actor_loss": -319.1939978221106, "actor_target_entropy": -6.0, "actor_entropy": 3.2977079815334744, "alpha_loss": 0.0006442098870932583, "alpha_value": 0.09866222778466172, "duration": 147.42399787902832, "step": 88875}
{"episode_reward": 485.6924387592541, "episode": 712.0, "Q1 loss": 7.615859138488769, "Q2 loss": 7.781434577941894, "Mean Target Q": 318.93674560546873, "Mean Q1": 318.92993334960937, "Mean Q2": 318.9308798828125, "critic_loss": 15.39729370880127, "batch_reward": 3.254494775772095, "actor_loss": -318.7927910589403, "actor_target_entropy": -6.0, "actor_entropy": 3.3014898684716996, "alpha_loss": -0.00795565185046965, "alpha_value": 0.09877807815586107, "duration": 166.89954495429993, "step": 89000}
{"episode_reward": 567.7031738891483, "episode": 713.0, "Q1 loss": 7.4175362930297855, "Q2 loss": 7.612883987426758, "Mean Target Q": 319.48853295898436, "Mean Q1": 319.49322021484375, "Mean Q2": 319.4924846191406, "critic_loss": 15.030420341491698, "batch_reward": 3.260707290649414, "actor_loss": -319.58231123666917, "actor_target_entropy": -6.0, "actor_entropy": 3.283168217492482, "alpha_loss": -0.010458591453258007, "alpha_value": 0.09896221356464996, "duration": 152.9522783756256, "step": 89125}
{"episode_reward": 569.6205468227857, "episode": 714.0, "Q1 loss": 7.26156555557251, "Q2 loss": 7.248123600006103, "Mean Target Q": 319.20421118164063, "Mean Q1": 319.19584521484376, "Mean Q2": 319.1958166503906, "critic_loss": 14.509689193725587, "batch_reward": 3.241465887069702, "actor_loss": -319.82108036164317, "actor_target_entropy": -6.0, "actor_entropy": 3.2259730715905466, "alpha_loss": -0.01327608959118445, "alpha_value": 0.09935351395036658, "duration": 137.6703646183014, "step": 89250}
{"episode_reward": 565.6218750661795, "episode": 715.0, "Q1 loss": 7.6035580177307125, "Q2 loss": 7.563446083068848, "Mean Target Q": 320.0277858886719, "Mean Q1": 320.0338247070313, "Mean Q2": 320.032302734375, "critic_loss": 15.167004081726073, "batch_reward": 3.2638493156433106, "actor_loss": -320.4725656660776, "actor_target_entropy": -6.0, "actor_entropy": 3.3317048284742565, "alpha_loss": -0.01027031259478203, "alpha_value": 0.09950970700700168, "duration": 92.0509192943573, "step": 89375}
{"episode_reward": 581.9333462483045, "episode": 716.0, "Q1 loss": 8.244478206634522, "Q2 loss": 8.289487350463867, "Mean Target Q": 320.0424033203125, "Mean Q1": 320.0371369628906, "Mean Q2": 320.0393935546875, "critic_loss": 16.533965545654297, "batch_reward": 3.2644256839752197, "actor_loss": -320.08166208574846, "actor_target_entropy": -6.0, "actor_entropy": 3.3242895910816808, "alpha_loss": -0.0077894892723810285, "alpha_value": 0.09987476242707666, "duration": 90.57588052749634, "step": 89500}
{"episode_reward": 585.8749958922712, "episode": 717.0, "Q1 loss": 9.247852951049804, "Q2 loss": 9.135632816314697, "Mean Target Q": 320.0774514160156, "Mean Q1": 320.07651171875, "Mean Q2": 320.07598876953125, "critic_loss": 18.38348568725586, "batch_reward": 3.253147829055786, "actor_loss": -320.24082728794644, "actor_target_entropy": -6.0, "actor_entropy": 3.2248178588019476, "alpha_loss": -0.0190448071216307, "alpha_value": 0.10014277784584343, "duration": 91.8592140674591, "step": 89625}
{"episode_reward": 550.8299315376561, "episode": 718.0, "Q1 loss": 7.553259239196778, "Q2 loss": 7.446255985260009, "Mean Target Q": 320.7013520507812, "Mean Q1": 320.6970234375, "Mean Q2": 320.69757006835937, "critic_loss": 14.999515151977539, "batch_reward": 3.2818450355529785, "actor_loss": -320.9996126236454, "actor_target_entropy": -6.0, "actor_entropy": 3.292708335384246, "alpha_loss": -0.002755866938030287, "alpha_value": 0.10046641632224315, "duration": 92.96046137809753, "step": 89750}
{"episode_reward": 478.4440423487773, "episode": 719.0, "Q1 loss": 7.527280574798584, "Q2 loss": 7.4139334564208985, "Mean Target Q": 320.2650100097656, "Mean Q1": 320.262654296875, "Mean Q2": 320.26393115234373, "critic_loss": 14.94121403503418, "batch_reward": 3.265450777053833, "actor_loss": -319.96622236948167, "actor_target_entropy": -6.0, "actor_entropy": 3.278559234407213, "alpha_loss": -0.0021315043688648278, "alpha_value": 0.10044847294122129, "duration": 85.16670322418213, "step": 89875}
{"episode_reward": 524.7567114619749, "episode": 720.0, "Q1 loss": 7.116617965698242, "Q2 loss": 7.3155986633300785, "Mean Target Q": 320.648349609375, "Mean Q1": 320.6477053222656, "Mean Q2": 320.6476374511719, "critic_loss": 14.43221671295166, "batch_reward": 3.263963165283203, "actor_loss": -320.5765154438634, "actor_target_entropy": -6.0, "actor_entropy": 3.260858243511569, "alpha_loss": -0.010004736024946455, "alpha_value": 0.10061149295705038, "step": 90000}
{"duration": 152.38145327568054, "step": 90000}
{"episode_reward": 529.5827045600334, "episode": 721.0, "Q1 loss": 7.1791123046875, "Q2 loss": 7.094169105529785, "Mean Target Q": 320.69217724609376, "Mean Q1": 320.6903566894531, "Mean Q2": 320.6910983886719, "critic_loss": 14.273281425476075, "batch_reward": 3.258452953338623, "actor_loss": -320.9078587123326, "actor_target_entropy": -6.0, "actor_entropy": 3.388334838170854, "alpha_loss": 0.002832638425013376, "alpha_value": 0.10077454517543571, "duration": 152.8834524154663, "step": 90125}
{"episode_reward": 563.6672199145739, "episode": 722.0, "Q1 loss": 7.1896999740600585, "Q2 loss": 7.218048320770263, "Mean Target Q": 321.38783520507815, "Mean Q1": 321.38492163085937, "Mean Q2": 321.3845544433594, "critic_loss": 14.407748268127442, "batch_reward": 3.2722121295928956, "actor_loss": -322.0375420355028, "actor_target_entropy": -6.0, "actor_entropy": 3.353581597728114, "alpha_loss": 0.004474224860689813, "alpha_value": 0.10062344834106747, "duration": 103.39401316642761, "step": 90250}
{"episode_reward": 564.1033141910807, "episode": 723.0, "Q1 loss": 7.046351947784424, "Q2 loss": 7.112395351409912, "Mean Target Q": 321.13364697265627, "Mean Q1": 321.13767578125, "Mean Q2": 321.137095703125, "critic_loss": 14.15874725341797, "batch_reward": 3.275743703842163, "actor_loss": -321.104486374628, "actor_target_entropy": -6.0, "actor_entropy": 3.269851113122607, "alpha_loss": 0.00399405016962971, "alpha_value": 0.10055714700534814, "duration": 101.13707065582275, "step": 90375}
{"episode_reward": 517.2232281002256, "episode": 724.0, "Q1 loss": 7.580808326721192, "Q2 loss": 7.4391899681091305, "Mean Target Q": 321.55929736328125, "Mean Q1": 321.5601010742188, "Mean Q2": 321.5593745117188, "critic_loss": 15.019998222351074, "batch_reward": 3.276876817703247, "actor_loss": -322.6649647374307, "actor_target_entropy": -6.0, "actor_entropy": 3.2211622538105136, "alpha_loss": -0.011249595329225544, "alpha_value": 0.1005642033462285, "duration": 110.99832344055176, "step": 90500}
{"episode_reward": 602.2644161966356, "episode": 725.0, "Q1 loss": 7.569482326507568, "Q2 loss": 7.662689456939697, "Mean Target Q": 321.9757041015625, "Mean Q1": 321.96974487304686, "Mean Q2": 321.9686333007813, "critic_loss": 15.23217180633545, "batch_reward": 3.2889131488800047, "actor_loss": -322.059084937686, "actor_target_entropy": -6.0, "actor_entropy": 3.307541086560204, "alpha_loss": 0.00554462256915276, "alpha_value": 0.10063247372014265, "duration": 99.54170346260071, "step": 90625}
{"episode_reward": 569.6413156084864, "episode": 726.0, "Q1 loss": 7.9661997680664065, "Q2 loss": 7.848558559417724, "Mean Target Q": 321.43238623046875, "Mean Q1": 321.427599609375, "Mean Q2": 321.43185961914065, "critic_loss": 15.81475830078125, "batch_reward": 3.2799722347259523, "actor_loss": -321.4693618282195, "actor_target_entropy": -6.0, "actor_entropy": 3.3096554740782707, "alpha_loss": -0.008141783509223212, "alpha_value": 0.10073974500050106, "duration": 86.50975513458252, "step": 90750}
{"episode_reward": 545.6644304975259, "episode": 727.0, "Q1 loss": 7.673901599884033, "Q2 loss": 7.688464706420898, "Mean Target Q": 321.2925539550781, "Mean Q1": 321.28390478515627, "Mean Q2": 321.282275390625, "critic_loss": 15.362366348266601, "batch_reward": 3.2673716678619384, "actor_loss": -321.3036561996218, "actor_target_entropy": -6.0, "actor_entropy": 3.365052722749256, "alpha_loss": 0.0033336624185303374, "alpha_value": 0.100739479776922, "duration": 91.28358149528503, "step": 90875}
{"episode_reward": 495.5221993896986, "episode": 728.0, "Q1 loss": 7.383216602325439, "Q2 loss": 7.385544841766357, "Mean Target Q": 321.797720703125, "Mean Q1": 321.80646923828124, "Mean Q2": 321.80909716796873, "critic_loss": 14.768761352539062, "batch_reward": 3.272939952850342, "actor_loss": -322.01561367896295, "actor_target_entropy": -6.0, "actor_entropy": 3.373971385340537, "alpha_loss": 0.001105935906150168, "alpha_value": 0.10074239746648869, "duration": 99.22834396362305, "step": 91000}
{"episode_reward": 494.8892040055353, "episode": 729.0, "Q1 loss": 8.960543788909913, "Q2 loss": 8.869354316711426, "Mean Target Q": 322.4375627441406, "Mean Q1": 322.43559155273437, "Mean Q2": 322.43083178710935, "critic_loss": 17.82989806365967, "batch_reward": 3.283653757095337, "actor_loss": -322.67103697761655, "actor_target_entropy": -6.0, "actor_entropy": 3.3897758060031467, "alpha_loss": 0.001002160728805595, "alpha_value": 0.10070755478659833, "duration": 98.7112078666687, "step": 91125}
{"episode_reward": 534.6751277211292, "episode": 730.0, "Q1 loss": 9.825853107452392, "Q2 loss": 9.794756256103515, "Mean Target Q": 322.7887551269531, "Mean Q1": 322.7894052734375, "Mean Q2": 322.78852270507815, "critic_loss": 19.620609405517577, "batch_reward": 3.289790782928467, "actor_loss": -323.08097051805066, "actor_target_entropy": -6.0, "actor_entropy": 3.3903709457766626, "alpha_loss": -0.008082676183191998, "alpha_value": 0.1007940120515966, "duration": 147.50710463523865, "step": 91250}
{"episode_reward": 564.5330311224623, "episode": 731.0, "Q1 loss": 8.293618579864502, "Q2 loss": 8.40964485168457, "Mean Target Q": 323.0495576171875, "Mean Q1": 323.0406320800781, "Mean Q2": 323.0436259765625, "critic_loss": 16.703263412475586, "batch_reward": 3.291039218902588, "actor_loss": -322.99280996171257, "actor_target_entropy": -6.0, "actor_entropy": 3.3718458130246116, "alpha_loss": 0.0022638119897612978, "alpha_value": 0.10084482717373479, "duration": 153.70087242126465, "step": 91375}
{"episode_reward": 564.9948462405399, "episode": 732.0, "Q1 loss": 9.735703758239746, "Q2 loss": 9.62642113494873, "Mean Target Q": 323.07916381835935, "Mean Q1": 323.08178442382814, "Mean Q2": 323.0781962890625, "critic_loss": 19.362124931335448, "batch_reward": 3.297852563858032, "actor_loss": -323.38272242392264, "actor_target_entropy": -6.0, "actor_entropy": 3.394430648896002, "alpha_loss": 0.0025180783160331267, "alpha_value": 0.10078115186980369, "duration": 166.65785360336304, "step": 91500}
{"episode_reward": 573.7749930578985, "episode": 733.0, "Q1 loss": 7.8877959747314454, "Q2 loss": 7.939363288879394, "Mean Target Q": 323.0245266113281, "Mean Q1": 323.02233618164064, "Mean Q2": 323.02663549804686, "critic_loss": 15.827159202575684, "batch_reward": 3.287087465286255, "actor_loss": -323.06793309771825, "actor_target_entropy": -6.0, "actor_entropy": 3.4513371369195363, "alpha_loss": -0.002509609881108479, "alpha_value": 0.10077837638585668, "duration": 151.8008155822754, "step": 91625}
{"episode_reward": 497.4641559057565, "episode": 734.0, "Q1 loss": 8.235150665283204, "Q2 loss": 8.118073726654053, "Mean Target Q": 322.77737158203126, "Mean Q1": 322.7707680664063, "Mean Q2": 322.76820654296876, "critic_loss": 16.353224380493163, "batch_reward": 3.2870577392578126, "actor_loss": -322.90708726452243, "actor_target_entropy": -6.0, "actor_entropy": 3.333621444240693, "alpha_loss": 0.004759427546823938, "alpha_value": 0.10076519484085376, "duration": 152.55902194976807, "step": 91750}
{"episode_reward": 618.0811813981726, "episode": 735.0, "Q1 loss": 8.204248367309571, "Q2 loss": 8.13994566345215, "Mean Target Q": 323.45301147460935, "Mean Q1": 323.4563662109375, "Mean Q2": 323.4582058105469, "critic_loss": 16.344194038391112, "batch_reward": 3.290547918319702, "actor_loss": -323.64749823676215, "actor_target_entropy": -6.0, "actor_entropy": 3.370330288296654, "alpha_loss": -0.01341483737563803, "alpha_value": 0.10088050871218916, "duration": 148.03325629234314, "step": 91875}
{"episode_reward": 554.055410224134, "episode": 736.0, "Q1 loss": 7.709265533447265, "Q2 loss": 7.572514333724976, "Mean Target Q": 323.96071704101564, "Mean Q1": 323.9568547363281, "Mean Q2": 323.955822265625, "critic_loss": 15.281779876708985, "batch_reward": 3.2938971157073973, "actor_loss": -324.0881510088521, "actor_target_entropy": -6.0, "actor_entropy": 3.438989108608615, "alpha_loss": -0.0019463029269489549, "alpha_value": 0.10107609034705904, "duration": 102.71376347541809, "step": 92000}
{"episode_reward": 588.8187249064182, "episode": 737.0, "Q1 loss": 8.10950499343872, "Q2 loss": 7.953770931243897, "Mean Target Q": 323.86191381835937, "Mean Q1": 323.859611328125, "Mean Q2": 323.8623740234375, "critic_loss": 16.063275939941406, "batch_reward": 3.2907057304382326, "actor_loss": -324.2092009044829, "actor_target_entropy": -6.0, "actor_entropy": 3.298514176928808, "alpha_loss": 0.005380570400683652, "alpha_value": 0.1009985784038224, "duration": 125.46832299232483, "step": 92125}
{"episode_reward": 528.0949918977868, "episode": 738.0, "Q1 loss": 8.220126831054687, "Q2 loss": 8.030791286468506, "Mean Target Q": 323.82263452148436, "Mean Q1": 323.81848852539065, "Mean Q2": 323.81540014648436, "critic_loss": 16.250918197631837, "batch_reward": 3.29314252281189, "actor_loss": -323.74046079574094, "actor_target_entropy": -6.0, "actor_entropy": 3.3944104602259975, "alpha_loss": 0.0019791083440424935, "alpha_value": 0.10094734296520533, "duration": 155.7257204055786, "step": 92250}
{"episode_reward": 563.5204667230832, "episode": 739.0, "Q1 loss": 7.330806186676026, "Q2 loss": 7.14759366607666, "Mean Target Q": 323.55012158203124, "Mean Q1": 323.5574912109375, "Mean Q2": 323.5546787109375, "critic_loss": 14.478399848937988, "batch_reward": 3.2904037170410154, "actor_loss": -323.95301261780753, "actor_target_entropy": -6.0, "actor_entropy": 3.4176678316933766, "alpha_loss": -0.0039479244234306475, "alpha_value": 0.10098329120426296, "duration": 152.46661043167114, "step": 92375}
{"episode_reward": 394.1585275002034, "episode": 740.0, "Q1 loss": 7.026068447113037, "Q2 loss": 7.011866722106934, "Mean Target Q": 324.837974609375, "Mean Q1": 324.8333374023438, "Mean Q2": 324.8333679199219, "critic_loss": 14.037935195922852, "batch_reward": 3.302109561920166, "actor_loss": -325.0095790739982, "actor_target_entropy": -6.0, "actor_entropy": 3.3833041306464904, "alpha_loss": -0.009633323267823266, "alpha_value": 0.10116914249340692, "duration": 138.63178324699402, "step": 92500}
{"episode_reward": 523.0769511325293, "episode": 741.0, "Q1 loss": 7.57735241317749, "Q2 loss": 7.419678985595703, "Mean Target Q": 324.29384790039063, "Mean Q1": 324.2905126953125, "Mean Q2": 324.29187451171873, "critic_loss": 14.997031387329102, "batch_reward": 3.294678691864014, "actor_loss": -323.94473799448167, "actor_target_entropy": -6.0, "actor_entropy": 3.3254162735409207, "alpha_loss": 0.001907586164417721, "alpha_value": 0.10121094860632747, "duration": 150.49921011924744, "step": 92625}
{"episode_reward": 552.57946264403, "episode": 742.0, "Q1 loss": 7.462502590179444, "Q2 loss": 7.205429607391357, "Mean Target Q": 324.3442844238281, "Mean Q1": 324.34278784179685, "Mean Q2": 324.34214477539064, "critic_loss": 14.66793214416504, "batch_reward": 3.297118341445923, "actor_loss": -324.1375924387286, "actor_target_entropy": -6.0, "actor_entropy": 3.3620023612053163, "alpha_loss": -0.004178414263972832, "alpha_value": 0.10131437893883537, "duration": 163.4732129573822, "step": 92750}
{"episode_reward": 515.9669262447708, "episode": 743.0, "Q1 loss": 7.039594955444336, "Q2 loss": 7.009221744537354, "Mean Target Q": 325.0363603515625, "Mean Q1": 325.0367333984375, "Mean Q2": 325.03809814453126, "critic_loss": 14.048816734313965, "batch_reward": 3.3014273166656496, "actor_loss": -325.1594771127852, "actor_target_entropy": -6.0, "actor_entropy": 3.3900050511435857, "alpha_loss": -0.0045421367015926134, "alpha_value": 0.10139271398147907, "duration": 152.63599133491516, "step": 92875}
{"episode_reward": 475.6370307950755, "episode": 744.0, "Q1 loss": 7.170811222076416, "Q2 loss": 7.28571146774292, "Mean Target Q": 324.695142578125, "Mean Q1": 324.6949765625, "Mean Q2": 324.6924560546875, "critic_loss": 14.45652271270752, "batch_reward": 3.3076591415405274, "actor_loss": -325.4118529289, "actor_target_entropy": -6.0, "actor_entropy": 3.3605230931312806, "alpha_loss": -0.0005845801994925545, "alpha_value": 0.1013797170395512, "duration": 148.89357805252075, "step": 93000}
{"episode_reward": 554.1690812613381, "episode": 745.0, "Q1 loss": 7.795547557830811, "Q2 loss": 7.65823791885376, "Mean Target Q": 324.8146428222656, "Mean Q1": 324.80781079101564, "Mean Q2": 324.81000903320313, "critic_loss": 15.453785453796387, "batch_reward": 3.3065137062072756, "actor_loss": -325.1549745589968, "actor_target_entropy": -6.0, "actor_entropy": 3.3296630306849404, "alpha_loss": 0.006545376716299899, "alpha_value": 0.10138422888548797, "duration": 151.61928820610046, "step": 93125}
{"episode_reward": 564.2323110566614, "episode": 746.0, "Q1 loss": 7.74660948562622, "Q2 loss": 7.630854221343994, "Mean Target Q": 324.7452282714844, "Mean Q1": 324.74678051757815, "Mean Q2": 324.7478674316406, "critic_loss": 15.37746371459961, "batch_reward": 3.3032276935577394, "actor_loss": -325.4111062326739, "actor_target_entropy": -6.0, "actor_entropy": 3.3312280985616867, "alpha_loss": 0.005209041522785781, "alpha_value": 0.1011085359815611, "duration": 155.8166766166687, "step": 93250}
{"episode_reward": 506.7486356789151, "episode": 747.0, "Q1 loss": 7.9409641227722165, "Q2 loss": 7.824358001708984, "Mean Target Q": 325.596431640625, "Mean Q1": 325.5930869140625, "Mean Q2": 325.5925673828125, "critic_loss": 15.765322082519532, "batch_reward": 3.309633159637451, "actor_loss": -326.4129401312934, "actor_target_entropy": -6.0, "actor_entropy": 3.2726117807721335, "alpha_loss": 0.0014508981479420548, "alpha_value": 0.101126948514257, "duration": 159.972754240036, "step": 93375}
{"episode_reward": 560.4786502615108, "episode": 748.0, "Q1 loss": 7.122572238922119, "Q2 loss": 6.992552303314209, "Mean Target Q": 325.81906689453126, "Mean Q1": 325.8171965332031, "Mean Q2": 325.820810546875, "critic_loss": 14.115124496459961, "batch_reward": 3.3163732414245604, "actor_loss": -325.8700034849105, "actor_target_entropy": -6.0, "actor_entropy": 3.3093938404513943, "alpha_loss": -0.0024424597598432054, "alpha_value": 0.10118446326857905, "duration": 140.31495237350464, "step": 93500}
{"episode_reward": 549.121564516427, "episode": 749.0, "Q1 loss": 7.113416675567627, "Q2 loss": 7.020013839721679, "Mean Target Q": 326.526451171875, "Mean Q1": 326.5293046875, "Mean Q2": 326.5220627441406, "critic_loss": 14.133430488586425, "batch_reward": 3.3233517990112307, "actor_loss": -326.9586796836248, "actor_target_entropy": -6.0, "actor_entropy": 3.3250142922477117, "alpha_loss": 0.0020130541552567764, "alpha_value": 0.10112928835074135, "duration": 148.73486495018005, "step": 93625}
{"episode_reward": 605.4233518022546, "episode": 750.0, "Q1 loss": 7.282532978057861, "Q2 loss": 7.252477336883545, "Mean Target Q": 326.00051245117186, "Mean Q1": 325.994423828125, "Mean Q2": 325.9962648925781, "critic_loss": 14.535010345458984, "batch_reward": 3.3129771728515625, "actor_loss": -326.3268777170489, "actor_target_entropy": -6.0, "actor_entropy": 3.331777737986657, "alpha_loss": 0.007438810256820532, "alpha_value": 0.1010245399735643, "duration": 153.33107352256775, "step": 93750}
{"episode_reward": 571.9122897241898, "episode": 751.0, "Q1 loss": 7.506762260437012, "Q2 loss": 7.42467147064209, "Mean Target Q": 325.7176296386719, "Mean Q1": 325.721107421875, "Mean Q2": 325.72009594726563, "critic_loss": 14.93143367767334, "batch_reward": 3.31961856842041, "actor_loss": -326.26523650638643, "actor_target_entropy": -6.0, "actor_entropy": 3.374103197975764, "alpha_loss": -0.001087562328884526, "alpha_value": 0.10089536167724872, "duration": 152.13013982772827, "step": 93875}
{"episode_reward": 573.3133355322304, "episode": 752.0, "Q1 loss": 7.034260593414307, "Q2 loss": 7.1528892364501955, "Mean Target Q": 325.90789990234373, "Mean Q1": 325.90279223632814, "Mean Q2": 325.90546752929686, "critic_loss": 14.187149833679198, "batch_reward": 3.3097955627441404, "actor_loss": -326.5183361422631, "actor_target_entropy": -6.0, "actor_entropy": 3.36216668159731, "alpha_loss": 0.0040490181343029105, "alpha_value": 0.10098639748928889, "duration": 146.3806025981903, "step": 94000}
{"episode_reward": 606.7911009712936, "episode": 753.0, "Q1 loss": 7.276425931930542, "Q2 loss": 7.107147037506103, "Mean Target Q": 326.3997919921875, "Mean Q1": 326.3947224121094, "Mean Q2": 326.3957824707031, "critic_loss": 14.383572929382325, "batch_reward": 3.3128924388885497, "actor_loss": -326.50807020399304, "actor_target_entropy": -6.0, "actor_entropy": 3.3812767626747253, "alpha_loss": 0.003944201102953345, "alpha_value": 0.10088931969789477, "duration": 135.44325637817383, "step": 94125}
{"episode_reward": 615.8241336890769, "episode": 754.0, "Q1 loss": 7.66507723236084, "Q2 loss": 7.640225658416748, "Mean Target Q": 326.453185546875, "Mean Q1": 326.45429077148435, "Mean Q2": 326.45481591796874, "critic_loss": 15.305302864074706, "batch_reward": 3.3204092712402344, "actor_loss": -327.40950898201237, "actor_target_entropy": -6.0, "actor_entropy": 3.3673165152149815, "alpha_loss": -0.004352300867228018, "alpha_value": 0.1008063254070905, "duration": 138.91574788093567, "step": 94250}
{"episode_reward": 537.1831260786337, "episode": 755.0, "Q1 loss": 7.465088165283203, "Q2 loss": 7.383312866210938, "Mean Target Q": 326.26767602539064, "Mean Q1": 326.266701171875, "Mean Q2": 326.2646337890625, "critic_loss": 14.848401054382323, "batch_reward": 3.3153902378082276, "actor_loss": -326.6198362320188, "actor_target_entropy": -6.0, "actor_entropy": 3.3634435638548834, "alpha_loss": 0.013220973098502746, "alpha_value": 0.10068636212889212, "duration": 171.53029227256775, "step": 94375}
{"episode_reward": 575.5581002655582, "episode": 756.0, "Q1 loss": 8.019901885986329, "Q2 loss": 8.119162296295166, "Mean Target Q": 326.3887143554688, "Mean Q1": 326.39267041015626, "Mean Q2": 326.3914470214844, "critic_loss": 16.13906416320801, "batch_reward": 3.3154679145812986, "actor_loss": -327.27300434727823, "actor_target_entropy": -6.0, "actor_entropy": 3.2581190986018025, "alpha_loss": 0.0008653469398737916, "alpha_value": 0.10051356558479388, "duration": 158.95208883285522, "step": 94500}
{"episode_reward": 526.442110421177, "episode": 757.0, "Q1 loss": 7.580299377441406, "Q2 loss": 7.557603733062744, "Mean Target Q": 326.63805712890627, "Mean Q1": 326.63372875976563, "Mean Q2": 326.63250244140625, "critic_loss": 15.137903007507324, "batch_reward": 3.328150194168091, "actor_loss": -326.87169877309645, "actor_target_entropy": -6.0, "actor_entropy": 3.349568946020944, "alpha_loss": 0.003985520271170471, "alpha_value": 0.10051958138266084, "duration": 162.2908172607422, "step": 94625}
{"episode_reward": 482.678613572951, "episode": 758.0, "Q1 loss": 7.847363719940185, "Q2 loss": 7.882580493927002, "Mean Target Q": 326.99576318359374, "Mean Q1": 326.9874738769531, "Mean Q2": 326.991423828125, "critic_loss": 15.729944305419922, "batch_reward": 3.3219027004241943, "actor_loss": -327.08406608335434, "actor_target_entropy": -6.0, "actor_entropy": 3.3790420870627127, "alpha_loss": 0.008451686743947287, "alpha_value": 0.10022473888900894, "duration": 132.4020392894745, "step": 94750}
{"episode_reward": 589.169708574526, "episode": 759.0, "Q1 loss": 7.812592567443848, "Q2 loss": 7.756725440979004, "Mean Target Q": 327.09994482421877, "Mean Q1": 327.1073361816406, "Mean Q2": 327.1043120117188, "critic_loss": 15.56931800842285, "batch_reward": 3.3261637439727783, "actor_loss": -327.24053567553324, "actor_target_entropy": -6.0, "actor_entropy": 3.3891312735421315, "alpha_loss": 0.006357512695507871, "alpha_value": 0.10010598431434738, "duration": 91.6512348651886, "step": 94875}
{"episode_reward": 532.8112217302964, "episode": 760.0, "Q1 loss": 8.315279472351074, "Q2 loss": 8.379605819702148, "Mean Target Q": 326.88377099609374, "Mean Q1": 326.8774953613281, "Mean Q2": 326.876712890625, "critic_loss": 16.69488525390625, "batch_reward": 3.3323560447692873, "actor_loss": -327.31984144641507, "actor_target_entropy": -6.0, "actor_entropy": 3.3458772128628147, "alpha_loss": -0.004344213768960007, "alpha_value": 0.10006046962876268, "step": 95000}
{"duration": 102.52685928344727, "step": 95000}
{"episode_reward": 565.6334057858675, "episode": 761.0, "Q1 loss": 7.248851341247558, "Q2 loss": 7.263615982055664, "Mean Target Q": 327.17269873046877, "Mean Q1": 327.164341796875, "Mean Q2": 327.1671994628906, "critic_loss": 14.512467323303223, "batch_reward": 3.3223267307281494, "actor_loss": -327.65479581318203, "actor_target_entropy": -6.0, "actor_entropy": 3.373207338272579, "alpha_loss": -0.0045940275969249865, "alpha_value": 0.10019933808553665, "duration": 93.34923100471497, "step": 95125}
{"episode_reward": 541.0360657106033, "episode": 762.0, "Q1 loss": 6.91335994720459, "Q2 loss": 6.906878467559815, "Mean Target Q": 327.0118461914063, "Mean Q1": 327.01577001953126, "Mean Q2": 327.0129604492187, "critic_loss": 13.820238426208496, "batch_reward": 3.3231443786621093, "actor_loss": -327.2130865281628, "actor_target_entropy": -6.0, "actor_entropy": 3.332844195827361, "alpha_loss": -0.010009772542323317, "alpha_value": 0.1003691018048556, "duration": 93.45183801651001, "step": 95250}
{"episode_reward": 533.2389881363254, "episode": 763.0, "Q1 loss": 7.301039947509766, "Q2 loss": 7.161632804870606, "Mean Target Q": 327.41269677734374, "Mean Q1": 327.4121376953125, "Mean Q2": 327.4083889160156, "critic_loss": 14.462672821044922, "batch_reward": 3.3275797538757326, "actor_loss": -327.61797805059524, "actor_target_entropy": -6.0, "actor_entropy": 3.3396941442338246, "alpha_loss": 0.0006980817203247358, "alpha_value": 0.10047488161448966, "duration": 98.152188539505, "step": 95375}
{"episode_reward": 576.6666135174361, "episode": 764.0, "Q1 loss": 7.969173587799072, "Q2 loss": 8.079736915588379, "Mean Target Q": 328.01992138671875, "Mean Q1": 328.01581005859373, "Mean Q2": 328.023248046875, "critic_loss": 16.04891045379639, "batch_reward": 3.3366508598327638, "actor_loss": -328.3068680301789, "actor_target_entropy": -6.0, "actor_entropy": 3.3595990096369097, "alpha_loss": -0.017644310227384972, "alpha_value": 0.10068805055384182, "duration": 84.50479006767273, "step": 95500}
{"episode_reward": 562.3297377538039, "episode": 765.0, "Q1 loss": 7.4471521453857425, "Q2 loss": 7.44105708694458, "Mean Target Q": 328.31654223632813, "Mean Q1": 328.3147607421875, "Mean Q2": 328.31389819335936, "critic_loss": 14.888209144592285, "batch_reward": 3.3370508613586427, "actor_loss": -328.6240922231523, "actor_target_entropy": -6.0, "actor_entropy": 3.3929717237987216, "alpha_loss": -0.008292122640543513, "alpha_value": 0.10100939217844476, "duration": 81.26185345649719, "step": 95625}
{"episode_reward": 549.9530452999237, "episode": 766.0, "Q1 loss": 6.701150299072266, "Q2 loss": 6.6169488258361815, "Mean Target Q": 328.0905017089844, "Mean Q1": 328.0880107421875, "Mean Q2": 328.08858984375, "critic_loss": 13.318099136352538, "batch_reward": 3.3313230743408204, "actor_loss": -328.55843623991933, "actor_target_entropy": -6.0, "actor_entropy": 3.3483605807827366, "alpha_loss": -0.005329064810798774, "alpha_value": 0.10119751504402663, "duration": 72.37494587898254, "step": 95750}
{"episode_reward": 540.7513157751955, "episode": 767.0, "Q1 loss": 6.731632740020752, "Q2 loss": 6.767530391693115, "Mean Target Q": 328.33849609375, "Mean Q1": 328.34059912109376, "Mean Q2": 328.3382980957031, "critic_loss": 13.49916318511963, "batch_reward": 3.338609313964844, "actor_loss": -328.71080186631946, "actor_target_entropy": -6.0, "actor_entropy": 3.297663056661212, "alpha_loss": 0.004324772664981466, "alpha_value": 0.10119869549650982, "duration": 84.18382930755615, "step": 95875}
{"episode_reward": 555.3390739340476, "episode": 768.0, "Q1 loss": 7.488382831573486, "Q2 loss": 7.4433388404846195, "Mean Target Q": 328.13036865234375, "Mean Q1": 328.12338842773437, "Mean Q2": 328.12430615234376, "critic_loss": 14.93172159576416, "batch_reward": 3.332067527770996, "actor_loss": -328.3615909699471, "actor_target_entropy": -6.0, "actor_entropy": 3.302040673071338, "alpha_loss": -0.002233633294611448, "alpha_value": 0.10115053143917344, "duration": 87.72123837471008, "step": 96000}
{"episode_reward": 603.9285879042058, "episode": 769.0, "Q1 loss": 7.099731670379638, "Q2 loss": 7.107884998321533, "Mean Target Q": 328.63927490234374, "Mean Q1": 328.6340178222656, "Mean Q2": 328.6359494628906, "critic_loss": 14.207616706848144, "batch_reward": 3.3310480880737305, "actor_loss": -328.5703643314422, "actor_target_entropy": -6.0, "actor_entropy": 3.312353875901964, "alpha_loss": 0.008690824795011726, "alpha_value": 0.10116737407864829, "duration": 100.48907208442688, "step": 96125}
{"episode_reward": 559.4877286135109, "episode": 770.0, "Q1 loss": 6.75633016204834, "Q2 loss": 6.780009346008301, "Mean Target Q": 329.2830534667969, "Mean Q1": 329.2899128417969, "Mean Q2": 329.28785375976565, "critic_loss": 13.536339553833008, "batch_reward": 3.346968023300171, "actor_loss": -329.5146779706401, "actor_target_entropy": -6.0, "actor_entropy": 3.2875109141872776, "alpha_loss": 0.006569971578315862, "alpha_value": 0.10087913648426496, "duration": 123.862468957901, "step": 96250}
{"episode_reward": 588.806928212316, "episode": 771.0, "Q1 loss": 7.3016933250427245, "Q2 loss": 7.256391273498535, "Mean Target Q": 328.8889538574219, "Mean Q1": 328.886525390625, "Mean Q2": 328.88718115234377, "critic_loss": 14.558084621429444, "batch_reward": 3.352993797302246, "actor_loss": -328.9849393329923, "actor_target_entropy": -6.0, "actor_entropy": 3.253890737654671, "alpha_loss": -0.001148116242672716, "alpha_value": 0.10079697599929534, "duration": 72.86518669128418, "step": 96375}
{"episode_reward": 530.8282740061219, "episode": 772.0, "Q1 loss": 7.084692790985107, "Q2 loss": 7.220194404602051, "Mean Target Q": 329.1470085449219, "Mean Q1": 329.1425563964844, "Mean Q2": 329.14193774414065, "critic_loss": 14.304887184143066, "batch_reward": 3.340697914123535, "actor_loss": -329.5154773342994, "actor_target_entropy": -6.0, "actor_entropy": 3.331503368193103, "alpha_loss": -0.0009972894519206979, "alpha_value": 0.10084844663752376, "duration": 77.97959065437317, "step": 96500}
{"episode_reward": 534.2764816621324, "episode": 773.0, "Q1 loss": 7.654472095489502, "Q2 loss": 7.775145519256592, "Mean Target Q": 329.2581457519531, "Mean Q1": 329.260298828125, "Mean Q2": 329.26125341796876, "critic_loss": 15.429617584228515, "batch_reward": 3.3443983764648437, "actor_loss": -329.58045160202755, "actor_target_entropy": -6.0, "actor_entropy": 3.3958419693840876, "alpha_loss": -0.0023228533802524447, "alpha_value": 0.10089472075527575, "duration": 79.21260356903076, "step": 96625}
{"episode_reward": 594.0802388558768, "episode": 774.0, "Q1 loss": 8.467296825408935, "Q2 loss": 8.407538604736327, "Mean Target Q": 330.21586572265625, "Mean Q1": 330.2159169921875, "Mean Q2": 330.21697534179685, "critic_loss": 16.874835350036623, "batch_reward": 3.3588673362731933, "actor_loss": -330.1546798213836, "actor_target_entropy": -6.0, "actor_entropy": 3.3612146646745744, "alpha_loss": -0.0022458601273566245, "alpha_value": 0.10098035122036297, "duration": 72.60575079917908, "step": 96750}
{"episode_reward": 478.08882454184084, "episode": 775.0, "Q1 loss": 7.49476354598999, "Q2 loss": 7.238790084838867, "Mean Target Q": 329.697494140625, "Mean Q1": 329.7008146972656, "Mean Q2": 329.69674389648435, "critic_loss": 14.733553672790528, "batch_reward": 3.353521436691284, "actor_loss": -330.1749437120226, "actor_target_entropy": -6.0, "actor_entropy": 3.300931219070677, "alpha_loss": 0.002791438717395067, "alpha_value": 0.10100052658503228, "duration": 70.81825613975525, "step": 96875}
{"episode_reward": 564.0625062511924, "episode": 776.0, "Q1 loss": 7.225245384216309, "Q2 loss": 7.226321781158448, "Mean Target Q": 330.00541625976564, "Mean Q1": 329.99411328125, "Mean Q2": 329.9978081054688, "critic_loss": 14.451567138671875, "batch_reward": 3.354026720046997, "actor_loss": -330.48922237273183, "actor_target_entropy": -6.0, "actor_entropy": 3.3819105894334855, "alpha_loss": -0.0042894950451990285, "alpha_value": 0.10096312091689522, "duration": 74.88156986236572, "step": 97000}
{"episode_reward": 600.6547755769312, "episode": 777.0, "Q1 loss": 7.557345390319824, "Q2 loss": 7.626954978942871, "Mean Target Q": 329.9899250488281, "Mean Q1": 329.99205712890625, "Mean Q2": 329.99168481445315, "critic_loss": 15.18430044555664, "batch_reward": 3.3402295207977293, "actor_loss": -329.8540320017981, "actor_target_entropy": -6.0, "actor_entropy": 3.378770945564149, "alpha_loss": -0.0010491345772549274, "alpha_value": 0.1010018222987995, "duration": 70.90580439567566, "step": 97125}
{"episode_reward": 563.4724681479, "episode": 778.0, "Q1 loss": 8.603445430755615, "Q2 loss": 8.57716301727295, "Mean Target Q": 329.87614868164064, "Mean Q1": 329.87118359375, "Mean Q2": 329.87246240234373, "critic_loss": 17.180608451843263, "batch_reward": 3.3383783740997313, "actor_loss": -330.00233114919354, "actor_target_entropy": -6.0, "actor_entropy": 3.3782864039944065, "alpha_loss": 0.0008122840362991537, "alpha_value": 0.1009768862309381, "duration": 69.59851384162903, "step": 97250}
{"episode_reward": 556.8887090238886, "episode": 779.0, "Q1 loss": 7.914774547576904, "Q2 loss": 8.051357765197753, "Mean Target Q": 330.88646264648435, "Mean Q1": 330.887025390625, "Mean Q2": 330.8873657226562, "critic_loss": 15.966132301330566, "batch_reward": 3.358182855606079, "actor_loss": -330.89290945870533, "actor_target_entropy": -6.0, "actor_entropy": 3.3698642783694797, "alpha_loss": -0.011317301445478012, "alpha_value": 0.10121992884341531, "duration": 72.3368763923645, "step": 97375}
{"episode_reward": 571.566741395781, "episode": 780.0, "Q1 loss": 8.212766670227051, "Q2 loss": 8.137561206817628, "Mean Target Q": 330.6191953125, "Mean Q1": 330.61684912109376, "Mean Q2": 330.6191826171875, "critic_loss": 16.350327911376954, "batch_reward": 3.3500479316711425, "actor_loss": -330.94171093356226, "actor_target_entropy": -6.0, "actor_entropy": 3.3420235456958896, "alpha_loss": -0.002587187272917119, "alpha_value": 0.10134513758878493, "duration": 139.76121592521667, "step": 97500}
{"episode_reward": 561.2419862331908, "episode": 781.0, "Q1 loss": 8.847149402618408, "Q2 loss": 8.777926551818847, "Mean Target Q": 330.85538745117185, "Mean Q1": 330.8558986816406, "Mean Q2": 330.85280249023435, "critic_loss": 17.62507592010498, "batch_reward": 3.3531891136169434, "actor_loss": -330.9596732003348, "actor_target_entropy": -6.0, "actor_entropy": 3.284273999077933, "alpha_loss": 0.0012010758380509084, "alpha_value": 0.10126750512392779, "duration": 126.32055807113647, "step": 97625}
{"episode_reward": 518.2207638928647, "episode": 782.0, "Q1 loss": 9.215644649505615, "Q2 loss": 9.176812164306641, "Mean Target Q": 330.82468310546875, "Mean Q1": 330.8187409667969, "Mean Q2": 330.8202375488281, "critic_loss": 18.39245687866211, "batch_reward": 3.3517355041503905, "actor_loss": -331.1943733461442, "actor_target_entropy": -6.0, "actor_entropy": 3.30586717590209, "alpha_loss": -0.003219347067868277, "alpha_value": 0.10136259965939688, "duration": 115.50347089767456, "step": 97750}
{"episode_reward": 527.9180355068295, "episode": 783.0, "Q1 loss": 7.809176597595215, "Q2 loss": 7.907650562286377, "Mean Target Q": 331.20468920898435, "Mean Q1": 331.20764477539063, "Mean Q2": 331.2070087890625, "critic_loss": 15.716827171325683, "batch_reward": 3.3479268074035646, "actor_loss": -331.43046497163317, "actor_target_entropy": -6.0, "actor_entropy": 3.3708362995632113, "alpha_loss": 0.0010169764485446708, "alpha_value": 0.10136322115858096, "duration": 120.88543462753296, "step": 97875}
{"episode_reward": 584.8098339356163, "episode": 784.0, "Q1 loss": 7.841982372283936, "Q2 loss": 7.604968055725098, "Mean Target Q": 331.4287846679687, "Mean Q1": 331.4216398925781, "Mean Q2": 331.42128247070315, "critic_loss": 15.44695046234131, "batch_reward": 3.3647109413146974, "actor_loss": -331.13705050560736, "actor_target_entropy": -6.0, "actor_entropy": 3.335061196357973, "alpha_loss": -0.0004893976954683181, "alpha_value": 0.10141748803203894, "duration": 68.9608244895935, "step": 98000}
{"episode_reward": 528.9237019118111, "episode": 785.0, "Q1 loss": 8.633661861419677, "Q2 loss": 8.652803512573243, "Mean Target Q": 331.8792404785156, "Mean Q1": 331.880513671875, "Mean Q2": 331.87796875, "critic_loss": 17.286465377807616, "batch_reward": 3.364336414337158, "actor_loss": -332.0243636842758, "actor_target_entropy": -6.0, "actor_entropy": 3.4119821465204634, "alpha_loss": 0.001521197816593543, "alpha_value": 0.10137508094800053, "duration": 73.98777413368225, "step": 98125}
{"episode_reward": 566.5065448470672, "episode": 786.0, "Q1 loss": 8.475302028656007, "Q2 loss": 8.593673599243164, "Mean Target Q": 331.51782983398436, "Mean Q1": 331.51645483398437, "Mean Q2": 331.5192927246094, "critic_loss": 17.068975540161134, "batch_reward": 3.359925645828247, "actor_loss": -332.21216903194306, "actor_target_entropy": -6.0, "actor_entropy": 3.340340079799775, "alpha_loss": 0.0043593616423858025, "alpha_value": 0.10137694815079723, "duration": 72.66330599784851, "step": 98250}
{"episode_reward": 542.6784217651933, "episode": 787.0, "Q1 loss": 7.791462268829346, "Q2 loss": 7.823005840301514, "Mean Target Q": 331.575189453125, "Mean Q1": 331.57363671875, "Mean Q2": 331.5706843261719, "critic_loss": 15.614468086242676, "batch_reward": 3.3605399208068847, "actor_loss": -331.68496897863963, "actor_target_entropy": -6.0, "actor_entropy": 3.3350413451119074, "alpha_loss": -0.006635808955050177, "alpha_value": 0.10129666122425948, "duration": 71.53984022140503, "step": 98375}
{"episode_reward": 562.6105124873701, "episode": 788.0, "Q1 loss": 8.2351096534729, "Q2 loss": 8.080154689788818, "Mean Target Q": 331.4044326171875, "Mean Q1": 331.3998278808594, "Mean Q2": 331.40179052734373, "critic_loss": 16.315264305114745, "batch_reward": 3.362747968673706, "actor_loss": -331.27599211662044, "actor_target_entropy": -6.0, "actor_entropy": 3.326562043159239, "alpha_loss": -0.010178656009356342, "alpha_value": 0.10157715101239007, "duration": 63.175676345825195, "step": 98500}
{"episode_reward": 542.8587767952667, "episode": 789.0, "Q1 loss": 8.839946090698243, "Q2 loss": 9.035304031372071, "Mean Target Q": 331.71450048828126, "Mean Q1": 331.711818359375, "Mean Q2": 331.7158369140625, "critic_loss": 17.87525004577637, "batch_reward": 3.3614212856292727, "actor_loss": -332.17826286194816, "actor_target_entropy": -6.0, "actor_entropy": 3.27542443502517, "alpha_loss": -0.007933288498500746, "alpha_value": 0.10176711845275446, "duration": 61.109004974365234, "step": 98625}
{"episode_reward": 565.8034257513577, "episode": 790.0, "Q1 loss": 7.499974140167236, "Q2 loss": 7.450900451660156, "Mean Target Q": 332.2570895996094, "Mean Q1": 332.2584431152344, "Mean Q2": 332.25816552734375, "critic_loss": 14.950874572753905, "batch_reward": 3.3725873432159426, "actor_loss": -332.6045665125693, "actor_target_entropy": -6.0, "actor_entropy": 3.2995474569259153, "alpha_loss": -0.0020326745561173847, "alpha_value": 0.10189998788584416, "duration": 67.32654166221619, "step": 98750}
{"episode_reward": 566.5714648431748, "episode": 791.0, "Q1 loss": 7.134535018920898, "Q2 loss": 6.911573837280273, "Mean Target Q": 332.3277434082031, "Mean Q1": 332.3296267089844, "Mean Q2": 332.328197265625, "critic_loss": 14.046108764648437, "batch_reward": 3.3680598545074463, "actor_loss": -332.6291983468192, "actor_target_entropy": -6.0, "actor_entropy": 3.279949812662034, "alpha_loss": -0.004965279875914492, "alpha_value": 0.10202321038722124, "duration": 67.17715406417847, "step": 98875}
{"episode_reward": 578.5971854928873, "episode": 792.0, "Q1 loss": 7.4994967041015625, "Q2 loss": 7.63208394241333, "Mean Target Q": 332.6684423828125, "Mean Q1": 332.6666853027344, "Mean Q2": 332.6668271484375, "critic_loss": 15.131580627441407, "batch_reward": 3.376162950515747, "actor_loss": -332.51747032903853, "actor_target_entropy": -6.0, "actor_entropy": 3.2609047658981813, "alpha_loss": 0.007463540622754203, "alpha_value": 0.10203573537844503, "duration": 73.85091614723206, "step": 99000}
{"episode_reward": 547.5118539659296, "episode": 793.0, "Q1 loss": 6.81843822479248, "Q2 loss": 6.8138184700012205, "Mean Target Q": 333.07102734375, "Mean Q1": 333.0714948730469, "Mean Q2": 333.07026147460937, "critic_loss": 13.632256675720216, "batch_reward": 3.3750080680847168, "actor_loss": -333.1854286799355, "actor_target_entropy": -6.0, "actor_entropy": 3.25590617694552, "alpha_loss": -0.0034530929821942535, "alpha_value": 0.10193556604718942, "duration": 66.71058893203735, "step": 99125}
{"episode_reward": 549.9723885361947, "episode": 794.0, "Q1 loss": 7.456112533569336, "Q2 loss": 7.90893856048584, "Mean Target Q": 332.86442993164064, "Mean Q1": 332.8564558105469, "Mean Q2": 332.8583500976562, "critic_loss": 15.365051078796387, "batch_reward": 3.379075517654419, "actor_loss": -333.3689132198211, "actor_target_entropy": -6.0, "actor_entropy": 3.319289476640763, "alpha_loss": -0.0009076288758566784, "alpha_value": 0.10195980330658523, "duration": 68.57856607437134, "step": 99250}
{"episode_reward": 555.2518324954335, "episode": 795.0, "Q1 loss": 10.71276159286499, "Q2 loss": 11.12745329284668, "Mean Target Q": 333.1700158691406, "Mean Q1": 333.16545043945314, "Mean Q2": 333.16588037109375, "critic_loss": 21.8402149810791, "batch_reward": 3.3718673343658447, "actor_loss": -333.5562584286644, "actor_target_entropy": -6.0, "actor_entropy": 3.281139502449641, "alpha_loss": -0.005371365415316726, "alpha_value": 0.10204109444666706, "duration": 73.69889307022095, "step": 99375}
{"episode_reward": 547.4341938575219, "episode": 796.0, "Q1 loss": 9.03310015487671, "Q2 loss": 8.800560531616211, "Mean Target Q": 333.31260302734376, "Mean Q1": 333.31283081054687, "Mean Q2": 333.31387182617186, "critic_loss": 17.83366064453125, "batch_reward": 3.376151292800903, "actor_loss": -333.5813175324471, "actor_target_entropy": -6.0, "actor_entropy": 3.2846347055127545, "alpha_loss": 0.0028304251571816784, "alpha_value": 0.10209604059170947, "duration": 68.72073769569397, "step": 99500}
{"episode_reward": 570.490429137899, "episode": 797.0, "Q1 loss": 9.802990787506104, "Q2 loss": 9.935007061004638, "Mean Target Q": 333.16504711914064, "Mean Q1": 333.16120922851565, "Mean Q2": 333.16211791992185, "critic_loss": 19.737997779846193, "batch_reward": 3.3792082901000975, "actor_loss": -333.59057374984496, "actor_target_entropy": -6.0, "actor_entropy": 3.2855502726539734, "alpha_loss": 0.005419035338693195, "alpha_value": 0.10202026529102957, "duration": 71.3244469165802, "step": 99625}
{"episode_reward": 565.4217330934811, "episode": 798.0, "Q1 loss": 9.443383441925048, "Q2 loss": 9.341661994934082, "Mean Target Q": 333.19091552734375, "Mean Q1": 333.193375, "Mean Q2": 333.19282763671873, "critic_loss": 18.785045501708986, "batch_reward": 3.3715110988616943, "actor_loss": -333.2846118557838, "actor_target_entropy": -6.0, "actor_entropy": 3.3345046312578264, "alpha_loss": 0.004955690061192839, "alpha_value": 0.10185111721537624, "duration": 73.51817178726196, "step": 99750}
{"episode_reward": 541.7789608329425, "episode": 799.0, "Q1 loss": 8.952265216827392, "Q2 loss": 9.314470676422118, "Mean Target Q": 333.369837890625, "Mean Q1": 333.36655078125, "Mean Q2": 333.36833129882814, "critic_loss": 18.26673583984375, "batch_reward": 3.376276210784912, "actor_loss": -334.11909848167784, "actor_target_entropy": -6.0, "actor_entropy": 3.3468603141724116, "alpha_loss": -0.0026615229250478837, "alpha_value": 0.10184300795507097, "duration": 85.17707443237305, "step": 99875}
{"episode_reward": 559.0679148142813, "episode": 800.0, "Q1 loss": 8.134859292737898, "Q2 loss": 8.367985183192838, "Mean Target Q": 333.82383826471147, "Mean Q1": 333.8217052336662, "Mean Q2": 333.8204584429341, "critic_loss": 16.502844541303574, "batch_reward": 3.3864395022392273, "actor_loss": -334.5663398004347, "actor_target_entropy": -6.0, "actor_entropy": 3.2850584099369664, "alpha_loss": -0.012934407857697337, "alpha_value": 0.10203378732831318, "step": 99999}
