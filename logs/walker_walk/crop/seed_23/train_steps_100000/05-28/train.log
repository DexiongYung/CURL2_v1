{"episode_reward": 0.0, "episode": 1.0, "duration": 82.07248187065125, "step": 500}
{"episode_reward": 45.447181319925, "episode": 2.0, "duration": 2.123777151107788, "step": 1000}
{"episode_reward": 30.66754504360952, "episode": 3.0, "Q1 loss": 0.02467654558364302, "Q2 loss": 0.024407147137448192, "Mean Target Q": 1.093896770492196, "Mean Q1": 1.0922756505487488, "Mean Q2": 1.0920882377400993, "critic_loss": 0.04908369201887399, "batch_reward": 0.07639155615866185, "actor_loss": -1.4738537423014642, "actor_target_entropy": -6.0, "actor_entropy": 7.615072622299194, "alpha_loss": 0.9782861151099205, "alpha_value": 0.09874661730103089, "duration": 4917.439801454544, "step": 1500}
{"episode_reward": 36.43341315447275, "episode": 4.0, "Q1 loss": 0.012624625434167683, "Q2 loss": 0.012230615269392729, "Mean Target Q": 2.026942897081375, "Mean Q1": 2.0264144394397734, "Mean Q2": 2.026386787891388, "critic_loss": 0.02485524078272283, "batch_reward": 0.09290547508001328, "actor_loss": -2.4122679595947267, "actor_target_entropy": -6.0, "actor_entropy": 7.775928249359131, "alpha_loss": 0.9683802280426025, "alpha_value": 0.09631010230304811, "duration": 4953.161514520645, "step": 2000}
{"episode_reward": 85.43693547167912, "episode": 5.0, "Q1 loss": 0.02352012684382498, "Q2 loss": 0.022277769891545177, "Mean Target Q": 2.9947941975593566, "Mean Q1": 2.9941469521522524, "Mean Q2": 2.9941052622795103, "critic_loss": 0.04579789686203003, "batch_reward": 0.09886866915225982, "actor_loss": -3.3675561885833742, "actor_target_entropy": -6.0, "actor_entropy": 7.798153373718262, "alpha_loss": 0.9425832905769348, "alpha_value": 0.09397948910734306, "duration": 5190.886088609695, "step": 2500}
{"episode_reward": 59.161939102586594, "episode": 6.0, "Q1 loss": 0.03290220456197858, "Q2 loss": 0.03194713852740824, "Mean Target Q": 4.00668546295166, "Mean Q1": 4.006075479507446, "Mean Q2": 4.006046200275422, "critic_loss": 0.06484934299439192, "batch_reward": 0.10032518836855889, "actor_loss": -4.367482941627502, "actor_target_entropy": -6.0, "actor_entropy": 7.790511442184449, "alpha_loss": 0.9135669822692871, "alpha_value": 0.0917378098075114, "duration": 4556.339219093323, "step": 3000}
{"episode_reward": 35.73892547224435, "episode": 7.0, "Q1 loss": 0.043246397525072096, "Q2 loss": 0.042621440704911945, "Mean Target Q": 4.951259615898132, "Mean Q1": 4.9504669542312625, "Mean Q2": 4.950530222892761, "critic_loss": 0.08586783829331399, "batch_reward": 0.10011350429058075, "actor_loss": -5.309713125228882, "actor_target_entropy": -6.0, "actor_entropy": 7.790319189071655, "alpha_loss": 0.8830042493343353, "alpha_value": 0.08958278805761209, "duration": 3769.541212797165, "step": 3500}
{"episode_reward": 50.01923778622766, "episode": 8.0, "Q1 loss": 0.055437253635376695, "Q2 loss": 0.05535475000366569, "Mean Target Q": 5.795434997558594, "Mean Q1": 5.794780376434326, "Mean Q2": 5.7948317718505855, "critic_loss": 0.11079200384765864, "batch_reward": 0.09757374006509781, "actor_loss": -6.1502191314697265, "actor_target_entropy": -6.0, "actor_entropy": 7.755179119110108, "alpha_loss": 0.8507189943790435, "alpha_value": 0.08750890144691048, "duration": 3251.304076910019, "step": 4000}
{"episode_reward": 40.07266764285666, "episode": 9.0, "Q1 loss": 0.10589054395258427, "Q2 loss": 0.10586605840921402, "Mean Target Q": 6.66785034942627, "Mean Q1": 6.6667812595367435, "Mean Q2": 6.666803862571716, "critic_loss": 0.21175660210847855, "batch_reward": 0.10088389764726162, "actor_loss": -7.013266208648681, "actor_target_entropy": -6.0, "actor_entropy": 7.752521354675293, "alpha_loss": 0.8213719801902771, "alpha_value": 0.0855130779431953, "duration": 4880.89052271843, "step": 4500}
{"episode_reward": 73.87680011460856, "episode": 10.0, "Q1 loss": 0.1558950129598379, "Q2 loss": 0.15668784584105014, "Mean Target Q": 7.445859444618225, "Mean Q1": 7.444527694702148, "Mean Q2": 7.44455553150177, "critic_loss": 0.312582858979702, "batch_reward": 0.10088276270031929, "actor_loss": -7.795200325012207, "actor_target_entropy": -6.0, "actor_entropy": 7.729837446212769, "alpha_loss": 0.7907959277629852, "alpha_value": 0.08358185495766096, "step": 5000}
{"duration": 4965.543548107147, "step": 5000}
{"episode_reward": 41.863092744101, "episode": 11.0, "Q1 loss": 0.24639555197954177, "Q2 loss": 0.24706958991289138, "Mean Target Q": 8.380720690727234, "Mean Q1": 8.37917930984497, "Mean Q2": 8.379304256439209, "critic_loss": 0.49346514177322387, "batch_reward": 0.1090030986815691, "actor_loss": -8.751418138504029, "actor_target_entropy": -6.0, "actor_entropy": 7.619563245773316, "alpha_loss": 0.7441735982894897, "alpha_value": 0.08172942636383755, "duration": 5045.5927011966705, "step": 5500}
{"episode_reward": 123.4596679382616, "episode": 12.0, "Q1 loss": 0.3322924348115921, "Q2 loss": 0.3326078582406044, "Mean Target Q": 9.480693656921387, "Mean Q1": 9.479564720153808, "Mean Q2": 9.479449283599854, "critic_loss": 0.6649002944827079, "batch_reward": 0.11904436315596104, "actor_loss": -9.859295738220215, "actor_target_entropy": -6.0, "actor_entropy": 7.496738035202027, "alpha_loss": 0.7028535327911377, "alpha_value": 0.0799834952161679, "duration": 4922.464671373367, "step": 6000}
{"episode_reward": 102.93552042150304, "episode": 13.0, "Q1 loss": 0.44106664723157885, "Q2 loss": 0.4387725009918213, "Mean Target Q": 10.480008380889892, "Mean Q1": 10.478441484451293, "Mean Q2": 10.478600015640259, "critic_loss": 0.8798391503095627, "batch_reward": 0.12333099980652332, "actor_loss": -10.855956356048583, "actor_target_entropy": -6.0, "actor_entropy": 7.309133344650268, "alpha_loss": 0.6754129240512848, "alpha_value": 0.07828228396999096, "duration": 675.6645529270172, "step": 6500}
{"episode_reward": 68.93761573266787, "episode": 14.0, "Q1 loss": 0.5247250925302506, "Q2 loss": 0.5264402168989182, "Mean Target Q": 11.390145235061645, "Mean Q1": 11.388507530212403, "Mean Q2": 11.388297872543335, "critic_loss": 1.0511653079986572, "batch_reward": 0.12066561618447304, "actor_loss": -11.776609001159668, "actor_target_entropy": -6.0, "actor_entropy": 7.226617012023926, "alpha_loss": 0.6480526294708252, "alpha_value": 0.0766340243312042, "duration": 449.5788698196411, "step": 7000}
{"episode_reward": 34.84504759669307, "episode": 15.0, "Q1 loss": 0.5096863267421723, "Q2 loss": 0.5090185012221337, "Mean Target Q": 12.32638314628601, "Mean Q1": 12.32450146484375, "Mean Q2": 12.324675884246826, "critic_loss": 1.0187048290967942, "batch_reward": 0.11685765267908574, "actor_loss": -12.690697013854981, "actor_target_entropy": -6.0, "actor_entropy": 7.133498106002808, "alpha_loss": 0.6284793882369996, "alpha_value": 0.07501590160416305, "duration": 374.22590589523315, "step": 7500}
{"episode_reward": 36.299327041424135, "episode": 16.0, "Q1 loss": 0.4557445696592331, "Q2 loss": 0.4508211658000946, "Mean Target Q": 13.123776071548463, "Mean Q1": 13.123084978103638, "Mean Q2": 13.122985702514649, "critic_loss": 0.906565737605095, "batch_reward": 0.11370616033673286, "actor_loss": -13.479138942718507, "actor_target_entropy": -6.0, "actor_entropy": 7.078547695159912, "alpha_loss": 0.6211479117870331, "alpha_value": 0.07341211402736697, "duration": 371.97878336906433, "step": 8000}
{"episode_reward": 35.765969321848736, "episode": 17.0, "Q1 loss": 0.506096363067627, "Q2 loss": 0.5039553334116935, "Mean Target Q": 13.930060976028443, "Mean Q1": 13.928303796768189, "Mean Q2": 13.928035970687866, "critic_loss": 1.0100516967773439, "batch_reward": 0.1124595163911581, "actor_loss": -14.269528591156005, "actor_target_entropy": -6.0, "actor_entropy": 7.073475437164307, "alpha_loss": 0.6031995248794556, "alpha_value": 0.07182117060377616, "duration": 353.7159218788147, "step": 8500}
{"episode_reward": 53.5029220496765, "episode": 18.0, "Q1 loss": 0.5063942559361457, "Q2 loss": 0.5078236042261124, "Mean Target Q": 14.649165103912354, "Mean Q1": 14.648120265960694, "Mean Q2": 14.64826936531067, "critic_loss": 1.0142178605794907, "batch_reward": 0.1122718760818243, "actor_loss": -15.00815353012085, "actor_target_entropy": -6.0, "actor_entropy": 6.934500013351441, "alpha_loss": 0.5671358785629272, "alpha_value": 0.07028666977570447, "duration": 336.38557481765747, "step": 9000}
{"episode_reward": 53.141128885201745, "episode": 19.0, "Q1 loss": 0.47650099539756774, "Q2 loss": 0.4758299423456192, "Mean Target Q": 15.397921875, "Mean Q1": 15.397241325378419, "Mean Q2": 15.39718643951416, "critic_loss": 0.9523309389352799, "batch_reward": 0.1113147132396698, "actor_loss": -15.724643398284913, "actor_target_entropy": -6.0, "actor_entropy": 6.810502443313599, "alpha_loss": 0.551147709608078, "alpha_value": 0.06880711231868994, "duration": 290.2008647918701, "step": 9500}
{"episode_reward": 48.10584261299708, "episode": 20.0, "Q1 loss": 0.4407366995215416, "Q2 loss": 0.4406719493865967, "Mean Target Q": 16.21419189453125, "Mean Q1": 16.21275931930542, "Mean Q2": 16.21261947250366, "critic_loss": 0.8814086501598358, "batch_reward": 0.11313821901381016, "actor_loss": -16.526980464935303, "actor_target_entropy": -6.0, "actor_entropy": 6.791820741653442, "alpha_loss": 0.5420569498538971, "alpha_value": 0.06734259787057424, "step": 10000}
{"duration": 428.84686160087585, "step": 10000}
{"episode_reward": 71.00227181558475, "episode": 21.0, "Q1 loss": 0.4133257436156273, "Q2 loss": 0.416239921271801, "Mean Target Q": 16.983628108978273, "Mean Q1": 16.98270203781128, "Mean Q2": 16.982547454833984, "critic_loss": 0.8295656658411026, "batch_reward": 0.11521375200152398, "actor_loss": -17.282117500305176, "actor_target_entropy": -6.0, "actor_entropy": 6.854306985855103, "alpha_loss": 0.5299746810197831, "alpha_value": 0.0658855253752033, "duration": 298.57864713668823, "step": 10500}
{"episode_reward": 79.35775484140284, "episode": 22.0, "Q1 loss": 0.3644834068417549, "Q2 loss": 0.36628447026014327, "Mean Target Q": 17.61545182800293, "Mean Q1": 17.614200588226318, "Mean Q2": 17.614360916137695, "critic_loss": 0.7307678759098053, "batch_reward": 0.11424637776613235, "actor_loss": -17.91252864074707, "actor_target_entropy": -6.0, "actor_entropy": 6.8915114536285405, "alpha_loss": 0.5192036765813828, "alpha_value": 0.06445597965704102, "duration": 324.10465574264526, "step": 11000}
{"episode_reward": 44.77935526883436, "episode": 23.0, "Q1 loss": 0.36272514218091967, "Q2 loss": 0.364097577303648, "Mean Target Q": 18.279517612457276, "Mean Q1": 18.27889707183838, "Mean Q2": 18.278977592468262, "critic_loss": 0.7268227193951606, "batch_reward": 0.11441920013725758, "actor_loss": -18.570443939208985, "actor_target_entropy": -6.0, "actor_entropy": 6.936112533569336, "alpha_loss": 0.5076798061132431, "alpha_value": 0.0630450644193952, "duration": 228.05335569381714, "step": 11500}
{"episode_reward": 69.98775636695012, "episode": 24.0, "Q1 loss": 0.3387091098129749, "Q2 loss": 0.33976470050215724, "Mean Target Q": 18.867512504577636, "Mean Q1": 18.866432777404786, "Mean Q2": 18.866402740478517, "critic_loss": 0.6784738100767136, "batch_reward": 0.11408503468334674, "actor_loss": -19.153288856506347, "actor_target_entropy": -6.0, "actor_entropy": 6.998377641677856, "alpha_loss": 0.49930099642276765, "alpha_value": 0.06165750451206749, "duration": 238.75022888183594, "step": 12000}
{"episode_reward": 38.175462083841495, "episode": 25.0, "Q1 loss": 0.3885030694007873, "Q2 loss": 0.39062143313884734, "Mean Target Q": 19.475765270233154, "Mean Q1": 19.47487019729614, "Mean Q2": 19.47457892227173, "critic_loss": 0.7791245015859604, "batch_reward": 0.11594633291661739, "actor_loss": -19.717582847595214, "actor_target_entropy": -6.0, "actor_entropy": 7.056185102462768, "alpha_loss": 0.49553597497940066, "alpha_value": 0.06027961328980052, "duration": 214.32741570472717, "step": 12500}
{"episode_reward": 122.20468818924103, "episode": 26.0, "Q1 loss": 0.3824823040664196, "Q2 loss": 0.38763679075241086, "Mean Target Q": 20.169091262817382, "Mean Q1": 20.16747709274292, "Mean Q2": 20.167675018310547, "critic_loss": 0.770119096338749, "batch_reward": 0.12146426947414875, "actor_loss": -20.417435928344727, "actor_target_entropy": -6.0, "actor_entropy": 7.022893585205078, "alpha_loss": 0.4790567357540131, "alpha_value": 0.058933534537234905, "duration": 215.59472346305847, "step": 13000}
{"episode_reward": 96.06201941115951, "episode": 27.0, "Q1 loss": 0.36335481563210487, "Q2 loss": 0.3683986251652241, "Mean Target Q": 20.695296321868895, "Mean Q1": 20.694201713562013, "Mean Q2": 20.694144824981688, "critic_loss": 0.7317534416913987, "batch_reward": 0.1255046647489071, "actor_loss": -20.94003028869629, "actor_target_entropy": -6.0, "actor_entropy": 6.981445310592651, "alpha_loss": 0.4690390133857727, "alpha_value": 0.05761778424027602, "duration": 296.3358929157257, "step": 13500}
{"episode_reward": 113.31844005961253, "episode": 28.0, "Q1 loss": 0.39430367600917815, "Q2 loss": 0.395542033970356, "Mean Target Q": 21.081988166809083, "Mean Q1": 21.08108106994629, "Mean Q2": 21.08087902069092, "critic_loss": 0.7898457122445106, "batch_reward": 0.12445546640455722, "actor_loss": -21.319951766967772, "actor_target_entropy": -6.0, "actor_entropy": 6.9606881561279295, "alpha_loss": 0.4528385590314865, "alpha_value": 0.05634137707582206, "duration": 290.6516418457031, "step": 14000}
{"episode_reward": 28.219685355589554, "episode": 29.0, "Q1 loss": 0.4005677579045296, "Q2 loss": 0.3983062224984169, "Mean Target Q": 21.33496857833862, "Mean Q1": 21.334267414093016, "Mean Q2": 21.334392734527587, "critic_loss": 0.7988739817738533, "batch_reward": 0.12316188131272793, "actor_loss": -21.573717834472657, "actor_target_entropy": -6.0, "actor_entropy": 6.980338804244995, "alpha_loss": 0.44129973912239073, "alpha_value": 0.05510008474441532, "duration": 236.94618463516235, "step": 14500}
{"episode_reward": 58.55895089177757, "episode": 30.0, "Q1 loss": 0.4217654100060463, "Q2 loss": 0.42321571630239485, "Mean Target Q": 21.7719052734375, "Mean Q1": 21.77038371658325, "Mean Q2": 21.77042427444458, "critic_loss": 0.8449811284542084, "batch_reward": 0.12624073414504527, "actor_loss": -21.98103645324707, "actor_target_entropy": -6.0, "actor_entropy": 7.015601634979248, "alpha_loss": 0.428774614572525, "alpha_value": 0.053885033957765116, "step": 15000}
{"duration": 314.91052508354187, "step": 15000}
{"episode_reward": 177.2727839247213, "episode": 31.0, "Q1 loss": 0.4793444570302963, "Q2 loss": 0.4815181091427803, "Mean Target Q": 22.263490543365478, "Mean Q1": 22.262622821807863, "Mean Q2": 22.262520877838135, "critic_loss": 0.9608625651597976, "batch_reward": 0.13330143354833127, "actor_loss": -22.49860092163086, "actor_target_entropy": -6.0, "actor_entropy": 6.933362905502319, "alpha_loss": 0.4123767701387405, "alpha_value": 0.05270823604354854, "duration": 212.00611519813538, "step": 15500}
{"episode_reward": 131.76133891357495, "episode": 32.0, "Q1 loss": 0.5143282772302628, "Q2 loss": 0.5156503709554672, "Mean Target Q": 22.656154037475584, "Mean Q1": 22.655138610839845, "Mean Q2": 22.655147972106935, "critic_loss": 1.0299786478281021, "batch_reward": 0.1378421477228403, "actor_loss": -22.899712692260742, "actor_target_entropy": -6.0, "actor_entropy": 6.793439842224121, "alpha_loss": 0.39398685657978055, "alpha_value": 0.05157106155702492, "duration": 202.23674488067627, "step": 16000}
{"episode_reward": 132.0357187090111, "episode": 33.0, "Q1 loss": 0.611154416501522, "Q2 loss": 0.6060954871773719, "Mean Target Q": 23.069897037506102, "Mean Q1": 23.068377685546874, "Mean Q2": 23.068537090301515, "critic_loss": 1.217249905705452, "batch_reward": 0.14154619796574117, "actor_loss": -23.32336112213135, "actor_target_entropy": -6.0, "actor_entropy": 6.750065679550171, "alpha_loss": 0.3721416331529617, "alpha_value": 0.05047666992870571, "duration": 262.9594066143036, "step": 16500}
{"episode_reward": 160.9607438944502, "episode": 34.0, "Q1 loss": 0.6741586206555367, "Q2 loss": 0.6728616264462471, "Mean Target Q": 23.511924633026123, "Mean Q1": 23.511260623931886, "Mean Q2": 23.511032375335695, "critic_loss": 1.3470202453136444, "batch_reward": 0.14501607377827166, "actor_loss": -23.769033126831054, "actor_target_entropy": -6.0, "actor_entropy": 6.605125232696533, "alpha_loss": 0.3463285231590271, "alpha_value": 0.04944283000837503, "duration": 271.4740982055664, "step": 17000}
{"episode_reward": 135.81529469596484, "episode": 35.0, "Q1 loss": 0.7487820473313331, "Q2 loss": 0.7455071252584458, "Mean Target Q": 23.943037490844727, "Mean Q1": 23.94160924530029, "Mean Q2": 23.941386898040772, "critic_loss": 1.494289174079895, "batch_reward": 0.14938830947875978, "actor_loss": -24.237702201843263, "actor_target_entropy": -6.0, "actor_entropy": 6.385671098709106, "alpha_loss": 0.32646169888973237, "alpha_value": 0.04844959751839411, "duration": 328.7509710788727, "step": 17500}
{"episode_reward": 173.3979538802427, "episode": 36.0, "Q1 loss": 0.8040238251686096, "Q2 loss": 0.806306160569191, "Mean Target Q": 24.6030691947937, "Mean Q1": 24.601939067840576, "Mean Q2": 24.601985466003416, "critic_loss": 1.6103299856185913, "batch_reward": 0.1557604483962059, "actor_loss": -24.88461946105957, "actor_target_entropy": -6.0, "actor_entropy": 6.202136894226074, "alpha_loss": 0.3022380162477493, "alpha_value": 0.04749309629767719, "duration": 262.887886762619, "step": 18000}
{"episode_reward": 155.69379612279144, "episode": 37.0, "Q1 loss": 0.9117020465135575, "Q2 loss": 0.9083653616905213, "Mean Target Q": 25.435042053222656, "Mean Q1": 25.433625984191895, "Mean Q2": 25.433759765625, "critic_loss": 1.8200674097537994, "batch_reward": 0.1613764444589615, "actor_loss": -25.829987396240234, "actor_target_entropy": -6.0, "actor_entropy": 5.868200912475586, "alpha_loss": 0.26211245906353, "alpha_value": 0.0466121379048304, "duration": 397.747807264328, "step": 18500}
{"episode_reward": 174.6832001078301, "episode": 38.0, "Q1 loss": 1.162185391664505, "Q2 loss": 1.1659746938943862, "Mean Target Q": 26.297374713897707, "Mean Q1": 26.29599474334717, "Mean Q2": 26.295880020141603, "critic_loss": 2.328160087585449, "batch_reward": 0.1665635702908039, "actor_loss": -26.7092795715332, "actor_target_entropy": -6.0, "actor_entropy": 5.662206531524658, "alpha_loss": 0.22575001579523085, "alpha_value": 0.04582004071045637, "duration": 348.89348006248474, "step": 19000}
{"episode_reward": 215.8915390563238, "episode": 39.0, "Q1 loss": 1.4374535624980926, "Q2 loss": 1.445273042201996, "Mean Target Q": 27.20965619659424, "Mean Q1": 27.20802386856079, "Mean Q2": 27.208179264068605, "critic_loss": 2.882726599931717, "batch_reward": 0.17125541815161704, "actor_loss": -27.677529083251954, "actor_target_entropy": -6.0, "actor_entropy": 5.343668472290039, "alpha_loss": 0.19628362292051316, "alpha_value": 0.045097144490346956, "duration": 454.89689326286316, "step": 19500}
{"episode_reward": 189.1323704352926, "episode": 40.0, "Q1 loss": 1.6513119647502899, "Q2 loss": 1.6660579280853272, "Mean Target Q": 28.31876218032837, "Mean Q1": 28.317442378997804, "Mean Q2": 28.317537311553956, "critic_loss": 3.317369893074036, "batch_reward": 0.1788841628432274, "actor_loss": -28.816369346618654, "actor_target_entropy": -6.0, "actor_entropy": 5.102943618774414, "alpha_loss": 0.17496807986497878, "alpha_value": 0.04443173612347714, "step": 20000}
{"duration": 354.9482719898224, "step": 20000}
{"episode_reward": 247.96962539815232, "episode": 41.0, "Q1 loss": 1.7655591011047362, "Q2 loss": 1.7730759544372559, "Mean Target Q": 29.516954818725587, "Mean Q1": 29.51510189819336, "Mean Q2": 29.515428241729737, "critic_loss": 3.5386350603103636, "batch_reward": 0.18852431002259254, "actor_loss": -30.027434844970703, "actor_target_entropy": -6.0, "actor_entropy": 4.915775550842286, "alpha_loss": 0.16592771548032761, "alpha_value": 0.043766396472080804, "duration": 288.47614216804504, "step": 20500}
{"episode_reward": 259.70409660907734, "episode": 42.0, "Q1 loss": 1.7259970881938935, "Q2 loss": 1.7389966850280763, "Mean Target Q": 30.657878189086915, "Mean Q1": 30.656041660308837, "Mean Q2": 30.655829700469972, "critic_loss": 3.4649937748908997, "batch_reward": 0.19315643516182898, "actor_loss": -31.15879300689697, "actor_target_entropy": -6.0, "actor_entropy": 4.8077304096221924, "alpha_loss": 0.17031952261924743, "alpha_value": 0.04307247454716843, "duration": 465.91451048851013, "step": 21000}
{"episode_reward": 160.88464487718298, "episode": 43.0, "Q1 loss": 1.6545073471069336, "Q2 loss": 1.6638495881557465, "Mean Target Q": 31.794005226135255, "Mean Q1": 31.79190531539917, "Mean Q2": 31.791915287017822, "critic_loss": 3.3183569321632387, "batch_reward": 0.19890156403183937, "actor_loss": -32.22329943084717, "actor_target_entropy": -6.0, "actor_entropy": 4.742634040832519, "alpha_loss": 0.17027044355869292, "alpha_value": 0.042328388756159914, "duration": 405.34797286987305, "step": 21500}
{"episode_reward": 285.0002338580153, "episode": 44.0, "Q1 loss": 1.599106469631195, "Q2 loss": 1.615177104473114, "Mean Target Q": 32.87093177032471, "Mean Q1": 32.86955723190307, "Mean Q2": 32.86960181427002, "critic_loss": 3.2142835764884947, "batch_reward": 0.20825514909625054, "actor_loss": -33.2990404663086, "actor_target_entropy": -6.0, "actor_entropy": 4.699998046875, "alpha_loss": 0.16257360571622848, "alpha_value": 0.0415661383922188, "duration": 346.92462825775146, "step": 22000}
{"episode_reward": 305.6156978723648, "episode": 45.0, "Q1 loss": 1.4986953394412994, "Q2 loss": 1.5128915541172028, "Mean Target Q": 33.81997928619385, "Mean Q1": 33.818070091247556, "Mean Q2": 33.81796911621094, "critic_loss": 3.011586894989014, "batch_reward": 0.21532543009519578, "actor_loss": -34.2399188079834, "actor_target_entropy": -6.0, "actor_entropy": 4.611755836486816, "alpha_loss": 0.1532818941473961, "alpha_value": 0.04081743430299151, "duration": 460.22759652137756, "step": 22500}
{"episode_reward": 223.49169935753017, "episode": 46.0, "Q1 loss": 1.3672915099859237, "Q2 loss": 1.3912048835754394, "Mean Target Q": 34.74150900268555, "Mean Q1": 34.74000492858887, "Mean Q2": 34.73984927368164, "critic_loss": 2.7584963932037354, "batch_reward": 0.21931286588311194, "actor_loss": -35.13497763061523, "actor_target_entropy": -6.0, "actor_entropy": 4.570925025939942, "alpha_loss": 0.14947068977355957, "alpha_value": 0.04007013793926028, "duration": 349.4288332462311, "step": 23000}
{"episode_reward": 167.74325545893495, "episode": 47.0, "Q1 loss": 1.2549122833013535, "Q2 loss": 1.269591182231903, "Mean Target Q": 35.536854034423826, "Mean Q1": 35.53484414672852, "Mean Q2": 35.5348002166748, "critic_loss": 2.52450346827507, "batch_reward": 0.2225036563873291, "actor_loss": -35.896688659667966, "actor_target_entropy": -6.0, "actor_entropy": 4.605604291915894, "alpha_loss": 0.14619371923804284, "alpha_value": 0.03931427228017128, "duration": 404.8816294670105, "step": 23500}
{"episode_reward": 234.4601697670339, "episode": 48.0, "Q1 loss": 1.1250598819255828, "Q2 loss": 1.1285364285707473, "Mean Target Q": 36.169462196350096, "Mean Q1": 36.16823723602295, "Mean Q2": 36.1682801361084, "critic_loss": 2.2535963127613066, "batch_reward": 0.22742722296714782, "actor_loss": -36.516197036743165, "actor_target_entropy": -6.0, "actor_entropy": 4.561143808364868, "alpha_loss": 0.14298763307929038, "alpha_value": 0.038547416090307964, "duration": 380.85680317878723, "step": 24000}
{"episode_reward": 148.27432988765375, "episode": 49.0, "Q1 loss": 1.0426388080120086, "Q2 loss": 1.050933589696884, "Mean Target Q": 36.70550648498535, "Mean Q1": 36.70383574676514, "Mean Q2": 36.703559211730955, "critic_loss": 2.0935723960399626, "batch_reward": 0.2274916068315506, "actor_loss": -37.019225692749025, "actor_target_entropy": -6.0, "actor_entropy": 4.590591257095337, "alpha_loss": 0.14110103622078896, "alpha_value": 0.037784153047948014, "duration": 261.8228876590729, "step": 24500}
{"episode_reward": 88.46889485917579, "episode": 50.0, "Q1 loss": 0.9648854997158051, "Q2 loss": 0.9738780249357224, "Mean Target Q": 37.183042984008786, "Mean Q1": 37.18178777313232, "Mean Q2": 37.18194658660889, "critic_loss": 1.938763522386551, "batch_reward": 0.23030040049552916, "actor_loss": -37.492336776733396, "actor_target_entropy": -6.0, "actor_entropy": 4.59023869895935, "alpha_loss": 0.13612123122811318, "alpha_value": 0.03701731736686821, "step": 25000}
{"duration": 458.2141468524933, "step": 25000}
{"episode_reward": 398.96971651085636, "episode": 51.0, "Q1 loss": 0.966920205116272, "Q2 loss": 0.957056086063385, "Mean Target Q": 37.82994134521484, "Mean Q1": 37.82896884918213, "Mean Q2": 37.82881509399414, "critic_loss": 1.923976292848587, "batch_reward": 0.24053637585043908, "actor_loss": -38.11574597167969, "actor_target_entropy": -6.0, "actor_entropy": 4.58164692401886, "alpha_loss": 0.13303837755322456, "alpha_value": 0.036254944202571346, "duration": 382.1409511566162, "step": 25500}
{"episode_reward": 301.3518340389136, "episode": 52.0, "Q1 loss": 0.988656500339508, "Q2 loss": 0.9931523609161377, "Mean Target Q": 38.346822090148926, "Mean Q1": 38.345550476074216, "Mean Q2": 38.345607948303225, "critic_loss": 1.981808865070343, "batch_reward": 0.24984588333964347, "actor_loss": -38.63145886230469, "actor_target_entropy": -6.0, "actor_entropy": 4.519325078010559, "alpha_loss": 0.1282762155532837, "alpha_value": 0.03550480759805169, "duration": 285.5287113189697, "step": 26000}
{"episode_reward": 328.9885989417534, "episode": 53.0, "Q1 loss": 1.014597447991371, "Q2 loss": 1.0175173962116242, "Mean Target Q": 38.82523497009277, "Mean Q1": 38.82337387084961, "Mean Q2": 38.82325677490234, "critic_loss": 2.0321148467063903, "batch_reward": 0.2579485615193844, "actor_loss": -39.12265992736816, "actor_target_entropy": -6.0, "actor_entropy": 4.4720498523712156, "alpha_loss": 0.12034188961982727, "alpha_value": 0.03477715891990998, "duration": 309.1228497028351, "step": 26500}
{"episode_reward": 408.43461129134096, "episode": 54.0, "Q1 loss": 1.0070451238155365, "Q2 loss": 1.0017740938663482, "Mean Target Q": 39.39454483032227, "Mean Q1": 39.39344137573242, "Mean Q2": 39.39372357940674, "critic_loss": 2.0088192129135134, "batch_reward": 0.2716395146548748, "actor_loss": -39.67068556213379, "actor_target_entropy": -6.0, "actor_entropy": 4.46998517036438, "alpha_loss": 0.11421206384897233, "alpha_value": 0.0340827904665507, "duration": 281.8855867385864, "step": 27000}
{"episode_reward": 503.0095342940018, "episode": 55.0, "Q1 loss": 1.073858470082283, "Q2 loss": 1.0735078432559968, "Mean Target Q": 40.01404374694824, "Mean Q1": 40.01282608795166, "Mean Q2": 40.01291248321533, "critic_loss": 2.1473663127422333, "batch_reward": 0.28181822711229326, "actor_loss": -40.265225372314454, "actor_target_entropy": -6.0, "actor_entropy": 4.402031562805176, "alpha_loss": 0.10633578172326089, "alpha_value": 0.033407153452200126, "duration": 341.00593400001526, "step": 27500}
{"episode_reward": 284.00909382198705, "episode": 56.0, "Q1 loss": 1.1416558552980423, "Q2 loss": 1.1437404543161391, "Mean Target Q": 40.51769495391846, "Mean Q1": 40.5156820602417, "Mean Q2": 40.51560934448242, "critic_loss": 2.2853963179588317, "batch_reward": 0.2854557669460773, "actor_loss": -40.814810272216796, "actor_target_entropy": -6.0, "actor_entropy": 4.35213738822937, "alpha_loss": 0.0954696324467659, "alpha_value": 0.03277323055751015, "duration": 293.5945360660553, "step": 28000}
{"episode_reward": 266.1798977296922, "episode": 57.0, "Q1 loss": 1.192957091331482, "Q2 loss": 1.1913068553209305, "Mean Target Q": 41.08498241424561, "Mean Q1": 41.08423142242432, "Mean Q2": 41.08399011993408, "critic_loss": 2.3842639427185057, "batch_reward": 0.2923161342740059, "actor_loss": -41.42951028442383, "actor_target_entropy": -6.0, "actor_entropy": 4.171236969947815, "alpha_loss": 0.08573068501055241, "alpha_value": 0.03218280422869301, "duration": 363.7810297012329, "step": 28500}
{"episode_reward": 427.80131792100957, "episode": 58.0, "Q1 loss": 1.2449946358203887, "Q2 loss": 1.2409527487754821, "Mean Target Q": 41.7434921875, "Mean Q1": 41.741639282226565, "Mean Q2": 41.74185509490967, "critic_loss": 2.4859473850727083, "batch_reward": 0.302089236587286, "actor_loss": -42.075275939941406, "actor_target_entropy": -6.0, "actor_entropy": 4.105938588142395, "alpha_loss": 0.08239716789126396, "alpha_value": 0.031613186112114125, "duration": 423.46698093414307, "step": 29000}
{"episode_reward": 425.4537641529271, "episode": 59.0, "Q1 loss": 1.2946965091228486, "Q2 loss": 1.2917100929021836, "Mean Target Q": 42.39195777130127, "Mean Q1": 42.390823028564455, "Mean Q2": 42.390939193725586, "critic_loss": 2.58640660071373, "batch_reward": 0.3090288196206093, "actor_loss": -42.7225891418457, "actor_target_entropy": -6.0, "actor_entropy": 4.110034651756287, "alpha_loss": 0.07302836957573891, "alpha_value": 0.03106408943436689, "duration": 486.6512644290924, "step": 29500}
{"episode_reward": 319.8658977854789, "episode": 60.0, "Q1 loss": 1.3852686593532562, "Q2 loss": 1.3925988447666169, "Mean Target Q": 43.073480598449706, "Mean Q1": 43.07202667236328, "Mean Q2": 43.07190013122558, "critic_loss": 2.777867506504059, "batch_reward": 0.31486189872026443, "actor_loss": -43.42435168457031, "actor_target_entropy": -6.0, "actor_entropy": 4.0220532283782955, "alpha_loss": 0.06658759260177613, "alpha_value": 0.030547081171032924, "step": 30000}
{"duration": 441.1013126373291, "step": 30000}
{"episode_reward": 309.13501286034716, "episode": 61.0, "Q1 loss": 1.451543648958206, "Q2 loss": 1.4484109601974486, "Mean Target Q": 43.80408679199219, "Mean Q1": 43.80302217102051, "Mean Q2": 43.802769813537594, "critic_loss": 2.899954609870911, "batch_reward": 0.3214476464390755, "actor_loss": -44.161404586791996, "actor_target_entropy": -6.0, "actor_entropy": 3.8684421491622927, "alpha_loss": 0.05999752341210842, "alpha_value": 0.03005468269710278, "duration": 438.3736267089844, "step": 30500}
{"episode_reward": 396.38298066720756, "episode": 62.0, "Q1 loss": 1.4903660600185393, "Q2 loss": 1.4947427802085878, "Mean Target Q": 44.56749309539795, "Mean Q1": 44.565575675964354, "Mean Q2": 44.56525504302979, "critic_loss": 2.98510884141922, "batch_reward": 0.3268551981449127, "actor_loss": -44.932597717285155, "actor_target_entropy": -6.0, "actor_entropy": 3.767962133407593, "alpha_loss": 0.053862892381846904, "alpha_value": 0.029577712229964317, "duration": 338.40847849845886, "step": 31000}
{"episode_reward": 303.32472896657293, "episode": 63.0, "Q1 loss": 1.4898259539604186, "Q2 loss": 1.5100462610721588, "Mean Target Q": 45.358094711303714, "Mean Q1": 45.35637679290772, "Mean Q2": 45.356961700439456, "critic_loss": 2.999872215270996, "batch_reward": 0.3361992248296738, "actor_loss": -45.713939453125, "actor_target_entropy": -6.0, "actor_entropy": 3.712626135826111, "alpha_loss": 0.0453239953443408, "alpha_value": 0.029135637533697193, "duration": 318.25485944747925, "step": 31500}
{"episode_reward": 506.6080592773012, "episode": 64.0, "Q1 loss": 1.5098770270347595, "Q2 loss": 1.5214648053646087, "Mean Target Q": 46.17513763427734, "Mean Q1": 46.17365037536621, "Mean Q2": 46.17352813720703, "critic_loss": 3.0313418316841125, "batch_reward": 0.34611449909210207, "actor_loss": -46.54972697448731, "actor_target_entropy": -6.0, "actor_entropy": 3.6149830045700075, "alpha_loss": 0.04103085128962994, "alpha_value": 0.028735367564690455, "duration": 269.1441717147827, "step": 32000}
{"episode_reward": 491.86356439075394, "episode": 65.0, "Q1 loss": 1.4894152362346649, "Q2 loss": 1.4946109704971313, "Mean Target Q": 47.04796355438232, "Mean Q1": 47.04620392608643, "Mean Q2": 47.04561618041992, "critic_loss": 2.984026211261749, "batch_reward": 0.354189163684845, "actor_loss": -47.41019268798828, "actor_target_entropy": -6.0, "actor_entropy": 3.5677651252746583, "alpha_loss": 0.03992421002686024, "alpha_value": 0.02832203616734237, "duration": 270.0830156803131, "step": 32500}
{"episode_reward": 366.8851956692881, "episode": 66.0, "Q1 loss": 1.5277182540893555, "Q2 loss": 1.5170159585475922, "Mean Target Q": 47.82281131744385, "Mean Q1": 47.82131629180908, "Mean Q2": 47.822099311828616, "critic_loss": 3.044734215259552, "batch_reward": 0.35837379181385043, "actor_loss": -48.20833871459961, "actor_target_entropy": -6.0, "actor_entropy": 3.4948584661483766, "alpha_loss": 0.03680644049495459, "alpha_value": 0.02791211179029251, "duration": 294.32052993774414, "step": 33000}
{"episode_reward": 382.90735025994627, "episode": 67.0, "Q1 loss": 1.5342239940166473, "Q2 loss": 1.5255415761470794, "Mean Target Q": 48.53759278106689, "Mean Q1": 48.536603042602536, "Mean Q2": 48.53626947021484, "critic_loss": 3.0597655706405638, "batch_reward": 0.3657543242573738, "actor_loss": -48.91157615661621, "actor_target_entropy": -6.0, "actor_entropy": 3.513327642440796, "alpha_loss": 0.030701889341697097, "alpha_value": 0.027521059822387322, "duration": 252.99056720733643, "step": 33500}
{"episode_reward": 433.0938544416028, "episode": 68.0, "Q1 loss": 1.6155571794509889, "Q2 loss": 1.6206933879852294, "Mean Target Q": 49.290990966796876, "Mean Q1": 49.28842375946045, "Mean Q2": 49.28807349395752, "critic_loss": 3.2362505650520323, "batch_reward": 0.37223814040422437, "actor_loss": -49.66797003173828, "actor_target_entropy": -6.0, "actor_entropy": 3.4567152194976805, "alpha_loss": 0.024654158381745218, "alpha_value": 0.027172949182059876, "duration": 234.20051765441895, "step": 34000}
{"episode_reward": 442.5897760898903, "episode": 69.0, "Q1 loss": 1.6456718235015868, "Q2 loss": 1.6427015764713286, "Mean Target Q": 50.107172233581544, "Mean Q1": 50.10601983642578, "Mean Q2": 50.10653114318848, "critic_loss": 3.28837339925766, "batch_reward": 0.3793151894211769, "actor_loss": -50.51090631103516, "actor_target_entropy": -6.0, "actor_entropy": 3.2656625452041625, "alpha_loss": 0.019753153127385303, "alpha_value": 0.026876244591256593, "duration": 356.18444204330444, "step": 34500}
{"episode_reward": 357.72085658182505, "episode": 70.0, "Q1 loss": 1.6468354394435882, "Q2 loss": 1.646611943244934, "Mean Target Q": 50.900466766357425, "Mean Q1": 50.8990174407959, "Mean Q2": 50.89904585266113, "critic_loss": 3.293447382926941, "batch_reward": 0.38558117985725404, "actor_loss": -51.294564682006836, "actor_target_entropy": -6.0, "actor_entropy": 3.2130411005020143, "alpha_loss": 0.018044731179252267, "alpha_value": 0.026611997508118487, "step": 35000}
{"duration": 460.6125991344452, "step": 35000}
{"episode_reward": 305.44677428576864, "episode": 71.0, "Q1 loss": 1.6336132459640502, "Q2 loss": 1.6262809495925903, "Mean Target Q": 51.58474456787109, "Mean Q1": 51.58351885223389, "Mean Q2": 51.582924224853514, "critic_loss": 3.259894196033478, "batch_reward": 0.3857107274532318, "actor_loss": -51.952150192260746, "actor_target_entropy": -6.0, "actor_entropy": 3.179294596672058, "alpha_loss": 0.01716820622049272, "alpha_value": 0.026317657092385822, "duration": 359.6698760986328, "step": 35500}
{"episode_reward": 330.7186087608691, "episode": 72.0, "Q1 loss": 1.724097027540207, "Q2 loss": 1.715414647102356, "Mean Target Q": 52.311052589416505, "Mean Q1": 52.30880544281006, "Mean Q2": 52.30917721557617, "critic_loss": 3.4395116782188415, "batch_reward": 0.38981222385168074, "actor_loss": -52.67052810668945, "actor_target_entropy": -6.0, "actor_entropy": 3.150170491218567, "alpha_loss": 0.017170692034997045, "alpha_value": 0.026017015561952652, "duration": 251.11520075798035, "step": 36000}
{"episode_reward": 259.7652196041501, "episode": 73.0, "Q1 loss": 1.7836146450042725, "Q2 loss": 1.780229453086853, "Mean Target Q": 52.984485290527346, "Mean Q1": 52.98348860168457, "Mean Q2": 52.983864654541016, "critic_loss": 3.563844093322754, "batch_reward": 0.39412076711654664, "actor_loss": -53.34779516601562, "actor_target_entropy": -6.0, "actor_entropy": 3.140602771759033, "alpha_loss": 0.014508474197005853, "alpha_value": 0.025713988822422266, "duration": 255.0550982952118, "step": 36500}
{"episode_reward": 351.2897360678756, "episode": 74.0, "Q1 loss": 1.8261661818027497, "Q2 loss": 1.8326248743534088, "Mean Target Q": 53.71552066802978, "Mean Q1": 53.71353164672851, "Mean Q2": 53.713182998657224, "critic_loss": 3.6587910599708557, "batch_reward": 0.40192800331115724, "actor_loss": -54.06881219482422, "actor_target_entropy": -6.0, "actor_entropy": 2.975014392852783, "alpha_loss": 0.014329356480855494, "alpha_value": 0.025416128813700808, "duration": 396.8703739643097, "step": 37000}
{"episode_reward": 544.2878424150076, "episode": 75.0, "Q1 loss": 1.822801596403122, "Q2 loss": 1.836837229013443, "Mean Target Q": 54.490878952026364, "Mean Q1": 54.48951176452637, "Mean Q2": 54.489690498352054, "critic_loss": 3.659638822078705, "batch_reward": 0.4084156175851822, "actor_loss": -54.837972717285155, "actor_target_entropy": -6.0, "actor_entropy": 2.894732184410095, "alpha_loss": 0.012605076460167765, "alpha_value": 0.025097580865818005, "duration": 391.51163029670715, "step": 37500}
{"episode_reward": 440.78138748862233, "episode": 76.0, "Q1 loss": 1.8538877050876617, "Q2 loss": 1.8534959361553192, "Mean Target Q": 55.21009893035889, "Mean Q1": 55.20852233886719, "Mean Q2": 55.2087140045166, "critic_loss": 3.7073836460113525, "batch_reward": 0.4148409829735756, "actor_loss": -55.5260701751709, "actor_target_entropy": -6.0, "actor_entropy": 2.8448230419158937, "alpha_loss": 0.010999777709599584, "alpha_value": 0.024831283725461582, "duration": 474.10839772224426, "step": 38000}
{"episode_reward": 472.9606817962826, "episode": 77.0, "Q1 loss": 1.8917699847221374, "Q2 loss": 1.8928185138702394, "Mean Target Q": 55.953772064208984, "Mean Q1": 55.95210912322998, "Mean Q2": 55.952130905151364, "critic_loss": 3.7845884971618653, "batch_reward": 0.4210779134631157, "actor_loss": -56.3397115020752, "actor_target_entropy": -6.0, "actor_entropy": 2.804757652282715, "alpha_loss": 0.008008086149347947, "alpha_value": 0.024566898281440028, "duration": 485.7145175933838, "step": 38500}
{"episode_reward": 478.82620041499786, "episode": 78.0, "Q1 loss": 1.9368711166381836, "Q2 loss": 1.929735846042633, "Mean Target Q": 56.68982169342041, "Mean Q1": 56.68850159454346, "Mean Q2": 56.68809583282471, "critic_loss": 3.866606957912445, "batch_reward": 0.42543920236825944, "actor_loss": -57.04980226135254, "actor_target_entropy": -6.0, "actor_entropy": 2.7607196788787842, "alpha_loss": 0.00723967670276761, "alpha_value": 0.024352686072508054, "duration": 288.1825432777405, "step": 39000}
{"episode_reward": 68.88261131162618, "episode": 79.0, "Q1 loss": 1.9457184762954711, "Q2 loss": 1.9529022097587585, "Mean Target Q": 57.27934886169434, "Mean Q1": 57.278150672912595, "Mean Q2": 57.27820509338379, "critic_loss": 3.8986206879615786, "batch_reward": 0.42508447080850603, "actor_loss": -57.65751252746582, "actor_target_entropy": -6.0, "actor_entropy": 2.7857468490600588, "alpha_loss": 0.002034648179775104, "alpha_value": 0.024215134963937707, "duration": 295.4818811416626, "step": 39500}
{"episode_reward": 524.8641704570832, "episode": 80.0, "Q1 loss": 2.0236246016025543, "Q2 loss": 1.9996474912166595, "Mean Target Q": 58.064280586242674, "Mean Q1": 58.06264119720459, "Mean Q2": 58.06319770050049, "critic_loss": 4.0232720799446104, "batch_reward": 0.435206692636013, "actor_loss": -58.442498123168946, "actor_target_entropy": -6.0, "actor_entropy": 2.748458737373352, "alpha_loss": 7.045799167826772e-05, "alpha_value": 0.02416126446966536, "step": 40000}
{"duration": 320.1781978607178, "step": 40000}
{"episode_reward": 484.10611697875567, "episode": 81.0, "Q1 loss": 2.0998487956523895, "Q2 loss": 2.1030225105285645, "Mean Target Q": 58.808616287231445, "Mean Q1": 58.80738475036621, "Mean Q2": 58.806707901000976, "critic_loss": 4.20287129831314, "batch_reward": 0.4390415878891945, "actor_loss": -59.15446691894531, "actor_target_entropy": -6.0, "actor_entropy": 2.607102842330933, "alpha_loss": 0.001979492384940386, "alpha_value": 0.024140635433892405, "duration": 314.67575120925903, "step": 40500}
{"episode_reward": 424.9983510046371, "episode": 82.0, "Q1 loss": 2.1866415503025056, "Q2 loss": 2.175594290733337, "Mean Target Q": 59.49106856536865, "Mean Q1": 59.4885213470459, "Mean Q2": 59.489182777404785, "critic_loss": 4.362235835552216, "batch_reward": 0.44588302981853484, "actor_loss": -59.8354645690918, "actor_target_entropy": -6.0, "actor_entropy": 2.6238307094573976, "alpha_loss": 0.0013455078011611477, "alpha_value": 0.024067997946705076, "duration": 407.9191610813141, "step": 41000}
{"episode_reward": 486.2813027705366, "episode": 83.0, "Q1 loss": 2.2456271948814392, "Q2 loss": 2.2238315169811247, "Mean Target Q": 60.2277850189209, "Mean Q1": 60.22649056243897, "Mean Q2": 60.226610527038574, "critic_loss": 4.4694587187767025, "batch_reward": 0.44906949877738955, "actor_loss": -60.631435897827146, "actor_target_entropy": -6.0, "actor_entropy": 2.553681077003479, "alpha_loss": 0.0007040750493761153, "alpha_value": 0.024010682905439076, "duration": 432.3817493915558, "step": 41500}
{"episode_reward": 381.71739205155023, "episode": 84.0, "Q1 loss": 2.274356824874878, "Q2 loss": 2.2583280708789824, "Mean Target Q": 60.96168755340576, "Mean Q1": 60.96000846862793, "Mean Q2": 60.95960890197754, "critic_loss": 4.532684895038605, "batch_reward": 0.4584848879575729, "actor_loss": -61.32675872802734, "actor_target_entropy": -6.0, "actor_entropy": 2.621571581840515, "alpha_loss": -0.0016325690599624067, "alpha_value": 0.024011246666788083, "duration": 403.2189836502075, "step": 42000}
{"episode_reward": 587.063273403585, "episode": 85.0, "Q1 loss": 2.3780849006175995, "Q2 loss": 2.372730747461319, "Mean Target Q": 61.731578521728515, "Mean Q1": 61.73012688446045, "Mean Q2": 61.73021076965332, "critic_loss": 4.750815648555756, "batch_reward": 0.46533780986070633, "actor_loss": -62.15269754028321, "actor_target_entropy": -6.0, "actor_entropy": 2.5240251779556275, "alpha_loss": -0.0027077944295015185, "alpha_value": 0.02417919761358877, "duration": 262.02087330818176, "step": 42500}
{"episode_reward": 400.4925040842446, "episode": 86.0, "Q1 loss": 2.428591897249222, "Q2 loss": 2.423507873296738, "Mean Target Q": 62.43057476043701, "Mean Q1": 62.42902180480957, "Mean Q2": 62.42888447570801, "critic_loss": 4.8520997824668886, "batch_reward": 0.4682744584083557, "actor_loss": -62.77590733337402, "actor_target_entropy": -6.0, "actor_entropy": 2.566643250465393, "alpha_loss": -0.00266322154738009, "alpha_value": 0.024343970113081988, "duration": 352.5841579437256, "step": 43000}
{"episode_reward": 477.64700711466526, "episode": 87.0, "Q1 loss": 2.477886620759964, "Q2 loss": 2.4684681193828584, "Mean Target Q": 63.18100688171387, "Mean Q1": 63.17865061950683, "Mean Q2": 63.17883296966553, "critic_loss": 4.9463547234535215, "batch_reward": 0.47489259231090547, "actor_loss": -63.550427291870115, "actor_target_entropy": -6.0, "actor_entropy": 2.4628346610069274, "alpha_loss": -0.0016085610663285478, "alpha_value": 0.024457094814515475, "duration": 427.6298305988312, "step": 43500}
{"episode_reward": 586.9543495721294, "episode": 88.0, "Q1 loss": 2.644528272867203, "Q2 loss": 2.6159302656650545, "Mean Target Q": 63.93970069885254, "Mean Q1": 63.9392728729248, "Mean Q2": 63.939029594421385, "critic_loss": 5.2604585318565364, "batch_reward": 0.48319373953342437, "actor_loss": -64.38833598327636, "actor_target_entropy": -6.0, "actor_entropy": 2.4642091884613038, "alpha_loss": -0.00463395980047062, "alpha_value": 0.024666066839382286, "duration": 497.31231689453125, "step": 44000}
{"episode_reward": 490.7342528145591, "episode": 89.0, "Q1 loss": 2.7300595407485964, "Q2 loss": 2.7200685572624206, "Mean Target Q": 64.7004193725586, "Mean Q1": 64.69696531677246, "Mean Q2": 64.69718041229248, "critic_loss": 5.450128098964691, "batch_reward": 0.4857119417190552, "actor_loss": -65.07003088378906, "actor_target_entropy": -6.0, "actor_entropy": 2.4508650097846987, "alpha_loss": -0.004941851776326075, "alpha_value": 0.025046984184042873, "duration": 365.266193151474, "step": 44500}
{"episode_reward": 424.60064170126634, "episode": 90.0, "Q1 loss": 2.850847867012024, "Q2 loss": 2.8359119203090666, "Mean Target Q": 65.518759765625, "Mean Q1": 65.51763723754883, "Mean Q2": 65.51738310241699, "critic_loss": 5.6867597970962525, "batch_reward": 0.4937701630592346, "actor_loss": -65.89051374816894, "actor_target_entropy": -6.0, "actor_entropy": 2.5095501646995544, "alpha_loss": -0.006521677309414372, "alpha_value": 0.025431762431974838, "step": 45000}
{"duration": 503.3416438102722, "step": 45000}
{"episode_reward": 536.5202063408967, "episode": 91.0, "Q1 loss": 2.910087911128998, "Q2 loss": 2.903603595733643, "Mean Target Q": 66.28906018066407, "Mean Q1": 66.28720217895508, "Mean Q2": 66.28730001831055, "critic_loss": 5.8136915016174315, "batch_reward": 0.49693921363353727, "actor_loss": -66.69460076904296, "actor_target_entropy": -6.0, "actor_entropy": 2.4774524726867675, "alpha_loss": -0.0031552360381465407, "alpha_value": 0.025872848106660882, "duration": 353.4092845916748, "step": 45500}
{"episode_reward": 496.507957609934, "episode": 92.0, "Q1 loss": 3.1389384174346926, "Q2 loss": 3.127338038444519, "Mean Target Q": 66.98406460571289, "Mean Q1": 66.9823355255127, "Mean Q2": 66.98217320251464, "critic_loss": 6.266276455879211, "batch_reward": 0.4959262157082558, "actor_loss": -67.3699577331543, "actor_target_entropy": -6.0, "actor_entropy": 2.5066582956314085, "alpha_loss": -0.004182769173523411, "alpha_value": 0.026080375954652343, "duration": 358.8923225402832, "step": 46000}
{"episode_reward": 196.82368307075464, "episode": 93.0, "Q1 loss": 3.259904436826706, "Q2 loss": 3.264796998500824, "Mean Target Q": 67.75906610107423, "Mean Q1": 67.75778189086914, "Mean Q2": 67.75797296142578, "critic_loss": 6.52470143699646, "batch_reward": 0.5027225150465965, "actor_loss": -68.14962741088867, "actor_target_entropy": -6.0, "actor_entropy": 2.498781424045563, "alpha_loss": -0.00401936767110601, "alpha_value": 0.026451720376313326, "duration": 248.60196256637573, "step": 46500}
{"episode_reward": 513.6415395239329, "episode": 94.0, "Q1 loss": 3.530994346618652, "Q2 loss": 3.5250998291969298, "Mean Target Q": 68.516626953125, "Mean Q1": 68.51451281738281, "Mean Q2": 68.51418092346191, "critic_loss": 7.056094181060791, "batch_reward": 0.5043600254058838, "actor_loss": -68.93555969238281, "actor_target_entropy": -6.0, "actor_entropy": 2.4653517832756044, "alpha_loss": -0.006237890005577356, "alpha_value": 0.026761427750924383, "duration": 274.23340129852295, "step": 47000}
{"episode_reward": 422.4113063785784, "episode": 95.0, "Q1 loss": 3.6017709846496584, "Q2 loss": 3.596700195789337, "Mean Target Q": 69.4395011138916, "Mean Q1": 69.43706504821778, "Mean Q2": 69.43687152099609, "critic_loss": 7.198471169471741, "batch_reward": 0.5115919986963272, "actor_loss": -69.89134838867187, "actor_target_entropy": -6.0, "actor_entropy": 2.471487771987915, "alpha_loss": -0.004141914747422561, "alpha_value": 0.02723271974076245, "duration": 461.59442496299744, "step": 47500}
{"episode_reward": 559.2922328870874, "episode": 96.0, "Q1 loss": 3.4795192999839784, "Q2 loss": 3.491237757205963, "Mean Target Q": 70.29712963867188, "Mean Q1": 70.29541638183593, "Mean Q2": 70.29576405334473, "critic_loss": 6.9707570610046385, "batch_reward": 0.5154778034090995, "actor_loss": -70.70772711181641, "actor_target_entropy": -6.0, "actor_entropy": 2.4411431427001955, "alpha_loss": -0.0050132349343039095, "alpha_value": 0.02755842618002494, "duration": 330.0826930999756, "step": 48000}
{"episode_reward": 510.18464200180426, "episode": 97.0, "Q1 loss": 3.625814600467682, "Q2 loss": 3.6108900771141053, "Mean Target Q": 71.41893354797364, "Mean Q1": 71.41728604125977, "Mean Q2": 71.41687188720704, "critic_loss": 7.236704683303833, "batch_reward": 0.5182544050216675, "actor_loss": -71.81569931030273, "actor_target_entropy": -6.0, "actor_entropy": 2.516414016723633, "alpha_loss": -0.0024010710027068853, "alpha_value": 0.02791173318872623, "duration": 270.8335201740265, "step": 48500}
{"episode_reward": 27.049353206183657, "episode": 98.0, "Q1 loss": 3.4875452580451967, "Q2 loss": 3.4803471298217774, "Mean Target Q": 72.27437017822265, "Mean Q1": 72.2719330444336, "Mean Q2": 72.27217477416993, "critic_loss": 6.967892379760742, "batch_reward": 0.5151553627252579, "actor_loss": -72.6501528930664, "actor_target_entropy": -6.0, "actor_entropy": 2.484461346626282, "alpha_loss": -0.0005279464547056705, "alpha_value": 0.0279911352985784, "duration": 263.65686082839966, "step": 49000}
{"episode_reward": 195.92312189502152, "episode": 99.0, "Q1 loss": 3.3640508036613466, "Q2 loss": 3.3672184009552, "Mean Target Q": 73.00965060424805, "Mean Q1": 73.007681640625, "Mean Q2": 73.0070415649414, "critic_loss": 6.731269199371338, "batch_reward": 0.5143609506487846, "actor_loss": -73.42196420288086, "actor_target_entropy": -6.0, "actor_entropy": 2.4444564452171327, "alpha_loss": 9.012083942070604e-05, "alpha_value": 0.02797014965505835, "duration": 292.28064489364624, "step": 49500}
{"episode_reward": 182.43366831840825, "episode": 100.0, "Q1 loss": 3.1856724004745485, "Q2 loss": 3.1819772491455076, "Mean Target Q": 73.69441549682617, "Mean Q1": 73.69235960388184, "Mean Q2": 73.6929072265625, "critic_loss": 6.367649645805359, "batch_reward": 0.515634941637516, "actor_loss": -74.15831130981445, "actor_target_entropy": -6.0, "actor_entropy": 2.4813264203071594, "alpha_loss": -0.0005366209107451141, "alpha_value": 0.028003359426004043, "step": 50000}
{"duration": 412.8315246105194, "step": 50000}
{"episode_reward": 573.7918554092315, "episode": 101.0, "Q1 loss": 3.156785919189453, "Q2 loss": 3.160957525730133, "Mean Target Q": 74.4770047302246, "Mean Q1": 74.47471154785157, "Mean Q2": 74.47463710021972, "critic_loss": 6.3177434329986575, "batch_reward": 0.5166749969720841, "actor_loss": -74.92627783203125, "actor_target_entropy": -6.0, "actor_entropy": 2.5398892307281495, "alpha_loss": -0.004005086812423542, "alpha_value": 0.02821903395527042, "duration": 343.6053977012634, "step": 50500}
{"episode_reward": 23.58354971253639, "episode": 102.0, "Q1 loss": 3.2435534510612487, "Q2 loss": 3.2201923294067383, "Mean Target Q": 75.32858294677735, "Mean Q1": 75.3268215637207, "Mean Q2": 75.32711604309083, "critic_loss": 6.463745780944825, "batch_reward": 0.512278027176857, "actor_loss": -75.69035537719726, "actor_target_entropy": -6.0, "actor_entropy": 2.612041260719299, "alpha_loss": -3.511013579554856e-05, "alpha_value": 0.028450958467100728, "duration": 406.7654685974121, "step": 51000}
{"episode_reward": 31.840123061583743, "episode": 103.0, "Q1 loss": 3.525851215362549, "Q2 loss": 3.516033630847931, "Mean Target Q": 75.90382473754883, "Mean Q1": 75.90232342529296, "Mean Q2": 75.90171871948242, "critic_loss": 7.041884833335876, "batch_reward": 0.5068194535970688, "actor_loss": -76.23878326416016, "actor_target_entropy": -6.0, "actor_entropy": 2.632387885093689, "alpha_loss": 0.0023993900037603453, "alpha_value": 0.028335763904050185, "duration": 410.1135711669922, "step": 51500}
{"episode_reward": 38.66073518469918, "episode": 104.0, "Q1 loss": 3.434153561592102, "Q2 loss": 3.4354921646118166, "Mean Target Q": 76.24768643188476, "Mean Q1": 76.2450647277832, "Mean Q2": 76.24527732849121, "critic_loss": 6.869645720481873, "batch_reward": 0.5098879371285439, "actor_loss": -76.62267584228516, "actor_target_entropy": -6.0, "actor_entropy": 2.666013102531433, "alpha_loss": 0.003422208013711497, "alpha_value": 0.028040205416436283, "duration": 316.2794785499573, "step": 52000}
{"episode_reward": 534.4122591015908, "episode": 105.0, "Q1 loss": 3.038283826828003, "Q2 loss": 3.0087878737449647, "Mean Target Q": 76.75048191833496, "Mean Q1": 76.74844429016113, "Mean Q2": 76.7488154296875, "critic_loss": 6.047071711540222, "batch_reward": 0.5129922979474068, "actor_loss": -77.10966259765625, "actor_target_entropy": -6.0, "actor_entropy": 2.632976566314697, "alpha_loss": 0.00013670771243050694, "alpha_value": 0.02782986613436987, "duration": 380.31211829185486, "step": 52500}
{"episode_reward": 451.7959229032101, "episode": 106.0, "Q1 loss": 2.857612771987915, "Q2 loss": 2.837645210266113, "Mean Target Q": 77.10681651306152, "Mean Q1": 77.10562571716308, "Mean Q2": 77.1056329498291, "critic_loss": 5.695257974624634, "batch_reward": 0.5142242550849915, "actor_loss": -77.43710214233398, "actor_target_entropy": -6.0, "actor_entropy": 2.6464798259735107, "alpha_loss": -0.0007005471391603351, "alpha_value": 0.027855913871293554, "duration": 420.32001662254333, "step": 53000}
{"episode_reward": 207.76056627440957, "episode": 107.0, "Q1 loss": 2.6680288057327273, "Q2 loss": 2.6439366950988767, "Mean Target Q": 77.47707232666015, "Mean Q1": 77.47509523010254, "Mean Q2": 77.47531820678711, "critic_loss": 5.311965497493744, "batch_reward": 0.5148241686224937, "actor_loss": -77.77803338623048, "actor_target_entropy": -6.0, "actor_entropy": 2.6543196811676024, "alpha_loss": 0.0009963346107397229, "alpha_value": 0.027923988402103157, "duration": 356.2993595600128, "step": 53500}
{"episode_reward": 432.29619924245844, "episode": 108.0, "Q1 loss": 2.5788131911754606, "Q2 loss": 2.5630926578044892, "Mean Target Q": 77.72199876403809, "Mean Q1": 77.7210096435547, "Mean Q2": 77.72065867614747, "critic_loss": 5.141905858039856, "batch_reward": 0.51892320561409, "actor_loss": -78.04846179199218, "actor_target_entropy": -6.0, "actor_entropy": 2.638610032081604, "alpha_loss": 0.005368204849772155, "alpha_value": 0.02767626916421307, "duration": 474.97114419937134, "step": 54000}
{"episode_reward": 440.45842337365116, "episode": 109.0, "Q1 loss": 2.478014447927475, "Q2 loss": 2.4691667091846465, "Mean Target Q": 77.99928050231934, "Mean Q1": 77.99706979370117, "Mean Q2": 77.99741638183593, "critic_loss": 4.947181149959564, "batch_reward": 0.5198841944336892, "actor_loss": -78.24798770141602, "actor_target_entropy": -6.0, "actor_entropy": 2.7128326368331908, "alpha_loss": 0.005015310408081859, "alpha_value": 0.027210303081197332, "duration": 366.3799660205841, "step": 54500}
{"episode_reward": 236.48493606225944, "episode": 110.0, "Q1 loss": 2.3619837839603424, "Q2 loss": 2.3611750812530516, "Mean Target Q": 78.1362743988037, "Mean Q1": 78.13469801330567, "Mean Q2": 78.13477323913574, "critic_loss": 4.723158874511719, "batch_reward": 0.5200589913129806, "actor_loss": -78.39798211669923, "actor_target_entropy": -6.0, "actor_entropy": 2.592696368217468, "alpha_loss": 0.004789041850017384, "alpha_value": 0.026753804765620004, "step": 55000}
{"duration": 311.8743875026703, "step": 55000}
{"episode_reward": 511.9445750340167, "episode": 111.0, "Q1 loss": 2.3747334144115446, "Q2 loss": 2.384379344701767, "Mean Target Q": 78.26644303894042, "Mean Q1": 78.26585125732421, "Mean Q2": 78.26494786071777, "critic_loss": 4.759112753391266, "batch_reward": 0.5249639313817024, "actor_loss": -78.53003649902344, "actor_target_entropy": -6.0, "actor_entropy": 2.5717049293518066, "alpha_loss": 0.007797401293646544, "alpha_value": 0.026287426286386466, "duration": 338.8600914478302, "step": 55500}
{"episode_reward": 33.15930787246657, "episode": 112.0, "Q1 loss": 2.602477813243866, "Q2 loss": 2.5933450021743774, "Mean Target Q": 78.32437747192382, "Mean Q1": 78.32201956176758, "Mean Q2": 78.32280934143067, "critic_loss": 5.195822810173035, "batch_reward": 0.5224445344805717, "actor_loss": -78.5789052734375, "actor_target_entropy": -6.0, "actor_entropy": 2.6618278303146363, "alpha_loss": 0.006937928964849562, "alpha_value": 0.025680707446399224, "duration": 343.1768901348114, "step": 56000}
{"episode_reward": 391.611364247357, "episode": 113.0, "Q1 loss": 2.441883721828461, "Q2 loss": 2.430984785079956, "Mean Target Q": 78.36341815185547, "Mean Q1": 78.36137768554687, "Mean Q2": 78.36127349853516, "critic_loss": 4.872868494510651, "batch_reward": 0.5231574686169624, "actor_loss": -78.57154803466797, "actor_target_entropy": -6.0, "actor_entropy": 2.6883349161148073, "alpha_loss": 0.004278905232436955, "alpha_value": 0.025255788498110755, "duration": 269.29388403892517, "step": 56500}
{"episode_reward": 148.59820767611546, "episode": 114.0, "Q1 loss": 2.3031346561908723, "Q2 loss": 2.278023537635803, "Mean Target Q": 78.46145782470703, "Mean Q1": 78.46080227661133, "Mean Q2": 78.46071852111817, "critic_loss": 4.581158198356628, "batch_reward": 0.5228697303533554, "actor_loss": -78.75322241210938, "actor_target_entropy": -6.0, "actor_entropy": 2.602184103012085, "alpha_loss": 0.0021123614944517613, "alpha_value": 0.02505801403042179, "duration": 406.05789065361023, "step": 57000}
{"episode_reward": 418.18075222000465, "episode": 115.0, "Q1 loss": 2.168089239358902, "Q2 loss": 2.1490504429340365, "Mean Target Q": 78.59725180053711, "Mean Q1": 78.59535238647462, "Mean Q2": 78.59569497680664, "critic_loss": 4.317139691829682, "batch_reward": 0.5268857843875885, "actor_loss": -78.89278033447266, "actor_target_entropy": -6.0, "actor_entropy": 2.5634363803863525, "alpha_loss": 0.002289398002671078, "alpha_value": 0.02486361604756423, "duration": 419.8299868106842, "step": 57500}
{"episode_reward": 635.5127584364285, "episode": 116.0, "Q1 loss": 2.063723284244537, "Q2 loss": 2.05850954580307, "Mean Target Q": 78.72884075927735, "Mean Q1": 78.72813865661621, "Mean Q2": 78.72771145629883, "critic_loss": 4.122232827663422, "batch_reward": 0.528518875002861, "actor_loss": -78.98984240722656, "actor_target_entropy": -6.0, "actor_entropy": 2.4826476583480837, "alpha_loss": 0.002421081754611805, "alpha_value": 0.024687638906474917, "duration": 312.0145568847656, "step": 58000}
{"episode_reward": 43.596908865690985, "episode": 117.0, "Q1 loss": 2.0935360879898073, "Q2 loss": 2.0590136575698854, "Mean Target Q": 78.91427755737304, "Mean Q1": 78.91235316467285, "Mean Q2": 78.91293669128417, "critic_loss": 4.15254974937439, "batch_reward": 0.5281140766143799, "actor_loss": -79.19593304443359, "actor_target_entropy": -6.0, "actor_entropy": 2.4469032487869264, "alpha_loss": 0.00041463647177442906, "alpha_value": 0.024579615811076396, "duration": 302.0770878791809, "step": 58500}
{"episode_reward": 612.9847756388339, "episode": 118.0, "Q1 loss": 2.07569056725502, "Q2 loss": 2.0575628926753997, "Mean Target Q": 79.09562619018554, "Mean Q1": 79.09406495666504, "Mean Q2": 79.09414598083497, "critic_loss": 4.133253454208374, "batch_reward": 0.5315721618533135, "actor_loss": -79.38605520629883, "actor_target_entropy": -6.0, "actor_entropy": 2.4132888412475584, "alpha_loss": -0.0006488712797872722, "alpha_value": 0.024627589984539875, "duration": 366.3916382789612, "step": 59000}
{"episode_reward": 459.65462779455305, "episode": 119.0, "Q1 loss": 2.184320219039917, "Q2 loss": 2.1870467715263366, "Mean Target Q": 79.1837918548584, "Mean Q1": 79.18325636291505, "Mean Q2": 79.18244386291504, "critic_loss": 4.371366990089417, "batch_reward": 0.5315503557920456, "actor_loss": -79.40953652954101, "actor_target_entropy": -6.0, "actor_entropy": 2.4365933661460875, "alpha_loss": -0.0018052583858370781, "alpha_value": 0.02472652114239317, "duration": 373.18975257873535, "step": 59500}
{"episode_reward": 24.783716444596326, "episode": 120.0, "Q1 loss": 2.166121557474136, "Q2 loss": 2.157187585115433, "Mean Target Q": 79.14063287353515, "Mean Q1": 79.13882679748535, "Mean Q2": 79.13887509155273, "critic_loss": 4.323309143543243, "batch_reward": 0.5315051138997078, "actor_loss": -79.42343621826171, "actor_target_entropy": -6.0, "actor_entropy": 2.4149919962882995, "alpha_loss": -0.00026457469689194113, "alpha_value": 0.024791219494060573, "step": 60000}
{"duration": 381.86148166656494, "step": 60000}
{"episode_reward": 65.57397303869162, "episode": 121.0, "Q1 loss": 2.178758418083191, "Q2 loss": 2.161347136259079, "Mean Target Q": 79.19606015014648, "Mean Q1": 79.19486073303223, "Mean Q2": 79.19540562438965, "critic_loss": 4.340105556488037, "batch_reward": 0.5307861892580986, "actor_loss": -79.42998236083984, "actor_target_entropy": -6.0, "actor_entropy": 2.405393548965454, "alpha_loss": -0.0012866971807088702, "alpha_value": 0.024851791038181862, "duration": 285.92896914482117, "step": 60500}
{"episode_reward": 618.7637847240167, "episode": 122.0, "Q1 loss": 2.1483672642707825, "Q2 loss": 2.1439858589172363, "Mean Target Q": 79.3502163848877, "Mean Q1": 79.34900819396972, "Mean Q2": 79.34870631408691, "critic_loss": 4.292353116512299, "batch_reward": 0.5371066908240318, "actor_loss": -79.62097637939453, "actor_target_entropy": -6.0, "actor_entropy": 2.3497671899795534, "alpha_loss": -0.001823733996367082, "alpha_value": 0.02506055115232745, "duration": 298.9296324253082, "step": 61000}
{"episode_reward": 711.2627201840257, "episode": 123.0, "Q1 loss": 2.1761780672073363, "Q2 loss": 2.1546725680828094, "Mean Target Q": 79.59034310913086, "Mean Q1": 79.58941741943359, "Mean Q2": 79.58940563964843, "critic_loss": 4.330850643157959, "batch_reward": 0.5449707607626915, "actor_loss": -79.83113674926757, "actor_target_entropy": -6.0, "actor_entropy": 2.414126977920532, "alpha_loss": -0.0019091777275316417, "alpha_value": 0.02513118134668071, "duration": 413.3519597053528, "step": 61500}
{"episode_reward": 620.2452196618906, "episode": 124.0, "Q1 loss": 2.2050147352218628, "Q2 loss": 2.1864956834316254, "Mean Target Q": 79.90263563537597, "Mean Q1": 79.90117863464356, "Mean Q2": 79.90161540222168, "critic_loss": 4.391510414123535, "batch_reward": 0.5514865656495094, "actor_loss": -80.23662036132812, "actor_target_entropy": -6.0, "actor_entropy": 2.4457369575500487, "alpha_loss": -0.00550784941134043, "alpha_value": 0.02555508936352995, "duration": 323.3869116306305, "step": 62000}
{"episode_reward": 682.6273567509688, "episode": 125.0, "Q1 loss": 2.2010463523864745, "Q2 loss": 2.1701137390136718, "Mean Target Q": 80.19587257385254, "Mean Q1": 80.19476319885254, "Mean Q2": 80.19465020751953, "critic_loss": 4.371160098075867, "batch_reward": 0.5569754443764686, "actor_loss": -80.46791369628906, "actor_target_entropy": -6.0, "actor_entropy": 2.4362301836013796, "alpha_loss": -0.005292494777473621, "alpha_value": 0.026043500956438984, "duration": 361.46570587158203, "step": 62500}
{"episode_reward": 733.3472967273915, "episode": 126.0, "Q1 loss": 2.1929444308280943, "Q2 loss": 2.177446661949158, "Mean Target Q": 80.50593405151368, "Mean Q1": 80.50500248718262, "Mean Q2": 80.50510231018066, "critic_loss": 4.3703910894393925, "batch_reward": 0.5615719151496887, "actor_loss": -80.79059796142577, "actor_target_entropy": -6.0, "actor_entropy": 2.499373459815979, "alpha_loss": -0.008781057177111506, "alpha_value": 0.026649239072574746, "duration": 326.732136964798, "step": 63000}
{"episode_reward": 669.5033878211449, "episode": 127.0, "Q1 loss": 2.2344590253829955, "Q2 loss": 2.2017898259162902, "Mean Target Q": 80.91803189086914, "Mean Q1": 80.91653163146972, "Mean Q2": 80.9166881866455, "critic_loss": 4.4362488489151, "batch_reward": 0.5709863830208778, "actor_loss": -81.22910833740234, "actor_target_entropy": -6.0, "actor_entropy": 2.556453320503235, "alpha_loss": -0.008190695937722921, "alpha_value": 0.027306886718219896, "duration": 244.74869084358215, "step": 63500}
{"episode_reward": 595.7495479390379, "episode": 128.0, "Q1 loss": 2.2369840800762177, "Q2 loss": 2.2134024441242217, "Mean Target Q": 81.20718037414551, "Mean Q1": 81.20616789245605, "Mean Q2": 81.2061824645996, "critic_loss": 4.450386526107788, "batch_reward": 0.573062107205391, "actor_loss": -81.5212822265625, "actor_target_entropy": -6.0, "actor_entropy": 2.5773408727645872, "alpha_loss": -0.0033355198269709946, "alpha_value": 0.027783828217277106, "duration": 210.8310685157776, "step": 64000}
{"episode_reward": 678.5452155143593, "episode": 129.0, "Q1 loss": 2.232600500822067, "Q2 loss": 2.2345626680850983, "Mean Target Q": 81.54052136230469, "Mean Q1": 81.53986599731445, "Mean Q2": 81.53971697998047, "critic_loss": 4.467163174629212, "batch_reward": 0.5808572692275047, "actor_loss": -81.83146203613282, "actor_target_entropy": -6.0, "actor_entropy": 2.5303740520477294, "alpha_loss": -0.004573042753618211, "alpha_value": 0.028079022463786796, "duration": 249.66321349143982, "step": 64500}
{"episode_reward": 560.4261296872911, "episode": 130.0, "Q1 loss": 2.283441296815872, "Q2 loss": 2.267631085157394, "Mean Target Q": 81.97501925659179, "Mean Q1": 81.9728212890625, "Mean Q2": 81.97294786071777, "critic_loss": 4.5510723834037785, "batch_reward": 0.5856674785614013, "actor_loss": -82.32406015014648, "actor_target_entropy": -6.0, "actor_entropy": 2.443163872718811, "alpha_loss": -0.003866694388212636, "alpha_value": 0.02840675715280582, "step": 65000}
{"duration": 337.45436549186707, "step": 65000}
{"episode_reward": 701.8358094360552, "episode": 131.0, "Q1 loss": 2.2675921161174775, "Q2 loss": 2.271987730026245, "Mean Target Q": 82.42787913513183, "Mean Q1": 82.42775187683105, "Mean Q2": 82.42755780029297, "critic_loss": 4.539579852581024, "batch_reward": 0.5935779154896736, "actor_loss": -82.7860092163086, "actor_target_entropy": -6.0, "actor_entropy": 2.477769464492798, "alpha_loss": -0.002649239518214017, "alpha_value": 0.02869013443585574, "duration": 309.7426242828369, "step": 65500}
{"episode_reward": 784.0771342693674, "episode": 132.0, "Q1 loss": 2.2332376990318297, "Q2 loss": 2.2332123301029205, "Mean Target Q": 82.85239097595215, "Mean Q1": 82.85056678771973, "Mean Q2": 82.85065580749512, "critic_loss": 4.466450026512146, "batch_reward": 0.5982480424642563, "actor_loss": -83.21433386230468, "actor_target_entropy": -6.0, "actor_entropy": 2.5256539421081543, "alpha_loss": -0.00536203249974642, "alpha_value": 0.029010252203198438, "duration": 270.4858076572418, "step": 66000}
{"episode_reward": 551.6781641787852, "episode": 133.0, "Q1 loss": 2.2367655549049377, "Q2 loss": 2.2264600536823274, "Mean Target Q": 83.26039697265625, "Mean Q1": 83.25942379760743, "Mean Q2": 83.25968565368652, "critic_loss": 4.463225604057312, "batch_reward": 0.6027854315638542, "actor_loss": -83.60269305419922, "actor_target_entropy": -6.0, "actor_entropy": 2.559045557975769, "alpha_loss": -0.007886581982020288, "alpha_value": 0.0295864579022458, "duration": 221.59695863723755, "step": 66500}
{"episode_reward": 688.9613682766617, "episode": 134.0, "Q1 loss": 2.248509225130081, "Q2 loss": 2.234129078388214, "Mean Target Q": 83.74727476501465, "Mean Q1": 83.74549851989747, "Mean Q2": 83.74552117919922, "critic_loss": 4.482638300895691, "batch_reward": 0.6055548743009568, "actor_loss": -84.10786355590821, "actor_target_entropy": -6.0, "actor_entropy": 2.6077311935424805, "alpha_loss": -0.0033148288025986405, "alpha_value": 0.030153005639405834, "duration": 196.04571533203125, "step": 67000}
{"episode_reward": 627.9908548460361, "episode": 135.0, "Q1 loss": 2.239622300863266, "Q2 loss": 2.220480101823807, "Mean Target Q": 84.235547164917, "Mean Q1": 84.23468995666504, "Mean Q2": 84.23462652587891, "critic_loss": 4.460102406024933, "batch_reward": 0.6133941495418549, "actor_loss": -84.61294973754883, "actor_target_entropy": -6.0, "actor_entropy": 2.525158037185669, "alpha_loss": -0.0012361118528060615, "alpha_value": 0.030306720658340912, "duration": 285.55698251724243, "step": 67500}
{"episode_reward": 497.45069984223426, "episode": 136.0, "Q1 loss": 2.1803045678138733, "Q2 loss": 2.1715491335392, "Mean Target Q": 84.72571784973144, "Mean Q1": 84.72452125549316, "Mean Q2": 84.72471879577637, "critic_loss": 4.3518537049293515, "batch_reward": 0.6159047278165817, "actor_loss": -85.07991873168945, "actor_target_entropy": -6.0, "actor_entropy": 2.5593361864089967, "alpha_loss": -0.0006553201847709716, "alpha_value": 0.030341917352954044, "duration": 205.7286605834961, "step": 68000}
{"episode_reward": 568.1596429285332, "episode": 137.0, "Q1 loss": 2.2024841599464415, "Q2 loss": 2.1843767120838167, "Mean Target Q": 85.11639602661133, "Mean Q1": 85.11569248962402, "Mean Q2": 85.11550038146973, "critic_loss": 4.386860872745514, "batch_reward": 0.6176497677564621, "actor_loss": -85.45698443603516, "actor_target_entropy": -6.0, "actor_entropy": 2.568746982574463, "alpha_loss": -0.0024171429697889837, "alpha_value": 0.030482380297921243, "duration": 280.3896334171295, "step": 68500}
{"episode_reward": 802.6014933145989, "episode": 138.0, "Q1 loss": 2.2073176980018614, "Q2 loss": 2.1946642701625825, "Mean Target Q": 85.65835317993164, "Mean Q1": 85.65655709838867, "Mean Q2": 85.6565514831543, "critic_loss": 4.401981970310211, "batch_reward": 0.6264940248727798, "actor_loss": -85.97601596069336, "actor_target_entropy": -6.0, "actor_entropy": 2.593016436576843, "alpha_loss": -0.0010064432271756232, "alpha_value": 0.030693266999551307, "duration": 188.69650864601135, "step": 69000}
{"episode_reward": 728.2735328410917, "episode": 139.0, "Q1 loss": 2.186827740192413, "Q2 loss": 2.1680352895259856, "Mean Target Q": 86.14293316650391, "Mean Q1": 86.14112239074707, "Mean Q2": 86.14144371032715, "critic_loss": 4.35486302947998, "batch_reward": 0.6324276815652847, "actor_loss": -86.52615277099609, "actor_target_entropy": -6.0, "actor_entropy": 2.4921974964141844, "alpha_loss": -0.00033260033209808173, "alpha_value": 0.030725883057343622, "duration": 293.5549199581146, "step": 69500}
{"episode_reward": 687.9639562859676, "episode": 140.0, "Q1 loss": 2.213797837257385, "Q2 loss": 2.196196025133133, "Mean Target Q": 86.69216033935547, "Mean Q1": 86.69196266174316, "Mean Q2": 86.69154754638672, "critic_loss": 4.4099938650131225, "batch_reward": 0.6409331998825073, "actor_loss": -87.06857043457032, "actor_target_entropy": -6.0, "actor_entropy": 2.5159218711853026, "alpha_loss": -0.0018527506939135492, "alpha_value": 0.030809689213761295, "step": 70000}
{"duration": 343.62112402915955, "step": 70000}
{"episode_reward": 678.899465633467, "episode": 141.0, "Q1 loss": 2.1679833755493165, "Q2 loss": 2.154341943025589, "Mean Target Q": 87.13589562988281, "Mean Q1": 87.1351143951416, "Mean Q2": 87.13519053649902, "critic_loss": 4.322325315475464, "batch_reward": 0.6419884209632873, "actor_loss": -87.4997490234375, "actor_target_entropy": -6.0, "actor_entropy": 2.510537832736969, "alpha_loss": -0.0014283841166179627, "alpha_value": 0.030957081668170173, "duration": 300.3900713920593, "step": 70500}
{"episode_reward": 766.884848450881, "episode": 142.0, "Q1 loss": 2.207397149324417, "Q2 loss": 2.199611654758453, "Mean Target Q": 87.68973136901856, "Mean Q1": 87.68810029602051, "Mean Q2": 87.68823408508301, "critic_loss": 4.40700880765915, "batch_reward": 0.6514248005151748, "actor_loss": -88.07086831665039, "actor_target_entropy": -6.0, "actor_entropy": 2.4797159061431886, "alpha_loss": -0.0034225446982309223, "alpha_value": 0.03120235270563183, "duration": 255.1323618888855, "step": 71000}
{"episode_reward": 680.4576177365572, "episode": 143.0, "Q1 loss": 2.264903390407562, "Q2 loss": 2.2496339039802553, "Mean Target Q": 88.09931297302246, "Mean Q1": 88.0981255645752, "Mean Q2": 88.09852879333496, "critic_loss": 4.51453729057312, "batch_reward": 0.6529562129974366, "actor_loss": -88.46831463623047, "actor_target_entropy": -6.0, "actor_entropy": 2.5396212139129637, "alpha_loss": -0.0016310565201565622, "alpha_value": 0.03151325072078412, "duration": 230.15156149864197, "step": 71500}
{"episode_reward": 549.5056889246458, "episode": 144.0, "Q1 loss": 2.2869423213005065, "Q2 loss": 2.272126625061035, "Mean Target Q": 88.60354235839844, "Mean Q1": 88.60223432922363, "Mean Q2": 88.60217491149902, "critic_loss": 4.559068950176239, "batch_reward": 0.6564914600849152, "actor_loss": -88.94945919799805, "actor_target_entropy": -6.0, "actor_entropy": 2.5200537853240967, "alpha_loss": -0.0038883584016002714, "alpha_value": 0.031757491282254975, "duration": 207.98000240325928, "step": 72000}
{"episode_reward": 724.3814762242297, "episode": 145.0, "Q1 loss": 2.2741545338630678, "Q2 loss": 2.2530924904346468, "Mean Target Q": 89.17369555664062, "Mean Q1": 89.17237185668945, "Mean Q2": 89.1718779144287, "critic_loss": 4.527247026443481, "batch_reward": 0.6659408349990845, "actor_loss": -89.55058700561523, "actor_target_entropy": -6.0, "actor_entropy": 2.5135297203063964, "alpha_loss": -0.0008191569030750543, "alpha_value": 0.0319831468631203, "duration": 349.5075333118439, "step": 72500}
{"episode_reward": 834.1962759427907, "episode": 146.0, "Q1 loss": 2.298794860839844, "Q2 loss": 2.295360331058502, "Mean Target Q": 89.69962770080566, "Mean Q1": 89.69849220275879, "Mean Q2": 89.69846862792969, "critic_loss": 4.594155191898346, "batch_reward": 0.6690105592012405, "actor_loss": -90.04011059570313, "actor_target_entropy": -6.0, "actor_entropy": 2.4975675563812256, "alpha_loss": -0.0015848527154885233, "alpha_value": 0.03213039415798088, "duration": 334.40379571914673, "step": 73000}
{"episode_reward": 760.0219059750987, "episode": 147.0, "Q1 loss": 2.2810372924804687, "Q2 loss": 2.265204230308533, "Mean Target Q": 90.21676170349122, "Mean Q1": 90.21583128356933, "Mean Q2": 90.21591784667969, "critic_loss": 4.546241522312164, "batch_reward": 0.6743102803230285, "actor_loss": -90.59762619018555, "actor_target_entropy": -6.0, "actor_entropy": 2.490382007598877, "alpha_loss": -0.0016874305699020624, "alpha_value": 0.03237310193207933, "duration": 312.0802364349365, "step": 73500}
{"episode_reward": 339.70981809801356, "episode": 148.0, "Q1 loss": 2.269092741012573, "Q2 loss": 2.256920846223831, "Mean Target Q": 90.61989671325684, "Mean Q1": 90.6191138305664, "Mean Q2": 90.61908674621581, "critic_loss": 4.526013592243195, "batch_reward": 0.6742649692296981, "actor_loss": -90.95409298706055, "actor_target_entropy": -6.0, "actor_entropy": 2.395620227813721, "alpha_loss": -0.00047933335229754446, "alpha_value": 0.03242435290799881, "duration": 402.3335416316986, "step": 74000}
{"episode_reward": 756.4028274636679, "episode": 149.0, "Q1 loss": 2.23424844288826, "Q2 loss": 2.226891130208969, "Mean Target Q": 91.18358100891113, "Mean Q1": 91.18113932800293, "Mean Q2": 91.18170579528808, "critic_loss": 4.461139575958252, "batch_reward": 0.6820023856163024, "actor_loss": -91.56850698852539, "actor_target_entropy": -6.0, "actor_entropy": 2.4685997076034547, "alpha_loss": -0.0027324627772904934, "alpha_value": 0.032549364920241554, "duration": 423.7393214702606, "step": 74500}
{"episode_reward": 793.6666333964473, "episode": 150.0, "Q1 loss": 2.237373942375183, "Q2 loss": 2.2332984564304352, "Mean Target Q": 91.78671804809571, "Mean Q1": 91.78652021789551, "Mean Q2": 91.78630250549317, "critic_loss": 4.470672398090363, "batch_reward": 0.6878240934610367, "actor_loss": -92.15590319824219, "actor_target_entropy": -6.0, "actor_entropy": 2.4539141817092895, "alpha_loss": -0.0013372468729503453, "alpha_value": 0.03282242242838714, "step": 75000}
{"duration": 519.9141645431519, "step": 75000}
{"episode_reward": 742.4840252643386, "episode": 151.0, "Q1 loss": 2.237113573551178, "Q2 loss": 2.2301890823841095, "Mean Target Q": 92.29624171447755, "Mean Q1": 92.29474768066406, "Mean Q2": 92.29530815124512, "critic_loss": 4.467302653312683, "batch_reward": 0.6966702111959457, "actor_loss": -92.63861364746094, "actor_target_entropy": -6.0, "actor_entropy": 2.390734568595886, "alpha_loss": 0.0005088389064185321, "alpha_value": 0.0327689083708245, "duration": 345.0181119441986, "step": 75500}
{"episode_reward": 785.8533672966299, "episode": 152.0, "Q1 loss": 2.268055970668793, "Q2 loss": 2.2456982128620147, "Mean Target Q": 92.8628468170166, "Mean Q1": 92.86199194335937, "Mean Q2": 92.86149055480956, "critic_loss": 4.513754177093506, "batch_reward": 0.69975930082798, "actor_loss": -93.19107775878906, "actor_target_entropy": -6.0, "actor_entropy": 2.3469256739616395, "alpha_loss": -0.002844732906902209, "alpha_value": 0.03301594252776217, "duration": 394.8253364562988, "step": 76000}
{"episode_reward": 783.5801143240033, "episode": 153.0, "Q1 loss": 2.296007130622864, "Q2 loss": 2.2584393129348754, "Mean Target Q": 93.4128565826416, "Mean Q1": 93.41247605895997, "Mean Q2": 93.41199584960937, "critic_loss": 4.554446446418762, "batch_reward": 0.7042027505636215, "actor_loss": -93.74426788330078, "actor_target_entropy": -6.0, "actor_entropy": 2.4348851127624513, "alpha_loss": -0.0032590021512005477, "alpha_value": 0.03331031750097564, "duration": 438.66802978515625, "step": 76500}
{"episode_reward": 808.819925514528, "episode": 154.0, "Q1 loss": 2.2729227645397185, "Q2 loss": 2.256230241775513, "Mean Target Q": 93.97929296875, "Mean Q1": 93.97792808532715, "Mean Q2": 93.97808267211914, "critic_loss": 4.529153001308441, "batch_reward": 0.7125443177223205, "actor_loss": -94.3278095703125, "actor_target_entropy": -6.0, "actor_entropy": 2.386918113708496, "alpha_loss": -0.0023418296293821186, "alpha_value": 0.03362943575431341, "duration": 521.8061766624451, "step": 77000}
{"episode_reward": 836.9093912568849, "episode": 155.0, "Q1 loss": 2.2418434245586396, "Q2 loss": 2.224455069541931, "Mean Target Q": 94.56379803466797, "Mean Q1": 94.56221560668945, "Mean Q2": 94.56240167236328, "critic_loss": 4.466298492908478, "batch_reward": 0.719367512345314, "actor_loss": -94.98087832641602, "actor_target_entropy": -6.0, "actor_entropy": 2.397859811782837, "alpha_loss": -0.004054724003886804, "alpha_value": 0.03392904506413283, "duration": 391.08192324638367, "step": 77500}
{"episode_reward": 833.0483228417537, "episode": 156.0, "Q1 loss": 2.2489168560504913, "Q2 loss": 2.2382069301605223, "Mean Target Q": 95.1219479675293, "Mean Q1": 95.1214024810791, "Mean Q2": 95.12157606506348, "critic_loss": 4.487123789310456, "batch_reward": 0.7230773638486863, "actor_loss": -95.4675086364746, "actor_target_entropy": -6.0, "actor_entropy": 2.404008900642395, "alpha_loss": -0.0006754153065849095, "alpha_value": 0.034149485959942376, "duration": 272.49286818504333, "step": 78000}
{"episode_reward": 862.2628216157274, "episode": 157.0, "Q1 loss": 2.2751274309158327, "Q2 loss": 2.273014971971512, "Mean Target Q": 95.67387767028809, "Mean Q1": 95.67180882263183, "Mean Q2": 95.6718681793213, "critic_loss": 4.548142395973206, "batch_reward": 0.7321699637174607, "actor_loss": -95.98343551635742, "actor_target_entropy": -6.0, "actor_entropy": 2.4743012533187865, "alpha_loss": -0.004673135188408196, "alpha_value": 0.03446666459861065, "duration": 383.1242377758026, "step": 78500}
{"episode_reward": 816.4134580455973, "episode": 158.0, "Q1 loss": 2.229674186706543, "Q2 loss": 2.2252144858837126, "Mean Target Q": 96.22409558105468, "Mean Q1": 96.22325436401367, "Mean Q2": 96.22327919006348, "critic_loss": 4.454888676166535, "batch_reward": 0.7335320838689804, "actor_loss": -96.61667657470703, "actor_target_entropy": -6.0, "actor_entropy": 2.450801679611206, "alpha_loss": -0.0021330228939186783, "alpha_value": 0.034848453347135516, "duration": 509.2683503627777, "step": 79000}
{"episode_reward": 877.6969703246563, "episode": 159.0, "Q1 loss": 2.2657387731075285, "Q2 loss": 2.226467034101486, "Mean Target Q": 96.87663066101074, "Mean Q1": 96.87576559448242, "Mean Q2": 96.87550930786132, "critic_loss": 4.492205799102783, "batch_reward": 0.7441784173250199, "actor_loss": -97.23013146972656, "actor_target_entropy": -6.0, "actor_entropy": 2.466846962928772, "alpha_loss": -0.0008860575607977807, "alpha_value": 0.03506011272466835, "duration": 616.5184934139252, "step": 79500}
{"episode_reward": 792.6370836419728, "episode": 160.0, "Q1 loss": 2.2282164549827574, "Q2 loss": 2.217576763868332, "Mean Target Q": 97.34603981018067, "Mean Q1": 97.34455940246582, "Mean Q2": 97.34467419433594, "critic_loss": 4.445793223381043, "batch_reward": 0.7442987127304077, "actor_loss": -97.70682189941407, "actor_target_entropy": -6.0, "actor_entropy": 2.4120866613388063, "alpha_loss": -0.00028518178127706054, "alpha_value": 0.03501776288005104, "step": 80000}
{"duration": 532.0479683876038, "step": 80000}
{"episode_reward": 834.5194419004008, "episode": 161.0, "Q1 loss": 2.2366285021305083, "Q2 loss": 2.2466738157272337, "Mean Target Q": 97.95646351623535, "Mean Q1": 97.95591636657714, "Mean Q2": 97.95573207092285, "critic_loss": 4.483302313804627, "batch_reward": 0.7531284794807435, "actor_loss": -98.343080078125, "actor_target_entropy": -6.0, "actor_entropy": 2.3852438549995423, "alpha_loss": -0.00010612726071849465, "alpha_value": 0.035109480351316086, "duration": 574.248654127121, "step": 80500}
{"episode_reward": 820.9426985009941, "episode": 162.0, "Q1 loss": 2.167281696796417, "Q2 loss": 2.1557426054477693, "Mean Target Q": 98.54051777648925, "Mean Q1": 98.53913937377929, "Mean Q2": 98.53931965637207, "critic_loss": 4.323024302005768, "batch_reward": 0.7573774831295014, "actor_loss": -98.9753547668457, "actor_target_entropy": -6.0, "actor_entropy": 2.4374883432388303, "alpha_loss": 0.0001850720380898565, "alpha_value": 0.03509446018390965, "duration": 511.58898758888245, "step": 81000}
{"episode_reward": 743.5143444611165, "episode": 163.0, "Q1 loss": 2.207170584201813, "Q2 loss": 2.207786693096161, "Mean Target Q": 99.10381144714356, "Mean Q1": 99.10326126098633, "Mean Q2": 99.10298954772949, "critic_loss": 4.414957281112671, "batch_reward": 0.7648699023723602, "actor_loss": -99.52915734863281, "actor_target_entropy": -6.0, "actor_entropy": 2.371689203262329, "alpha_loss": -0.0009493522928096354, "alpha_value": 0.035059744728971935, "duration": 531.3193998336792, "step": 81500}
{"episode_reward": 881.1104214133434, "episode": 164.0, "Q1 loss": 2.17780317568779, "Q2 loss": 2.162356444120407, "Mean Target Q": 99.64517010498047, "Mean Q1": 99.64394239807129, "Mean Q2": 99.64413549804688, "critic_loss": 4.340159620761871, "batch_reward": 0.7676691591739655, "actor_loss": -100.00419812011718, "actor_target_entropy": -6.0, "actor_entropy": 2.3974741005897524, "alpha_loss": -0.0012497245576232672, "alpha_value": 0.035270657141390487, "duration": 337.46658420562744, "step": 82000}
{"episode_reward": 807.2122849077793, "episode": 165.0, "Q1 loss": 2.199492379665375, "Q2 loss": 2.1760930342674256, "Mean Target Q": 100.30882159423828, "Mean Q1": 100.3081664428711, "Mean Q2": 100.30835458374024, "critic_loss": 4.37558541059494, "batch_reward": 0.77696431016922, "actor_loss": -100.68869732666016, "actor_target_entropy": -6.0, "actor_entropy": 2.3647119731903077, "alpha_loss": -0.003148473772685975, "alpha_value": 0.03547906395559929, "duration": 268.38910007476807, "step": 82500}
{"episode_reward": 800.152590756128, "episode": 166.0, "Q1 loss": 2.2224418652057647, "Q2 loss": 2.2230456008911132, "Mean Target Q": 100.83863220214843, "Mean Q1": 100.83639016723633, "Mean Q2": 100.83606535339355, "critic_loss": 4.445487473487854, "batch_reward": 0.7793390499353409, "actor_loss": -101.17487896728515, "actor_target_entropy": -6.0, "actor_entropy": 2.3705551013946535, "alpha_loss": -0.0024435902240220455, "alpha_value": 0.03580454109067662, "duration": 401.08584690093994, "step": 83000}
{"episode_reward": 899.6064369209282, "episode": 167.0, "Q1 loss": 2.178401827573776, "Q2 loss": 2.1670560247898103, "Mean Target Q": 101.4483892211914, "Mean Q1": 101.44801217651367, "Mean Q2": 101.44820695495605, "critic_loss": 4.345457855701446, "batch_reward": 0.7872257248163224, "actor_loss": -101.8260027770996, "actor_target_entropy": -6.0, "actor_entropy": 2.4369363288879393, "alpha_loss": 0.00023183879791758956, "alpha_value": 0.03590612224122123, "duration": 307.7023515701294, "step": 83500}
{"episode_reward": 791.4574793495949, "episode": 168.0, "Q1 loss": 2.1678083238601684, "Q2 loss": 2.153021971464157, "Mean Target Q": 102.02677787780762, "Mean Q1": 102.02544036865234, "Mean Q2": 102.02546649169922, "critic_loss": 4.3208302927017215, "batch_reward": 0.7903272505998612, "actor_loss": -102.42250643920899, "actor_target_entropy": -6.0, "actor_entropy": 2.401983483314514, "alpha_loss": 0.0009666254094336182, "alpha_value": 0.03586556660554164, "duration": 268.1950557231903, "step": 84000}
{"episode_reward": 769.3283803658238, "episode": 169.0, "Q1 loss": 2.164929893016815, "Q2 loss": 2.157781311750412, "Mean Target Q": 102.57817358398438, "Mean Q1": 102.57756492614746, "Mean Q2": 102.57749572753906, "critic_loss": 4.322711204528809, "batch_reward": 0.7930997052192688, "actor_loss": -102.96722317504883, "actor_target_entropy": -6.0, "actor_entropy": 2.3397789154052733, "alpha_loss": 0.001233902654144913, "alpha_value": 0.03576454692278632, "duration": 453.44632387161255, "step": 84500}
{"episode_reward": 722.615245419248, "episode": 170.0, "Q1 loss": 2.173851619720459, "Q2 loss": 2.171915056467056, "Mean Target Q": 103.15664698791504, "Mean Q1": 103.15596543884277, "Mean Q2": 103.1559161529541, "critic_loss": 4.3457666730880735, "batch_reward": 0.8006653257608414, "actor_loss": -103.56899887084961, "actor_target_entropy": -6.0, "actor_entropy": 2.3593105955123903, "alpha_loss": -0.0004951423436868936, "alpha_value": 0.035763149572138137, "step": 85000}
{"duration": 573.1970193386078, "step": 85000}
{"episode_reward": 912.7527348732851, "episode": 171.0, "Q1 loss": 2.203963145017624, "Q2 loss": 2.1928886501789093, "Mean Target Q": 103.61981594848633, "Mean Q1": 103.61865579223632, "Mean Q2": 103.61883454895019, "critic_loss": 4.396851794242859, "batch_reward": 0.8035984241962433, "actor_loss": -103.99925827026367, "actor_target_entropy": -6.0, "actor_entropy": 2.338216718673706, "alpha_loss": -0.0005974217548500747, "alpha_value": 0.03570309973065977, "duration": 399.24519395828247, "step": 85500}
{"episode_reward": 791.3578097653432, "episode": 172.0, "Q1 loss": 2.185918795347214, "Q2 loss": 2.1736970689296724, "Mean Target Q": 104.21496284484863, "Mean Q1": 104.21342538452149, "Mean Q2": 104.21344673156739, "critic_loss": 4.359615869998932, "batch_reward": 0.8098853105306625, "actor_loss": -104.64433563232421, "actor_target_entropy": -6.0, "actor_entropy": 2.3932547101974486, "alpha_loss": -0.0028477803578134627, "alpha_value": 0.03598059715241917, "duration": 508.16248083114624, "step": 86000}
{"episode_reward": 856.8256056762291, "episode": 173.0, "Q1 loss": 2.2039772922992706, "Q2 loss": 2.207068938732147, "Mean Target Q": 104.75680903625488, "Mean Q1": 104.75715252685546, "Mean Q2": 104.75727912902832, "critic_loss": 4.411046230316162, "batch_reward": 0.8142536737918854, "actor_loss": -105.14195526123046, "actor_target_entropy": -6.0, "actor_entropy": 2.409443347930908, "alpha_loss": -0.0007180953667266294, "alpha_value": 0.036081029880679585, "duration": 524.0913455486298, "step": 86500}
{"episode_reward": 878.7113316995027, "episode": 174.0, "Q1 loss": 2.1930802693367006, "Q2 loss": 2.185117008447647, "Mean Target Q": 105.30247705078125, "Mean Q1": 105.30099981689453, "Mean Q2": 105.30048931884765, "critic_loss": 4.378197275161743, "batch_reward": 0.820292160153389, "actor_loss": -105.71432232666015, "actor_target_entropy": -6.0, "actor_entropy": 2.327335964679718, "alpha_loss": -0.0013739387718960643, "alpha_value": 0.036257220442378515, "duration": 524.2422313690186, "step": 87000}
{"episode_reward": 754.3308808714539, "episode": 175.0, "Q1 loss": 2.2017681992053983, "Q2 loss": 2.196952223777771, "Mean Target Q": 105.88045059204102, "Mean Q1": 105.87842546081544, "Mean Q2": 105.87930491638184, "critic_loss": 4.398720422744751, "batch_reward": 0.8253658728599549, "actor_loss": -106.26307711791992, "actor_target_entropy": -6.0, "actor_entropy": 2.3616639318466186, "alpha_loss": -0.003243935976177454, "alpha_value": 0.03653155024739526, "duration": 513.3661499023438, "step": 87500}
{"episode_reward": 847.5890855523943, "episode": 176.0, "Q1 loss": 2.1707101204395296, "Q2 loss": 2.156269162416458, "Mean Target Q": 106.43102655029297, "Mean Q1": 106.43076899719239, "Mean Q2": 106.43034310913086, "critic_loss": 4.326979279994965, "batch_reward": 0.8278531131744384, "actor_loss": -106.82726239013672, "actor_target_entropy": -6.0, "actor_entropy": 2.3844886865615846, "alpha_loss": 0.0005252784851472825, "alpha_value": 0.03666459344647324, "duration": 498.1620216369629, "step": 88000}
{"episode_reward": 765.6665977077081, "episode": 177.0, "Q1 loss": 2.161675019264221, "Q2 loss": 2.1640640709400176, "Mean Target Q": 106.93317556762695, "Mean Q1": 106.93240077209472, "Mean Q2": 106.93238664245605, "critic_loss": 4.32573908662796, "batch_reward": 0.8328619104623795, "actor_loss": -107.29214089965821, "actor_target_entropy": -6.0, "actor_entropy": 2.3367818908691405, "alpha_loss": 0.0033833965060766787, "alpha_value": 0.036529236197968606, "duration": 472.130961894989, "step": 88500}
{"episode_reward": 793.348166027923, "episode": 178.0, "Q1 loss": 2.192049457550049, "Q2 loss": 2.184661609649658, "Mean Target Q": 107.48815768432617, "Mean Q1": 107.48648593139649, "Mean Q2": 107.48642324829102, "critic_loss": 4.376711078643799, "batch_reward": 0.8394640201330185, "actor_loss": -107.8611642150879, "actor_target_entropy": -6.0, "actor_entropy": 2.2631445903778076, "alpha_loss": 0.0027121190170291813, "alpha_value": 0.03607719892588552, "duration": 269.66236567497253, "step": 89000}
{"episode_reward": 906.9272595451893, "episode": 179.0, "Q1 loss": 2.1964477536678313, "Q2 loss": 2.1990201029777525, "Mean Target Q": 107.92010539245605, "Mean Q1": 107.91845166015625, "Mean Q2": 107.9186650390625, "critic_loss": 4.395467859268188, "batch_reward": 0.8424464017152786, "actor_loss": -108.21036776733398, "actor_target_entropy": -6.0, "actor_entropy": 2.3265267152786255, "alpha_loss": -0.0015447153891436755, "alpha_value": 0.0359897757303383, "duration": 279.04726552963257, "step": 89500}
{"episode_reward": 780.742113694424, "episode": 180.0, "Q1 loss": 2.192718890428543, "Q2 loss": 2.1907100083827973, "Mean Target Q": 108.40905955505372, "Mean Q1": 108.40897930908203, "Mean Q2": 108.40859487915039, "critic_loss": 4.383428896903991, "batch_reward": 0.8451902104616165, "actor_loss": -108.71817007446289, "actor_target_entropy": -6.0, "actor_entropy": 2.3726953830718993, "alpha_loss": -0.00014228265918791294, "alpha_value": 0.036138732001913414, "step": 90000}
{"duration": 345.8370499610901, "step": 90000}
{"episode_reward": 918.4997398735053, "episode": 181.0, "Q1 loss": 2.1819193789958953, "Q2 loss": 2.18316295671463, "Mean Target Q": 108.93571307373047, "Mean Q1": 108.93509817504882, "Mean Q2": 108.93509451293946, "critic_loss": 4.365082335948944, "batch_reward": 0.8530582464933395, "actor_loss": -109.3164338684082, "actor_target_entropy": -6.0, "actor_entropy": 2.3101558256149293, "alpha_loss": -0.0023182794565800575, "alpha_value": 0.036212470088131665, "duration": 369.48552107810974, "step": 90500}
{"episode_reward": 823.1443135337295, "episode": 182.0, "Q1 loss": 2.1655763885974886, "Q2 loss": 2.1691883893013, "Mean Target Q": 109.39894990539551, "Mean Q1": 109.39764421081543, "Mean Q2": 109.39783949279786, "critic_loss": 4.334764792919159, "batch_reward": 0.8562250022888184, "actor_loss": -109.76455975341797, "actor_target_entropy": -6.0, "actor_entropy": 2.3379911432266236, "alpha_loss": -8.604110358282924e-05, "alpha_value": 0.03637429389861967, "duration": 269.79870533943176, "step": 91000}
{"episode_reward": 792.3718538659549, "episode": 183.0, "Q1 loss": 2.22654606628418, "Q2 loss": 2.208623544216156, "Mean Target Q": 109.90217456054687, "Mean Q1": 109.90048112487793, "Mean Q2": 109.90065176391602, "critic_loss": 4.43516959476471, "batch_reward": 0.8608068848848343, "actor_loss": -110.2407483215332, "actor_target_entropy": -6.0, "actor_entropy": 2.3486746673583982, "alpha_loss": 0.0008614665940403939, "alpha_value": 0.03634304421532197, "duration": 309.60485076904297, "step": 91500}
{"episode_reward": 866.1766578375497, "episode": 184.0, "Q1 loss": 2.231767241477966, "Q2 loss": 2.239246343374252, "Mean Target Q": 110.43654557800294, "Mean Q1": 110.43608363342285, "Mean Q2": 110.43608753967285, "critic_loss": 4.471013587474823, "batch_reward": 0.8659825092554092, "actor_loss": -110.74601663208009, "actor_target_entropy": -6.0, "actor_entropy": 2.345817383289337, "alpha_loss": 0.0007206058769952505, "alpha_value": 0.03630582416554735, "duration": 429.50599122047424, "step": 92000}
{"episode_reward": 866.6418106969901, "episode": 185.0, "Q1 loss": 2.190963206768036, "Q2 loss": 2.187466034889221, "Mean Target Q": 110.89143975830078, "Mean Q1": 110.89088687133788, "Mean Q2": 110.89059934997559, "critic_loss": 4.378429246902466, "batch_reward": 0.8719717621803283, "actor_loss": -111.19537368774414, "actor_target_entropy": -6.0, "actor_entropy": 2.3653254604339597, "alpha_loss": -0.0005922349242027849, "alpha_value": 0.03626209022290582, "duration": 270.44020795822144, "step": 92500}
{"episode_reward": 899.847122704561, "episode": 186.0, "Q1 loss": 2.2123192610740663, "Q2 loss": 2.2126262476444243, "Mean Target Q": 111.31478939819335, "Mean Q1": 111.3122576751709, "Mean Q2": 111.31271607971192, "critic_loss": 4.4249455046653745, "batch_reward": 0.87301999604702, "actor_loss": -111.67986456298829, "actor_target_entropy": -6.0, "actor_entropy": 2.340608030319214, "alpha_loss": -0.0002765309875831008, "alpha_value": 0.03630205085447555, "duration": 231.53034687042236, "step": 93000}
{"episode_reward": 939.9778305875348, "episode": 187.0, "Q1 loss": 2.175033451557159, "Q2 loss": 2.174424427986145, "Mean Target Q": 111.85040542602539, "Mean Q1": 111.85069885253907, "Mean Q2": 111.85067674255372, "critic_loss": 4.349457877159119, "batch_reward": 0.8791105605363846, "actor_loss": -112.19393533325196, "actor_target_entropy": -6.0, "actor_entropy": 2.28649946975708, "alpha_loss": -0.00019261942873708904, "alpha_value": 0.0363409216297415, "duration": 251.06638598442078, "step": 93500}
{"episode_reward": 940.7122171489845, "episode": 188.0, "Q1 loss": 2.1706733174324038, "Q2 loss": 2.1747075428962708, "Mean Target Q": 112.44238897705078, "Mean Q1": 112.44060818481445, "Mean Q2": 112.44090930175781, "critic_loss": 4.3453808660507205, "batch_reward": 0.8848982130289078, "actor_loss": -112.81149612426758, "actor_target_entropy": -6.0, "actor_entropy": 2.3009425687789915, "alpha_loss": -0.0018452926040627062, "alpha_value": 0.036464121804014156, "duration": 264.5529453754425, "step": 94000}
{"episode_reward": 792.843879287694, "episode": 189.0, "Q1 loss": 2.199120283126831, "Q2 loss": 2.2004347977638243, "Mean Target Q": 112.95772328186035, "Mean Q1": 112.95735520935058, "Mean Q2": 112.95673207092285, "critic_loss": 4.399555076599121, "batch_reward": 0.8899348999261856, "actor_loss": -113.29114227294922, "actor_target_entropy": -6.0, "actor_entropy": 2.2157279381752013, "alpha_loss": 0.0006653267734218389, "alpha_value": 0.036515421095967004, "duration": 366.53789949417114, "step": 94500}
{"episode_reward": 885.9894329882327, "episode": 190.0, "Q1 loss": 2.185033579349518, "Q2 loss": 2.18110866355896, "Mean Target Q": 113.45766122436524, "Mean Q1": 113.45623767089843, "Mean Q2": 113.4567869720459, "critic_loss": 4.366142232894897, "batch_reward": 0.894815260052681, "actor_loss": -113.7832709350586, "actor_target_entropy": -6.0, "actor_entropy": 2.272918257713318, "alpha_loss": -0.0008387622146401554, "alpha_value": 0.03650818794798276, "step": 95000}
{"duration": 309.4925754070282, "step": 95000}
{"episode_reward": 900.0081507539536, "episode": 191.0, "Q1 loss": 2.1848183631896974, "Q2 loss": 2.163771944284439, "Mean Target Q": 113.95848028564453, "Mean Q1": 113.95767446899414, "Mean Q2": 113.95766358947753, "critic_loss": 4.348590304374695, "batch_reward": 0.8993648221492767, "actor_loss": -114.3148210144043, "actor_target_entropy": -6.0, "actor_entropy": 2.295766851425171, "alpha_loss": -0.0005500599315855652, "alpha_value": 0.03662224539053496, "duration": 241.26624274253845, "step": 95500}
{"episode_reward": 836.2059610514536, "episode": 192.0, "Q1 loss": 2.1766233911514283, "Q2 loss": 2.1705218751430513, "Mean Target Q": 114.4519602508545, "Mean Q1": 114.45056518554688, "Mean Q2": 114.45035942077637, "critic_loss": 4.347145269870758, "batch_reward": 0.9028928924798966, "actor_loss": -114.8022568359375, "actor_target_entropy": -6.0, "actor_entropy": 2.2046624593734743, "alpha_loss": 0.00045901826582849024, "alpha_value": 0.03660866738033225, "duration": 372.2641317844391, "step": 96000}
{"episode_reward": 906.635159483913, "episode": 193.0, "Q1 loss": 2.1757626221179964, "Q2 loss": 2.184932272195816, "Mean Target Q": 114.93230152893067, "Mean Q1": 114.93225813293456, "Mean Q2": 114.93253268432618, "critic_loss": 4.360694895267486, "batch_reward": 0.907493077993393, "actor_loss": -115.26256237792968, "actor_target_entropy": -6.0, "actor_entropy": 2.2265606236457827, "alpha_loss": -0.0008047306737862527, "alpha_value": 0.036518369212620395, "duration": 407.1175923347473, "step": 96500}
{"episode_reward": 868.9733572438377, "episode": 194.0, "Q1 loss": 2.1963479743003846, "Q2 loss": 2.1865712971687317, "Mean Target Q": 115.38140625, "Mean Q1": 115.38026327514649, "Mean Q2": 115.37992387390136, "critic_loss": 4.382919268608093, "batch_reward": 0.9113942217826844, "actor_loss": -115.7140531616211, "actor_target_entropy": -6.0, "actor_entropy": 2.2157827529907226, "alpha_loss": 0.003868763195583597, "alpha_value": 0.0364909671022939, "duration": 407.09232568740845, "step": 97000}
{"episode_reward": 899.4916031798058, "episode": 195.0, "Q1 loss": 2.1289292514324187, "Q2 loss": 2.1263950622081755, "Mean Target Q": 115.87354159545899, "Mean Q1": 115.87284761047363, "Mean Q2": 115.87290550231934, "critic_loss": 4.255324303627014, "batch_reward": 0.917876269698143, "actor_loss": -116.20761401367187, "actor_target_entropy": -6.0, "actor_entropy": 2.155239130496979, "alpha_loss": 0.0025447473141830415, "alpha_value": 0.036122907018594885, "duration": 304.32396841049194, "step": 97500}
{"episode_reward": 946.9191867396415, "episode": 196.0, "Q1 loss": 2.089801518201828, "Q2 loss": 2.0934950668811796, "Mean Target Q": 116.40885356140137, "Mean Q1": 116.40734446716309, "Mean Q2": 116.4072372894287, "critic_loss": 4.183296590328217, "batch_reward": 0.9200045784711838, "actor_loss": -116.74024423217773, "actor_target_entropy": -6.0, "actor_entropy": 2.189361713409424, "alpha_loss": 0.00039774033054709436, "alpha_value": 0.035967825991201983, "duration": 283.5907826423645, "step": 98000}
{"episode_reward": 943.038341438251, "episode": 197.0, "Q1 loss": 2.1557797362804414, "Q2 loss": 2.1571714560985567, "Mean Target Q": 116.92855021667481, "Mean Q1": 116.92778314208985, "Mean Q2": 116.92778816223145, "critic_loss": 4.312951193809509, "batch_reward": 0.9279954364299774, "actor_loss": -117.26179620361329, "actor_target_entropy": -6.0, "actor_entropy": 2.232751419067383, "alpha_loss": -0.0004188840049318969, "alpha_value": 0.03593441578614405, "duration": 263.83738470077515, "step": 98500}
{"episode_reward": 924.8094633669234, "episode": 198.0, "Q1 loss": 2.1505054540634156, "Q2 loss": 2.140645671606064, "Mean Target Q": 117.40297918701172, "Mean Q1": 117.40182382202148, "Mean Q2": 117.40226594543456, "critic_loss": 4.291151124477387, "batch_reward": 0.9289011374711991, "actor_loss": -117.84145104980469, "actor_target_entropy": -6.0, "actor_entropy": 2.1967991900444033, "alpha_loss": -0.0006265259047504515, "alpha_value": 0.03609259780985568, "duration": 331.9142463207245, "step": 99000}
{"episode_reward": 926.5603180640825, "episode": 199.0, "Q1 loss": 2.134180844783783, "Q2 loss": 2.1280842611789703, "Mean Target Q": 118.02487910461426, "Mean Q1": 118.02452465820312, "Mean Q2": 118.02442413330078, "critic_loss": 4.262265101909637, "batch_reward": 0.9354737132787705, "actor_loss": -118.39143240356445, "actor_target_entropy": -6.0, "actor_entropy": 2.1706046228408815, "alpha_loss": -0.0007337131118401885, "alpha_value": 0.03614967511667255, "duration": 307.88524889945984, "step": 99500}
{"episode_reward": 907.2061479392955, "episode": 200.0, "Q1 loss": 2.170445674168084, "Q2 loss": 2.1671780689445908, "Mean Target Q": 118.46252031651193, "Mean Q1": 118.46165912758133, "Mean Q2": 118.46166528919656, "critic_loss": 4.33762373952923, "batch_reward": 0.9375673493068061, "actor_loss": -118.81713845825195, "actor_target_entropy": -6.0, "actor_entropy": 2.210024751663208, "alpha_loss": -0.003386388178449124, "alpha_value": 0.03631526998382209, "step": 99999}
