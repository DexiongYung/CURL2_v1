{"episode_reward": 0.0, "episode": 1.0, "duration": 49.69837760925293, "step": 500}
{"episode_reward": 45.447181319925, "episode": 2.0, "duration": 2.228733539581299, "step": 1000}
{"episode_reward": 30.66754504360952, "episode": 3.0, "Q1 loss": 0.01408289582026191, "Q2 loss": 0.01607588031468913, "Mean Target Q": 0.8885905877836049, "Mean Q1": 0.8891792000234127, "Mean Q2": 0.8898265158571302, "critic_loss": 0.030158776096999646, "batch_reward": 0.07684579513967037, "actor_loss": -1.268877368092537, "actor_target_entropy": -6.0, "actor_entropy": 7.546235340476036, "alpha_loss": 0.9775876442193985, "alpha_value": 0.09877152610557012, "duration": 519.7166433334351, "step": 1500}
{"episode_reward": 40.239541048342076, "episode": 4.0, "Q1 loss": 0.004225391517393291, "Q2 loss": 0.004162660357076675, "Mean Target Q": 2.0023156406879425, "Mean Q1": 2.0019822914600374, "Mean Q2": 2.001985859870911, "critic_loss": 0.008388051892630756, "batch_reward": 0.08700240691006184, "actor_loss": -2.3889459762573244, "actor_target_entropy": -6.0, "actor_entropy": 7.772925275802613, "alpha_loss": 0.9672472016811371, "alpha_value": 0.09634339022272391, "duration": 339.66000509262085, "step": 2000}
{"episode_reward": 57.172171914335216, "episode": 5.0, "Q1 loss": 0.004852003655862063, "Q2 loss": 0.004795972482766956, "Mean Target Q": 3.0238747458457946, "Mean Q1": 3.023618921756744, "Mean Q2": 3.0236284255981447, "critic_loss": 0.009647976131178439, "batch_reward": 0.08821591743826866, "actor_loss": -3.40461349773407, "actor_target_entropy": -6.0, "actor_entropy": 7.8151344947814945, "alpha_loss": 0.9383246009349823, "alpha_value": 0.09401849493362409, "duration": 435.1197202205658, "step": 2500}
{"episode_reward": 50.463796339557206, "episode": 6.0, "Q1 loss": 0.005605647630058229, "Q2 loss": 0.005590352229773998, "Mean Target Q": 3.990938301563263, "Mean Q1": 3.990710816860199, "Mean Q2": 3.990709888458252, "critic_loss": 0.011195999859832228, "batch_reward": 0.08808089551329613, "actor_loss": -4.357846118927002, "actor_target_entropy": -6.0, "actor_entropy": 7.945143228530884, "alpha_loss": 0.914783935546875, "alpha_value": 0.09177872422266291, "duration": 282.1126039028168, "step": 3000}
{"episode_reward": 34.602481059161796, "episode": 7.0, "Q1 loss": 0.005592006127815694, "Q2 loss": 0.005627782257273793, "Mean Target Q": 4.913362519264221, "Mean Q1": 4.913026008605957, "Mean Q2": 4.913008091926574, "critic_loss": 0.011219788401387631, "batch_reward": 0.09043587346374989, "actor_loss": -5.271267162322998, "actor_target_entropy": -6.0, "actor_entropy": 8.034258432388306, "alpha_loss": 0.8919600398540497, "alpha_value": 0.0896084513059101, "duration": 261.1615459918976, "step": 3500}
{"episode_reward": 75.48137074849559, "episode": 8.0, "Q1 loss": 0.006666120164562017, "Q2 loss": 0.006712151075713336, "Mean Target Q": 5.814712655067444, "Mean Q1": 5.814471103668213, "Mean Q2": 5.814466175079346, "critic_loss": 0.013378271255642176, "batch_reward": 0.09476071266829968, "actor_loss": -6.168134798049927, "actor_target_entropy": -6.0, "actor_entropy": 8.032667867660523, "alpha_loss": 0.8654478907585144, "alpha_value": 0.08751305524371265, "duration": 313.2340979576111, "step": 4000}
{"episode_reward": 37.23427673750266, "episode": 9.0, "Q1 loss": 0.00678115346794948, "Q2 loss": 0.006835438906215132, "Mean Target Q": 6.671274483680725, "Mean Q1": 6.671133952140808, "Mean Q2": 6.67114186668396, "critic_loss": 0.013616592408157885, "batch_reward": 0.09469093525409698, "actor_loss": -7.015342956542969, "actor_target_entropy": -6.0, "actor_entropy": 8.064869812011718, "alpha_loss": 0.8442367885112763, "alpha_value": 0.08548288050415676, "duration": 421.98524737358093, "step": 4500}
{"episode_reward": 60.40882640138971, "episode": 10.0, "Q1 loss": 0.007375299380160868, "Q2 loss": 0.007371544736437499, "Mean Target Q": 7.481127800941468, "Mean Q1": 7.480742178916931, "Mean Q2": 7.480757759094239, "critic_loss": 0.014746844130568206, "batch_reward": 0.0951908688545227, "actor_loss": -7.817774551391602, "actor_target_entropy": -6.0, "actor_entropy": 8.079923223495483, "alpha_loss": 0.8198003032207489, "alpha_value": 0.08351483325208697, "step": 5000}
{"duration": 430.7293891906738, "step": 5000}
{"episode_reward": 39.346188043977506, "episode": 11.0, "Q1 loss": 0.008861694134771824, "Q2 loss": 0.00889528310764581, "Mean Target Q": 8.27034108543396, "Mean Q1": 8.27011079788208, "Mean Q2": 8.270131447792053, "critic_loss": 0.017756977239623665, "batch_reward": 0.09789201872050762, "actor_loss": -8.593237621307374, "actor_target_entropy": -6.0, "actor_entropy": 8.082302423477174, "alpha_loss": 0.7991512937545776, "alpha_value": 0.08160575774400808, "duration": 287.5861291885376, "step": 5500}
{"episode_reward": 84.99495921013207, "episode": 12.0, "Q1 loss": 0.008206194644793868, "Q2 loss": 0.008247068380005657, "Mean Target Q": 9.034048871994019, "Mean Q1": 9.033764068603515, "Mean Q2": 9.033742433547973, "critic_loss": 0.01645326304063201, "batch_reward": 0.10034862907230854, "actor_loss": -9.357345252990722, "actor_target_entropy": -6.0, "actor_entropy": 8.089197937011718, "alpha_loss": 0.7794687964916229, "alpha_value": 0.07974700006389929, "duration": 198.49082732200623, "step": 6000}
{"episode_reward": 41.5395149611325, "episode": 13.0, "Q1 loss": 0.010905369169078766, "Q2 loss": 0.010981025361455976, "Mean Target Q": 9.761605363845826, "Mean Q1": 9.761289394378663, "Mean Q2": 9.761329259872436, "critic_loss": 0.021886394564062356, "batch_reward": 0.10126268196105957, "actor_loss": -10.070967208862305, "actor_target_entropy": -6.0, "actor_entropy": 8.100625881195068, "alpha_loss": 0.760747986316681, "alpha_value": 0.07793823804396242, "duration": 285.80411410331726, "step": 6500}
{"episode_reward": 62.30798002005558, "episode": 14.0, "Q1 loss": 0.008548502036370337, "Q2 loss": 0.008617088745348155, "Mean Target Q": 10.43163052558899, "Mean Q1": 10.431425163269044, "Mean Q2": 10.431434267044068, "critic_loss": 0.017165590757504106, "batch_reward": 0.1004731933325529, "actor_loss": -10.72928757095337, "actor_target_entropy": -6.0, "actor_entropy": 8.124930376052857, "alpha_loss": 0.7438354885578156, "alpha_value": 0.07617225373658348, "duration": 520.145156621933, "step": 7000}
{"episode_reward": 36.040188061744274, "episode": 15.0, "Q1 loss": 0.008730544689111412, "Q2 loss": 0.00883656953368336, "Mean Target Q": 11.085486877441406, "Mean Q1": 11.085296588897705, "Mean Q2": 11.085286432266235, "critic_loss": 0.017567114239558576, "batch_reward": 0.09838001412153244, "actor_loss": -11.385152538299561, "actor_target_entropy": -6.0, "actor_entropy": 8.123516674041747, "alpha_loss": 0.7262608966827393, "alpha_value": 0.07444985282723586, "duration": 566.5023381710052, "step": 7500}
{"episode_reward": 35.85554483970546, "episode": 16.0, "Q1 loss": 0.011644474402070046, "Q2 loss": 0.011784154910594225, "Mean Target Q": 11.752572519302369, "Mean Q1": 11.752286800384521, "Mean Q2": 11.752305423736573, "critic_loss": 0.023428629294037818, "batch_reward": 0.10018035337328911, "actor_loss": -12.037599521636963, "actor_target_entropy": -6.0, "actor_entropy": 8.093719871520996, "alpha_loss": 0.7079488184452057, "alpha_value": 0.07277076540617343, "duration": 443.75286531448364, "step": 8000}
{"episode_reward": 72.83545356562949, "episode": 17.0, "Q1 loss": 0.008970721968449653, "Q2 loss": 0.00901608799956739, "Mean Target Q": 12.347810369491578, "Mean Q1": 12.347691102981567, "Mean Q2": 12.347685125350953, "critic_loss": 0.017986809961497784, "batch_reward": 0.09990950655937195, "actor_loss": -12.62740958404541, "actor_target_entropy": -6.0, "actor_entropy": 8.114054536819458, "alpha_loss": 0.6905410151481628, "alpha_value": 0.07113568522246465, "duration": 445.37326312065125, "step": 8500}
{"episode_reward": 36.9590397406167, "episode": 18.0, "Q1 loss": 0.010945203277282416, "Q2 loss": 0.010994154121726751, "Mean Target Q": 12.902916994094848, "Mean Q1": 12.90268363571167, "Mean Q2": 12.902699369430541, "critic_loss": 0.021939357424154877, "batch_reward": 0.09855534377694129, "actor_loss": -13.18009928894043, "actor_target_entropy": -6.0, "actor_entropy": 8.09707508277893, "alpha_loss": 0.6725051863193512, "alpha_value": 0.06954160171415773, "duration": 475.2009119987488, "step": 9000}
{"episode_reward": 42.68760241344805, "episode": 19.0, "Q1 loss": 0.008954345696605743, "Q2 loss": 0.009055359862744809, "Mean Target Q": 13.43310304260254, "Mean Q1": 13.432979570388794, "Mean Q2": 13.43294513130188, "critic_loss": 0.01800970554538071, "batch_reward": 0.09770906428992748, "actor_loss": -13.707775081634521, "actor_target_entropy": -6.0, "actor_entropy": 8.088906898498536, "alpha_loss": 0.6557934889793396, "alpha_value": 0.06798748440995675, "duration": 408.2281422615051, "step": 9500}
{"episode_reward": 42.59875396030691, "episode": 20.0, "Q1 loss": 0.011372031942941249, "Q2 loss": 0.011502711718901992, "Mean Target Q": 13.915455631256103, "Mean Q1": 13.915224269866943, "Mean Q2": 13.915232173919678, "critic_loss": 0.02287474372982979, "batch_reward": 0.09757936699688434, "actor_loss": -14.182849891662597, "actor_target_entropy": -6.0, "actor_entropy": 8.08636321258545, "alpha_loss": 0.6410403647422791, "alpha_value": 0.066469321439419, "step": 10000}
{"duration": 556.0384886264801, "step": 10000}
{"episode_reward": 43.86328515064936, "episode": 21.0, "Q1 loss": 0.015488237823359669, "Q2 loss": 0.01567612703423947, "Mean Target Q": 14.39732049369812, "Mean Q1": 14.397142665863036, "Mean Q2": 14.397144748687744, "critic_loss": 0.031164364852011205, "batch_reward": 0.09810816368460655, "actor_loss": -14.655098434448242, "actor_target_entropy": -6.0, "actor_entropy": 8.094776473999023, "alpha_loss": 0.6240814185142517, "alpha_value": 0.06498660507849427, "duration": 415.2777111530304, "step": 10500}
{"episode_reward": 60.36552665488431, "episode": 22.0, "Q1 loss": 0.012058917523361742, "Q2 loss": 0.012180982172489167, "Mean Target Q": 14.82499102783203, "Mean Q1": 14.82480457496643, "Mean Q2": 14.824835500717164, "critic_loss": 0.024239899650216102, "batch_reward": 0.09858528053760529, "actor_loss": -15.07316457748413, "actor_target_entropy": -6.0, "actor_entropy": 8.092679363250733, "alpha_loss": 0.6082545206546783, "alpha_value": 0.06354115994600233, "duration": 223.44457054138184, "step": 11000}
{"episode_reward": 53.85039218307743, "episode": 23.0, "Q1 loss": 0.014362109377048909, "Q2 loss": 0.014465399698354304, "Mean Target Q": 15.23572772026062, "Mean Q1": 15.235516464233399, "Mean Q2": 15.235499320983887, "critic_loss": 0.028827509047463538, "batch_reward": 0.09859425497055053, "actor_loss": -15.480747619628906, "actor_target_entropy": -6.0, "actor_entropy": 8.072624507904052, "alpha_loss": 0.5924072153568268, "alpha_value": 0.06212989121150162, "duration": 402.45735812187195, "step": 11500}
{"episode_reward": 49.36057342320752, "episode": 24.0, "Q1 loss": 0.015807561505585908, "Q2 loss": 0.015963489601388575, "Mean Target Q": 15.627768405914306, "Mean Q1": 15.627538373947143, "Mean Q2": 15.627548109054565, "critic_loss": 0.03177105111069977, "batch_reward": 0.09874047538638114, "actor_loss": -15.874266090393066, "actor_target_entropy": -6.0, "actor_entropy": 8.066474557876587, "alpha_loss": 0.5770920438766479, "alpha_value": 0.06075303603607351, "duration": 470.6504702568054, "step": 12000}
{"episode_reward": 48.64920653782605, "episode": 25.0, "Q1 loss": 0.017208633782342077, "Q2 loss": 0.01736398467980325, "Mean Target Q": 15.989187063217162, "Mean Q1": 15.98899499130249, "Mean Q2": 15.988991950988769, "critic_loss": 0.0345726184733212, "batch_reward": 0.09889024344086647, "actor_loss": -16.233375091552734, "actor_target_entropy": -6.0, "actor_entropy": 8.047628828048706, "alpha_loss": 0.5624229526519775, "alpha_value": 0.05940663219860508, "duration": 203.0104684829712, "step": 12500}
{"episode_reward": 48.44001890548584, "episode": 26.0, "Q1 loss": 0.018228153456002472, "Q2 loss": 0.018547646194696427, "Mean Target Q": 16.339050355911255, "Mean Q1": 16.338742250442504, "Mean Q2": 16.338725761413574, "critic_loss": 0.036775799691677095, "batch_reward": 0.09861399166285992, "actor_loss": -16.580696014404296, "actor_target_entropy": -6.0, "actor_entropy": 8.0304955368042, "alpha_loss": 0.5462727265357972, "alpha_value": 0.05809545449471074, "duration": 208.82153511047363, "step": 13000}
{"episode_reward": 43.204764306064796, "episode": 27.0, "Q1 loss": 0.023622463285923004, "Q2 loss": 0.023860885813832285, "Mean Target Q": 16.651034954071044, "Mean Q1": 16.650868850708008, "Mean Q2": 16.650884239196778, "critic_loss": 0.04748334915563464, "batch_reward": 0.09797339624166489, "actor_loss": -16.886672004699708, "actor_target_entropy": -6.0, "actor_entropy": 8.031343349456787, "alpha_loss": 0.5340058915615081, "alpha_value": 0.056812542355411375, "duration": 223.61462020874023, "step": 13500}
{"episode_reward": 40.51669655941574, "episode": 28.0, "Q1 loss": 0.022897987570613624, "Q2 loss": 0.023361593106761575, "Mean Target Q": 16.923189365386964, "Mean Q1": 16.923132328033446, "Mean Q2": 16.923153903961182, "critic_loss": 0.046259580664336684, "batch_reward": 0.09747052523493767, "actor_loss": -17.14267024230957, "actor_target_entropy": -6.0, "actor_entropy": 8.047603851318359, "alpha_loss": 0.5234453366994858, "alpha_value": 0.055553704948607056, "duration": 209.25024390220642, "step": 14000}
{"episode_reward": 51.44146670276759, "episode": 29.0, "Q1 loss": 0.02936715065687895, "Q2 loss": 0.029593065762892366, "Mean Target Q": 17.235069622039795, "Mean Q1": 17.23479027557373, "Mean Q2": 17.23473149871826, "critic_loss": 0.058960216373205185, "batch_reward": 0.09898413822054863, "actor_loss": -17.466816093444823, "actor_target_entropy": -6.0, "actor_entropy": 8.020910739898682, "alpha_loss": 0.5122126661539078, "alpha_value": 0.054318079779853486, "duration": 217.66850757598877, "step": 14500}
{"episode_reward": 86.65992092108205, "episode": 30.0, "Q1 loss": 0.030318233815953135, "Q2 loss": 0.030403229139745237, "Mean Target Q": 17.55391561126709, "Mean Q1": 17.553715129852296, "Mean Q2": 17.553723922729493, "critic_loss": 0.060721462961286304, "batch_reward": 0.10275089801847935, "actor_loss": -17.76696144104004, "actor_target_entropy": -6.0, "actor_entropy": 8.02486845779419, "alpha_loss": 0.4998132047653198, "alpha_value": 0.05310997607255778, "step": 15000}
{"duration": 249.46461009979248, "step": 15000}
{"episode_reward": 117.41230128383047, "episode": 31.0, "Q1 loss": 0.02735419485345483, "Q2 loss": 0.02754984392412007, "Mean Target Q": 17.79010687637329, "Mean Q1": 17.789959705352782, "Mean Q2": 17.789935417175293, "critic_loss": 0.05490403881669045, "batch_reward": 0.10460341911017895, "actor_loss": -17.99224312591553, "actor_target_entropy": -6.0, "actor_entropy": 8.000228052139283, "alpha_loss": 0.48712564885616305, "alpha_value": 0.05192885637178723, "duration": 244.66748785972595, "step": 15500}
{"episode_reward": 41.69552182854997, "episode": 32.0, "Q1 loss": 0.05026915821060538, "Q2 loss": 0.05052327272668481, "Mean Target Q": 17.986947277069092, "Mean Q1": 17.98667895889282, "Mean Q2": 17.986690452575683, "critic_loss": 0.10079243105649949, "batch_reward": 0.10562178580462933, "actor_loss": -18.182776679992674, "actor_target_entropy": -6.0, "actor_entropy": 8.010656217575074, "alpha_loss": 0.4747617859840393, "alpha_value": 0.05077679834018261, "duration": 365.72223925590515, "step": 16000}
{"episode_reward": 96.8551489641298, "episode": 33.0, "Q1 loss": 0.03167323135212064, "Q2 loss": 0.031877801835536956, "Mean Target Q": 18.174235164642333, "Mean Q1": 18.17395276260376, "Mean Q2": 18.173933700561523, "critic_loss": 0.06355103339627385, "batch_reward": 0.10642131182551384, "actor_loss": -18.373998641967773, "actor_target_entropy": -6.0, "actor_entropy": 7.9983284740448, "alpha_loss": 0.46133678901195524, "alpha_value": 0.04965223405743862, "duration": 523.3060309886932, "step": 16500}
{"episode_reward": 43.73915297772856, "episode": 34.0, "Q1 loss": 0.025992092799395322, "Q2 loss": 0.026314398981630804, "Mean Target Q": 18.346238662719728, "Mean Q1": 18.34612172317505, "Mean Q2": 18.346136001586913, "critic_loss": 0.052306491695344445, "batch_reward": 0.10606684942543507, "actor_loss": -18.544125312805175, "actor_target_entropy": -6.0, "actor_entropy": 7.99390662574768, "alpha_loss": 0.44950736725330354, "alpha_value": 0.04855668327096875, "duration": 264.0563097000122, "step": 17000}
{"episode_reward": 44.01638188050136, "episode": 35.0, "Q1 loss": 0.026206785766407847, "Q2 loss": 0.02625892278365791, "Mean Target Q": 18.49857325363159, "Mean Q1": 18.498382884979247, "Mean Q2": 18.49839444732666, "critic_loss": 0.052465708512812854, "batch_reward": 0.10553561510145665, "actor_loss": -18.67270756530762, "actor_target_entropy": -6.0, "actor_entropy": 8.009249546051025, "alpha_loss": 0.4406369688510895, "alpha_value": 0.047481702411206375, "duration": 197.10232138633728, "step": 17500}
{"episode_reward": 40.96831193043181, "episode": 36.0, "Q1 loss": 0.027625589691102504, "Q2 loss": 0.027951658157631756, "Mean Target Q": 18.698120655059814, "Mean Q1": 18.697850337982178, "Mean Q2": 18.69786199951172, "critic_loss": 0.055577247712761166, "batch_reward": 0.10487349681556225, "actor_loss": -18.87931568145752, "actor_target_entropy": -6.0, "actor_entropy": 8.01505202102661, "alpha_loss": 0.4304756155014038, "alpha_value": 0.0464274330816416, "duration": 328.4793245792389, "step": 18000}
{"episode_reward": 61.46413663127294, "episode": 37.0, "Q1 loss": 0.043796112423762676, "Q2 loss": 0.04412348380498588, "Mean Target Q": 18.934930740356446, "Mean Q1": 18.93481410217285, "Mean Q2": 18.93477843093872, "critic_loss": 0.08791959638893604, "batch_reward": 0.10648353543877602, "actor_loss": -19.10657430267334, "actor_target_entropy": -6.0, "actor_entropy": 8.011817575454712, "alpha_loss": 0.418666840672493, "alpha_value": 0.04539817838420462, "duration": 230.19163966178894, "step": 18500}
{"episode_reward": 98.28860315880709, "episode": 38.0, "Q1 loss": 0.02541742954775691, "Q2 loss": 0.025577125931158663, "Mean Target Q": 19.162376094818114, "Mean Q1": 19.162156665802, "Mean Q2": 19.162169982910157, "critic_loss": 0.050994555432349445, "batch_reward": 0.10742033340036869, "actor_loss": -19.328806800842287, "actor_target_entropy": -6.0, "actor_entropy": 8.008617122650147, "alpha_loss": 0.40843127882480623, "alpha_value": 0.044393188478670874, "duration": 200.92806148529053, "step": 19000}
{"episode_reward": 45.86990692197212, "episode": 39.0, "Q1 loss": 0.02409824778325856, "Q2 loss": 0.024154871415346862, "Mean Target Q": 19.328902736663817, "Mean Q1": 19.32883689880371, "Mean Q2": 19.328855991363525, "critic_loss": 0.04825311926007271, "batch_reward": 0.10743322820961475, "actor_loss": -19.490940696716308, "actor_target_entropy": -6.0, "actor_entropy": 7.994263595581055, "alpha_loss": 0.3983540889024734, "alpha_value": 0.04341073019921246, "duration": 197.09024930000305, "step": 19500}
{"episode_reward": 55.8569889244535, "episode": 40.0, "Q1 loss": 0.02266164735518396, "Q2 loss": 0.0228110772613436, "Mean Target Q": 19.449360622406004, "Mean Q1": 19.44926315307617, "Mean Q2": 19.449228240966796, "critic_loss": 0.04547272472083569, "batch_reward": 0.10708553029596805, "actor_loss": -19.630494300842287, "actor_target_entropy": -6.0, "actor_entropy": 8.002328117370606, "alpha_loss": 0.38811863124370577, "alpha_value": 0.042450482972646746, "step": 20000}
{"duration": 267.88072657585144, "step": 20000}
{"episode_reward": 49.402744282105175, "episode": 41.0, "Q1 loss": 0.026671493953093886, "Q2 loss": 0.02682721378840506, "Mean Target Q": 19.59765693283081, "Mean Q1": 19.597304977416993, "Mean Q2": 19.597306716918947, "critic_loss": 0.05349870777875185, "batch_reward": 0.10685174584388733, "actor_loss": -19.760987869262696, "actor_target_entropy": -6.0, "actor_entropy": 7.9878641147613525, "alpha_loss": 0.37735017919540403, "alpha_value": 0.041512787070504625, "duration": 199.77056646347046, "step": 20500}
{"episode_reward": 43.95901280558674, "episode": 42.0, "Q1 loss": 0.02012657595798373, "Q2 loss": 0.020318510042503478, "Mean Target Q": 19.724858001708984, "Mean Q1": 19.724727840423583, "Mean Q2": 19.724735763549806, "critic_loss": 0.040445086065679786, "batch_reward": 0.10672386099398136, "actor_loss": -19.89289344024658, "actor_target_entropy": -6.0, "actor_entropy": 7.9889930076599125, "alpha_loss": 0.3669016908407211, "alpha_value": 0.04059930694582855, "duration": 182.86527943611145, "step": 21000}
{"episode_reward": 45.34491468873304, "episode": 43.0, "Q1 loss": 0.022151682564988732, "Q2 loss": 0.022343349339440464, "Mean Target Q": 19.854855041503907, "Mean Q1": 19.854660823822023, "Mean Q2": 19.854675338745118, "critic_loss": 0.04449503191933036, "batch_reward": 0.10651027762889861, "actor_loss": -20.01468344116211, "actor_target_entropy": -6.0, "actor_entropy": 7.9838006324768065, "alpha_loss": 0.3587540953159332, "alpha_value": 0.03970478046360053, "duration": 436.4694447517395, "step": 21500}
{"episode_reward": 52.43548566862835, "episode": 44.0, "Q1 loss": 0.03330677667073906, "Q2 loss": 0.03348454933986068, "Mean Target Q": 20.037902198791503, "Mean Q1": 20.037818687438964, "Mean Q2": 20.037791748046875, "critic_loss": 0.06679132591933012, "batch_reward": 0.1078510560542345, "actor_loss": -20.19190924835205, "actor_target_entropy": -6.0, "actor_entropy": 7.9714751739501954, "alpha_loss": 0.3502092410326004, "alpha_value": 0.03882744571350218, "duration": 607.876143693924, "step": 22000}
{"episode_reward": 84.80254828992686, "episode": 45.0, "Q1 loss": 0.02666628827340901, "Q2 loss": 0.02670646297559142, "Mean Target Q": 20.112682662963866, "Mean Q1": 20.11253088760376, "Mean Q2": 20.112541606903076, "critic_loss": 0.05337275115400553, "batch_reward": 0.10787132674455643, "actor_loss": -20.26104958343506, "actor_target_entropy": -6.0, "actor_entropy": 7.964497344970703, "alpha_loss": 0.34149074280261993, "alpha_value": 0.03796916043238201, "duration": 418.37691950798035, "step": 22500}
{"episode_reward": 47.82832486002152, "episode": 46.0, "Q1 loss": 0.0359403258562088, "Q2 loss": 0.03624229661375284, "Mean Target Q": 20.250784702301026, "Mean Q1": 20.25067596435547, "Mean Q2": 20.25066222000122, "critic_loss": 0.072182622410357, "batch_reward": 0.10833055506646633, "actor_loss": -20.39620443725586, "actor_target_entropy": -6.0, "actor_entropy": 7.951636253356933, "alpha_loss": 0.33284581065177915, "alpha_value": 0.037131047092979756, "duration": 539.2463276386261, "step": 23000}
{"episode_reward": 74.6570462156362, "episode": 47.0, "Q1 loss": 0.02929933035373688, "Q2 loss": 0.0293843388017267, "Mean Target Q": 20.343401443481444, "Mean Q1": 20.343174255371093, "Mean Q2": 20.34313967895508, "critic_loss": 0.05868366914615035, "batch_reward": 0.10838254183530807, "actor_loss": -20.496642097473146, "actor_target_entropy": -6.0, "actor_entropy": 7.965586126327515, "alpha_loss": 0.32576294910907744, "alpha_value": 0.036309513440481334, "duration": 440.12057876586914, "step": 23500}
{"episode_reward": 48.46350665166304, "episode": 48.0, "Q1 loss": 0.03126097632944584, "Q2 loss": 0.03133399175480008, "Mean Target Q": 20.402404304504394, "Mean Q1": 20.402126399993897, "Mean Q2": 20.402176120758057, "critic_loss": 0.06259496818482876, "batch_reward": 0.1086493609547615, "actor_loss": -20.55575562286377, "actor_target_entropy": -6.0, "actor_entropy": 7.9736730632781985, "alpha_loss": 0.31786869597434997, "alpha_value": 0.03550438895886058, "duration": 563.1374475955963, "step": 24000}
{"episode_reward": 66.88685921067898, "episode": 49.0, "Q1 loss": 0.030279063241556287, "Q2 loss": 0.030524932213127614, "Mean Target Q": 20.46970050048828, "Mean Q1": 20.469643623352052, "Mean Q2": 20.4695881690979, "critic_loss": 0.06080399553850293, "batch_reward": 0.10891814763844013, "actor_loss": -20.620602195739746, "actor_target_entropy": -6.0, "actor_entropy": 7.959067056655884, "alpha_loss": 0.31012366664409635, "alpha_value": 0.03471784453425405, "duration": 512.7298340797424, "step": 24500}
{"episode_reward": 62.4104262352742, "episode": 50.0, "Q1 loss": 0.025115446113049986, "Q2 loss": 0.02514222477003932, "Mean Target Q": 20.497788497924805, "Mean Q1": 20.497639377593995, "Mean Q2": 20.497697246551514, "critic_loss": 0.05025767089053988, "batch_reward": 0.10889060519635678, "actor_loss": -20.641924964904785, "actor_target_entropy": -6.0, "actor_entropy": 7.962341896057129, "alpha_loss": 0.30383848142623904, "alpha_value": 0.03394688648461449, "step": 25000}
{"duration": 621.8742668628693, "step": 25000}
{"episode_reward": 53.43805395366047, "episode": 51.0, "Q1 loss": 0.02666480475664139, "Q2 loss": 0.02698965742625296, "Mean Target Q": 20.545018592834474, "Mean Q1": 20.544882976531984, "Mean Q2": 20.544859066009522, "critic_loss": 0.05365446220338345, "batch_reward": 0.10973717483878136, "actor_loss": -20.690497276306154, "actor_target_entropy": -6.0, "actor_entropy": 7.952477891921997, "alpha_loss": 0.29634438240528105, "alpha_value": 0.033191906074972896, "duration": 421.9135982990265, "step": 25500}
{"episode_reward": 58.532708393581856, "episode": 52.0, "Q1 loss": 0.024860082790255547, "Q2 loss": 0.024894953075796367, "Mean Target Q": 20.587811122894287, "Mean Q1": 20.58779184341431, "Mean Q2": 20.587775192260743, "critic_loss": 0.04975503581389785, "batch_reward": 0.10973456113040447, "actor_loss": -20.723759605407714, "actor_target_entropy": -6.0, "actor_entropy": 7.933638343811035, "alpha_loss": 0.288307754278183, "alpha_value": 0.032455806081837825, "duration": 415.79947900772095, "step": 26000}
{"episode_reward": 58.125347888241, "episode": 53.0, "Q1 loss": 0.0401302430126816, "Q2 loss": 0.04022762905806303, "Mean Target Q": 20.679867164611817, "Mean Q1": 20.67972548675537, "Mean Q2": 20.679720924377442, "critic_loss": 0.08035787193849683, "batch_reward": 0.10966459763050079, "actor_loss": -20.81742910003662, "actor_target_entropy": -6.0, "actor_entropy": 7.9207958869934085, "alpha_loss": 0.2810710016489029, "alpha_value": 0.031737735721524364, "duration": 397.00663208961487, "step": 26500}
{"episode_reward": 87.2099739801128, "episode": 54.0, "Q1 loss": 0.03857755098491907, "Q2 loss": 0.0387476302459836, "Mean Target Q": 20.808328498840332, "Mean Q1": 20.808071479797363, "Mean Q2": 20.80804033279419, "critic_loss": 0.07732518118619919, "batch_reward": 0.11097709193825722, "actor_loss": -20.949421180725096, "actor_target_entropy": -6.0, "actor_entropy": 7.907893440246582, "alpha_loss": 0.27401528811454773, "alpha_value": 0.031033879686074704, "duration": 420.3852937221527, "step": 27000}
{"episode_reward": 69.64238963867777, "episode": 55.0, "Q1 loss": 0.028662744168192148, "Q2 loss": 0.028749201834201814, "Mean Target Q": 20.849724948883058, "Mean Q1": 20.849540920257567, "Mean Q2": 20.849592727661133, "critic_loss": 0.05741194602102041, "batch_reward": 0.11200150819122791, "actor_loss": -20.977737693786622, "actor_target_entropy": -6.0, "actor_entropy": 7.893274984359741, "alpha_loss": 0.2675352957248688, "alpha_value": 0.030348159845169153, "duration": 360.8877823352814, "step": 27500}
{"episode_reward": 68.98032318470356, "episode": 56.0, "Q1 loss": 0.024256103221327065, "Q2 loss": 0.024359563684090972, "Mean Target Q": 20.84185638809204, "Mean Q1": 20.841735321044922, "Mean Q2": 20.841691112518312, "critic_loss": 0.0486156668625772, "batch_reward": 0.11177854053676128, "actor_loss": -20.953673248291015, "actor_target_entropy": -6.0, "actor_entropy": 7.894918104171753, "alpha_loss": 0.2599171186685562, "alpha_value": 0.02967711749754197, "duration": 179.52174949645996, "step": 28000}
{"episode_reward": 61.9921931453982, "episode": 57.0, "Q1 loss": 0.0457905707731843, "Q2 loss": 0.04585296292603016, "Mean Target Q": 20.841657703399658, "Mean Q1": 20.84158237838745, "Mean Q2": 20.841587657928468, "critic_loss": 0.09164353361725808, "batch_reward": 0.11195333774387836, "actor_loss": -20.962919677734376, "actor_target_entropy": -6.0, "actor_entropy": 7.883656351089478, "alpha_loss": 0.2525579059123993, "alpha_value": 0.0290235116317394, "duration": 198.9409215450287, "step": 28500}
{"episode_reward": 59.27589585005384, "episode": 58.0, "Q1 loss": 0.044463628757745025, "Q2 loss": 0.04439394183829427, "Mean Target Q": 20.90040355682373, "Mean Q1": 20.900141036987304, "Mean Q2": 20.900158123016357, "critic_loss": 0.08885757079720497, "batch_reward": 0.11280026523768902, "actor_loss": -21.023324806213378, "actor_target_entropy": -6.0, "actor_entropy": 7.873258411407471, "alpha_loss": 0.2464346517920494, "alpha_value": 0.028383766880956587, "duration": 213.43867301940918, "step": 29000}
{"episode_reward": 81.78281047317967, "episode": 59.0, "Q1 loss": 0.03862559853494167, "Q2 loss": 0.03859852575883269, "Mean Target Q": 20.953756309509277, "Mean Q1": 20.95359808731079, "Mean Q2": 20.9535825920105, "critic_loss": 0.07722412431240082, "batch_reward": 0.11320437940955162, "actor_loss": -21.06836597442627, "actor_target_entropy": -6.0, "actor_entropy": 7.82893360710144, "alpha_loss": 0.23749215823411943, "alpha_value": 0.027762254054208818, "duration": 210.983717918396, "step": 29500}
{"episode_reward": 72.12294105504829, "episode": 60.0, "Q1 loss": 0.04047091705724597, "Q2 loss": 0.04070538604259491, "Mean Target Q": 20.97837363052368, "Mean Q1": 20.9780964012146, "Mean Q2": 20.9781580619812, "critic_loss": 0.08117630314826965, "batch_reward": 0.11442201861739158, "actor_loss": -21.08052967834473, "actor_target_entropy": -6.0, "actor_entropy": 7.847646881103516, "alpha_loss": 0.23073541951179505, "alpha_value": 0.02715672015787444, "step": 30000}
{"duration": 347.30750370025635, "step": 30000}
{"episode_reward": 89.5888196644134, "episode": 61.0, "Q1 loss": 0.04489939946681261, "Q2 loss": 0.04486250701546669, "Mean Target Q": 21.008214141845702, "Mean Q1": 21.008106037139893, "Mean Q2": 21.008030418395997, "critic_loss": 0.08976190634816884, "batch_reward": 0.11515251109004021, "actor_loss": -21.11250978088379, "actor_target_entropy": -6.0, "actor_entropy": 7.801273342132569, "alpha_loss": 0.2217959102988243, "alpha_value": 0.026568221586344733, "duration": 346.41090178489685, "step": 30500}
{"episode_reward": 105.880212073054, "episode": 62.0, "Q1 loss": 0.034781404376029966, "Q2 loss": 0.03469173070788383, "Mean Target Q": 21.001055057525633, "Mean Q1": 21.001007125854493, "Mean Q2": 21.001051280975343, "critic_loss": 0.06947313496470452, "batch_reward": 0.11633592183887959, "actor_loss": -21.115426109313965, "actor_target_entropy": -6.0, "actor_entropy": 7.789446001052856, "alpha_loss": 0.2155557930469513, "alpha_value": 0.02599584277186202, "duration": 320.3307406902313, "step": 31000}
{"episode_reward": 58.09280088407576, "episode": 63.0, "Q1 loss": 0.030587143056094647, "Q2 loss": 0.030564105488359927, "Mean Target Q": 20.92977890777588, "Mean Q1": 20.929667942047118, "Mean Q2": 20.929719650268556, "critic_loss": 0.061151248596608636, "batch_reward": 0.11565541636943817, "actor_loss": -21.03124464416504, "actor_target_entropy": -6.0, "actor_entropy": 7.7985665817260745, "alpha_loss": 0.2113966616988182, "alpha_value": 0.025431643850278438, "duration": 361.01822543144226, "step": 31500}
{"episode_reward": 61.43118227521295, "episode": 64.0, "Q1 loss": 0.03953804053738713, "Q2 loss": 0.03950881555303931, "Mean Target Q": 20.959608791351318, "Mean Q1": 20.959317646026612, "Mean Q2": 20.95929072189331, "critic_loss": 0.07904685624688863, "batch_reward": 0.11661423338949681, "actor_loss": -21.073184448242188, "actor_target_entropy": -6.0, "actor_entropy": 7.798449842453003, "alpha_loss": 0.20496826416254044, "alpha_value": 0.024877314558928967, "duration": 207.95518112182617, "step": 32000}
{"episode_reward": 91.90965069908644, "episode": 65.0, "Q1 loss": 0.04891784319281578, "Q2 loss": 0.048962234176695346, "Mean Target Q": 20.978373413085937, "Mean Q1": 20.978324409484863, "Mean Q2": 20.97828549194336, "critic_loss": 0.09788007718324661, "batch_reward": 0.11820911173522472, "actor_loss": -21.089526733398436, "actor_target_entropy": -6.0, "actor_entropy": 7.747047609329224, "alpha_loss": 0.19607307040691377, "alpha_value": 0.0243402627855517, "duration": 200.10635638237, "step": 32500}
{"episode_reward": 69.34473658715756, "episode": 66.0, "Q1 loss": 0.034976378079503774, "Q2 loss": 0.03491072936728597, "Mean Target Q": 20.960551223754884, "Mean Q1": 20.96037244796753, "Mean Q2": 20.96038232421875, "critic_loss": 0.06988710752874613, "batch_reward": 0.1182031562179327, "actor_loss": -21.085689834594728, "actor_target_entropy": -6.0, "actor_entropy": 7.720747659683227, "alpha_loss": 0.1895878282189369, "alpha_value": 0.023820356026158288, "duration": 233.6844937801361, "step": 33000}
{"episode_reward": 81.13906582047449, "episode": 67.0, "Q1 loss": 0.02924787548184395, "Q2 loss": 0.029335939157754183, "Mean Target Q": 20.945584896087645, "Mean Q1": 20.94543293762207, "Mean Q2": 20.945428672790527, "critic_loss": 0.05858381464332342, "batch_reward": 0.11859943203628064, "actor_loss": -21.05208741760254, "actor_target_entropy": -6.0, "actor_entropy": 7.683318756103516, "alpha_loss": 0.18287675601243972, "alpha_value": 0.02331252844006447, "duration": 185.94502925872803, "step": 33500}
{"episode_reward": 72.44917552297018, "episode": 68.0, "Q1 loss": 0.034377855025231836, "Q2 loss": 0.03434859324619174, "Mean Target Q": 20.94794018173218, "Mean Q1": 20.947761562347413, "Mean Q2": 20.947748359680176, "critic_loss": 0.06872644831985235, "batch_reward": 0.11860537897050381, "actor_loss": -21.069951721191405, "actor_target_entropy": -6.0, "actor_entropy": 7.65632011795044, "alpha_loss": 0.1769577045440674, "alpha_value": 0.02281616103083035, "duration": 294.5194194316864, "step": 34000}
{"episode_reward": 68.35029768192891, "episode": 69.0, "Q1 loss": 0.033182690668851135, "Q2 loss": 0.03319802974537015, "Mean Target Q": 20.93871748352051, "Mean Q1": 20.938662643432618, "Mean Q2": 20.938643844604492, "critic_loss": 0.06638072035461665, "batch_reward": 0.11907957053184509, "actor_loss": -21.05424036407471, "actor_target_entropy": -6.0, "actor_entropy": 7.631331874847412, "alpha_loss": 0.17154223692417145, "alpha_value": 0.02232993164488291, "duration": 285.9046368598938, "step": 34500}
{"episode_reward": 68.26246826401905, "episode": 70.0, "Q1 loss": 0.04461279956251383, "Q2 loss": 0.044796621654182675, "Mean Target Q": 20.968449192047117, "Mean Q1": 20.968447246551513, "Mean Q2": 20.9684020690918, "critic_loss": 0.08940942126512527, "batch_reward": 0.11971513056755066, "actor_loss": -21.070663162231444, "actor_target_entropy": -6.0, "actor_entropy": 7.602579912185669, "alpha_loss": 0.1659220243692398, "alpha_value": 0.02185485166164588, "step": 35000}
{"duration": 256.55627036094666, "step": 35000}
{"episode_reward": 92.18773444447211, "episode": 71.0, "Q1 loss": 0.03984842057153583, "Q2 loss": 0.03987669480964542, "Mean Target Q": 20.96895722579956, "Mean Q1": 20.968857879638673, "Mean Q2": 20.968846752166748, "critic_loss": 0.0797251154333353, "batch_reward": 0.11981522299349308, "actor_loss": -21.07292808532715, "actor_target_entropy": -6.0, "actor_entropy": 7.586713647842407, "alpha_loss": 0.16091445749998093, "alpha_value": 0.021388876947213895, "duration": 197.01328229904175, "step": 35500}
{"episode_reward": 61.470689112544555, "episode": 72.0, "Q1 loss": 0.03236928053945303, "Q2 loss": 0.03248815688490868, "Mean Target Q": 20.965074115753175, "Mean Q1": 20.964830432891844, "Mean Q2": 20.964870880126952, "critic_loss": 0.06485743740200997, "batch_reward": 0.12086050064861774, "actor_loss": -21.08048286437988, "actor_target_entropy": -6.0, "actor_entropy": 7.513153472900391, "alpha_loss": 0.15268127489089967, "alpha_value": 0.02093529880565546, "duration": 212.52300477027893, "step": 36000}
{"episode_reward": 76.70522892128056, "episode": 73.0, "Q1 loss": 0.03680757504701614, "Q2 loss": 0.03676240435615182, "Mean Target Q": 20.956779914855957, "Mean Q1": 20.956472640991212, "Mean Q2": 20.956464569091796, "critic_loss": 0.073569979198277, "batch_reward": 0.12078105886280537, "actor_loss": -21.064779823303223, "actor_target_entropy": -6.0, "actor_entropy": 7.444817966461182, "alpha_loss": 0.1456679450273514, "alpha_value": 0.020501021638168467, "duration": 226.61043334007263, "step": 36500}
{"episode_reward": 75.32639163533587, "episode": 74.0, "Q1 loss": 0.036598678555339575, "Q2 loss": 0.03648730976879597, "Mean Target Q": 20.99149089431763, "Mean Q1": 20.99152061843872, "Mean Q2": 20.9914889793396, "critic_loss": 0.07308598834276199, "batch_reward": 0.12179113620519638, "actor_loss": -21.105664169311524, "actor_target_entropy": -6.0, "actor_entropy": 7.4094945945739745, "alpha_loss": 0.1395307132601738, "alpha_value": 0.020077848639599168, "duration": 201.08834290504456, "step": 37000}
{"episode_reward": 92.36987310055999, "episode": 75.0, "Q1 loss": 0.03726696456223726, "Q2 loss": 0.03731009493768215, "Mean Target Q": 21.01282532501221, "Mean Q1": 21.012690662384035, "Mean Q2": 21.01267984008789, "critic_loss": 0.07457705973833799, "batch_reward": 0.12190294276177883, "actor_loss": -21.13534757232666, "actor_target_entropy": -6.0, "actor_entropy": 7.39294102859497, "alpha_loss": 0.1351864255666733, "alpha_value": 0.01966226671075727, "duration": 190.91069054603577, "step": 37500}
{"episode_reward": 88.79335216703701, "episode": 76.0, "Q1 loss": 0.05614725882932544, "Q2 loss": 0.055957929771393536, "Mean Target Q": 21.07097648239136, "Mean Q1": 21.070941246032714, "Mean Q2": 21.070951343536375, "critic_loss": 0.11210518874973059, "batch_reward": 0.124359475299716, "actor_loss": -21.17947509765625, "actor_target_entropy": -6.0, "actor_entropy": 7.387615440368652, "alpha_loss": 0.13125866624712945, "alpha_value": 0.019253464518428316, "duration": 196.1961452960968, "step": 38000}
{"episode_reward": 136.37497059834047, "episode": 77.0, "Q1 loss": 0.05750928178429603, "Q2 loss": 0.05744477730244398, "Mean Target Q": 21.0419104385376, "Mean Q1": 21.041728527069093, "Mean Q2": 21.041722358703613, "critic_loss": 0.11495405870676041, "batch_reward": 0.12616644282639028, "actor_loss": -21.166195892333985, "actor_target_entropy": -6.0, "actor_entropy": 7.363638128280639, "alpha_loss": 0.12631351825594903, "alpha_value": 0.018851024888590542, "duration": 221.4798355102539, "step": 38500}
{"episode_reward": 138.99600392424094, "episode": 78.0, "Q1 loss": 0.0555264997407794, "Q2 loss": 0.05549742748215795, "Mean Target Q": 20.964499950408936, "Mean Q1": 20.964369552612304, "Mean Q2": 20.964341777801515, "critic_loss": 0.11102392747998238, "batch_reward": 0.1270633732229471, "actor_loss": -21.087437927246093, "actor_target_entropy": -6.0, "actor_entropy": 7.329517391204834, "alpha_loss": 0.12121347740292548, "alpha_value": 0.018459227347695895, "duration": 241.73353457450867, "step": 39000}
{"episode_reward": 79.23637948466613, "episode": 79.0, "Q1 loss": 0.06731203218176961, "Q2 loss": 0.06727604881674051, "Mean Target Q": 20.879286228179932, "Mean Q1": 20.879066505432128, "Mean Q2": 20.8791064453125, "critic_loss": 0.1345880808085203, "batch_reward": 0.12768492238223553, "actor_loss": -21.006029640197752, "actor_target_entropy": -6.0, "actor_entropy": 7.372028020858765, "alpha_loss": 0.1177820834517479, "alpha_value": 0.018076263205978303, "duration": 340.24756145477295, "step": 39500}
{"episode_reward": 69.6552146019551, "episode": 80.0, "Q1 loss": 0.08994504088908434, "Q2 loss": 0.09030173449218273, "Mean Target Q": 20.83841651916504, "Mean Q1": 20.838008415222166, "Mean Q2": 20.838007877349852, "critic_loss": 0.18024677509069442, "batch_reward": 0.1275687879025936, "actor_loss": -20.940664360046387, "actor_target_entropy": -6.0, "actor_entropy": 7.3251467685699465, "alpha_loss": 0.11247868683934212, "alpha_value": 0.01769958747386151, "step": 40000}
{"duration": 376.38922119140625, "step": 40000}
{"episode_reward": 99.66816601327677, "episode": 81.0, "Q1 loss": 0.09986162380129099, "Q2 loss": 0.10011071769893169, "Mean Target Q": 20.919098766326904, "Mean Q1": 20.919103542327882, "Mean Q2": 20.919092483520508, "critic_loss": 0.1999723415374756, "batch_reward": 0.12877356153726577, "actor_loss": -21.038808738708497, "actor_target_entropy": -6.0, "actor_entropy": 7.30003851890564, "alpha_loss": 0.10736983466148377, "alpha_value": 0.01733405879979887, "duration": 186.7415075302124, "step": 40500}
{"episode_reward": 93.62923737537865, "episode": 82.0, "Q1 loss": 0.08205453408509493, "Q2 loss": 0.0817647038474679, "Mean Target Q": 20.921035640716553, "Mean Q1": 20.92123034667969, "Mean Q2": 20.921244812011718, "critic_loss": 0.16381923785805702, "batch_reward": 0.1294195544719696, "actor_loss": -21.04916300201416, "actor_target_entropy": -6.0, "actor_entropy": 7.2509354324340825, "alpha_loss": 0.10237740686535836, "alpha_value": 0.016979812371400862, "duration": 238.72590279579163, "step": 41000}
{"episode_reward": 84.04598693827673, "episode": 83.0, "Q1 loss": 0.10004986748099327, "Q2 loss": 0.10007216779142618, "Mean Target Q": 20.883253520965575, "Mean Q1": 20.88278658294678, "Mean Q2": 20.882822856903076, "critic_loss": 0.20012203548848628, "batch_reward": 0.1290279586315155, "actor_loss": -21.00330502319336, "actor_target_entropy": -6.0, "actor_entropy": 7.223894386291504, "alpha_loss": 0.09735464826226234, "alpha_value": 0.01663566576014401, "duration": 335.05655455589294, "step": 41500}
{"episode_reward": 77.0323028372138, "episode": 84.0, "Q1 loss": 0.11554066681116819, "Q2 loss": 0.1153258052766323, "Mean Target Q": 20.860597469329836, "Mean Q1": 20.860530620574952, "Mean Q2": 20.86051782989502, "critic_loss": 0.23086647209525107, "batch_reward": 0.12991528038680553, "actor_loss": -20.983639465332033, "actor_target_entropy": -6.0, "actor_entropy": 7.252729509353638, "alpha_loss": 0.09619806843996048, "alpha_value": 0.016296273161188368, "duration": 206.56240963935852, "step": 42000}
{"episode_reward": 101.36454916148992, "episode": 85.0, "Q1 loss": 0.11431072246283293, "Q2 loss": 0.11486522931605578, "Mean Target Q": 20.90872531890869, "Mean Q1": 20.90859408187866, "Mean Q2": 20.908561767578124, "critic_loss": 0.22917595171928407, "batch_reward": 0.13086769729852676, "actor_loss": -21.0239359664917, "actor_target_entropy": -6.0, "actor_entropy": 7.272935825347901, "alpha_loss": 0.09574275743961334, "alpha_value": 0.01595163365221545, "duration": 205.9807767868042, "step": 42500}
{"episode_reward": 70.5682856276176, "episode": 86.0, "Q1 loss": 0.12239771278202534, "Q2 loss": 0.12283139643073082, "Mean Target Q": 20.892686809539796, "Mean Q1": 20.89235241699219, "Mean Q2": 20.892335563659667, "critic_loss": 0.24522910878062248, "batch_reward": 0.13095816695690154, "actor_loss": -21.033346321105956, "actor_target_entropy": -6.0, "actor_entropy": 7.215341856002808, "alpha_loss": 0.09014913380146027, "alpha_value": 0.015615554533094152, "duration": 196.73010325431824, "step": 43000}
{"episode_reward": 89.94914793681626, "episode": 87.0, "Q1 loss": 0.09650205881893635, "Q2 loss": 0.0969334665313363, "Mean Target Q": 20.86759900665283, "Mean Q1": 20.867706493377685, "Mean Q2": 20.867712959289552, "critic_loss": 0.1934355252236128, "batch_reward": 0.131474339812994, "actor_loss": -20.980502395629884, "actor_target_entropy": -6.0, "actor_entropy": 7.189946552276611, "alpha_loss": 0.08698012140393258, "alpha_value": 0.015290227205544448, "duration": 202.58264017105103, "step": 43500}
{"episode_reward": 83.75264505810084, "episode": 88.0, "Q1 loss": 0.09636921535432338, "Q2 loss": 0.09658310668170453, "Mean Target Q": 20.802088581085204, "Mean Q1": 20.801904411315917, "Mean Q2": 20.801927394866944, "critic_loss": 0.1929523218870163, "batch_reward": 0.1319177588969469, "actor_loss": -20.917737533569337, "actor_target_entropy": -6.0, "actor_entropy": 7.135362596511841, "alpha_loss": 0.08174843418598175, "alpha_value": 0.014974016440011508, "duration": 311.9944567680359, "step": 44000}
{"episode_reward": 97.10929622327276, "episode": 89.0, "Q1 loss": 0.08824942252039909, "Q2 loss": 0.08857995369285344, "Mean Target Q": 20.90245048904419, "Mean Q1": 20.902386463165282, "Mean Q2": 20.90240071487427, "critic_loss": 0.17682937602698803, "batch_reward": 0.13339310047030448, "actor_loss": -20.99829598236084, "actor_target_entropy": -6.0, "actor_entropy": 7.049533203125, "alpha_loss": 0.07628585919737815, "alpha_value": 0.014675464031724214, "duration": 431.05166840553284, "step": 44500}
{"episode_reward": 115.43302485099873, "episode": 90.0, "Q1 loss": 0.09582222370803356, "Q2 loss": 0.09586609583348035, "Mean Target Q": 20.946307834625244, "Mean Q1": 20.946359340667726, "Mean Q2": 20.946400547027586, "critic_loss": 0.1916883192062378, "batch_reward": 0.13367973259091379, "actor_loss": -21.06115982055664, "actor_target_entropy": -6.0, "actor_entropy": 7.015880146026611, "alpha_loss": 0.0725819367915392, "alpha_value": 0.014384918409290615, "step": 45000}
{"duration": 500.31040501594543, "step": 45000}
{"episode_reward": 95.88373908327473, "episode": 91.0, "Q1 loss": 0.10236091323941945, "Q2 loss": 0.10286884352564812, "Mean Target Q": 20.987728481292724, "Mean Q1": 20.987497085571288, "Mean Q2": 20.987522132873536, "critic_loss": 0.2052297564893961, "batch_reward": 0.13497103817760944, "actor_loss": -21.10224577331543, "actor_target_entropy": -6.0, "actor_entropy": 6.983416284561157, "alpha_loss": 0.06971669597923756, "alpha_value": 0.014101120486491753, "duration": 432.8728678226471, "step": 45500}
{"episode_reward": 138.4716687322016, "episode": 92.0, "Q1 loss": 0.11087523435801268, "Q2 loss": 0.11146051061153411, "Mean Target Q": 21.048776023864747, "Mean Q1": 21.048622745513917, "Mean Q2": 21.048636737823486, "critic_loss": 0.2223357445448637, "batch_reward": 0.1358199980854988, "actor_loss": -21.1739997177124, "actor_target_entropy": -6.0, "actor_entropy": 7.000469825744629, "alpha_loss": 0.06898524092137813, "alpha_value": 0.013816753064301147, "duration": 206.40922141075134, "step": 46000}
{"episode_reward": 90.36326591092798, "episode": 93.0, "Q1 loss": 0.10432978572696447, "Q2 loss": 0.1045537680014968, "Mean Target Q": 21.11058480834961, "Mean Q1": 21.110714836120607, "Mean Q2": 21.110709732055664, "critic_loss": 0.2088835536390543, "batch_reward": 0.13672497613728046, "actor_loss": -21.22509162902832, "actor_target_entropy": -6.0, "actor_entropy": 7.005348638534546, "alpha_loss": 0.06746837924420833, "alpha_value": 0.013532014445295152, "duration": 289.78156542778015, "step": 46500}
{"episode_reward": 63.345710226194164, "episode": 94.0, "Q1 loss": 0.11845440275222063, "Q2 loss": 0.11962184906750918, "Mean Target Q": 21.195436107635498, "Mean Q1": 21.19519383239746, "Mean Q2": 21.195171619415284, "critic_loss": 0.23807625178992747, "batch_reward": 0.13665076410770416, "actor_loss": -21.3122211227417, "actor_target_entropy": -6.0, "actor_entropy": 6.9897121334075925, "alpha_loss": 0.06429976937174797, "alpha_value": 0.013253168759047028, "duration": 441.19523215293884, "step": 47000}
{"episode_reward": 93.38587543009693, "episode": 95.0, "Q1 loss": 0.1621883123219013, "Q2 loss": 0.16240817216038703, "Mean Target Q": 21.28662459564209, "Mean Q1": 21.286574577331542, "Mean Q2": 21.28661078643799, "critic_loss": 0.3245964846163988, "batch_reward": 0.13684600971639158, "actor_loss": -21.40971251678467, "actor_target_entropy": -6.0, "actor_entropy": 7.013395528793335, "alpha_loss": 0.06264822134375572, "alpha_value": 0.0129796442205709, "duration": 412.7216110229492, "step": 47500}
{"episode_reward": 83.7989562988087, "episode": 96.0, "Q1 loss": 0.14917578894644976, "Q2 loss": 0.14910992360115052, "Mean Target Q": 21.444867427825926, "Mean Q1": 21.44487618637085, "Mean Q2": 21.444870281219483, "critic_loss": 0.29828571221232414, "batch_reward": 0.13738527581095694, "actor_loss": -21.55772782897949, "actor_target_entropy": -6.0, "actor_entropy": 6.985649433135986, "alpha_loss": 0.05973146222531796, "alpha_value": 0.012708521066123961, "duration": 489.42853331565857, "step": 48000}
{"episode_reward": 91.24705326742976, "episode": 97.0, "Q1 loss": 0.16273455885797738, "Q2 loss": 0.1636662207171321, "Mean Target Q": 21.528859268188477, "Mean Q1": 21.528665439605714, "Mean Q2": 21.528684852600097, "critic_loss": 0.32640077820420266, "batch_reward": 0.13733757458627224, "actor_loss": -21.651261894226074, "actor_target_entropy": -6.0, "actor_entropy": 6.9436010665893555, "alpha_loss": 0.05634953771531582, "alpha_value": 0.01245297504176704, "duration": 574.1686761379242, "step": 48500}
{"episode_reward": 79.6700325843136, "episode": 98.0, "Q1 loss": 0.144037391833961, "Q2 loss": 0.14436680042743683, "Mean Target Q": 21.600357704162597, "Mean Q1": 21.60043522644043, "Mean Q2": 21.600427268981935, "critic_loss": 0.2884041922986507, "batch_reward": 0.1376296956241131, "actor_loss": -21.717835762023928, "actor_target_entropy": -6.0, "actor_entropy": 6.938370544433594, "alpha_loss": 0.05460179102420807, "alpha_value": 0.012197871720716135, "duration": 363.3086597919464, "step": 49000}
{"episode_reward": 104.48928360537569, "episode": 99.0, "Q1 loss": 0.13537697062641382, "Q2 loss": 0.1359519875496626, "Mean Target Q": 21.5814291305542, "Mean Q1": 21.581380268096925, "Mean Q2": 21.581402324676514, "critic_loss": 0.27132895804941654, "batch_reward": 0.1383017247915268, "actor_loss": -21.706620277404785, "actor_target_entropy": -6.0, "actor_entropy": 6.890884670257568, "alpha_loss": 0.051624939903616905, "alpha_value": 0.011951239259629553, "duration": 450.62215185165405, "step": 49500}
{"episode_reward": 91.91797969010706, "episode": 100.0, "Q1 loss": 0.13621257342398166, "Q2 loss": 0.13556250666081907, "Mean Target Q": 21.543506656646727, "Mean Q1": 21.543426788330077, "Mean Q2": 21.54346630859375, "critic_loss": 0.2717750809192657, "batch_reward": 0.13859098406136036, "actor_loss": -21.66921671295166, "actor_target_entropy": -6.0, "actor_entropy": 6.887882488250733, "alpha_loss": 0.05022674375772476, "alpha_value": 0.011708627797976833, "step": 50000}
{"duration": 523.7420423030853, "step": 50000}
{"episode_reward": 77.75501658117877, "episode": 101.0, "Q1 loss": 0.144109771206975, "Q2 loss": 0.14477691780030727, "Mean Target Q": 21.524886241912842, "Mean Q1": 21.524931846618653, "Mean Q2": 21.524868141174316, "critic_loss": 0.2888866889476776, "batch_reward": 0.13906166020035743, "actor_loss": -21.63836427307129, "actor_target_entropy": -6.0, "actor_entropy": 6.878069723129273, "alpha_loss": 0.04737912073731423, "alpha_value": 0.011470627743700064, "duration": 360.06165313720703, "step": 50500}
{"episode_reward": 79.41163157623215, "episode": 102.0, "Q1 loss": 0.14594245901703834, "Q2 loss": 0.14624155160784721, "Mean Target Q": 21.52976820755005, "Mean Q1": 21.529667873382568, "Mean Q2": 21.529630458831786, "critic_loss": 0.2921840102672577, "batch_reward": 0.1393584168255329, "actor_loss": -21.66231022644043, "actor_target_entropy": -6.0, "actor_entropy": 6.757537591934204, "alpha_loss": 0.042182224556803705, "alpha_value": 0.011250508826102765, "duration": 537.2145178318024, "step": 51000}
{"episode_reward": 86.26453540777881, "episode": 103.0, "Q1 loss": 0.17054215806722642, "Q2 loss": 0.17118802799284458, "Mean Target Q": 21.471191349029542, "Mean Q1": 21.471132266998293, "Mean Q2": 21.471166316986086, "critic_loss": 0.34173018610477446, "batch_reward": 0.13985169488191604, "actor_loss": -21.602180038452147, "actor_target_entropy": -6.0, "actor_entropy": 6.739928478240967, "alpha_loss": 0.04023455880582333, "alpha_value": 0.011039163453680462, "duration": 316.4825596809387, "step": 51500}
{"episode_reward": 110.25971624539366, "episode": 104.0, "Q1 loss": 0.19561931848526, "Q2 loss": 0.1955607981979847, "Mean Target Q": 21.52363278579712, "Mean Q1": 21.523324180603026, "Mean Q2": 21.523311965942383, "critic_loss": 0.3911801162660122, "batch_reward": 0.14014929835498333, "actor_loss": -21.666134460449218, "actor_target_entropy": -6.0, "actor_entropy": 6.673846563339233, "alpha_loss": 0.03685597337782383, "alpha_value": 0.010834128033043306, "duration": 205.04374814033508, "step": 52000}
{"episode_reward": 93.90774281548575, "episode": 105.0, "Q1 loss": 0.22438755832612514, "Q2 loss": 0.2248862506300211, "Mean Target Q": 21.46921597290039, "Mean Q1": 21.46967170715332, "Mean Q2": 21.469591136932372, "critic_loss": 0.44927380841970443, "batch_reward": 0.1403239116668701, "actor_loss": -21.584655151367187, "actor_target_entropy": -6.0, "actor_entropy": 6.682941663742065, "alpha_loss": 0.03552740851789713, "alpha_value": 0.010635353534644966, "duration": 224.02233743667603, "step": 52500}
{"episode_reward": 83.60288682491158, "episode": 106.0, "Q1 loss": 0.18880977554619313, "Q2 loss": 0.18964228026568888, "Mean Target Q": 21.406069107055664, "Mean Q1": 21.40589814376831, "Mean Q2": 21.40592300796509, "critic_loss": 0.37845205774903296, "batch_reward": 0.14112214894592762, "actor_loss": -21.533397705078126, "actor_target_entropy": -6.0, "actor_entropy": 6.660459962844849, "alpha_loss": 0.034494510889053344, "alpha_value": 0.010435325654631926, "duration": 336.9662981033325, "step": 53000}
{"episode_reward": 94.58381086534847, "episode": 107.0, "Q1 loss": 0.1710456321835518, "Q2 loss": 0.17052614353597165, "Mean Target Q": 21.418541900634764, "Mean Q1": 21.418439640045165, "Mean Q2": 21.418492782592775, "critic_loss": 0.34157177519798276, "batch_reward": 0.14228367528319358, "actor_loss": -21.546635704040526, "actor_target_entropy": -6.0, "actor_entropy": 6.614003702163696, "alpha_loss": 0.032199610553681854, "alpha_value": 0.010238416089020125, "duration": 514.2760272026062, "step": 53500}
{"episode_reward": 101.3782812618208, "episode": 108.0, "Q1 loss": 0.17768325577676297, "Q2 loss": 0.17792539818584918, "Mean Target Q": 21.45066435623169, "Mean Q1": 21.45083115386963, "Mean Q2": 21.45079658126831, "critic_loss": 0.3556086544692516, "batch_reward": 0.1421184591948986, "actor_loss": -21.573075218200685, "actor_target_entropy": -6.0, "actor_entropy": 6.612545289993286, "alpha_loss": 0.030467861749231814, "alpha_value": 0.010049850181166078, "duration": 496.7534511089325, "step": 54000}
{"episode_reward": 103.35028921562963, "episode": 109.0, "Q1 loss": 0.17780778488516807, "Q2 loss": 0.17777962619066237, "Mean Target Q": 21.414409046173095, "Mean Q1": 21.414513305664062, "Mean Q2": 21.414575481414794, "critic_loss": 0.3555874121487141, "batch_reward": 0.14312192870676518, "actor_loss": -21.516416954040526, "actor_target_entropy": -6.0, "actor_entropy": 6.608298343658447, "alpha_loss": 0.03017339349538088, "alpha_value": 0.009855788799174535, "duration": 482.20163464546204, "step": 54500}
{"episode_reward": 81.67852785218591, "episode": 110.0, "Q1 loss": 0.1751503407806158, "Q2 loss": 0.17505064308643342, "Mean Target Q": 21.365689544677736, "Mean Q1": 21.365894702911376, "Mean Q2": 21.365911964416505, "critic_loss": 0.3502009837627411, "batch_reward": 0.14222745110094548, "actor_loss": -21.474102554321288, "actor_target_entropy": -6.0, "actor_entropy": 6.599273256301879, "alpha_loss": 0.028572395920753477, "alpha_value": 0.009666435115834746, "step": 55000}
{"duration": 463.713009595871, "step": 55000}
{"episode_reward": 97.32037787549558, "episode": 111.0, "Q1 loss": 0.20553501249849795, "Q2 loss": 0.20539199098944663, "Mean Target Q": 21.32956698989868, "Mean Q1": 21.32920421218872, "Mean Q2": 21.329199577331543, "critic_loss": 0.4109270028471947, "batch_reward": 0.14366666978597642, "actor_loss": -21.44522085571289, "actor_target_entropy": -6.0, "actor_entropy": 6.54946992301941, "alpha_loss": 0.026833046779036522, "alpha_value": 0.009482058358701953, "duration": 418.2769284248352, "step": 55500}
{"episode_reward": 100.0741299371481, "episode": 112.0, "Q1 loss": 0.25593635968863965, "Q2 loss": 0.25535568423569205, "Mean Target Q": 21.33668935394287, "Mean Q1": 21.33630902862549, "Mean Q2": 21.336264808654786, "critic_loss": 0.5112920439839364, "batch_reward": 0.14418650813400746, "actor_loss": -21.452684089660643, "actor_target_entropy": -6.0, "actor_entropy": 6.578595157623291, "alpha_loss": 0.025791564077138902, "alpha_value": 0.009297112713036383, "duration": 432.43953013420105, "step": 56000}
{"episode_reward": 75.81905851186063, "episode": 113.0, "Q1 loss": 0.2198569139689207, "Q2 loss": 0.22071102529764175, "Mean Target Q": 21.410034114837647, "Mean Q1": 21.410197074890135, "Mean Q2": 21.41019729232788, "critic_loss": 0.44056793904304503, "batch_reward": 0.14388816246390343, "actor_loss": -21.521678100585937, "actor_target_entropy": -6.0, "actor_entropy": 6.542762619018554, "alpha_loss": 0.023865270145237445, "alpha_value": 0.009122914145819854, "duration": 508.2072021961212, "step": 56500}
{"episode_reward": 77.89522024253449, "episode": 114.0, "Q1 loss": 0.2132269369661808, "Q2 loss": 0.2141708181500435, "Mean Target Q": 21.44895401763916, "Mean Q1": 21.449051776885987, "Mean Q2": 21.449031372070312, "critic_loss": 0.4273977548182011, "batch_reward": 0.14374529246985912, "actor_loss": -21.567750778198242, "actor_target_entropy": -6.0, "actor_entropy": 6.572223440170288, "alpha_loss": 0.0233455225341022, "alpha_value": 0.008949022135422171, "duration": 509.4532141685486, "step": 57000}
{"episode_reward": 102.83551127598388, "episode": 115.0, "Q1 loss": 0.21817684215307237, "Q2 loss": 0.21731487990915777, "Mean Target Q": 21.502368919372557, "Mean Q1": 21.502556995391846, "Mean Q2": 21.50251277923584, "critic_loss": 0.43549172300100325, "batch_reward": 0.1451617521494627, "actor_loss": -21.62773848724365, "actor_target_entropy": -6.0, "actor_entropy": 6.507527332305909, "alpha_loss": 0.020704932298511267, "alpha_value": 0.008782516137499457, "duration": 500.817421913147, "step": 57500}
{"episode_reward": 80.18263623423678, "episode": 116.0, "Q1 loss": 0.2671287748217583, "Q2 loss": 0.26612824234366417, "Mean Target Q": 21.49627970123291, "Mean Q1": 21.495824268341064, "Mean Q2": 21.49590891647339, "critic_loss": 0.533257015824318, "batch_reward": 0.14477360478043555, "actor_loss": -21.63040673828125, "actor_target_entropy": -6.0, "actor_entropy": 6.516441738128662, "alpha_loss": 0.018891642697155476, "alpha_value": 0.008625190764463397, "duration": 554.4936573505402, "step": 58000}
{"episode_reward": 79.32647333530316, "episode": 117.0, "Q1 loss": 0.28042535181343553, "Q2 loss": 0.2803463655859232, "Mean Target Q": 21.581275131225585, "Mean Q1": 21.58119808959961, "Mean Q2": 21.58115494918823, "critic_loss": 0.5607717197537422, "batch_reward": 0.14464698393642902, "actor_loss": -21.693511260986327, "actor_target_entropy": -6.0, "actor_entropy": 6.496765748977661, "alpha_loss": 0.019441783897578717, "alpha_value": 0.008469568999614084, "duration": 560.9856867790222, "step": 58500}
{"episode_reward": 98.41012575289389, "episode": 118.0, "Q1 loss": 0.24109946358203888, "Q2 loss": 0.2410298379510641, "Mean Target Q": 21.574009826660156, "Mean Q1": 21.57402445602417, "Mean Q2": 21.57400944900513, "critic_loss": 0.48212930327653886, "batch_reward": 0.14561089426279067, "actor_loss": -21.710631958007813, "actor_target_entropy": -6.0, "actor_entropy": 6.44328680229187, "alpha_loss": 0.016115013374015687, "alpha_value": 0.008316386957068982, "duration": 551.2594335079193, "step": 59000}
{"episode_reward": 93.04825593855519, "episode": 119.0, "Q1 loss": 0.2853965262770653, "Q2 loss": 0.28699291168153285, "Mean Target Q": 21.665063236236573, "Mean Q1": 21.66503664779663, "Mean Q2": 21.66507054901123, "critic_loss": 0.5723894380629063, "batch_reward": 0.14584415632486344, "actor_loss": -21.786136100769042, "actor_target_entropy": -6.0, "actor_entropy": 6.415436092376709, "alpha_loss": 0.0150920506156981, "alpha_value": 0.00818094434473811, "duration": 490.43332743644714, "step": 59500}
{"episode_reward": 95.2972211601189, "episode": 120.0, "Q1 loss": 0.24970159035921097, "Q2 loss": 0.2510401302576065, "Mean Target Q": 21.715466426849364, "Mean Q1": 21.715598960876466, "Mean Q2": 21.715537590026855, "critic_loss": 0.5007417203485965, "batch_reward": 0.14570244240760805, "actor_loss": -21.836286476135253, "actor_target_entropy": -6.0, "actor_entropy": 6.413313037872315, "alpha_loss": 0.014128903904929758, "alpha_value": 0.008043044947787036, "step": 60000}
{"duration": 329.76905965805054, "step": 60000}
{"episode_reward": 90.89712853220878, "episode": 121.0, "Q1 loss": 0.26407266247272493, "Q2 loss": 0.26504842323064803, "Mean Target Q": 21.720728511810304, "Mean Q1": 21.720704284667967, "Mean Q2": 21.72069928741455, "critic_loss": 0.5291210865080357, "batch_reward": 0.1468922834098339, "actor_loss": -21.849998222351076, "actor_target_entropy": -6.0, "actor_entropy": 6.349625854492188, "alpha_loss": 0.012213212663307787, "alpha_value": 0.007911141291685079, "duration": 532.0165462493896, "step": 60500}
{"episode_reward": 88.53513931305886, "episode": 122.0, "Q1 loss": 0.2775824802219868, "Q2 loss": 0.27713778817653656, "Mean Target Q": 21.86277359390259, "Mean Q1": 21.862779399871826, "Mean Q2": 21.862737579345705, "critic_loss": 0.5547202689051628, "batch_reward": 0.14700033865869044, "actor_loss": -22.00625527191162, "actor_target_entropy": -6.0, "actor_entropy": 6.302244474411011, "alpha_loss": 0.010110638853162527, "alpha_value": 0.007796928513991327, "duration": 575.2541377544403, "step": 61000}
{"episode_reward": 90.9549793536824, "episode": 123.0, "Q1 loss": 0.2995692180991173, "Q2 loss": 0.2988342652618885, "Mean Target Q": 22.05331052017212, "Mean Q1": 22.05308833312988, "Mean Q2": 22.053177280426027, "critic_loss": 0.5984034845232964, "batch_reward": 0.14798961049318313, "actor_loss": -22.1972494430542, "actor_target_entropy": -6.0, "actor_entropy": 6.28615675163269, "alpha_loss": 0.009322989225853234, "alpha_value": 0.007689249741878834, "duration": 571.6380896568298, "step": 61500}
{"episode_reward": 112.32763175143774, "episode": 124.0, "Q1 loss": 0.3020722342729569, "Q2 loss": 0.30343224106729033, "Mean Target Q": 22.117211349487306, "Mean Q1": 22.117371871948244, "Mean Q2": 22.11730417251587, "critic_loss": 0.6055044757425785, "batch_reward": 0.14764733242988587, "actor_loss": -22.266308425903322, "actor_target_entropy": -6.0, "actor_entropy": 6.296437417984008, "alpha_loss": 0.010566339762881398, "alpha_value": 0.007569718708943327, "duration": 573.9810287952423, "step": 62000}
{"episode_reward": 101.05426420052878, "episode": 125.0, "Q1 loss": 0.30529288527369497, "Q2 loss": 0.3054630103856325, "Mean Target Q": 22.14424402999878, "Mean Q1": 22.144171298980712, "Mean Q2": 22.14411770629883, "critic_loss": 0.6107558961212635, "batch_reward": 0.14815744125843047, "actor_loss": -22.291997726440428, "actor_target_entropy": -6.0, "actor_entropy": 6.252497690200806, "alpha_loss": 0.008702111339196563, "alpha_value": 0.007446619887114292, "duration": 541.2560214996338, "step": 62500}
{"episode_reward": 100.16448646478544, "episode": 126.0, "Q1 loss": 0.33734190537035463, "Q2 loss": 0.3383353236168623, "Mean Target Q": 22.28264281463623, "Mean Q1": 22.282787296295165, "Mean Q2": 22.28287092590332, "critic_loss": 0.67567722889781, "batch_reward": 0.14841121876239777, "actor_loss": -22.411003372192383, "actor_target_entropy": -6.0, "actor_entropy": 6.259761692047119, "alpha_loss": 0.007872317751636729, "alpha_value": 0.007339886300373993, "duration": 598.4900734424591, "step": 63000}
{"episode_reward": 84.23394984047563, "episode": 127.0, "Q1 loss": 0.41540351700782774, "Q2 loss": 0.4143421041965485, "Mean Target Q": 22.396306056976318, "Mean Q1": 22.39642881011963, "Mean Q2": 22.396443649291992, "critic_loss": 0.8297456211447716, "batch_reward": 0.14887902450561524, "actor_loss": -22.521597122192382, "actor_target_entropy": -6.0, "actor_entropy": 6.26400270652771, "alpha_loss": 0.007019862477201968, "alpha_value": 0.007228797929470638, "duration": 567.4479238986969, "step": 63500}
{"episode_reward": 118.50436466891718, "episode": 128.0, "Q1 loss": 0.44320364743471147, "Q2 loss": 0.4431726357638836, "Mean Target Q": 22.42927458190918, "Mean Q1": 22.428981204986574, "Mean Q2": 22.428907733917235, "critic_loss": 0.886376284301281, "batch_reward": 0.1495650183111429, "actor_loss": -22.571758575439453, "actor_target_entropy": -6.0, "actor_entropy": 6.267385074615478, "alpha_loss": 0.006775703544262796, "alpha_value": 0.007129545533432115, "duration": 580.0064477920532, "step": 64000}
{"episode_reward": 108.69611491438702, "episode": 129.0, "Q1 loss": 0.49354755291342733, "Q2 loss": 0.4926160462796688, "Mean Target Q": 22.564895038604735, "Mean Q1": 22.56494221878052, "Mean Q2": 22.565025756835936, "critic_loss": 0.9861635984778404, "batch_reward": 0.14967128857970238, "actor_loss": -22.686461791992187, "actor_target_entropy": -6.0, "actor_entropy": 6.3372921314239505, "alpha_loss": 0.006845070369774476, "alpha_value": 0.007015603918772426, "duration": 349.845237493515, "step": 64500}
{"episode_reward": 94.99337972030133, "episode": 130.0, "Q1 loss": 0.5532105849981308, "Q2 loss": 0.555101959913969, "Mean Target Q": 22.684451332092284, "Mean Q1": 22.68426146316528, "Mean Q2": 22.68434655380249, "critic_loss": 1.1083125414848327, "batch_reward": 0.14985050037503242, "actor_loss": -22.847855628967285, "actor_target_entropy": -6.0, "actor_entropy": 6.263868534088135, "alpha_loss": 0.006110360861173831, "alpha_value": 0.006909816979173833, "step": 65000}
{"duration": 359.3552072048187, "step": 65000}
{"episode_reward": 81.10160285624333, "episode": 131.0, "Q1 loss": 0.6809140317738056, "Q2 loss": 0.6838397383391858, "Mean Target Q": 22.75759513092041, "Mean Q1": 22.758161075592042, "Mean Q2": 22.758128646850587, "critic_loss": 1.3647537684440614, "batch_reward": 0.15030690750479697, "actor_loss": -22.886399574279785, "actor_target_entropy": -6.0, "actor_entropy": 6.228438802719117, "alpha_loss": 0.0052877683334518226, "alpha_value": 0.006807712155549534, "duration": 319.69313955307007, "step": 65500}
{"episode_reward": 111.23991026317425, "episode": 132.0, "Q1 loss": 0.6246027770042419, "Q2 loss": 0.6266772024333477, "Mean Target Q": 22.851477573394774, "Mean Q1": 22.850704391479493, "Mean Q2": 22.85084675216675, "critic_loss": 1.2512799813747406, "batch_reward": 0.15035612455010414, "actor_loss": -23.0454421005249, "actor_target_entropy": -6.0, "actor_entropy": 6.153242177963257, "alpha_loss": 0.0033463945718831384, "alpha_value": 0.006723958321417687, "duration": 519.5396182537079, "step": 66000}
{"episode_reward": 125.24992758303456, "episode": 133.0, "Q1 loss": 0.5546578116118908, "Q2 loss": 0.5548656197190285, "Mean Target Q": 22.98489028930664, "Mean Q1": 22.984557865142822, "Mean Q2": 22.98454067993164, "critic_loss": 1.1095234325528145, "batch_reward": 0.1520708862245083, "actor_loss": -23.07464705657959, "actor_target_entropy": -6.0, "actor_entropy": 6.205478191375732, "alpha_loss": 0.004272725690738298, "alpha_value": 0.006647593409234257, "duration": 318.990327835083, "step": 66500}
{"episode_reward": 116.72208176772259, "episode": 134.0, "Q1 loss": 0.6780717539787292, "Q2 loss": 0.6832984681129456, "Mean Target Q": 23.12644637298584, "Mean Q1": 23.12683931350708, "Mean Q2": 23.126880630493165, "critic_loss": 1.3613702256679534, "batch_reward": 0.15233751845359803, "actor_loss": -23.282326248168946, "actor_target_entropy": -6.0, "actor_entropy": 6.155734037399292, "alpha_loss": 0.00304345886799274, "alpha_value": 0.0065643233520656175, "duration": 332.92715978622437, "step": 67000}
{"episode_reward": 68.64572949804212, "episode": 135.0, "Q1 loss": 0.5651946834027767, "Q2 loss": 0.5642138419151306, "Mean Target Q": 23.158214767456055, "Mean Q1": 23.15835375213623, "Mean Q2": 23.15840336227417, "critic_loss": 1.1294085254073143, "batch_reward": 0.15227511301636695, "actor_loss": -23.320340606689452, "actor_target_entropy": -6.0, "actor_entropy": 6.111911825180053, "alpha_loss": 0.002571268992847763, "alpha_value": 0.0065007096586648955, "duration": 295.30410599708557, "step": 67500}
{"episode_reward": 98.8600915025751, "episode": 136.0, "Q1 loss": 0.6857983087003231, "Q2 loss": 0.683903965741396, "Mean Target Q": 23.21889669418335, "Mean Q1": 23.219188514709472, "Mean Q2": 23.219131160736083, "critic_loss": 1.3697022768855094, "batch_reward": 0.15263469350337983, "actor_loss": -23.425509773254394, "actor_target_entropy": -6.0, "actor_entropy": 6.0490885353088375, "alpha_loss": 0.002106456403620541, "alpha_value": 0.006437070190944776, "duration": 301.736448764801, "step": 68000}
{"episode_reward": 126.22260272223966, "episode": 137.0, "Q1 loss": 0.625600783765316, "Q2 loss": 0.6285880180597305, "Mean Target Q": 23.355413841247557, "Mean Q1": 23.35543726348877, "Mean Q2": 23.355408420562743, "critic_loss": 1.254188800215721, "batch_reward": 0.1538153074979782, "actor_loss": -23.50366403198242, "actor_target_entropy": -6.0, "actor_entropy": 6.068980409622192, "alpha_loss": 0.0018582566461991519, "alpha_value": 0.0063869923105350284, "duration": 552.7217314243317, "step": 68500}
{"episode_reward": 77.62738232820736, "episode": 138.0, "Q1 loss": 0.6957266054451465, "Q2 loss": 0.6974788919687271, "Mean Target Q": 23.458758682250977, "Mean Q1": 23.459995594024658, "Mean Q2": 23.459981781005858, "critic_loss": 1.3932054988741875, "batch_reward": 0.15282862934470176, "actor_loss": -23.622725555419922, "actor_target_entropy": -6.0, "actor_entropy": 6.082133701324463, "alpha_loss": 0.0008981860692729242, "alpha_value": 0.0063422341448480584, "duration": 530.8156728744507, "step": 69000}
{"episode_reward": 117.34217056331308, "episode": 139.0, "Q1 loss": 0.7012330544888973, "Q2 loss": 0.707527916520834, "Mean Target Q": 23.36695600128174, "Mean Q1": 23.36661469268799, "Mean Q2": 23.366699100494383, "critic_loss": 1.4087609720826149, "batch_reward": 0.15408203062415124, "actor_loss": -23.502463470458984, "actor_target_entropy": -6.0, "actor_entropy": 6.070750720977784, "alpha_loss": 0.0003111663505551405, "alpha_value": 0.006327072588937317, "duration": 608.5192873477936, "step": 69500}
{"episode_reward": 101.17956892833189, "episode": 140.0, "Q1 loss": 0.8813091165721416, "Q2 loss": 0.8868426164388656, "Mean Target Q": 23.40295513153076, "Mean Q1": 23.40337967300415, "Mean Q2": 23.403060497283935, "critic_loss": 1.768151738166809, "batch_reward": 0.15459982565045358, "actor_loss": -23.537447257995606, "actor_target_entropy": -6.0, "actor_entropy": 6.071736753463745, "alpha_loss": 0.0008061888917000033, "alpha_value": 0.0063112298530824985, "step": 70000}
{"duration": 473.7730801105499, "step": 70000}
{"episode_reward": 101.74432671618432, "episode": 141.0, "Q1 loss": 0.8886253165602684, "Q2 loss": 0.8954035111367703, "Mean Target Q": 23.47585792160034, "Mean Q1": 23.47535494995117, "Mean Q2": 23.475447971343993, "critic_loss": 1.7840288316011428, "batch_reward": 0.1545563562810421, "actor_loss": -23.5501483001709, "actor_target_entropy": -6.0, "actor_entropy": 6.096695611953735, "alpha_loss": 0.001733745011209976, "alpha_value": 0.006252412877602243, "duration": 284.59359407424927, "step": 70500}
{"episode_reward": 84.88971288509161, "episode": 142.0, "Q1 loss": 0.6951261177062988, "Q2 loss": 0.6979758969545364, "Mean Target Q": 23.560497646331786, "Mean Q1": 23.56163619995117, "Mean Q2": 23.561846382141113, "critic_loss": 1.3931020176410676, "batch_reward": 0.15497863194346428, "actor_loss": -23.700270622253417, "actor_target_entropy": -6.0, "actor_entropy": 6.100861455917358, "alpha_loss": 0.001666094398999121, "alpha_value": 0.0061892579604756835, "duration": 330.0313012599945, "step": 71000}
{"episode_reward": 118.37020330646544, "episode": 143.0, "Q1 loss": 0.5511587070226669, "Q2 loss": 0.5516717968285084, "Mean Target Q": 23.59593273162842, "Mean Q1": 23.59613021850586, "Mean Q2": 23.596199199676512, "critic_loss": 1.1028305025100709, "batch_reward": 0.1554958420395851, "actor_loss": -23.757023017883302, "actor_target_entropy": -6.0, "actor_entropy": 6.0234921932220455, "alpha_loss": 0.0011972610120428726, "alpha_value": 0.00611896772113297, "duration": 287.1995339393616, "step": 71500}
{"episode_reward": 84.07654205211469, "episode": 144.0, "Q1 loss": 0.6059460172951221, "Q2 loss": 0.6093022709190845, "Mean Target Q": 23.720986240386964, "Mean Q1": 23.7210041885376, "Mean Q2": 23.721126930236817, "critic_loss": 1.2152482914328575, "batch_reward": 0.15477710843086243, "actor_loss": -23.83880431365967, "actor_target_entropy": -6.0, "actor_entropy": 5.938697540283203, "alpha_loss": 9.094154369086027e-05, "alpha_value": 0.0061015294144548485, "duration": 289.6272201538086, "step": 72000}
{"episode_reward": 95.78366957981096, "episode": 145.0, "Q1 loss": 0.7377932369709015, "Q2 loss": 0.7405234686434269, "Mean Target Q": 23.823273216247557, "Mean Q1": 23.82337096786499, "Mean Q2": 23.82344580078125, "critic_loss": 1.4783167079687118, "batch_reward": 0.15587824285030366, "actor_loss": -23.95725682067871, "actor_target_entropy": -6.0, "actor_entropy": 6.0765489406585695, "alpha_loss": 0.0010320499047229532, "alpha_value": 0.006076834279115571, "duration": 352.9020195007324, "step": 72500}
{"episode_reward": 133.0706332666935, "episode": 146.0, "Q1 loss": 0.7606530616283417, "Q2 loss": 0.7603597375154495, "Mean Target Q": 23.915935459136964, "Mean Q1": 23.916716827392577, "Mean Q2": 23.916821002960205, "critic_loss": 1.5210128076672553, "batch_reward": 0.1555225813984871, "actor_loss": -24.09692430114746, "actor_target_entropy": -6.0, "actor_entropy": 5.8864269390106205, "alpha_loss": -0.0010582556434092112, "alpha_value": 0.006065626658503744, "duration": 318.9503016471863, "step": 73000}
{"episode_reward": 93.20806045784707, "episode": 147.0, "Q1 loss": 0.5823217171132564, "Q2 loss": 0.5830615647137165, "Mean Target Q": 23.830517303466795, "Mean Q1": 23.830608612060548, "Mean Q2": 23.83062355041504, "critic_loss": 1.165383281648159, "batch_reward": 0.15610015136003494, "actor_loss": -23.983487464904787, "actor_target_entropy": -6.0, "actor_entropy": 5.960589782714844, "alpha_loss": -0.0016907372782879976, "alpha_value": 0.006153981978697227, "duration": 276.2569468021393, "step": 73500}
{"episode_reward": 108.88544427032143, "episode": 148.0, "Q1 loss": 0.6133332747519016, "Q2 loss": 0.6106240647733212, "Mean Target Q": 23.92374390411377, "Mean Q1": 23.923930042266846, "Mean Q2": 23.923842727661132, "critic_loss": 1.2239573395252228, "batch_reward": 0.15680824431777002, "actor_loss": -24.06356549835205, "actor_target_entropy": -6.0, "actor_entropy": 5.957304309844971, "alpha_loss": -0.0006080072458134964, "alpha_value": 0.006212530660250752, "duration": 295.8881046772003, "step": 74000}
{"episode_reward": 89.85145379957413, "episode": 149.0, "Q1 loss": 0.6092470165193081, "Q2 loss": 0.6099565407633781, "Mean Target Q": 23.97933625793457, "Mean Q1": 23.980181663513182, "Mean Q2": 23.980162479400636, "critic_loss": 1.219203556060791, "batch_reward": 0.15722325751185418, "actor_loss": -24.141158866882325, "actor_target_entropy": -6.0, "actor_entropy": 5.949287801742554, "alpha_loss": -0.0014252572638797573, "alpha_value": 0.006258633709927324, "duration": 278.5291938781738, "step": 74500}
{"episode_reward": 128.22096457313663, "episode": 150.0, "Q1 loss": 0.558396245867014, "Q2 loss": 0.56046099832654, "Mean Target Q": 24.082701553344727, "Mean Q1": 24.08275353240967, "Mean Q2": 24.08277855682373, "critic_loss": 1.1188572432994843, "batch_reward": 0.1574870484173298, "actor_loss": -24.24054962158203, "actor_target_entropy": -6.0, "actor_entropy": 5.886853338241577, "alpha_loss": -0.0014435825580148957, "alpha_value": 0.006349297756068332, "step": 75000}
{"duration": 473.8576512336731, "step": 75000}
{"episode_reward": 87.3364729431546, "episode": 151.0, "Q1 loss": 1.572195886015892, "Q2 loss": 1.5758101066350938, "Mean Target Q": 24.08379553604126, "Mean Q1": 24.08416117477417, "Mean Q2": 24.084401237487793, "critic_loss": 3.1480060148239137, "batch_reward": 0.15786136281490326, "actor_loss": -24.24289144897461, "actor_target_entropy": -6.0, "actor_entropy": 6.031222414016724, "alpha_loss": -0.001461870640341658, "alpha_value": 0.006398594799529672, "duration": 546.6601150035858, "step": 75500}
{"episode_reward": 90.77751856989168, "episode": 152.0, "Q1 loss": 1.3225868353843688, "Q2 loss": 1.330358998656273, "Mean Target Q": 24.22594367980957, "Mean Q1": 24.22474750137329, "Mean Q2": 24.224700817108154, "critic_loss": 2.6529458400011063, "batch_reward": 0.15752056458592414, "actor_loss": -24.379403709411623, "actor_target_entropy": -6.0, "actor_entropy": 6.172224576950073, "alpha_loss": -0.0008119543189532123, "alpha_value": 0.0064578039535352185, "duration": 602.6039175987244, "step": 76000}
{"episode_reward": 98.50370984283958, "episode": 153.0, "Q1 loss": 0.6598519177734852, "Q2 loss": 0.6584652781188488, "Mean Target Q": 24.368500831604003, "Mean Q1": 24.369182571411134, "Mean Q2": 24.3692543258667, "critic_loss": 1.3183171976804733, "batch_reward": 0.15783411863446237, "actor_loss": -24.418154289245606, "actor_target_entropy": -6.0, "actor_entropy": 6.000716924667358, "alpha_loss": -0.0019092217814177274, "alpha_value": 0.006533258458441272, "duration": 666.2149958610535, "step": 76500}
{"episode_reward": 81.52085718378888, "episode": 154.0, "Q1 loss": 0.5498210668563843, "Q2 loss": 0.5483932567834854, "Mean Target Q": 24.434345748901368, "Mean Q1": 24.43409412384033, "Mean Q2": 24.434167278289795, "critic_loss": 1.0982143270969391, "batch_reward": 0.15809140691161155, "actor_loss": -24.55957089996338, "actor_target_entropy": -6.0, "actor_entropy": 5.916344705581665, "alpha_loss": -0.0019585811774013562, "alpha_value": 0.006629813784645879, "duration": 682.670245885849, "step": 77000}
{"episode_reward": 88.89978432682688, "episode": 155.0, "Q1 loss": 0.609760981708765, "Q2 loss": 0.6147840709388256, "Mean Target Q": 24.50029275894165, "Mean Q1": 24.50052735900879, "Mean Q2": 24.50070810317993, "critic_loss": 1.2245450523495673, "batch_reward": 0.15815474876761437, "actor_loss": -24.589668159484862, "actor_target_entropy": -6.0, "actor_entropy": 5.919116493225098, "alpha_loss": -0.0017415834872517735, "alpha_value": 0.006719344814078343, "duration": 576.7887749671936, "step": 77500}
{"episode_reward": 87.48437159627375, "episode": 156.0, "Q1 loss": 0.5877186001837253, "Q2 loss": 0.5887644623816013, "Mean Target Q": 24.673663898468018, "Mean Q1": 24.674120849609373, "Mean Q2": 24.674118968963622, "critic_loss": 1.1764830642938613, "batch_reward": 0.15872150284051895, "actor_loss": -24.833405883789062, "actor_target_entropy": -6.0, "actor_entropy": 5.8456765575408935, "alpha_loss": -0.0012436266754521058, "alpha_value": 0.006798281844753958, "duration": 680.4602916240692, "step": 78000}
{"episode_reward": 94.99683640643278, "episode": 157.0, "Q1 loss": 0.5499314489364624, "Q2 loss": 0.555744997471571, "Mean Target Q": 24.632134422302247, "Mean Q1": 24.632701248168946, "Mean Q2": 24.63275635147095, "critic_loss": 1.1056764460206032, "batch_reward": 0.15887466275691986, "actor_loss": -24.817392753601073, "actor_target_entropy": -6.0, "actor_entropy": 5.8514863395690915, "alpha_loss": -0.00025911257800180466, "alpha_value": 0.006833549843008954, "duration": 669.1375298500061, "step": 78500}
{"episode_reward": 112.7362491088802, "episode": 158.0, "Q1 loss": 0.7396735615730285, "Q2 loss": 0.7409230727255345, "Mean Target Q": 24.752764114379882, "Mean Q1": 24.752468009948732, "Mean Q2": 24.75250616455078, "critic_loss": 1.480596635878086, "batch_reward": 0.15878954076766968, "actor_loss": -24.905215309143067, "actor_target_entropy": -6.0, "actor_entropy": 5.87014680480957, "alpha_loss": 1.4093460282310844e-05, "alpha_value": 0.006835307457889022, "duration": 679.6168737411499, "step": 79000}
{"episode_reward": 100.7868663371244, "episode": 159.0, "Q1 loss": 0.5696224032938481, "Q2 loss": 0.5711491939723492, "Mean Target Q": 24.84060248184204, "Mean Q1": 24.841005474090576, "Mean Q2": 24.841084033966066, "critic_loss": 1.1407715989947318, "batch_reward": 0.15836264139413833, "actor_loss": -25.03374787902832, "actor_target_entropy": -6.0, "actor_entropy": 5.817625057220459, "alpha_loss": 0.0009527456665528007, "alpha_value": 0.006826257764851065, "duration": 647.6666445732117, "step": 79500}
{"episode_reward": 68.53340155193062, "episode": 160.0, "Q1 loss": 0.5245585494339466, "Q2 loss": 0.5269497430324555, "Mean Target Q": 24.905973526000977, "Mean Q1": 24.906435321807862, "Mean Q2": 24.90669747543335, "critic_loss": 1.051508292555809, "batch_reward": 0.1594486697614193, "actor_loss": -25.101246971130372, "actor_target_entropy": -6.0, "actor_entropy": 5.798190132141113, "alpha_loss": 0.0005360602432629094, "alpha_value": 0.0067655135992266075, "step": 80000}
{"duration": 646.8108472824097, "step": 80000}
{"episode_reward": 109.87538137674571, "episode": 161.0, "Q1 loss": 0.5262214269340039, "Q2 loss": 0.5276667194366456, "Mean Target Q": 24.99669100189209, "Mean Q1": 24.996803600311278, "Mean Q2": 24.996934013366698, "critic_loss": 1.0538881437182426, "batch_reward": 0.15964340537786484, "actor_loss": -25.13566254425049, "actor_target_entropy": -6.0, "actor_entropy": 5.76138779258728, "alpha_loss": -0.0005280290422379039, "alpha_value": 0.006771605405243206, "duration": 621.3064205646515, "step": 80500}
{"episode_reward": 103.29475284945732, "episode": 162.0, "Q1 loss": 0.548405263453722, "Q2 loss": 0.5591507396996022, "Mean Target Q": 24.90303088760376, "Mean Q1": 24.902759159088134, "Mean Q2": 24.902992321014406, "critic_loss": 1.1075560023784639, "batch_reward": 0.15974996981024742, "actor_loss": -25.101132919311524, "actor_target_entropy": -6.0, "actor_entropy": 5.814364286422729, "alpha_loss": -0.00011887420353014022, "alpha_value": 0.006789536265281913, "duration": 515.1655049324036, "step": 81000}
{"episode_reward": 92.98451761369473, "episode": 163.0, "Q1 loss": 0.6455173686146736, "Q2 loss": 0.6442606978416443, "Mean Target Q": 25.008035526275634, "Mean Q1": 25.008260330200194, "Mean Q2": 25.00835432434082, "critic_loss": 1.2897780686020852, "batch_reward": 0.15974389937520028, "actor_loss": -25.138573699951174, "actor_target_entropy": -6.0, "actor_entropy": 5.756053050994873, "alpha_loss": -0.0008358858509454877, "alpha_value": 0.006831123595869999, "duration": 625.2972707748413, "step": 81500}
{"episode_reward": 91.48946225147994, "episode": 164.0, "Q1 loss": 0.6880849021077156, "Q2 loss": 0.6986206473708153, "Mean Target Q": 25.15958012008667, "Mean Q1": 25.15999995803833, "Mean Q2": 25.159964252471923, "critic_loss": 1.3867055505514145, "batch_reward": 0.16008159920573234, "actor_loss": -25.262441329956054, "actor_target_entropy": -6.0, "actor_entropy": 5.807239446640015, "alpha_loss": 0.0003200814460287802, "alpha_value": 0.006857387665475113, "duration": 614.4130942821503, "step": 82000}
{"episode_reward": 90.65960802040442, "episode": 165.0, "Q1 loss": 0.6212177263796329, "Q2 loss": 0.6264622621536254, "Mean Target Q": 25.150871376037596, "Mean Q1": 25.15032431411743, "Mean Q2": 25.150374942779543, "critic_loss": 1.2476799861192702, "batch_reward": 0.16021879267692565, "actor_loss": -25.312318397521974, "actor_target_entropy": -6.0, "actor_entropy": 5.8050485019683835, "alpha_loss": -0.0003462638218188658, "alpha_value": 0.0068476158909172614, "duration": 578.2327938079834, "step": 82500}
{"episode_reward": 91.09674252188458, "episode": 166.0, "Q1 loss": 0.6320223834216595, "Q2 loss": 0.6303850147426129, "Mean Target Q": 25.233279602050782, "Mean Q1": 25.232539024353027, "Mean Q2": 25.232456871032714, "critic_loss": 1.2624073981046677, "batch_reward": 0.16065651705861092, "actor_loss": -25.39570687866211, "actor_target_entropy": -6.0, "actor_entropy": 5.768203283309936, "alpha_loss": -0.0006007474390789866, "alpha_value": 0.006888906687646223, "duration": 459.10618901252747, "step": 83000}
{"episode_reward": 77.27164113326779, "episode": 167.0, "Q1 loss": 0.605453244715929, "Q2 loss": 0.6071915409862995, "Mean Target Q": 25.269335796356202, "Mean Q1": 25.269522758483888, "Mean Q2": 25.269566204071044, "critic_loss": 1.2126447865366936, "batch_reward": 0.15981525218486786, "actor_loss": -25.378361656188964, "actor_target_entropy": -6.0, "actor_entropy": 5.782915428161621, "alpha_loss": -0.0004899360469426029, "alpha_value": 0.006925479657409717, "duration": 545.85001039505, "step": 83500}
{"episode_reward": 74.59249276386058, "episode": 168.0, "Q1 loss": 0.8634151909053326, "Q2 loss": 0.8675948890447617, "Mean Target Q": 25.357598335266115, "Mean Q1": 25.356767490386964, "Mean Q2": 25.35686108016968, "critic_loss": 1.7310100761651992, "batch_reward": 0.1602359374165535, "actor_loss": -25.495261047363282, "actor_target_entropy": -6.0, "actor_entropy": 5.831613527297973, "alpha_loss": -3.379318630322814e-05, "alpha_value": 0.006943912080786738, "duration": 627.5704300403595, "step": 84000}
{"episode_reward": 113.99472174798815, "episode": 169.0, "Q1 loss": 0.6662985500097275, "Q2 loss": 0.6641152276396751, "Mean Target Q": 25.421306621551512, "Mean Q1": 25.42129761505127, "Mean Q2": 25.421376735687257, "critic_loss": 1.3304137748479843, "batch_reward": 0.16020605236291885, "actor_loss": -25.5577385559082, "actor_target_entropy": -6.0, "actor_entropy": 5.817172813415527, "alpha_loss": 6.987498851958662e-05, "alpha_value": 0.006943162022933443, "duration": 608.90105509758, "step": 84500}
{"episode_reward": 94.88967080064272, "episode": 170.0, "Q1 loss": 0.5710045388042927, "Q2 loss": 0.5722960261702538, "Mean Target Q": 25.502485370635988, "Mean Q1": 25.502465007781982, "Mean Q2": 25.502387268066407, "critic_loss": 1.1433005613684655, "batch_reward": 0.16074896809458733, "actor_loss": -25.644639976501466, "actor_target_entropy": -6.0, "actor_entropy": 5.815164213180542, "alpha_loss": -0.0006345156935567502, "alpha_value": 0.006967787885156239, "step": 85000}
{"duration": 606.688395023346, "step": 85000}
{"episode_reward": 84.04834264891174, "episode": 171.0, "Q1 loss": 0.6981278130114078, "Q2 loss": 0.6949269272089005, "Mean Target Q": 25.518688591003418, "Mean Q1": 25.518274665832518, "Mean Q2": 25.51804150390625, "critic_loss": 1.3930547409653664, "batch_reward": 0.16086682286858558, "actor_loss": -25.66774856567383, "actor_target_entropy": -6.0, "actor_entropy": 5.82413888168335, "alpha_loss": -0.0004812918415991589, "alpha_value": 0.006991135422794939, "duration": 510.01997923851013, "step": 85500}
{"episode_reward": 111.65032885337936, "episode": 172.0, "Q1 loss": 0.5882389009296894, "Q2 loss": 0.5862970256209373, "Mean Target Q": 25.562113399505616, "Mean Q1": 25.56180260848999, "Mean Q2": 25.561887203216553, "critic_loss": 1.174535927116871, "batch_reward": 0.16169047886133195, "actor_loss": -25.707363067626954, "actor_target_entropy": -6.0, "actor_entropy": 5.806822727203369, "alpha_loss": -0.00026209987117908895, "alpha_value": 0.007022255792186417, "duration": 577.5822103023529, "step": 86000}
{"episode_reward": 115.11728400198542, "episode": 173.0, "Q1 loss": 0.619518109291792, "Q2 loss": 0.619886422097683, "Mean Target Q": 25.57369637298584, "Mean Q1": 25.57381639480591, "Mean Q2": 25.57393871307373, "critic_loss": 1.2394045305252075, "batch_reward": 0.16181268578767777, "actor_loss": -25.7386078414917, "actor_target_entropy": -6.0, "actor_entropy": 5.808826875686646, "alpha_loss": -0.00018013871274888516, "alpha_value": 0.007050010647259992, "duration": 565.4646108150482, "step": 86500}
{"episode_reward": 91.68789840231749, "episode": 174.0, "Q1 loss": 0.6279879932701588, "Q2 loss": 0.6250002539157867, "Mean Target Q": 25.61271997833252, "Mean Q1": 25.612859493255616, "Mean Q2": 25.613028858184816, "critic_loss": 1.2529882455468178, "batch_reward": 0.1621932871043682, "actor_loss": -25.773180702209473, "actor_target_entropy": -6.0, "actor_entropy": 5.828003597259522, "alpha_loss": -0.00025521374674281104, "alpha_value": 0.007057972571378557, "duration": 478.5116534233093, "step": 87000}
{"episode_reward": 92.8466022688631, "episode": 175.0, "Q1 loss": 0.572683629065752, "Q2 loss": 0.5719541330635548, "Mean Target Q": 25.644860717773437, "Mean Q1": 25.644251907348632, "Mean Q2": 25.644312801361085, "critic_loss": 1.144637764275074, "batch_reward": 0.16116242173314094, "actor_loss": -25.82392523956299, "actor_target_entropy": -6.0, "actor_entropy": 5.841896375656128, "alpha_loss": -0.00045372853690059855, "alpha_value": 0.007086012585979678, "duration": 426.81939792633057, "step": 87500}
{"episode_reward": 72.73387270850012, "episode": 176.0, "Q1 loss": 0.6524321680665016, "Q2 loss": 0.6466830664277077, "Mean Target Q": 25.70809337234497, "Mean Q1": 25.708017650604248, "Mean Q2": 25.708079582214356, "critic_loss": 1.2991152358651161, "batch_reward": 0.16204110923409462, "actor_loss": -25.864640289306642, "actor_target_entropy": -6.0, "actor_entropy": 5.799756855010986, "alpha_loss": -0.0013042090733069926, "alpha_value": 0.007159272181442248, "duration": 258.71741700172424, "step": 88000}
{"episode_reward": 91.383607185844, "episode": 177.0, "Q1 loss": 0.8094254741072655, "Q2 loss": 0.8050430339276791, "Mean Target Q": 25.603409114837646, "Mean Q1": 25.60345594406128, "Mean Q2": 25.60338823699951, "critic_loss": 1.6144685059785844, "batch_reward": 0.1618239216208458, "actor_loss": -25.707455612182617, "actor_target_entropy": -6.0, "actor_entropy": 5.820917373657227, "alpha_loss": -0.0014848714030231349, "alpha_value": 0.007250088377242406, "duration": 230.66258263587952, "step": 88500}
{"episode_reward": 86.58921342571088, "episode": 178.0, "Q1 loss": 0.9508985378742218, "Q2 loss": 0.9557343798279763, "Mean Target Q": 25.556421646118164, "Mean Q1": 25.55531116104126, "Mean Q2": 25.555484943389892, "critic_loss": 1.9066329128742219, "batch_reward": 0.1617022477388382, "actor_loss": -25.703468063354492, "actor_target_entropy": -6.0, "actor_entropy": 5.908252910614014, "alpha_loss": -0.000784626037813723, "alpha_value": 0.00733628167449389, "duration": 356.5574414730072, "step": 89000}
{"episode_reward": 108.26225818999085, "episode": 179.0, "Q1 loss": 1.0188276190757752, "Q2 loss": 1.0040226338505744, "Mean Target Q": 25.59541997909546, "Mean Q1": 25.59539861679077, "Mean Q2": 25.59533309173584, "critic_loss": 2.0228502568006514, "batch_reward": 0.1623564591407776, "actor_loss": -25.71976077270508, "actor_target_entropy": -6.0, "actor_entropy": 5.895346555709839, "alpha_loss": -0.0013608529907651245, "alpha_value": 0.007409044441394404, "duration": 376.59335827827454, "step": 89500}
{"episode_reward": 102.81119906137373, "episode": 180.0, "Q1 loss": 0.8268859398961067, "Q2 loss": 0.8299688611030579, "Mean Target Q": 25.65169519805908, "Mean Q1": 25.65161399078369, "Mean Q2": 25.651626037597655, "critic_loss": 1.656854802250862, "batch_reward": 0.1624159827530384, "actor_loss": -25.804762329101564, "actor_target_entropy": -6.0, "actor_entropy": 5.853965681076049, "alpha_loss": 0.001263443824776914, "alpha_value": 0.007407496924640024, "step": 90000}
{"duration": 280.2237524986267, "step": 90000}
{"episode_reward": 116.5669838648936, "episode": 181.0, "Q1 loss": 0.7493406838178635, "Q2 loss": 0.749401102989912, "Mean Target Q": 25.706558567047118, "Mean Q1": 25.706962982177735, "Mean Q2": 25.707112617492676, "critic_loss": 1.4987417874336242, "batch_reward": 0.16251792883872987, "actor_loss": -25.911008171081544, "actor_target_entropy": -6.0, "actor_entropy": 5.8418925094604495, "alpha_loss": 0.0016253567357198335, "alpha_value": 0.007328665492603457, "duration": 227.57292938232422, "step": 90500}
{"episode_reward": 97.15531896148788, "episode": 182.0, "Q1 loss": 0.8287535797953606, "Q2 loss": 0.8367359577417374, "Mean Target Q": 25.795150436401368, "Mean Q1": 25.79490495300293, "Mean Q2": 25.79492123413086, "critic_loss": 1.6654895354509354, "batch_reward": 0.1625160513818264, "actor_loss": -25.95193822479248, "actor_target_entropy": -6.0, "actor_entropy": 5.882970319747924, "alpha_loss": 0.0012324221768649295, "alpha_value": 0.007241971345882692, "duration": 238.25667595863342, "step": 91000}
{"episode_reward": 61.14819904069514, "episode": 183.0, "Q1 loss": 0.7721247037649155, "Q2 loss": 0.7702138269543648, "Mean Target Q": 25.909775722503664, "Mean Q1": 25.909441066741945, "Mean Q2": 25.909613388061523, "critic_loss": 1.5423385313749314, "batch_reward": 0.16270221763849257, "actor_loss": -26.07871989440918, "actor_target_entropy": -6.0, "actor_entropy": 5.940531929016113, "alpha_loss": 0.0018349236553476657, "alpha_value": 0.007137409757169707, "duration": 247.8623948097229, "step": 91500}
{"episode_reward": 96.80702562565861, "episode": 184.0, "Q1 loss": 0.7353906670808792, "Q2 loss": 0.7373894171118737, "Mean Target Q": 25.91416237640381, "Mean Q1": 25.914083518981933, "Mean Q2": 25.914194526672365, "critic_loss": 1.472780081987381, "batch_reward": 0.1626619332432747, "actor_loss": -26.05037393951416, "actor_target_entropy": -6.0, "actor_entropy": 5.881872493743897, "alpha_loss": 0.0014807749384199269, "alpha_value": 0.007036609047466078, "duration": 568.780656337738, "step": 92000}
{"episode_reward": 105.38169793193026, "episode": 185.0, "Q1 loss": 0.7370826629698276, "Q2 loss": 0.7367859377861022, "Mean Target Q": 26.059026027679444, "Mean Q1": 26.05859590911865, "Mean Q2": 26.05860573577881, "critic_loss": 1.473868606865406, "batch_reward": 0.1628556229174137, "actor_loss": -26.20953298950195, "actor_target_entropy": -6.0, "actor_entropy": 5.868088611602783, "alpha_loss": 0.0006536354036070407, "alpha_value": 0.006963863212053443, "duration": 288.90448570251465, "step": 92500}
{"episode_reward": 100.55398785583455, "episode": 186.0, "Q1 loss": 0.6774326224923134, "Q2 loss": 0.6845549735724926, "Mean Target Q": 26.142174015045168, "Mean Q1": 26.141926651000976, "Mean Q2": 26.141897357940675, "critic_loss": 1.361987592101097, "batch_reward": 0.16329228833317758, "actor_loss": -26.367072845458985, "actor_target_entropy": -6.0, "actor_entropy": 5.850612691879272, "alpha_loss": -0.0005206180620007216, "alpha_value": 0.006979697633185177, "duration": 267.4589276313782, "step": 93000}
{"episode_reward": 92.73374440664375, "episode": 187.0, "Q1 loss": 0.6290237501263618, "Q2 loss": 0.6305505270659924, "Mean Target Q": 26.151151645660402, "Mean Q1": 26.151062503814696, "Mean Q2": 26.151033462524413, "critic_loss": 1.2595742774009704, "batch_reward": 0.16435517376661302, "actor_loss": -26.352152572631837, "actor_target_entropy": -6.0, "actor_entropy": 5.7498725872039795, "alpha_loss": -0.001317031710059382, "alpha_value": 0.007031164795529624, "duration": 239.58906984329224, "step": 93500}
{"episode_reward": 129.9328823177691, "episode": 188.0, "Q1 loss": 0.6813506546914577, "Q2 loss": 0.6844618721306324, "Mean Target Q": 26.24318314743042, "Mean Q1": 26.243353958129884, "Mean Q2": 26.24336407852173, "critic_loss": 1.3658125281333924, "batch_reward": 0.16381668365001678, "actor_loss": -26.399585746765137, "actor_target_entropy": -6.0, "actor_entropy": 5.840058809280396, "alpha_loss": -0.0005796066157054156, "alpha_value": 0.00709317211748448, "duration": 227.982745885849, "step": 94000}
{"episode_reward": 96.37068876431921, "episode": 189.0, "Q1 loss": 0.8182655955553055, "Q2 loss": 0.8191150270104408, "Mean Target Q": 26.26518844604492, "Mean Q1": 26.265378341674804, "Mean Q2": 26.265272701263427, "critic_loss": 1.6373806179761887, "batch_reward": 0.16522814282774925, "actor_loss": -26.391306617736817, "actor_target_entropy": -6.0, "actor_entropy": 5.865925142288208, "alpha_loss": 0.0007901547637302428, "alpha_value": 0.007092209397103622, "duration": 339.71227192878723, "step": 94500}
{"episode_reward": 142.9885513276421, "episode": 190.0, "Q1 loss": 0.7874620506167411, "Q2 loss": 0.7902822296619415, "Mean Target Q": 26.326700637817382, "Mean Q1": 26.326497451782227, "Mean Q2": 26.32663021850586, "critic_loss": 1.5777442845106124, "batch_reward": 0.16502044668793678, "actor_loss": -26.42161195373535, "actor_target_entropy": -6.0, "actor_entropy": 5.855802366256714, "alpha_loss": 0.0001238667187280953, "alpha_value": 0.007052151834252916, "step": 95000}
{"duration": 290.6740753650665, "step": 95000}
{"episode_reward": 102.77855059726349, "episode": 191.0, "Q1 loss": 0.854659375756979, "Q2 loss": 0.865914587110281, "Mean Target Q": 26.41313190460205, "Mean Q1": 26.412683181762695, "Mean Q2": 26.412499561309815, "critic_loss": 1.720573964357376, "batch_reward": 0.16556025844812394, "actor_loss": -26.521963150024416, "actor_target_entropy": -6.0, "actor_entropy": 5.873653930664062, "alpha_loss": -0.00016675026970915495, "alpha_value": 0.007056549881717092, "duration": 239.8605179786682, "step": 95500}
{"episode_reward": 143.2077398866362, "episode": 192.0, "Q1 loss": 0.7261119095683097, "Q2 loss": 0.7357246965169907, "Mean Target Q": 26.391542137145997, "Mean Q1": 26.391163757324218, "Mean Q2": 26.391204170227052, "critic_loss": 1.4618366060256958, "batch_reward": 0.1656029789149761, "actor_loss": -26.556745018005373, "actor_target_entropy": -6.0, "actor_entropy": 5.815057107925415, "alpha_loss": 0.0005247956522507593, "alpha_value": 0.007053312692012725, "duration": 280.56569647789, "step": 96000}
{"episode_reward": 93.07841672095847, "episode": 193.0, "Q1 loss": 0.7263597179055213, "Q2 loss": 0.7287939123213291, "Mean Target Q": 26.48631132888794, "Mean Q1": 26.486586517333983, "Mean Q2": 26.48669245529175, "critic_loss": 1.4551536285281181, "batch_reward": 0.1657983990907669, "actor_loss": -26.67717029571533, "actor_target_entropy": -6.0, "actor_entropy": 5.827513349533081, "alpha_loss": 9.819932444952428e-05, "alpha_value": 0.007041035571971986, "duration": 325.6773519515991, "step": 96500}
{"episode_reward": 94.76263614185146, "episode": 194.0, "Q1 loss": 0.7646887798011303, "Q2 loss": 0.7693883737027645, "Mean Target Q": 26.418488876342774, "Mean Q1": 26.41818547821045, "Mean Q2": 26.418217613220214, "critic_loss": 1.5340771475434303, "batch_reward": 0.1669104859828949, "actor_loss": -26.580860786437988, "actor_target_entropy": -6.0, "actor_entropy": 5.852954431533814, "alpha_loss": 0.0006015171856270172, "alpha_value": 0.007006520452326302, "duration": 236.81289505958557, "step": 97000}
{"episode_reward": 133.9866727464438, "episode": 195.0, "Q1 loss": 0.766636234343052, "Q2 loss": 0.7720005358457566, "Mean Target Q": 26.50916962814331, "Mean Q1": 26.509475997924806, "Mean Q2": 26.50946381378174, "critic_loss": 1.5386367678642272, "batch_reward": 0.16631079921126365, "actor_loss": -26.690194572448732, "actor_target_entropy": -6.0, "actor_entropy": 5.818574409484864, "alpha_loss": 0.0011703257872723043, "alpha_value": 0.006945058674729895, "duration": 230.2342653274536, "step": 97500}
{"episode_reward": 81.54666485173311, "episode": 196.0, "Q1 loss": 0.6424473697543144, "Q2 loss": 0.6425557405352592, "Mean Target Q": 26.566463073730468, "Mean Q1": 26.566813816070557, "Mean Q2": 26.566855876922606, "critic_loss": 1.2850031068325043, "batch_reward": 0.16646402782201766, "actor_loss": -26.726351387023925, "actor_target_entropy": -6.0, "actor_entropy": 5.774279859542847, "alpha_loss": 0.0012889833617955445, "alpha_value": 0.006866538589712811, "duration": 480.4984543323517, "step": 98000}
{"episode_reward": 107.75937860390626, "episode": 197.0, "Q1 loss": 0.6737144839167595, "Q2 loss": 0.680513258010149, "Mean Target Q": 26.613686157226564, "Mean Q1": 26.613823062896728, "Mean Q2": 26.61391281890869, "critic_loss": 1.354227741420269, "batch_reward": 0.16751229977607726, "actor_loss": -26.737838714599608, "actor_target_entropy": -6.0, "actor_entropy": 5.736439092636108, "alpha_loss": 0.0003222351818694733, "alpha_value": 0.006818016265384808, "duration": 451.9689128398895, "step": 98500}
{"episode_reward": 114.49612810611494, "episode": 198.0, "Q1 loss": 0.8603176488876343, "Q2 loss": 0.8745315473675728, "Mean Target Q": 26.696728145599366, "Mean Q1": 26.69639979171753, "Mean Q2": 26.69634907913208, "critic_loss": 1.7348491963148116, "batch_reward": 0.16740027162432672, "actor_loss": -26.859978340148924, "actor_target_entropy": -6.0, "actor_entropy": 5.707247735977173, "alpha_loss": -0.0013572272994206286, "alpha_value": 0.0068675102462319474, "duration": 540.4224061965942, "step": 99000}
{"episode_reward": 93.49154334409177, "episode": 199.0, "Q1 loss": 0.7377724331617356, "Q2 loss": 0.736523149639368, "Mean Target Q": 26.803383338928224, "Mean Q1": 26.80301872253418, "Mean Q2": 26.802901119232178, "critic_loss": 1.474295583844185, "batch_reward": 0.1674825653731823, "actor_loss": -26.943105270385743, "actor_target_entropy": -6.0, "actor_entropy": 5.731928997039795, "alpha_loss": -0.0005312070369254797, "alpha_value": 0.006926992972527516, "duration": 336.14046025276184, "step": 99500}
{"episode_reward": 76.91684568361877, "episode": 200.0, "Q1 loss": 0.6935186439860083, "Q2 loss": 0.6900149496022112, "Mean Target Q": 26.799898671243856, "Mean Q1": 26.800783080901795, "Mean Q2": 26.800907922412208, "critic_loss": 1.3835335947827012, "batch_reward": 0.16657288721902577, "actor_loss": -26.938274574279784, "actor_target_entropy": -6.0, "actor_entropy": 5.715647382736206, "alpha_loss": 0.0004838525709346868, "alpha_value": 0.006921222822150022, "step": 99999}
